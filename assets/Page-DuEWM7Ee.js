import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Where that Unsloth Q0.01_K_M GGUF at?","link_flair_richtext":[{"e":"text","t":"Other"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxpidc","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"ups":617,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_y35oj","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Other","can_mod_post":false,"score":617,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/EDvGpwrJbGoDqgFUlnrOG6u2rjob-WEc_cUroT4VetA.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752287825,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/e2em6rucvccf1.jpeg","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?auto=webp&amp;s=b31ab99ee8084bc03a9a32ab253760eedf04ab2a","width":1125,"height":1125},"resolutions":[{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d086bd0581bd67e0ab1809820331054699c24205","width":108,"height":108},{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=53552ee8da77fc5558dccbff543e2ce95db3a1ec","width":216,"height":216},{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=119de6485072ce8c932511ac9212b2c54226d3c3","width":320,"height":320},{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4380544f532ff369f435679247aa08f3c9afdb66","width":640,"height":640},{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d80310d09a7861b28e80d1931667a5854f946377","width":960,"height":960},{"url":"https://preview.redd.it/e2em6rucvccf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=069a5b690eb18b3ada98a1195295e98d4876661a","width":1080,"height":1080}],"variants":{},"id":"KiVxcTo7hz7MHstS7c0wdFc8090G1XP_159_wJ9dN2U"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"7a7848d2-bf8e-11ed-8c2f-765d15199f78","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#94e044","id":"1lxpidc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Porespellar","discussion_type":null,"num_comments":33,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/","stickied":false,"url":"https://i.redd.it/e2em6rucvccf1.jpeg","subreddit_subscribers":498346,"created_utc":1752287825,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rs8bi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2p4m0x","score":6,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" yup, I hope the eval is true.  I have been saving to build a system capable of running deepseek better, looks like I need to keep saving.  I was going to go for about 384gb of ram on an older epyc build, looks like i need a newer build and to be going for 1TB of ram. :-/   Mad times!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2rs8bi","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yup, I hope the eval is true.  I have been saving to build a system capable of running deepseek better, looks like I need to keep saving.  I was going to go for about 384gb of ram on an older epyc build, looks like i need a newer build and to be going for 1TB of ram. :-/   Mad times!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2rs8bi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752346089,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752346089,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2p4m0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Deishu2088","can_mod_post":false,"created_utc":1752309549,"send_replies":true,"parent_id":"t1_n2otowb","score":31,"author_fullname":"t2_3ct0n120","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lmao take your time. I doubt anything will be usable on my system, but it'll be interesting to see what comes of this model over the next few weeks/months.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2p4m0x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lmao take your time. I doubt anything will be usable on my system, but it&amp;#39;ll be interesting to see what comes of this model over the next few weeks/months.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2p4m0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752309549,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qbpfz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ObscuraMirage","can_mod_post":false,"created_utc":1752329693,"send_replies":true,"parent_id":"t1_n2otowb","score":13,"author_fullname":"t2_1lhlr1gno5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you guys at Unsloth for your hard work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qbpfz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you guys at Unsloth for your hard work!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2qbpfz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752329693,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n2otowb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1752303173,"send_replies":true,"parent_id":"t3_1lxpidc","score":107,"author_fullname":"t2_1162lx9rgr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We were working on it for Kimi but there were some chat template issues. Also imatrix will take a minimum of 18 hours no joke! Sorry guys! ðŸ˜­","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2otowb","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We were working on it for Kimi but there were some chat template issues. Also imatrix will take a minimum of 18 hours no joke! Sorry guys! ðŸ˜­&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2otowb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752303173,"author_flair_text":"Llama 2","treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":107}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"609bf7d4-01f3-11f0-9760-5611c8333bee","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2nyzj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"You_Wen_AzzHu","can_mod_post":false,"created_utc":1752288742,"send_replies":true,"parent_id":"t3_1lxpidc","score":47,"author_fullname":"t2_p4oxcufl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's a larger v3.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nyzj7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"exllama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a larger v3.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2nyzj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752288742,"author_flair_text":"exllama","treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2nyjed","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OGScottingham","can_mod_post":false,"created_utc":1752288570,"send_replies":true,"parent_id":"t3_1lxpidc","score":68,"author_fullname":"t2_5p0rvz5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This made me lol. It hit too close to home.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nyjed","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This made me lol. It hit too close to home.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2nyjed/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752288570,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":68}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oa5gj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sergeysi","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2o6jwv","score":24,"author_fullname":"t2_qv27h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It seems K2 is trained in FP8. 1TB for unquantised 1T parameters.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2oa5gj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems K2 is trained in FP8. 1TB for unquantised 1T parameters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2oa5gj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752293332,"author_flair_text":null,"treatment_tags":[],"created_utc":1752293332,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oik9q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kind-Access1026","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2o6jwv","score":8,"author_fullname":"t2_u47kpxen","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" Their safetensors files only add up to 1 TB,Â  Because They released FP8 version","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2oik9q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their safetensors files only add up to 1 TB,Â  Because They released FP8 version&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2oik9q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752297222,"author_flair_text":null,"treatment_tags":[],"created_utc":1752297222,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n2o6jwv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeProgrammer99","can_mod_post":false,"created_utc":1752291814,"send_replies":true,"parent_id":"t1_n2nxuot","score":47,"author_fullname":"t2_w4j8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hard to say what \\"work decently\\" means exactly, but... Full precision (that is, assuming FP16) for 1T tokens would be 2 TB. Their safetensors files only add up to 1 TB, so I guess they uploaded it at half precision. To keep a *decent* amount of the intelligence, let's just say 2.5bpw, so about 320 GB for the model.\\n\\nBy my calculations, their KV cache requires a whopping 1708 KB *per token*, so the max 131,072 context would be another 213.5 GB at full precision. Maybe it wouldn't suffer too much from halving the precision given that most open-weights models use 1/10 that much memory per token, so it should be able to run with roughly 427 GB of RAM.\\n\\n(The KV calculation is hidden layers \\\\[61\\\\] times hidden size \\\\[7168\\\\] times KV head count \\\\[64\\\\] divided by attention head count \\\\[64\\\\] divided by 256, and the 256 comes from 2 per query-value *pair* \\\\* 2 bytes for FP16 precision / 1024 bytes per KB.)","edited":1752292452,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2o6jwv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hard to say what &amp;quot;work decently&amp;quot; means exactly, but... Full precision (that is, assuming FP16) for 1T tokens would be 2 TB. Their safetensors files only add up to 1 TB, so I guess they uploaded it at half precision. To keep a &lt;em&gt;decent&lt;/em&gt; amount of the intelligence, let&amp;#39;s just say 2.5bpw, so about 320 GB for the model.&lt;/p&gt;\\n\\n&lt;p&gt;By my calculations, their KV cache requires a whopping 1708 KB &lt;em&gt;per token&lt;/em&gt;, so the max 131,072 context would be another 213.5 GB at full precision. Maybe it wouldn&amp;#39;t suffer too much from halving the precision given that most open-weights models use 1/10 that much memory per token, so it should be able to run with roughly 427 GB of RAM.&lt;/p&gt;\\n\\n&lt;p&gt;(The KV calculation is hidden layers [61] times hidden size [7168] times KV head count [64] divided by attention head count [64] divided by 256, and the 256 comes from 2 per query-value &lt;em&gt;pair&lt;/em&gt; * 2 bytes for FP16 precision / 1024 bytes per KB.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2o6jwv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752291814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2puwsd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"poli-cya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2p8dc8","score":6,"author_fullname":"t2_q8g93lhv4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That seems to match well with /u/DeProgrammer99's math above, 1TB for the model and ~215GB for the KV cache.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2puwsd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That seems to match well with &lt;a href=\\"/u/DeProgrammer99\\"&gt;/u/DeProgrammer99&lt;/a&gt;&amp;#39;s math above, 1TB for the model and ~215GB for the KV cache.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2puwsd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752323489,"author_flair_text":null,"treatment_tags":[],"created_utc":1752323489,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ph51y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crinkez","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2p8dc8","score":9,"author_fullname":"t2_1l1e573g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"RIP my rtx 3060 12GB","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ph51y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RIP my rtx 3060 12GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2ph51y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752317019,"author_flair_text":null,"treatment_tags":[],"created_utc":1752317019,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qent7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2p8dc8","score":1,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"With AWQ quants, it should be possible to run it on 8x H100/ 8x A100 setup that's quite common. And making those quants should be less than $1000 in compute, around $700","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2qent7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With AWQ quants, it should be possible to run it on 8x H100/ 8x A100 setup that&amp;#39;s quite common. And making those quants should be less than $1000 in compute, around $700&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2qent7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752330674,"author_flair_text":null,"treatment_tags":[],"created_utc":1752330674,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2p8dc8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"moncallikta","can_mod_post":false,"created_utc":1752311836,"send_replies":true,"parent_id":"t1_n2nxuot","score":15,"author_fullname":"t2_15ju4l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Their deployment guide \\\\[1\\\\] says a node of 16 H100s is the starting point to launch it. Which means 16\\\\*80 GB = 1280 GB VRAM.\\n\\n\\\\[1\\\\]: [https://github.com/MoonshotAI/Kimi-K2/blob/main/docs/deploy\\\\_guidance.md](https://github.com/MoonshotAI/Kimi-K2/blob/main/docs/deploy_guidance.md)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2p8dc8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their deployment guide [1] says a node of 16 H100s is the starting point to launch it. Which means 16*80 GB = 1280 GB VRAM.&lt;/p&gt;\\n\\n&lt;p&gt;[1]: &lt;a href=\\"https://github.com/MoonshotAI/Kimi-K2/blob/main/docs/deploy_guidance.md\\"&gt;https://github.com/MoonshotAI/Kimi-K2/blob/main/docs/deploy_guidance.md&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2p8dc8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752311836,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qeykh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pq34v","score":13,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bro all of that is straight up made up, llms make it so easy to put out fake stuff that sounds genuine at the first glance.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2qeykh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bro all of that is straight up made up, llms make it so easy to put out fake stuff that sounds genuine at the first glance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2qeykh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752330772,"author_flair_text":null,"treatment_tags":[],"created_utc":1752330772,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qf5rb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pr5b3","score":7,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it doesn't, it's an LLM hallucination. There's no 4-bit gptq/awq quant released yet, and if it will be released by someone, it'll weight about 500GB and will be runnable on 8x h100, not 2x h100.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qf5rb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it doesn&amp;#39;t, it&amp;#39;s an LLM hallucination. There&amp;#39;s no 4-bit gptq/awq quant released yet, and if it will be released by someone, it&amp;#39;ll weight about 500GB and will be runnable on 8x h100, not 2x h100.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2qf5rb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752330838,"author_flair_text":null,"treatment_tags":[],"created_utc":1752330838,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pr5b3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pq34v","score":1,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How does the 4-bit math work for those cards? 4x RTX A6000 is 192GB VRAM, but surely a 4-bit quant would require ~ 256GB","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2pr5b3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does the 4-bit math work for those cards? 4x RTX A6000 is 192GB VRAM, but surely a 4-bit quant would require ~ 256GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pr5b3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752321892,"author_flair_text":null,"treatment_tags":[],"created_utc":1752321892,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pq34v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"ies7","can_mod_post":false,"created_utc":1752321425,"send_replies":true,"parent_id":"t1_n2nxuot","score":-8,"author_fullname":"t2_ifa1n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Source: I asked kimi.com yesterday.Â Â \\n\\n\\nThe model is an 8-expert MoE with 32 B active parameters per token. Moonshotâ€™s reference spec is:\\n\\n\\nâ€¢ GPU: 8Ã—A100 80 GB or 8Ã—H100 80 GB for full-precision inference at 60â€“70 tokens/s.\\n\\n\\nâ€¢ CPU: 64 cores (AMD EPYC or Intel Xeon) for the auxiliary routing logic.\\n\\n\\nâ€¢ RAM: 600 GB+ system memory to keep the 2 TB of sharded weights hot-mapped.\\n\\n\\nâ€¢ Storage: 3 TB NVMe (4 GB/s+)â€”weights decompress on first load and stay resident.\\n\\n\\n\\nThe company also released a 4-bit GPTQ checkpoint that drops the VRAM requirement to â‰ˆ 160 GB total (2Ã—A100 80 GB or 4Ã—RTX 4090 24 GB) at ~25 tokens/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pq34v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Source: I asked kimi.com yesterday.Â Â &lt;/p&gt;\\n\\n&lt;p&gt;The model is an 8-expert MoE with 32 B active parameters per token. Moonshotâ€™s reference spec is:&lt;/p&gt;\\n\\n&lt;p&gt;â€¢ GPU: 8Ã—A100 80 GB or 8Ã—H100 80 GB for full-precision inference at 60â€“70 tokens/s.&lt;/p&gt;\\n\\n&lt;p&gt;â€¢ CPU: 64 cores (AMD EPYC or Intel Xeon) for the auxiliary routing logic.&lt;/p&gt;\\n\\n&lt;p&gt;â€¢ RAM: 600 GB+ system memory to keep the 2 TB of sharded weights hot-mapped.&lt;/p&gt;\\n\\n&lt;p&gt;â€¢ Storage: 3 TB NVMe (4 GB/s+)â€”weights decompress on first load and stay resident.&lt;/p&gt;\\n\\n&lt;p&gt;The company also released a 4-bit GPTQ checkpoint that drops the VRAM requirement to â‰ˆ 160 GB total (2Ã—A100 80 GB or 4Ã—RTX 4090 24 GB) at ~25 tokens/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pq34v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752321425,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}}],"before":null}},"user_reports":[],"saved":false,"id":"n2nxuot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eralyon","can_mod_post":false,"created_utc":1752288303,"send_replies":true,"parent_id":"t3_1lxpidc","score":12,"author_fullname":"t2_9atnv3r4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am curious to know how much memory one needs to make it work decently?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nxuot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am curious to know how much memory one needs to make it work decently?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2nxuot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752288303,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2reqfo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nananashi3","can_mod_post":false,"created_utc":1752341891,"send_replies":true,"parent_id":"t3_1lxpidc","score":7,"author_fullname":"t2_soegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unless I'm wrong, a 12+/-8GB GPU should be able to fit a Q0.1 quant, so Q0.01 sounds rather excessive and extra dumbed down. Q0.05 might be a sweet spot perhaps.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2reqfo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless I&amp;#39;m wrong, a 12+/-8GB GPU should be able to fit a Q0.1 quant, so Q0.01 sounds rather excessive and extra dumbed down. Q0.05 might be a sweet spot perhaps.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2reqfo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752341891,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2p4ubh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"taurentipper","can_mod_post":false,"created_utc":1752309686,"send_replies":true,"parent_id":"t3_1lxpidc","score":3,"author_fullname":"t2_kxjq7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So good xD","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2p4ubh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So good xD&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2p4ubh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752309686,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2pytgq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pt85m","score":5,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you, this is interesting context.\\n\\nFrom a technical perspective my primary use cases aren't affected by censorship in the slightest, but from an ethical perspective I do not wish to support, popularize, or even condone censored models.\\n\\nA parental exception to the notion of censorship sits comfortably with me. My kids are still young enough that I wish to control access to information and imagery in an age-appropriate manner, however I'm still against censorship of LLMs in this context, preferring guardrails around the LLM instead.\\n\\nThis way I delegate the question \\"what age is the appropriate age?\\" to the process of natural selection. Once my kids have successfully hacked around the guardrails and into Pandora's box I can confer congratulations on their cleverness while thanking the universe for relieving me of a difficult parenting decision.\\n\\nWinner winner, chicken dinner.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pytgq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you, this is interesting context.&lt;/p&gt;\\n\\n&lt;p&gt;From a technical perspective my primary use cases aren&amp;#39;t affected by censorship in the slightest, but from an ethical perspective I do not wish to support, popularize, or even condone censored models.&lt;/p&gt;\\n\\n&lt;p&gt;A parental exception to the notion of censorship sits comfortably with me. My kids are still young enough that I wish to control access to information and imagery in an age-appropriate manner, however I&amp;#39;m still against censorship of LLMs in this context, preferring guardrails around the LLM instead.&lt;/p&gt;\\n\\n&lt;p&gt;This way I delegate the question &amp;quot;what age is the appropriate age?&amp;quot; to the process of natural selection. Once my kids have successfully hacked around the guardrails and into Pandora&amp;#39;s box I can confer congratulations on their cleverness while thanking the universe for relieving me of a difficult parenting decision.&lt;/p&gt;\\n\\n&lt;p&gt;Winner winner, chicken dinner.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pytgq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752325033,"author_flair_text":null,"treatment_tags":[],"created_utc":1752325033,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pt85m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2prebc","score":7,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Prefill is starting the response with something to steer the model. ex. \\"Yes I am going to reply uncensored now:\\"\\n\\nSafetymaxxed means it's full of refusals, in this case even with filled up context and system prompts that tell it not to be. It is *not* like deepseek was and from the examples I saw these guys went hard into the censorship. I'm not downloading 300gb of model over days for all that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2pt85m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Prefill is starting the response with something to steer the model. ex. &amp;quot;Yes I am going to reply uncensored now:&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Safetymaxxed means it&amp;#39;s full of refusals, in this case even with filled up context and system prompts that tell it not to be. It is &lt;em&gt;not&lt;/em&gt; like deepseek was and from the examples I saw these guys went hard into the censorship. I&amp;#39;m not downloading 300gb of model over days for all that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pt85m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752322789,"author_flair_text":null,"treatment_tags":[],"created_utc":1752322789,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n2prebc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1752322002,"send_replies":true,"parent_id":"t1_n2pjy64","score":6,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you explain what all these words mean? Safetymaxxed? Prefill?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2prebc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you explain what all these words mean? Safetymaxxed? Prefill?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxpidc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2prebc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752322002,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pjy64","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752318488,"send_replies":true,"parent_id":"t3_1lxpidc","score":2,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"People already saying it's safetymaxxed to where you'd have to use a prefill. Disappointment inbound.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pjy64","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People already saying it&amp;#39;s safetymaxxed to where you&amp;#39;d have to use a prefill. Disappointment inbound.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pjy64/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752318488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2p7zoa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ed_ww","can_mod_post":false,"created_utc":1752311604,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_12h9lfdo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe someone will make some distills? âœŒðŸ¼ðŸ˜„","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2p7zoa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe someone will make some distills? âœŒðŸ¼ðŸ˜„&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2p7zoa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752311604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2pav39","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1752313375,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"When the number of active parameters is something you could barely fit if it was a dense model, itâ€™s safe to say itâ€™s not a model for your hardware.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pav39","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When the number of active parameters is something you could barely fit if it was a dense model, itâ€™s safe to say itâ€™s not a model for your hardware.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2pav39/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752313375,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rdzq6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1752341667,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"*diagram not to scale","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rdzq6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;*diagram not to scale&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2rdzq6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752341667,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2u8097","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gcavalcante8808","can_mod_post":false,"created_utc":1752377039,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_sgcos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hahaha I was not prepares for IQ001XXs hahaha","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2u8097","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hahaha I was not prepares for IQ001XXs hahaha&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2u8097/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752377039,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2udwve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chillinewman","can_mod_post":false,"created_utc":1752379573,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_6lvn2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is only gonna get bigger.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2udwve","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is only gonna get bigger.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2udwve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752379573,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qfch3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1752330900,"send_replies":true,"parent_id":"t3_1lxpidc","score":1,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We need quantum compute at this stage. 1 bit of VRAM can fit 10 simultaneous states.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qfch3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need quantum compute at this stage. 1 bit of VRAM can fit 10 simultaneous states.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2qfch3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752330900,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oitek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kind-Access1026","can_mod_post":false,"created_utc":1752297347,"send_replies":true,"parent_id":"t3_1lxpidc","score":-2,"author_fullname":"t2_u47kpxen","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pay their API bills &amp; forget your 3090 on fire, everybody wins. You will cool in summer","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2oitek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pay their API bills &amp;amp; forget your 3090 on fire, everybody wins. You will cool in summer&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxpidc/where_that_unsloth_q001_k_m_gguf_at/n2oitek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752297347,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxpidc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
