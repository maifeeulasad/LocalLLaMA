import{j as l}from"./index-BUtHYhT3.js";import{R as e}from"./RedditPostRenderer-BaN1Fn7z.js";import"./index-Cli9kp5v.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Build vLLM on  CUDA 12.9, Kernel 6.15.2, NVIDIA 575.64, PyTorch 2.9cu129 Nightly\\n\\nLet's fucking go!!!!!!!!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Build vLLM on  CUDA 12.9, Kernel 6.15.2, NVIDIA 575.64, PyTorch 2.9cu129 Nightly","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lshe4q","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.33,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1rig07ocmc","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751742225,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Build vLLM on  CUDA 12.9, Kernel 6.15.2, NVIDIA 575.64, PyTorch 2.9cu129 Nightly&lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s fucking go!!!!!!!!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lshe4q","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Sorry_Ad191","discussion_type":null,"num_comments":18,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/","subreddit_subscribers":494986,"created_utc":1751742225,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1itgs1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1isz3r","score":1,"author_fullname":"t2_a04uj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh nice, thanks for the tip!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1itgs1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh nice, thanks for the tip!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1itgs1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751745500,"author_flair_text":null,"treatment_tags":[],"created_utc":1751745500,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1isz3r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751745333,"send_replies":true,"parent_id":"t1_n1is7qr","score":3,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"    python -m pip install -e . --no-build-isolation\\n    python -m pip install -e . --no-build-isolation -v # -v so I can see what step its on","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1isz3r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;pre&gt;&lt;code&gt;python -m pip install -e . --no-build-isolation\\npython -m pip install -e . --no-build-isolation -v # -v so I can see what step its on\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1isz3r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751745333,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1j34fb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1j158f","score":1,"author_fullname":"t2_a04uj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, the readme is more than enough to get it installed.","edited":false,"author_flair_css_class":null,"name":"t1_n1j34fb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, the readme is more than enough to get it installed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lshe4q","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1j34fb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751748663,"author_flair_text":null,"collapsed":false,"created_utc":1751748663,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1j158f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1iyziy","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh wow ok. I heard flashinfer is the way to go. Any special sauce to compile it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1j158f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh wow ok. I heard flashinfer is the way to go. Any special sauce to compile it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1j158f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751748025,"author_flair_text":null,"treatment_tags":[],"created_utc":1751748025,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1iyziy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ixwb3","score":1,"author_fullname":"t2_a04uj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It just finished for me with a missing ProcessorMixin module error of which I canâ€™t pip install. \\n\\nThe commands Iâ€™m running are largely the same outside Iâ€™m using UV, Iâ€™m installing cuda.txt and not common.txt in requirements, Iâ€™m also compiling transformers and flashInfer. \\n\\nI might strip out the transformers bit and try again.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1iyziy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It just finished for me with a missing ProcessorMixin module error of which I canâ€™t pip install. &lt;/p&gt;\\n\\n&lt;p&gt;The commands Iâ€™m running are largely the same outside Iâ€™m using UV, Iâ€™m installing cuda.txt and not common.txt in requirements, Iâ€™m also compiling transformers and flashInfer. &lt;/p&gt;\\n\\n&lt;p&gt;I might strip out the transformers bit and try again.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1iyziy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751747319,"author_flair_text":null,"treatment_tags":[],"created_utc":1751747319,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ixwb3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751746967,"send_replies":true,"parent_id":"t1_n1is7qr","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Any luck?\\n\\nI'm building again, this is what I'm trying:\\n\\n  \\nVerified NVIDIA-SMI for Driver 575.62 and CUDA 12.9\\n\\n\\n\\ngit clone [https://github.com/vllm-project/vllm.git](https://github.com/vllm-project/vllm.git)\\n\\ncd vllm\\n\\npython -m venv vllm\\n\\nsource ./vllm/bin/activate\\n\\n\\n\\npip3 install --pre torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/nightly/cu129](https://download.pytorch.org/whl/nightly/cu129)  \\\\# note changed cu128 to cu129\\n\\n\\n\\npython use\\\\_existing\\\\_torch.py\\n\\npython -m pip install -r requirements/build.txt\\n\\npython -m pip install -r requirements/common.txt\\n\\npython -m pip install -e . --no-build-isolation -v    # -v to see which step its on","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ixwb3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any luck?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m building again, this is what I&amp;#39;m trying:&lt;/p&gt;\\n\\n&lt;p&gt;Verified NVIDIA-SMI for Driver 575.62 and CUDA 12.9&lt;/p&gt;\\n\\n&lt;p&gt;git clone &lt;a href=\\"https://github.com/vllm-project/vllm.git\\"&gt;https://github.com/vllm-project/vllm.git&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;cd vllm&lt;/p&gt;\\n\\n&lt;p&gt;python -m venv vllm&lt;/p&gt;\\n\\n&lt;p&gt;source ./vllm/bin/activate&lt;/p&gt;\\n\\n&lt;p&gt;pip3 install --pre torch torchvision torchaudio --index-url &lt;a href=\\"https://download.pytorch.org/whl/nightly/cu129\\"&gt;https://download.pytorch.org/whl/nightly/cu129&lt;/a&gt;  # note changed cu128 to cu129&lt;/p&gt;\\n\\n&lt;p&gt;python use_existing_torch.py&lt;/p&gt;\\n\\n&lt;p&gt;python -m pip install -r requirements/build.txt&lt;/p&gt;\\n\\n&lt;p&gt;python -m pip install -r requirements/common.txt&lt;/p&gt;\\n\\n&lt;p&gt;python -m pip install -e . --no-build-isolation -v    # -v to see which step its on&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1ixwb3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751746967,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1is7qr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"created_utc":1751745077,"send_replies":true,"parent_id":"t3_1lshe4q","score":2,"author_fullname":"t2_a04uj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Iâ€™m still compiling ðŸ˜‘","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1is7qr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Iâ€™m still compiling ðŸ˜‘&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1is7qr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751745077,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1im5ld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751743044,"send_replies":true,"parent_id":"t3_1lshe4q","score":3,"author_fullname":"t2_1rig07ocmc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Successfully installed vllm-0.9.2rc2.dev26+gcf4cd5398.d20250705.cu129","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1im5ld","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Successfully installed vllm-0.9.2rc2.dev26+gcf4cd5398.d20250705.cu129&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1im5ld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751743044,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1iqfvq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ipnyt","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When attempting to start vLLM I got \\"ImportError: /home/snow/miniconda3/bin/../lib/libstdc++.so.6: version \\\\\`CXXABI\\\\_1.3.15' not found (required by /home/snow/vllm/vllm/\\\\_C.abi3.so)\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1iqfvq","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When attempting to start vLLM I got &amp;quot;ImportError: /home/snow/miniconda3/bin/../lib/libstdc++.so.6: version \`CXXABI_1.3.15&amp;#39; not found (required by /home/snow/vllm/vllm/_C.abi3.so)&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1iqfvq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751744489,"author_flair_text":null,"treatment_tags":[],"created_utc":1751744489,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ipnyt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751744229,"send_replies":true,"parent_id":"t1_n1ior16","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I got some errors. I think it was because of my miniconda env. So rebuilding now in a fresh venv instead. Damn I wish it was easier to use the new nvidia cards with vLLM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ipnyt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I got some errors. I think it was because of my miniconda env. So rebuilding now in a fresh venv instead. Damn I wish it was easier to use the new nvidia cards with vLLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1ipnyt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751744229,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ior16","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"created_utc":1751743917,"send_replies":true,"parent_id":"t3_1lshe4q","score":1,"author_fullname":"t2_a04uj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hopefully it works consistently this time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ior16","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hopefully it works consistently this time.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1ior16/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751743917,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1jltki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751755127,"send_replies":true,"parent_id":"t1_n1ji96s","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"not sure i couldn't get it to work with with 2 gpus --tensor-parallelism (-tp 2) but it seems some people solved thy by upgrading nvidia-nccl-cu12 to a newer version. I've been able to run models on 1 Blackwell gpu with just pip install vllm for a little bit now.\\n\\nthere were also some new kernel merged a couple days ago I think for fp8  or something","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1jltki","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;not sure i couldn&amp;#39;t get it to work with with 2 gpus --tensor-parallelism (-tp 2) but it seems some people solved thy by upgrading nvidia-nccl-cu12 to a newer version. I&amp;#39;ve been able to run models on 1 Blackwell gpu with just pip install vllm for a little bit now.&lt;/p&gt;\\n\\n&lt;p&gt;there were also some new kernel merged a couple days ago I think for fp8  or something&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1jltki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751755127,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1jr0cj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751757030,"send_replies":true,"parent_id":"t1_n1ji96s","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This might be working now, I had to increase /dev/shim, it kept crashing and I didn't understand why at first. finally adding --shm-size=2gb to the docker run command seems to work\\n\\n    docker run --gpus all \\\\\\n      --shm-size=2gb \\\\  # Sets /dev/shm to 2GB inside container\\n      -p 5000:5000 \\\\\\n      -v ~/.cache/huggingface:/root/.cache/huggingface \\\\\\n      nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3 bash","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1jr0cj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This might be working now, I had to increase /dev/shim, it kept crashing and I didn&amp;#39;t understand why at first. finally adding --shm-size=2gb to the docker run command seems to work&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;docker run --gpus all \\\\\\n  --shm-size=2gb \\\\  # Sets /dev/shm to 2GB inside container\\n  -p 5000:5000 \\\\\\n  -v ~/.cache/huggingface:/root/.cache/huggingface \\\\\\n  nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3 bash\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1jr0cj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751757030,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ji96s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1751753841,"send_replies":true,"parent_id":"t3_1lshe4q","score":1,"author_fullname":"t2_9so78ol2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anything different than compiling for a 5090 a month ago? been running fine with a 9.1+githashhere for a while now.\\n\\nhttps://github.com/vllm-project/vllm/issues/18916\\n\\nlots of good info here for alternatives with docker or w/e","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ji96s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anything different than compiling for a 5090 a month ago? been running fine with a 9.1+githashhere for a while now.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/vllm-project/vllm/issues/18916\\"&gt;https://github.com/vllm-project/vllm/issues/18916&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;lots of good info here for alternatives with docker or w/e&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1ji96s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751753841,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1kogvs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751770251,"send_replies":true,"parent_id":"t3_1lshe4q","score":1,"author_fullname":"t2_1rig07ocmc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I got it working with\\n\\ndocker run --gpus all -it -p 8000:8000 --shm-size=2gb -v \\\\~/vllm:/vllm   -v /mnt/vol/huggingface:/root/.cache/huggingface  -e NCCL\\\\_CUMEM\\\\_ENABLE=0  [nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3](http://nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3) bash\\n\\nBut its slower than llama.cpp!!! Edit: Ok when doing 4 concurrent requests it blows llama.cpp out of the water!","edited":1751770728,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1kogvs","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I got it working with&lt;/p&gt;\\n\\n&lt;p&gt;docker run --gpus all -it -p 8000:8000 --shm-size=2gb -v ~/vllm:/vllm   -v /mnt/vol/huggingface:/root/.cache/huggingface  -e NCCL_CUMEM_ENABLE=0  &lt;a href=\\"http://nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3\\"&gt;nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3&lt;/a&gt; bash&lt;/p&gt;\\n\\n&lt;p&gt;But its slower than llama.cpp!!! Edit: Ok when doing 4 concurrent requests it blows llama.cpp out of the water!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1kogvs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751770251,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1k9wp5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1jxcmv","score":1,"author_fullname":"t2_1rig07ocmc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"resorting to try and use this container instead with docker \\"nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1k9wp5","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;resorting to try and use this container instead with docker &amp;quot;nvcr.io/nvidia/tritonserver:25.06-vllm-python-py3&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1k9wp5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751764263,"author_flair_text":null,"treatment_tags":[],"created_utc":1751764263,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1jxcmv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DAlmighty","can_mod_post":false,"created_utc":1751759337,"send_replies":true,"parent_id":"t1_n1jajq8","score":2,"author_fullname":"t2_a04uj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Iâ€™m getting this error now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1jxcmv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Iâ€™m getting this error now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lshe4q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1jxcmv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751759337,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1jajq8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751751154,"send_replies":true,"parent_id":"t3_1lshe4q","score":0,"author_fullname":"t2_1rig07ocmc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"# undefined symbol: _Z35cutlass_blockwise_scaled_grouped_mmRN2at6TensorERKS0_S3_S3_S3_S3_S3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1jajq8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;h1&gt;undefined symbol: _Z35cutlass_blockwise_scaled_grouped_mmRN2at6TensorERKS0_S3_S3_S3_S3_S3&lt;/h1&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lshe4q/build_vllm_on_cuda_129_kernel_6152_nvidia_57564/n1jajq8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751751154,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lshe4q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),o=()=>l.jsx(e,{data:t});export{o as default};
