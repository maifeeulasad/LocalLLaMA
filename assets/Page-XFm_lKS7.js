import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"You probably already know about my [benchmark](https://www.designarena.ai/), but here's [context](https://www.reddit.com/r/LocalLLaMA/comments/1lxth6s/comment/n2qoqtk/?context=3) if you missed it. The tldr is that it's a crowdsource benchmark that takes human preferences on frontend and image generations from different models to produce a leaderboard ranking for which models are currently the best at UI and design generation. \\n\\nI'm going to try to keep these update posts to once-a-week or every other week to not come off as spam (sorry for that earlier, though I'm just seeing interesting results). Also, we realize there are flaws to the leaderboard (as all leaderboards and benchmarks have) that we're progressively trying to improve, but think it has been a good barometer for evaluating the models in particular tiers when it comes to coding. \\n\\nAnyways, since my last update on the 11th, we've added a few models, and in the last 24 hours, specifically Qwen3-235B-A22B-Instruct-2507 and Qwen3-Coder (less than an hour ago). Though the sample size is still very small, Qwen3-235B-A22B-Instruct-2507 appears to be killing it. I was reading through remarks on Twitter and Reddit that the Instruct model was on par with Opus which I thought was hyperbole at the time, but maybe that claim will hold true in the long run. \\n\\nWhat has been your experience with these Qwen models and what do you think? Open source is killing it right now. ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"UI/UX benchmark update 7/22: Newest Qwen models added, Qwen3 takes the lead in terms of win rate (though still early)","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":92,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6ztb2","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"ups":74,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_98ouo03z","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":74,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/yOnjsudSDwwMasrhJ1H10swcbMrmX3jIP8XzRlgDA6k.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753244753,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;You probably already know about my &lt;a href=\\"https://www.designarena.ai/\\"&gt;benchmark&lt;/a&gt;, but here&amp;#39;s &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lxth6s/comment/n2qoqtk/?context=3\\"&gt;context&lt;/a&gt; if you missed it. The tldr is that it&amp;#39;s a crowdsource benchmark that takes human preferences on frontend and image generations from different models to produce a leaderboard ranking for which models are currently the best at UI and design generation. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m going to try to keep these update posts to once-a-week or every other week to not come off as spam (sorry for that earlier, though I&amp;#39;m just seeing interesting results). Also, we realize there are flaws to the leaderboard (as all leaderboards and benchmarks have) that we&amp;#39;re progressively trying to improve, but think it has been a good barometer for evaluating the models in particular tiers when it comes to coding. &lt;/p&gt;\\n\\n&lt;p&gt;Anyways, since my last update on the 11th, we&amp;#39;ve added a few models, and in the last 24 hours, specifically Qwen3-235B-A22B-Instruct-2507 and Qwen3-Coder (less than an hour ago). Though the sample size is still very small, Qwen3-235B-A22B-Instruct-2507 appears to be killing it. I was reading through remarks on Twitter and Reddit that the Instruct model was on par with Opus which I thought was hyperbole at the time, but maybe that claim will hold true in the long run. &lt;/p&gt;\\n\\n&lt;p&gt;What has been your experience with these Qwen models and what do you think? Open source is killing it right now. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/lcjgeavzvjef1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/lcjgeavzvjef1.png?auto=webp&amp;s=31df1bef3a627d2ba33e030e86d5d66a2b9b0ee0","width":1333,"height":881},"resolutions":[{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d4b029e6012124dc9f449076bfcd1f4cfdf2ac1","width":108,"height":71},{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1205127af73fd4083008a096571d899bc2b6aadd","width":216,"height":142},{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf64c9f604b8aef2fea7c80e52aa0d92de5fb99a","width":320,"height":211},{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8550da9c204aaebc89b401002be06079a6beec29","width":640,"height":422},{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1c69386465fdc08532cb1ba6e8d60c731e32bc4b","width":960,"height":634},{"url":"https://preview.redd.it/lcjgeavzvjef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c87d7c433bad8b28ef732c515d7baa7baf7a784c","width":1080,"height":713}],"variants":{},"id":"nLkR4n4kuyoAJ5FYt5FCPobA_n2hnoAkT68Lm-yyAho"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m6ztb2","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Accomplished-Copy332","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/","stickied":false,"url":"https://i.redd.it/lcjgeavzvjef1.png","subreddit_subscribers":503518,"created_utc":1753244753,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4pgj80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Utoko","can_mod_post":false,"created_utc":1753276185,"send_replies":true,"parent_id":"t1_n4p1syr","score":2,"author_fullname":"t2_6a8ry","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I guess a bit of hype leads to more votes : o\\n\\nbut ye it dropped already to 6. place with 81 votes now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pgj80","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I guess a bit of hype leads to more votes : o&lt;/p&gt;\\n\\n&lt;p&gt;but ye it dropped already to 6. place with 81 votes now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4pgj80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753276185,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4p1syr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kathane37","can_mod_post":false,"created_utc":1753270881,"send_replies":true,"parent_id":"t3_1m6ztb2","score":6,"author_fullname":"t2_91nqzv8x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You need more vote before it became statisticaly significant \\nYour work is good but please at least wait for a few hundred vote before displaying results","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4p1syr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need more vote before it became statisticaly significant \\nYour work is good but please at least wait for a few hundred vote before displaying results&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4p1syr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753270881,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ztb2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4oh9ee","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Accomplished-Copy332","can_mod_post":false,"created_utc":1753260460,"send_replies":true,"parent_id":"t1_n4o6yu6","score":4,"author_fullname":"t2_98ouo03z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, we’re working on adding them. Inference time for those models are just a bit too slow currently for the platform but we’re working with the developers of those models and providers to add it as a part of the benchmark.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oh9ee","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, we’re working on adding them. Inference time for those models are just a bit too slow currently for the platform but we’re working with the developers of those models and providers to add it as a part of the benchmark.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4oh9ee/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260460,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4o6yu6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1753254552,"send_replies":true,"parent_id":"t3_1m6ztb2","score":4,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you add [UIGEN-X-8B](https://www.reddit.com/r/LocalLLaMA/comments/1m2ukka/uigenx8b_hybrid_reasoning_model_built_for_direct/) as well as [UIGEN-T3-32B-Preview](https://www.reddit.com/r/LocalLLaMA/comments/1l808xc/get_claude_at_home_new_ui_generation_model_for/) to the list of tested models for website generation? They're dedicated extensive fine-tunes for that purpose. It'd be interesting to see how they perform, compared to their vanilla versions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o6yu6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you add &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1m2ukka/uigenx8b_hybrid_reasoning_model_built_for_direct/\\"&gt;UIGEN-X-8B&lt;/a&gt; as well as &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1l808xc/get_claude_at_home_new_ui_generation_model_for/\\"&gt;UIGEN-T3-32B-Preview&lt;/a&gt; to the list of tested models for website generation? They&amp;#39;re dedicated extensive fine-tunes for that purpose. It&amp;#39;d be interesting to see how they perform, compared to their vanilla versions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4o6yu6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753254552,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ztb2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ohjb8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Copy332","can_mod_post":false,"created_utc":1753260617,"send_replies":true,"parent_id":"t1_n4ocx1c","score":2,"author_fullname":"t2_98ouo03z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree which is why I noted the sample size is still very small to be statistically significant but it is interesting to see how Qwen3 is doing well among its very small sample size. It’ll be interesting to see how it holds up when we receive more data for it. \\n\\nNot making any kind of rigorous statistical conclusion here, just noting that qwen3 has been really interesting to see from a coding perspective so far.\\n\\nOne thing to note is that you’re right that there’s a lot of uncertainty here. For instance, just after 20 more comparisons, Qwen3 went from #1 to #4 so yes too early to make a definitive conclusion. That said, it is interesting to see how some of these open source models are still punching up against their weight class.","edited":1753260864,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ohjb8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree which is why I noted the sample size is still very small to be statistically significant but it is interesting to see how Qwen3 is doing well among its very small sample size. It’ll be interesting to see how it holds up when we receive more data for it. &lt;/p&gt;\\n\\n&lt;p&gt;Not making any kind of rigorous statistical conclusion here, just noting that qwen3 has been really interesting to see from a coding perspective so far.&lt;/p&gt;\\n\\n&lt;p&gt;One thing to note is that you’re right that there’s a lot of uncertainty here. For instance, just after 20 more comparisons, Qwen3 went from #1 to #4 so yes too early to make a definitive conclusion. That said, it is interesting to see how some of these open source models are still punching up against their weight class.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4ohjb8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260617,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ocx1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rockbandit","can_mod_post":false,"created_utc":1753257936,"send_replies":true,"parent_id":"t3_1m6ztb2","score":2,"author_fullname":"t2_3uw17","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pardon my contrarian take here, but the comparison between these two models is statistically meaningless due to the wildly different sample sizes. Qwen3 shows 57 total trials, while Opus 4 shows 2,237 trials.\\n\\nSure, the win rates appear similar (71.9% vs. 71.4%), but the level of uncertainty in the first model's performance is ridiculous. Something like 12%.\\n\\nThat means its true win rate could be as low as ~60% or as high as ~84%.\\n\\nSo, these ELO ratings and win rates really mean nothing at the moment, until you have way more data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ocx1c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pardon my contrarian take here, but the comparison between these two models is statistically meaningless due to the wildly different sample sizes. Qwen3 shows 57 total trials, while Opus 4 shows 2,237 trials.&lt;/p&gt;\\n\\n&lt;p&gt;Sure, the win rates appear similar (71.9% vs. 71.4%), but the level of uncertainty in the first model&amp;#39;s performance is ridiculous. Something like 12%.&lt;/p&gt;\\n\\n&lt;p&gt;That means its true win rate could be as low as ~60% or as high as ~84%.&lt;/p&gt;\\n\\n&lt;p&gt;So, these ELO ratings and win rates really mean nothing at the moment, until you have way more data.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4ocx1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753257936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ztb2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4qymaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Copy332","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qv7rq","score":2,"author_fullname":"t2_98ouo03z","approved_by":null,"mod_note":null,"all_awardings":[],"body":"No worries, just wanted to make sure it wasn't a mistake on our end haha. Thanks for the feedback as well!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4qymaf","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No worries, just wanted to make sure it wasn&amp;#39;t a mistake on our end haha. Thanks for the feedback as well!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ztb2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qymaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753291569,"author_flair_text":null,"treatment_tags":[],"created_utc":1753291569,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qv7rq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qt6sa","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ohhh I apologize, I learned something new today. You are right, I am surprised it performs so badly in comparison! Thank you for your reply!","edited":false,"author_flair_css_class":null,"name":"t1_n4qv7rq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ohhh I apologize, I learned something new today. You are right, I am surprised it performs so badly in comparison! Thank you for your reply!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6ztb2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qv7rq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753290670,"author_flair_text":null,"collapsed":false,"created_utc":1753290670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qt6sa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Copy332","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qsoyw","score":2,"author_fullname":"t2_98ouo03z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is the model you're referring to right? Sorry if I'm misunderstanding\\n\\nhttps://preview.redd.it/6cekal1onnef1.png?width=1712&amp;format=png&amp;auto=webp&amp;s=4fb98ef4be2da6f361a2a743a13de3102e0003e0\\n\\nThis is the one currently on our leaderboard.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qt6sa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the model you&amp;#39;re referring to right? Sorry if I&amp;#39;m misunderstanding&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/6cekal1onnef1.png?width=1712&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4fb98ef4be2da6f361a2a743a13de3102e0003e0\\"&gt;https://preview.redd.it/6cekal1onnef1.png?width=1712&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4fb98ef4be2da6f361a2a743a13de3102e0003e0&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This is the one currently on our leaderboard.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qt6sa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753290131,"media_metadata":{"6cekal1onnef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":18,"x":108,"u":"https://preview.redd.it/6cekal1onnef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3761cfdd69a0f1405513da14fecbe0660f9394a3"},{"y":36,"x":216,"u":"https://preview.redd.it/6cekal1onnef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f6c186a836d291bbd66c74650dc1b566c8b383e3"},{"y":53,"x":320,"u":"https://preview.redd.it/6cekal1onnef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=845feddceac06dcb738ebdf86e175634f1aa70ec"},{"y":107,"x":640,"u":"https://preview.redd.it/6cekal1onnef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=439356497e2dc016a9b72cef44919b16ba994c89"},{"y":161,"x":960,"u":"https://preview.redd.it/6cekal1onnef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b6f805e40ec3c4be04f8e2f67148c2e9b44bab8"},{"y":181,"x":1080,"u":"https://preview.redd.it/6cekal1onnef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc29a70e86a3fdbbdfcabdb3dd10e3f2678d5d62"}],"s":{"y":288,"x":1712,"u":"https://preview.redd.it/6cekal1onnef1.png?width=1712&amp;format=png&amp;auto=webp&amp;s=4fb98ef4be2da6f361a2a743a13de3102e0003e0"},"id":"6cekal1onnef1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1753290131,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qsoyw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qbmbo","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh I meant the much more sophisticated &amp; recently released 2507. GGUFs have been out for just two weeks and Qwen3-Coder is being compared against it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4qsoyw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh I meant the much more sophisticated &amp;amp; recently released 2507. GGUFs have been out for just two weeks and Qwen3-Coder is being compared against it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qsoyw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753289996,"author_flair_text":null,"treatment_tags":[],"created_utc":1753289996,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qbmbo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Copy332","can_mod_post":false,"created_utc":1753285284,"send_replies":true,"parent_id":"t1_n4pdv75","score":1,"author_fullname":"t2_98ouo03z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Devstral Small has actually already been on there for a while! If you scroll down on the leaderboard, it’s 35th.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qbmbo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Devstral Small has actually already been on there for a while! If you scroll down on the leaderboard, it’s 35th.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qbmbo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753285284,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pdv75","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1753275312,"send_replies":true,"parent_id":"t3_1m6ztb2","score":1,"author_fullname":"t2_omawcpyf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for adding new models incessantly, your benchmark is one of my favourites, because you can't train a model for it other than making the model good :)\\n\\nAlso happy to see than I am not the only one pointing out that your benchmark needs too favour models that have few battles played, otherwise the scoring is meaningless. If you want, you could add a range for each's ELO rating to clearly show how certain results are.\\n\\nI wonder, will you be adding Mistral's Devstral Small 2507 as well?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pdv75","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for adding new models incessantly, your benchmark is one of my favourites, because you can&amp;#39;t train a model for it other than making the model good :)&lt;/p&gt;\\n\\n&lt;p&gt;Also happy to see than I am not the only one pointing out that your benchmark needs too favour models that have few battles played, otherwise the scoring is meaningless. If you want, you could add a range for each&amp;#39;s ELO rating to clearly show how certain results are.&lt;/p&gt;\\n\\n&lt;p&gt;I wonder, will you be adding Mistral&amp;#39;s Devstral Small 2507 as well?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4pdv75/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753275312,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ztb2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4qv0cv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Copy332","can_mod_post":false,"created_utc":1753290616,"send_replies":true,"parent_id":"t1_n4qlp5h","score":1,"author_fullname":"t2_98ouo03z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think there's that much of a discrepancy in Gemini 2.5 pro's performance here. Ignoring the Qwen models since they were just recently added, 2.5 Pro is 6th and in the same tier as the Claude models (Opus, Sonnet 4, 3.7 Sonnet) and Deepseek R1-0528 which aligns with the results on webdev arena. \\n\\nThat said, I think this benchmark and web arena are evaluating two different things. We're looking at how LLMs perform mostly just from a design and UI perspective, while I think webdev arena indexes more on functional coding / backend which I've heard Gemini 2.5 Pro is very good at, though might not be as strong on frontend as the Claude or the DeepSeek models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qv0cv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think there&amp;#39;s that much of a discrepancy in Gemini 2.5 pro&amp;#39;s performance here. Ignoring the Qwen models since they were just recently added, 2.5 Pro is 6th and in the same tier as the Claude models (Opus, Sonnet 4, 3.7 Sonnet) and Deepseek R1-0528 which aligns with the results on webdev arena. &lt;/p&gt;\\n\\n&lt;p&gt;That said, I think this benchmark and web arena are evaluating two different things. We&amp;#39;re looking at how LLMs perform mostly just from a design and UI perspective, while I think webdev arena indexes more on functional coding / backend which I&amp;#39;ve heard Gemini 2.5 Pro is very good at, though might not be as strong on frontend as the Claude or the DeepSeek models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ztb2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qv0cv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753290616,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qlp5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shark8866","can_mod_post":false,"created_utc":1753288080,"send_replies":true,"parent_id":"t3_1m6ztb2","score":1,"author_fullname":"t2_1237cb8qq5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi. Do you know why there is a discrepancy in Gemini 2.5 pro's performance on your benchmark and the web dev arena?\\n\\n[https://web.lmarena.ai/leaderboard](https://web.lmarena.ai/leaderboard)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qlp5h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi. Do you know why there is a discrepancy in Gemini 2.5 pro&amp;#39;s performance on your benchmark and the web dev arena?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://web.lmarena.ai/leaderboard\\"&gt;https://web.lmarena.ai/leaderboard&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ztb2/uiux_benchmark_update_722_newest_qwen_models/n4qlp5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753288080,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ztb2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(t,{data:a});export{n as default};
