import{j as e}from"./index-DDI5xNtT.js";import{R as l}from"./RedditPostRenderer-D2w0CxE4.js";import"./index-CZ5j6e3h.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"**Hardware:**  \\nOld Dell E6440 — i5-4310M, 8GB RAM, integrated graphics (no GPU).\\n\\nThis is just a fun side project (I use paid AI tools for serious tasks). I'm currently running **Llama-3.2-1B-Instruct-Q4\\\\_K\\\\_M** locally, it runs well, it's useful for what it is as a side project and some use cases work, but outputs can be weird and it often ignores instructions.\\n\\nGiven this limited hardware, what other similarly lightweight models would you recommend that might perform better? I tried the 3B variant but it was extremely slow compared to this one. Any ideas of what else to try?\\n\\nThanks a lot much appreciated.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Need your opinion please, appreciated.","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ln4iyg","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.6,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1a1t9ybw","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751166323,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;Hardware:&lt;/strong&gt;&lt;br/&gt;\\nOld Dell E6440 — i5-4310M, 8GB RAM, integrated graphics (no GPU).&lt;/p&gt;\\n\\n&lt;p&gt;This is just a fun side project (I use paid AI tools for serious tasks). I&amp;#39;m currently running &lt;strong&gt;Llama-3.2-1B-Instruct-Q4_K_M&lt;/strong&gt; locally, it runs well, it&amp;#39;s useful for what it is as a side project and some use cases work, but outputs can be weird and it often ignores instructions.&lt;/p&gt;\\n\\n&lt;p&gt;Given this limited hardware, what other similarly lightweight models would you recommend that might perform better? I tried the 3B variant but it was extremely slow compared to this one. Any ideas of what else to try?&lt;/p&gt;\\n\\n&lt;p&gt;Thanks a lot much appreciated.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ln4iyg","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"rakha589","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ln4iyg/need_your_opinion_please_appreciated/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ln4iyg/need_your_opinion_please_appreciated/","subreddit_subscribers":492929,"created_utc":1751166323,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cnvsj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheTartRevolution","can_mod_post":false,"created_utc":1751167942,"send_replies":true,"parent_id":"t3_1ln4iyg","score":5,"author_fullname":"t2_bxpr1g1z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Your best option would more than likely be Qwen-0.6 for fast inference or Qwen-1.7b for better responses. Also depending on your laptop and if your comfortable with it, it looks like you can upgrade the ram in that laptop up too 16 gigabtyes. I'd only do it if you can some DDR3 ram cheap though because the laptop is old and not worth putting a lot of money into.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cnvsj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your best option would more than likely be Qwen-0.6 for fast inference or Qwen-1.7b for better responses. Also depending on your laptop and if your comfortable with it, it looks like you can upgrade the ram in that laptop up too 16 gigabtyes. I&amp;#39;d only do it if you can some DDR3 ram cheap though because the laptop is old and not worth putting a lot of money into.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln4iyg/need_your_opinion_please_appreciated/n0cnvsj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751167942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln4iyg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0do9bn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1751187354,"send_replies":true,"parent_id":"t3_1ln4iyg","score":1,"author_fullname":"t2_3f9vjjno","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried running Gemma 3 4b on my old macbook air with 8gb ddr3 and it worked pretty well. My good laptop got stolen so it's my daily driver for now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0do9bn","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried running Gemma 3 4b on my old macbook air with 8gb ddr3 and it worked pretty well. My good laptop got stolen so it&amp;#39;s my daily driver for now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln4iyg/need_your_opinion_please_appreciated/n0do9bn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751187354,"author_flair_text":"Llama 70B","treatment_tags":[],"link_id":"t3_1ln4iyg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dpxfw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jamaalwakamaal","can_mod_post":false,"created_utc":1751188387,"send_replies":true,"parent_id":"t3_1ln4iyg","score":2,"author_fullname":"t2_alyeos2m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"qwen 3 0.6b, q4km of qwen 3 1.7b and gemma 3 1b, use tools like PageAssist on web browser for web search etc","edited":1751189774,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dpxfw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen 3 0.6b, q4km of qwen 3 1.7b and gemma 3 1b, use tools like PageAssist on web browser for web search etc&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln4iyg/need_your_opinion_please_appreciated/n0dpxfw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751188387,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln4iyg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
