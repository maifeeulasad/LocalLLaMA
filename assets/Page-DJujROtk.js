import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I get that speed with only simple requests like \\"hello\\" , \\"who are you ?\\"  \\n  \\nIt runs on :  \\n4  x Xeon X7550  @ 2.00GHz , hyperthreading deactivated (32 physical cores)  \\n512G  @ 1333 MT/s (2666Mhz) , all slots populated (64 sticks)\\n\\nThe software is :  \\nllama.cpp:server-b5918 (n-1 llamacpp version)  \\nmodel Kimi-K2-Instruct-UD-TQ1 (250GB model)\\n\\ni never used llamacpp before and didn't positioned any additional parameter.  \\n(usually running ollama)\\n\\nI thought kimi-k2 was great on cpu, but maybe that setup is too old,  \\ni also see most peoples posting setups with an additional gpu, is it mandatory ?\\n\\nMaybe someone has suggestions or explainations.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Trying to run kimi-k2 on cpu only, getting about 1token / 30sec","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m39n48","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.47,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_wpsl8","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752862335,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I get that speed with only simple requests like &amp;quot;hello&amp;quot; , &amp;quot;who are you ?&amp;quot;  &lt;/p&gt;\\n\\n&lt;p&gt;It runs on :&lt;br/&gt;\\n4  x Xeon X7550  @ 2.00GHz , hyperthreading deactivated (32 physical cores)&lt;br/&gt;\\n512G  @ 1333 MT/s (2666Mhz) , all slots populated (64 sticks)&lt;/p&gt;\\n\\n&lt;p&gt;The software is :&lt;br/&gt;\\nllama.cpp:server-b5918 (n-1 llamacpp version)&lt;br/&gt;\\nmodel Kimi-K2-Instruct-UD-TQ1 (250GB model)&lt;/p&gt;\\n\\n&lt;p&gt;i never used llamacpp before and didn&amp;#39;t positioned any additional parameter.&lt;br/&gt;\\n(usually running ollama)&lt;/p&gt;\\n\\n&lt;p&gt;I thought kimi-k2 was great on cpu, but maybe that setup is too old,&lt;br/&gt;\\ni also see most peoples posting setups with an additional gpu, is it mandatory ?&lt;/p&gt;\\n\\n&lt;p&gt;Maybe someone has suggestions or explainations.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m39n48","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"orogor","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/","subreddit_subscribers":501527,"created_utc":1752862335,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3v7rgc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752865131,"send_replies":true,"parent_id":"t3_1m39n48","score":11,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Xeon X7550\\n\\nIs ass. Barely faster than N100 atom.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v7rgc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Xeon X7550&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Is ass. Barely faster than N100 atom.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3v7rgc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865131,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uze33","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MontageKapalua6302","can_mod_post":false,"created_utc":1752862682,"send_replies":true,"parent_id":"t1_n3uz827","score":34,"author_fullname":"t2_1sw7mi8krb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As a customer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uze33","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a customer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m39n48","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3uze33/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862682,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uz827","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Koksny","can_mod_post":false,"created_utc":1752862633,"send_replies":true,"parent_id":"t3_1m39n48","score":29,"author_fullname":"t2_olk3n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Xeon X7550\\n\\nThis CPU is old enough to be on Epstein Island.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uz827","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Xeon X7550&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;This CPU is old enough to be on Epstein Island.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3uz827/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862633,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3v0nqr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"offlinesir","can_mod_post":false,"created_utc":1752863054,"send_replies":true,"parent_id":"t3_1m39n48","score":15,"author_fullname":"t2_jn5ft2le","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You answered you own question with \\"but maybe that setup is too old\\"\\n\\nCmon, really? A 250GB model on hardware from **2010**?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v0nqr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You answered you own question with &amp;quot;but maybe that setup is too old&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Cmon, really? A 250GB model on hardware from &lt;strong&gt;2010&lt;/strong&gt;?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3v0nqr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752863054,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ws8or","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wb4nf","score":1,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, it does run well on CPU (relative to the size for sure) but it's still a challenging workload and like a lot of server / HPC tasks needs some tuning.  I think if you set up the system right, e.g. using only one or two sockets for execution and the others as memory sources.  The limits of the system (i.e. slow memory and busses) will mean it's not going to be super fast, but you can probably get like 3 t/s which is enough to play around with","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3ws8or","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, it does run well on CPU (relative to the size for sure) but it&amp;#39;s still a challenging workload and like a lot of server / HPC tasks needs some tuning.  I think if you set up the system right, e.g. using only one or two sockets for execution and the others as memory sources.  The limits of the system (i.e. slow memory and busses) will mean it&amp;#39;s not going to be super fast, but you can probably get like 3 t/s which is enough to play around with&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m39n48","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3ws8or/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752883002,"author_flair_text":null,"treatment_tags":[],"created_utc":1752883002,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wb4nf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"orogor","can_mod_post":false,"created_utc":1752877134,"send_replies":true,"parent_id":"t1_n3v9gjw","score":-1,"author_fullname":"t2_wpsl8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, i try to recycle old servers.  \\n  \\nI do have another old server with some gpu which can perfectly run some smaller models.  \\n(qwen2.5:14b on ollama for example, or yes some deepseek-r1)  \\nThis server is the one with the most memory, the other ones have 256G of ram.  \\nIn general the disks are slow and there's already some small workload running on them.\\n\\nMy understanding was that kimi-k2 was more cpu oriented and it was mostly in need of a lot of ram, so i was having some hopes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wb4nf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, i try to recycle old servers.  &lt;/p&gt;\\n\\n&lt;p&gt;I do have another old server with some gpu which can perfectly run some smaller models.&lt;br/&gt;\\n(qwen2.5:14b on ollama for example, or yes some deepseek-r1)&lt;br/&gt;\\nThis server is the one with the most memory, the other ones have 256G of ram.&lt;br/&gt;\\nIn general the disks are slow and there&amp;#39;s already some small workload running on them.&lt;/p&gt;\\n\\n&lt;p&gt;My understanding was that kimi-k2 was more cpu oriented and it was mostly in need of a lot of ram, so i was having some hopes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m39n48","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3wb4nf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752877134,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v9gjw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1752865632,"send_replies":true,"parent_id":"t3_1m39n48","score":5,"author_fullname":"t2_lpdsy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; 4 x Xeon\\n\\nIn addition to what the others have said, I think this is actually the biggest issue here.  Current CPU inference is pretty bad at multi-socket in general, but that's mostly even dual socket.  Quad socket is a whole new nightmare.  Consider that each CPU has 4 QPI links, so that means every CPU can directly talk at 1x speed (~13GBps == ~1.2ch DDR3) or each CPU can only talk to 2 others at ~26GBps but the third is 2 hops away and destroys bandwidth anyways.\\n\\nYou could try to limit yourself to two (adjacent!) CPUs.  I'm guessing that means 256GB RAM, which is a bit tight, so you could test Deepseek in that config and seeing how it goes.  Note that Deepseek requires less RAM but runs a little slower (37B active vs 32B).\\n\\n&gt; i also see most peoples posting setups with an additional gpu, is it mandatory ?\\n\\nOn my system it goes from like 10 to 15 t/s.  It's a nice boost but it's not going to fix this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v9gjw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;4 x Xeon&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;In addition to what the others have said, I think this is actually the biggest issue here.  Current CPU inference is pretty bad at multi-socket in general, but that&amp;#39;s mostly even dual socket.  Quad socket is a whole new nightmare.  Consider that each CPU has 4 QPI links, so that means every CPU can directly talk at 1x speed (~13GBps == ~1.2ch DDR3) or each CPU can only talk to 2 others at ~26GBps but the third is 2 hops away and destroys bandwidth anyways.&lt;/p&gt;\\n\\n&lt;p&gt;You could try to limit yourself to two (adjacent!) CPUs.  I&amp;#39;m guessing that means 256GB RAM, which is a bit tight, so you could test Deepseek in that config and seeing how it goes.  Note that Deepseek requires less RAM but runs a little slower (37B active vs 32B).&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;i also see most peoples posting setups with an additional gpu, is it mandatory ?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;On my system it goes from like 10 to 15 t/s.  It&amp;#39;s a nice boost but it&amp;#39;s not going to fix this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3v9gjw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865632,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uzpm6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752862776,"send_replies":true,"parent_id":"t3_1m39n48","score":2,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yes, get you some GPU and yet it's old.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uzpm6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, get you some GPU and yet it&amp;#39;s old.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3uzpm6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862776,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vmr39","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dc740","can_mod_post":false,"created_utc":1752869585,"send_replies":true,"parent_id":"t3_1m39n48","score":1,"author_fullname":"t2_dkwhd0p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Don't disable hyper threading in these old Intel. AMD gets better performance without HT, but not Intel. Enable flash attention. Set the server to performance mode. Put a GPU to help with the calculations. Pin the process to only one numa node. Experiment with numactl --interleave=all. Experiment with the number of layers you put on the GPU and experiment with the -ot parameter. You won't get huge t/s though. Check for second hand CPUs to upgrade those xeons with faster alternatives. But don't break the bank. There won't be a return of investment. It's just for fun","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vmr39","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t disable hyper threading in these old Intel. AMD gets better performance without HT, but not Intel. Enable flash attention. Set the server to performance mode. Put a GPU to help with the calculations. Pin the process to only one numa node. Experiment with numactl --interleave=all. Experiment with the number of layers you put on the GPU and experiment with the -ot parameter. You won&amp;#39;t get huge t/s though. Check for second hand CPUs to upgrade those xeons with faster alternatives. But don&amp;#39;t break the bank. There won&amp;#39;t be a return of investment. It&amp;#39;s just for fun&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3vmr39/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752869585,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vyxyg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTshop_ai","can_mod_post":false,"created_utc":1752873214,"send_replies":true,"parent_id":"t3_1m39n48","score":1,"author_fullname":"t2_rkmud0isr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice Trolling.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vyxyg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice Trolling.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3vyxyg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752873214,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n41lmwf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maleficent_Age1577","can_mod_post":false,"created_utc":1752952835,"send_replies":true,"parent_id":"t3_1m39n48","score":1,"author_fullname":"t2_gxl5vlowd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"whats wrong with 30t/s? pick up a book and read it while it solves your questions of eternal mysticity.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n41lmwf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;whats wrong with 30t/s? pick up a book and read it while it solves your questions of eternal mysticity.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n41lmwf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752952835,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n41vyew","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mmowg","can_mod_post":false,"created_utc":1752956168,"send_replies":true,"parent_id":"t3_1m39n48","score":1,"author_fullname":"t2_1lpshptw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Windows or Linux? Anyway, my advices are the following and I love old workstations or servers: use Linux (lightweight as Mint), a SSD (of course) and ask to Kimi itself how improve the TPS, one of tricks is \\"numactl\\". With it you can get 1.5 TpS using koboldcpp and the most small GGUF model of Kimi.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n41vyew","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Windows or Linux? Anyway, my advices are the following and I love old workstations or servers: use Linux (lightweight as Mint), a SSD (of course) and ask to Kimi itself how improve the TPS, one of tricks is &amp;quot;numactl&amp;quot;. With it you can get 1.5 TpS using koboldcpp and the most small GGUF model of Kimi.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n41vyew/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752956168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vbhgk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"presidentbidden","can_mod_post":false,"created_utc":1752866238,"send_replies":true,"parent_id":"t3_1m39n48","score":1,"author_fullname":"t2_rxqqxmit","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"bro if you cant upgrade forget LLMs. running it in old hardware is big waste of time and electricity","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vbhgk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;bro if you cant upgrade forget LLMs. running it in old hardware is big waste of time and electricity&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m39n48/trying_to_run_kimik2_on_cpu_only_getting_about/n3vbhgk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866238,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m39n48","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
