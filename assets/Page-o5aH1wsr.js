import{j as e}from"./index-BpC9hjVs.js";import{R as t}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"**What is this?**\\n\\nA variant of beam search which runs from the point of view of different system prompts. The workflow runs in an optimising LLM proxy that sends an artifact back to Open WebUI that listens to the data from the pending completion.\\n\\n[Code](https://github.com/av/harbor/blob/main/boost/src/modules/nbs.py). ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Narrative Beam Search workflow in Open WebUI","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":87,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltbg2s","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":"#bd9e9e","ups":62,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","is_original_content":false,"author_fullname":"t2_o7p5m","secure_media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/067r3vt8ebbf1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1080,"width":1728,"scrubber_media_url":"https://v.redd.it/067r3vt8ebbf1/DASH_96.mp4","dash_url":"https://v.redd.it/067r3vt8ebbf1/DASHPlaylist.mpd?a=1754557366%2CYjI1MWUwMzY3Y2MxNTdkMjk4NTE4NDJlNWNhNzFhZDM3YzIxM2VkZmI5YWE0NTgwYTc0Yjk0MGVjZmE0NWEzYQ%3D%3D&amp;v=1&amp;f=sd","duration":208,"hls_url":"https://v.redd.it/067r3vt8ebbf1/HLSPlaylist.m3u8?a=1754557366%2CNzgwMTU3YzQ2ZDI3ZDgxY2ZmNGMzODM5NGUyNDg3OGU2MmQxODk4ZTMwNDg3ZDU4ODA4N2I2NGMwZjI2MWQxYg%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":62,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=140&amp;height=87&amp;crop=140:87,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=05931cebc1ca617c621a78879aa337714e440d94","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751834380,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;What is this?&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;A variant of beam search which runs from the point of view of different system prompts. The workflow runs in an optimising LLM proxy that sends an artifact back to Open WebUI that listens to the data from the pending completion.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/av/harbor/blob/main/boost/src/modules/nbs.py\\"&gt;Code&lt;/a&gt;. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/067r3vt8ebbf1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?format=pjpg&amp;auto=webp&amp;s=480a5f2a3d96719f71da354800cccbdbbbff864d","width":1920,"height":1200},"resolutions":[{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a5259ceeed5dda16f2ea2ddf334adbff791a2e0f","width":108,"height":67},{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=86c8f7591ffab17153ff02d4bc82f7d1edbb956a","width":216,"height":135},{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=98d47c1d3d15e579f1d038ff6e5677450994a6e8","width":320,"height":200},{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0545d0feac30144b36981c0f58a885cb0ec719f6","width":640,"height":400},{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=57c29f4b8439434bc02fb2f1eb80e6ed9ce04059","width":960,"height":600},{"url":"https://external-preview.redd.it/cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b97e61cec44334e49a1592a6ca757b26e4911957","width":1080,"height":675}],"variants":{},"id":"cGprbTl2dDhlYmJmMfNv2qQc5KO5fB6gHC38B4rcVAB-vfM2l6tq4JjQRNK2"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Alpaca","treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1ltbg2s","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Everlier","discussion_type":null,"num_comments":1,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/067r3vt8ebbf1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1080,"width":1728,"scrubber_media_url":"https://v.redd.it/067r3vt8ebbf1/DASH_96.mp4","dash_url":"https://v.redd.it/067r3vt8ebbf1/DASHPlaylist.mpd?a=1754557366%2CYjI1MWUwMzY3Y2MxNTdkMjk4NTE4NDJlNWNhNzFhZDM3YzIxM2VkZmI5YWE0NTgwYTc0Yjk0MGVjZmE0NWEzYQ%3D%3D&amp;v=1&amp;f=sd","duration":208,"hls_url":"https://v.redd.it/067r3vt8ebbf1/HLSPlaylist.m3u8?a=1754557366%2CNzgwMTU3YzQ2ZDI3ZDgxY2ZmNGMzODM5NGUyNDg3OGU2MmQxODk4ZTMwNDg3ZDU4ODA4N2I2NGMwZjI2MWQxYg%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1ltbg2s/narrative_beam_search_workflow_in_open_webui/","stickied":false,"url":"https://v.redd.it/067r3vt8ebbf1","subreddit_subscribers":496034,"created_utc":1751834380,"num_crossposts":0,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1p7ubj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1751836212,"send_replies":true,"parent_id":"t3_1ltbg2s","score":6,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This doesn't look like beam search to me, as the implementation would need to look into the future then, instead of just generating and choosing, but an interesting thing to look at nonetheless. So, your implementation generates 4 continuation tokens for each persona, then picks the most fitting continuation (what ever is \\"most fitting\\" to the LLM) and then repeats.\\n\\nThe confidence score is unused so far. Maybe you can do something with the confidence and logits, and indeed do a bit of real beam search - maybe one path wins over the others after looking 2 or 3 steps into the future.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1p7ubj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This doesn&amp;#39;t look like beam search to me, as the implementation would need to look into the future then, instead of just generating and choosing, but an interesting thing to look at nonetheless. So, your implementation generates 4 continuation tokens for each persona, then picks the most fitting continuation (what ever is &amp;quot;most fitting&amp;quot; to the LLM) and then repeats.&lt;/p&gt;\\n\\n&lt;p&gt;The confidence score is unused so far. Maybe you can do something with the confidence and logits, and indeed do a bit of real beam search - maybe one path wins over the others after looking 2 or 3 steps into the future.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltbg2s/narrative_beam_search_workflow_in_open_webui/n1p7ubj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751836212,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltbg2s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}}]`),i=()=>e.jsx(t,{data:a});export{i as default};
