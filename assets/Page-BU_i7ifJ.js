import{j as e}from"./index-M5RGZ30t.js";import{R as l}from"./RedditPostRenderer-d9C3p581.js";import"./index-DmZ84jx5.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"From HF repo:\\n\\n&gt;Model Introduction\\n\\n&gt;With the rapid advancement of artificial intelligence technology, large language models (LLMs) have achieved remarkable progress in natural language processing, computer vision, and scientific tasks. However, as model scales continue to expand, optimizing resource consumption while maintaining high performance has become a critical challenge. To address this, we have explored Mixture of Experts (MoE) architectures. The newly introduced Hunyuan-A13B model features a total of 80 billion parameters with 13 billion active parameters. It not only delivers high-performance results but also achieves optimal resource efficiency, successfully balancing computational power and resource utilization.\\n\\n&gt;Key Features and Advantages\\n\\n&gt;Compact yet Powerful: With only 13 billion active parameters (out of a total of 80 billion), the model delivers competitive performance on a wide range of benchmark tasks, rivaling much larger models.\\n\\n&gt;Hybrid Inference Support: Supports both fast and slow thinking modes, allowing users to flexibly choose according to their needs.\\n\\n&gt;Ultra-Long Context Understanding: Natively supports a 256K context window, maintaining stable performance on long-text tasks.\\n\\n&gt;Enhanced Agent Capabilities: Optimized for agent tasks, achieving leading results on benchmarks such as BFCL-v3 and τ-Bench.\\n\\n&gt;Efficient Inference: Utilizes Grouped Query Attention (GQA) and supports multiple quantization formats, enabling highly efficient inference.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Hunyuan-A13B released","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1llndut","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.99,"author_flair_background_color":null,"ups":524,"domain":"huggingface.co","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_g8fwjts3","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":524,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=55331ee41a47e2fe47456563e81c3d25e624896c","author_cakeday":true,"edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751007561,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;From HF repo:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Model Introduction&lt;/p&gt;\\n\\n&lt;p&gt;With the rapid advancement of artificial intelligence technology, large language models (LLMs) have achieved remarkable progress in natural language processing, computer vision, and scientific tasks. However, as model scales continue to expand, optimizing resource consumption while maintaining high performance has become a critical challenge. To address this, we have explored Mixture of Experts (MoE) architectures. The newly introduced Hunyuan-A13B model features a total of 80 billion parameters with 13 billion active parameters. It not only delivers high-performance results but also achieves optimal resource efficiency, successfully balancing computational power and resource utilization.&lt;/p&gt;\\n\\n&lt;p&gt;Key Features and Advantages&lt;/p&gt;\\n\\n&lt;p&gt;Compact yet Powerful: With only 13 billion active parameters (out of a total of 80 billion), the model delivers competitive performance on a wide range of benchmark tasks, rivaling much larger models.&lt;/p&gt;\\n\\n&lt;p&gt;Hybrid Inference Support: Supports both fast and slow thinking modes, allowing users to flexibly choose according to their needs.&lt;/p&gt;\\n\\n&lt;p&gt;Ultra-Long Context Understanding: Natively supports a 256K context window, maintaining stable performance on long-text tasks.&lt;/p&gt;\\n\\n&lt;p&gt;Enhanced Agent Capabilities: Optimized for agent tasks, achieving leading results on benchmarks such as BFCL-v3 and τ-Bench.&lt;/p&gt;\\n\\n&lt;p&gt;Efficient Inference: Utilizes Grouped Query Attention (GQA) and supports multiple quantization formats, enabling highly efficient inference.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/tencent/Hunyuan-A13B-Instruct","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?auto=webp&amp;s=34cabcdda6b37ae6e3f85dd7607f10dc2b5f1ac7","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=07fddabe91e442028f9a3c3afd189223a7d91fce","width":108,"height":58},{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ee3256d5380270fc602776fd46aa44d50e57ec8","width":216,"height":116},{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab65a9fbee8b46ef1d086bab44568f0ff3f72833","width":320,"height":172},{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=975cbb18dc0dd9f2342d47d40a0f9fb8fe177327","width":640,"height":345},{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=99a118442fdfb239383930ed0687bdea10777474","width":960,"height":518},{"url":"https://external-preview.redd.it/B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fd5d6edfba83b7dd8d2a586a152403dc93361a3a","width":1080,"height":583}],"variants":{},"id":"B1uwVS2BmhDOjFW0XJ6pW7-r7n5zECGun4YlOmky9YY"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1llndut","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"kristaller486","discussion_type":null,"num_comments":141,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/","stickied":false,"url":"https://huggingface.co/tencent/Hunyuan-A13B-Instruct","subreddit_subscribers":492232,"created_utc":1751007561,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n023dld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01yw9r","score":4,"author_fullname":"t2_ielo6","approved_by":null,"mod_note":null,"all_awardings":[],"body":"If this is true, there could be hope for a 4.1!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n023dld","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If this is true, there could be hope for a 4.1!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n023dld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751029217,"author_flair_text":null,"treatment_tags":[],"created_utc":1751029217,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n01yw9r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zulfiqaar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01gqf2","score":15,"author_fullname":"t2_ln48t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well Meta pirated 82 terabytes of books for training their models, so unfortunately they don't get that excuse. Looks like immediately after Anthropics win, Meta also won based on precedent (training on copyrighted content), however the allegations of piracy remains to be determined. Apparently Meta engineers specifically tried to minimise seeding while sucking up pretty much every book torrent in existence..darn leechers haha. Which is probably in their favour though as it avoids the illegal redistribution charge.","edited":1751042885,"author_flair_css_class":null,"name":"t1_n01yw9r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well Meta pirated 82 terabytes of books for training their models, so unfortunately they don&amp;#39;t get that excuse. Looks like immediately after Anthropics win, Meta also won based on precedent (training on copyrighted content), however the allegations of piracy remains to be determined. Apparently Meta engineers specifically tried to minimise seeding while sucking up pretty much every book torrent in existence..darn leechers haha. Which is probably in their favour though as it avoids the illegal redistribution charge.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01yw9r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751027617,"author_flair_text":null,"collapsed":false,"created_utc":1751027617,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n01gqf2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":20,"author_fullname":"t2_ielo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sounds reasonable. Guess we have to wait til someone crowdfunds an open model that takes Anthropic’s approach of buying a million books and scanning them to train a model with highest quality data. Door seems open now that the court ruled in their favor. Chinese models are probably training on mass pirated pdfs so unsurprisingly they’re better than Llama4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01gqf2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sounds reasonable. Guess we have to wait til someone crowdfunds an open model that takes Anthropic’s approach of buying a million books and scanning them to train a model with highest quality data. Door seems open now that the court ruled in their favor. Chinese models are probably training on mass pirated pdfs so unsurprisingly they’re better than Llama4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01gqf2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751019709,"author_flair_text":null,"treatment_tags":[],"created_utc":1751019709,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0210dl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Cod-2138","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":4,"author_fullname":"t2_jv0rq5eq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama4 is a lot more sparse so it's even harder to train than otherwise. \\n\\nThey should probably keep pretraining DSV3 lmao","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0210dl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama4 is a lot more sparse so it&amp;#39;s even harder to train than otherwise. &lt;/p&gt;\\n\\n&lt;p&gt;They should probably keep pretraining DSV3 lmao&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0210dl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751028387,"author_flair_text":null,"treatment_tags":[],"created_utc":1751028387,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n041s0g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zugzwang_CYOA","can_mod_post":false,"send_replies":true,"parent_id":"t1_n02ef5m","score":2,"author_fullname":"t2_mzaab62c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not so sure about that. Expensive VRAM is superior for the dense models of the past, but huge mixture of experts models seems to be the direction that local is going now. CPUmaxxing is much better for big MoE stuff than 3090 stacking.","edited":false,"author_flair_css_class":null,"name":"t1_n041s0g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not so sure about that. Expensive VRAM is superior for the dense models of the past, but huge mixture of experts models seems to be the direction that local is going now. CPUmaxxing is much better for big MoE stuff than 3090 stacking.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n041s0g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751049687,"author_flair_text":null,"collapsed":false,"created_utc":1751049687,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n02ef5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HilLiedTroopsDied","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":5,"author_fullname":"t2_1snfn3ui","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Prices of used 3090's, and other large Vram cards going to get even higher!. Intel where is the B60 Pros!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02ef5m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Prices of used 3090&amp;#39;s, and other large Vram cards going to get even higher!. Intel where is the B60 Pros!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02ef5m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751032808,"author_flair_text":null,"treatment_tags":[],"created_utc":1751032808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02g7na","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":5,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no, the vision is also fully native (ie, wasn't added post pre-training), which is one of the only open models with actual native vision.\\n\\nllama 4 has the most robust vision in any open model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02g7na","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, the vision is also fully native (ie, wasn&amp;#39;t added post pre-training), which is one of the only open models with actual native vision.&lt;/p&gt;\\n\\n&lt;p&gt;llama 4 has the most robust vision in any open model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02g7na/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751033356,"author_flair_text":null,"treatment_tags":[],"created_utc":1751033356,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01v4m4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dark-light92","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01o1h1","score":8,"author_fullname":"t2_3lvoq8zw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LM arena is not a good comprehensive benchmark. It's a vibe benchmark. And meta's data is all vibes so that's not surprising at all.\\n\\nI second that the issue most likely is the training data.","edited":false,"author_flair_css_class":null,"name":"t1_n01v4m4","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LM arena is not a good comprehensive benchmark. It&amp;#39;s a vibe benchmark. And meta&amp;#39;s data is all vibes so that&amp;#39;s not surprising at all.&lt;/p&gt;\\n\\n&lt;p&gt;I second that the issue most likely is the training data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01v4m4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751026184,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1751026184,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n01o1h1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":3,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; The problem isn't the architecture, it's Meta's data. Garbage in, garbage out.\\nWho knew facebook comments makes for shit data.\\n\\nWhat is interesting., their Maverick-experimental on LM-arena is really a very fun interesting model. Great creative writer, vibes similar to V3-0324. There is a very special reason why meta botched llama 4, and it is not data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01o1h1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The problem isn&amp;#39;t the architecture, it&amp;#39;s Meta&amp;#39;s data. Garbage in, garbage out.\\nWho knew facebook comments makes for shit data.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;What is interesting., their Maverick-experimental on LM-arena is really a very fun interesting model. Great creative writer, vibes similar to V3-0324. There is a very special reason why meta botched llama 4, and it is not data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01o1h1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751023221,"author_flair_text":null,"treatment_tags":[],"created_utc":1751023221,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02etyh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HilLiedTroopsDied","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01qqvx","score":2,"author_fullname":"t2_1snfn3ui","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it'd be a shame is someone(s) hacked the big tech companies and torrented their training sets. Need a Fat pipe to clear the terrabytes of data.","edited":false,"author_flair_css_class":null,"name":"t1_n02etyh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;d be a shame is someone(s) hacked the big tech companies and torrented their training sets. Need a Fat pipe to clear the terrabytes of data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02etyh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751032934,"author_flair_text":null,"collapsed":false,"created_utc":1751032934,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n01qqvx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustinPooDough","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":1,"author_fullname":"t2_4kns99rz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is why Google will win it all. Google has all, Google knows all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01qqvx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is why Google will win it all. Google has all, Google knows all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01qqvx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751024401,"author_flair_text":null,"treatment_tags":[],"created_utc":1751024401,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04g8b4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheThoccnessMonster","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f7nr","score":1,"author_fullname":"t2_5nwuqw4y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, some of them anyway. Their data pile needs to be revisited.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04g8b4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, some of them anyway. Their data pile needs to be revisited.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04g8b4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751053969,"author_flair_text":null,"treatment_tags":[],"created_utc":1751053969,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n01f7nr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0148kj","score":64,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama 4 architecture is LITERALLY just Deepseek V3 with a few tweaks (RoPE+NoPE etc) to add long context and stuff. \\n\\nThe problem isn't the architecture, it's Meta's data. Garbage in, garbage out. \\n\\nWho knew facebook comments makes for shit data.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01f7nr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 4 architecture is LITERALLY just Deepseek V3 with a few tweaks (RoPE+NoPE etc) to add long context and stuff. &lt;/p&gt;\\n\\n&lt;p&gt;The problem isn&amp;#39;t the architecture, it&amp;#39;s Meta&amp;#39;s data. Garbage in, garbage out. &lt;/p&gt;\\n\\n&lt;p&gt;Who knew facebook comments makes for shit data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01f7nr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018904,"author_flair_text":null,"treatment_tags":[],"created_utc":1751018904,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":64}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02gk6b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0148kj","score":3,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah same.\\n\\nthough i think it will take more time for them to regain traction, especially with all of the changes they are going thru rn. i'd say give it 6 months.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n02gk6b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah same.&lt;/p&gt;\\n\\n&lt;p&gt;though i think it will take more time for them to regain traction, especially with all of the changes they are going thru rn. i&amp;#39;d say give it 6 months.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02gk6b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751033460,"author_flair_text":null,"treatment_tags":[],"created_utc":1751033460,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0148kj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"created_utc":1751012582,"send_replies":true,"parent_id":"t1_n00wjwn","score":80,"author_fullname":"t2_ielo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Salt in the wound… i’m still rooting for meta to turn it around with a llama 4.1 that comes roaring back to the top spot","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0148kj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Salt in the wound… i’m still rooting for meta to turn it around with a llama 4.1 that comes roaring back to the top spot&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0148kj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012582,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":80}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01jpoj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"created_utc":1751021220,"send_replies":true,"parent_id":"t1_n00wjwn","score":18,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[Eval scores table](https://i.imgur.com/4dMCq5e.png) from the model page\\n\\nThese scores are pretty insane for Jan 2025. Wish they added o3 and Gemini 2.5 Pro for comparison, even if they're better.\\n\\nEdit: \\n\\n\\n| Topic                  | Benchmark            | OpenAI-o1-1217 | DeepSeek R1 | Qwen3-A22B | Hunyuan-A13B-Instruct | Gemini 2.5 Pro | OpenAI o3 | OpenAI o4-mini | DeepSeek R1-0528 |\\n|:----------------------:|:--------------------:|:-------------:|:-----------:|:----------:|:---------------------:|:--------------:|:---------:|:--------------:|:----------------:|\\n| Mathematics            | AIME 2024            | 74.3          | 79.8        | 85.7       | 87.3                  | 92.0 %        | 91.6 %    | 93.4 %        | 91.4 %           |\\n| Mathematics            | AIME 2025            | 79.2          | 70.0        | 81.5       | 76.8                  | 86.7 %        | 88.9 %    | 92.7 %       | 87.5 %           |\\n| Mathematics            | MATH                 | 96.4          | 94.9        | 94.0       | 94.3                  | –              | –         | –              | –                |\\n| Science                | GPQA-Diamond         | 78.0          | 71.5        | 71.1       | 71.2                  | 84.0 %        | 83.3 %    | 81.4 %        | 81.0 %           |\\n| Science                | OlympiadBench        | 83.1          | 82.4        | 85.7       | 82.7                  | –              | –         | –              | –                |\\n| Coding                 | Livecodebench        | 63.9          | 65.9        | 70.7       | 63.9                  | 73.6 %        | 75.8 %   | 80.2 %        | 73.3 %           |\\n| Coding                 | Fullstackbench       | 64.6          | 71.6        | 65.6       | 67.8                  | 63.8 %        | 69.1 %    | 68.1 %        | 57.6 %           |","edited":1751024849,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01jpoj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://i.imgur.com/4dMCq5e.png\\"&gt;Eval scores table&lt;/a&gt; from the model page&lt;/p&gt;\\n\\n&lt;p&gt;These scores are pretty insane for Jan 2025. Wish they added o3 and Gemini 2.5 Pro for comparison, even if they&amp;#39;re better.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: &lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"center\\"&gt;Topic&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;Benchmark&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;OpenAI-o1-1217&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;DeepSeek R1&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;Qwen3-A22B&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;Hunyuan-A13B-Instruct&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;Gemini 2.5 Pro&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;OpenAI o3&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;OpenAI o4-mini&lt;/th&gt;\\n&lt;th align=\\"center\\"&gt;DeepSeek R1-0528&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Mathematics&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;AIME 2024&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;74.3&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;79.8&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;85.7&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;87.3&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;92.0 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;91.6 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;93.4 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;91.4 %&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Mathematics&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;AIME 2025&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;79.2&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;70.0&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;81.5&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;76.8&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;86.7 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;88.9 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;92.7 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;87.5 %&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Mathematics&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;MATH&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;96.4&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;94.9&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;94.0&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;94.3&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Science&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;GPQA-Diamond&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;78.0&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;71.5&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;71.1&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;71.2&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;84.0 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;83.3 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;81.4 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;81.0 %&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Science&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;OlympiadBench&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;83.1&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;82.4&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;85.7&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;82.7&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;–&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Coding&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;Livecodebench&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;63.9&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;65.9&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;70.7&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;63.9&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;73.6 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;75.8 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;80.2 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;73.3 %&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"center\\"&gt;Coding&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;Fullstackbench&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;64.6&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;71.6&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;65.6&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;67.8&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;63.8 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;69.1 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;68.1 %&lt;/td&gt;\\n&lt;td align=\\"center\\"&gt;57.6 %&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01jpoj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751021220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02z0r6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MagicaItux","can_mod_post":false,"created_utc":1751038784,"send_replies":true,"parent_id":"t1_n00wjwn","score":2,"author_fullname":"t2_h7lo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's awesome, do you think we can merge that with the hyena hierarchy's context starting at 4T?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02z0r6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s awesome, do you think we can merge that with the hyena hierarchy&amp;#39;s context starting at 4T?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02z0r6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038784,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n00wjwn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vincentz42","can_mod_post":false,"created_utc":1751008074,"send_replies":true,"parent_id":"t3_1llndut","score":254,"author_fullname":"t2_5tzp8vnx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The evals are incredible and trade blows with DeepSeek R1-0120.   \\n  \\nNote this model has 80B parameters in total and 13B active parameters. So it requires roughly the same amount of memory compared to Llama 3 70B while offering 5x throughput because of MoE.\\n\\nThis is what the Llama 4 Maverick should have been.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00wjwn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The evals are incredible and trade blows with DeepSeek R1-0120.   &lt;/p&gt;\\n\\n&lt;p&gt;Note this model has 80B parameters in total and 13B active parameters. So it requires roughly the same amount of memory compared to Llama 3 70B while offering 5x throughput because of MoE.&lt;/p&gt;\\n\\n&lt;p&gt;This is what the Llama 4 Maverick should have been.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00wjwn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008074,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":254}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01idc1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Affectionate-Hat-536","can_mod_post":false,"send_replies":true,"parent_id":"t1_n00zesf","score":13,"author_fullname":"t2_7htykppj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am in this exact boat with M4 Max 64GB. Hope to try this weekend.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01idc1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am in this exact boat with M4 Max 64GB. Hope to try this weekend.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01idc1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751020557,"author_flair_text":null,"treatment_tags":[],"created_utc":1751020557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02kjw7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"blurredphotos","can_mod_post":false,"send_replies":true,"parent_id":"t1_n00zesf","score":2,"author_fullname":"t2_9qd6yhwf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bingo","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n02kjw7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bingo&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02kjw7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751034630,"author_flair_text":null,"treatment_tags":[],"created_utc":1751034630,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n05sktd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Hat-536","can_mod_post":false,"send_replies":true,"parent_id":"t1_n00zesf","score":1,"author_fullname":"t2_7htykppj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you know if there gguf for this model is available anywhere? I hope there’s ollama or MLX version soon","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n05sktd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know if there gguf for this model is available anywhere? I hope there’s ollama or MLX version soon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n05sktd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751069819,"author_flair_text":null,"treatment_tags":[],"created_utc":1751069819,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n00zesf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1751009715,"send_replies":true,"parent_id":"t1_n00wy61","score":49,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice sweet spot for 64 GB RAM laptops with unified memory too. At q4 we're looking at around 40 GB RAM to load the entire model. It should be fast if it has 13B active params.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00zesf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice sweet spot for 64 GB RAM laptops with unified memory too. At q4 we&amp;#39;re looking at around 40 GB RAM to load the entire model. It should be fast if it has 13B active params.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00zesf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751009715,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":49}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n00y3tk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mxforest","can_mod_post":false,"created_utc":1751008954,"send_replies":true,"parent_id":"t1_n00wy61","score":15,"author_fullname":"t2_kenmq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is just perfect. I have been wishing for something in this range and these guys delivered. Would also love a 80B dense model. Can switch to it where speed is less important and accuracy is more.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00y3tk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is just perfect. I have been wishing for something in this range and these guys delivered. Would also love a 80B dense model. Can switch to it where speed is less important and accuracy is more.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00y3tk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008954,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n041gjt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sourceholder","can_mod_post":false,"created_utc":1751049593,"send_replies":true,"parent_id":"t1_n00wy61","score":2,"author_fullname":"t2_35jjv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much extra VRAM is required to achieve 256k context?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n041gjt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much extra VRAM is required to achieve 256k context?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n041gjt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751049593,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n00wy61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jferments","can_mod_post":false,"created_utc":1751008296,"send_replies":true,"parent_id":"t3_1llndut","score":130,"author_fullname":"t2_xs66a5h67","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"80B-A13B is such a perfect sweet spot of power vs. VRAM usage .... and native 256k context 🫠🫠🫠","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00wy61","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;80B-A13B is such a perfect sweet spot of power vs. VRAM usage .... and native 256k context 🫠🫠🫠&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00wy61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008296,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":130}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01eh7i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stoppableDissolution","can_mod_post":false,"created_utc":1751018507,"send_replies":true,"parent_id":"t1_n0197gn","score":14,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"48gb too, q4 will fit just perfect. Maybe even q6 with good speed with some creative offloading.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01eh7i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;48gb too, q4 will fit just perfect. Maybe even q6 with good speed with some creative offloading.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01eh7i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018507,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n0197gn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1751015521,"send_replies":true,"parent_id":"t3_1llndut","score":45,"author_fullname":"t2_qhlcbiy3k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Perfect size for 64GB RAM systems, this is exactly the MoE size the community has wanted for a long time! Let's goooooo!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0197gn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Perfect size for 64GB RAM systems, this is exactly the MoE size the community has wanted for a long time! Let&amp;#39;s goooooo!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0197gn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015521,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":45}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n027byl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeProgrammer99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01txt9","score":9,"author_fullname":"t2_w4j8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's about perfect for 64 GB main memory if quantized to ~5 bits per weight with room for context. That's how much RAM I have in both my work and personal machines.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n027byl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s about perfect for 64 GB main memory if quantized to ~5 bits per weight with room for context. That&amp;#39;s how much RAM I have in both my work and personal machines.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n027byl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751030554,"author_flair_text":null,"treatment_tags":[],"created_utc":1751030554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n054ait","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Goldkoron","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01txt9","score":2,"author_fullname":"t2_8fz90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My 2 3090s and 48gb 4090","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n054ait","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My 2 3090s and 48gb 4090&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n054ait/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751061429,"author_flair_text":null,"treatment_tags":[],"created_utc":1751061429,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06j8m0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01txt9","score":2,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"should be able to run quantized with 2x3090.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n06j8m0","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;should be able to run quantized with 2x3090.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06j8m0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751080037,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1751080037,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n01txt9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"takuonline","can_mod_post":false,"created_utc":1751025711,"send_replies":true,"parent_id":"t1_n00z313","score":7,"author_fullname":"t2_5uqxt8em","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Perfect for what setup?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01txt9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Perfect for what setup?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01txt9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751025711,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n00z313","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TeakTop","can_mod_post":false,"created_utc":1751009526,"send_replies":true,"parent_id":"t3_1llndut","score":64,"author_fullname":"t2_iwqeo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow this is a perfectly sized MoE. If the benchmarks live up, this model is one hell of a gift for local ai.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00z313","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow this is a perfectly sized MoE. If the benchmarks live up, this model is one hell of a gift for local ai.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00z313/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751009526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":64}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01t8na","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LocoMod","can_mod_post":false,"send_replies":true,"parent_id":"t1_n015z5r","score":11,"author_fullname":"t2_6uuoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're a gentleman and a scholar. Thanks.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01t8na","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re a gentleman and a scholar. Thanks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01t8na/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751025430,"author_flair_text":null,"treatment_tags":[],"created_utc":1751025430,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04rnzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noeda","can_mod_post":false,"send_replies":true,"parent_id":"t1_n03vou6","score":6,"author_fullname":"t2_9oskj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, I saw this comment thread in the morning, now came back with the intention to say that if I don't see activity or someone working on it, I'd have a stab at it. I feel it's happened now a few times I see some interesting model I want to hack together, but some incredibly industrious person showed up instead and put it together much faster :D\\n\\nIf it's ngxson I'd expect it to be ready soonish. One of these super industrious persons as far as I can tell :) It's probably ready before I can even look at it properly but since the last comment says there's some gibberish I can at least say if no updates this weekend I'm probably going to look at the PR and maybe help verify the computation graph or wherever it looks like the problem might be.\\n\\nI sometimes wonder where do people summon the time and energy to hack together stuff on such short notice!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04rnzs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, I saw this comment thread in the morning, now came back with the intention to say that if I don&amp;#39;t see activity or someone working on it, I&amp;#39;d have a stab at it. I feel it&amp;#39;s happened now a few times I see some interesting model I want to hack together, but some incredibly industrious person showed up instead and put it together much faster :D&lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s ngxson I&amp;#39;d expect it to be ready soonish. One of these super industrious persons as far as I can tell :) It&amp;#39;s probably ready before I can even look at it properly but since the last comment says there&amp;#39;s some gibberish I can at least say if no updates this weekend I&amp;#39;m probably going to look at the PR and maybe help verify the computation graph or wherever it looks like the problem might be.&lt;/p&gt;\\n\\n&lt;p&gt;I sometimes wonder where do people summon the time and energy to hack together stuff on such short notice!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04rnzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751057426,"author_flair_text":null,"treatment_tags":[],"created_utc":1751057426,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04suq2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OutlandishnessIll466","can_mod_post":false,"send_replies":true,"parent_id":"t1_n03vou6","score":2,"author_fullname":"t2_e4ru5ouw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah! Just pull and build that branch. No need to wait for the pull request. Just there is no GGUF up yet.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04suq2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah! Just pull and build that branch. No need to wait for the pull request. Just there is no GGUF up yet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04suq2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751057785,"author_flair_text":null,"treatment_tags":[],"created_utc":1751057785,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n03vou6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_n015z5r","score":12,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh the PR (by ngxson of course) also: [https://github.com/ggml-org/llama.cpp/pull/14425](https://github.com/ggml-org/llama.cpp/pull/14425)\\n\\nHopefully we can run it soon :o","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n03vou6","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh the PR (by ngxson of course) also: &lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/14425\\"&gt;https://github.com/ggml-org/llama.cpp/pull/14425&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Hopefully we can run it soon :o&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03vou6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751047929,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751047929,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n015z5r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"matteogeniaccio","can_mod_post":false,"created_utc":1751013627,"send_replies":true,"parent_id":"t1_n00wmb1","score":28,"author_fullname":"t2_hoxc8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not yet. This is the issue so you can track it: [https://github.com/ggml-org/llama.cpp/issues/14415](https://github.com/ggml-org/llama.cpp/issues/14415)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n015z5r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not yet. This is the issue so you can track it: &lt;a href=\\"https://github.com/ggml-org/llama.cpp/issues/14415\\"&gt;https://github.com/ggml-org/llama.cpp/issues/14415&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n015z5r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751013627,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01muhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lothariusdark","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01erkz","score":10,"author_fullname":"t2_idhb522c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, offloading places parts of the model in your GPU VRAM and what doesnt fit remains in the normal RAM. This means you run mostly at CPU speeds, but allows you to run far larger models at the cost of longer generation times.\\n\\nThis makes large \\"dense\\" models (70B/72B/100B+) very slow. You get roughly around 1.5t/s with DDR4 and 2.5t/s with DDR5 RAM.\\n\\nHowever, MoE models are still very fast with offloading, while having more parameters and thus better quality responses.\\n\\nQwen3 30B A3B for example is blazingly fast when using GPU only, so fast in fact that you cant read or even skim as fast as it generates. (thats partially necessary due to long thought processes but the point stands)\\n\\nAs such you can use larger quants, Q8 to get the highest quality out of the model while still retaining usable speeds. Or you can fill your VRAM with context because even offloaded to RAM the model is still fast enough.\\n\\nThis means this new model has technically 80B parameters, but runs on CPU as fast as a 13B model, which means its very usable at that speed.\\n\\nKeep in mind this is all precluding coding tasks. There you want the highest speeds possible, but for everything else, offloading MoE models is awesome.","edited":false,"author_flair_css_class":null,"name":"t1_n01muhu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, offloading places parts of the model in your GPU VRAM and what doesnt fit remains in the normal RAM. This means you run mostly at CPU speeds, but allows you to run far larger models at the cost of longer generation times.&lt;/p&gt;\\n\\n&lt;p&gt;This makes large &amp;quot;dense&amp;quot; models (70B/72B/100B+) very slow. You get roughly around 1.5t/s with DDR4 and 2.5t/s with DDR5 RAM.&lt;/p&gt;\\n\\n&lt;p&gt;However, MoE models are still very fast with offloading, while having more parameters and thus better quality responses.&lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 30B A3B for example is blazingly fast when using GPU only, so fast in fact that you cant read or even skim as fast as it generates. (thats partially necessary due to long thought processes but the point stands)&lt;/p&gt;\\n\\n&lt;p&gt;As such you can use larger quants, Q8 to get the highest quality out of the model while still retaining usable speeds. Or you can fill your VRAM with context because even offloaded to RAM the model is still fast enough.&lt;/p&gt;\\n\\n&lt;p&gt;This means this new model has technically 80B parameters, but runs on CPU as fast as a 13B model, which means its very usable at that speed.&lt;/p&gt;\\n\\n&lt;p&gt;Keep in mind this is all precluding coding tasks. There you want the highest speeds possible, but for everything else, offloading MoE models is awesome.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01muhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751022685,"author_flair_text":null,"collapsed":false,"created_utc":1751022685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n01erkz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bigs819","can_mod_post":false,"send_replies":true,"parent_id":"t1_n010va8","score":1,"author_fullname":"t2_13eg3r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What does offloading do?  I thought making it fit into limited GPU ram solely relied on quantizing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01erkz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What does offloading do?  I thought making it fit into limited GPU ram solely relied on quantizing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01erkz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018663,"author_flair_text":null,"treatment_tags":[],"created_utc":1751018663,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n010va8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lothariusdark","can_mod_post":false,"send_replies":true,"parent_id":"t1_n00z3mo","score":10,"author_fullname":"t2_idhb522c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It doesnt quite fit into 24GB VRAM :D\\n\\nSo I need to wait until offloading is possible.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n010va8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesnt quite fit into 24GB VRAM :D&lt;/p&gt;\\n\\n&lt;p&gt;So I need to wait until offloading is possible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n010va8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010584,"author_flair_text":null,"treatment_tags":[],"created_utc":1751010584,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n00z3mo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mysterious_Finish543","can_mod_post":false,"created_utc":1751009536,"send_replies":true,"parent_id":"t1_n00wmb1","score":24,"author_fullname":"t2_gbx2bcdvl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Doesn't look like it at the moment.\\n\\nHowever, support seems to be available for vLLM and SGLang.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00z3mo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doesn&amp;#39;t look like it at the moment.&lt;/p&gt;\\n\\n&lt;p&gt;However, support seems to be available for vLLM and SGLang.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00z3mo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751009536,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01fjz0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1751019086,"send_replies":true,"parent_id":"t1_n00wmb1","score":4,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Someone post the where gguf picture please","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01fjz0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone post the where gguf picture please&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01fjz0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751019086,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n00wmb1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lothariusdark","can_mod_post":false,"created_utc":1751008111,"send_replies":true,"parent_id":"t3_1llndut","score":33,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This doesnt work with llama.cpp yet, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00wmb1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This doesnt work with llama.cpp yet, right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00wmb1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008111,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03ij2m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VoidAlchemy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n02kkw6","score":6,"author_fullname":"t2_n321yfw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've seen it before where smaller quants sometimes \\"beat\\" the original model on some benchmarks as [shown in The Great Quant Wars of 2025](https://www.reddit.com/r/LocalLLaMA/comments/1khwxal/the_great_quant_wars_of_2025/) as well.\\n\\nI like to measure Perplexity and KL-Divergence of various sized quants relative to the full model. This let's us have some idea of how \\"different\\" the quantized output will be relative to the full size.\\n\\nSo yeah while the 4bit does score pretty similar to the original on most of those listed benchmarks, it is unlikely that it is always \\"better\\".","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n03ij2m","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve seen it before where smaller quants sometimes &amp;quot;beat&amp;quot; the original model on some benchmarks as &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1khwxal/the_great_quant_wars_of_2025/\\"&gt;shown in The Great Quant Wars of 2025&lt;/a&gt; as well.&lt;/p&gt;\\n\\n&lt;p&gt;I like to measure Perplexity and KL-Divergence of various sized quants relative to the full model. This let&amp;#39;s us have some idea of how &amp;quot;different&amp;quot; the quantized output will be relative to the full size.&lt;/p&gt;\\n\\n&lt;p&gt;So yeah while the 4bit does score pretty similar to the original on most of those listed benchmarks, it is unlikely that it is always &amp;quot;better&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03ij2m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751044270,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751044270,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n02kkw6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Educational-Shoe9300","can_mod_post":false,"created_utc":1751034637,"send_replies":true,"parent_id":"t1_n01jwzn","score":6,"author_fullname":"t2_12jmnu4u9t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is it possible that the Hunyuan A13B has almost no precision loss at 4bit quantization? Or am I misreading this benchmark: [https://github.com/Tencent-Hunyuan/Hunyuan-A13B?tab=readme-ov-file#int4-benchmark](https://github.com/Tencent-Hunyuan/Hunyuan-A13B?tab=readme-ov-file#int4-benchmark)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02kkw6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it possible that the Hunyuan A13B has almost no precision loss at 4bit quantization? Or am I misreading this benchmark: &lt;a href=\\"https://github.com/Tencent-Hunyuan/Hunyuan-A13B?tab=readme-ov-file#int4-benchmark\\"&gt;https://github.com/Tencent-Hunyuan/Hunyuan-A13B?tab=readme-ov-file#int4-benchmark&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02kkw6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751034637,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n01jwzn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResearchCrafty1804","can_mod_post":false,"created_utc":1751021319,"send_replies":true,"parent_id":"t3_1llndut","score":20,"author_fullname":"t2_c705ri9b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What a great release!\\n \\nThey even provide benchmark for the q8 and q4 quants, I wish every model author would do that. \\n\\nLooking forward to testing myself.\\n\\nKudos Hunyuan!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01jwzn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What a great release!&lt;/p&gt;\\n\\n&lt;p&gt;They even provide benchmark for the q8 and q4 quants, I wish every model author would do that. &lt;/p&gt;\\n\\n&lt;p&gt;Looking forward to testing myself.&lt;/p&gt;\\n\\n&lt;p&gt;Kudos Hunyuan!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01jwzn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751021319,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"body":"The license allows commercial use of up to 100 million users per month and prohibits the use of the model in the UK, EU and South Korea.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01i3ix","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PaluMacil","can_mod_post":false,"send_replies":true,"parent_id":"t1_n018mrz","score":5,"author_fullname":"t2_ww9q4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can add extra characters to Unicode code points which won’t be visible but could say whatever you want","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n01i3ix","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can add extra characters to Unicode code points which won’t be visible but could say whatever you want&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01i3ix/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751020418,"author_flair_text":null,"treatment_tags":[],"created_utc":1751020418,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n018mrz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JadedFig5848","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013gov","score":3,"author_fullname":"t2_1oo56jrgsb","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see, do you have any examples of the emission of chars in unique ways?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n018mrz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see, do you have any examples of the emission of chars in unique ways?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n018mrz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015184,"author_flair_text":null,"treatment_tags":[],"created_utc":1751015184,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n013gov","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eposnix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n011jrn","score":16,"author_fullname":"t2_7oo5j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Normally license breaches are detected by subtle leaks like a config file that points to \\"hunyuan-a13b\\", an employee that accidently posts information, or marketing material that lists the model by name. Companies can also include watermarks in the training data that point to their training set, or train it to emit characters in unique ways.","edited":false,"author_flair_css_class":null,"name":"t1_n013gov","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Normally license breaches are detected by subtle leaks like a config file that points to &amp;quot;hunyuan-a13b&amp;quot;, an employee that accidently posts information, or marketing material that lists the model by name. Companies can also include watermarks in the training data that point to their training set, or train it to emit characters in unique ways.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n013gov/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012119,"author_flair_text":null,"collapsed":false,"created_utc":1751012119,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n014nwe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n011jrn","score":12,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's to avoid EU AI act requirements if I understand correctly.\\n\\nIt was discussed e.g. here:\\n\\nhttps://www.reddit.com/r/aiwars/comments/1g5bz3k/tencents_license_for_its_image_generator_now/\\n\\nMeta does the same starting with Llama 3.2 if I recall correctly:\\n\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1jtejzj/llama_4_is_open_unless_you_are_in_the_eu/","edited":false,"author_flair_css_class":null,"name":"t1_n014nwe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s to avoid EU AI act requirements if I understand correctly.&lt;/p&gt;\\n\\n&lt;p&gt;It was discussed e.g. here:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/aiwars/comments/1g5bz3k/tencents_license_for_its_image_generator_now/\\"&gt;https://www.reddit.com/r/aiwars/comments/1g5bz3k/tencents_license_for_its_image_generator_now/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Meta does the same starting with Llama 3.2 if I recall correctly:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1jtejzj/llama_4_is_open_unless_you_are_in_the_eu/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jtejzj/llama_4_is_open_unless_you_are_in_the_eu/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n014nwe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012838,"author_flair_text":null,"collapsed":false,"created_utc":1751012838,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n027own","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n011jrn","score":5,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's really hard to hide something like that in a large company.  People find out. \\n\\nIt becomes a massive conspiracy involving more and more people.  You have to hope every employee that knows is totally ok with \\"never tell anyone that we're stealing this model.\\"  I.e. you need to employee more and more people with questionable ethics. \\n\\nOne small leak opens the door to court ordered discovery.  The risk for large companies are too large to bother.","edited":false,"author_flair_css_class":null,"name":"t1_n027own","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s really hard to hide something like that in a large company.  People find out. &lt;/p&gt;\\n\\n&lt;p&gt;It becomes a massive conspiracy involving more and more people.  You have to hope every employee that knows is totally ok with &amp;quot;never tell anyone that we&amp;#39;re stealing this model.&amp;quot;  I.e. you need to employee more and more people with questionable ethics. &lt;/p&gt;\\n\\n&lt;p&gt;One small leak opens the door to court ordered discovery.  The risk for large companies are too large to bother.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n027own/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751030673,"author_flair_text":null,"collapsed":false,"created_utc":1751030673,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n011jrn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JadedFig5848","can_mod_post":false,"send_replies":true,"parent_id":"t1_n010bco","score":3,"author_fullname":"t2_1oo56jrgsb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree but let's say a big company uses it. How can people technically sniff out the model? \\n\\nI'm just curious","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n011jrn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree but let&amp;#39;s say a big company uses it. How can people technically sniff out the model? &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m just curious&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n011jrn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010986,"author_flair_text":null,"treatment_tags":[],"created_utc":1751010986,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n010bco","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eposnix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n00z5kt","score":32,"author_fullname":"t2_7oo5j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They are basically saying anyone can use it outside of huge companies like Meta or Apple that have the compute and reach to serve millions of people.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n010bco","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are basically saying anyone can use it outside of huge companies like Meta or Apple that have the compute and reach to serve millions of people.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n010bco/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010253,"author_flair_text":null,"treatment_tags":[],"created_utc":1751010253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}}],"before":null}},"user_reports":[],"saved":false,"id":"n00z5kt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JadedFig5848","can_mod_post":false,"created_utc":1751009568,"send_replies":true,"parent_id":"t1_n00vz9o","score":9,"author_fullname":"t2_1oo56jrgsb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Curious, how would they know?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00z5kt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Curious, how would they know?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00z5kt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751009568,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02wws7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hak8or","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01ctq5","score":2,"author_fullname":"t2_95p4l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;EU has AI Directive that basically forbids existence of large enough models\\n\\n\\"Basically\\"? How is mistral handling this? I know their AI laws are quite specific, but I haven't heard of them being limiting to that degree.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02wws7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;EU has AI Directive that basically forbids existence of large enough models&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&amp;quot;Basically&amp;quot;? How is mistral handling this? I know their AI laws are quite specific, but I haven&amp;#39;t heard of them being limiting to that degree.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02wws7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038188,"author_flair_text":null,"treatment_tags":[],"created_utc":1751038188,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n01ctq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AssistBorn4589","can_mod_post":false,"send_replies":true,"parent_id":"t1_n012svo","score":15,"author_fullname":"t2_rorjsgop","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"EU has AI Directive that basically forbids existence of large enough models, plus hundreds of pages of other regulations, including regulations prohibiting LLMs from generating hatespeech and criminal content.\\n\\nIt's logical that rest of the world doesn't want to engage with that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01ctq5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;EU has AI Directive that basically forbids existence of large enough models, plus hundreds of pages of other regulations, including regulations prohibiting LLMs from generating hatespeech and criminal content.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s logical that rest of the world doesn&amp;#39;t want to engage with that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01ctq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751017605,"author_flair_text":null,"treatment_tags":[],"created_utc":1751017605,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03hvbh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_n02zd74","score":3,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL\\\\_202401689](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL_202401689)  \\nArt.55:  \\n...providers of general-purpose AI models with systemic risk shall:  \\n\\\\- perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks  \\n\\\\- assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the placing on the market, or the use of general-purpose AI models with systemic risk  \\n\\\\- keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities, relevant information about serious incidents and possible corrective measures to address them\\n\\nWhat is systemic risk?  \\nRecital 110:  \\nGeneral-purpose AI models could pose systemic risks which include, but are not limited to, any actual or reasonably foreseeable negative effects in relation to major accidents, disruptions of critical sectors and serious consequences to public health and safety; any actual or reasonably foreseeable negative effects on democratic processes, public and economic security; **the dissemination of illegal, false, or discriminatory content**\\n\\nSo anyone deploying big-enough models has to prune their dataset from anything EU deems illegal (and its not about copyright), redteam that the model is unable to generate it, and monitor that if it does it has to be immediately reported. What is \\"false\\" or \\"discriminatory\\" content? Well, whatever they will decide to sue you about if they so desire, lol.\\n\\nWhether it will be enforced or not will totally depend on the political desire.","edited":false,"author_flair_css_class":null,"name":"t1_n03hvbh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL_202401689\\"&gt;https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL_202401689&lt;/a&gt;&lt;br/&gt;\\nArt.55:&lt;br/&gt;\\n...providers of general-purpose AI models with systemic risk shall:&lt;br/&gt;\\n- perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks&lt;br/&gt;\\n- assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the placing on the market, or the use of general-purpose AI models with systemic risk&lt;br/&gt;\\n- keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities, relevant information about serious incidents and possible corrective measures to address them&lt;/p&gt;\\n\\n&lt;p&gt;What is systemic risk?&lt;br/&gt;\\nRecital 110:&lt;br/&gt;\\nGeneral-purpose AI models could pose systemic risks which include, but are not limited to, any actual or reasonably foreseeable negative effects in relation to major accidents, disruptions of critical sectors and serious consequences to public health and safety; any actual or reasonably foreseeable negative effects on democratic processes, public and economic security; &lt;strong&gt;the dissemination of illegal, false, or discriminatory content&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;So anyone deploying big-enough models has to prune their dataset from anything EU deems illegal (and its not about copyright), redteam that the model is unable to generate it, and monitor that if it does it has to be immediately reported. What is &amp;quot;false&amp;quot; or &amp;quot;discriminatory&amp;quot; content? Well, whatever they will decide to sue you about if they so desire, lol.&lt;/p&gt;\\n\\n&lt;p&gt;Whether it will be enforced or not will totally depend on the political desire.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03hvbh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751044085,"author_flair_text":null,"collapsed":false,"created_utc":1751044085,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n02zd74","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StyMaar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01e3hx","score":3,"author_fullname":"t2_mlc3a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I read this BS all over the place, but fact is **there's no provision for censoring hate speech in the European AI act**.\\n\\nThe key point in the AI act that leads to these artificial restrictions is the obligation to respect intellectual property of the material you are training on, and now you see the actual reason that bothers model makers.\\n\\n(As if EU was enforcing their regulation anyway, for instance GDPR is routinely being violated but the pro-business stance of the regulators means they barely do anything against that).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02zd74","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I read this BS all over the place, but fact is &lt;strong&gt;there&amp;#39;s no provision for censoring hate speech in the European AI act&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;The key point in the AI act that leads to these artificial restrictions is the obligation to respect intellectual property of the material you are training on, and now you see the actual reason that bothers model makers.&lt;/p&gt;\\n\\n&lt;p&gt;(As if EU was enforcing their regulation anyway, for instance GDPR is routinely being violated but the pro-business stance of the regulators means they barely do anything against that).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02zd74/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038881,"author_flair_text":null,"treatment_tags":[],"created_utc":1751038881,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n01e3hx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_n012svo","score":12,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not data protection laws, but censorship, in that case. Fuck AI act, huge mistake that puts us behind the progress yet again.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01e3hx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not data protection laws, but censorship, in that case. Fuck AI act, huge mistake that puts us behind the progress yet again.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01e3hx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018304,"author_flair_text":null,"treatment_tags":[],"created_utc":1751018304,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n012svo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DisturbedNeo","can_mod_post":false,"created_utc":1751011723,"send_replies":false,"parent_id":"t1_n00vz9o","score":3,"author_fullname":"t2_adnhw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All places that have extensive data protection laws. Curious.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n012svo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All places that have extensive data protection laws. Curious.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n012svo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751011723,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04tjmj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1751057995,"send_replies":true,"parent_id":"t1_n00vz9o","score":1,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt;  and prohibits the use of the model in the UK, EU and South Korea.\\n\\nLmao","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04tjmj","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt;  and prohibits the use of the model in the UK, EU and South Korea.&lt;/p&gt;\\n\\n&lt;p&gt;Lmao&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04tjmj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751057995,"author_flair_text":"Alpaca","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03i8t9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01x5sn","score":1,"author_fullname":"t2_1n0su21k4z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; Pretty sure a drug lord making drugs that get shipped to the EU can be prosecuted even if he isn't a EU resident\\n\\nYeah no, thats no how that works, you cant prosecute someone outside of your jurisdiction. By, well, definition of jurisdiction.\\n\\n\\\\&gt; EU's “AI Act” isn't about censoring AI so that they cannot spit “hate speech”\\n\\n[https://www.reddit.com/r/LocalLLaMA/comments/1llndut/comment/n03hvbh/](https://www.reddit.com/r/LocalLLaMA/comments/1llndut/comment/n03hvbh/)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n03i8t9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Pretty sure a drug lord making drugs that get shipped to the EU can be prosecuted even if he isn&amp;#39;t a EU resident&lt;/p&gt;\\n\\n&lt;p&gt;Yeah no, thats no how that works, you cant prosecute someone outside of your jurisdiction. By, well, definition of jurisdiction.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; EU&amp;#39;s “AI Act” isn&amp;#39;t about censoring AI so that they cannot spit “hate speech”&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1llndut/comment/n03hvbh/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1llndut/comment/n03hvbh/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03i8t9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751044190,"author_flair_text":null,"treatment_tags":[],"created_utc":1751044190,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n01x5sn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StyMaar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01uy7o","score":0,"author_fullname":"t2_mlc3a","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;  But it would be smuggler who is prosecuted, not the producer.\\n\\nPretty sure a drug lord making drugs that get shipped to the EU can be prosecuted even if he isn't a EU resident, and adding a sticker explaining that smuglers aren't allowed to ship it to the EU wouldn't change much.\\n\\n&gt; And no amount of censorship during training can prevent model from generating \\"hate speech\\" or whatever they decide to restrict, so that regulation is just impossible to comply with.\\n\\nEU's “AI Act” isn't about censoring AI so that they cannot spit “hate speech”. That “regulation impossible to comply with” is just a strawman actually. (In fact, companies like Meta even had such geographic restriction before the AI act was even passed, it is suspected that it was done as retaliation against the constraints GDPR put on Facebook).","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n01x5sn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;But it would be smuggler who is prosecuted, not the producer.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Pretty sure a drug lord making drugs that get shipped to the EU can be prosecuted even if he isn&amp;#39;t a EU resident, and adding a sticker explaining that smuglers aren&amp;#39;t allowed to ship it to the EU wouldn&amp;#39;t change much.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;And no amount of censorship during training can prevent model from generating &amp;quot;hate speech&amp;quot; or whatever they decide to restrict, so that regulation is just impossible to comply with.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;EU&amp;#39;s “AI Act” isn&amp;#39;t about censoring AI so that they cannot spit “hate speech”. That “regulation impossible to comply with” is just a strawman actually. (In fact, companies like Meta even had such geographic restriction before the AI act was even passed, it is suspected that it was done as retaliation against the constraints GDPR put on Facebook).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01x5sn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751026962,"author_flair_text":null,"treatment_tags":[],"created_utc":1751026962,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n01uy7o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01sq21","score":1,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But it would be smuggler who is prosecuted, not the producer.\\n\\nAnd no amount of censorship during training can prevent model from generating \\"hate speech\\" or whatever they decide to restrict, so that regulation is just impossible to comply with. Whether its going to be enforced is just a question of desire to exert pressure against a company.","edited":false,"author_flair_css_class":null,"name":"t1_n01uy7o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But it would be smuggler who is prosecuted, not the producer.&lt;/p&gt;\\n\\n&lt;p&gt;And no amount of censorship during training can prevent model from generating &amp;quot;hate speech&amp;quot; or whatever they decide to restrict, so that regulation is just impossible to comply with. Whether its going to be enforced is just a question of desire to exert pressure against a company.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01uy7o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751026112,"author_flair_text":null,"collapsed":false,"created_utc":1751026112,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n01sq21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StyMaar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01e74t","score":-1,"author_fullname":"t2_mlc3a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The European Commission has had a pro-business stance pretty much forever, and uses the tools at its disposal very lightly (see how many times they agreed to a privacy-violation deal with US corporation “Safe Harbor”/“Privacy shield” that get shut down by European justice every time because it does indeed violates European laws.\\n\\nBut of course it's an attempt to say “of course no, we're not distributing this to the EU” but that's not giving them actual legal protection. Should someone do harmful stuff with that in the EU, then the AI makers could be prosecuted for making it anyway (it doesn't mean that they would be condemned in the end, but the license doesn't change the expected outcome by much).\\n\\nYou can't smuggle drugs with a stickers “Consuming this in the EU is forbidden” and expect to be safe from prosecution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01sq21","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The European Commission has had a pro-business stance pretty much forever, and uses the tools at its disposal very lightly (see how many times they agreed to a privacy-violation deal with US corporation “Safe Harbor”/“Privacy shield” that get shut down by European justice every time because it does indeed violates European laws.&lt;/p&gt;\\n\\n&lt;p&gt;But of course it&amp;#39;s an attempt to say “of course no, we&amp;#39;re not distributing this to the EU” but that&amp;#39;s not giving them actual legal protection. Should someone do harmful stuff with that in the EU, then the AI makers could be prosecuted for making it anyway (it doesn&amp;#39;t mean that they would be condemned in the end, but the license doesn&amp;#39;t change the expected outcome by much).&lt;/p&gt;\\n\\n&lt;p&gt;You can&amp;#39;t smuggle drugs with a stickers “Consuming this in the EU is forbidden” and expect to be safe from prosecution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01sq21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751025224,"author_flair_text":null,"treatment_tags":[],"created_utc":1751025224,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n01e74t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01b1yc","score":7,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does, in a sense that company shields itseft from Eurocommission trying to go after it for whatever bullshit reason","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01e74t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does, in a sense that company shields itseft from Eurocommission trying to go after it for whatever bullshit reason&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01e74t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018356,"author_flair_text":null,"treatment_tags":[],"created_utc":1751018356,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n01b1yc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"StyMaar","can_mod_post":false,"created_utc":1751016597,"send_replies":true,"parent_id":"t1_n00vz9o","score":-7,"author_fullname":"t2_mlc3a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; prohibits the use of the model in the UK, EU and South Korea.\\n\\nAs if this restriction had any value. ¯\\\\_ (ツ)_/¯","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01b1yc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;prohibits the use of the model in the UK, EU and South Korea.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;As if this restriction had any value. ¯_ (ツ)_/¯&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01b1yc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751016597,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"n00vz9o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kristaller486","can_mod_post":false,"created_utc":1751007748,"send_replies":true,"parent_id":"t3_1llndut","score":46,"author_fullname":"t2_g8fwjts3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00vz9o","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The license allows commercial use of up to 100 million users per month and prohibits the use of the model in the UK, EU and South Korea.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00vz9o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751007748,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n025kzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Admirable-Star7088","can_mod_post":false,"send_replies":true,"parent_id":"t1_n02289h","score":3,"author_fullname":"t2_qhlcbiy3k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Guess I will just wait for all the above steps to be done then, so I can run GGUF. An [issue has opened](https://github.com/ggml-org/llama.cpp/issues/14415) on Llama.cpp github to add support, so the very first step has been taken :D","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n025kzs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Guess I will just wait for all the above steps to be done then, so I can run GGUF. An &lt;a href=\\"https://github.com/ggml-org/llama.cpp/issues/14415\\"&gt;issue has opened&lt;/a&gt; on Llama.cpp github to add support, so the very first step has been taken :D&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n025kzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751029971,"author_flair_text":null,"treatment_tags":[],"created_utc":1751029971,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n02289h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Severin_Suveren","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01m7dg","score":3,"author_fullname":"t2_vfpsd1c8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think it is possible, but extremely ineffective. Quants like GPTQ, EXL2 and AWQ are optimized for VRAM runtime and excel at it","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n02289h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it is possible, but extremely ineffective. Quants like GPTQ, EXL2 and AWQ are optimized for VRAM runtime and excel at it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02289h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751028815,"author_flair_text":null,"treatment_tags":[],"created_utc":1751028815,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n01m7dg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Tenzu9","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01l53z","score":4,"author_fullname":"t2_10wgss","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good question.. I'm not sure to be honest. I have only used transformers with small models. I do know that transformers allows model sharding with a library called accelerate. However, whether that will work with GPTQ models is unknown to me.","edited":false,"author_flair_css_class":null,"name":"t1_n01m7dg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good question.. I&amp;#39;m not sure to be honest. I have only used transformers with small models. I do know that transformers allows model sharding with a library called accelerate. However, whether that will work with GPTQ models is unknown to me.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01m7dg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751022391,"author_flair_text":null,"collapsed":false,"created_utc":1751022391,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n01l53z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f1yn","score":5,"author_fullname":"t2_qhlcbiy3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have previously only been using GGUFs because, to my (incorrect?) knowledge, other formats like GPTQ can only run on GPU/VRAM exclusively. Or can I offload to system RAM also with GPTQ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01l53z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have previously only been using GGUFs because, to my (incorrect?) knowledge, other formats like GPTQ can only run on GPU/VRAM exclusively. Or can I offload to system RAM also with GPTQ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01l53z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751021899,"author_flair_text":null,"treatment_tags":[],"created_utc":1751021899,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04w37a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xxPoLyGLoTxx","can_mod_post":false,"created_utc":1751058788,"send_replies":true,"parent_id":"t1_n047ob0","score":1,"author_fullname":"t2_85uj8ku","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Regular transformers failed. Have to try this next. Thanks for the tip","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n04w37a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Regular transformers failed. Have to try this next. Thanks for the tip&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04w37a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751058788,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n047ob0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tenzu9","can_mod_post":false,"send_replies":true,"parent_id":"t1_n03a5ek","score":2,"author_fullname":"t2_10wgss","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this mlx transformers fork maybe able run it:  \\n[https://github.com/ToluClassics/mlx-transformers](https://github.com/ToluClassics/mlx-transformers)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n047ob0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this mlx transformers fork maybe able run it:&lt;br/&gt;\\n&lt;a href=\\"https://github.com/ToluClassics/mlx-transformers\\"&gt;https://github.com/ToluClassics/mlx-transformers&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n047ob0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751051401,"author_flair_text":null,"treatment_tags":[],"created_utc":1751051401,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n03a5ek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xxPoLyGLoTxx","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0394c0","score":1,"author_fullname":"t2_85uj8ku","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have no idea either. But it's downloaded so let's see what happens. :)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n03a5ek","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have no idea either. But it&amp;#39;s downloaded so let&amp;#39;s see what happens. :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03a5ek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751041908,"author_flair_text":null,"treatment_tags":[],"created_utc":1751041908,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0394c0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tenzu9","can_mod_post":false,"send_replies":true,"parent_id":"t1_n032ly7","score":1,"author_fullname":"t2_10wgss","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just be sure you know your way around Python before you waste 40 GB... This is a quantized transformers model, not a gguf. I have no idea if it supports MLX.","edited":false,"author_flair_css_class":null,"name":"t1_n0394c0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just be sure you know your way around Python before you waste 40 GB... This is a quantized transformers model, not a gguf. I have no idea if it supports MLX.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0394c0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751041616,"author_flair_text":null,"collapsed":false,"created_utc":1751041616,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n032ly7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xxPoLyGLoTxx","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01f1yn","score":1,"author_fullname":"t2_85uj8ku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Downloading now...\\n\\nSo, I always just use LM Studio to run my models. Do you happen to know if I can convert the model to MLX format use the mlx-lm library in Python?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n032ly7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Downloading now...&lt;/p&gt;\\n\\n&lt;p&gt;So, I always just use LM Studio to run my models. Do you happen to know if I can convert the model to MLX format use the mlx-lm library in Python?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n032ly7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751039778,"author_flair_text":null,"treatment_tags":[],"created_utc":1751039778,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n01f1yn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Tenzu9","can_mod_post":false,"send_replies":true,"parent_id":"t1_n019n15","score":6,"author_fullname":"t2_10wgss","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"or... download the official Int4 quant and run it from the included py file (its 43 GB):\\n\\n[https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GPTQ-Int4](https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GPTQ-Int4)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01f1yn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;or... download the official Int4 quant and run it from the included py file (its 43 GB):&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GPTQ-Int4\\"&gt;https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GPTQ-Int4&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01f1yn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751018818,"author_flair_text":null,"treatment_tags":[],"created_utc":1751018818,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n019n15","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1751015776,"send_replies":true,"parent_id":"t1_n00wgyx","score":17,"author_fullname":"t2_qhlcbiy3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wonder if this works out of the box in llama.cpp? Or if we must go through the usual steps first:\\n\\n1. Wait for added support.\\n2. Wait for Unsloth to sort out all bugs.\\n3. Wait for our favorite apps (Koboldcpp, LM Studio, etc) to update to the latest llama.cpp build.\\n\\nIf this model is good though, it will be very worth the wait!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n019n15","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if this works out of the box in llama.cpp? Or if we must go through the usual steps first:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Wait for added support.&lt;/li&gt;\\n&lt;li&gt;Wait for Unsloth to sort out all bugs.&lt;/li&gt;\\n&lt;li&gt;Wait for our favorite apps (Koboldcpp, LM Studio, etc) to update to the latest llama.cpp build.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;If this model is good though, it will be very worth the wait!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n019n15/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015776,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"n00wgyx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wonderful_Second5322","can_mod_post":false,"created_utc":1751008027,"send_replies":true,"parent_id":"t3_1llndut","score":25,"author_fullname":"t2_z0tqo4itn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"GGUFs?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00wgyx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GGUFs?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00wgyx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008027,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01pz0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013mqh","score":5,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was really hoping for Apache. Oh well. It’s a high bar I won’t hit. As long as it doesn’t have rug pull capabilities.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01pz0a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was really hoping for Apache. Oh well. It’s a high bar I won’t hit. As long as it doesn’t have rug pull capabilities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01pz0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751024072,"author_flair_text":null,"treatment_tags":[],"created_utc":1751024072,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0159na","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ResidentPositive4122","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013mqh","score":3,"author_fullname":"t2_10nxrjjgay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hah, yes, my bad. Thanks, I'll edit.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0159na","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hah, yes, my bad. Thanks, I&amp;#39;ll edit.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0159na/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751013200,"author_flair_text":null,"treatment_tags":[],"created_utc":1751013200,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n058g9l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013mqh","score":2,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just a casual 1/80th of the human population.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n058g9l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just a casual 1/80th of the human population.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n058g9l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751062814,"author_flair_text":null,"treatment_tags":[],"created_utc":1751062814,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n013mqh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"matteogeniaccio","can_mod_post":false,"created_utc":1751012221,"send_replies":true,"parent_id":"t1_n00wocj","score":14,"author_fullname":"t2_hoxc8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it's 100 **million** monthly users","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n013mqh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s 100 &lt;strong&gt;million&lt;/strong&gt; monthly users&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n013mqh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012221,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01plt3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1751023913,"send_replies":true,"parent_id":"t1_n00wocj","score":4,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't like that we're topping out at 32b now. Let alone having 13b active only. Training data will make or break it. \\n\\nFor some reason they uploaded it yesterday and then hid/deleted.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01plt3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t like that we&amp;#39;re topping out at 32b now. Let alone having 13b active only. Training data will make or break it. &lt;/p&gt;\\n\\n&lt;p&gt;For some reason they uploaded it yesterday and then hid/deleted.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01plt3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751023913,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n05ohm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Different_Fix_2217","can_mod_post":false,"created_utc":1751068340,"send_replies":true,"parent_id":"t1_n00wocj","score":2,"author_fullname":"t2_4dhrrvi6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The whole dense equivalent thing is unproven / speculatory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05ohm0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The whole dense equivalent thing is unproven / speculatory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n05ohm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751068340,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n00wocj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResidentPositive4122","can_mod_post":false,"created_utc":1751008142,"send_replies":true,"parent_id":"t3_1llndut","score":33,"author_fullname":"t2_10nxrjjgay","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting, it's a 80B_13A model, which gives ~32B dense equivalent. \\n\\nEvals look amazing (beating qwen3-32B across the board, close to qwen3-A22B and even better on some). I guess we'll have to wait for 3rd party evals to see if they match this in real-world scenarios. Interesting that this scores significantly higher on agentic benchmarks. \\n\\nWith only 13B_active it should be considerably faster to run, if you have the vram.\\n\\nLicense sux tho, kinda like meta (&lt;100M monthly users) but with added restrictions for EU. Oh well...","edited":1751013215,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00wocj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting, it&amp;#39;s a 80B_13A model, which gives ~32B dense equivalent. &lt;/p&gt;\\n\\n&lt;p&gt;Evals look amazing (beating qwen3-32B across the board, close to qwen3-A22B and even better on some). I guess we&amp;#39;ll have to wait for 3rd party evals to see if they match this in real-world scenarios. Interesting that this scores significantly higher on agentic benchmarks. &lt;/p&gt;\\n\\n&lt;p&gt;With only 13B_active it should be considerably faster to run, if you have the vram.&lt;/p&gt;\\n\\n&lt;p&gt;License sux tho, kinda like meta (&amp;lt;100M monthly users) but with added restrictions for EU. Oh well...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00wocj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751008142,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07d7r6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"5lipperySausage","can_mod_post":false,"created_utc":1751094827,"send_replies":true,"parent_id":"t1_n0114aw","score":1,"author_fullname":"t2_jvpz2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They will. GLM got added and other randoms","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07d7r6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They will. GLM got added and other randoms&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n07d7r6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094827,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0114aw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Classic_Pair2011","can_mod_post":false,"created_utc":1751010731,"send_replies":true,"parent_id":"t3_1llndut","score":11,"author_fullname":"t2_j094hwboh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Who will provide this model on Openrouter? I hope somebody pick it up","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0114aw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Who will provide this model on Openrouter? I hope somebody pick it up&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0114aw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010731,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01q56m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dr_Me_123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n01fqzp","score":7,"author_fullname":"t2_59yau29b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well that's true if your VRAM can load an 80B model entirely. But if you need to load a part of it into your RAM, that depends.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01q56m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well that&amp;#39;s true if your VRAM can load an 80B model entirely. But if you need to load a part of it into your RAM, that depends.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01q56m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751024146,"author_flair_text":null,"treatment_tags":[],"created_utc":1751024146,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n01fqzp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1751019189,"send_replies":true,"parent_id":"t1_n014h9j","score":3,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That runs faster than Qwen 32b! 13b active means this will inference significantly faster than a dense 32b model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01fqzp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That runs faster than Qwen 32b! 13b active means this will inference significantly faster than a dense 32b model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01fqzp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751019189,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n065qym","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"getfitdotus","can_mod_post":false,"created_utc":1751074726,"send_replies":true,"parent_id":"t1_n014h9j","score":1,"author_fullname":"t2_dst51dcb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"this model is actually really good. But I do not like the &lt;answer&gt; tags and the implementation on vllm is not 100% its using a python slow tokenizer instead.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n065qym","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this model is actually really good. But I do not like the &amp;lt;answer&amp;gt; tags and the implementation on vllm is not 100% its using a python slow tokenizer instead.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n065qym/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751074726,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n014h9j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dr_Me_123","can_mod_post":false,"created_utc":1751012726,"send_replies":true,"parent_id":"t3_1llndut","score":8,"author_fullname":"t2_59yau29b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The online demo didn't yield any surprising results. So perhaps just be an upgrade of Qwen3 30B with more VRAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n014h9j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The online demo didn&amp;#39;t yield any surprising results. So perhaps just be an upgrade of Qwen3 30B with more VRAM.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n014h9j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012726,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01gvtf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fizzy1242","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013v2v","score":8,"author_fullname":"t2_16zcsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"remember to use the --fmoe flag too if you use ik_llama.cpp fork","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n01gvtf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;remember to use the --fmoe flag too if you use ik_llama.cpp fork&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01gvtf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751019788,"author_flair_text":null,"treatment_tags":[],"created_utc":1751019788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03wbd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_n013v2v","score":1,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you have free VRAM you can also stack them like:\\n\\n\\\\--override-tensor \\"(\\\\[0-2\\\\]).ffn\\\\_.\\\\*\\\\_exps.=CUDA0\\" --override-tensor \\"(\\\\[3-9\\\\]|\\\\[1-9\\\\]\\\\[0-9\\\\]+).ffn\\\\_.\\\\*\\\\_exps.=CPU\\"\\n\\nSo that offloads the first three of the MoE layers to GPU and rest to CPU. My speed on llama 4 scout went from 8 tok/sec to 18.5 from this.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n03wbd3","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you have free VRAM you can also stack them like:&lt;/p&gt;\\n\\n&lt;p&gt;--override-tensor &amp;quot;([0-2]).ffn_.*_exps.=CUDA0&amp;quot; --override-tensor &amp;quot;([3-9]|[1-9][0-9]+).ffn_.*_exps.=CPU&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;So that offloads the first three of the MoE layers to GPU and rest to CPU. My speed on llama 4 scout went from 8 tok/sec to 18.5 from this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03wbd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751048106,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751048106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n013v2v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"matteogeniaccio","can_mod_post":false,"created_utc":1751012361,"send_replies":true,"parent_id":"t1_n00yrjn","score":26,"author_fullname":"t2_hoxc8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"in llama.cpp the command I used so far is \`--override-tensor \\"([0-9]+).ffn_.*_exps.=CPU\\"\`\\n\\nIt puts the non-important bits in the CPU, then I manually tune \`-ngl\` to remove additional stuff from VRAM","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n013v2v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;in llama.cpp the command I used so far is &lt;code&gt;--override-tensor &amp;quot;([0-9]+).ffn_.*_exps.=CPU&amp;quot;&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It puts the non-important bits in the CPU, then I manually tune &lt;code&gt;-ngl&lt;/code&gt; to remove additional stuff from VRAM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n013v2v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012361,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}}],"before":null}},"user_reports":[],"saved":false,"id":"n00yrjn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1751009340,"send_replies":true,"parent_id":"t3_1llndut","score":8,"author_fullname":"t2_9so78ol2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"does anybody remember the command to throw the important bits into vram again?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00yrjn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does anybody remember the command to throw the important bits into vram again?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00yrjn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751009340,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n012x5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Barry_22","can_mod_post":false,"created_utc":1751011794,"send_replies":true,"parent_id":"t3_1llndut","score":7,"author_fullname":"t2_pctbl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow, great. How many languages it supports?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n012x5h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, great. How many languages it supports?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n012x5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751011794,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01xrp8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"05032-MendicantBias","can_mod_post":false,"created_utc":1751027192,"send_replies":true,"parent_id":"t3_1llndut","score":8,"author_fullname":"t2_6id3lwou","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It feels like this should work wonders with 64GB RAM + 24GB VRAM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01xrp8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It feels like this should work wonders with 64GB RAM + 24GB VRAM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01xrp8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751027192,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01152c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1751010744,"send_replies":true,"parent_id":"t3_1llndut","score":6,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks perfect!!! What a great time we are living now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01152c","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks perfect!!! What a great time we are living now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01152c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010744,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06osd9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ivari","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06n0m8","score":1,"author_fullname":"t2_707lw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My CPU is currently Ryzen 5 1600 lol. Will upgrade in few months once I finish my mortgage.","edited":false,"author_flair_css_class":null,"name":"t1_n06osd9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My CPU is currently Ryzen 5 1600 lol. Will upgrade in few months once I finish my mortgage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1llndut","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06osd9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751082446,"author_flair_text":null,"collapsed":false,"created_utc":1751082446,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06n0m8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Calcidiol","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06ej7f","score":1,"author_fullname":"t2_tailqi90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah maybe -- you can look at what kinds of RAM bandwidth benchmarks (large size e.g. 128MBy...GBy range sequential 128 bit wide reads) your RAM might achieve based on your CPU / RAM type and speed.\\n\\nThe A13B part of the model name says that at Q4 it'll read approximately 13GBy/2 bytes so around 7GBy read to generate a token.  So if your CPU can keep up and get 21 GBy/s RAM BW that might be around 3T/s, or 10T/s if you can get your system to 70GBy/s RAM BW etc.\\n\\nSo the possible speeds are usually in the 3T/s to 14T/s range with DDR4 or DDR5 RAM and a fast enough CPU to handle it also using only CPU+RAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06n0m8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah maybe -- you can look at what kinds of RAM bandwidth benchmarks (large size e.g. 128MBy...GBy range sequential 128 bit wide reads) your RAM might achieve based on your CPU / RAM type and speed.&lt;/p&gt;\\n\\n&lt;p&gt;The A13B part of the model name says that at Q4 it&amp;#39;ll read approximately 13GBy/2 bytes so around 7GBy read to generate a token.  So if your CPU can keep up and get 21 GBy/s RAM BW that might be around 3T/s, or 10T/s if you can get your system to 70GBy/s RAM BW etc.&lt;/p&gt;\\n\\n&lt;p&gt;So the possible speeds are usually in the 3T/s to 14T/s range with DDR4 or DDR5 RAM and a fast enough CPU to handle it also using only CPU+RAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06n0m8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751081659,"author_flair_text":null,"treatment_tags":[],"created_utc":1751081659,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06ej7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ivari","can_mod_post":false,"send_replies":true,"parent_id":"t1_n04jaho","score":1,"author_fullname":"t2_707lw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"so like for example, I can just upgrade my 16 GB ram to 64 GB ram and stay with my RTX 3050 to use this model at Q4 in a good enough speed?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n06ej7f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so like for example, I can just upgrade my 16 GB ram to 64 GB ram and stay with my RTX 3050 to use this model at Q4 in a good enough speed?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06ej7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751078106,"author_flair_text":null,"treatment_tags":[],"created_utc":1751078106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n04jaho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Calcidiol","can_mod_post":false,"created_utc":1751054898,"send_replies":true,"parent_id":"t1_n019x8y","score":1,"author_fullname":"t2_tailqi90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You could run a Q4 model (given the right SW / format) with no VRAM, just 48 or whatever GBy RAM -- then if you have N amount of VRAM it'll be able to use that much less RAM for the model and that much VRAM instead so it'll provide a fractional benefit.  But there's no absolutely needed RAM/VRAM ratio depending on how you set it up.\\n\\nIf you have SW or specific configurations that prioritizes using the VRAM to hold particular data like KV cache or whatever model components then of course you'd be using up whatever that takes amount of VRAM vs. RAM.\\n\\nTransferring from RAM to VRAM is slow though so usually you just pick a chunk of the inference data to stay in VRAM even though it's only a small part of the total puzzle and just provides speed benefit by handling that which it can permanently store &amp; process in VRAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04jaho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could run a Q4 model (given the right SW / format) with no VRAM, just 48 or whatever GBy RAM -- then if you have N amount of VRAM it&amp;#39;ll be able to use that much less RAM for the model and that much VRAM instead so it&amp;#39;ll provide a fractional benefit.  But there&amp;#39;s no absolutely needed RAM/VRAM ratio depending on how you set it up.&lt;/p&gt;\\n\\n&lt;p&gt;If you have SW or specific configurations that prioritizes using the VRAM to hold particular data like KV cache or whatever model components then of course you&amp;#39;d be using up whatever that takes amount of VRAM vs. RAM.&lt;/p&gt;\\n\\n&lt;p&gt;Transferring from RAM to VRAM is slow though so usually you just pick a chunk of the inference data to stay in VRAM even though it&amp;#39;s only a small part of the total puzzle and just provides speed benefit by handling that which it can permanently store &amp;amp; process in VRAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04jaho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751054898,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n019x8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ivari","can_mod_post":false,"created_utc":1751015944,"send_replies":true,"parent_id":"t3_1llndut","score":7,"author_fullname":"t2_707lw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"At 13B active experts, and Q4, that is around 8 gb vram and 48GB ram requirements right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n019x8y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At 13B active experts, and Q4, that is around 8 gb vram and 48GB ram requirements right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n019x8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015944,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0197ui","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"matteogeniaccio","can_mod_post":false,"created_utc":1751015527,"send_replies":true,"parent_id":"t1_n0134zq","score":2,"author_fullname":"t2_hoxc8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think it's in the documentation from their github: [https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/train/README.md](https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/train/README.md)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0197ui","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it&amp;#39;s in the documentation from their github: &lt;a href=\\"https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/train/README.md\\"&gt;https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/train/README.md&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0197ui/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015527,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0134zq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"m98789","can_mod_post":false,"created_utc":1751011924,"send_replies":true,"parent_id":"t3_1llndut","score":5,"author_fullname":"t2_hq5gkn85","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fine tune how","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0134zq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fine tune how&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n0134zq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751011924,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03l4u6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1751044994,"send_replies":true,"parent_id":"t1_n023h1q","score":3,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree it looks promising, but life is too short to struggle with dependency-hell.\\n\\nJust wait for GGUFs and use llama.cpp.  There's plenty of other work to focus on in the meantime.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03l4u6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree it looks promising, but life is too short to struggle with dependency-hell.&lt;/p&gt;\\n\\n&lt;p&gt;Just wait for GGUFs and use llama.cpp.  There&amp;#39;s plenty of other work to focus on in the meantime.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03l4u6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751044994,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n05lc2o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nmkd","can_mod_post":false,"created_utc":1751067250,"send_replies":true,"parent_id":"t1_n023h1q","score":2,"author_fullname":"t2_rg6rx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait a few days, then doubleclick koboldcpp and you're all set.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05lc2o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait a few days, then doubleclick koboldcpp and you&amp;#39;re all set.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n05lc2o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751067250,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n065ugb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"getfitdotus","can_mod_post":false,"created_utc":1751074763,"send_replies":true,"parent_id":"t1_n023h1q","score":1,"author_fullname":"t2_dst51dcb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"need to use the vllm docker to make it work. official PR is still pending","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n065ugb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;need to use the vllm docker to make it work. official PR is still pending&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n065ugb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751074763,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07yqci","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ben1984th","can_mod_post":false,"created_utc":1751107424,"send_replies":true,"parent_id":"t1_n023h1q","score":1,"author_fullname":"t2_13o91s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I got it to run with the official docker image. sglang and vllm. But I'm unable to extend the context window to 256k. But the implementation seems to be quite buggy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07yqci","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I got it to run with the official docker image. sglang and vllm. But I&amp;#39;m unable to extend the context window to 256k. But the implementation seems to be quite buggy&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n07yqci/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751107424,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n023h1q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"created_utc":1751029250,"send_replies":true,"parent_id":"t3_1llndut","score":3,"author_fullname":"t2_slwqrxz3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks promising.\\n\\nI could not make it work with vLLM and gave up after 2 hours of battling with dependencies. I didn't try the published docker image. Can someone who was able to run it share some important dependencies? versions of vllm, transformers, torch, flash-attn, cuda etc.?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n023h1q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks promising.&lt;/p&gt;\\n\\n&lt;p&gt;I could not make it work with vLLM and gave up after 2 hours of battling with dependencies. I didn&amp;#39;t try the published docker image. Can someone who was able to run it share some important dependencies? versions of vllm, transformers, torch, flash-attn, cuda etc.?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n023h1q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751029250,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02ygbw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xxPoLyGLoTxx","can_mod_post":false,"created_utc":1751038624,"send_replies":true,"parent_id":"t3_1llndut","score":3,"author_fullname":"t2_85uj8ku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks great! Quick someone make an mlx 8 bit version.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02ygbw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks great! Quick someone make an mlx 8 bit version.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02ygbw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038624,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04uqz8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1751058367,"send_replies":true,"parent_id":"t1_n04e2jz","score":1,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What creative models do you like?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04uqz8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What creative models do you like?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04uqz8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751058367,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n04e2jz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"martinerous","can_mod_post":false,"created_utc":1751053315,"send_replies":true,"parent_id":"t3_1llndut","score":5,"author_fullname":"t2_5tp54ey","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tried the demo for creative writing. Liked the style - no annoying slop, good story flow and details. Disappointed about intelligence - it often mixes up characters and actions even in a single sentence. Based on math and science eval results, I expected the total opposite - a stiff and smart model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04e2jz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried the demo for creative writing. Liked the style - no annoying slop, good story flow and details. Disappointed about intelligence - it often mixes up characters and actions even in a single sentence. Based on math and science eval results, I expected the total opposite - a stiff and smart model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04e2jz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751053315,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04efgb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"starshade16","can_mod_post":false,"created_utc":1751053423,"send_replies":true,"parent_id":"t3_1llndut","score":4,"author_fullname":"t2_1niddtyf79","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wtf do we have to do to get these guys to include tools in their LLMs? Come on guys.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04efgb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wtf do we have to do to get these guys to include tools in their LLMs? Come on guys.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04efgb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751053423,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n01il0u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Radiant_Hair_2739","can_mod_post":false,"created_utc":1751020667,"send_replies":true,"parent_id":"t3_1llndut","score":7,"author_fullname":"t2_i4xr6aod","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can't wait for llama.cpp or LM Studio!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n01il0u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can&amp;#39;t wait for llama.cpp or LM Studio!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n01il0u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751020667,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06slok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06buwp","score":4,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah, thank you! This solved all my problems!!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n06slok","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah, thank you! This solved all my problems!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06slok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751084164,"author_flair_text":null,"treatment_tags":[],"created_utc":1751084164,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n06buwp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1751077062,"send_replies":true,"parent_id":"t1_n02h487","score":1,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://downloadmoreram.com/](https://downloadmoreram.com/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06buwp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://downloadmoreram.com/\\"&gt;https://downloadmoreram.com/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n06buwp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751077062,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n02h487","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1751033625,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I dont have enough VRAM :'(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02h487","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I dont have enough VRAM :&amp;#39;(&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02h487/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751033625,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n02y8on","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MagicaItux","can_mod_post":false,"created_utc":1751038564,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_h7lo6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Detected Pickle imports (4)\\n\\n\\"torch._utils._rebuild_tensor_v2\\",\\n\\"torch.BFloat16Storage\\",\\n\\"torch.FloatStorage\\",\\n\\"collections.OrderedDict\\"\\n\\nIf you really want to run it with keeping that in mind, I'd just drop the uri of the .bin file in the right hyena hierarchy\\n\\n\\nDetected Pickle imports (4)\\n\\n\\nSo could you explain this?\\n&gt; \\"torch._utils._rebuild_tensor_v2\\",\\n&gt; \\"torch.BFloat16Storage\\",\\n&gt; \\"torch.FloatStorage\\",\\n&gt; \\"collections.OrderedDict\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02y8on","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Detected Pickle imports (4)&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;torch._utils._rebuild_tensor_v2&amp;quot;,\\n&amp;quot;torch.BFloat16Storage&amp;quot;,\\n&amp;quot;torch.FloatStorage&amp;quot;,\\n&amp;quot;collections.OrderedDict&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;If you really want to run it with keeping that in mind, I&amp;#39;d just drop the uri of the .bin file in the right hyena hierarchy&lt;/p&gt;\\n\\n&lt;p&gt;Detected Pickle imports (4)&lt;/p&gt;\\n\\n&lt;p&gt;So could you explain this?&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;&amp;quot;torch._utils._rebuild_tensor_v2&amp;quot;,\\n&amp;quot;torch.BFloat16Storage&amp;quot;,\\n&amp;quot;torch.FloatStorage&amp;quot;,\\n&amp;quot;collections.OrderedDict&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02y8on/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038564,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03me69","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1751045344,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"someone please tag the gguf troopers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03me69","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;someone please tag the gguf troopers&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03me69/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751045344,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03p0sj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BumbleSlob","can_mod_post":false,"created_utc":1751046072,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_1j7fhlcqkp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"64Gb or higher Unified Memory gang, rise up!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03p0sj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;64Gb or higher Unified Memory gang, rise up!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03p0sj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751046072,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04n3g5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Googulator","can_mod_post":false,"created_utc":1751056038,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_n4o9l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"At first I read \\"Hunyadi-A13B\\", and thought, a Hungarian LLM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04n3g5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At first I read &amp;quot;Hunyadi-A13B&amp;quot;, and thought, a Hungarian LLM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04n3g5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751056038,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07jujg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bionioncle","can_mod_post":false,"created_utc":1751098693,"send_replies":true,"parent_id":"t3_1llndut","score":2,"author_fullname":"t2_di7sz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So I have 64GB RAM and 3060 12G VRAM, which quant can I meaningfully run this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07jujg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I have 64GB RAM and 3060 12G VRAM, which quant can I meaningfully run this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n07jujg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751098693,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n025hvx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iansltx_","can_mod_post":false,"created_utc":1751029942,"send_replies":true,"parent_id":"t3_1llndut","score":3,"author_fullname":"t2_tal3nl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"...and now to wait until it shows up in ollama-compatible q4. 64GB unified RAM here so this should perform nicely.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n025hvx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...and now to wait until it shows up in ollama-compatible q4. 64GB unified RAM here so this should perform nicely.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n025hvx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751029942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04set9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mybrandnewaccount95","can_mod_post":false,"created_utc":1751057652,"send_replies":true,"parent_id":"t3_1llndut","score":1,"author_fullname":"t2_2r6yfku9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hopefully that 256k context is legit","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04set9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hopefully that 256k context is legit&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04set9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751057652,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03wsg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"random-tomato","can_mod_post":false,"created_utc":1751048243,"send_replies":true,"parent_id":"t1_n02zm9p","score":3,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Training LLMs from scratch take millions, if not hundreds of millions of dollars, at least if you want good performance. You can try fine-tuning though, it's a lot less expensive: [https://docs.unsloth.ai/](https://docs.unsloth.ai/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03wsg8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Training LLMs from scratch take millions, if not hundreds of millions of dollars, at least if you want good performance. You can try fine-tuning though, it&amp;#39;s a lot less expensive: &lt;a href=\\"https://docs.unsloth.ai/\\"&gt;https://docs.unsloth.ai/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03wsg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751048243,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n02zm9p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"elij7","can_mod_post":false,"created_utc":1751038951,"send_replies":true,"parent_id":"t3_1llndut","score":1,"author_fullname":"t2_kjt3ane","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m new to the whole build your own LLM thing. Would this be a good starting point to build my own model? Better than Mixtral 8x7B?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n02zm9p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m new to the whole build your own LLM thing. Would this be a good starting point to build my own model? Better than Mixtral 8x7B?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n02zm9p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751038951,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n049g6j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mantafloppy","can_mod_post":false,"created_utc":1751051922,"send_replies":true,"parent_id":"t1_n03r1q2","score":6,"author_fullname":"t2_co2hf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think someone \\"pocket dial\\" on reddit :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n049g6j","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think someone &amp;quot;pocket dial&amp;quot; on reddit :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n049g6j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751051922,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n04zgvq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tengo_harambe","can_mod_post":false,"created_utc":1751059859,"send_replies":true,"parent_id":"t1_n03r1q2","score":5,"author_fullname":"t2_sgx7w7mb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"something's off with your chat template bro","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n04zgvq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;something&amp;#39;s off with your chat template bro&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n04zgvq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751059859,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n03r1q2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rdmkyran","can_mod_post":false,"created_utc":1751046627,"send_replies":true,"parent_id":"t3_1llndut","score":-2,"author_fullname":"t2_y4m0d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jjjjjjjjjjjjjjjjjjjjjjjk.jjjjkjjjjjjjjjjj jjjjjjjjjjjjjjj jjjjjjjj njj jjjjjjnjjjjjjjjjjjjjjjjjjn'''''k j j j kkkjnknk nj nnj. j nn n. Nnknkk knk  nk k j n k. K k k n k j knnn k n kn n kn. n n nnnnn un k'''kkkkkkkk''kkkkkkk k nk kk kk'''''kkkk.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03r1q2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jjjjjjjjjjjjjjjjjjjjjjjk.jjjjkjjjjjjjjjjj jjjjjjjjjjjjjjj jjjjjjjj njj jjjjjjnjjjjjjjjjjjjjjjjjjn&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;k j j j kkkjnknk nj nnj. j nn n. Nnknkk knk  nk k j n k. K k k n k j knnn k n kn n kn. n n nnnnn un k&amp;#39;&amp;#39;&amp;#39;kkkkkkkk&amp;#39;&amp;#39;kkkkkkk k nk kk kk&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;kkkk.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03r1q2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751046627,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n018ebu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mxforest","can_mod_post":false,"send_replies":true,"parent_id":"t1_n014yq7","score":21,"author_fullname":"t2_kenmq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I bet 10 cents he doesn't.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n018ebu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I bet 10 cents he doesn&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n018ebu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015047,"author_flair_text":null,"treatment_tags":[],"created_utc":1751015047,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}}],"before":null}},"user_reports":[],"saved":false,"id":"n014yq7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RuthlessCriticismAll","can_mod_post":false,"created_utc":1751013018,"send_replies":false,"parent_id":"t1_n00zx26","score":21,"author_fullname":"t2_7777b0y0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"does he know...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n014yq7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does he know...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n014yq7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751013018,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}}],"before":null}},"user_reports":[],"saved":false,"id":"n00zx26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Alkaided","can_mod_post":false,"created_utc":1751010017,"send_replies":true,"parent_id":"t3_1llndut","score":-14,"author_fullname":"t2_4mwdz9k7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"The first paragraph has a very very strong smell of Chinese…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n00zx26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The first paragraph has a very very strong smell of Chinese…&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n00zx26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751010017,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n013wse","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"created_utc":1751012389,"send_replies":true,"parent_id":"t1_n011t4r","score":14,"author_fullname":"t2_ielo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just like these language models aren’t really “large”?\\n\\n256k is definitely ultra long compared to the typical context that can be run locally… qwen3 is 32k for example. There are some 128k finetunes but 256k is a big improvement over 32k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n013wse","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just like these language models aren’t really “large”?&lt;/p&gt;\\n\\n&lt;p&gt;256k is definitely ultra long compared to the typical context that can be run locally… qwen3 is 32k for example. There are some 128k finetunes but 256k is a big improvement over 32k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n013wse/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751012389,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n03ivsd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bene_42069","can_mod_post":false,"send_replies":true,"parent_id":"t1_n022o6o","score":1,"author_fullname":"t2_9yo3ah1u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What kind of tasks do you work on to need that much?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n03ivsd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What kind of tasks do you work on to need that much?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n03ivsd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751044369,"author_flair_text":null,"treatment_tags":[],"created_utc":1751044369,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n022o6o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"lochyw","can_mod_post":false,"send_replies":true,"parent_id":"t1_n019f0i","score":-6,"author_fullname":"t2_fin6v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's hardly 1-2M","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n022o6o","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s hardly 1-2M&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n022o6o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751028970,"author_flair_text":null,"treatment_tags":[],"created_utc":1751028970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"n019f0i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bene_42069","can_mod_post":false,"created_utc":1751015646,"send_replies":true,"parent_id":"t1_n011t4r","score":11,"author_fullname":"t2_9yo3ah1u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How broken can your standard be? lol. Even o3 is \\"just\\" that much.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n019f0i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How broken can your standard be? lol. Even o3 is &amp;quot;just&amp;quot; that much.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1llndut","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n019f0i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751015646,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n011t4r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"lochyw","can_mod_post":false,"created_utc":1751011140,"send_replies":true,"parent_id":"t3_1llndut","score":-24,"author_fullname":"t2_fin6v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"256k is not ultra long..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n011t4r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;256k is not ultra long..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1llndut/hunyuana13b_released/n011t4r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751011140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1llndut","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-24}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
