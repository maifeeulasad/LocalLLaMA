import{j as e}from"./index-BgwOAK4-.js";import{R as t}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I\'m using a local AI model qwen2.5:14b-instruct running via Ollama, but it doesn\'t automatically call tools follow by my prompt instruction like OpenAI models do.\\n\\nalso i have limited gpu: NVIDIA A10 24gb ram, so I just only use lightweight model\\n\\nHow should I design my prompt to ensure the model understands when and how to trigger tool use properly.\\n\\nAlso im currently using N8N and workflow look like this\\n\\nhttps://preview.redd.it/jzvxl7pn96cf1.png?width=938&amp;format=png&amp;auto=webp&amp;s=1c794dba7d676078e22c02dc0a267ce5eee23838\\n\\nHere is my current prompts:\\n\\nYou are an assistant specialized in SQL reporting and visualization.\\n\\nYou have access to the following tools:\\n\\n\\\\- \\\\`Execute\\\\_sql\\\\_query\\\\`\\n\\n\\\\- \\\\`list\\\\_chart\\\\_available\\\\`\\n\\n\\\\- \\\\`create\\\\_chart\\\\`\\n\\n\\\\## Instructions:\\n\\n1. \\\\*\\\\*If the user asks about anything related to the database, tables, or data\\\\*\\\\*, you must:- Analyze the request.- Formulate an appropriate SQL query.- Then \\\\*\\\\*always use the \\\\`Execute\\\\_sql\\\\_query\\\\` tool\\\\*\\\\* to get the data result.\\n2. \\\\*\\\\*If the user asks to create a chart\\\\*\\\\*, you must:- First, use the \\\\`list\\\\_chart\\\\_available\\\\` tool to get the available chart types.- Then, based on the result and the user’s intent, choose the most appropriate chart type.- Finally, use the \\\\`create\\\\_chart\\\\` tool.-  do not create any link from \\\\`create\\\\_chart\\\\` tool, just show the image\\n\\nNever use \\\\`create\\\\_chart\\\\` directly without first calling \\\\`list\\\\_chart\\\\_available\\\\`.\\n\\n3. In any SQL query you generate, \\\\*\\\\*always include \\\\`LIMIT 20\\\\`\\\\*\\\\*, unless explicitly told otherwise.\\n\\n4. Only call tools when necessary. If the question can be answered without executing a query or generating a chart, respond naturally using your knowledge.\\n\\n4. You are working with the following table(s):\\n\\n\\\\*\\\\*Tables information\\\\*\\\\*:  \\n...","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Ollama calling tools","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"media_metadata":{"jzvxl7pn96cf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":38,"x":108,"u":"https://preview.redd.it/jzvxl7pn96cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6519dcd51005aeba5952281ff3886363a6f9d6c"},{"y":76,"x":216,"u":"https://preview.redd.it/jzvxl7pn96cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0abf01dcd08ed4252808072f4b0419db2a5a603f"},{"y":113,"x":320,"u":"https://preview.redd.it/jzvxl7pn96cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=279fc9fa51385702e0de2c9330884b4a221b9c8d"},{"y":227,"x":640,"u":"https://preview.redd.it/jzvxl7pn96cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=892895841f0f07df2c694f439e145130159a14ab"}],"s":{"y":334,"x":938,"u":"https://preview.redd.it/jzvxl7pn96cf1.png?width=938&amp;format=png&amp;auto=webp&amp;s=1c794dba7d676078e22c02dc0a267ce5eee23838"},"id":"jzvxl7pn96cf1"}},"name":"t3_1lwxrai","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.17,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_efnhbt7w0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752208774,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752208245,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m using a local AI model qwen2.5:14b-instruct running via Ollama, but it doesn&amp;#39;t automatically call tools follow by my prompt instruction like OpenAI models do.&lt;/p&gt;\\n\\n&lt;p&gt;also i have limited gpu: NVIDIA A10 24gb ram, so I just only use lightweight model&lt;/p&gt;\\n\\n&lt;p&gt;How should I design my prompt to ensure the model understands when and how to trigger tool use properly.&lt;/p&gt;\\n\\n&lt;p&gt;Also im currently using N8N and workflow look like this&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/jzvxl7pn96cf1.png?width=938&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c794dba7d676078e22c02dc0a267ce5eee23838\\"&gt;https://preview.redd.it/jzvxl7pn96cf1.png?width=938&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c794dba7d676078e22c02dc0a267ce5eee23838&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Here is my current prompts:&lt;/p&gt;\\n\\n&lt;p&gt;You are an assistant specialized in SQL reporting and visualization.&lt;/p&gt;\\n\\n&lt;p&gt;You have access to the following tools:&lt;/p&gt;\\n\\n&lt;p&gt;- `Execute_sql_query`&lt;/p&gt;\\n\\n&lt;p&gt;- `list_chart_available`&lt;/p&gt;\\n\\n&lt;p&gt;- `create_chart`&lt;/p&gt;\\n\\n&lt;p&gt;## Instructions:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;**If the user asks about anything related to the database, tables, or data**, you must:- Analyze the request.- Formulate an appropriate SQL query.- Then **always use the `Execute_sql_query` tool** to get the data result.&lt;/li&gt;\\n&lt;li&gt;**If the user asks to create a chart**, you must:- First, use the `list_chart_available` tool to get the available chart types.- Then, based on the result and the user’s intent, choose the most appropriate chart type.- Finally, use the `create_chart` tool.-  do not create any link from `create_chart` tool, just show the image&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Never use `create_chart` directly without first calling `list_chart_available`.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;In any SQL query you generate, **always include `LIMIT 20`**, unless explicitly told otherwise.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Only call tools when necessary. If the question can be answered without executing a query or generating a chart, respond naturally using your knowledge.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;You are working with the following table(s):&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;**Tables information**:&lt;br/&gt;\\n...&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lwxrai","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Practical-Corgi-9906","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/","subreddit_subscribers":497503,"created_utc":1752208245,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2htmkt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"croninsiglos","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2hte9y","score":5,"author_fullname":"t2_v7qje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, not really. Look at the raw response (you\'d have to manually parse it out of the content)\\n\\nhttps://pastebin.com/LiMHDqfi\\n\\ntry that on the terminal with both qwen3:14b and then again with qwen2.5:14b-instruct\\n\\nOnly qwen3:14b will have the explicit tool call in the response just like openai function calling. Even qwen3:06b will call the tool correctly in that example. \\n\\nTo get it working in qwen2.5 you\'d probably have the fix the chat template so the tool call is in the expected format.\\n\\nedit: fixed the link","edited":1752209485,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2htmkt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, not really. Look at the raw response (you&amp;#39;d have to manually parse it out of the content)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://pastebin.com/LiMHDqfi\\"&gt;https://pastebin.com/LiMHDqfi&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;try that on the terminal with both qwen3:14b and then again with qwen2.5:14b-instruct&lt;/p&gt;\\n\\n&lt;p&gt;Only qwen3:14b will have the explicit tool call in the response just like openai function calling. Even qwen3:06b will call the tool correctly in that example. &lt;/p&gt;\\n\\n&lt;p&gt;To get it working in qwen2.5 you&amp;#39;d probably have the fix the chat template so the tool call is in the expected format.&lt;/p&gt;\\n\\n&lt;p&gt;edit: fixed the link&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwxrai","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2htmkt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752208733,"author_flair_text":null,"treatment_tags":[],"created_utc":1752208733,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2hte9y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Practical-Corgi-9906","can_mod_post":false,"created_utc":1752208630,"send_replies":true,"parent_id":"t1_n2ht8oq","score":1,"author_fullname":"t2_efnhbt7w0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" qwen2.5:14b-instruct also support tools","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hte9y","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt; qwen2.5:14b-instruct also support tools&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwxrai","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2hte9y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752208630,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ht8oq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"croninsiglos","can_mod_post":false,"created_utc":1752208561,"send_replies":true,"parent_id":"t3_1lwxrai","score":2,"author_fullname":"t2_v7qje","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use a model that supports tools... Try qwen3:14b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ht8oq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use a model that supports tools... Try qwen3:14b&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2ht8oq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752208561,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwxrai","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2husay","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Practical-Corgi-9906","can_mod_post":false,"created_utc":1752209254,"send_replies":true,"parent_id":"t1_n2hu8of","score":1,"author_fullname":"t2_efnhbt7w0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i mean my model calling tools is weird, not like the openai , sometime it\'s call right tool, sometime with the same question, it\'s not calling tool.  So i think the problem belongs to prompts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2husay","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i mean my model calling tools is weird, not like the openai , sometime it&amp;#39;s call right tool, sometime with the same question, it&amp;#39;s not calling tool.  So i think the problem belongs to prompts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwxrai","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2husay/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752209254,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2hu8of","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BrilliantAudience497","can_mod_post":false,"created_utc":1752209006,"send_replies":true,"parent_id":"t3_1lwxrai","score":3,"author_fullname":"t2_1p34vnz066","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its probably also worth trying some different inference backends. I spent a long time debugging super unreliable tool calling on ollama before finally trying some other backends (llama.cpp and vllm), and its turns out the problem was something with ollama.\\n\\n\\nAt the very least I\'d recommend pulling down llama.cpp and see if swapping to that fixes the tool calling, if there are no other problems with your setup.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hu8of","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its probably also worth trying some different inference backends. I spent a long time debugging super unreliable tool calling on ollama before finally trying some other backends (llama.cpp and vllm), and its turns out the problem was something with ollama.&lt;/p&gt;\\n\\n&lt;p&gt;At the very least I&amp;#39;d recommend pulling down llama.cpp and see if swapping to that fixes the tool calling, if there are no other problems with your setup.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2hu8of/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752209006,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwxrai","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i4s3o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752214125,"send_replies":true,"parent_id":"t3_1lwxrai","score":1,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is your json payload look? like you need to include the tools in the payload in order for the model to output the appropriate Json object. Your script will need to then parse the response to activate the tool.\\n\\nYou can read about it here.\\nhttps://ollama.com/blog/tool-support","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i4s3o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is your json payload look? like you need to include the tools in the payload in order for the model to output the appropriate Json object. Your script will need to then parse the response to activate the tool.&lt;/p&gt;\\n\\n&lt;p&gt;You can read about it here.\\n&lt;a href=\\"https://ollama.com/blog/tool-support\\"&gt;https://ollama.com/blog/tool-support&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwxrai/ollama_calling_tools/n2i4s3o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752214125,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwxrai","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),r=()=>e.jsx(t,{data:l});export{r as default};
