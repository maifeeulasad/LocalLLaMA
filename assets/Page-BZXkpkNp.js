import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm writing a program that compares two text sections. Sometimes the OCR screws up so I can't just do a A==B comparison.\\n\\nFor instance, I'd like the LLM to compare\\n\\n\\"Further\\" == \\"Father\\" and say \\"Same\\".\\n\\nBut \\"15\\" == \\"30\\" and say \\"Different\\"\\n\\nI know the beefier ChatGPT models can do this, but I need to run this locally.\\n\\nMy plan is to run the prompt ~3-5 times, using ~3 different models, and if a consensus is met, using that consensus output. \\n\\nHistorically and currently, I've had trouble getting ~7B models to follow instructions like this. I may be able to get up to ~70B models, and maybe maybe 400B models if I can get cost approval. But for now, I'm mostly looking for 'prompt engineering'.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What kind of prompts *Always* give a 1 word response?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lqphqd","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.36,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_u49aibv3e","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751548996,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m writing a program that compares two text sections. Sometimes the OCR screws up so I can&amp;#39;t just do a A==B comparison.&lt;/p&gt;\\n\\n&lt;p&gt;For instance, I&amp;#39;d like the LLM to compare&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Further&amp;quot; == &amp;quot;Father&amp;quot; and say &amp;quot;Same&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;But &amp;quot;15&amp;quot; == &amp;quot;30&amp;quot; and say &amp;quot;Different&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;I know the beefier ChatGPT models can do this, but I need to run this locally.&lt;/p&gt;\\n\\n&lt;p&gt;My plan is to run the prompt ~3-5 times, using ~3 different models, and if a consensus is met, using that consensus output. &lt;/p&gt;\\n\\n&lt;p&gt;Historically and currently, I&amp;#39;ve had trouble getting ~7B models to follow instructions like this. I may be able to get up to ~70B models, and maybe maybe 400B models if I can get cost approval. But for now, I&amp;#39;m mostly looking for &amp;#39;prompt engineering&amp;#39;.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lqphqd","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Waterbottles_solve","discussion_type":null,"num_comments":26,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/","subreddit_subscribers":494198,"created_utc":1751548996,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14mtlh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mad_Undead","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14kwd4","score":13,"author_fullname":"t2_1pv1zl00","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Seems like simple type check followed by any distance metric with a threshold will work for your examples. But if you want to use LLM - use structured output with boolean type..","edited":1751552429,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n14mtlh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems like simple type check followed by any distance metric with a threshold will work for your examples. But if you want to use LLM - use structured output with boolean type..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14mtlh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751551317,"author_flair_text":null,"treatment_tags":[],"created_utc":1751551317,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n18it6u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14kwd4","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://en.wikipedia.org/wiki/Levenshtein_distance","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n18it6u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/Levenshtein_distance\\"&gt;https://en.wikipedia.org/wiki/Levenshtein_distance&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n18it6u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751594851,"author_flair_text":null,"treatment_tags":[],"created_utc":1751594851,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n14kwd4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Waterbottles_solve","can_mod_post":false,"created_utc":1751550726,"send_replies":true,"parent_id":"t1_n14h02o","score":-2,"author_fullname":"t2_u49aibv3e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What then?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14kwd4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What then?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14kwd4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550726,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n14h02o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KriosXVII","can_mod_post":false,"created_utc":1751549476,"send_replies":true,"parent_id":"t3_1lqphqd","score":18,"author_fullname":"t2_l8llqff","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You don't need a LLM for this. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14h02o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don&amp;#39;t need a LLM for this. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14h02o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549476,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14necy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Noiselexer","can_mod_post":false,"created_utc":1751551495,"send_replies":true,"parent_id":"t3_1lqphqd","score":12,"author_fullname":"t2_n4xpz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We been doing spellchecks for 30 years you would think we don't need llms for this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14necy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We been doing spellchecks for 30 years you would think we don&amp;#39;t need llms for this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14necy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751551495,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1629x1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Thing797","can_mod_post":false,"send_replies":true,"parent_id":"t1_n161f8t","score":2,"author_fullname":"t2_1anh6qztwr","approved_by":null,"mod_note":null,"all_awardings":[],"body":"1. If it works, it works.  \\n2. LLMs are a type of machine learning model  \\n3. This isn't inherently a machine learning task. You can do this with fuzzy matching (https://pypi.org/project/thefuzz/) for example.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1629x1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;If it works, it works.&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;LLMs are a type of machine learning model&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;This isn&amp;#39;t inherently a machine learning task. You can do this with fuzzy matching (&lt;a href=\\"https://pypi.org/project/thefuzz/\\"&gt;https://pypi.org/project/thefuzz/&lt;/a&gt;) for example.&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lqphqd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n1629x1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751565930,"author_flair_text":null,"treatment_tags":[],"created_utc":1751565930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n161f8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fit-Produce420","can_mod_post":false,"send_replies":true,"parent_id":"t1_n15l8ya","score":1,"author_fullname":"t2_tewf9bdwg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why use a language model for a machine learning task?","edited":false,"author_flair_css_class":null,"name":"t1_n161f8t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why use a language model for a machine learning task?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lqphqd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n161f8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751565684,"author_flair_text":null,"collapsed":false,"created_utc":1751565684,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n15l8ya","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Thing797","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14w860","score":1,"author_fullname":"t2_1anh6qztwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, if I understand the task right it's a binary classification. You could solve it a bunch of ways (even without any ML) but OP is trying with an LLM in the original post.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n15l8ya","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, if I understand the task right it&amp;#39;s a binary classification. You could solve it a bunch of ways (even without any ML) but OP is trying with an LLM in the original post.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n15l8ya/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751561195,"author_flair_text":null,"treatment_tags":[],"created_utc":1751561195,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n14w860","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cMonkiii","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14jan3","score":2,"author_fullname":"t2_110jlz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This just seems like a classification issue then? Is this for LLMs specially, or just a machine learning task","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n14w860","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This just seems like a classification issue then? Is this for LLMs specially, or just a machine learning task&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14w860/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751554111,"author_flair_text":null,"treatment_tags":[],"created_utc":1751554111,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n14jan3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Thing797","can_mod_post":false,"created_utc":1751550221,"send_replies":true,"parent_id":"t1_n14h0go","score":1,"author_fullname":"t2_1anh6qztwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OCR = Optical Character Recognition.\\n\\nIt's looking at an image and trying to pull out all the text, it's not about the words being semantically close, they are visually close.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14jan3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OCR = Optical Character Recognition.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s looking at an image and trying to pull out all the text, it&amp;#39;s not about the words being semantically close, they are visually close.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14jan3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550221,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n162clh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"send_replies":true,"parent_id":"t1_n161lj4","score":2,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ocr is hard man :sob:","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n162clh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ocr is hard man :sob:&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n162clh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751565952,"author_flair_text":null,"treatment_tags":[],"created_utc":1751565952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n161lj4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fit-Produce420","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14kukf","score":0,"author_fullname":"t2_tewf9bdwg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If the system you're using were smart enough correct mistakes couldn't you just use a system smart enough to avoid mistakes?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n161lj4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the system you&amp;#39;re using were smart enough correct mistakes couldn&amp;#39;t you just use a system smart enough to avoid mistakes?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n161lj4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751565734,"author_flair_text":null,"treatment_tags":[],"created_utc":1751565734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n14kukf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Waterbottles_solve","can_mod_post":false,"created_utc":1751550711,"send_replies":true,"parent_id":"t1_n14h0go","score":1,"author_fullname":"t2_u49aibv3e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its OCR mistakes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14kukf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its OCR mistakes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14kukf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550711,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n14h0go","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"created_utc":1751549480,"send_replies":true,"parent_id":"t3_1lqphqd","score":8,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wait. What? What?!\\n\\nHow is ”Further” == “Father”?\\n\\nI could get ”Further” ~ “Father” and it return True… or ”Further” vs “Father” returning “Similar”… what am I missing? What English accent has these as the same word?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14h0go","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait. What? What?!&lt;/p&gt;\\n\\n&lt;p&gt;How is ”Further” == “Father”?&lt;/p&gt;\\n\\n&lt;p&gt;I could get ”Further” ~ “Father” and it return True… or ”Further” vs “Father” returning “Similar”… what am I missing? What English accent has these as the same word?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14h0go/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549480,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14gf3s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Source-9920","can_mod_post":false,"created_utc":1751549285,"send_replies":true,"parent_id":"t3_1lqphqd","score":5,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Few shot examples in the prompt itself","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14gf3s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Few shot examples in the prompt itself&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14gf3s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549285,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n156ln2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1751557037,"send_replies":true,"parent_id":"t3_1lqphqd","score":3,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LLMs are the new hammers, and everything is now a nail.\\n\\nThis is something that's literally been solved for half a century!!!\\n\\nAs has been suggested, a basic distance metric will work wonderfully with this, is super fast and efficient, and a naive implementation can be done in a couple dozen lines of code if you don't want to use a ready made library.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n156ln2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LLMs are the new hammers, and everything is now a nail.&lt;/p&gt;\\n\\n&lt;p&gt;This is something that&amp;#39;s literally been solved for half a century!!!&lt;/p&gt;\\n\\n&lt;p&gt;As has been suggested, a basic distance metric will work wonderfully with this, is super fast and efficient, and a naive implementation can be done in a couple dozen lines of code if you don&amp;#39;t want to use a ready made library.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n156ln2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751557037,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14gbv5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cybran3","can_mod_post":false,"created_utc":1751549255,"send_replies":true,"parent_id":"t3_1lqphqd","score":7,"author_fullname":"t2_41gmkw5z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why don’t you ask one of the big models to give you a prompt for this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14gbv5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why don’t you ask one of the big models to give you a prompt for this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14gbv5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549255,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14prqj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Thing797","can_mod_post":false,"send_replies":true,"parent_id":"t1_n14lc2t","score":2,"author_fullname":"t2_1anh6qztwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fuzzy matching (https://pypi.org/project/thefuzz/) with a threshold may also work for this if you can install pip packages.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n14prqj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuzzy matching (&lt;a href=\\"https://pypi.org/project/thefuzz/\\"&gt;https://pypi.org/project/thefuzz/&lt;/a&gt;) with a threshold may also work for this if you can install pip packages.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14prqj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751552216,"author_flair_text":null,"treatment_tags":[],"created_utc":1751552216,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n14lc2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Waterbottles_solve","can_mod_post":false,"created_utc":1751550860,"send_replies":true,"parent_id":"t1_n14hirm","score":1,"author_fullname":"t2_u49aibv3e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you. I don't believe I'll be able to use that 'off the shelf', due to not having local admin or WSL, but there is def something useful here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14lc2t","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. I don&amp;#39;t believe I&amp;#39;ll be able to use that &amp;#39;off the shelf&amp;#39;, due to not having local admin or WSL, but there is def something useful here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqphqd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14lc2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550860,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n14hirm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Thing797","can_mod_post":false,"created_utc":1751549645,"send_replies":true,"parent_id":"t3_1lqphqd","score":3,"author_fullname":"t2_1anh6qztwr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use guided choice option in vllm for this, see here : [https://docs.vllm.ai/en/latest/features/structured\\\\_outputs.html#online-serving-openai-api](https://docs.vllm.ai/en/latest/features/structured_outputs.html#online-serving-openai-api)\\n\\nThis should work with any model. The model produces logits for all possible tokens, and those can be subset to just ones you want, so you will guaranteed only ever get one of the ones for your classification.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14hirm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use guided choice option in vllm for this, see here : &lt;a href=\\"https://docs.vllm.ai/en/latest/features/structured_outputs.html#online-serving-openai-api\\"&gt;https://docs.vllm.ai/en/latest/features/structured_outputs.html#online-serving-openai-api&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This should work with any model. The model produces logits for all possible tokens, and those can be subset to just ones you want, so you will guaranteed only ever get one of the ones for your classification.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14hirm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549645,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1535k6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AutomataManifold","can_mod_post":false,"created_utc":1751556071,"send_replies":true,"parent_id":"t3_1lqphqd","score":2,"author_fullname":"t2_bfs5bk7y8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not clear on your task; you want similar words to be measured at the same but similar-but-distinct numbers to be read as different?\\n\\nYou've got some options, none of which really require a big model:\\n\\n* Use structured prompting (via Guidance, Instructor, etc.) to confine the logits to output \\"True\\" and \\"False\\" (easy, expensive)\\n* Graft a classifier head onto an existing model, training it on your dataset to distinguish between your outcomes and output true/false instead of next token. You can use something like NoisOCR to generate synthetic data pairs to train on. (hard, needs training)\\n* Use an NLP library (such as NLTK) to split your text into words and then calculate the Levenshtein distance between the words in the two texts, skipping over the numbers. Requires the words to line up but would be very fast in comparison to any LLM. (medium, need to write the code)\\n* Use an existing OCR cleaning library such as OCRfixr. (easy if it is sufficient for your use case)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1535k6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not clear on your task; you want similar words to be measured at the same but similar-but-distinct numbers to be read as different?&lt;/p&gt;\\n\\n&lt;p&gt;You&amp;#39;ve got some options, none of which really require a big model:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Use structured prompting (via Guidance, Instructor, etc.) to confine the logits to output &amp;quot;True&amp;quot; and &amp;quot;False&amp;quot; (easy, expensive)&lt;/li&gt;\\n&lt;li&gt;Graft a classifier head onto an existing model, training it on your dataset to distinguish between your outcomes and output true/false instead of next token. You can use something like NoisOCR to generate synthetic data pairs to train on. (hard, needs training)&lt;/li&gt;\\n&lt;li&gt;Use an NLP library (such as NLTK) to split your text into words and then calculate the Levenshtein distance between the words in the two texts, skipping over the numbers. Requires the words to line up but would be very fast in comparison to any LLM. (medium, need to write the code)&lt;/li&gt;\\n&lt;li&gt;Use an existing OCR cleaning library such as OCRfixr. (easy if it is sufficient for your use case)&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n1535k6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751556071,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14l7in","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1751550821,"send_replies":true,"parent_id":"t3_1lqphqd","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"imo it would be better to instruct the model to give an explanation and then answer same/not same (or whatever binary answer you need) in some way that you can easily paese. there are many options, you could simply instruct it to place the final answer in \\"/boxed{...}\\" or use a structured output.\\n\\nas someone said there are ways to ensure the output token is one of those you accept (ie, vLLM has this option)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14l7in","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;imo it would be better to instruct the model to give an explanation and then answer same/not same (or whatever binary answer you need) in some way that you can easily paese. there are many options, you could simply instruct it to place the final answer in &amp;quot;/boxed{...}&amp;quot; or use a structured output.&lt;/p&gt;\\n\\n&lt;p&gt;as someone said there are ways to ensure the output token is one of those you accept (ie, vLLM has this option)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14l7in/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550821,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14m63n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rickyhatespeas","can_mod_post":false,"created_utc":1751551116,"send_replies":true,"parent_id":"t3_1lqphqd","score":1,"author_fullname":"t2_bfw4k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you not just set a max tokens to however many your responses are? Like 15? That's what I do when I use local models as judges like that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14m63n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you not just set a max tokens to however many your responses are? Like 15? That&amp;#39;s what I do when I use local models as judges like that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14m63n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751551116,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14yaq7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Demonicated","can_mod_post":false,"created_utc":1751554700,"send_replies":true,"parent_id":"t3_1lqphqd","score":1,"author_fullname":"t2_98vsi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had this issue. You can solve it by having two steps. One pass for analysis then send it back to a model and all it to reduce it to one word A or B. Also use a non chatty model for the second pass.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14yaq7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had this issue. You can solve it by having two steps. One pass for analysis then send it back to a model and all it to reduce it to one word A or B. Also use a non chatty model for the second pass.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n14yaq7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751554700,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17nbrs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hanthunius","can_mod_post":false,"created_utc":1751583389,"send_replies":true,"parent_id":"t3_1lqphqd","score":1,"author_fullname":"t2_d2gb9jhgg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this looks like a kill-a-fly-with-a-bazooka solution. There's a bunch of textual comparing methods that you could use instead of an LLM. Look up \\"Levenshtein distance\\" as a starter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17nbrs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this looks like a kill-a-fly-with-a-bazooka solution. There&amp;#39;s a bunch of textual comparing methods that you could use instead of an LLM. Look up &amp;quot;Levenshtein distance&amp;quot; as a starter.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n17nbrs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751583389,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1502y8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"itch-","can_mod_post":false,"created_utc":1751555207,"send_replies":true,"parent_id":"t3_1lqphqd","score":1,"author_fullname":"t2_110ui9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't it generally a bad idea to try to do this, especially with a small model? You're asking for all computation to have already reached the correct conclusion on outputting the first token. And all the following tokens are just completing the word. Small wonder then that the large models have less trouble.\\n\\nIMO you prompt it to give the answer in a formatted way like json, and don't mind what else it adds. Then remove all of the characters outside the {} part of the answer, and parse the json.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1502y8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t it generally a bad idea to try to do this, especially with a small model? You&amp;#39;re asking for all computation to have already reached the correct conclusion on outputting the first token. And all the following tokens are just completing the word. Small wonder then that the large models have less trouble.&lt;/p&gt;\\n\\n&lt;p&gt;IMO you prompt it to give the answer in a formatted way like json, and don&amp;#39;t mind what else it adds. Then remove all of the characters outside the {} part of the answer, and parse the json.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqphqd/what_kind_of_prompts_always_give_a_1_word_response/n1502y8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751555207,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqphqd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
