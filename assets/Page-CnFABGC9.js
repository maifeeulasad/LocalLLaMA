import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"AI-generated content is easy to spot these days:  \\n  \\n– The em dashes  \\n– The “It’s not X, but Y”   \\n– Snappy one-line sentences  \\n– Lots of emojis  \\n...\\n\\nMany of us use AI to edit text, build chatbots, write reports...  \\nWhat technique do you use to make sure the output isn't generic AI slop?\\n\\nDo you use specific prompts? Few-shot examples? Guardrails? Certain models? Fine-tuning?\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How do you keep AI outputs from sounding AI?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m84s47","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.72,"author_flair_background_color":null,"subreddit_type":"public","ups":20,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_376cy","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":20,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753364580,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;AI-generated content is easy to spot these days:  &lt;/p&gt;\\n\\n&lt;p&gt;– The em dashes&lt;br/&gt;\\n– The “It’s not X, but Y”&lt;br/&gt;\\n– Snappy one-line sentences&lt;br/&gt;\\n– Lots of emojis&lt;br/&gt;\\n...&lt;/p&gt;\\n\\n&lt;p&gt;Many of us use AI to edit text, build chatbots, write reports...&lt;br/&gt;\\nWhat technique do you use to make sure the output isn&amp;#39;t generic AI slop?&lt;/p&gt;\\n\\n&lt;p&gt;Do you use specific prompts? Few-shot examples? Guardrails? Certain models? Fine-tuning?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m84s47","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"resiros","discussion_type":null,"num_comments":17,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/","subreddit_subscribers":504023,"created_utc":1753364580,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4xv7mj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GortKlaatu_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4wuut6","score":3,"author_fullname":"t2_ixeagk4w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not when I tried it \\\\[ChatGPT (o3)\\\\], but I was also very explicit about how I communicate: ie: like an engineer, technical, no business/corporate buzz words, concise get to the point.\\n\\nWithout that bit it sounded like a business major fresh out of college or a sales person with crap words like \\"synergy\\". It was a lot of words without actually \\"saying\\" anything.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4xv7mj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not when I tried it [ChatGPT (o3)], but I was also very explicit about how I communicate: ie: like an engineer, technical, no business/corporate buzz words, concise get to the point.&lt;/p&gt;\\n\\n&lt;p&gt;Without that bit it sounded like a business major fresh out of college or a sales person with crap words like &amp;quot;synergy&amp;quot;. It was a lot of words without actually &amp;quot;saying&amp;quot; anything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4xv7mj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753379496,"author_flair_text":null,"treatment_tags":[],"created_utc":1753379496,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4wuut6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4wtj6t","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a pretty practical way of doing things. Does it have cases where it slips up and stuff? I tried doing that with ChatGPT but it couldn't do it","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4wuut6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a pretty practical way of doing things. Does it have cases where it slips up and stuff? I tried doing that with ChatGPT but it couldn&amp;#39;t do it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wuut6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753369634,"author_flair_text":null,"treatment_tags":[],"created_utc":1753369634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4wtj6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GortKlaatu_","can_mod_post":false,"created_utc":1753369266,"send_replies":true,"parent_id":"t1_n4wjisu","score":6,"author_fullname":"t2_ixeagk4w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tell it the kind of person I am and to use my persona to rewrite the content in \\"my voice\\". In the latest frontier models, I've had this work extremely well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wtj6t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tell it the kind of person I am and to use my persona to rewrite the content in &amp;quot;my voice&amp;quot;. In the latest frontier models, I&amp;#39;ve had this work extremely well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wtj6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753369266,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4wjisu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1753366421,"send_replies":true,"parent_id":"t3_1m84s47","score":25,"author_fullname":"t2_cw6v7ot8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just rewrite the entire thing. I try to make it match my own grammar standards.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wjisu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just rewrite the entire thing. I try to make it match my own grammar standards.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wjisu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753366421,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4wx3wf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlbanySteamedHams","can_mod_post":false,"created_utc":1753370258,"send_replies":true,"parent_id":"t3_1m84s47","score":5,"author_fullname":"t2_znbcg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In context with its own output I’ve given it example text that I would like it to mimic. Then ask it to do a a forensic analysis of the two writing styles to compare contrast them. Something like this:\\n\\nhttps://en.wikipedia.org/wiki/Stylometry?wprov=sfti1\\n\\nThen I have it develop a set of guidelines for writing to avoid its default writing mode and adopt the target one. Those guidelines can be fed into a new prompt to constrain output or used to drive a round of critical reflection to edit previously generated text. \\n\\nWith large samples of default ai slop and ideal target language, the “contrasted stylometry” guidelines can get you pretty far. \\n\\nNote: I’ve used this with flagship models. For smaller local models you may want to use a flagship to develop the guidelines for the local model to use. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wx3wf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In context with its own output I’ve given it example text that I would like it to mimic. Then ask it to do a a forensic analysis of the two writing styles to compare contrast them. Something like this:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/Stylometry?wprov=sfti1\\"&gt;https://en.wikipedia.org/wiki/Stylometry?wprov=sfti1&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Then I have it develop a set of guidelines for writing to avoid its default writing mode and adopt the target one. Those guidelines can be fed into a new prompt to constrain output or used to drive a round of critical reflection to edit previously generated text. &lt;/p&gt;\\n\\n&lt;p&gt;With large samples of default ai slop and ideal target language, the “contrasted stylometry” guidelines can get you pretty far. &lt;/p&gt;\\n\\n&lt;p&gt;Note: I’ve used this with flagship models. For smaller local models you may want to use a flagship to develop the guidelines for the local model to use. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wx3wf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753370258,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4yg2af","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"resiros","can_mod_post":false,"created_utc":1753385404,"send_replies":true,"parent_id":"t1_n4y05nm","score":2,"author_fullname":"t2_376cy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the logit bias is a great idea!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4yg2af","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the logit bias is a great idea!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4yg2af/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753385404,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4y05nm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1753380869,"send_replies":true,"parent_id":"t3_1m84s47","score":4,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A few things:\\n\\n* I pass llama-cli a grammar which forces it to infer only ASCII, which eliminates emojis and unicode.\\n\\n* Sometimes a system prompt can go a long way.  I totally eliminated Big-Tiger-Gemma-27B-v3 positivity with the system prompt: \\n\\n&gt; You are a clinical, erudite assistant.  Your tone is flat and expressionless. You avoid unnecessary chatter, warnings, or disclaimers.  Never use the term \\"delve\\".\\n\\n* Adding writing samples to the prompt can go a long way to changing the tone of inference output.  I added 1624 words of writing examples from Marsha Wells' Murderbot Diaries books to my murderbot-story generator, and it totally transformed the tone of its prose, eliminating many (but not all) GPTisms (this is with Gemma3-27B).\\n\\n* None of the above techniques prevented Gemma3-27B from overusing ellipses, so I eliminated them entirely by passing llama.cpp logit-bias parameters setting negative-infinity bias for all tokens in its vocabulary which contain ellipses (which turned out to be a lot of them, not even counting tokens obviously for filepaths):\\n\\n&gt; --logit-bias 92541-inf --logit-bias 229389-inf --logit-bias 856-inf --logit-bias 1390-inf --logit-bias 2006-inf --logit-bias 2728-inf --logit-bias 3729-inf --logit-bias 41256-inf --logit-bias 72741-inf --logit-bias 73660-inf --logit-bias 84125-inf --logit-bias 93601-inf --logit-bias 100111-inf --logit-bias 95619-inf --logit-bias 93601-inf --logit-bias 84125-inf --logit-bias 73660-inf --logit-bias 72741-inf --logit-bias 72831-inf --logit-bias 95619-inf\\n\\nObviously that will have to be tailored to the vocabulary of whatever model you're using.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4y05nm","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A few things:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;I pass llama-cli a grammar which forces it to infer only ASCII, which eliminates emojis and unicode.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Sometimes a system prompt can go a long way.  I totally eliminated Big-Tiger-Gemma-27B-v3 positivity with the system prompt: &lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;You are a clinical, erudite assistant.  Your tone is flat and expressionless. You avoid unnecessary chatter, warnings, or disclaimers.  Never use the term &amp;quot;delve&amp;quot;.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;Adding writing samples to the prompt can go a long way to changing the tone of inference output.  I added 1624 words of writing examples from Marsha Wells&amp;#39; Murderbot Diaries books to my murderbot-story generator, and it totally transformed the tone of its prose, eliminating many (but not all) GPTisms (this is with Gemma3-27B).&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;None of the above techniques prevented Gemma3-27B from overusing ellipses, so I eliminated them entirely by passing llama.cpp logit-bias parameters setting negative-infinity bias for all tokens in its vocabulary which contain ellipses (which turned out to be a lot of them, not even counting tokens obviously for filepaths):&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;--logit-bias 92541-inf --logit-bias 229389-inf --logit-bias 856-inf --logit-bias 1390-inf --logit-bias 2006-inf --logit-bias 2728-inf --logit-bias 3729-inf --logit-bias 41256-inf --logit-bias 72741-inf --logit-bias 73660-inf --logit-bias 84125-inf --logit-bias 93601-inf --logit-bias 100111-inf --logit-bias 95619-inf --logit-bias 93601-inf --logit-bias 84125-inf --logit-bias 73660-inf --logit-bias 72741-inf --logit-bias 72831-inf --logit-bias 95619-inf&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Obviously that will have to be tailored to the vocabulary of whatever model you&amp;#39;re using.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4y05nm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753380869,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4wlr0t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1753367067,"send_replies":true,"parent_id":"t3_1m84s47","score":7,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Learn how to articulate the style you want and the things you want to avoid, and have both as part of your prompt. Every time I see something I don't like, I add it to my prompt template. Works for me even with 7-8B models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wlr0t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Learn how to articulate the style you want and the things you want to avoid, and have both as part of your prompt. Every time I see something I don&amp;#39;t like, I add it to my prompt template. Works for me even with 7-8B models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wlr0t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753367067,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4xjr6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"llmentry","can_mod_post":false,"created_utc":1753376449,"send_replies":true,"parent_id":"t3_1m84s47","score":4,"author_fullname":"t2_1lufy6yx6z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A few suggestions:\\n\\nUse a good system prompt to establish some ground rules and the way you write.  If you can give examples in context, that would be useful.  (I'd avoid examples that accidentally provide unhelpful, different context to the document you're working on).\\n\\nIf the document is important, ask for some brief dot point ideas, and then write out your own response from scratch using the points as a rough guide.  Your writing will always sound the most like you :)\\n\\nIf it's not that important, then explicitly push the model away from lists, headings, em-dashes, delves, and anything that smells of LLM in your system prompt.  And then view the document as a draft given to you by an assistant.  Edit the crap out of it, improve it and make it your own.  \\n\\nNo matter what approach you take, you *always* have to edit.  Quite apart from matching your writing style, some of what the model writes will likely be erroneous and will need correcting anyway.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4xjr6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A few suggestions:&lt;/p&gt;\\n\\n&lt;p&gt;Use a good system prompt to establish some ground rules and the way you write.  If you can give examples in context, that would be useful.  (I&amp;#39;d avoid examples that accidentally provide unhelpful, different context to the document you&amp;#39;re working on).&lt;/p&gt;\\n\\n&lt;p&gt;If the document is important, ask for some brief dot point ideas, and then write out your own response from scratch using the points as a rough guide.  Your writing will always sound the most like you :)&lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s not that important, then explicitly push the model away from lists, headings, em-dashes, delves, and anything that smells of LLM in your system prompt.  And then view the document as a draft given to you by an assistant.  Edit the crap out of it, improve it and make it your own.  &lt;/p&gt;\\n\\n&lt;p&gt;No matter what approach you take, you &lt;em&gt;always&lt;/em&gt; have to edit.  Quite apart from matching your writing style, some of what the model writes will likely be erroneous and will need correcting anyway.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4xjr6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753376449,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4wlm3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UBIAI","can_mod_post":false,"created_utc":1753367026,"send_replies":true,"parent_id":"t3_1m84s47","score":3,"author_fullname":"t2_32tnavmg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s getting easier to spot AI-generated content, and you’ve identified the main telltale signs. I think the way to get around this is to fine-tune your model (using LoRa technique) on the type of content you want it to produce. This way, it learns to replicate your style, voice, and tone, and it can produce content that’s much more natural and human-like.\\n\\nIf you’re looking for a step-by-step approach, check out this guide ( [https://ubiai.gitbook.io/llm-guide](https://ubiai.gitbook.io/llm-guide) ). It has some great insights. It covers everything from the data you’ll need to the different training methods.\\n\\nAnd this blog post: [https://ubiai.tools/how-to-fine-tune-llms-to-transform-your-business/](https://ubiai.tools/how-to-fine-tune-llms-to-transform-your-business/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wlm3g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s getting easier to spot AI-generated content, and you’ve identified the main telltale signs. I think the way to get around this is to fine-tune your model (using LoRa technique) on the type of content you want it to produce. This way, it learns to replicate your style, voice, and tone, and it can produce content that’s much more natural and human-like.&lt;/p&gt;\\n\\n&lt;p&gt;If you’re looking for a step-by-step approach, check out this guide ( &lt;a href=\\"https://ubiai.gitbook.io/llm-guide\\"&gt;https://ubiai.gitbook.io/llm-guide&lt;/a&gt; ). It has some great insights. It covers everything from the data you’ll need to the different training methods.&lt;/p&gt;\\n\\n&lt;p&gt;And this blog post: &lt;a href=\\"https://ubiai.tools/how-to-fine-tune-llms-to-transform-your-business/\\"&gt;https://ubiai.tools/how-to-fine-tune-llms-to-transform-your-business/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wlm3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753367026,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4wqh4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harlekinrains","can_mod_post":false,"created_utc":1753368417,"send_replies":true,"parent_id":"t1_n4wpla4","score":2,"author_fullname":"t2_4296b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also, if you are a student doing homework, do your homework.\\n\\nBut also - kimi.com K (maybe 2 based, maybe not) \\"research\\" functionality and lechats reasoning functionality are great at writing below university class research papers. ;)\\n\\nAnd they are free. Dont overlook them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wqh4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also, if you are a student doing homework, do your homework.&lt;/p&gt;\\n\\n&lt;p&gt;But also - kimi.com K (maybe 2 based, maybe not) &amp;quot;research&amp;quot; functionality and lechats reasoning functionality are great at writing below university class research papers. ;)&lt;/p&gt;\\n\\n&lt;p&gt;And they are free. Dont overlook them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wqh4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753368417,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4wpla4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harlekinrains","can_mod_post":false,"created_utc":1753368171,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"author_fullname":"t2_4296b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You could try filtering it through: Glm4 32B (I only used it through openrouter so far).\\n\\nJust make up a prompt that explains what you want to do.\\n\\nIt is one of the most \\"natural sounding\\" LLM models - at least in german. :)\\n\\nSee also:\\n\\nhttps://old.reddit.com/r/LocalLLaMA/comments/1m80gsn/glm45_is_about_to_be_released/","edited":1753368433,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4wpla4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could try filtering it through: Glm4 32B (I only used it through openrouter so far).&lt;/p&gt;\\n\\n&lt;p&gt;Just make up a prompt that explains what you want to do.&lt;/p&gt;\\n\\n&lt;p&gt;It is one of the most &amp;quot;natural sounding&amp;quot; LLM models - at least in german. :)&lt;/p&gt;\\n\\n&lt;p&gt;See also:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1m80gsn/glm45_is_about_to_be_released/\\"&gt;https://old.reddit.com/r/LocalLLaMA/comments/1m80gsn/glm45_is_about_to_be_released/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4wpla4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753368171,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4youa9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1753387857,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"author_fullname":"t2_1k4sjdwzk2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's a mouse and cat game. Whatever changes are made will eventually be discovered. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4youa9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a mouse and cat game. Whatever changes are made will eventually be discovered. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4youa9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753387857,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4yxksi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zeth0s","can_mod_post":false,"created_utc":1753390297,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"author_fullname":"t2_2lnhq3n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The real answer is:\\n\\n\\nStart the text yourself (few sentences) and ask a non-reasoning to \\"complete\\" it (use the exact word).\\n\\n\\nThis is the right way to minimize consequences of the \\"chat interaction\\" fine tuning, that is the major cause of the \\"AI slop\\" style","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4yxksi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The real answer is:&lt;/p&gt;\\n\\n&lt;p&gt;Start the text yourself (few sentences) and ask a non-reasoning to &amp;quot;complete&amp;quot; it (use the exact word).&lt;/p&gt;\\n\\n&lt;p&gt;This is the right way to minimize consequences of the &amp;quot;chat interaction&amp;quot; fine tuning, that is the major cause of the &amp;quot;AI slop&amp;quot; style&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4yxksi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753390297,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4zkzba","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jferments","can_mod_post":false,"created_utc":1753397475,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"author_fullname":"t2_xs66a5h67","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use a system prompt to specify style. Or train a style LoRA.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4zkzba","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use a system prompt to specify style. Or train a style LoRA.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4zkzba/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753397475,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1m84s47","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n503bms","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n503bms/","num_reports":null,"locked":false,"name":"t1_n503bms","created":1753403668,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1753403668,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n502uv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Yarkm13","can_mod_post":false,"created_utc":1753403503,"send_replies":true,"parent_id":"t1_n4x7mwh","score":1,"author_fullname":"t2_4c5ffpmr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That awkward moment when I realize I’ve been using em dashes for decades…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n502uv6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That awkward moment when I realize I’ve been using em dashes for decades…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m84s47","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n502uv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753403503,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4x7mwh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1753373137,"send_replies":true,"parent_id":"t3_1m84s47","score":1,"author_fullname":"t2_9hl4ymvj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\- Woah that langue is way to fancy, dumb it down a little please.\\n\\nUsually does the trick for me lol. (Then ctrl+f and delete all the dashes)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4x7mwh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;- Woah that langue is way to fancy, dumb it down a little please.&lt;/p&gt;\\n\\n&lt;p&gt;Usually does the trick for me lol. (Then ctrl+f and delete all the dashes)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m84s47/how_do_you_keep_ai_outputs_from_sounding_ai/n4x7mwh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753373137,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m84s47","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(t,{data:l});export{s as default};
