import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"(Disclaimers: Nothing new here especially given the recent posts, but was supposed to report back at u/Evening_Ad6637 et al. Furthermore, i am a total noob and do local LLM via LM Studio on Windows 11, so no fancy ik\\\\_llama.cpp etc., as it is just so convenient.)\\n\\nI finally received 2x64 GB DDR5 5600 MHz Sticks (Kingston [Datasheet](https://www.kingston.com/datasheets/KF556C36BBE-8.pdf)) giving me 128 GB RAM on my ITX Build. I did load the EXPO0 timing profile giving CL36 etc.   \\nThis is complemented by a Low Profile RTX 4060 with 8 GB, all controlled by a Ryzen 9 7950X (any CPU would do).\\n\\nThrough LM Studio, I downloaded and ran both unsloth's 128K Q3\\\\_K\\\\_XL quant (103.7 GB) as well as managed to run the **IQ4\\\\_XS** quant (125.5 GB) on a freshly restarted windows machine. (Haven't tried crashing or stress testing it yet, it currently works without issues).  \\nI left all model settings untouched and increased the context to \\\\~17000. \\n\\n**Time to first token** on a prompt about a Berlin neighborhood took **around 10 sec, then 3.3-2.7 tps.**\\n\\nI can try to provide any further information or run prompts for you and return the response as well as times. Just wanted to update you that this works. Cheers!  \\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"FYI Qwen3 235B A22B IQ4_XS works with 128 GB DDR5 + 8GB VRAM in Windows","link_flair_richtext":[{"e":"text","t":"Generation"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lx5n8c","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.93,"author_flair_background_color":null,"subreddit_type":"public","ups":26,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_omawcpyf","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Generation","can_mod_post":false,"score":26,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752237036,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;(Disclaimers: Nothing new here especially given the recent posts, but was supposed to report back at &lt;a href=\\"/u/Evening_Ad6637\\"&gt;u/Evening_Ad6637&lt;/a&gt; et al. Furthermore, i am a total noob and do local LLM via LM Studio on Windows 11, so no fancy ik_llama.cpp etc., as it is just so convenient.)&lt;/p&gt;\\n\\n&lt;p&gt;I finally received 2x64 GB DDR5 5600 MHz Sticks (Kingston &lt;a href=\\"https://www.kingston.com/datasheets/KF556C36BBE-8.pdf\\"&gt;Datasheet&lt;/a&gt;) giving me 128 GB RAM on my ITX Build. I did load the EXPO0 timing profile giving CL36 etc.&lt;br/&gt;\\nThis is complemented by a Low Profile RTX 4060 with 8 GB, all controlled by a Ryzen 9 7950X (any CPU would do).&lt;/p&gt;\\n\\n&lt;p&gt;Through LM Studio, I downloaded and ran both unsloth&amp;#39;s 128K Q3_K_XL quant (103.7 GB) as well as managed to run the &lt;strong&gt;IQ4_XS&lt;/strong&gt; quant (125.5 GB) on a freshly restarted windows machine. (Haven&amp;#39;t tried crashing or stress testing it yet, it currently works without issues).&lt;br/&gt;\\nI left all model settings untouched and increased the context to ~17000. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Time to first token&lt;/strong&gt; on a prompt about a Berlin neighborhood took &lt;strong&gt;around 10 sec, then 3.3-2.7 tps.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I can try to provide any further information or run prompts for you and return the response as well as times. Just wanted to update you that this works. Cheers!  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"23bddba8-ff56-11ed-9688-1a11994b71f7","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#b5a3d0","id":"1lx5n8c","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Karim_acing_it","discussion_type":null,"num_comments":15,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/","subreddit_subscribers":497826,"created_utc":1752237036,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2otys9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2msxzy","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We are not capped here. With full model, you mean the BF16 or Q8? XD Will start downloading asap afterwards and launch your prompt :)","edited":false,"author_flair_css_class":null,"name":"t1_n2otys9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We are not capped here. With full model, you mean the BF16 or Q8? XD Will start downloading asap afterwards and launch your prompt :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lx5n8c","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2otys9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752303327,"author_flair_text":null,"collapsed":false,"created_utc":1752303327,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2p9fhf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2msxzy","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Send me the prompt via DM, I can just post the numbers here and return you the prompt reply via DM","edited":false,"author_flair_css_class":null,"name":"t1_n2p9fhf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Send me the prompt via DM, I can just post the numbers here and return you the prompt reply via DM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lx5n8c","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2p9fhf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752312493,"author_flair_text":null,"collapsed":false,"created_utc":1752312493,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2msxzy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"--dany--","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mebdc","score":1,"author_fullname":"t2_bjeo1gwy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for being so responsive! A few reported that qwen is very sensitive to quantization, therefore asking for a full model. Hope your internet is not capped. But feel free to do whatever you see fit. Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2msxzy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for being so responsive! A few reported that qwen is very sensitive to quantization, therefore asking for a full model. Hope your internet is not capped. But feel free to do whatever you see fit. Thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2msxzy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752273589,"author_flair_text":null,"treatment_tags":[],"created_utc":1752273589,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mebdc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m4gpq","score":2,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hi, using my PC I can test the same prompt on the following quants for you and report the speeds and outputs. \\n\\nI have the following Qwen3 models already downloaded, all unsloth 128k quants:\\n\\n**32B Q6\\\\_K\\\\_XL** (non 128k unsloth quant)\\n\\n**235B IQ4\\\\_XS, Q3\\\\_K\\\\_XL**\\n\\n(I also have 30B A3B Q6\\\\_K\\\\_XL and Q8\\\\_K\\\\_XL, as well as 14B an 8B, the latter two both Q8 from qwen directly)\\n\\nI could download the 32B Q8\\\\_K\\\\_XL as well, but I don't think the improvement in KL divergence over the Q6\\\\_K\\\\_XL is noteworthy.   \\nPlease send me your prompts that I can run LM studio, I am not that creative and don't know your use case. :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2mebdc","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, using my PC I can test the same prompt on the following quants for you and report the speeds and outputs. &lt;/p&gt;\\n\\n&lt;p&gt;I have the following Qwen3 models already downloaded, all unsloth 128k quants:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;32B Q6_K_XL&lt;/strong&gt; (non 128k unsloth quant)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;235B IQ4_XS, Q3_K_XL&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;(I also have 30B A3B Q6_K_XL and Q8_K_XL, as well as 14B an 8B, the latter two both Q8 from qwen directly)&lt;/p&gt;\\n\\n&lt;p&gt;I could download the 32B Q8_K_XL as well, but I don&amp;#39;t think the improvement in KL divergence over the Q6_K_XL is noteworthy.&lt;br/&gt;\\nPlease send me your prompts that I can run LM studio, I am not that creative and don&amp;#39;t know your use case. :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2mebdc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268848,"author_flair_text":null,"treatment_tags":[],"created_utc":1752268848,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m4gpq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"--dany--","can_mod_post":false,"created_utc":1752265896,"send_replies":true,"parent_id":"t1_n2jeei2","score":1,"author_fullname":"t2_bjeo1gwy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for sharing! do you have any evaluation of qwen3-235b heavily quantized against qwen3-32 full? How much is the difference?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m4gpq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for sharing! do you have any evaluation of qwen3-235b heavily quantized against qwen3-32 full? How much is the difference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2m4gpq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752265896,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2jeei2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1752237124,"send_replies":true,"parent_id":"t3_1lx5n8c","score":11,"author_fullname":"t2_omawcpyf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For some tasks to me, speed doesn't matter and so I can send off a prompt and return a bit later to get a high quality response, hence the value gained over smaller models. I know this is inefficient, but I am not a power user and happy with the results. A 300€ investment into 128 GB RAM is more sensible for my application compared to upgrading from 8GB VRAM to 16VRAM, given I had only 32 GB RAM previously.\\n\\nHence, being able to run Qwen3 235B finally is quite a nice addition and I am happy :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jeei2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For some tasks to me, speed doesn&amp;#39;t matter and so I can send off a prompt and return a bit later to get a high quality response, hence the value gained over smaller models. I know this is inefficient, but I am not a power user and happy with the results. A 300€ investment into 128 GB RAM is more sensible for my application compared to upgrading from 8GB VRAM to 16VRAM, given I had only 32 GB RAM previously.&lt;/p&gt;\\n\\n&lt;p&gt;Hence, being able to run Qwen3 235B finally is quite a nice addition and I am happy :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2jeei2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752237124,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jfmhk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"makistsa","can_mod_post":false,"created_utc":1752237561,"send_replies":true,"parent_id":"t3_1lx5n8c","score":2,"author_fullname":"t2_3l1o090d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I would loosen the timings and try to increase the frequency.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jfmhk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would loosen the timings and try to increase the frequency.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2jfmhk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752237561,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kxayz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1752253420,"send_replies":true,"parent_id":"t1_n2k951o","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try it out and you will be pleasantly surprised :D that 256gb ram lets you run a much larger quant :))","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kxayz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try it out and you will be pleasantly surprised :D that 256gb ram lets you run a much larger quant :))&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2kxayz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752253420,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2k951o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jatilq","can_mod_post":false,"created_utc":1752246632,"send_replies":true,"parent_id":"t3_1lx5n8c","score":1,"author_fullname":"t2_3txs3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wonder how bad this would be on my old T7910 with x2 Xeons,  256gb ram and 2x 3060 12gb.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2k951o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wonder how bad this would be on my old T7910 with x2 Xeons,  256gb ram and 2x 3060 12gb.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2k951o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752246632,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2llw2i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752260364,"send_replies":true,"parent_id":"t1_n2l8cko","score":1,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you tried Dots?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2llw2i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried Dots?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2llw2i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752260364,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2l8cko","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752256457,"send_replies":true,"parent_id":"t3_1lx5n8c","score":1,"author_fullname":"t2_5hobp6m4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Over twice as slow as hunyuan a13b on my cpu only setup. I get 7tps at q4 with hunyuan, ddr5, intel ultra 7. (But qwen is much better, hunyuan disappointed me so far.)","edited":1752256640,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2l8cko","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Over twice as slow as hunyuan a13b on my cpu only setup. I get 7tps at q4 with hunyuan, ddr5, intel ultra 7. (But qwen is much better, hunyuan disappointed me so far.)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2l8cko/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752256457,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2otunz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1752303263,"send_replies":true,"parent_id":"t1_n2mj0yi","score":1,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure can do. Do you have a prompt that I can run?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2otunz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure can do. Do you have a prompt that I can run?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2otunz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752303263,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mj0yi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dionisioalcaraz","can_mod_post":false,"created_utc":1752270326,"send_replies":true,"parent_id":"t3_1lx5n8c","score":1,"author_fullname":"t2_rl5alicdt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm hesitating if it worth buying 2x64GB DDR5 5600Mhz for my mini PC to run unsloth Qwen235B-UD-Q3\\\\_K\\\\_XL, is it possible for you to make a CPU only test for that model? I wonder if it will be much less than that \\\\~3 t/s you got.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mj0yi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m hesitating if it worth buying 2x64GB DDR5 5600Mhz for my mini PC to run unsloth Qwen235B-UD-Q3_K_XL, is it possible for you to make a CPU only test for that model? I wonder if it will be much less than that ~3 t/s you got.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2mj0yi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270326,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ouvr6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1752303845,"send_replies":true,"parent_id":"t1_n2n40ob","score":2,"author_fullname":"t2_omawcpyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Absolutely, for daily tasks, coding, time-conscious stuff, I use Claude Pro and ChatGPT. Can't speak for others, but for me, there are simply topics I would like to get a second opinion on without wanting to resort to online servers. No way things are kept confidential no matter what that Terms of Service say. I am not paranoid, tbh I couldn't care less if stuff gets leaked, but if I have the option to keep things local, heck yeah I'd prefer that if I can. And for those things, to me, the tps really don't matter at all.\\n\\nI personally notice that the bigger models clearly do better analyses and are able to give better advice. Sure, Qwen 32B and Gemma 27B are already great, but why hold back if you can afford the hardware? This is RAM man, not some specialised GPU or somethings that is absurdly expensive and not beneficial for other PC tasks. I know of people with less financial freedom wasting 10x the funds on video games, investing in wasting their life times. YMMV\\n\\nEdit: to reply to your question in full, I was asked to report back to at least 6 redditers on whether this build works, hence my post. Cheers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ouvr6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Absolutely, for daily tasks, coding, time-conscious stuff, I use Claude Pro and ChatGPT. Can&amp;#39;t speak for others, but for me, there are simply topics I would like to get a second opinion on without wanting to resort to online servers. No way things are kept confidential no matter what that Terms of Service say. I am not paranoid, tbh I couldn&amp;#39;t care less if stuff gets leaked, but if I have the option to keep things local, heck yeah I&amp;#39;d prefer that if I can. And for those things, to me, the tps really don&amp;#39;t matter at all.&lt;/p&gt;\\n\\n&lt;p&gt;I personally notice that the bigger models clearly do better analyses and are able to give better advice. Sure, Qwen 32B and Gemma 27B are already great, but why hold back if you can afford the hardware? This is RAM man, not some specialised GPU or somethings that is absurdly expensive and not beneficial for other PC tasks. I know of people with less financial freedom wasting 10x the funds on video games, investing in wasting their life times. YMMV&lt;/p&gt;\\n\\n&lt;p&gt;Edit: to reply to your question in full, I was asked to report back to at least 6 redditers on whether this build works, hence my post. Cheers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx5n8c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2ouvr6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752303845,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2n40ob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lazy-Pattern-5171","can_mod_post":false,"created_utc":1752277388,"send_replies":true,"parent_id":"t3_1lx5n8c","score":1,"author_fullname":"t2_1lyjk8is25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My only problem with all these posts about users running absurdly large models on their local setups without spending the market rate amount for GPUs is that what do you do with this beyond the posting and the bragging rights? Okay you made it work. Congratulations but are you realistically going to make it work? You’re much more likely to fall back to hosted or api based pricing for any real world use case.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2n40ob","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My only problem with all these posts about users running absurdly large models on their local setups without spending the market rate amount for GPUs is that what do you do with this beyond the posting and the bragging rights? Okay you made it work. Congratulations but are you realistically going to make it work? You’re much more likely to fall back to hosted or api based pricing for any real world use case.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx5n8c/fyi_qwen3_235b_a22b_iq4_xs_works_with_128_gb_ddr5/n2n40ob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752277388,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx5n8c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
