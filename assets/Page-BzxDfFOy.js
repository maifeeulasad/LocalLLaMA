import{j as e}from"./index-CeRg6Q3f.js";import{R as l}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"PS1: This may look like a rant, but other opinions are welcome, I may be super wrong\\n\\nPS2: I generally manually script my way out of my AI functional needs, but I also care about open source sustainability\\n\\nTitle self explanatory, I feel like building a cool open source project/tool and then only validating it on closed models from openai/google is kinda defeating the purpose of it being open source.\\n- A nice open source agent framework, yeah sorry we only test against gpt4, so it may perform poorly on XXX open model\\n- A cool openwebui function/filter that I can use with my locally hosted model, nop it sends api calls to openai go figure\\n\\nI understand that some tooling was designed in the beginning with gpt4 in mind (good luck when openai think your features are cool and they ll offer it directly on their platform).\\n\\nI understand also that gpt4 or claude can do the heavy lifting but if you say you support local models, I dont know maybe test with local models?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Open source projects/tools vendor locking themselves to openai?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1gt9f5y","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":1974,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_h4h2az0s","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":1974,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/i-BBxcAUYE5vxfCy-li_OaNHkjKHnEoKvnhg4zgNFOg.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1731833199,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;PS1: This may look like a rant, but other opinions are welcome, I may be super wrong&lt;/p&gt;\\n\\n&lt;p&gt;PS2: I generally manually script my way out of my AI functional needs, but I also care about open source sustainability&lt;/p&gt;\\n\\n&lt;p&gt;Title self explanatory, I feel like building a cool open source project/tool and then only validating it on closed models from openai/google is kinda defeating the purpose of it being open source.\\n- A nice open source agent framework, yeah sorry we only test against gpt4, so it may perform poorly on XXX open model\\n- A cool openwebui function/filter that I can use with my locally hosted model, nop it sends api calls to openai go figure&lt;/p&gt;\\n\\n&lt;p&gt;I understand that some tooling was designed in the beginning with gpt4 in mind (good luck when openai think your features are cool and they ll offer it directly on their platform).&lt;/p&gt;\\n\\n&lt;p&gt;I understand also that gpt4 or claude can do the heavy lifting but if you say you support local models, I dont know maybe test with local models?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/cpwspl39df1e1.jpeg","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/cpwspl39df1e1.jpeg?auto=webp&amp;s=e192abe1ceda59f8493d16c8fa17068d0135e307","width":500,"height":500},"resolutions":[{"url":"https://preview.redd.it/cpwspl39df1e1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9017a07997def4023916243038385443c194d522","width":108,"height":108},{"url":"https://preview.redd.it/cpwspl39df1e1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2cf86be185b2f07235ed39a310a6dae526a08e8","width":216,"height":216},{"url":"https://preview.redd.it/cpwspl39df1e1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b5579bfacc96f77ccef8ab96daac0ec2e1ae2713","width":320,"height":320}],"variants":{},"id":"wxfzrbsR94UwtPScg6asnT76-nSBWchJg9bYM00OKWA"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1gt9f5y","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"tabspaces","discussion_type":null,"num_comments":197,"send_replies":false,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/","stickied":false,"url":"https://i.redd.it/cpwspl39df1e1.jpeg","subreddit_subscribers":492315,"created_utc":1731833199,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmdlrj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Rainmaker526","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkujtn","score":7,"author_fullname":"t2_o1emusz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well.. except for other frameworks getting a compatibly layer and the user no longer requiring a subscription.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmdlrj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well.. except for other frameworks getting a compatibly layer and the user no longer requiring a subscription.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmdlrj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731865021,"author_flair_text":null,"treatment_tags":[],"created_utc":1731865021,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxwgfhk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Any_Pressure4251","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxw24vl","score":1,"author_fullname":"t2_6yisgee3","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Running is one thing, doing what you ask, is another. \\n\\nI was elated with Qwen 32b when I first ran it, but when I tried it with Cline, it's lack of good function calling showed it's a benchmark LLM.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxwgfhk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Running is one thing, doing what you ask, is another. &lt;/p&gt;\\n\\n&lt;p&gt;I was elated with Qwen 32b when I first ran it, but when I tried it with Cline, it&amp;#39;s lack of good function calling showed it&amp;#39;s a benchmark LLM.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxwgfhk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732007567,"author_flair_text":null,"treatment_tags":[],"created_utc":1732007567,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxw24vl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gaspoweredcat","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxqkadh","score":1,"author_fullname":"t2_153qitf6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I beg to differ,  codestral and qwen are not bad for code, Ive used both and deepseek cider v2 lite quite regularly and at the mo I find qwen2.5-coder-32b is my preferred, all of those can pretty comfortably run on a single 3090","edited":false,"author_flair_css_class":null,"name":"t1_lxw24vl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I beg to differ,  codestral and qwen are not bad for code, Ive used both and deepseek cider v2 lite quite regularly and at the mo I find qwen2.5-coder-32b is my preferred, all of those can pretty comfortably run on a single 3090&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxw24vl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731998416,"author_flair_text":null,"collapsed":false,"created_utc":1731998416,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxqkadh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Any_Pressure4251","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkujtn","score":-6,"author_fullname":"t2_6yisgee3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Because local models are weak compared to closed.\\n\\nThe only open model that is good for coding is DeepSeek Coder, but running that model requires a lot GPU power that is beyond most consumers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxqkadh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because local models are weak compared to closed.&lt;/p&gt;\\n\\n&lt;p&gt;The only open model that is good for coding is DeepSeek Coder, but running that model requires a lot GPU power that is beyond most consumers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqkadh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731926580,"author_flair_text":null,"treatment_tags":[],"created_utc":1731926580,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkujtn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gaspoweredcat","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxki8ai","score":54,"author_fullname":"t2_153qitf6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"its an absurdly simple thing to do and it opens up functionality, i cant see a reason not to do it really","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkujtn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;its an absurdly simple thing to do and it opens up functionality, i cant see a reason not to do it really&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkujtn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731842645,"author_flair_text":null,"treatment_tags":[],"created_utc":1731842645,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mchnd8q","id":"mchnd8q","parent_id":"t1_mcgb16f","depth":4,"children":["mchnd8q"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcgb16f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"121POINT5","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxia0","score":1,"author_fullname":"t2_3bgiodxx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Or just change your hosts file","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcgb16f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or just change your hosts file&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/mcgb16f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739400940,"author_flair_text":null,"treatment_tags":[],"created_utc":1739400940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxm1olh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SureUnderstanding358","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxlcogb","score":3,"author_fullname":"t2_8gneyjn3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\nyes yes and yes\\n\\nwell...depending on the client. only the well written ones will enforce https. ive seen plenty that dont.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_lxm1olh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes yes and yes&lt;/p&gt;\\n\\n&lt;p&gt;well...depending on the client. only the well written ones will enforce https. ive seen plenty that dont.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm1olh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731861064,"author_flair_text":null,"treatment_tags":[],"created_utc":1731861064,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlcogb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"perk11","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkz9da","score":8,"author_fullname":"t2_ar5cq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It will be using SSL, so you'd also need the proxy to issue a fake SSL certificate for openai.com and have your system trust it.\\n\\nYou also probably don't even need php, just nginx is capable of doing it.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxlcogb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will be using SSL, so you&amp;#39;d also need the proxy to issue a fake SSL certificate for openai.com and have your system trust it.&lt;/p&gt;\\n\\n&lt;p&gt;You also probably don&amp;#39;t even need php, just nginx is capable of doing it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlcogb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731851954,"author_flair_text":null,"treatment_tags":[],"created_utc":1731851954,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpife7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"snwfdhmp","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkz9da","score":1,"author_fullname":"t2_4n7cjfi","approved_by":null,"mod_note":null,"all_awardings":[],"body":"key checks are most likely only \\"not null\\"","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxpife7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;key checks are most likely only &amp;quot;not null&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpife7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731904137,"author_flair_text":null,"treatment_tags":[],"created_utc":1731904137,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkz9da","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SureUnderstanding358","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxth2","score":9,"author_fullname":"t2_8gneyjn3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"no, sorry :/ im old so id probably toss something together in php + nginx to re-write the headers in flight and put ollama or mlx behind it. \\n\\njust out of curiosity, what happens if you just toss in a random oai key? if you setup wireshark...you can check and see if your client is a actually validating the key or just expecting it not to be null. \\n\\nthis is on my thanksgiving vacation project list. if i make it work, ill share my notes","edited":false,"author_flair_css_class":null,"name":"t1_lxkz9da","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, sorry :/ im old so id probably toss something together in php + nginx to re-write the headers in flight and put ollama or mlx behind it. &lt;/p&gt;\\n\\n&lt;p&gt;just out of curiosity, what happens if you just toss in a random oai key? if you setup wireshark...you can check and see if your client is a actually validating the key or just expecting it not to be null. &lt;/p&gt;\\n\\n&lt;p&gt;this is on my thanksgiving vacation project list. if i make it work, ill share my notes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkz9da/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731845509,"author_flair_text":null,"collapsed":false,"created_utc":1731845509,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkxth2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ali0une","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxia0","score":1,"author_fullname":"t2_ciytjqdyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any recommendation for a Linux box?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkxth2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any recommendation for a Linux box?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkxth2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731844673,"author_flair_text":null,"treatment_tags":[],"created_utc":1731844673,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkxia0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SureUnderstanding358","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxki8ai","score":14,"author_fullname":"t2_8gneyjn3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"setup a proxy","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkxia0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;setup a proxy&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkxia0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731844486,"author_flair_text":null,"treatment_tags":[],"created_utc":1731844486,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxm5xuo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SirPuzzleheaded5284","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxki8ai","score":2,"author_fullname":"t2_qkwmo7t4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you can set an env variable for that if they are using the official OpenAI libs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxm5xuo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you can set an env variable for that if they are using the official OpenAI libs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm5xuo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731862468,"author_flair_text":null,"treatment_tags":[],"created_utc":1731862468,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxki8ai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ali0une","can_mod_post":false,"created_utc":1731834443,"send_replies":true,"parent_id":"t1_lxkhw0q","score":136,"author_fullname":"t2_ciytjqdyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exactly this. i'm tired having to modify the code just for that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxki8ai","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly this. i&amp;#39;m tired having to modify the code just for that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxki8ai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731834443,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":136}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxwkh7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cryptomartin1993","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxldnjr","score":2,"author_fullname":"t2_novllsl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, its really fucking easy","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxwkh7d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, its really fucking easy&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxwkh7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732010305,"author_flair_text":null,"treatment_tags":[],"created_utc":1732010305,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxldnjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1731852366,"send_replies":true,"parent_id":"t1_lxkhw0q","score":43,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let's be real, most of these projects are just python scripts and you can edit the endpoint where it calls the openai package.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxldnjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let&amp;#39;s be real, most of these projects are just python scripts and you can edit the endpoint where it calls the openai package.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxldnjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731852366,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":43}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":23,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":6,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxp9mes","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StickyDirtyKeyboard","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmihrl","score":1,"author_fullname":"t2_14aj9l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can probably also skip the export/set if you just have it read any other environment variable that's already set by default.\\n\\nAt one point, I hacked some code to use the \`OS\` env var instead, so my \\"API Key\\" was \`WINDOWS_NT\` :p","edited":false,"author_flair_css_class":null,"name":"t1_lxp9mes","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can probably also skip the export/set if you just have it read any other environment variable that&amp;#39;s already set by default.&lt;/p&gt;\\n\\n&lt;p&gt;At one point, I hacked some code to use the &lt;code&gt;OS&lt;/code&gt; env var instead, so my &amp;quot;API Key&amp;quot; was &lt;code&gt;WINDOWS_NT&lt;/code&gt; :p&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxp9mes/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731900460,"author_flair_text":null,"collapsed":false,"created_utc":1731900460,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxor60i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pneuny","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmihrl","score":1,"author_fullname":"t2_3umival0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it's a fake key, you don't even need to set an environment variable. Just define it as a hardcoded string.","edited":false,"author_flair_css_class":null,"name":"t1_lxor60i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s a fake key, you don&amp;#39;t even need to set an environment variable. Just define it as a hardcoded string.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxor60i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731893524,"author_flair_text":null,"collapsed":false,"created_utc":1731893524,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmihrl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmei8o","score":6,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmihrl/","num_reports":null,"locked":false,"name":"t1_lxmihrl","created":1731866638,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1731866638,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxnfilk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pedalnomica","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmei8o","score":3,"author_fullname":"t2_b0d7j6x9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I know you shouldn't share API keys publicly, but mine is \\"CantBeEmpty\\"\\n\\n\\nFeel free to go wild!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxnfilk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know you shouldn&amp;#39;t share API keys publicly, but mine is &amp;quot;CantBeEmpty&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Feel free to go wild!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnfilk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731877174,"author_flair_text":null,"treatment_tags":[],"created_utc":1731877174,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxsqmjk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tamereen","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxniya0","score":1,"author_fullname":"t2_cqb64adsd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ok  i'll try again thank you for the reply","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_lxsqmjk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok  i&amp;#39;ll try again thank you for the reply&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxsqmjk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731955734,"author_flair_text":null,"treatment_tags":[],"created_utc":1731955734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxniya0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1731878264,"send_replies":true,"parent_id":"t1_lxmkq7f","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"The example on their site just says put in an arbitrary value. It's not needed for ollama to work but is required because most code using OAI calls expects a value there. \\n\\n[OpenAI compatibility · Ollama Blog](https://ollama.com/blog/openai-compatibility)","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The example on their site just says put in an arbitrary value. It&amp;#39;s not needed for ollama to work but is required because most code using OAI calls expects a value there. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ollama.com/blog/openai-compatibility\\"&gt;OpenAI compatibility · Ollama Blog&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxniya0/","num_reports":null,"locked":false,"name":"t1_lxniya0","created":1731878264,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmkq7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tamereen","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmipyq","score":0,"author_fullname":"t2_cqb64adsd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you sure, last time I tried to use some of the Kemantic Kernel examples (from microsoft) to Ollama I got an exception when i sent a dummy key (because cannot be null or empty with some methods designed for OpenAI). Some of the examples work with an explicit ollama call (without key) but when it's openAI, I was not able without a key. The endpoint was correct with ollama server. I'll try again.","edited":false,"author_flair_css_class":null,"name":"t1_lxmkq7f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you sure, last time I tried to use some of the Kemantic Kernel examples (from microsoft) to Ollama I got an exception when i sent a dummy key (because cannot be null or empty with some methods designed for OpenAI). Some of the examples work with an explicit ollama call (without key) but when it&amp;#39;s openAI, I was not able without a key. The endpoint was correct with ollama server. I&amp;#39;ll try again.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmkq7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731867362,"author_flair_text":null,"collapsed":false,"created_utc":1731867362,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmipyq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"this-just_in","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmei8o","score":2,"author_fullname":"t2_kdmu4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Set a value and the unathenticated API provider (like Ollama) will happily ignore it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmipyq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Set a value and the unathenticated API provider (like Ollama) will happily ignore it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmipyq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731866712,"author_flair_text":null,"treatment_tags":[],"created_utc":1731866712,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmei8o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tamereen","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxl8hao","score":4,"author_fullname":"t2_cqb64adsd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do you manage the API key when it can not be null or empty, with ollama or llama.cpp ?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxmei8o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you manage the API key when it can not be null or empty, with ollama or llama.cpp ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmei8o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731865323,"author_flair_text":null,"treatment_tags":[],"created_utc":1731865323,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlr2hf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emprahsFury","can_mod_post":false,"send_replies":false,"parent_id":"t1_lxl8hao","score":0,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What variables do you change in say perplexica?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxlr2hf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What variables do you change in say perplexica?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlr2hf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731857472,"author_flair_text":null,"treatment_tags":[],"created_utc":1731857472,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl8hao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkhw0q","score":23,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Ollama. The existing OAI code can be used, you just change 2 variables in the API call to point it at the ollama server.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama. The existing OAI code can be used, you just change 2 variables in the API call to point it at the ollama server.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl8hao/","num_reports":null,"locked":false,"name":"t1_lxl8hao","created":1731850133,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1731850133,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmglez","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cddelgado","can_mod_post":false,"created_utc":1731866015,"send_replies":true,"parent_id":"t1_lxkhw0q","score":6,"author_fullname":"t2_b68un","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For Python projects at least you don't even need to hack the hosts file. The OpenAI API library supports API base URL changes. \\n\\n[Openai-Python Change Base Url | Restackio](https://www.restack.io/p/openai-python-answer-change-base-url-cat-ai)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmglez","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For Python projects at least you don&amp;#39;t even need to hack the hosts file. The OpenAI API library supports API base URL changes. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.restack.io/p/openai-python-answer-change-base-url-cat-ai\\"&gt;Openai-Python Change Base Url | Restackio&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmglez/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731866015,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmf1bs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"herozorro","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxm5h65","score":15,"author_fullname":"t2_nsny3r8c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah lots of people here havent coded an app to understand the unreliable nature of different models with the same prompt","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxmf1bs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah lots of people here havent coded an app to understand the unreliable nature of different models with the same prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmf1bs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731865500,"author_flair_text":null,"treatment_tags":[],"created_utc":1731865500,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxq421f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gaspoweredcat","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxm5h65","score":2,"author_fullname":"t2_153qitf6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Results yes but a lot of llm serving options support openai style api calls meaning it should work with many models in the same sort of way just offering a different result eh if you have an llm trained on a specific task etc it may offer a preferable response","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxq421f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Results yes but a lot of llm serving options support openai style api calls meaning it should work with many models in the same sort of way just offering a different result eh if you have an llm trained on a specific task etc it may offer a preferable response&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq421f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731915777,"author_flair_text":null,"treatment_tags":[],"created_utc":1731915777,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxm5h65","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iwalkthelonelyroads","can_mod_post":false,"created_utc":1731862314,"send_replies":true,"parent_id":"t1_lxkhw0q","score":4,"author_fullname":"t2_174n4u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"but different LLMs different results right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxm5h65","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;but different LLMs different results right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm5h65/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731862314,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmt95e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FaceDeer","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxldt6m","score":5,"author_fullname":"t2_4ljvm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think OP is talking about applications that hard-code the API's URL to point to OpenAI's servers, without giving you the option to point it at a local model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxmt95e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think OP is talking about applications that hard-code the API&amp;#39;s URL to point to OpenAI&amp;#39;s servers, without giving you the option to point it at a local model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmt95e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731870034,"author_flair_text":null,"treatment_tags":[],"created_utc":1731870034,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"lxldt6m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Inevitable-Start-653","can_mod_post":false,"created_utc":1731852431,"send_replies":true,"parent_id":"t1_lxkhw0q","score":2,"author_fullname":"t2_9clwj2hf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oobaboogas textgen can do this.  I try out \\"open ai API\\" tools frequently just using a local model and textgen.  I think the op is a little off, I like open ai API it's just a standard and you can often use a local model in lieu of actually using privatized models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxldt6m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oobaboogas textgen can do this.  I try out &amp;quot;open ai API&amp;quot; tools frequently just using a local model and textgen.  I think the op is a little off, I like open ai API it&amp;#39;s just a standard and you can often use a local model in lieu of actually using privatized models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxldt6m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731852431,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxla1jk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"created_utc":1731850815,"send_replies":true,"parent_id":"t1_lxkhw0q","score":2,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; you could trick it into working with local by editing your hosts file and redirecting openais url to localhost\\n\\nOh! That's actually smart!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxla1jk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;you could trick it into working with local by editing your hosts file and redirecting openais url to localhost&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Oh! That&amp;#39;s actually smart!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxla1jk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731850815,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlpk36","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"habanerotaco","can_mod_post":false,"created_utc":1731856938,"send_replies":true,"parent_id":"t1_lxkhw0q","score":2,"author_fullname":"t2_88b6vcfr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The openai library lets you change the base url","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlpk36","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The openai library lets you change the base url&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlpk36/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731856938,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkllf4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheCTRL","can_mod_post":false,"created_utc":1731836704,"send_replies":true,"parent_id":"t1_lxkhw0q","score":2,"author_fullname":"t2_nd535qq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just place an entry in your hosts file or in your local dns","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkllf4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just place an entry in your hosts file or in your local dns&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkllf4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731836704,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxknjfc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"arcandor","can_mod_post":false,"created_utc":1731838012,"send_replies":true,"parent_id":"t1_lxkhw0q","score":2,"author_fullname":"t2_3gpqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Lots of times all you have to do is set an environment variable...\\n\\nOPENAI_BASE_URL = (your open ai compatible endpoint, ollama or whatever's IP)\\n\\nNo need to modify the source code if they are using the OpenAI package.","edited":1731868997,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxknjfc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lots of times all you have to do is set an environment variable...&lt;/p&gt;\\n\\n&lt;p&gt;OPENAI_BASE_URL = (your open ai compatible endpoint, ollama or whatever&amp;#39;s IP)&lt;/p&gt;\\n\\n&lt;p&gt;No need to modify the source code if they are using the OpenAI package.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxknjfc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838012,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxllhg2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"khaliiil","can_mod_post":false,"created_utc":1731855469,"send_replies":true,"parent_id":"t1_lxkhw0q","score":1,"author_fullname":"t2_13sum7q7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you name some useful open source projects that only offer openai? I would love to add the local possibility for them, it'd be a fun little project.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxllhg2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you name some useful open source projects that only offer openai? I would love to add the local possibility for them, it&amp;#39;d be a fun little project.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxllhg2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731855469,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxl5kxv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maigpy","can_mod_post":false,"created_utc":1731848794,"send_replies":true,"parent_id":"t1_lxkhw0q","score":1,"author_fullname":"t2_13cwvy61pn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ollama\\nand you're golden.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl5kxv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ollama\\nand you&amp;#39;re golden.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl5kxv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731848794,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmerxa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"herozorro","can_mod_post":false,"created_utc":1731865411,"send_replies":true,"parent_id":"t1_lxkhw0q","score":0,"author_fullname":"t2_nsny3r8c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; its basically as simple as allowing you to change the endpoint url\\n\\nits not as simple as that. because different models react differently (need to be prompted differently, need different edge cases to be caught, etc), so the app will break.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmerxa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;its basically as simple as allowing you to change the endpoint url&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;its not as simple as that. because different models react differently (need to be prompted differently, need different edge cases to be caught, etc), so the app will break.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmerxa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731865411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkhw0q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gaspoweredcat","can_mod_post":false,"created_utc":1731834216,"send_replies":true,"parent_id":"t3_1gt9f5y","score":362,"author_fullname":"t2_153qitf6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"its a shame they dont include local as an option, its basically as simple as allowing you to change the endpoint url (if im right technically you could trick it into working with local by editing your hosts file and redirecting openais url to localhost)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkhw0q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;its a shame they dont include local as an option, its basically as simple as allowing you to change the endpoint url (if im right technically you could trick it into working with local by editing your hosts file and redirecting openais url to localhost)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkhw0q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731834216,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":362}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxorif1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"popiazaza","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxntbf6","score":2,"author_fullname":"t2_f6vyt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You were replying with different topic from my comment and asking what's the point of my post?\\n\\nI'm not asking for developer to support more models/APIs. I'm just asking those who support OpenRouter to let me set the OpenAI compatible API endpoint.\\n\\nYou could just upvote [this comment](https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkrtag/) and move on. No need to be this aggressive.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_lxorif1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You were replying with different topic from my comment and asking what&amp;#39;s the point of my post?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m not asking for developer to support more models/APIs. I&amp;#39;m just asking those who support OpenRouter to let me set the OpenAI compatible API endpoint.&lt;/p&gt;\\n\\n&lt;p&gt;You could just upvote &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkrtag/\\"&gt;this comment&lt;/a&gt; and move on. No need to be this aggressive.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxorif1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731893650,"author_flair_text":null,"treatment_tags":[],"created_utc":1731893650,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxntbf6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"novexion","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxnpqgj","score":-3,"author_fullname":"t2_5acalax1","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It takes 3 minutes. Whats the point of the post?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxntbf6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It takes 3 minutes. Whats the point of the post?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxntbf6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731881679,"author_flair_text":null,"treatment_tags":[],"created_utc":1731881679,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxnpqgj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"popiazaza","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxncsu0","score":0,"author_fullname":"t2_f6vyt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It doesn't prevent you from make the change and compiling from source. You could implement anything that way, yay.\\n\\nBut that's not the point of the post, isn't it?","edited":false,"author_flair_css_class":null,"name":"t1_lxnpqgj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t prevent you from make the change and compiling from source. You could implement anything that way, yay.&lt;/p&gt;\\n\\n&lt;p&gt;But that&amp;#39;s not the point of the post, isn&amp;#39;t it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnpqgj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731880494,"author_flair_text":null,"collapsed":false,"created_utc":1731880494,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxncsu0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"novexion","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxnb7xw","score":-4,"author_fullname":"t2_5acalax1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can set your own endpoint though just change url from open routers to your own api endpoint. I’m confused as to what you’re trying to say. How is the OSS preventing you from changing a single line of code that sets the url?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxncsu0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can set your own endpoint though just change url from open routers to your own api endpoint. I’m confused as to what you’re trying to say. How is the OSS preventing you from changing a single line of code that sets the url?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxncsu0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731876331,"author_flair_text":null,"treatment_tags":[],"created_utc":1731876331,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}},"user_reports":[],"saved":false,"id":"lxnb7xw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"popiazaza","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxn51o5","score":5,"author_fullname":"t2_f6vyt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just let me set my API endpoint instead of making it OpenRouter specific setting.\\n\\nI don't think it takes more time to do it than making OpenRouter option.\\n\\nWe are talking about OSS that DOESN'T let us set our own API endpoint btw.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxnb7xw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just let me set my API endpoint instead of making it OpenRouter specific setting.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think it takes more time to do it than making OpenRouter option.&lt;/p&gt;\\n\\n&lt;p&gt;We are talking about OSS that DOESN&amp;#39;T let us set our own API endpoint btw.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnb7xw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731875825,"author_flair_text":null,"treatment_tags":[],"created_utc":1731875825,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"lxn51o5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"novexion","can_mod_post":false,"created_utc":1731873827,"send_replies":true,"parent_id":"t1_lxkkvgn","score":6,"author_fullname":"t2_5acalax1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But openrouter is OpenAI api compatible so what do you expect?\\n\\nDo you want these open source developers to take extra time supporting models that have unique api formats? When those models could just use OpenAI compatible endpoint?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxn51o5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But openrouter is OpenAI api compatible so what do you expect?&lt;/p&gt;\\n\\n&lt;p&gt;Do you want these open source developers to take extra time supporting models that have unique api formats? When those models could just use OpenAI compatible endpoint?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxn51o5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731873827,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkkvgn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"popiazaza","can_mod_post":false,"created_utc":1731836226,"send_replies":true,"parent_id":"t3_1gt9f5y","score":48,"author_fullname":"t2_f6vyt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Extend that to OpenRouter too.\\n\\nToo many project slap OpenRouter and say it support any model (that OpenRouter router has).\\n\\nOpenRouter isn't really \\"open\\". You can't set it to route to any API.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkkvgn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Extend that to OpenRouter too.&lt;/p&gt;\\n\\n&lt;p&gt;Too many project slap OpenRouter and say it support any model (that OpenRouter router has).&lt;/p&gt;\\n\\n&lt;p&gt;OpenRouter isn&amp;#39;t really &amp;quot;open&amp;quot;. You can&amp;#39;t set it to route to any API.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkkvgn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731836226,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":48}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkyywc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ImJacksLackOfBeetus","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxabd","score":6,"author_fullname":"t2_mnx4f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Totally agree, makes things a lot more plug-and-play.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkyywc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Totally agree, makes things a lot more plug-and-play.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkyywc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731845344,"author_flair_text":null,"treatment_tags":[],"created_utc":1731845344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxl6upx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxabd","score":6,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agreed. The OpenAI API has essentially become like the S3 API for block storage. S3 is technically an Amazon product, but the API is at this point just the industry standard for any product in that market.\\n\\nThe OpenAI API has become the same. If you don't offer an OpenAI API endpoint then most tools won't work with your product. So it's natural that pretty much everyone has adapted it. To my knowledge the only major AI company that don't offer an official OpenAI endpoint for their service at this point is Anthropic. Everybody else (including Google) has an OpenAI endpoint.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxl6upx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agreed. The OpenAI API has essentially become like the S3 API for block storage. S3 is technically an Amazon product, but the API is at this point just the industry standard for any product in that market.&lt;/p&gt;\\n\\n&lt;p&gt;The OpenAI API has become the same. If you don&amp;#39;t offer an OpenAI API endpoint then most tools won&amp;#39;t work with your product. So it&amp;#39;s natural that pretty much everyone has adapted it. To my knowledge the only major AI company that don&amp;#39;t offer an official OpenAI endpoint for their service at this point is Anthropic. Everybody else (including Google) has an OpenAI endpoint.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl6upx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731849391,"author_flair_text":null,"treatment_tags":[],"created_utc":1731849391,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmen89","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"10minOfNamingMyAcc","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxabd","score":1,"author_fullname":"t2_7rqxjz0i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yet no tool lets you use it...\\nKobold cop has chat (openai compatible) and text completions endpoints.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxmen89","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yet no tool lets you use it...\\nKobold cop has chat (openai compatible) and text completions endpoints.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmen89/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731865368,"author_flair_text":null,"treatment_tags":[],"created_utc":1731865368,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxqikm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maykey","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxabd","score":1,"author_fullname":"t2_17tuu7pv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; it's a good thing we have a standard API \\n\\ntext-generation-webui had at least 2 api before that. Maybe more as I think in first versions streaming was done by web sockets and non streaming was usual post request similar to kobold ai(not sure kobold.cpp existed back then)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxqikm0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;it&amp;#39;s a good thing we have a standard API &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;text-generation-webui had at least 2 api before that. Maybe more as I think in first versions streaming was done by web sockets and non streaming was usual post request similar to kobold ai(not sure kobold.cpp existed back then)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqikm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731925477,"author_flair_text":null,"treatment_tags":[],"created_utc":1731925477,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkxabd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrdevlar","can_mod_post":false,"created_utc":1731844355,"send_replies":true,"parent_id":"t1_lxkrtag","score":21,"author_fullname":"t2_4u8mb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\`text-generation-webui\` also has an OpenAI API. \\n\\nI may not like OpenAI, but I do think it's a good thing we have a standard API that is shared across a lot of different applications.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkxabd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;code&gt;text-generation-webui&lt;/code&gt; also has an OpenAI API. &lt;/p&gt;\\n\\n&lt;p&gt;I may not like OpenAI, but I do think it&amp;#39;s a good thing we have a standard API that is shared across a lot of different applications.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkxabd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731844355,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpufiq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"umarmnaq","can_mod_post":false,"created_utc":1731909995,"send_replies":true,"parent_id":"t1_lxkrtag","score":3,"author_fullname":"t2_9y98kd8hb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also, most of the time, there is no need to even change the code. A simple enviroment variable tends to do the trick","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxpufiq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also, most of the time, there is no need to even change the code. A simple enviroment variable tends to do the trick&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpufiq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731909995,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxqhjim","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maykey","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxqf19w","score":1,"author_fullname":"t2_17tuu7pv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And authors of tools that use openai are not localllama. \\nAt least they definitely care less about rant than about PR","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxqhjim","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And authors of tools that use openai are not localllama. \\nAt least they definitely care less about rant than about PR&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqhjim/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731924804,"author_flair_text":null,"treatment_tags":[],"created_utc":1731924804,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxqf19w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ImJacksLackOfBeetus","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxq8ftf","score":1,"author_fullname":"t2_mnx4f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean this is /r/**Local**LLaMA. : P\\n\\nAnyway, if you have any other online text generation service that is OpenAI API compatible you can just as easily plug that one in, point is you're not really locked down to OpenAI in an opensource project, even if it's \\"hardcoded\\".","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxqf19w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean this is /r/&lt;strong&gt;Local&lt;/strong&gt;LLaMA. : P&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, if you have any other online text generation service that is OpenAI API compatible you can just as easily plug that one in, point is you&amp;#39;re not really locked down to OpenAI in an opensource project, even if it&amp;#39;s &amp;quot;hardcoded&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqf19w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731923141,"author_flair_text":null,"treatment_tags":[],"created_utc":1731923141,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxq8ftf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"created_utc":1731918657,"send_replies":true,"parent_id":"t1_lxkrtag","score":2,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes but people don't have the gpu power to run it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxq8ftf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes but people don&amp;#39;t have the gpu power to run it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq8ftf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731918657,"author_flair_text":"Llama 3.1","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkrtag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ImJacksLackOfBeetus","can_mod_post":false,"created_utc":1731840859,"send_replies":true,"parent_id":"t3_1gt9f5y","score":32,"author_fullname":"t2_mnx4f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If this was closed source I'd agree, but with open source you can just edit the hardcoded endpoint. I know LM Studio and Ollama are OpenAI API compatible (enough), the change is often as simple as replacing *api.openai.com* with *localhost:1234*.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkrtag","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If this was closed source I&amp;#39;d agree, but with open source you can just edit the hardcoded endpoint. I know LM Studio and Ollama are OpenAI API compatible (enough), the change is often as simple as replacing &lt;em&gt;api.openai.com&lt;/em&gt; with &lt;em&gt;localhost:1234&lt;/em&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkrtag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731840859,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxo3xnc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Curious_Betsy_","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxn27rm","score":1,"author_fullname":"t2_3xlx9ubu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see, ty","edited":false,"author_flair_css_class":null,"name":"t1_lxo3xnc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see, ty&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxo3xnc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731885307,"author_flair_text":null,"collapsed":false,"created_utc":1731885307,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxn27rm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robbie7_______","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmi6gf","score":9,"author_fullname":"t2_gv24l9fw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama-server is one of the binaries built into llama.cpp (which is the engine underlying ollama). It has a built-in OpenAI-compatible endpoint which should work reasonably well with most programs that just need completions or chat completions.","edited":1731873125,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxn27rm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama-server is one of the binaries built into llama.cpp (which is the engine underlying ollama). It has a built-in OpenAI-compatible endpoint which should work reasonably well with most programs that just need completions or chat completions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxn27rm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731872895,"author_flair_text":null,"treatment_tags":[],"created_utc":1731872895,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmi6gf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Curious_Betsy_","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkowz8","score":2,"author_fullname":"t2_3xlx9ubu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait, what is llama-server? And how can it replace the processing that would be done by OpenAI (via the API)?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxmi6gf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait, what is llama-server? And how can it replace the processing that would be done by OpenAI (via the API)?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmi6gf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731866536,"author_flair_text":null,"treatment_tags":[],"created_utc":1731866536,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxl2cqx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ChernobogDan","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkowz8","score":6,"author_fullname":"t2_mbo5z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\nWhy not tweak 3 layers of abstractions of configs and debug why some of them don’t propagate to a lower level.\\n\\nIsnt this back propagation?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxl2cqx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not tweak 3 layers of abstractions of configs and debug why some of them don’t propagate to a lower level.&lt;/p&gt;\\n\\n&lt;p&gt;Isnt this back propagation?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl2cqx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731847213,"author_flair_text":null,"treatment_tags":[],"created_utc":1731847213,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxqavgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheTerrasque","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxqafql","score":1,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's what I did early days, made switching models a real pain. Ollama handles that automatically, which is nice. llama-server kinda handles it, but only if the template is one of the pre-approved ones.","edited":false,"author_flair_css_class":null,"name":"t1_lxqavgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s what I did early days, made switching models a real pain. Ollama handles that automatically, which is nice. llama-server kinda handles it, but only if the template is one of the pre-approved ones.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqavgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731920307,"author_flair_text":null,"collapsed":false,"created_utc":1731920307,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m738h1j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Echo9Zulu-","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxqafql","score":1,"author_fullname":"t2_pw77g8dq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I use the apply.chat_template method in Transformers","edited":false,"author_flair_css_class":null,"name":"t1_m738h1j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use the apply.chat_template method in Transformers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/m738h1j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736858973,"author_flair_text":null,"collapsed":false,"created_utc":1736858973,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxqafql","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robbie7_______","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxpommk","score":1,"author_fullname":"t2_gv24l9fw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My use case is pretty bare-bones, so I just build the template client-side. I’d think this would cover most use cases","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxqafql","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My use case is pretty bare-bones, so I just build the template client-side. I’d think this would cover most use cases&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqafql/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731920016,"author_flair_text":null,"treatment_tags":[],"created_utc":1731920016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxpommk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheTerrasque","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkowz8","score":1,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because it's templating is ass.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxpommk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because it&amp;#39;s templating is ass.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpommk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731906949,"author_flair_text":null,"treatment_tags":[],"created_utc":1731906949,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":0,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxnqjzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1731880762,"send_replies":true,"parent_id":"t1_lxkowz8","score":0,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"You could even put open-webui on top of ollama and use the API provided by open-webui 🤯","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could even put open-webui on top of ollama and use the API provided by open-webui 🤯&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnqjzm/","num_reports":null,"locked":false,"name":"t1_lxnqjzm","created":1731880762,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"41af45de-fdc0-11ee-a05e-8227e0534943","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxooi0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkw30d","score":2,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, I will give it a try with latest Ollama. Would love to not have to run unnecessary components for sure.","edited":false,"author_flair_css_class":null,"name":"t1_lxooi0a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I will give it a try with latest Ollama. Would love to not have to run unnecessary components for sure.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxooi0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731892543,"author_flair_text":null,"collapsed":false,"created_utc":1731892543,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkw30d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"micseydel","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkpu00","score":9,"author_fullname":"t2_gfdbo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://ollama.com/blog/openai-compatibility as of February\\n\\n\\n&gt;Ollama now has built-in compatibility with the OpenAI Chat Completions API, making it possible to use more tooling and applications with Ollama locally.\\n\\n\\nThey then do a demo starting with \`ollama pull llama2\` 🦙","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkw30d","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 8B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://ollama.com/blog/openai-compatibility\\"&gt;https://ollama.com/blog/openai-compatibility&lt;/a&gt; as of February&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Ollama now has built-in compatibility with the OpenAI Chat Completions API, making it possible to use more tooling and applications with Ollama locally.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;They then do a demo starting with &lt;code&gt;ollama pull llama2&lt;/code&gt; 🦙&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkw30d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731843616,"author_flair_text":"Llama 8B","treatment_tags":[],"created_utc":1731843616,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxon7ju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxn2gvo","score":1,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Definitely not Herculean. More like annoying.","edited":false,"author_flair_css_class":null,"name":"t1_lxon7ju","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely not Herculean. More like annoying.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxon7ju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731892071,"author_flair_text":null,"collapsed":false,"created_utc":1731892071,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxn2gvo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robbie7_______","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkpu00","score":2,"author_fullname":"t2_gv24l9fw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I personally don’t find downloading GGUFs from HuggingFace to be a particularly Herculean task, but YMMV","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxn2gvo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I personally don’t find downloading GGUFs from HuggingFace to be a particularly Herculean task, but YMMV&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxn2gvo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731872979,"author_flair_text":null,"treatment_tags":[],"created_utc":1731872979,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkpu00","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkowz8","score":-24,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does it have a pull like ollama? Otherwise I ain't touching it lol","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkpu00","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it have a pull like ollama? Otherwise I ain&amp;#39;t touching it lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkpu00/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731839547,"author_flair_text":null,"treatment_tags":[],"created_utc":1731839547,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-24}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkowz8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robbie7_______","can_mod_post":false,"created_utc":1731838931,"send_replies":true,"parent_id":"t1_lxkjjbg","score":117,"author_fullname":"t2_gv24l9fw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Man, just run llama-server. Why do we need 3 layers of abstraction to do something already built into the lowest layer?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkowz8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Man, just run llama-server. Why do we need 3 layers of abstraction to do something already built into the lowest layer?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkowz8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838931,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":117}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmxea0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WolpertingerRumo","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxktbsr","score":1,"author_fullname":"t2_eju17wbbf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Haven’t tried it out yet, but I remembered the headline","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxmxea0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haven’t tried it out yet, but I remembered the headline&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmxea0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731871328,"author_flair_text":null,"treatment_tags":[],"created_utc":1731871328,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxktbsr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_yustaguy_","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkskgc","score":7,"author_fullname":"t2_8x8zgntch","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh, I stand corrected. neat!","edited":false,"author_flair_css_class":null,"name":"t1_lxktbsr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh, I stand corrected. neat!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxktbsr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731841844,"author_flair_text":null,"collapsed":false,"created_utc":1731841844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxrqntd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WolpertingerRumo","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxpovim","score":1,"author_fullname":"t2_eju17wbbf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I never changed over, so I don’t know. Most of my projects support ollama, the others get LocalAI.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxrqntd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I never changed over, so I don’t know. Most of my projects support ollama, the others get LocalAI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxrqntd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731944748,"author_flair_text":null,"treatment_tags":[],"created_utc":1731944748,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxpovim","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheTerrasque","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkskgc","score":1,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Iirc there's no way to set context length via it, so for most of my projects I moved back to ollama's api","edited":false,"author_flair_css_class":null,"name":"t1_lxpovim","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Iirc there&amp;#39;s no way to set context length via it, so for most of my projects I moved back to ollama&amp;#39;s api&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpovim/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731907070,"author_flair_text":null,"collapsed":false,"created_utc":1731907070,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkskgc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WolpertingerRumo","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkq6j3","score":36,"author_fullname":"t2_eju17wbbf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I thought they have both now?\\n\\nhttps://ollama.com/blog/openai-compatibility","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkskgc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought they have both now?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ollama.com/blog/openai-compatibility\\"&gt;https://ollama.com/blog/openai-compatibility&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkskgc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731841352,"author_flair_text":null,"treatment_tags":[],"created_utc":1731841352,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkq6j3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_yustaguy_","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxklbel","score":6,"author_fullname":"t2_8x8zgntch","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ollama has a slightly different API... because... reasons","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkq6j3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama has a slightly different API... because... reasons&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkq6j3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731839780,"author_flair_text":null,"treatment_tags":[],"created_utc":1731839780,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxknzrb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxklbel","score":-2,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I never managed to get that working. It looked like its implementation was not compatible with the new openai.completions interface.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxknzrb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I never managed to get that working. It looked like its implementation was not compatible with the new openai.completions interface.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxknzrb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838320,"author_flair_text":null,"treatment_tags":[],"created_utc":1731838320,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxklbel","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WolpertingerRumo","can_mod_post":false,"created_utc":1731836519,"send_replies":true,"parent_id":"t1_lxkjjbg","score":17,"author_fullname":"t2_eju17wbbf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Doesn’t ollama do that by itself?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxklbel","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doesn’t ollama do that by itself?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxklbel/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731836519,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpub4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"umarmnaq","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxlqnkd","score":6,"author_fullname":"t2_9y98kd8hb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\`export OPENAI_API_BASE='http://localhost:11434/v1'\`","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxpub4f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;code&gt;export OPENAI_API_BASE=&amp;#39;http://localhost:11434/v1&amp;#39;&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpub4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731909927,"author_flair_text":null,"treatment_tags":[],"created_utc":1731909927,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlqnkd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emprahsFury","can_mod_post":false,"created_utc":1731857326,"send_replies":false,"parent_id":"t1_lxkjjbg","score":8,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Then you realize they only allow you to add an api key, and the base url is hardcoded","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlqnkd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Then you realize they only allow you to add an api key, and the base url is hardcoded&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlqnkd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731857326,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpslaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxps5g9","score":1,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for this.","edited":false,"author_flair_css_class":null,"name":"t1_lxpslaa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpslaa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731908985,"author_flair_text":null,"collapsed":false,"created_utc":1731908985,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxps5g9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Murky_Mountain_97","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxon96k","score":2,"author_fullname":"t2_c1t6569u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It allows non transformer models such as computer vision, audio, statistical tools in addition to LLM inference endpoints 💯⚡️","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxps5g9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It allows non transformer models such as computer vision, audio, statistical tools in addition to LLM inference endpoints 💯⚡️&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxps5g9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731908751,"author_flair_text":null,"treatment_tags":[],"created_utc":1731908751,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxon96k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxmoyqm","score":1,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does it have any advantages over Ollama?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxon96k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it have any advantages over Ollama?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxon96k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731892088,"author_flair_text":null,"treatment_tags":[],"created_utc":1731892088,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxmoyqm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Murky_Mountain_97","can_mod_post":false,"created_utc":1731868699,"send_replies":true,"parent_id":"t1_lxkjjbg","score":-1,"author_fullname":"t2_c1t6569u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Solo is another Ollama alternative for compound AI ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmoyqm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Solo is another Ollama alternative for compound AI &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmoyqm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731868699,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxklb1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WolpertingerRumo","can_mod_post":false,"created_utc":1731836512,"send_replies":true,"parent_id":"t1_lxkjjbg","score":-1,"author_fullname":"t2_eju17wbbf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Doesn’t plans do that by itself?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxklb1w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doesn’t plans do that by itself?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxklb1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731836512,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkqr2o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HMikeeU","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxko274","score":1,"author_fullname":"t2_17e7ah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's what they were saying...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkqr2o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s what they were saying...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkqr2o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731840161,"author_flair_text":null,"treatment_tags":[],"created_utc":1731840161,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkvyhw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxku6vm","score":5,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah, got it, makes sense. One issue with that is, you will have to build tools that capitalize on the strengths of the underlying model, and in case of LocalLLMs, it means necessarily building tools specific to certain LLMs","edited":false,"author_flair_css_class":null,"name":"t1_lxkvyhw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah, got it, makes sense. One issue with that is, you will have to build tools that capitalize on the strengths of the underlying model, and in case of LocalLLMs, it means necessarily building tools specific to certain LLMs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkvyhw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731843537,"author_flair_text":null,"collapsed":false,"created_utc":1731843537,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"lxku6vm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxko274","score":-2,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am not saying I want a local gpt4, Nor I am ranting about the use of the API of openai (as other commenters are pointing), I can obviously simulate that with a lot of tools.\\n\\nBut you can develop functional products using the capability of locally available models, say llama or qwen or whatever. that is if you test and build your product around their, less than gpt4, capabilities.\\n\\nbut if all you do is built tools that work fantastic with gpt4, simply pointing the client to a local model served with openai API wouldnt work, you generally get poor results","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxku6vm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am not saying I want a local gpt4, Nor I am ranting about the use of the API of openai (as other commenters are pointing), I can obviously simulate that with a lot of tools.&lt;/p&gt;\\n\\n&lt;p&gt;But you can develop functional products using the capability of locally available models, say llama or qwen or whatever. that is if you test and build your product around their, less than gpt4, capabilities.&lt;/p&gt;\\n\\n&lt;p&gt;but if all you do is built tools that work fantastic with gpt4, simply pointing the client to a local model served with openai API wouldnt work, you generally get poor results&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxku6vm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731842410,"author_flair_text":null,"treatment_tags":[],"created_utc":1731842410,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxko274","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"baddadpuns","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkk1dc","score":9,"author_fullname":"t2_if2kwdg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We will never have locally running gpt4, so if we use local LLMs, it will never be at the same level as GPT4. Its part of the compromise with LLMs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxko274","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We will never have locally running gpt4, so if we use local LLMs, it will never be at the same level as GPT4. Its part of the compromise with LLMs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxko274/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838364,"author_flair_text":null,"treatment_tags":[],"created_utc":1731838364,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkk1dc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731835660,"send_replies":true,"parent_id":"t1_lxkjjbg","score":-13,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, already done that, but I dont have a gpt4 locally so results may not be the same","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkk1dc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, already done that, but I dont have a gpt4 locally so results may not be the same&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkk1dc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731835660,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-13}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkjjbg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"baddadpuns","can_mod_post":false,"created_utc":1731835321,"send_replies":true,"parent_id":"t3_1gt9f5y","score":64,"author_fullname":"t2_if2kwdg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use LiteLLM to create an OpenAI api to local LLMs running  on Ollama, and you can easily plugin your local LLM  instead of OpenAI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkjjbg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use LiteLLM to create an OpenAI api to local LLMs running  on Ollama, and you can easily plugin your local LLM  instead of OpenAI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkjjbg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731835321,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":64}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxost21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AutomataManifold","can_mod_post":false,"created_utc":1731894129,"send_replies":true,"parent_id":"t1_lxlwgk1","score":4,"author_fullname":"t2_bfs5bk7y8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, though some of them have been annoying. Partcularly libraries. If I have to edit some deeply nested python file it's a lot more work than pip install whatever. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxost21","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, though some of them have been annoying. Partcularly libraries. If I have to edit some deeply nested python file it&amp;#39;s a lot more work than pip install whatever. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxost21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731894129,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxnqu2l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"frozen_tuna","can_mod_post":false,"created_utc":1731880852,"send_replies":true,"parent_id":"t1_lxlwgk1","score":1,"author_fullname":"t2_ecuq6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very true. I *did* have to get comfortable with docker compose to get \\"SuperAGI\\" (vaguely) working with TGWUI but hey, I had it running.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxnqu2l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very true. I &lt;em&gt;did&lt;/em&gt; have to get comfortable with docker compose to get &amp;quot;SuperAGI&amp;quot; (vaguely) working with TGWUI but hey, I had it running.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnqu2l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731880852,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlwgk1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"created_utc":1731859334,"send_replies":true,"parent_id":"t3_1gt9f5y","score":14,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm yet to see an opensource project that uses OpenAI compatible endpoint that I haven't been able to make use a local llm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlwgk1","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m yet to see an opensource project that uses OpenAI compatible endpoint that I haven&amp;#39;t been able to make use a local llm.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlwgk1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731859334,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxs8qul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"agntdrake","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxr8dv8","score":2,"author_fullname":"t2_4emw8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The input token limit isn't the same thing as the context size. Increasing the context size causes the amount of memory consumed to increase during inference which could be more than your GPU can handle. The input token limit just cuts off the number of input tokens. Very different things.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxs8qul","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The input token limit isn&amp;#39;t the same thing as the context size. Increasing the context size causes the amount of memory consumed to increase during inference which could be more than your GPU can handle. The input token limit just cuts off the number of input tokens. Very different things.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxs8qul/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731950356,"author_flair_text":null,"treatment_tags":[],"created_utc":1731950356,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxr8dv8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"micamecava","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxooiri","score":0,"author_fullname":"t2_frj0be6a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would suppose that if you’re using a client library you are able to programatically set the input token limit","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxr8dv8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would suppose that if you’re using a client library you are able to programatically set the input token limit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxr8dv8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731938331,"author_flair_text":null,"treatment_tags":[],"created_utc":1731938331,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxooiri","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"agntdrake","can_mod_post":false,"created_utc":1731892551,"send_replies":true,"parent_id":"t1_lxkjl8s","score":0,"author_fullname":"t2_4emw8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Except when you want to change something like the context size and there's no way to do that with the OpenAI API.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxooiri","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Except when you want to change something like the context size and there&amp;#39;s no way to do that with the OpenAI API.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxooiri/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731892551,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkjl8s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"micamecava","can_mod_post":false,"created_utc":1731835358,"send_replies":true,"parent_id":"t3_1gt9f5y","score":18,"author_fullname":"t2_frj0be6a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also it’s not really a vendor lock-in if your client lib has become an industry standard for completions API. You can (at least for now) hotswap a provider by changing the endpoint and an api key, and move to Google, Together, Cerebras, vllm that you can use to host a bunch of models, and even Ollama for local models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkjl8s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also it’s not really a vendor lock-in if your client lib has become an industry standard for completions API. You can (at least for now) hotswap a provider by changing the endpoint and an api key, and move to Google, Together, Cerebras, vllm that you can use to host a bunch of models, and even Ollama for local models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkjl8s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731835358,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpxydv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DangKilla","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkuu4f","score":2,"author_fullname":"t2_9qbn3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not sure why you're being downvoted. This is what Silicon Valley VC's do. They buy the market share until they're a monopoly. The VC model dies via compatibility and open weights. \\n\\nGoogle seems to be trying its best to not be open as if it knows it will lose its search engine monopoly.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxpxydv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure why you&amp;#39;re being downvoted. This is what Silicon Valley VC&amp;#39;s do. They buy the market share until they&amp;#39;re a monopoly. The VC model dies via compatibility and open weights. &lt;/p&gt;\\n\\n&lt;p&gt;Google seems to be trying its best to not be open as if it knows it will lose its search engine monopoly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpxydv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731912009,"author_flair_text":null,"treatment_tags":[],"created_utc":1731912009,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkvxbv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"heftybyte","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkuu4f","score":1,"author_fullname":"t2_4d8hj39","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s an interesting idea! Not sure if it would be possible to have standards in the same way but maybe some sort of translation layer.\\n\\nOpenAI *api* is actually profitable. Massively profitable in fact. They are only losing billions from the free tier not the paid tier. This benefits them because they are essentially paying for high quality user generated training data as well as market share in the industry. \\n\\nI believe that not only will they not raise prices, but prices will continue to drop dramatically as it has (ex: price of gpt4o is 95% less than gpt4-32k) as they move to more cost effective hardware, smaller high quality models (gpt4o-mini beats and is smaller than gpt4-32k at 99% less cost) and ongoing optimization techniques.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkvxbv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s an interesting idea! Not sure if it would be possible to have standards in the same way but maybe some sort of translation layer.&lt;/p&gt;\\n\\n&lt;p&gt;OpenAI &lt;em&gt;api&lt;/em&gt; is actually profitable. Massively profitable in fact. They are only losing billions from the free tier not the paid tier. This benefits them because they are essentially paying for high quality user generated training data as well as market share in the industry. &lt;/p&gt;\\n\\n&lt;p&gt;I believe that not only will they not raise prices, but prices will continue to drop dramatically as it has (ex: price of gpt4o is 95% less than gpt4-32k) as they move to more cost effective hardware, smaller high quality models (gpt4o-mini beats and is smaller than gpt4-32k at 99% less cost) and ongoing optimization techniques.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkvxbv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731843518,"author_flair_text":null,"treatment_tags":[],"created_utc":1731843518,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkuu4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731842828,"send_replies":true,"parent_id":"t1_lxkqkbl","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"valid point!, reminds me of the standards meme [https://xkcd.com/927/](https://xkcd.com/927/)\\n\\nNot sure how hard is to define a sort of standard LLM models can abide by, so you get similar behavior given the same prompt. that will make plug and play a breeze.\\n\\nFor the costs of running large model in the cloud, openai for example is not profitable yet (5B$ loss in 2024), which means today's cheap cost of using their services are subsidized by investor's money. the day they decide they want to make money prices will not be the same","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkuu4f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;valid point!, reminds me of the standards meme &lt;a href=\\"https://xkcd.com/927/\\"&gt;https://xkcd.com/927/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Not sure how hard is to define a sort of standard LLM models can abide by, so you get similar behavior given the same prompt. that will make plug and play a breeze.&lt;/p&gt;\\n\\n&lt;p&gt;For the costs of running large model in the cloud, openai for example is not profitable yet (5B$ loss in 2024), which means today&amp;#39;s cheap cost of using their services are subsidized by investor&amp;#39;s money. the day they decide they want to make money prices will not be the same&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkuu4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731842828,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkqkbl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"heftybyte","can_mod_post":false,"created_utc":1731840036,"send_replies":true,"parent_id":"t3_1gt9f5y","score":17,"author_fullname":"t2_4d8hj39","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well if you want to get high quality and high accuracy results you’re mostly going to rely on a really large model which can’t be run locally anyway and will also have cost associated with running in the cloud.\\n\\nAlso prompt engineering has different results across models so swapping out an LLM might break things somewhat or be less reliable. Smaller open source models are even more sensitive to this because they don’t generalize as well. Even if you test against open source and local models, you won’t be able to have prompts that work well across all model options that people might want to use.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkqkbl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well if you want to get high quality and high accuracy results you’re mostly going to rely on a really large model which can’t be run locally anyway and will also have cost associated with running in the cloud.&lt;/p&gt;\\n\\n&lt;p&gt;Also prompt engineering has different results across models so swapping out an LLM might break things somewhat or be less reliable. Smaller open source models are even more sensitive to this because they don’t generalize as well. Even if you test against open source and local models, you won’t be able to have prompts that work well across all model options that people might want to use.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkqkbl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731840036,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlwsa4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"my_name_isnt_clever","can_mod_post":false,"send_replies":false,"parent_id":"t1_lxl0ev2","score":11,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If the person/org making the project only uses OpenAI there is nothing wrong with developing it that way. We're all being broken records in this thread but again - that's what open source is for. They're not obligated to spend their own time on features they wouldn't use.","edited":false,"author_flair_css_class":null,"name":"t1_lxlwsa4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the person/org making the project only uses OpenAI there is nothing wrong with developing it that way. We&amp;#39;re all being broken records in this thread but again - that&amp;#39;s what open source is for. They&amp;#39;re not obligated to spend their own time on features they wouldn&amp;#39;t use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlwsa4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731859441,"author_flair_text":null,"collapsed":false,"created_utc":1731859441,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlhf7o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Paulonemillionand3","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxlh56t","score":7,"author_fullname":"t2_mcapx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"fork it then","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_lxlhf7o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;fork it then&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlhf7o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853908,"author_flair_text":null,"treatment_tags":[],"created_utc":1731853908,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlh56t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxl34t0","score":2,"author_fullname":"t2_h4h2az0s","approved_by":null,"mod_note":null,"all_awardings":[],"body":"yep sure thing can do!, but good luck convincing the project author to restructure it to support custom models/prompts/calls.\\n\\nAs said by someone else here, this mainly for enthusiasts running \\"good enough\\" models on their hardware, so smaller niche","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_lxlh56t","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yep sure thing can do!, but good luck convincing the project author to restructure it to support custom models/prompts/calls.&lt;/p&gt;\\n\\n&lt;p&gt;As said by someone else here, this mainly for enthusiasts running &amp;quot;good enough&amp;quot; models on their hardware, so smaller niche&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlh56t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853797,"author_flair_text":null,"treatment_tags":[],"created_utc":1731853797,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl34t0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dydhaw","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxl0ev2","score":10,"author_fullname":"t2_cexuk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"if it could be easily fixed, then you can easily fix it yourself! that's the beauty of open source","edited":false,"author_flair_css_class":null,"name":"t1_lxl34t0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if it could be easily fixed, then you can easily fix it yourself! that&amp;#39;s the beauty of open source&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gt9f5y","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl34t0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731847610,"author_flair_text":null,"collapsed":false,"created_utc":1731847610,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl0ev2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkxs05","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I can give the example of crewAI, (tested it a couple of months ago dunno if it changed). the prompt (hardcoded not customize-able) it was using to run its agents was tailored to gpt4, the agents were working 50% of the time with local models (32b, 70b).\\n\\nThis would have been easily fixed if they tested against one of the most common open LLM model, (I am not expecting it to work with every model not have results as gpt4 but at least it would work)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl0ev2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can give the example of crewAI, (tested it a couple of months ago dunno if it changed). the prompt (hardcoded not customize-able) it was using to run its agents was tailored to gpt4, the agents were working 50% of the time with local models (32b, 70b).&lt;/p&gt;\\n\\n&lt;p&gt;This would have been easily fixed if they tested against one of the most common open LLM model, (I am not expecting it to work with every model not have results as gpt4 but at least it would work)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl0ev2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731846158,"author_flair_text":null,"treatment_tags":[],"created_utc":1731846158,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkxs05","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dydhaw","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkv4y5","score":18,"author_fullname":"t2_cexuk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's kind of a given that local models will perform poorly when compared to SOTA models? not sure what you expect really","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxkxs05","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s kind of a given that local models will perform poorly when compared to SOTA models? not sure what you expect really&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkxs05/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731844649,"author_flair_text":null,"treatment_tags":[],"created_utc":1731844649,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlx5d8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"my_name_isnt_clever","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxl36c4","score":3,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's really the best case scenario for compatibility. Other libraries like anthropic and ollama aren't nearly as flexible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlx5d8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s really the best case scenario for compatibility. Other libraries like anthropic and ollama aren&amp;#39;t nearly as flexible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlx5d8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731859563,"author_flair_text":null,"treatment_tags":[],"created_utc":1731859563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl36c4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ImJacksLackOfBeetus","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkv4y5","score":7,"author_fullname":"t2_mnx4f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; or maybe i wasnt clear\\n\\nProbably this, because the issue you raised, some open-source project asking for an OpenAI key, is not an issue at all.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxl36c4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;or maybe i wasnt clear&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Probably this, because the issue you raised, some open-source project asking for an OpenAI key, is not an issue at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl36c4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731847632,"author_flair_text":null,"treatment_tags":[],"created_utc":1731847632,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxny3f6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dookymagnet","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkv4y5","score":2,"author_fullname":"t2_mh3dovnn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"“Omg. This product doesn’t work with my poorly trained under computed local LLM?? What a waste of energy from the founders.”\\n\\nIt’s open source. Since you’re so capable change it yourself?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxny3f6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;“Omg. This product doesn’t work with my poorly trained under computed local LLM?? What a waste of energy from the founders.”&lt;/p&gt;\\n\\n&lt;p&gt;It’s open source. Since you’re so capable change it yourself?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxny3f6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731883285,"author_flair_text":null,"treatment_tags":[],"created_utc":1731883285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlf0h1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkv4y5","score":2,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Part of it is the use of chat completions. After trying to use those vs text completion, I see where a lot of the lost performance comes from. The openAI api is very stifling and has incompatibilities with local model templating. \\n\\nI get \\"poor\\" performance from models in simple chat. Writing for me, writing their name in every message. Only thing that's different is the format. OpenAI trains for it's api so if you get 5 system messages in a row it doesn't get confused. Local models are tuned without this flexibility.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxlf0h1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Part of it is the use of chat completions. After trying to use those vs text completion, I see where a lot of the lost performance comes from. The openAI api is very stifling and has incompatibilities with local model templating. &lt;/p&gt;\\n\\n&lt;p&gt;I get &amp;quot;poor&amp;quot; performance from models in simple chat. Writing for me, writing their name in every message. Only thing that&amp;#39;s different is the format. OpenAI trains for it&amp;#39;s api so if you get 5 system messages in a row it doesn&amp;#39;t get confused. Local models are tuned without this flexibility.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlf0h1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731852934,"author_flair_text":null,"treatment_tags":[],"created_utc":1731852934,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxoxqeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"johnkapolos","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkv4y5","score":1,"author_fullname":"t2_te4dl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I am speaking about the behavior/performance difference between using gpt4 and an opensource model. it is easy to switch to a local model, but in most cases the tool is not really designed to work with such model and will perform poorly.\\n\\nUnless it's a trivial thing, you need different prompting for different LLMs. Especially important if the program has to parse the response. Moreover, the dev's life is so much easier by using OAI's structured response (which others don't have).\\n\\nIn other words, supporting different LLMs needs work, if they output isn't trivial. If I'm just generating blog posts, sure, no biggie.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxoxqeg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I am speaking about the behavior/performance difference between using gpt4 and an opensource model. it is easy to switch to a local model, but in most cases the tool is not really designed to work with such model and will perform poorly.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Unless it&amp;#39;s a trivial thing, you need different prompting for different LLMs. Especially important if the program has to parse the response. Moreover, the dev&amp;#39;s life is so much easier by using OAI&amp;#39;s structured response (which others don&amp;#39;t have).&lt;/p&gt;\\n\\n&lt;p&gt;In other words, supporting different LLMs needs work, if they output isn&amp;#39;t trivial. If I&amp;#39;m just generating blog posts, sure, no biggie.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxoxqeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731895952,"author_flair_text":null,"treatment_tags":[],"created_utc":1731895952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkv4y5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tabspaces","can_mod_post":false,"created_utc":1731843020,"send_replies":false,"parent_id":"t1_lxkuvs9","score":4,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"half of the comments missed the point, or maybe i wasnt clear, i am not speaking of the use of the openai API, I can work around it in 1000 different way.\\n\\nI am speaking about the behavior/performance difference between using gpt4 and an opensource model. it is easy to switch to a local model, but in most cases the tool is not really designed to work with such model and will perform poorly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkv4y5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;half of the comments missed the point, or maybe i wasnt clear, i am not speaking of the use of the openai API, I can work around it in 1000 different way.&lt;/p&gt;\\n\\n&lt;p&gt;I am speaking about the behavior/performance difference between using gpt4 and an opensource model. it is easy to switch to a local model, but in most cases the tool is not really designed to work with such model and will perform poorly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkv4y5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731843020,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkuvs9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dydhaw","can_mod_post":false,"created_utc":1731842857,"send_replies":true,"parent_id":"t3_1gt9f5y","score":15,"author_fullname":"t2_cexuk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Too bad you can't change it and make it connect to any service you want. If only the Source code was Openly available, like some kind of... free code software","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkuvs9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Too bad you can&amp;#39;t change it and make it connect to any service you want. If only the Source code was Openly available, like some kind of... free code software&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkuvs9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731842857,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlj32g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ConsciousDissonance","can_mod_post":false,"created_utc":1731854560,"send_replies":true,"parent_id":"t3_1gt9f5y","score":3,"author_fullname":"t2_9gca374n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":" Just because it’s open source does not mean that it has to be built with local models in mind and vice versa for closed source. Its likely useful to the person who made it, even if it’s not to you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlj32g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just because it’s open source does not mean that it has to be built with local models in mind and vice versa for closed source. Its likely useful to the person who made it, even if it’s not to you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlj32g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731854560,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlh893","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JakobDylanC","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxlgsv6","score":3,"author_fullname":"t2_bdjxk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I take back what I said slightly - it's not that easy. There are edge case issues that you'll hit with certain providers but not others. Requires good design and a lot of testing to get things working well across the board.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxlh893","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I take back what I said slightly - it&amp;#39;s not that easy. There are edge case issues that you&amp;#39;ll hit with certain providers but not others. Requires good design and a lot of testing to get things working well across the board.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlh893/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853831,"author_flair_text":null,"treatment_tags":[],"created_utc":1731853831,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlgsv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731853658,"send_replies":true,"parent_id":"t1_lxl75p4","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/](https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlgsv6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlgsv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853658,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl75p4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JakobDylanC","can_mod_post":false,"created_utc":1731849531,"send_replies":true,"parent_id":"t3_1gt9f5y","score":2,"author_fullname":"t2_bdjxk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There are so many OpenAI compatible APIs. Even Ollama is OpenAI compatible now. It’s pretty easy to support all of them.\\n\\nI think I did a pretty good job of this in my project: https://github.com/jakobdylanc/llmcord","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl75p4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are so many OpenAI compatible APIs. Even Ollama is OpenAI compatible now. It’s pretty easy to support all of them.&lt;/p&gt;\\n\\n&lt;p&gt;I think I did a pretty good job of this in my project: &lt;a href=\\"https://github.com/jakobdylanc/llmcord\\"&gt;https://github.com/jakobdylanc/llmcord&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl75p4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731849531,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmr77w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FrostyContribution35","can_mod_post":false,"created_utc":1731869392,"send_replies":true,"parent_id":"t3_1gt9f5y","score":2,"author_fullname":"t2_60t745im","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just dig through the code and change the api_url to your local model. Basically every backend (llama.cpp, ollama, vllm, tabbyapi, sglang, Aphrodite, etc) has an OpenAI API compatible endpoint.\\n\\nLike it or not, but the OpenAI API has become the defacto standard for running inference on LLMs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmr77w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just dig through the code and change the api_url to your local model. Basically every backend (llama.cpp, ollama, vllm, tabbyapi, sglang, Aphrodite, etc) has an OpenAI API compatible endpoint.&lt;/p&gt;\\n\\n&lt;p&gt;Like it or not, but the OpenAI API has become the defacto standard for running inference on LLMs&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmr77w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731869392,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxtmuoc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vegetable_Sun_9225","can_mod_post":false,"created_utc":1731965483,"send_replies":true,"parent_id":"t3_1gt9f5y","score":2,"author_fullname":"t2_dsowj79s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Based on the comments and the original post, I think there is a bit of conflation going on. Here are some thoughts and some ways to think about it. \\n\\n\\\\* Most open source projects spawn from a user or group of users who are trying to solve a problem that they already have. They are focused on their goals and want to share it with others who have similar goals.   \\n\\\\* Ideally once in the open, others contribute and make the solution stronger or possibly expanded to solve other problems  \\n\\\\* Most people are GPU poor and it takes more effort to get a smaller model to perform well (without fine tuning) so when it comes to solving problems, it's often bigger bang for the buck to connect it with a bigger model first.  \\n\\\\* A project that uses the OpenAI API spec doesn't mean it has a dependency on OpenAI. The industry as a whole has defacto adopted the OpenAI API spec as the interface for interoperability. It's allowed a lot of projects to integrate with each other with near 0 effort.   \\n\\\\* For projects that use OpenAI directly and only support their models, it's often limited effort to swap the client to vLLM, OpenRouter, Ollama, etc.   \\n\\\\* The rub in the above bullet point comes from implementations that use some key feature of that model (the model has a specific system template for example).  \\n\\\\* When i put together open source projects, like this one for [analyzing videos using llama 11b vision](https://github.com/byjlw/video-analyzer) I structure the code in just a way that it can be used with other backends/clients and different models in the future. But i'm trying to solve a problem, not make it a general use tool that can be used for all models and backends. It's available in the open source for people to submit PRs. \\n\\n  \\nAll this to say, I'd say most of the open source projects out there are well set up to run both locally with Open Source models and Hosted Closed Source models. It may not work out of the box, but the effort tends to be fairly low because we've adopted the OpenAI API spec.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxtmuoc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Based on the comments and the original post, I think there is a bit of conflation going on. Here are some thoughts and some ways to think about it. &lt;/p&gt;\\n\\n&lt;p&gt;* Most open source projects spawn from a user or group of users who are trying to solve a problem that they already have. They are focused on their goals and want to share it with others who have similar goals.&lt;br/&gt;\\n* Ideally once in the open, others contribute and make the solution stronger or possibly expanded to solve other problems&lt;br/&gt;\\n* Most people are GPU poor and it takes more effort to get a smaller model to perform well (without fine tuning) so when it comes to solving problems, it&amp;#39;s often bigger bang for the buck to connect it with a bigger model first.&lt;br/&gt;\\n* A project that uses the OpenAI API spec doesn&amp;#39;t mean it has a dependency on OpenAI. The industry as a whole has defacto adopted the OpenAI API spec as the interface for interoperability. It&amp;#39;s allowed a lot of projects to integrate with each other with near 0 effort.&lt;br/&gt;\\n* For projects that use OpenAI directly and only support their models, it&amp;#39;s often limited effort to swap the client to vLLM, OpenRouter, Ollama, etc.&lt;br/&gt;\\n* The rub in the above bullet point comes from implementations that use some key feature of that model (the model has a specific system template for example).&lt;br/&gt;\\n* When i put together open source projects, like this one for &lt;a href=\\"https://github.com/byjlw/video-analyzer\\"&gt;analyzing videos using llama 11b vision&lt;/a&gt; I structure the code in just a way that it can be used with other backends/clients and different models in the future. But i&amp;#39;m trying to solve a problem, not make it a general use tool that can be used for all models and backends. It&amp;#39;s available in the open source for people to submit PRs. &lt;/p&gt;\\n\\n&lt;p&gt;All this to say, I&amp;#39;d say most of the open source projects out there are well set up to run both locally with Open Source models and Hosted Closed Source models. It may not work out of the box, but the effort tends to be fairly low because we&amp;#39;ve adopted the OpenAI API spec.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxtmuoc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731965483,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxm3hd2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DataPhreak","can_mod_post":false,"created_utc":1731861658,"send_replies":true,"parent_id":"t3_1gt9f5y","score":3,"author_fullname":"t2_4q7zg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/h24wzu6vph1e1.png?width=316&amp;format=png&amp;auto=webp&amp;s=82b7b0c87bf3f05d67325c46f251ef9accf11737\\n\\nKind of a pain to maintain all these apis.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxm3hd2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/h24wzu6vph1e1.png?width=316&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82b7b0c87bf3f05d67325c46f251ef9accf11737\\"&gt;https://preview.redd.it/h24wzu6vph1e1.png?width=316&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82b7b0c87bf3f05d67325c46f251ef9accf11737&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Kind of a pain to maintain all these apis.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm3hd2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731861658,"media_metadata":{"h24wzu6vph1e1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":216,"x":108,"u":"https://preview.redd.it/h24wzu6vph1e1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b653709942e920720eb2dd6257ebad98ed5dd9c"},{"y":432,"x":216,"u":"https://preview.redd.it/h24wzu6vph1e1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=137e0aa8d68eeee06542c06f6af9715ccc6bb302"}],"s":{"y":809,"x":316,"u":"https://preview.redd.it/h24wzu6vph1e1.png?width=316&amp;format=png&amp;auto=webp&amp;s=82b7b0c87bf3f05d67325c46f251ef9accf11737"},"id":"h24wzu6vph1e1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmkwzg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pohui","can_mod_post":false,"created_utc":1731867423,"send_replies":true,"parent_id":"t3_1gt9f5y","score":3,"author_fullname":"t2_87tjx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's still an open source project, you aren't owed an implementation that suits your need. Either implement it yourself, or move on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmkwzg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s still an open source project, you aren&amp;#39;t owed an implementation that suits your need. Either implement it yourself, or move on.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmkwzg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731867423,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":7,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxq3ov1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gaspoweredcat","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxl2gfw","score":1,"author_fullname":"t2_153qitf6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Absolutely true, running CPU inference sucks but these days quantized models allow for moderate systems to run them, most GPUs these days pack 8gb, even the measly 4gb on my laptops internal t1000 can run the likes of 7b models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxq3ov1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Absolutely true, running CPU inference sucks but these days quantized models allow for moderate systems to run them, most GPUs these days pack 8gb, even the measly 4gb on my laptops internal t1000 can run the likes of 7b models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq3ov1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731915539,"author_flair_text":null,"treatment_tags":[],"created_utc":1731915539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl2gfw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1731847267,"send_replies":true,"parent_id":"t1_lxki1n5","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Depends, it's pretty slow if you can't unload to VRAM.","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends, it&amp;#39;s pretty slow if you can&amp;#39;t unload to VRAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl2gfw/","num_reports":null,"locked":false,"name":"t1_lxl2gfw","created":1731847267,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"lxki1n5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gaspoweredcat","can_mod_post":false,"created_utc":1731834319,"send_replies":true,"parent_id":"t1_lxkglcn","score":10,"author_fullname":"t2_153qitf6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i dunno its getting pretty close to easy setup and use for the end user, things like LM studio and Msty make it really easy to run a local model and plenty of them are now useful and runnable on a moderate PC","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxki1n5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i dunno its getting pretty close to easy setup and use for the end user, things like LM studio and Msty make it really easy to run a local model and plenty of them are now useful and runnable on a moderate PC&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxki1n5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731834319,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkq7l5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"aaronr_90","can_mod_post":false,"created_utc":1731839799,"send_replies":true,"parent_id":"t1_lxkglcn","score":-6,"author_fullname":"t2_jbgpw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is the r/localllama not r/localrunningprojectusingtheopenaiapi","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkq7l5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the &lt;a href=\\"/r/localllama\\"&gt;r/localllama&lt;/a&gt; not r/localrunningprojectusingtheopenaiapi&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkq7l5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731839799,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkglcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gt9f5y","score":7,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Will you supply access to your own LLM-server for your apps? Probably not right?\\n\\nLocally hosted LLMs is for us enthusiasts, not the general public, at least not in quite a while.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will you supply access to your own LLM-server for your apps? Probably not right?&lt;/p&gt;\\n\\n&lt;p&gt;Locally hosted LLMs is for us enthusiasts, not the general public, at least not in quite a while.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkglcn/","num_reports":null,"locked":false,"name":"t1_lxkglcn","created":1731833353,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1731833353,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxn0tp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731872437,"send_replies":true,"parent_id":"t1_lxm43ax","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"💯","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxn0tp3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;💯&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxn0tp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731872437,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxm43ax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"schalex88","can_mod_post":false,"created_utc":1731861857,"send_replies":true,"parent_id":"t3_1gt9f5y","score":4,"author_fullname":"t2_4bqgvrmq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I totally feel you on this. It’s weird seeing open source projects rely so much on closed models like GPT-4 or Claude. It kinda goes against the whole open source spirit, right?\\n\\nI get that GPT-4 is powerful and easy to use, but if you’re saying you support local models, at least give them a real shot. Otherwise, it’s just frustrating for those of us wanting a more open ecosystem. Glad you brought this up—definitely an important convo to have!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxm43ax","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I totally feel you on this. It’s weird seeing open source projects rely so much on closed models like GPT-4 or Claude. It kinda goes against the whole open source spirit, right?&lt;/p&gt;\\n\\n&lt;p&gt;I get that GPT-4 is powerful and easy to use, but if you’re saying you support local models, at least give them a real shot. Otherwise, it’s just frustrating for those of us wanting a more open ecosystem. Glad you brought this up—definitely an important convo to have!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm43ax/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731861857,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxploic","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Flamming_Kitty","can_mod_post":false,"created_utc":1731905564,"send_replies":true,"parent_id":"t3_1gt9f5y","score":2,"author_fullname":"t2_a2g91iptd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=8022a4beb5c48bb97a7f9dc3b4398de0bc5671e1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxploic","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8022a4beb5c48bb97a7f9dc3b4398de0bc5671e1\\"&gt;https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=8022a4beb5c48bb97a7f9dc3b4398de0bc5671e1&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxploic/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731905564,"media_metadata":{"r3uhda6fcl1e1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":108,"x":108,"u":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bcef1b89377827c8d4cbcebc93c6eec646ac402"},{"y":216,"x":216,"u":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2fc59e6c7fb43ab66ba39e349ccbe5e582e7f76"},{"y":321,"x":320,"u":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6191d619ea733013f06bb54d51a058a2e5f5fbe"},{"y":642,"x":640,"u":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2a21a291b77c81f9d2ecf5a6c5f47106725c029a"}],"s":{"y":703,"x":700,"u":"https://preview.redd.it/r3uhda6fcl1e1.jpeg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=8022a4beb5c48bb97a7f9dc3b4398de0bc5671e1"},"id":"r3uhda6fcl1e1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlktkf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SatoshiNotMe","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxlj298","score":3,"author_fullname":"t2_mdaj7zqy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Those are my thoughts as well. At the moment my only reason to use litellm is for Anthropic models, which is the only LLM provider that so far has not provided an OpenAI-compatible API (even Gemini recently announced an OpenAI-compatible API).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlktkf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Those are my thoughts as well. At the moment my only reason to use litellm is for Anthropic models, which is the only LLM provider that so far has not provided an OpenAI-compatible API (even Gemini recently announced an OpenAI-compatible API).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlktkf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731855222,"author_flair_text":null,"treatment_tags":[],"created_utc":1731855222,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlj298","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segalord","can_mod_post":false,"send_replies":true,"parent_id":"t1_lxkzhzw","score":3,"author_fullname":"t2_1gcy2sos","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Litellm has a lot of open source connectors which are only available in the paid version for portkey, but it’s hard to tell what goes wrong with litellm because the code is a mess. Portkey is nice if you can afford it, easier setup. Not leaning anyway tho, classic hard to setup and maintain open source project vs semi open source but good product","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lxlj298","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Litellm has a lot of open source connectors which are only available in the paid version for portkey, but it’s hard to tell what goes wrong with litellm because the code is a mess. Portkey is nice if you can afford it, easier setup. Not leaning anyway tho, classic hard to setup and maintain open source project vs semi open source but good product&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlj298/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731854552,"author_flair_text":null,"treatment_tags":[],"created_utc":1731854552,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkzhzw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SatoshiNotMe","can_mod_post":false,"created_utc":1731845643,"send_replies":true,"parent_id":"t1_lxkjudm","score":3,"author_fullname":"t2_mdaj7zqy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Any tradeoff vs litellm?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkzhzw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any tradeoff vs litellm?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkzhzw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731845643,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"lxkjudm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segalord","can_mod_post":false,"created_utc":1731835527,"send_replies":true,"parent_id":"t3_1gt9f5y","score":2,"author_fullname":"t2_1gcy2sos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I use portkey gateway for a unified interface (I use the  paid version tho because I need analytics)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkjudm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use portkey gateway for a unified interface (I use the  paid version tho because I need analytics)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkjudm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731835527,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkq2pc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LahmeriMohamed","can_mod_post":false,"created_utc":1731839708,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_qyphghnb5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"true","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkq2pc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;true&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkq2pc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731839708,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxksdru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WolpertingerRumo","can_mod_post":false,"created_utc":1731841230,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_eju17wbbf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LocalAI-AIO is a complete drop in for OpenAi, with all functions. I’m just experimenting with CPU so I cannot tell you how good it is, but give it a spin, it’s very simple:\\n\\nhttps://localai.io/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxksdru","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LocalAI-AIO is a complete drop in for OpenAi, with all functions. I’m just experimenting with CPU so I cannot tell you how good it is, but give it a spin, it’s very simple:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://localai.io/\\"&gt;https://localai.io/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxksdru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731841230,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkyst1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jeidoz","can_mod_post":false,"created_utc":1731845246,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_11owuvt3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just got used to looking for solutions with Ollama or Onnx keywords. Both of them support the ability to run own local models.\\n\\nIf you need to create an app with self-hosted LLM, you can try a Semantic Core project. It is a kinda ORM for AI with easy to use for text, chat, image, and voice interfaces","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkyst1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just got used to looking for solutions with Ollama or Onnx keywords. Both of them support the ability to run own local models.&lt;/p&gt;\\n\\n&lt;p&gt;If you need to create an app with self-hosted LLM, you can try a Semantic Core project. It is a kinda ORM for AI with easy to use for text, chat, image, and voice interfaces&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkyst1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731845246,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxl2npy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Exotic-Investment110","can_mod_post":false,"created_utc":1731847370,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_7qc0s1b7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I use the free trial on Vertex and with litellm i make the openai compatible key, either with claude or gemini. Additionally, i use lmstudio to make a server with a locally hosted model. \\n\\nOpenwebui in this setup works really really great, as well as other applications asking for an openai compatible key.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl2npy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use the free trial on Vertex and with litellm i make the openai compatible key, either with claude or gemini. Additionally, i use lmstudio to make a server with a locally hosted model. &lt;/p&gt;\\n\\n&lt;p&gt;Openwebui in this setup works really really great, as well as other applications asking for an openai compatible key.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl2npy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731847370,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxllhxa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"khaliiil","can_mod_post":false,"created_utc":1731855474,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_13sum7q7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you name some useful open source projects that only offer openai? I would love to add the local possibility for them, it’d be a fun little project.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxllhxa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you name some useful open source projects that only offer openai? I would love to add the local possibility for them, it’d be a fun little project.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxllhxa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731855474,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxln9pi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GimmePanties","can_mod_post":false,"created_utc":1731856118,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_o42ku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do some work and edit the code to point wherever you like. Pretty much every LLM besides Anthropic supports the OpenAI endpoints.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxln9pi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do some work and edit the code to point wherever you like. Pretty much every LLM besides Anthropic supports the OpenAI endpoints.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxln9pi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731856118,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlrzbn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening-Notice-7041","can_mod_post":false,"created_utc":1731857791,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_867cixm4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As a developer it is just kind of the easiest and cheapest option out there right now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlrzbn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a developer it is just kind of the easiest and cheapest option out there right now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlrzbn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731857791,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxm49cp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"schalex88","can_mod_post":false,"created_utc":1731861913,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_4bqgvrmq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I totally feel you on this. It’s weird seeing open source projects rely so much on closed models like GPT-4 or Claude. It kinda goes against the whole open source spirit, right?\\n\\nI get that GPT-4 is powerful and easy to use, but if you’re saying you support local models, at least give them a real shot. Otherwise, it’s just frustrating for those of us wanting a more open ecosystem. Glad you brought this up—definitely an important convo to have!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxm49cp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I totally feel you on this. It’s weird seeing open source projects rely so much on closed models like GPT-4 or Claude. It kinda goes against the whole open source spirit, right?&lt;/p&gt;\\n\\n&lt;p&gt;I get that GPT-4 is powerful and easy to use, but if you’re saying you support local models, at least give them a real shot. Otherwise, it’s just frustrating for those of us wanting a more open ecosystem. Glad you brought this up—definitely an important convo to have!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxm49cp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731861913,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmkq90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1731867363,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most of my opensource project require an OpenAI api key, but they work perfectly with local models served through an openai API like vllm,llama.cpp server, tabbyapi, etc. It gives the option to use whatever LLM you want, you just specify the base URL, preprompt format and that's it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmkq90","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most of my opensource project require an OpenAI api key, but they work perfectly with local models served through an openai API like vllm,llama.cpp server, tabbyapi, etc. It gives the option to use whatever LLM you want, you just specify the base URL, preprompt format and that&amp;#39;s it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmkq90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731867363,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmlby3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Built couple of projects here and thee (non are popular by anymeans) but I always use litellm as the llm connector and make so that people can use what they want to (litellms support 100+ provider)","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Built couple of projects here and thee (non are popular by anymeans) but I always use litellm as the llm connector and make so that people can use what they want to (litellms support 100+ provider)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmlby3/","num_reports":null,"locked":false,"name":"t1_lxmlby3","created":1731867555,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1731867555,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1gt9f5y","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmoguk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Yeah, fr.\\n\\nA while back, I got all excited about some compute saving method, fell for the idea. Wasted time looking into it only to find that it involved cloud gpu.","edited":1731872283,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, fr.&lt;/p&gt;\\n\\n&lt;p&gt;A while back, I got all excited about some compute saving method, fell for the idea. Wasted time looking into it only to find that it involved cloud gpu.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmoguk/","num_reports":null,"locked":false,"name":"t1_lxmoguk","created":1731868546,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1731868546,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmot9c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Murky_Mountain_97","can_mod_post":false,"created_utc":1731868652,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_c1t6569u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just use solo-server and it works without any API KEYs because it runs locally, pretty good for prototyping and hackathons ⚡️","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmot9c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just use solo-server and it works without any API KEYs because it runs locally, pretty good for prototyping and hackathons ⚡️&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmot9c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731868652,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxmpphv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"avianio","can_mod_post":false,"created_utc":1731868928,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_rzn5v54i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is the exact reason we're trying to make our APIs 1:1 compatible with OpenAI. As long as you can switch the API url, you can switch to Open Source.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxmpphv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the exact reason we&amp;#39;re trying to make our APIs 1:1 compatible with OpenAI. As long as you can switch the API url, you can switch to Open Source.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxmpphv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731868928,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxn4ruq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"novexion","can_mod_post":false,"created_utc":1731873737,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_5acalax1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it’s open source you need only change a couple lines to switch providers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxn4ruq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it’s open source you need only change a couple lines to switch providers&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxn4ruq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731873737,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxnl2gk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"artificial_genius","can_mod_post":false,"created_utc":1731878960,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_gqcxnnmr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it has openai in Python you can just export a different endpoint and it will connect to say your text-gen. I got a lot of those only works on openai things to run locally like that. Feel free to ask Claude about it because it will help you fix your issues and understand how to.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxnl2gk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it has openai in Python you can just export a different endpoint and it will connect to say your text-gen. I got a lot of those only works on openai things to run locally like that. Feel free to ask Claude about it because it will help you fix your issues and understand how to.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnl2gk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731878960,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxnm4c2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CalangoVelho","can_mod_post":false,"created_utc":1731879307,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_uxp2xkt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use LiteLLM proxy and route it to whatever you want","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxnm4c2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use LiteLLM proxy and route it to whatever you want&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxnm4c2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731879307,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxo9zr1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BokuNoToga","can_mod_post":false,"created_utc":1731887440,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_ygor84zdt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lmao for fr","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxo9zr1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lmao for fr&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxo9zr1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731887440,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxovbs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Abishek_1999","can_mod_post":false,"created_utc":1731895056,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_78733u0cu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can tweak it. Set base url to groqs. Then you can put groqs api key instead. It's what I do. Openai compliance ftw","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxovbs8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can tweak it. Set base url to groqs. Then you can put groqs api key instead. It&amp;#39;s what I do. Openai compliance ftw&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxovbs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731895056,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxphwzj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"justintime777777","can_mod_post":false,"created_utc":1731903917,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_fj0wjvdc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What’s the issue, just point it at your Ollama OpenAI endpoint.\\n\\nIf they don’t support it custom urls…\\nIt’s open source just fix it, \\nEven if you can’t code literally just paste the code into your favorite llm and tell it the details of your ollama endpoint.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxphwzj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What’s the issue, just point it at your Ollama OpenAI endpoint.&lt;/p&gt;\\n\\n&lt;p&gt;If they don’t support it custom urls…\\nIt’s open source just fix it, \\nEven if you can’t code literally just paste the code into your favorite llm and tell it the details of your ollama endpoint.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxphwzj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731903917,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpqox2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1731907988,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_79slapln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you tried bolt with Llama3.2:3b  and was not impressed, am I right? :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxpqox2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you tried bolt with Llama3.2:3b  and was not impressed, am I right? :D&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpqox2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731907988,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxprntc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Plane_Past129","can_mod_post":false,"created_utc":1731908491,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_7skklds16","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"lmao","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxprntc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lmao&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxprntc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731908491,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpx9wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jascha_eng","can_mod_post":false,"created_utc":1731911611,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_orzu2qddt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Honestly, as someone working on such a project. I didn't really realize how similar the APIs of all the providers are and that there are projects such as litellm which really make connection other models easy: [https://github.com/BerriAI/litellm](https://github.com/BerriAI/litellm)\\n\\nI assume this will improve soon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxpx9wo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly, as someone working on such a project. I didn&amp;#39;t really realize how similar the APIs of all the providers are and that there are projects such as litellm which really make connection other models easy: &lt;a href=\\"https://github.com/BerriAI/litellm\\"&gt;https://github.com/BerriAI/litellm&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I assume this will improve soon.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpx9wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731911611,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxpzzxw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kspviswaphd","can_mod_post":false,"created_utc":1731913221,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_te6m4m4y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Meme is spot on 😂","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxpzzxw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meme is spot on 😂&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxpzzxw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731913221,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxq4js8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mokeysurfer","can_mod_post":false,"created_utc":1731916098,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_2jtmfgc2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think though yes you can rectify this. A good solution is to make a library that abstracts the call to API endpoints such that a developer doesn't need to worry about which models to support, can set a default model, and users can easily configure a different one. Maybe I give it a shot myself.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxq4js8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think though yes you can rectify this. A good solution is to make a library that abstracts the call to API endpoints such that a developer doesn&amp;#39;t need to worry about which models to support, can set a default model, and users can easily configure a different one. Maybe I give it a shot myself.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq4js8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731916098,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxq7nc0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FitContribution2946","can_mod_post":false,"created_utc":1731918130,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_19p7mwt8h7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i use openRouter for my projects for people who cant do local","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxq7nc0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i use openRouter for my projects for people who cant do local&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq7nc0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731918130,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxq8pu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cr4yfish1","can_mod_post":false,"created_utc":1731918843,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_lhq184yk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Agree. I’m building an AI app right now and added an option to use your own ollama endpoint because of this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxq8pu1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree. I’m building an AI app right now and added an option to use your own ollama endpoint because of this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxq8pu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731918843,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxqfsaw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thistleknot","can_mod_post":false,"created_utc":1731923641,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_18ipm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well they are the industry leader\\n\\n\\nIts very easy to setup an open ai compatible endpoint that acts like openai but sends to your local lm\\n\\n\\nI use text generation webui but there are other tools","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxqfsaw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well they are the industry leader&lt;/p&gt;\\n\\n&lt;p&gt;Its very easy to setup an open ai compatible endpoint that acts like openai but sends to your local lm&lt;/p&gt;\\n\\n&lt;p&gt;I use text generation webui but there are other tools&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqfsaw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731923641,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxqhh6z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"markusrg","can_mod_post":false,"created_utc":1731924761,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_aanjvbbf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It would be interesting to just have an OS-level proxy that intercepts calls to OpenAI/Anthropic/Google and just directs traffic to wherever you choose instead. Would make it trivial to redirect to llama-server and friends without having to mess with tool-specific options/config/code. You could even make it per-tool by inspecting the requests.\\n\\nMaybe something like this exists already? Anyone know?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxqhh6z","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It would be interesting to just have an OS-level proxy that intercepts calls to OpenAI/Anthropic/Google and just directs traffic to wherever you choose instead. Would make it trivial to redirect to llama-server and friends without having to mess with tool-specific options/config/code. You could even make it per-tool by inspecting the requests.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe something like this exists already? Anyone know?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxqhh6z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731924761,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxrp7l7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FarVision5","can_mod_post":false,"created_utc":1731944282,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_7876y6xx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I run across many lazy developers that throw in openai and call it a day.  Fortunately, newer products like Windsurf from Codium (new!) are amazingly performant. I've had it refactor the entire codebase to use other things like Gemini and I'm sure it could go local.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxrp7l7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I run across many lazy developers that throw in openai and call it a day.  Fortunately, newer products like Windsurf from Codium (new!) are amazingly performant. I&amp;#39;ve had it refactor the entire codebase to use other things like Gemini and I&amp;#39;m sure it could go local.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxrp7l7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731944282,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxrrfjo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"6d656c6c6f","can_mod_post":false,"created_utc":1731944994,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_2on9boi6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":" If the people create the \\"open source\\" projects are actually opeanai employees (or salt altman) to use and pay?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxrrfjo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the people create the &amp;quot;open source&amp;quot; projects are actually opeanai employees (or salt altman) to use and pay?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxrrfjo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731944994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxtjln7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SnooPeanuts1152","can_mod_post":false,"created_utc":1731964501,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_2gf04eba","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you can always add that feature since it's open source. look at [bolt.new](http://bolt.new) as a example. It's free and uses claude but it's open source and someone made it work with ollama.\\n\\nSo if the tool gets enough traction, just wait til someone creates a fork that works with local llms if you can't do it yourself.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxtjln7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can always add that feature since it&amp;#39;s open source. look at &lt;a href=\\"http://bolt.new\\"&gt;bolt.new&lt;/a&gt; as a example. It&amp;#39;s free and uses claude but it&amp;#39;s open source and someone made it work with ollama.&lt;/p&gt;\\n\\n&lt;p&gt;So if the tool gets enough traction, just wait til someone creates a fork that works with local llms if you can&amp;#39;t do it yourself.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxtjln7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731964501,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxwjjhg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ChobPT","can_mod_post":false,"created_utc":1732009682,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_2q6j4oox","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Am I the only one thinking about the fact that some of the most used interfaces use the OpenAI API scheme, so one would only have to change the host?\\n\\n\\n\\nAm I missing something?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxwjjhg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Am I the only one thinking about the fact that some of the most used interfaces use the OpenAI API scheme, so one would only have to change the host?&lt;/p&gt;\\n\\n&lt;p&gt;Am I missing something?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxwjjhg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732009682,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxwxizl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Warhouse512","can_mod_post":false,"created_utc":1732017967,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_j4dn9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LiteLLM is a thing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxwxizl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LiteLLM is a thing&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxwxizl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732017967,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxyykam","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmymckeegan","can_mod_post":false,"created_utc":1732042308,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_o6yjgbe3w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The API specs for OpenAI are literally the same as most other providers including Groq, Mistral, etc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxyykam","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The API specs for OpenAI are literally the same as most other providers including Groq, Mistral, etc&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxyykam/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732042308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lykqk8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"professor-studio","can_mod_post":false,"created_utc":1732368942,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_444yo4zn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"guys,can somebody explain or even create a small tutorial ? I have some free but closed source programs which using OpenAI only api (so you can’t change url,only key). Are there any easy methods to make proxy from this program to local lmstudio ? preferable only gui programs. I have proxifier","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lykqk8k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;guys,can somebody explain or even create a small tutorial ? I have some free but closed source programs which using OpenAI only api (so you can’t change url,only key). Are there any easy methods to make proxy from this program to local lmstudio ? preferable only gui programs. I have proxifier&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lykqk8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732368942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m2axtnf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zby","can_mod_post":false,"created_utc":1734338896,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_1wzjm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is because the compatibility layers suck: [https://zzbbyy.substack.com/p/what-is-a-response](https://zzbbyy.substack.com/p/what-is-a-response)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m2axtnf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is because the compatibility layers suck: &lt;a href=\\"https://zzbbyy.substack.com/p/what-is-a-response\\"&gt;https://zzbbyy.substack.com/p/what-is-a-response&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/m2axtnf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1734338896,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkp4e1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"niceman1212","can_mod_post":false,"created_utc":1731839068,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_2a910ior","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Almost every app I’ve seen has a way to override the endpoint???","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkp4e1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Almost every app I’ve seen has a way to override the endpoint???&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkp4e1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731839068,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkro7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacoballessio","can_mod_post":false,"created_utc":1731840767,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_pyjfc2u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Open AI is usually easiest to set up. The projects you're talking about are open source tho, so if you wanna have LLaMA support you can add it yourself","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkro7f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Open AI is usually easiest to set up. The projects you&amp;#39;re talking about are open source tho, so if you wanna have LLaMA support you can add it yourself&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkro7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731840767,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlgrhb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731853642,"send_replies":true,"parent_id":"t1_lxl8wtn","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/](https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlgrhb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlgrhb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853642,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxl8wtn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SuddenPoem2654","can_mod_post":false,"created_utc":1731850307,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_18xe43vfow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No one need to test their code on 'Open Models'.  Everyone and their brother now has an **Openai** compatible endpoint, and thankfully we are settling on that format it looks like, instead of everyone creating something different.\\n\\nWant your own endpoint? Load up LM Studio.  Or write your own. Or edit an existing.\\n\\nits literally one line of code to change.   Problem I have is local models until very recently are kinda seen as toys, and not production ready.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl8wtn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No one need to test their code on &amp;#39;Open Models&amp;#39;.  Everyone and their brother now has an &lt;strong&gt;Openai&lt;/strong&gt; compatible endpoint, and thankfully we are settling on that format it looks like, instead of everyone creating something different.&lt;/p&gt;\\n\\n&lt;p&gt;Want your own endpoint? Load up LM Studio.  Or write your own. Or edit an existing.&lt;/p&gt;\\n\\n&lt;p&gt;its literally one line of code to change.   Problem I have is local models until very recently are kinda seen as toys, and not production ready.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl8wtn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731850307,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxlgoj3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1731853609,"send_replies":true,"parent_id":"t1_lxlefgh","score":1,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/](https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlgoj3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1gt9f5y/comment/lxkv4y5/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlgoj3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731853609,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lxlefgh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DogeDrivenDesign","can_mod_post":false,"created_utc":1731852691,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_ge0dpxqy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"skill issue, use litellm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxlefgh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;skill issue, use litellm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxlefgh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731852691,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxny7fz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oOaurOra","can_mod_post":false,"created_utc":1731883323,"send_replies":true,"parent_id":"t3_1gt9f5y","score":1,"author_fullname":"t2_19n4s45u81","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"lol. it’s OPEN SOURCE. Just change it. 🤦🏼","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxny7fz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol. it’s OPEN SOURCE. Just change it. 🤦🏼&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxny7fz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731883323,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkob2y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mintybadgerme","can_mod_post":false,"created_utc":1731838527,"send_replies":true,"parent_id":"t3_1gt9f5y","score":0,"author_fullname":"t2_r6grz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://nexa.ai/  ??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkob2y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://nexa.ai/\\"&gt;https://nexa.ai/&lt;/a&gt;  ??&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkob2y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838527,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxl8w6y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SuddenPoem2654","can_mod_post":false,"created_utc":1731850300,"send_replies":true,"parent_id":"t3_1gt9f5y","score":0,"author_fullname":"t2_18xe43vfow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No one need to test their code on 'Open Models'.  Everyone and their brother now has an **Openai** compatible endpoint, and thankfully we are settling on that format it looks like, instead of everyone creating something different.\\n\\nWant your own endpoint? Load up LM Studio.  Or write your own. Or edit an existing.\\n\\nits literally one line of code to change.   Problem I have is local models until very recently are kinda seen as toys, and not production ready.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxl8w6y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No one need to test their code on &amp;#39;Open Models&amp;#39;.  Everyone and their brother now has an &lt;strong&gt;Openai&lt;/strong&gt; compatible endpoint, and thankfully we are settling on that format it looks like, instead of everyone creating something different.&lt;/p&gt;\\n\\n&lt;p&gt;Want your own endpoint? Load up LM Studio.  Or write your own. Or edit an existing.&lt;/p&gt;\\n\\n&lt;p&gt;its literally one line of code to change.   Problem I have is local models until very recently are kinda seen as toys, and not production ready.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxl8w6y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731850300,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lxkohou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Plus_Complaint6157","can_mod_post":false,"created_utc":1731838648,"send_replies":true,"parent_id":"t1_lxko7bk","score":-2,"author_fullname":"t2_57wgmdg01","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Uncaught Error: Minified React error #419;\\n\\n'**The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.**\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxkohou","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Uncaught Error: Minified React error #419;&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#39;&lt;strong&gt;The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.&lt;/strong&gt;&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gt9f5y","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxkohou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838648,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"lxko7bk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Plus_Complaint6157","can_mod_post":false,"created_utc":1731838457,"send_replies":true,"parent_id":"t3_1gt9f5y","score":-4,"author_fullname":"t2_57wgmdg01","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/v09iiqpqsf1e1.png?width=711&amp;format=png&amp;auto=webp&amp;s=1f1ee87bdedc1d44c88bedc03ec0bf5e74bcd842\\n\\nNice frontend, bro.\\n\\nHow much dollars do these frontenders burn per hour?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lxko7bk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/v09iiqpqsf1e1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f1ee87bdedc1d44c88bedc03ec0bf5e74bcd842\\"&gt;https://preview.redd.it/v09iiqpqsf1e1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f1ee87bdedc1d44c88bedc03ec0bf5e74bcd842&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Nice frontend, bro.&lt;/p&gt;\\n\\n&lt;p&gt;How much dollars do these frontenders burn per hour?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gt9f5y/open_source_projectstools_vendor_locking/lxko7bk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1731838457,"media_metadata":{"v09iiqpqsf1e1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":42,"x":108,"u":"https://preview.redd.it/v09iiqpqsf1e1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b67813d3d4d2fb3b2337e323e84c0722b073e8bc"},{"y":84,"x":216,"u":"https://preview.redd.it/v09iiqpqsf1e1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f4739bda08bf62d9ff43a47b2e472d6d94f85e71"},{"y":124,"x":320,"u":"https://preview.redd.it/v09iiqpqsf1e1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=26b9216c608c6bc3d6456478989142f141e4c02d"},{"y":249,"x":640,"u":"https://preview.redd.it/v09iiqpqsf1e1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b55cff8513dc8278bf102fe3186156cbfe80092a"}],"s":{"y":277,"x":711,"u":"https://preview.redd.it/v09iiqpqsf1e1.png?width=711&amp;format=png&amp;auto=webp&amp;s=1f1ee87bdedc1d44c88bedc03ec0bf5e74bcd842"},"id":"v09iiqpqsf1e1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gt9f5y","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
