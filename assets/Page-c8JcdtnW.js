import{j as e}from"./index-cvG704yx.js";import{R as l}from"./RedditPostRenderer-CBthLTAH.js";import"./index-D-GavSZU.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"&gt; Granite-speech-3.3-8b is a compact and efficient speech-language model, specifically designed for automatic speech recognition (ASR) and automatic speech translation (AST). Granite-speech-3.3-8b uses a two-pass design, unlike integrated models that combine speech and language into a single pass. Initial calls to granite-speech-3.3-8b will transcribe audio files into text. To process the transcribed text using the underlying Granite language model, users must make a second call as each step must be explicitly initiated.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Granite-speech-3.3-8b","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1lwztnp","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":null,"ups":66,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_14okit","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":66,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=053d27c16b7a3703e6c44e7947dee7416b794087","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752215624,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"huggingface.co","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Granite-speech-3.3-8b is a compact and efficient speech-language model, specifically designed for automatic speech recognition (ASR) and automatic speech translation (AST). Granite-speech-3.3-8b uses a two-pass design, unlike integrated models that combine speech and language into a single pass. Initial calls to granite-speech-3.3-8b will transcribe audio files into text. To process the transcribed text using the underlying Granite language model, users must make a second call as each step must be explicitly initiated.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/ibm-granite/granite-speech-3.3-8b","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?auto=webp&amp;s=6a3208c0a6f02901382bbd3492727a406bc355d7","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b597cda2512d75e467a9d18009ec6b56f088c226","width":108,"height":58},{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6ca5c778f9d46e7644bcaf275e25c54ed791e4b","width":216,"height":116},{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1466b35cfdeaf83843dfff5de0fd2b2fd99cce5","width":320,"height":172},{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3a3cfa1633e9a330cab59c33f8413530288842b0","width":640,"height":345},{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8f1cb95f3fb7fc5d831f7164e052e20bad2b6c7b","width":960,"height":518},{"url":"https://external-preview.redd.it/qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2830c5eb6c21433c267b36769a91e9f7e7de0cac","width":1080,"height":583}],"variants":{},"id":"qCjJtYOA1xCC4NeAQLlvmQH4l0rYxhSxDnkaBD28QmM"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1lwztnp","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Balance-","discussion_type":null,"num_comments":12,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/","stickied":false,"url":"https://huggingface.co/ibm-granite/granite-speech-3.3-8b","subreddit_subscribers":497503,"created_utc":1752215624,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2laxfc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bjodah","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2k0k0m","score":1,"author_fullname":"t2_atvy2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not a separate model, but an adapter for whisper: [https://github.com/ufal/whisper\\\\_streaming](https://github.com/ufal/whisper_streaming)\\n\\nIt works really nicely, I run [https://github.com/speaches-ai/speaches](https://github.com/speaches-ai/speaches) locally as the backend, I have bound a \\"record\\" function to a key in emacs, and I can dictate anywhere, the latency is on the order of a couple of seconds.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2laxfc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not a separate model, but an adapter for whisper: &lt;a href=\\"https://github.com/ufal/whisper_streaming\\"&gt;https://github.com/ufal/whisper_streaming&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It works really nicely, I run &lt;a href=\\"https://github.com/speaches-ai/speaches\\"&gt;https://github.com/speaches-ai/speaches&lt;/a&gt; locally as the backend, I have bound a &amp;quot;record&amp;quot; function to a key in emacs, and I can dictate anywhere, the latency is on the order of a couple of seconds.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2laxfc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752257183,"author_flair_text":null,"treatment_tags":[],"created_utc":1752257183,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2k0k0m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"elemental-mind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2int7r","score":1,"author_fullname":"t2_zuk73gll6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Any repo for this? Especially streaming voice? Would be interested. Only native streaming model for transcription I find good so far is from Kyutai...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2k0k0m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any repo for this? Especially streaming voice? Would be interested. Only native streaming model for transcription I find good so far is from Kyutai...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2k0k0m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752244186,"author_flair_text":null,"treatment_tags":[],"created_utc":1752244186,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2k2586","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2int7r","score":1,"author_fullname":"t2_8lvrytgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For English only, tho.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2k2586","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For English only, tho.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2k2586/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752244645,"author_flair_text":null,"treatment_tags":[],"created_utc":1752244645,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2int7r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1752224745,"send_replies":true,"parent_id":"t1_n2icyy0","score":3,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The nvidia parakeet model has been able to do real time transcription for a long time now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2int7r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The nvidia parakeet model has been able to do real time transcription for a long time now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2int7r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752224745,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2icyy0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"therealAtten","can_mod_post":false,"created_utc":1752218513,"send_replies":true,"parent_id":"t3_1lwztnp","score":14,"author_fullname":"t2_484a7y1b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Big!! I wish more LLM frontends would implement a dictation function, it makes LLM interaction so much more exciting  \\nEdit: they even have a 2B ASR Model next to their 8B model, this could transcript in real time on an average device..","edited":1752218814,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2icyy0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Big!! I wish more LLM frontends would implement a dictation function, it makes LLM interaction so much more exciting&lt;br/&gt;\\nEdit: they even have a 2B ASR Model next to their 8B model, this could transcript in real time on an average device..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2icyy0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752218513,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwztnp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i9w62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1752216828,"send_replies":true,"parent_id":"t3_1lwztnp","score":7,"author_fullname":"t2_8lvrytgw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"revision 3.3.2 supports multilingual speech inputs in English, French, German, Spanish and Portuguese\\"\\n\\n\\nNice.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i9w62","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;revision 3.3.2 supports multilingual speech inputs in English, French, German, Spanish and Portuguese&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Nice.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2i9w62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752216828,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwztnp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jshup","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Balance-","can_mod_post":false,"created_utc":1752241785,"send_replies":true,"parent_id":"t1_n2ih0uh","score":4,"author_fullname":"t2_14okit","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or: They also have a model that’s a quarter of the size and almost as good!\\n\\nThe glass can be half-full here :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jshup","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or: They also have a model that’s a quarter of the size and almost as good!&lt;/p&gt;\\n\\n&lt;p&gt;The glass can be half-full here :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2jshup/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752241785,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ih0uh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lothariusdark","can_mod_post":false,"created_utc":1752220811,"send_replies":true,"parent_id":"t3_1lwztnp","score":4,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Apache 2.0 license, but its not much better than their 3.3-2B model so thats kinda disappointing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ih0uh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apache 2.0 license, but its not much better than their 3.3-2B model so thats kinda disappointing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2ih0uh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752220811,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwztnp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2j129o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hunting-Succcubus","can_mod_post":false,"created_utc":1752231706,"send_replies":true,"parent_id":"t1_n2j0cen","score":3,"author_fullname":"t2_3wxyen0t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"exl2 when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2j129o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;exl2 when?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2j129o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752231706,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jhhcp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Blue_Dude3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2jckil","score":1,"author_fullname":"t2_anezbbp7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"mini cpm was supported.. but I don't think that will work here","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2jhhcp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mini cpm was supported.. but I don&amp;#39;t think that will work here&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2jhhcp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752238205,"author_flair_text":null,"treatment_tags":[],"created_utc":1752238205,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2jckil","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_-inside-_","can_mod_post":false,"created_utc":1752236456,"send_replies":true,"parent_id":"t1_n2j0cen","score":2,"author_fullname":"t2_gf4vh19m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"does llamacpp support speech input?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jckil","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does llamacpp support speech input?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwztnp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2jckil/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752236456,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2j0cen","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Blue_Dude3","can_mod_post":false,"created_utc":1752231381,"send_replies":true,"parent_id":"t3_1lwztnp","score":3,"author_fullname":"t2_anezbbp7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gguf when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2j0cen","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gguf when?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwztnp/granitespeech338b/n2j0cen/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752231381,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwztnp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
