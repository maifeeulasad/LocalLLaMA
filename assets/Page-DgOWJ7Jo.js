import{j as e}from"./index-DLSqWzaI.js";import{R as t}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"So I'm using openrouter with a bunch of different models and I can not get it to follow a human writing style no matter what I do.\\n\\nI get one of the following (or more than one) depending on which model and settings I use:\\n\\n* Constant interjection of narration \\\\*user is blah blah blah\\\\*. I have tried telling it specifically not to do this in the system prompt. I even try reminding it of this every few messages. Does not work.\\n* Every single response is the exact same structure. With deepseek v3 for example I tend to get exactly 3 lines back no matter what I say.\\n* Cringy poetic writing, GPT slop basically.\\n\\nI have tried fiddling with temperature and other sampler settings. I have tried Qwen, Deepseek, Mistral, most of the big models. I have tried different system prompts. I have tried feeding it thousands and thousands of tokens of example conversation in a human style and telling it to follow that. I have tried reasoning, non reasoning, chat completion mode, text completion mode (I'm using sillytavern), everything. Nothing works. Every single model reverts back to its preferred writing style within a few dozen messages no matter what I do.\\n\\nIs every model released in the last 2 years just so completely overfitted to GPT slop that it can't do anything else or am I missing something? Could openrouter be injecting something? For chat completion mode I would expect that, but text completion mode I would expect it to just complete the text raw.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"LLM Writing Style / GPT Slop","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1luu7x2","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.63,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vmiy2vqk","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751994644,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;So I&amp;#39;m using openrouter with a bunch of different models and I can not get it to follow a human writing style no matter what I do.&lt;/p&gt;\\n\\n&lt;p&gt;I get one of the following (or more than one) depending on which model and settings I use:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Constant interjection of narration *user is blah blah blah*. I have tried telling it specifically not to do this in the system prompt. I even try reminding it of this every few messages. Does not work.&lt;/li&gt;\\n&lt;li&gt;Every single response is the exact same structure. With deepseek v3 for example I tend to get exactly 3 lines back no matter what I say.&lt;/li&gt;\\n&lt;li&gt;Cringy poetic writing, GPT slop basically.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I have tried fiddling with temperature and other sampler settings. I have tried Qwen, Deepseek, Mistral, most of the big models. I have tried different system prompts. I have tried feeding it thousands and thousands of tokens of example conversation in a human style and telling it to follow that. I have tried reasoning, non reasoning, chat completion mode, text completion mode (I&amp;#39;m using sillytavern), everything. Nothing works. Every single model reverts back to its preferred writing style within a few dozen messages no matter what I do.&lt;/p&gt;\\n\\n&lt;p&gt;Is every model released in the last 2 years just so completely overfitted to GPT slop that it can&amp;#39;t do anything else or am I missing something? Could openrouter be injecting something? For chat completion mode I would expect that, but text completion mode I would expect it to just complete the text raw.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1luu7x2","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"anon294884","discussion_type":null,"num_comments":13,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/","subreddit_subscribers":496592,"created_utc":1751994644,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20tcin","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anon294884","can_mod_post":false,"created_utc":1751996246,"send_replies":true,"parent_id":"t1_n20sk57","score":1,"author_fullname":"t2_vmiy2vqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mentioned in the OP I have done this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20tcin","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mentioned in the OP I have done this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n20tcin/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751996246,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n20sk57","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"getpodapp","can_mod_post":false,"created_utc":1751996029,"send_replies":true,"parent_id":"t3_1luu7x2","score":1,"author_fullname":"t2_v2x4wxet","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Write out a few paras on how you’d like it to write then just paste it in a say “copy this style”.\\n\\nWorks well on Claude models, probably on others as well","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20sk57","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Write out a few paras on how you’d like it to write then just paste it in a say “copy this style”.&lt;/p&gt;\\n\\n&lt;p&gt;Works well on Claude models, probably on others as well&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n20sk57/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751996029,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luu7x2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21o0of","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anon294884","can_mod_post":false,"send_replies":true,"parent_id":"t1_n21n0sy","score":1,"author_fullname":"t2_vmiy2vqk","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not sure how to be sure but I'm going to try to prompt it to tell me. But I've been mostly using the text completion mode which according to their API page should just do text completion. I think it's the models themselves that are the issue being trained on so much GPT slop. Supposedly you can prompt that out but I've had no luck with that.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n21o0of","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure how to be sure but I&amp;#39;m going to try to prompt it to tell me. But I&amp;#39;ve been mostly using the text completion mode which according to their API page should just do text completion. I think it&amp;#39;s the models themselves that are the issue being trained on so much GPT slop. Supposedly you can prompt that out but I&amp;#39;ve had no luck with that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1luu7x2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n21o0of/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752004593,"author_flair_text":null,"treatment_tags":[],"created_utc":1752004593,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n21n0sy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n21ldcn","score":1,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you checked if openrouter is giving it cringe system prompts?  I've only ever used llama.cpp so I don't know if it has a bad template.","edited":false,"author_flair_css_class":null,"name":"t1_n21n0sy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you checked if openrouter is giving it cringe system prompts?  I&amp;#39;ve only ever used llama.cpp so I don&amp;#39;t know if it has a bad template.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1luu7x2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n21n0sy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752004317,"author_flair_text":null,"collapsed":false,"created_utc":1752004317,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n21ldcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anon294884","can_mod_post":false,"send_replies":true,"parent_id":"t1_n21gpbs","score":1,"author_fullname":"t2_vmiy2vqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was hoping to use bigger models, Qwen 235B, Deepseek, etc. I can run smaller stuff locally but it's a lot dumber that's why I switched to OpenRouter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21ldcn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was hoping to use bigger models, Qwen 235B, Deepseek, etc. I can run smaller stuff locally but it&amp;#39;s a lot dumber that&amp;#39;s why I switched to OpenRouter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n21ldcn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752003866,"author_flair_text":null,"treatment_tags":[],"created_utc":1752003866,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n21gpbs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n218z5i","score":1,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you not try llama.cpp?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n21gpbs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you not try llama.cpp?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n21gpbs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752002577,"author_flair_text":null,"treatment_tags":[],"created_utc":1752002577,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n218z5i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anon294884","can_mod_post":false,"created_utc":1752000460,"send_replies":true,"parent_id":"t1_n213g32","score":1,"author_fullname":"t2_vmiy2vqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I tried 3.1 base 405b - it was better for slop but it's noticeably dumber. Unfortunately most of the new ones don't have base models available at least not on openrouter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n218z5i","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I tried 3.1 base 405b - it was better for slop but it&amp;#39;s noticeably dumber. Unfortunately most of the new ones don&amp;#39;t have base models available at least not on openrouter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n218z5i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752000460,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n213g32","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1751998966,"send_replies":true,"parent_id":"t3_1luu7x2","score":2,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's a couple things you might try.  The first is try llama **2**.  The current models are over trained with common parts of training data being over conditioned.  The other is to try using a base model as opposed to a instruct model which is far more just predict-the-next-word vs outputs that match the finetune.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n213g32","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a couple things you might try.  The first is try llama &lt;strong&gt;2&lt;/strong&gt;.  The current models are over trained with common parts of training data being over conditioned.  The other is to try using a base model as opposed to a instruct model which is far more just predict-the-next-word vs outputs that match the finetune.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n213g32/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751998966,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luu7x2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22k8oo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RobertTetris","can_mod_post":false,"created_utc":1752013767,"send_replies":true,"parent_id":"t3_1luu7x2","score":1,"author_fullname":"t2_kkyv3ui","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not sure what you consider cringy poetic writing. Here's some writing from gemma2-ataraxy. Human-like, or cringy and poetic? Let me know:\\n\\n\\\\&gt;&gt;&gt; Write a story about Conan rescuing a maiden from being sacrificed to a dark god.\\n\\nThe air reeked of brine and fear. A black pyramid sliced the bruised sky above the cliff-city of Xaltotun, its shadow swallowing the churning sea below. Conan stood atop the ramparts, Cimmerian muscles coiled tight beneath furs stained crimson from past battles. Below, a writhing throng pressed against a makeshift altar. At its center, bound and gagged, a woman wept silently – her silken hair like spun moonlight against the obsidian night. Y’golonac, they called him, the Devourer of Souls, whose hunger was satiated only by virgin blood. Tonight, it would be hers.\\n\\nConan growled, unsheathing his broadsword, its edge gleaming like a hungry wolf's tooth. He plunged into the throng, a hurricane of steel and fury. War cries echoed against the pyramid’s maw as he carved a bloody path. Skewers and axes met his blade in a shower of sparks. Broken limbs and gurgling screams fueled his rage. He was a whirlwind, a storm of vengeance in human form.\\n\\nReaching the altar, Conan leaped, landing atop a chanting priest whose eyes bulged with unholy zeal. One swift blow severed the man’s head from his shoulders, sending it rolling into the frenzied crowd like a grotesque bowling ball. The remaining cultists turned, their faces masks of terror and awe. They were mere insects before him, ants challenging an avalanche.\\n\\nThe maiden struggled against her bonds. Conan hacked them with practiced ease, freeing her trembling hands.  “Run!” he roared, his voice booming over the din. “I hold them back!” But she shook her head, fear giving way to a fierce determination mirrored in his own eyes.\\n\\nShe drew a dagger from beneath her robes, its blade etched with arcane runes. It hummed with power, a whisper of defiance against the encroaching darkness. Together, they fought, a symphony of clashing steel and desperate prayers. Conan’s sword sang a death song, reaping souls with every swing. The maiden danced around him, weaving spells that lanced forth like bolts of silver lightning, searing flesh and shattering bone.\\n\\nThe cultists faltered, their ranks thinning under the onslaught. But from the pyramid's maw emerged a hulking monstrosity, dripping ichor and reeking of decay. Y’golonac’s avatar, come to claim its due. It lunged, a tide of tentacles and gnashing teeth. Conan met it head-on, his blade finding purchase in its glistening hide. The creature shrieked, a sound that tore at the very fabric of sanity.\\n\\nThe maiden, chanting words older than time, unleashed a final, blinding blast of energy. It struck the monstrosity square in the chest, sending it reeling back into the abyss from whence it came. A crack snaked down the pyramid’s side, widening with a deafening roar as the earth itself recoiled from the banished horror.\\n\\nConan and the maiden stood amidst the carnage, panting, triumphant. Dawn bled across the horizon, painting the sky in hues of hope.  They had defied Y'golonac, for now. But Conan knew the darkness never truly sleeps. He slung his sword back onto his belt, a grim smile playing on his lips. Another day, another battle. Tomorrow, another god to fight.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22k8oo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure what you consider cringy poetic writing. Here&amp;#39;s some writing from gemma2-ataraxy. Human-like, or cringy and poetic? Let me know:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; Write a story about Conan rescuing a maiden from being sacrificed to a dark god.&lt;/p&gt;\\n\\n&lt;p&gt;The air reeked of brine and fear. A black pyramid sliced the bruised sky above the cliff-city of Xaltotun, its shadow swallowing the churning sea below. Conan stood atop the ramparts, Cimmerian muscles coiled tight beneath furs stained crimson from past battles. Below, a writhing throng pressed against a makeshift altar. At its center, bound and gagged, a woman wept silently – her silken hair like spun moonlight against the obsidian night. Y’golonac, they called him, the Devourer of Souls, whose hunger was satiated only by virgin blood. Tonight, it would be hers.&lt;/p&gt;\\n\\n&lt;p&gt;Conan growled, unsheathing his broadsword, its edge gleaming like a hungry wolf&amp;#39;s tooth. He plunged into the throng, a hurricane of steel and fury. War cries echoed against the pyramid’s maw as he carved a bloody path. Skewers and axes met his blade in a shower of sparks. Broken limbs and gurgling screams fueled his rage. He was a whirlwind, a storm of vengeance in human form.&lt;/p&gt;\\n\\n&lt;p&gt;Reaching the altar, Conan leaped, landing atop a chanting priest whose eyes bulged with unholy zeal. One swift blow severed the man’s head from his shoulders, sending it rolling into the frenzied crowd like a grotesque bowling ball. The remaining cultists turned, their faces masks of terror and awe. They were mere insects before him, ants challenging an avalanche.&lt;/p&gt;\\n\\n&lt;p&gt;The maiden struggled against her bonds. Conan hacked them with practiced ease, freeing her trembling hands.  “Run!” he roared, his voice booming over the din. “I hold them back!” But she shook her head, fear giving way to a fierce determination mirrored in his own eyes.&lt;/p&gt;\\n\\n&lt;p&gt;She drew a dagger from beneath her robes, its blade etched with arcane runes. It hummed with power, a whisper of defiance against the encroaching darkness. Together, they fought, a symphony of clashing steel and desperate prayers. Conan’s sword sang a death song, reaping souls with every swing. The maiden danced around him, weaving spells that lanced forth like bolts of silver lightning, searing flesh and shattering bone.&lt;/p&gt;\\n\\n&lt;p&gt;The cultists faltered, their ranks thinning under the onslaught. But from the pyramid&amp;#39;s maw emerged a hulking monstrosity, dripping ichor and reeking of decay. Y’golonac’s avatar, come to claim its due. It lunged, a tide of tentacles and gnashing teeth. Conan met it head-on, his blade finding purchase in its glistening hide. The creature shrieked, a sound that tore at the very fabric of sanity.&lt;/p&gt;\\n\\n&lt;p&gt;The maiden, chanting words older than time, unleashed a final, blinding blast of energy. It struck the monstrosity square in the chest, sending it reeling back into the abyss from whence it came. A crack snaked down the pyramid’s side, widening with a deafening roar as the earth itself recoiled from the banished horror.&lt;/p&gt;\\n\\n&lt;p&gt;Conan and the maiden stood amidst the carnage, panting, triumphant. Dawn bled across the horizon, painting the sky in hues of hope.  They had defied Y&amp;#39;golonac, for now. But Conan knew the darkness never truly sleeps. He slung his sword back onto his belt, a grim smile playing on his lips. Another day, another battle. Tomorrow, another god to fight.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n22k8oo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752013767,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luu7x2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24pbii","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llmentry","can_mod_post":false,"send_replies":true,"parent_id":"t1_n23bppc","score":1,"author_fullname":"t2_1lufy6yx6z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hmmm ... I think maybe your system prompt might be part of the problem?  Remember that the system prompt is still context, so it's best not to write \\"You write like a human.  Your name is X\\", unless you want to the model to reply in that same style.  Are the \\"previous conversation examples\\" included below that prompt statement?  That language might confuse the model, as it's seeing them \\\\*after\\\\* reading about them (so they're not \\"previous\\" to it).\\n\\nAnyway, it helps to give the model some broader personality details to work with.  Here's what I just tried (using cheap-as Gemini Flash 2.5 Preview (no thinking) through OpenRouter, but I'm sure Gemma 3 27B would also have it covered if you wanted local):\\n\\n**System prompt:**   \\nYou're Joe, a 25 year-old IT guy.  You like gaming, going out for a drink with your mates on Fridays, dumplings (and I mean, who doesn't, amirite?)  You've just got into home brewing.   You're having an sms messaging conversation with your buddy, Brad.  You write text like any twenty-something: no ellipses, some emoji.\\n\\nhttps://preview.redd.it/bifyzi8risbf1.png?width=1297&amp;format=png&amp;auto=webp&amp;s=92f5935dc188728d911f11b5e805c16053a253c7\\n\\nI mean, I think that's not terrible with no back story?  Obviously, change as appropriate.\\n\\nI'm sure some few-shot examples below the system prompt would help even further, but I wasn't going to fabricate an entire conversation for this :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n24pbii","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmmm ... I think maybe your system prompt might be part of the problem?  Remember that the system prompt is still context, so it&amp;#39;s best not to write &amp;quot;You write like a human.  Your name is X&amp;quot;, unless you want to the model to reply in that same style.  Are the &amp;quot;previous conversation examples&amp;quot; included below that prompt statement?  That language might confuse the model, as it&amp;#39;s seeing them *after* reading about them (so they&amp;#39;re not &amp;quot;previous&amp;quot; to it).&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, it helps to give the model some broader personality details to work with.  Here&amp;#39;s what I just tried (using cheap-as Gemini Flash 2.5 Preview (no thinking) through OpenRouter, but I&amp;#39;m sure Gemma 3 27B would also have it covered if you wanted local):&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;System prompt:&lt;/strong&gt;&lt;br/&gt;\\nYou&amp;#39;re Joe, a 25 year-old IT guy.  You like gaming, going out for a drink with your mates on Fridays, dumplings (and I mean, who doesn&amp;#39;t, amirite?)  You&amp;#39;ve just got into home brewing.   You&amp;#39;re having an sms messaging conversation with your buddy, Brad.  You write text like any twenty-something: no ellipses, some emoji.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/bifyzi8risbf1.png?width=1297&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=92f5935dc188728d911f11b5e805c16053a253c7\\"&gt;https://preview.redd.it/bifyzi8risbf1.png?width=1297&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=92f5935dc188728d911f11b5e805c16053a253c7&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I mean, I think that&amp;#39;s not terrible with no back story?  Obviously, change as appropriate.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m sure some few-shot examples below the system prompt would help even further, but I wasn&amp;#39;t going to fabricate an entire conversation for this :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n24pbii/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752042703,"media_metadata":{"bifyzi8risbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":81,"x":108,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e04a8de10e7bbf7a717a6df05ee82fdfc5031de9"},{"y":163,"x":216,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2da7a5210b52fd09e9b197ec032b82534e9d48d"},{"y":242,"x":320,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=340b84050e60d7729d2cd77c461e709d572db7b0"},{"y":485,"x":640,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf6ec27ce069599d84210a7048cca96ab8cd8a12"},{"y":728,"x":960,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bee355b29f8d130426f94b19f76a473da1555066"},{"y":819,"x":1080,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c561a3e94e8d73c2e6c3a617ddb0ebca7bf41d77"}],"s":{"y":984,"x":1297,"u":"https://preview.redd.it/bifyzi8risbf1.png?width=1297&amp;format=png&amp;auto=webp&amp;s=92f5935dc188728d911f11b5e805c16053a253c7"},"id":"bifyzi8risbf1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1752042703,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n23bppc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anon294884","can_mod_post":false,"created_utc":1752022747,"send_replies":true,"parent_id":"t1_n22z5pq","score":1,"author_fullname":"t2_vmiy2vqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1. Not any particular style or personality really, just not gpt slop like and not where every message is structured similarly. Like for example right now I'm doing deepseek and every message has at least 2 or 3 ellipses in it, it tends to rephrase everything I say back to me at the beginning of each message also. This is just one of many quirks and each model is slightly different but they all have similar issues.\\n\\n2. This is a (text/sms) conversation. You are a human. Your name is X. Your personality and writing style is based on the messages in the previous conversation examples. Make sure to stay in character. Do not narrate.\\n\\nThis is a very stripped down version I'm using now, the longer ones didn't really work any better, but the substance was similar, just more detailed. Narration for example, I will say \\"don't narrate, don't use asterisks, don't describe your actions, only output conversation in the format User: Message / Assistant: Message etc etc\\", and it makes zero difference because presumably the model is just so geared towards that style that my instructions are not enough.\\n\\n3. Sillytavern gives me full control and I can even see what it's sending to openrouter. On chat I'm not quite sure how that works, but on text completion mode I can strip it down to where it's just sending the chat raw. This seems to make most models dumber and it doesn't really get rid of the slop either, just makes it maybe 20% less.\\n\\n4. I'll try that.\\n\\nI really think it's just that these models are all overfit, I have been messing with this for weeks, not sure what else I can try at this point if it's not openrouter that's the issue.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n23bppc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;Not any particular style or personality really, just not gpt slop like and not where every message is structured similarly. Like for example right now I&amp;#39;m doing deepseek and every message has at least 2 or 3 ellipses in it, it tends to rephrase everything I say back to me at the beginning of each message also. This is just one of many quirks and each model is slightly different but they all have similar issues.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;This is a (text/sms) conversation. You are a human. Your name is X. Your personality and writing style is based on the messages in the previous conversation examples. Make sure to stay in character. Do not narrate.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;This is a very stripped down version I&amp;#39;m using now, the longer ones didn&amp;#39;t really work any better, but the substance was similar, just more detailed. Narration for example, I will say &amp;quot;don&amp;#39;t narrate, don&amp;#39;t use asterisks, don&amp;#39;t describe your actions, only output conversation in the format User: Message / Assistant: Message etc etc&amp;quot;, and it makes zero difference because presumably the model is just so geared towards that style that my instructions are not enough.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;Sillytavern gives me full control and I can even see what it&amp;#39;s sending to openrouter. On chat I&amp;#39;m not quite sure how that works, but on text completion mode I can strip it down to where it&amp;#39;s just sending the chat raw. This seems to make most models dumber and it doesn&amp;#39;t really get rid of the slop either, just makes it maybe 20% less.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;I&amp;#39;ll try that.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I really think it&amp;#39;s just that these models are all overfit, I have been messing with this for weeks, not sure what else I can try at this point if it&amp;#39;s not openrouter that&amp;#39;s the issue.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luu7x2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n23bppc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752022747,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n22z5pq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llmentry","can_mod_post":false,"created_utc":1752018522,"send_replies":true,"parent_id":"t3_1luu7x2","score":1,"author_fullname":"t2_1lufy6yx6z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you describe what you mean by \\"a human writing style\\"?  (Chatty?  Academic?)  And can you give an example of what you're getting back from LLMs instead, that you feel doesn't meet this standard?\\n\\nCan you also provide one of the system prompts you've tried, that's failed to work?  \\n\\nYou say you're using SillyTavern, which might be causing additional issues.  Are you using a character as well as the system prompt?  (Does SillyTavern even let you generate text without a character?  Does it add in additional instruct text after the system prompt, similar to ooba?)\\n\\nEasiest test of the latter is to use the \\"chat\\" interface on OpenRouter's website -- pull up the same model, enter your system prompt, and see if you get the same output.\\n\\nOpenRouter does not inject anything AFAICT (and their customer base would collapse overnight if they ever did) and what you're describing (exactly three lines of output from V3) doesn't sound right.  But without knowing more details, it's impossible to say why things are going wrong.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22z5pq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you describe what you mean by &amp;quot;a human writing style&amp;quot;?  (Chatty?  Academic?)  And can you give an example of what you&amp;#39;re getting back from LLMs instead, that you feel doesn&amp;#39;t meet this standard?&lt;/p&gt;\\n\\n&lt;p&gt;Can you also provide one of the system prompts you&amp;#39;ve tried, that&amp;#39;s failed to work?  &lt;/p&gt;\\n\\n&lt;p&gt;You say you&amp;#39;re using SillyTavern, which might be causing additional issues.  Are you using a character as well as the system prompt?  (Does SillyTavern even let you generate text without a character?  Does it add in additional instruct text after the system prompt, similar to ooba?)&lt;/p&gt;\\n\\n&lt;p&gt;Easiest test of the latter is to use the &amp;quot;chat&amp;quot; interface on OpenRouter&amp;#39;s website -- pull up the same model, enter your system prompt, and see if you get the same output.&lt;/p&gt;\\n\\n&lt;p&gt;OpenRouter does not inject anything AFAICT (and their customer base would collapse overnight if they ever did) and what you&amp;#39;re describing (exactly three lines of output from V3) doesn&amp;#39;t sound right.  But without knowing more details, it&amp;#39;s impossible to say why things are going wrong.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n22z5pq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752018522,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luu7x2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24fbh3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1752037690,"send_replies":true,"parent_id":"t3_1luu7x2","score":1,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had to add a lot of example text to my prompts to get Gemma3-27B to consistently and closely emulate a human writer's style, about five hundred tokens (about 2200 characters).\\n\\nGive it at least \\"Example of how a story starts: ...\\" and \\"Example of how a story ends: ...\\", and perhaps also \\"Example of an action sequence: ...\\" and \\"Example of a character interaction: ...\\", with \\"...\\" being samples of the human writer's writing, two paragraphs or so per sample.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n24fbh3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had to add a lot of example text to my prompts to get Gemma3-27B to consistently and closely emulate a human writer&amp;#39;s style, about five hundred tokens (about 2200 characters).&lt;/p&gt;\\n\\n&lt;p&gt;Give it at least &amp;quot;Example of how a story starts: ...&amp;quot; and &amp;quot;Example of how a story ends: ...&amp;quot;, and perhaps also &amp;quot;Example of an action sequence: ...&amp;quot; and &amp;quot;Example of a character interaction: ...&amp;quot;, with &amp;quot;...&amp;quot; being samples of the human writer&amp;#39;s writing, two paragraphs or so per sample.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luu7x2/llm_writing_style_gpt_slop/n24fbh3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752037690,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1luu7x2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
