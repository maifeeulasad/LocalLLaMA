import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF · Hugging Face","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1m71f20","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.85,"author_flair_background_color":null,"ups":57,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lsixf36sr","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":57,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=8d404162721f954167cc891f633466a429b34c96","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753250317,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"huggingface.co","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?auto=webp&amp;s=b0e606fe60c3b427cf1340db7a0ca6006dff3e57","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ad6d1b6c4559472693b7af1de31e24e4a8023a3","width":108,"height":58},{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1145966d2cde6471e76bb43f495683a63b013b72","width":216,"height":116},{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7fff728a74e01125301fc6c9d2699680540ef0a","width":320,"height":172},{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=60e9638973c964d4a82b7f30f192158867f7fc48","width":640,"height":345},{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=350210cdc15e1c044856de883fd8d259a90dd1f0","width":960,"height":518},{"url":"https://external-preview.redd.it/gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9863761bbb4db313f92685d42bb3689971cd9fe8","width":1080,"height":583}],"variants":{},"id":"gwBpjvEsSJP9TEvm8JruyOhsY560jiGO-1v9Go-RAwk"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1m71f20","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"Fun-Wolf-2007","discussion_type":null,"num_comments":29,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/","stickied":false,"url":"https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF","subreddit_subscribers":503757,"created_utc":1753250317,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4o9z5i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Cow1976","can_mod_post":false,"created_utc":1753256256,"send_replies":true,"parent_id":"t1_n4o9q4f","score":4,"author_fullname":"t2_3pwbsmdr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"😄👌","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o9z5i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;😄👌&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4o9z5i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753256256,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4o9q4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Jazzlike_Source_5983","can_mod_post":false,"created_utc":1753256109,"send_replies":true,"parent_id":"t3_1m71f20","score":14,"author_fullname":"t2_ap0ra8pe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"holy GOD this thing this good. Like. CRAZY good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o9q4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;holy GOD this thing this good. Like. CRAZY good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4o9q4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753256109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m71f20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4r0udv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thireus","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qeb3d","score":1,"author_fullname":"t2_8u7n5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice stuff!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4r0udv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice stuff!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4r0udv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753292160,"author_flair_text":null,"treatment_tags":[],"created_utc":1753292160,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qeb3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoneyPowerNexis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qbg7q","score":2,"author_fullname":"t2_635g2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you can call the huggingface api from the tampermonkey script to just get the file data instead of scraping it from the page. \\n\\nHere is my latest generated by Qwen3-235B-A22B-Instruct-2507-Q2_K:\\n\\nhttps://pastebin.com/NHjdNbPe\\n\\nI also added the ability to copy all the download urls for the files in the current directory to the clipboard by clicking on the file size output. I like to get those and use wget to do the downloading.","edited":false,"author_flair_css_class":null,"name":"t1_n4qeb3d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can call the huggingface api from the tampermonkey script to just get the file data instead of scraping it from the page. &lt;/p&gt;\\n\\n&lt;p&gt;Here is my latest generated by Qwen3-235B-A22B-Instruct-2507-Q2_K:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://pastebin.com/NHjdNbPe\\"&gt;https://pastebin.com/NHjdNbPe&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I also added the ability to copy all the download urls for the files in the current directory to the clipboard by clicking on the file size output. I like to get those and use wget to do the downloading.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qeb3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753286020,"author_flair_text":null,"collapsed":false,"created_utc":1753286020,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qbg7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thireus","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pjqum","score":1,"author_fullname":"t2_8u7n5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice thanks. Would be cool if it could automatically click to show more files.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qbg7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice thanks. Would be cool if it could automatically click to show more files.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qbg7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753285239,"author_flair_text":null,"treatment_tags":[],"created_utc":1753285239,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pjqum","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoneyPowerNexis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pbj97","score":2,"author_fullname":"t2_635g2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ok, it only gets the total of whats shown on the page. I have updated it so you can click show more files and it will update the total. I'm using an observer which might hog resources so you could comment out the observer part and just click on the total to have it update. This was just a quick hack because Ive been browsing so many files today and evaluating whether to get them. I didnt think of directories with large numbers of files.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4pjqum","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ok, it only gets the total of whats shown on the page. I have updated it so you can click show more files and it will update the total. I&amp;#39;m using an observer which might hog resources so you could comment out the observer part and just click on the total to have it update. This was just a quick hack because Ive been browsing so many files today and evaluating whether to get them. I didnt think of directories with large numbers of files.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4pjqum/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753277207,"author_flair_text":null,"treatment_tags":[],"created_utc":1753277207,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pbj97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thireus","can_mod_post":false,"created_utc":1753274524,"send_replies":true,"parent_id":"t1_n4ojt80","score":4,"author_fullname":"t2_8u7n5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does it work on this one? https://huggingface.co/Thireus/Kimi-K2-Instruct-THIREUS-BF16-SPECIAL_SPLIT\\n\\nShould be more than 1TB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pbj97","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it work on this one? &lt;a href=\\"https://huggingface.co/Thireus/Kimi-K2-Instruct-THIREUS-BF16-SPECIAL_SPLIT\\"&gt;https://huggingface.co/Thireus/Kimi-K2-Instruct-THIREUS-BF16-SPECIAL_SPLIT&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Should be more than 1TB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4pbj97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753274524,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ojt80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoneyPowerNexis","can_mod_post":false,"created_utc":1753261936,"send_replies":true,"parent_id":"t3_1m71f20","score":7,"author_fullname":"t2_635g2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice. My first bit of code with this model:\\n\\n    // ==UserScript==\\n    // @name         Hugging Face File Size Sum (Optimized)\\n    // @namespace    http://tampermonkey.net/\\n    // @version      0.4\\n    // @description  Sum file sizes on Hugging Face and display total; updates on click and DOM change (optimized for performance)\\n    // @author       You\\n    // @match        https://huggingface.co/*\\n    // @grant        none\\n    // ==/UserScript==\\n    \\n    (function () {\\n      'use strict';\\n    \\n      const SIZE_SELECTOR = 'span.truncate.max-sm\\\\\\\\:text-xs';\\n    \\n      // Create floating display\\n      const totalDiv = document.createElement('div');\\n      totalDiv.style.position = 'fixed';\\n      totalDiv.style.bottom = '10px';\\n      totalDiv.style.right = '10px';\\n      totalDiv.style.backgroundColor = '#f0f0f0';\\n      totalDiv.style.padding = '8px 12px';\\n      totalDiv.style.borderRadius = '6px';\\n      totalDiv.style.fontSize = '14px';\\n      totalDiv.style.fontWeight = 'bold';\\n      totalDiv.style.boxShadow = '0 0 6px rgba(0, 0, 0, 0.15)';\\n      totalDiv.style.zIndex = '1000';\\n      totalDiv.style.cursor = 'pointer';\\n      totalDiv.title = 'Click to recalculate file size total';\\n      totalDiv.textContent = 'Calculating...';\\n      document.body.appendChild(totalDiv);\\n    \\n      // ⏱️ Debounce function to avoid spamming recalculations\\n      function debounce(fn, delay) {\\n        let timeout;\\n        return (...args) =&gt; {\\n          clearTimeout(timeout);\\n          timeout = setTimeout(() =&gt; fn(...args), delay);\\n        };\\n      }\\n    \\n      // File Size Calculation\\n      function calculateTotalSize() {\\n        const elements = document.querySelectorAll(SIZE_SELECTOR);\\n        let total = 0;\\n    \\n        for (const element of elements) {\\n          const text = element.textContent.trim();\\n          const parts = text.split(' ');\\n          if (parts.length !== 2) continue;\\n    \\n          const size = parseFloat(parts[0]);\\n          const unit = parts[1];\\n    \\n          if (!isNaN(size)) {\\n            if (unit === 'GB') total += size;\\n            else if (unit === 'MB') total += size / 1024;\\n            else if (unit === 'TB') total += size * 1024;\\n          }\\n        }\\n    \\n        const formatted = total.toFixed(2) + ' GB';\\n        totalDiv.textContent = formatted;\\n        console.log('[Hugging Face Size] Total:', formatted);\\n      }\\n    \\n      // Manually trigger calc\\n      totalDiv.addEventListener('click', calculateTotalSize);\\n    \\n      // Try to scope observer to container of file list\\n      const targetContainer = document.querySelector('[data-testid=\\"repo-files\\"]') || document.body; // fallback\\n    \\n      const debouncedUpdate = debounce(calculateTotalSize, 500);\\n    \\n      const observer = new MutationObserver(() =&gt; {\\n        debouncedUpdate();\\n      });\\n    \\n      observer.observe(targetContainer, {\\n        childList: true,\\n        subtree: true\\n      });\\n    \\n      // Initial calculation\\n      calculateTotalSize();\\n    })();\\n\\n\\nIts a tampermonkey script that shows the total file size of a huggingface directory [in the bottom right corner](https://imgur.com/a/Qg8ymyp)","edited":1753276995,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ojt80","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice. My first bit of code with this model:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;// ==UserScript==\\n// @name         Hugging Face File Size Sum (Optimized)\\n// @namespace    http://tampermonkey.net/\\n// @version      0.4\\n// @description  Sum file sizes on Hugging Face and display total; updates on click and DOM change (optimized for performance)\\n// @author       You\\n// @match        https://huggingface.co/*\\n// @grant        none\\n// ==/UserScript==\\n\\n(function () {\\n  &amp;#39;use strict&amp;#39;;\\n\\n  const SIZE_SELECTOR = &amp;#39;span.truncate.max-sm\\\\\\\\:text-xs&amp;#39;;\\n\\n  // Create floating display\\n  const totalDiv = document.createElement(&amp;#39;div&amp;#39;);\\n  totalDiv.style.position = &amp;#39;fixed&amp;#39;;\\n  totalDiv.style.bottom = &amp;#39;10px&amp;#39;;\\n  totalDiv.style.right = &amp;#39;10px&amp;#39;;\\n  totalDiv.style.backgroundColor = &amp;#39;#f0f0f0&amp;#39;;\\n  totalDiv.style.padding = &amp;#39;8px 12px&amp;#39;;\\n  totalDiv.style.borderRadius = &amp;#39;6px&amp;#39;;\\n  totalDiv.style.fontSize = &amp;#39;14px&amp;#39;;\\n  totalDiv.style.fontWeight = &amp;#39;bold&amp;#39;;\\n  totalDiv.style.boxShadow = &amp;#39;0 0 6px rgba(0, 0, 0, 0.15)&amp;#39;;\\n  totalDiv.style.zIndex = &amp;#39;1000&amp;#39;;\\n  totalDiv.style.cursor = &amp;#39;pointer&amp;#39;;\\n  totalDiv.title = &amp;#39;Click to recalculate file size total&amp;#39;;\\n  totalDiv.textContent = &amp;#39;Calculating...&amp;#39;;\\n  document.body.appendChild(totalDiv);\\n\\n  // ⏱️ Debounce function to avoid spamming recalculations\\n  function debounce(fn, delay) {\\n    let timeout;\\n    return (...args) =&amp;gt; {\\n      clearTimeout(timeout);\\n      timeout = setTimeout(() =&amp;gt; fn(...args), delay);\\n    };\\n  }\\n\\n  // File Size Calculation\\n  function calculateTotalSize() {\\n    const elements = document.querySelectorAll(SIZE_SELECTOR);\\n    let total = 0;\\n\\n    for (const element of elements) {\\n      const text = element.textContent.trim();\\n      const parts = text.split(&amp;#39; &amp;#39;);\\n      if (parts.length !== 2) continue;\\n\\n      const size = parseFloat(parts[0]);\\n      const unit = parts[1];\\n\\n      if (!isNaN(size)) {\\n        if (unit === &amp;#39;GB&amp;#39;) total += size;\\n        else if (unit === &amp;#39;MB&amp;#39;) total += size / 1024;\\n        else if (unit === &amp;#39;TB&amp;#39;) total += size * 1024;\\n      }\\n    }\\n\\n    const formatted = total.toFixed(2) + &amp;#39; GB&amp;#39;;\\n    totalDiv.textContent = formatted;\\n    console.log(&amp;#39;[Hugging Face Size] Total:&amp;#39;, formatted);\\n  }\\n\\n  // Manually trigger calc\\n  totalDiv.addEventListener(&amp;#39;click&amp;#39;, calculateTotalSize);\\n\\n  // Try to scope observer to container of file list\\n  const targetContainer = document.querySelector(&amp;#39;[data-testid=&amp;quot;repo-files&amp;quot;]&amp;#39;) || document.body; // fallback\\n\\n  const debouncedUpdate = debounce(calculateTotalSize, 500);\\n\\n  const observer = new MutationObserver(() =&amp;gt; {\\n    debouncedUpdate();\\n  });\\n\\n  observer.observe(targetContainer, {\\n    childList: true,\\n    subtree: true\\n  });\\n\\n  // Initial calculation\\n  calculateTotalSize();\\n})();\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Its a tampermonkey script that shows the total file size of a huggingface directory &lt;a href=\\"https://imgur.com/a/Qg8ymyp\\"&gt;in the bottom right corner&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ojt80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753261936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m71f20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4r04gy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PhysicsPast8286","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qxxcn","score":1,"author_fullname":"t2_1c2mqjxrgv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Okay thank you for confirming. I have \\\\~200 GB of VRAM, will I be able to run the 4 bit quantized model? If yes, is it even worth running because of degradation in performance?","edited":false,"author_flair_css_class":null,"name":"t1_n4r04gy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay thank you for confirming. I have ~200 GB of VRAM, will I be able to run the 4 bit quantized model? If yes, is it even worth running because of degradation in performance?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4r04gy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753291966,"author_flair_text":null,"collapsed":false,"created_utc":1753291966,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qxxcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qum7n","score":1,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yup, that's how the numbers work on the simplest level. The model file size and how much vram/ram needed decreases.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qxxcn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yup, that&amp;#39;s how the numbers work on the simplest level. The model file size and how much vram/ram needed decreases.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qxxcn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753291387,"author_flair_text":null,"treatment_tags":[],"created_utc":1753291387,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4qyrmh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qum7n","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any quantization is going to reduce the quality of the output. Even going from 16 to 8 has an impact.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4qyrmh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any quantization is going to reduce the quality of the output. Even going from 16 to 8 has an impact.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qyrmh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753291608,"author_flair_text":null,"treatment_tags":[],"created_utc":1753291608,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4sdxl7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Papabear3339","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4s7ode","score":1,"author_fullname":"t2_7iw5w8ac","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Only one way to find out :)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4sdxl7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Only one way to find out :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4sdxl7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753305921,"author_flair_text":null,"treatment_tags":[],"created_utc":1753305921,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4s7ode","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PhysicsPast8286","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ry7rc","score":1,"author_fullname":"t2_1c2mqjxrgv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have \\\\~200 GB of VRAM, will I be able to run the 4 bit quantized model? If yes, is it even worth running because of degradation in performance?","edited":false,"author_flair_css_class":null,"name":"t1_n4s7ode","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have ~200 GB of VRAM, will I be able to run the 4 bit quantized model? If yes, is it even worth running because of degradation in performance?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4s7ode/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753304117,"author_flair_text":null,"collapsed":false,"created_utc":1753304117,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ry7rc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Papabear3339","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qum7n","score":1,"author_fullname":"t2_7iw5w8ac","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Smaller = dumber just to warn.\\n\\nDon't grab the 1 bit quant and then start complaining when is kind of dumb.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ry7rc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Smaller = dumber just to warn.&lt;/p&gt;\\n\\n&lt;p&gt;Don&amp;#39;t grab the 1 bit quant and then start complaining when is kind of dumb.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ry7rc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753301480,"author_flair_text":null,"treatment_tags":[],"created_utc":1753301480,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qum7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PhysicsPast8286","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4p9yp1","score":0,"author_fullname":"t2_1c2mqjxrgv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Okay, I asked ChatGPT and it came back with:\\n\\n|Quantization|Memory Usage Reduction vs FP16|Description|\\n|:-|:-|:-|\\n|**8-bit (Q8)**|\\\\~40–50% less RAM/VRAM|Very minimal speed/memory trade-off|\\n|**5-bit (Q5\\\\_K\\\\_M, Q5\\\\_0)**|\\\\~60–70% less RAM/VRAM|Good quality vs. size trade-off|\\n|**4-bit (Q4\\\\_K\\\\_M, Q4\\\\_0)**|\\\\~70–80% less RAM/VRAM|Common for local LLMs, big savings|\\n|**3-bit and below**|\\\\~80–90% less RAM/VRAM|Significant degradation in quality|\\n\\nCan you please confirm if it's true?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4qum7n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay, I asked ChatGPT and it came back with:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Quantization&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Memory Usage Reduction vs FP16&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Description&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;8-bit (Q8)&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;~40–50% less RAM/VRAM&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Very minimal speed/memory trade-off&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;5-bit (Q5_K_M, Q5_0)&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;~60–70% less RAM/VRAM&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Good quality vs. size trade-off&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;4-bit (Q4_K_M, Q4_0)&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;~70–80% less RAM/VRAM&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Common for local LLMs, big savings&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;3-bit and below&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;~80–90% less RAM/VRAM&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Significant degradation in quality&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;Can you please confirm if it&amp;#39;s true?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qum7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753290511,"author_flair_text":null,"treatment_tags":[],"created_utc":1753290511,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4p9yp1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"created_utc":1753273975,"send_replies":true,"parent_id":"t1_n4o3shr","score":0,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which GGUF? There's a lot of them bro. Q8 is half of FP16. Q4 is 1/4 of FP16. Q2 1/8. 16 bit, 8 bit, 4 bit, 2 bits etc to represent a parameter. Performance (smartness) is tricker and varies.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4p9yp1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which GGUF? There&amp;#39;s a lot of them bro. Q8 is half of FP16. Q4 is 1/4 of FP16. Q2 1/8. 16 bit, 8 bit, 4 bit, 2 bits etc to represent a parameter. Performance (smartness) is tricker and varies.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4p9yp1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753273975,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4o3shr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PhysicsPast8286","can_mod_post":false,"created_utc":1753252829,"send_replies":true,"parent_id":"t3_1m71f20","score":2,"author_fullname":"t2_1c2mqjxrgv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone explain me by what % the hardware requirements will be dropped if I use Unsloth's GGUF instead of the Non-Quantized Model. Also, by what % the performance drop?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o3shr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone explain me by what % the hardware requirements will be dropped if I use Unsloth&amp;#39;s GGUF instead of the Non-Quantized Model. Also, by what % the performance drop?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4o3shr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753252829,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m71f20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4oj0g7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ohsee","score":4,"author_fullname":"t2_8eneodlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ow thank god","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4oj0g7","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ow thank god&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4oj0g7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753261471,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753261471,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ss9rf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ohsee","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm very interested to see how unquantized variants of smaller models fair against qwen 3 coder @ 4 bit.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ss9rf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m very interested to see how unquantized variants of smaller models fair against qwen 3 coder @ 4 bit.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ss9rf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753310361,"author_flair_text":null,"treatment_tags":[],"created_utc":1753310361,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ohsee","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1753260762,"send_replies":true,"parent_id":"t1_n4of6j2","score":6,"author_fullname":"t2_4gc7hf3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They are working on smaller variants of qwen3 coder ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ohsee","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are working on smaller variants of qwen3 coder &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ohsee/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260762,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4q6lvj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pseudonerv","can_mod_post":false,"created_utc":1753283902,"send_replies":true,"parent_id":"t1_n4of6j2","score":1,"author_fullname":"t2_eerln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait a bit and nvidia might just release their cut down version like nemotron super and ultra. Whether it’s good, you bet","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4q6lvj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait a bit and nvidia might just release their cut down version like nemotron super and ultra. Whether it’s good, you bet&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4q6lvj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753283902,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4qzevj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4qf546","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I run it (4 bit mlx) on a mac studio: 24.99 tok/sec for 146 tokens and 0.33s to first token\\n\\nI use it for a high-context coding assistant (Cline), which uses ~50k tokens before I start the tasking. It seemed to handle it well enough to review my code and write a blog post about it:\\nhttps://convergence.ninja/post/blogs/000016-ForeverFantasyFreshFoundation.md","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4qzevj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I run it (4 bit mlx) on a mac studio: 24.99 tok/sec for 146 tokens and 0.33s to first token&lt;/p&gt;\\n\\n&lt;p&gt;I use it for a high-context coding assistant (Cline), which uses ~50k tokens before I start the tasking. It seemed to handle it well enough to review my code and write a blog post about it:\\n&lt;a href=\\"https://convergence.ninja/post/blogs/000016-ForeverFantasyFreshFoundation.md\\"&gt;https://convergence.ninja/post/blogs/000016-ForeverFantasyFreshFoundation.md&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qzevj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753291778,"author_flair_text":null,"treatment_tags":[],"created_utc":1753291778,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4qf546","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pqciw","score":1,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"At 5 tok/s","edited":false,"author_flair_css_class":null,"name":"t1_n4qf546","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At 5 tok/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m71f20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4qf546/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753286248,"author_flair_text":null,"collapsed":false,"created_utc":1753286248,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pqciw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"createthiscom","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ogsed","score":0,"author_fullname":"t2_ozxxf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I run it at home.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pqciw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I run it at home.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4pqciw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753279260,"author_flair_text":null,"treatment_tags":[],"created_utc":1753279260,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ogsed","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ogp2u","score":1,"author_fullname":"t2_8eneodlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cry’s in sadness , it will be 10 years before hardware will be cheap enough to run this at home","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ogsed","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cry’s in sadness , it will be 10 years before hardware will be cheap enough to run this at home&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ogsed/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260187,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753260187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ogp2u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"un_passant","can_mod_post":false,"created_utc":1753260134,"send_replies":true,"parent_id":"t1_n4of6j2","score":2,"author_fullname":"t2_7rqtc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Of course not.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ogp2u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Of course not.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m71f20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4ogp2u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260134,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4of6j2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"created_utc":1753259250,"send_replies":true,"parent_id":"t3_1m71f20","score":1,"author_fullname":"t2_8eneodlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So question is it possible to merge the experts into one uber expert to make a great 32B model?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4of6j2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So question is it possible to merge the experts into one uber expert to make a great 32B model?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4of6j2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753259250,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m71f20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4o497f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"T2WIN","can_mod_post":false,"created_utc":1753253076,"send_replies":true,"parent_id":"t3_1m71f20","score":-11,"author_fullname":"t2_38ilynpn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"You neer less VRAM as you decrease the size of the weights. For this kind of model, it is often too big to fit in VRAM so instead of reducing VRAM requirements you reduce RAM size requirements. For performance, it is difficult to answer. I suggest you find further info on quantization.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o497f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You neer less VRAM as you decrease the size of the weights. For this kind of model, it is often too big to fit in VRAM so instead of reducing VRAM requirements you reduce RAM size requirements. For performance, it is difficult to answer. I suggest you find further info on quantization.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m71f20/unslothqwen3coder480ba35binstructgguf_hugging_face/n4o497f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753253076,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m71f20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-11}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
