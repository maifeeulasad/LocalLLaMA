import{j as l}from"./index-C_z07ZVC.js";import{R as e}from"./RedditPostRenderer-DPnSR41P.js";import"./index-DKzOAewW.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Are there any locally run LLMs with audio input and text output? I'm not looking for an LLM that simply uses Whisper behind the scenes, as I want it to account for how the user actually speaks. For example, it should be able to detect the user's accent, capture filler words like “ums,” note pauses or gaps, and analyze the timing and delivery of their speech.\\n\\nI know GPT, Gemini can do this but I haven't been able to find something similar thats opensource. ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Audio Input LLM","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ln1m7d","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.8,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_6l4zbp8z","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751156912,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Are there any locally run LLMs with audio input and text output? I&amp;#39;m not looking for an LLM that simply uses Whisper behind the scenes, as I want it to account for how the user actually speaks. For example, it should be able to detect the user&amp;#39;s accent, capture filler words like “ums,” note pauses or gaps, and analyze the timing and delivery of their speech.&lt;/p&gt;\\n\\n&lt;p&gt;I know GPT, Gemini can do this but I haven&amp;#39;t been able to find something similar thats opensource. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ln1m7d","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"TarunRaviYT","discussion_type":null,"num_comments":13,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/","subreddit_subscribers":492929,"created_utc":1751156912,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0c3ex6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Icy-Corgi4757","can_mod_post":false,"created_utc":1751159541,"send_replies":true,"parent_id":"t3_1ln1m7d","score":17,"author_fullname":"t2_kcecqeip9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3n and Qwen 2.5 Omni. Omni does voice out but you can always omit that from the response.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0c3ex6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3n and Qwen 2.5 Omni. Omni does voice out but you can always omit that from the response.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0c3ex6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751159541,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f4x2m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mk321","can_mod_post":false,"created_utc":1751210499,"send_replies":true,"parent_id":"t1_n0c0b48","score":1,"author_fullname":"t2_8vdmr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How to use it with audio?\\n\\nIn Ollama I can only write text.\\n\\nIn LM Studio I can put text or file.\\n\\nThere is any \\"app\\" where I could use audio (best if real time like ChatGPT) in local model? \\n\\nOf course I could write Python app for that. But maybe there is some good app like LM Studio?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f4x2m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How to use it with audio?&lt;/p&gt;\\n\\n&lt;p&gt;In Ollama I can only write text.&lt;/p&gt;\\n\\n&lt;p&gt;In LM Studio I can put text or file.&lt;/p&gt;\\n\\n&lt;p&gt;There is any &amp;quot;app&amp;quot; where I could use audio (best if real time like ChatGPT) in local model? &lt;/p&gt;\\n\\n&lt;p&gt;Of course I could write Python app for that. But maybe there is some good app like LM Studio?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln1m7d","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0f4x2m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751210499,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0c0b48","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1751158336,"send_replies":true,"parent_id":"t3_1ln1m7d","score":5,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3n supports audio, image, video input. You could try that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0c0b48","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3n supports audio, image, video input. You could try that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0c0b48/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751158336,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0c7b7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"created_utc":1751161085,"send_replies":true,"parent_id":"t3_1ln1m7d","score":3,"author_fullname":"t2_e9jh97s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0c7b7d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/\\"&gt;https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0c7b7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751161085,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dttdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"teachersecret","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0d2wgt","score":1,"author_fullname":"t2_ddyte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you look, that does analysis of the audio including the ability to do emotional analysis on phrases that are spoken. You don't get the words out of this, you get the emotional content he's looking for. You would stack that with a traditional whisper workflow to get the data you want.","edited":1751214948,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0dttdr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you look, that does analysis of the audio including the ability to do emotional analysis on phrases that are spoken. You don&amp;#39;t get the words out of this, you get the emotional content he&amp;#39;s looking for. You would stack that with a traditional whisper workflow to get the data you want.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln1m7d","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0dttdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751190785,"author_flair_text":null,"treatment_tags":[],"created_utc":1751190785,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0d2wgt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lochyw","can_mod_post":false,"created_utc":1751174989,"send_replies":true,"parent_id":"t1_n0cbezu","score":1,"author_fullname":"t2_fin6v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is not capable of ASR, it says it run on the page.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0d2wgt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is not capable of ASR, it says it run on the page.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln1m7d","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0d2wgt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751174989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cbezu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"teachersecret","can_mod_post":false,"created_utc":1751162717,"send_replies":true,"parent_id":"t3_1ln1m7d","score":2,"author_fullname":"t2_ddyte","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[https://huggingface.co/nvidia/audio-flamingo-2](https://huggingface.co/nvidia/audio-flamingo-2)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cbezu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/audio-flamingo-2\\"&gt;https://huggingface.co/nvidia/audio-flamingo-2&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0cbezu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751162717,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ckd91","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Temporary_Expert_731","can_mod_post":false,"created_utc":1751166425,"send_replies":true,"parent_id":"t3_1ln1m7d","score":2,"author_fullname":"t2_jggsv8qq4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen2Audio is the closest fit  \\n[https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ckd91","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen2Audio is the closest fit&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct\\"&gt;https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0ckd91/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751166425,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dn6ic","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1751186701,"send_replies":true,"parent_id":"t1_n0bz6u1","score":2,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is Qwen-2.5-Omni which can do all that and more natively.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dn6ic","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is Qwen-2.5-Omni which can do all that and more natively.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln1m7d","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0dn6ic/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751186701,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0bz6u1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Melting735","can_mod_post":false,"created_utc":1751157903,"send_replies":true,"parent_id":"t3_1ln1m7d","score":4,"author_fullname":"t2_5go93eic","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There isn’t really a single open source model that does all that natively. But you can kind of build your own pipeline. Use Whisper for transcription. Then feed that into something like Parselmouth or Gentle for prosody and timing. From there you could send it into a local LLM like Mistral. It's a bit of a DIY setup but totally doable if you're okay with some tweaking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bz6u1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There isn’t really a single open source model that does all that natively. But you can kind of build your own pipeline. Use Whisper for transcription. Then feed that into something like Parselmouth or Gentle for prosody and timing. From there you could send it into a local LLM like Mistral. It&amp;#39;s a bit of a DIY setup but totally doable if you&amp;#39;re okay with some tweaking.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0bz6u1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751157903,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cu2x6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Klutzy-Snow8016","can_mod_post":false,"created_utc":1751170726,"send_replies":true,"parent_id":"t3_1ln1m7d","score":1,"author_fullname":"t2_1d5l610jz3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Phi-4-multimodal\\nhttps://huggingface.co/microsoft/Phi-4-multimodal-instruct","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cu2x6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi-4-multimodal\\n&lt;a href=\\"https://huggingface.co/microsoft/Phi-4-multimodal-instruct\\"&gt;https://huggingface.co/microsoft/Phi-4-multimodal-instruct&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0cu2x6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751170726,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0d2lyo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HealthCorrect","can_mod_post":false,"created_utc":1751174838,"send_replies":true,"parent_id":"t3_1ln1m7d","score":1,"author_fullname":"t2_7w7ujxhh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3n once llama.cpp supports multimodality","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0d2lyo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3n once llama.cpp supports multimodality&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0d2lyo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751174838,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dl3ig","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1751185403,"send_replies":true,"parent_id":"t3_1ln1m7d","score":0,"author_fullname":"t2_79slapln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wait, are you a cop? :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dl3ig","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wait, are you a cop? :D&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln1m7d/audio_input_llm/n0dl3ig/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751185403,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln1m7d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>l.jsx(e,{data:a});export{n as default};
