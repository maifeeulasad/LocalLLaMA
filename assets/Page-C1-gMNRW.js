import{j as e}from"./index-Bu7qcPAU.js";import{R as t}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Just add `/no_think` in the system prompt and the model will mostly stop reasoning \\n\\nYou can also add your own conditions like `when i write /nt it means /no_think` or `always /no_think except if i write /think` if the model is smart enough it will mostly follow your orders\\n\\nTested on qwen3","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Tired of writing /no_think every time you prompt?","link_flair_richtext":[{"e":"text","t":"Tutorial | Guide"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lwwh8s","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.58,"author_flair_background_color":null,"subreddit_type":"public","ups":3,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_rxgre5u8","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Tutorial | Guide","can_mod_post":false,"score":3,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752204167,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Just add &lt;code&gt;/no_think&lt;/code&gt; in the system prompt and the model will mostly stop reasoning &lt;/p&gt;\\n\\n&lt;p&gt;You can also add your own conditions like &lt;code&gt;when i write /nt it means /no_think&lt;/code&gt; or &lt;code&gt;always /no_think except if i write /think&lt;/code&gt; if the model is smart enough it will mostly follow your orders&lt;/p&gt;\\n\\n&lt;p&gt;Tested on qwen3&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"449b05a6-bf8e-11ed-b4bd-66961e47bd50","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#0079d3","id":"1lwwh8s","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Iq1pl","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/","subreddit_subscribers":497504,"created_utc":1752204167,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hvmn9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"muxxington","can_mod_post":false,"created_utc":1752209640,"send_replies":true,"parent_id":"t1_n2hn571","score":1,"author_fullname":"t2_1ktdmsvo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can this get overwritten by system prompt?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hvmn9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can this get overwritten by system prompt?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwwh8s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2hvmn9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752209640,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2hn571","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1752205951,"send_replies":true,"parent_id":"t3_1lwwh8s","score":7,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"there are options to disable thinking, like on llama-server:\\n\\n`--reasoning-budget N controls the amount of thinking allowed; currently only one of: -1 for unrestricted thinking budget, or 0 to disable thinking (default: -1)`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hn571","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;there are options to disable thinking, like on llama-server:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;--reasoning-budget N controls the amount of thinking allowed; currently only one of: -1 for unrestricted thinking budget, or 0 to disable thinking (default: -1)&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2hn571/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752205951,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lwwh8s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ifut3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Chromix_","can_mod_post":false,"created_utc":1752220158,"send_replies":true,"parent_id":"t3_1lwwh8s","score":2,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You\'ve tested it, it works, but it potentially decreases scores in larger benchmarks a bit, since the model isn\'t prompted in the way it was trained.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ifut3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;ve tested it, it works, but it potentially decreases scores in larger benchmarks a bit, since the model isn&amp;#39;t prompted in the way it was trained.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2ifut3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752220158,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwwh8s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jd3k9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"4whatreason","can_mod_post":false,"created_utc":1752236650,"send_replies":true,"parent_id":"t1_n2is7f3","score":1,"author_fullname":"t2_5soxl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes and no. \\\\no_think goes once into the system prompt and adding that is supported by most things you can use to run LLMs, this would have to be inserted specifically at the beginning of of the assistant response every time and the model would continue from there. It likely isn\'t supported by many things to run LLMs out of the box. \\n\\nAlso, models are specifically trained to still give good output when \\\\no_think is enabled. The model has never been trained to give \\"good\\" responses when it always starts with this for every response. So it would work to prevent it from thinking before responding, but you can\'t be as confident about the quality of the models responses.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jd3k9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and no. \\\\no_think goes once into the system prompt and adding that is supported by most things you can use to run LLMs, this would have to be inserted specifically at the beginning of of the assistant response every time and the model would continue from there. It likely isn&amp;#39;t supported by many things to run LLMs out of the box. &lt;/p&gt;\\n\\n&lt;p&gt;Also, models are specifically trained to still give good output when \\\\no_think is enabled. The model has never been trained to give &amp;quot;good&amp;quot; responses when it always starts with this for every response. So it would work to prevent it from thinking before responding, but you can&amp;#39;t be as confident about the quality of the models responses.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwwh8s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2jd3k9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752236650,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2is7f3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kaisurniwurer","can_mod_post":false,"created_utc":1752227253,"send_replies":true,"parent_id":"t3_1lwwh8s","score":2,"author_fullname":"t2_qafso","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wouldn\'t it be easier to always \\"start with\\"?\\n\\n    &lt;think&gt;\\n    Okay, lets do my best.\\n    &lt;/think&gt;","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2is7f3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wouldn&amp;#39;t it be easier to always &amp;quot;start with&amp;quot;?&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;&amp;lt;think&amp;gt;\\nOkay, lets do my best.\\n&amp;lt;/think&amp;gt;\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2is7f3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752227253,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwwh8s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i28dv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"randomanoni","can_mod_post":false,"created_utc":1752212835,"send_replies":true,"parent_id":"t3_1lwwh8s","score":1,"author_fullname":"t2_tmyziykn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wrote this for Aider: https://github.com/Aider-AI/aider/pull/3979\\nI still use it via TabbyAPI, but I forgot if it works via llama.cpp and others.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i28dv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wrote this for Aider: &lt;a href=\\"https://github.com/Aider-AI/aider/pull/3979\\"&gt;https://github.com/Aider-AI/aider/pull/3979&lt;/a&gt;\\nI still use it via TabbyAPI, but I forgot if it works via llama.cpp and others.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2i28dv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752212835,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwwh8s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i918f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1752216370,"send_replies":true,"parent_id":"t3_1lwwh8s","score":1,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just wrote two wrapper-scripts for inferring with Qwen3-32B: `q3t` for \\"thinking\\", and `q3` for no \\"thinking\\".  The latter just explicitly includes the empty \\"think\\" tags in the prompt (which is what the inference stack is doing for you when you specify `/no_think`).\\n\\nhttp://ciar.org/h/q3\\n\\nhttp://ciar.org/h/q3t","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i918f","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just wrote two wrapper-scripts for inferring with Qwen3-32B: &lt;code&gt;q3t&lt;/code&gt; for &amp;quot;thinking&amp;quot;, and &lt;code&gt;q3&lt;/code&gt; for no &amp;quot;thinking&amp;quot;.  The latter just explicitly includes the empty &amp;quot;think&amp;quot; tags in the prompt (which is what the inference stack is doing for you when you specify &lt;code&gt;/no_think&lt;/code&gt;).&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"http://ciar.org/h/q3\\"&gt;http://ciar.org/h/q3&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"http://ciar.org/h/q3t\\"&gt;http://ciar.org/h/q3t&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwwh8s/tired_of_writing_no_think_every_time_you_prompt/n2i918f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752216370,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lwwh8s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),n=()=>e.jsx(t,{data:l});export{n as default};
