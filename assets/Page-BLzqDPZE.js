import{j as e}from"./index-CqAPCjw5.js";import{R as l}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Decided to fine-tune LLaMA on my poor RTX 3060 for a niche task (legal docs, don’t ask why). It's been... an adventure. Fans screaming, temps soaring, and I swear the PC growled at me once.\\n\\nAnyone else trying to make LLaMA behave on local hardware? What’s your setup — LoRA? QLoRA? Brute force and prayers?\\n\\nWould love to hear your hacks, horror stories, or success flexes.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Trying to fine-tune LLaMA locally… and my GPU is crying","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxfs4d","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.85,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_uaotuj04","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752261579,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Decided to fine-tune LLaMA on my poor RTX 3060 for a niche task (legal docs, don’t ask why). It&amp;#39;s been... an adventure. Fans screaming, temps soaring, and I swear the PC growled at me once.&lt;/p&gt;\\n\\n&lt;p&gt;Anyone else trying to make LLaMA behave on local hardware? What’s your setup — LoRA? QLoRA? Brute force and prayers?&lt;/p&gt;\\n\\n&lt;p&gt;Would love to hear your hacks, horror stories, or success flexes.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lxfs4d","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"No_Edge2098","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/","subreddit_subscribers":497825,"created_utc":1752261579,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lsa47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752262261,"send_replies":true,"parent_id":"t3_1lxfs4d","score":8,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Coil whine.  It's super easy to hear on mine because the only fan my PC has is on the GPU, and even then it's way overspec.  It reminds me of old movies with hackers on terminals, where for some reason the computer makes a bunch of noises when outputing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lsa47","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Coil whine.  It&amp;#39;s super easy to hear on mine because the only fan my PC has is on the GPU, and even then it&amp;#39;s way overspec.  It reminds me of old movies with hackers on terminals, where for some reason the computer makes a bunch of noises when outputing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/n2lsa47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752262261,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxfs4d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lwywf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BenniB99","can_mod_post":false,"created_utc":1752263684,"send_replies":true,"parent_id":"t3_1lxfs4d","score":5,"author_fullname":"t2_17xncyy5vl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its the noise the model makes when it is thinking :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lwywf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its the noise the model makes when it is thinking :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/n2lwywf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752263684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxfs4d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2maqzx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Disya321","can_mod_post":false,"created_utc":1752267753,"send_replies":true,"parent_id":"t3_1lxfs4d","score":3,"author_fullname":"t2_9ga497h7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The 8B model will be too slow on a 3060 with small batch sizes, switch to 4B. This can significantly reduce time.  \\nI did SFT on 10k examples and it took 8 hours on a 3060 (qwen3 4b).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2maqzx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The 8B model will be too slow on a 3060 with small batch sizes, switch to 4B. This can significantly reduce time.&lt;br/&gt;\\nI did SFT on 10k examples and it took 8 hours on a 3060 (qwen3 4b).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/n2maqzx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267753,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxfs4d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2okki1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maifee","can_mod_post":false,"created_utc":1752298239,"send_replies":true,"parent_id":"t3_1lxfs4d","score":1,"author_fullname":"t2_1fuhylzi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Care to share your fine-tuning code??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2okki1","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Care to share your fine-tuning code??&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxfs4d/trying_to_finetune_llama_locally_and_my_gpu_is/n2okki1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752298239,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1lxfs4d","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:a});export{r as default};
