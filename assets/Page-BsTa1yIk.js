import{j as e}from"./index-CWmJdUH_.js";import{R as t}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm running it with latest llama-server (llama.cpp) and with the suggested parameters (same as the non-thinking Qwen3 ones)\\n\\nDidn't see that with the \\"old\\" 235b with /no\\\\_think \\n\\nIs that expected?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"In Qwen3-235B-A22B-Instruct-2507-UD-Q4 (unsloth) I'm seeing some \\"but wait\\" and related ones (like kinda questioning and answering itself), were the model seems to \\"think\\" (even when is a non-thinking model and I haven't setup any system prompt), have you seen something similar?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m69sb6","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.82,"author_flair_background_color":null,"subreddit_type":"public","ups":7,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_joxwuyje","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":7,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753177544,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m running it with latest llama-server (llama.cpp) and with the suggested parameters (same as the non-thinking Qwen3 ones)&lt;/p&gt;\\n\\n&lt;p&gt;Didn&amp;#39;t see that with the &amp;quot;old&amp;quot; 235b with /no_think &lt;/p&gt;\\n\\n&lt;p&gt;Is that expected?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m69sb6","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"relmny","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/","subreddit_subscribers":503254,"created_utc":1753177544,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4nl3vq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"relmny","can_mod_post":false,"created_utc":1753243721,"send_replies":true,"parent_id":"t1_n4hxki7","score":1,"author_fullname":"t2_joxwuyje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks.  \\nAlthough I wonder why I've never seen that behavior with the hybrid models with the /no\\\\_think flag...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nl3vq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks.&lt;br/&gt;\\nAlthough I wonder why I&amp;#39;ve never seen that behavior with the hybrid models with the /no_think flag...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m69sb6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4nl3vq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753243721,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4hxki7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResidentPositive4122","can_mod_post":false,"created_utc":1753177965,"send_replies":true,"parent_id":"t3_1m69sb6","score":10,"author_fullname":"t2_10nxrjjgay","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen is known to use \\"cot\\" / tool use / instruct / \\"thinking\\" etc traces in their pretraining data. This is a direct consequence of that pretraining. Their base models aren't truly \\"base\\". Qwen3-base models answer questions, follow instructions, and so on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hxki7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen is known to use &amp;quot;cot&amp;quot; / tool use / instruct / &amp;quot;thinking&amp;quot; etc traces in their pretraining data. This is a direct consequence of that pretraining. Their base models aren&amp;#39;t truly &amp;quot;base&amp;quot;. Qwen3-base models answer questions, follow instructions, and so on.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4hxki7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753177965,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m69sb6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4o2mg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"relmny","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4nwnuv","score":1,"author_fullname":"t2_joxwuyje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Actually I tried without any system prompt (because is non-thinking model) first, then I added the  /no\\\\_think to test it one-two times, and the behavior was the same.\\n\\nI still see:\\n\\nwait:  \\nBut wait  \\nWait — this is important.\\n\\n  \\nI now tested the \\"old\\" 235b (ud-q4 from unsloth) and no \\"waits\\" at all...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o2mg8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually I tried without any system prompt (because is non-thinking model) first, then I added the  /no_think to test it one-two times, and the behavior was the same.&lt;/p&gt;\\n\\n&lt;p&gt;I still see:&lt;/p&gt;\\n\\n&lt;p&gt;wait:&lt;br/&gt;\\nBut wait&lt;br/&gt;\\nWait — this is important.&lt;/p&gt;\\n\\n&lt;p&gt;I now tested the &amp;quot;old&amp;quot; 235b (ud-q4 from unsloth) and no &amp;quot;waits&amp;quot; at all...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m69sb6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4o2mg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753252189,"author_flair_text":null,"treatment_tags":[],"created_utc":1753252189,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nwnuv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SidneyFong","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4nr1s8","score":1,"author_fullname":"t2_929ppz18","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For the new Qwen3 Instruct, I stripped the /nothink flag from the prompt/template. Not sure whether that matters but if you're still using the old template might worth a try to remove \\"/nothink\\" and see whether it makes a difference.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4nwnuv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For the new Qwen3 Instruct, I stripped the /nothink flag from the prompt/template. Not sure whether that matters but if you&amp;#39;re still using the old template might worth a try to remove &amp;quot;/nothink&amp;quot; and see whether it makes a difference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m69sb6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4nwnuv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753249079,"author_flair_text":null,"treatment_tags":[],"created_utc":1753249079,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nr1s8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"relmny","can_mod_post":false,"created_utc":1753246351,"send_replies":true,"parent_id":"t1_n4kuwwc","score":1,"author_fullname":"t2_joxwuyje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In my case the behavior is not only the \\"wait or But wait\\" but also (lots of) questions/answers. \\n\\nSome times about half of the answer is that behavior. It's like the thinking process is embedded in the answer itself. Very strange. I've never seen that before with any Qwen3 hybrid models with the /no\\\\_think flag.\\n\\nIt basically happens when I ask questions that might have multiple right answers (like computer/network issues and so).\\n\\nI might try a different quant and see...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nr1s8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my case the behavior is not only the &amp;quot;wait or But wait&amp;quot; but also (lots of) questions/answers. &lt;/p&gt;\\n\\n&lt;p&gt;Some times about half of the answer is that behavior. It&amp;#39;s like the thinking process is embedded in the answer itself. Very strange. I&amp;#39;ve never seen that before with any Qwen3 hybrid models with the /no_think flag.&lt;/p&gt;\\n\\n&lt;p&gt;It basically happens when I ask questions that might have multiple right answers (like computer/network issues and so).&lt;/p&gt;\\n\\n&lt;p&gt;I might try a different quant and see...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m69sb6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4nr1s8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753246351,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4kuwwc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SidneyFong","can_mod_post":false,"created_utc":1753211708,"send_replies":true,"parent_id":"t3_1m69sb6","score":1,"author_fullname":"t2_929ppz18","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see similar results. I asked it a difficult question basically asking it to compose a phrase in a tonal language with strict tone requirements (which is inherently difficult in a combinatorial sense). It expectedly failed the task, but it recognized its answers were wrong and kept trying. (Well, I asked in Chinese/Cantonese, and it just kept trying. This behavior is new and I think I only seen this in Qwen3-235B-A22B-Instruct-2507 (the others just pretend it worked).  \\n  \\n [https://github.com/hnfong/public-crap/blob/main/prompts/cantonese/048-cantonesejyutping1.prompt.Qwen3-235B-A22B-Instruct-2507-Q6\\\\_K-00001-of-00004.gguf.0.out](https://github.com/hnfong/public-crap/blob/main/prompts/cantonese/048-cantonesejyutping1.prompt.Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004.gguf.0.out) \\n\\nOther than that there's not a lot of \\"wait...\\" results that I see. Maybe you're seeing it for difficult questions too where it recognizes the answer might not be correct and wanted to review it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4kuwwc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see similar results. I asked it a difficult question basically asking it to compose a phrase in a tonal language with strict tone requirements (which is inherently difficult in a combinatorial sense). It expectedly failed the task, but it recognized its answers were wrong and kept trying. (Well, I asked in Chinese/Cantonese, and it just kept trying. This behavior is new and I think I only seen this in Qwen3-235B-A22B-Instruct-2507 (the others just pretend it worked).  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/hnfong/public-crap/blob/main/prompts/cantonese/048-cantonesejyutping1.prompt.Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004.gguf.0.out\\"&gt;https://github.com/hnfong/public-crap/blob/main/prompts/cantonese/048-cantonesejyutping1.prompt.Qwen3-235B-A22B-Instruct-2507-Q6_K-00001-of-00004.gguf.0.out&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Other than that there&amp;#39;s not a lot of &amp;quot;wait...&amp;quot; results that I see. Maybe you&amp;#39;re seeing it for difficult questions too where it recognizes the answer might not be correct and wanted to review it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m69sb6/in_qwen3235ba22binstruct2507udq4_unsloth_im/n4kuwwc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753211708,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m69sb6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
