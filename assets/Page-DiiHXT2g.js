import{j as e}from"./index-DOAmItP2.js";import{R as l}from"./RedditPostRenderer-KKgzpPpv.js";import"./index-YSfz60vQ.js";const a=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"There was a post going around recently, [OpenAI Charges by the Minute, So Make the Minutes Shorter](https://george.mand.is/2025/06/openai-charges-by-the-minute-so-make-the-minutes-shorter/), proposing to speed up audio to lower inference / api costs for speech recognition / transcription / stt. I for one was intrigued by the results but given that they were based primarily on anecdotal evidence I felt compelled to perform a proper evaluation.  [This repo](https://github.com/LeonEricsson/stt-speedup-bench) contains the full experiments, and below is the TLDR, accompanying the figure.\\n\\n*Performance degradation is exponential, at 2× playback most models are already 3–5× worse; push to 2.5× and accuracy falls off a cliff, with 20× degradation not uncommon. There are still sweet spots, though: Whisper-large-turbo only drifts from 5.39 % to 6.92 % WER (≈ 28 % relative hit) at 1.5×, and GPT-4o tolerates 1.2 × with a trivial \\\\~3 % penalty.*","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Cheaper Transcriptions, Pricier Errors!","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":105,"top_awarded_type":null,"hide_score":false,"name":"t3_1lr217c","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"ups":49,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_il0a6","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":49,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/_T0JEKXjbl1-1yPdcGmPvzT5_mkJxvIujuZuXXUgBIE.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751579712,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;There was a post going around recently, &lt;a href=\\"https://george.mand.is/2025/06/openai-charges-by-the-minute-so-make-the-minutes-shorter/\\"&gt;OpenAI Charges by the Minute, So Make the Minutes Shorter&lt;/a&gt;, proposing to speed up audio to lower inference / api costs for speech recognition / transcription / stt. I for one was intrigued by the results but given that they were based primarily on anecdotal evidence I felt compelled to perform a proper evaluation.  &lt;a href=\\"https://github.com/LeonEricsson/stt-speedup-bench\\"&gt;This repo&lt;/a&gt; contains the full experiments, and below is the TLDR, accompanying the figure.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;em&gt;Performance degradation is exponential, at 2× playback most models are already 3–5× worse; push to 2.5× and accuracy falls off a cliff, with 20× degradation not uncommon. There are still sweet spots, though: Whisper-large-turbo only drifts from 5.39 % to 6.92 % WER (≈ 28 % relative hit) at 1.5×, and GPT-4o tolerates 1.2 × with a trivial ~3 % penalty.&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/zznx9kqgdqaf1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?auto=webp&amp;s=e55e98d4e368d1bde35cf122dad1daa776b285db","width":4536,"height":3424},"resolutions":[{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e006d46639f7d58dbb81b6b89ee9f7844b4a237","width":108,"height":81},{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a3a662116c9a28cf52bcd2a988cb9b39b7c221f","width":216,"height":163},{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ced1207f1f8cacc2319df8811e05cb589c87b74a","width":320,"height":241},{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b6c6aa04a999c4484b5ede2e12f9048adef610c","width":640,"height":483},{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9335244fab3d82235a1fc6e13a3fb7b0c5f24dca","width":960,"height":724},{"url":"https://preview.redd.it/zznx9kqgdqaf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eae79278e3cf69af04d2430deb9bbb50d04be18f","width":1080,"height":815}],"variants":{},"id":"8990gZSYUKrs_OXv0_x0DEk4f9hzGw9peKUOzBnsZJc"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lr217c","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"TelloLeEngineer","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/","stickied":false,"url":"https://i.redd.it/zznx9kqgdqaf1.png","subreddit_subscribers":494198,"created_utc":1751579712,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17fl2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iamgladiator","can_mod_post":false,"created_utc":1751580784,"send_replies":true,"parent_id":"t3_1lr217c","score":4,"author_fullname":"t2_capf2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you for your work and sharing it! Awesome test","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17fl2q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for your work and sharing it! Awesome test&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n17fl2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751580784,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr217c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n196jmc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Failiiix","can_mod_post":false,"created_utc":1751604632,"send_replies":true,"parent_id":"t1_n18fdvd","score":1,"author_fullname":"t2_xbip5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you expand this thought? What does playback factor do and where can I change that using whisper large locally?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n196jmc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you expand this thought? What does playback factor do and where can I change that using whisper large locally?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lr217c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n196jmc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751604632,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n19b87m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EndlessZone123","can_mod_post":false,"created_utc":1751606851,"send_replies":true,"parent_id":"t1_n18fdvd","score":1,"author_fullname":"t2_10pxq3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well usually you just use a faster/smaller model if you want quicker outputs. Both achieve like the same thing. Speeding up audio is the only option if you are using an api without the choice of using a smaller model.\\n\\nWhisper small still going to be faster than 2x speed large.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n19b87m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well usually you just use a faster/smaller model if you want quicker outputs. Both achieve like the same thing. Speeding up audio is the only option if you are using an api without the choice of using a smaller model.&lt;/p&gt;\\n\\n&lt;p&gt;Whisper small still going to be faster than 2x speed large.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lr217c","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n19b87m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751606851,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n18fdvd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pedalnomica","can_mod_post":false,"created_utc":1751593574,"send_replies":true,"parent_id":"t3_1lr217c","score":3,"author_fullname":"t2_b0d7j6x9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This technique could potentially be useful for reducing latency with local models...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n18fdvd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This technique could potentially be useful for reducing latency with local models...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n18fdvd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751593574,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr217c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17moez","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wellomello","can_mod_post":false,"created_utc":1751583169,"send_replies":true,"parent_id":"t3_1lr217c","score":3,"author_fullname":"t2_6686dlai","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"20% savings for 3% error (that may be even on statistical uncertainty?) is absolutely sweet for production envs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17moez","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;20% savings for 3% error (that may be even on statistical uncertainty?) is absolutely sweet for production envs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n17moez/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751583169,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr217c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n194vt4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tist20","can_mod_post":false,"created_utc":1751603871,"send_replies":true,"parent_id":"t3_1lr217c","score":1,"author_fullname":"t2_6c1pbm21","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting. Does the error rate decrease if you set the playback speed to less than 1, for example to 0.5?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n194vt4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting. Does the error rate decrease if you set the playback speed to less than 1, for example to 0.5?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr217c/cheaper_transcriptions_pricier_errors/n194vt4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751603871,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr217c","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),s=()=>e.jsx(l,{data:a});export{s as default};
