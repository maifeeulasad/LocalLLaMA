import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"\\n**Reason**\\nSo I was walking around my room thinking about my current laptop lenovo yoga slim 7\\nand then started thinking about other laptops,\\nnamely..\\n\\n\\n\\n\\n\\n**Question 1**\\n\\nMacbook Air/Pro.\\nhow are the apple products when used for local training? \\nmore specifically how are the last 3 generations of Macbook Pros when running locally?\\n\\n\\n\\n**Question 2**\\n\\nare there any cloud providers that are ‘private’ atleast well encrypted and secure? and don’t sell themselves to a government, if no, that’s unfortunate and someone should build that :).\\nand..\\n\\n\\n\\n**Question 3**\\n\\nwhat are the most efficient (cost, storage, gpu, cpu, connection speed, etc) machines to build a private server that can train models and store images from 10+ devices onto a private storage  server.\\n\\n\\n\\n\\nThank you if you’ve read this far, \\nand even more thank you to the people that can answer and do :)\\n\\n\\n\\n\\n\\n\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"ML on Macbook","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7pn05","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.4,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_4iu4e2ma","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753315817,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;\\nSo I was walking around my room thinking about my current laptop lenovo yoga slim 7\\nand then started thinking about other laptops,\\nnamely..&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Question 1&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Macbook Air/Pro.\\nhow are the apple products when used for local training? \\nmore specifically how are the last 3 generations of Macbook Pros when running locally?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Question 2&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;are there any cloud providers that are ‘private’ atleast well encrypted and secure? and don’t sell themselves to a government, if no, that’s unfortunate and someone should build that :).\\nand..&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Question 3&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;what are the most efficient (cost, storage, gpu, cpu, connection speed, etc) machines to build a private server that can train models and store images from 10+ devices onto a private storage  server.&lt;/p&gt;\\n\\n&lt;p&gt;Thank you if you’ve read this far, \\nand even more thank you to the people that can answer and do :)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m7pn05","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"CaslerTheTesticle","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/","subreddit_subscribers":504025,"created_utc":1753315817,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4utish","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CaslerTheTesticle","can_mod_post":false,"created_utc":1753338917,"send_replies":true,"parent_id":"t1_n4trs0b","score":1,"author_fullname":"t2_4iu4e2ma","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you ❤️\\n\\nthat is very expensive\\ncloud does not cost that much on google colab","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4utish","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you ❤️&lt;/p&gt;\\n\\n&lt;p&gt;that is very expensive\\ncloud does not cost that much on google colab&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7pn05","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/n4utish/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753338917,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4trs0b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dizzy-Cantaloupe8892","can_mod_post":false,"created_utc":1753322417,"send_replies":true,"parent_id":"t3_1m7pn05","score":2,"author_fullname":"t2_dssg622ox","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The latest MacBooks with Apple Silicon are capable for ML work. M4 Pro supports up to 64GB of fast unified memory with 273GB/s bandwidth and the M4 has Apple's fastest Neural Engine at 38 TOPS. Training performance varies by framework. MLX (Apple's framework) will better utilize the unified memory system compared to PyTorch and TensorFlow which aren't fully optimized for Apple Silicon yet. Building a private ML server is where things get interesting cost-wise. A single RTX 5090 with 32GB VRAM at $2000 beats the older dual RTX 3090 setup, uses less power (575W vs 700W), and avoids the now-expensive NVLink bridges.\\n\\nCloud costs are brutal - an A100 runs $32k-$287k annually depending on provider. But services like Banana, Replicate, and others offer auto-scaling that can cut costs by 90% if you don't need 24/7 availability. \\n\\nFor your 10+ device storage server, start with a basic setup around $2-3k: Ryzen/Intel consumer CPU, 64-128GB RAM, multiple large drives in RAID, and 10GbE networking. Focus on efficiency over raw power - modern hardware is faster and uses less electricity than repurposed old servers. Add GPU compute later when you know your actual workload requirements.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4trs0b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The latest MacBooks with Apple Silicon are capable for ML work. M4 Pro supports up to 64GB of fast unified memory with 273GB/s bandwidth and the M4 has Apple&amp;#39;s fastest Neural Engine at 38 TOPS. Training performance varies by framework. MLX (Apple&amp;#39;s framework) will better utilize the unified memory system compared to PyTorch and TensorFlow which aren&amp;#39;t fully optimized for Apple Silicon yet. Building a private ML server is where things get interesting cost-wise. A single RTX 5090 with 32GB VRAM at $2000 beats the older dual RTX 3090 setup, uses less power (575W vs 700W), and avoids the now-expensive NVLink bridges.&lt;/p&gt;\\n\\n&lt;p&gt;Cloud costs are brutal - an A100 runs $32k-$287k annually depending on provider. But services like Banana, Replicate, and others offer auto-scaling that can cut costs by 90% if you don&amp;#39;t need 24/7 availability. &lt;/p&gt;\\n\\n&lt;p&gt;For your 10+ device storage server, start with a basic setup around $2-3k: Ryzen/Intel consumer CPU, 64-128GB RAM, multiple large drives in RAID, and 10GbE networking. Focus on efficiency over raw power - modern hardware is faster and uses less electricity than repurposed old servers. Add GPU compute later when you know your actual workload requirements.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/n4trs0b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753322417,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7pn05","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4uwl1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4uti2l","score":0,"author_fullname":"t2_1tpuoj72sa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"question 2: there are none. question 3: RTX Pro 6000 or GH200 624GB or better.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4uwl1y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;question 2: there are none. question 3: RTX Pro 6000 or GH200 624GB or better.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7pn05","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/n4uwl1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753340565,"author_flair_text":null,"treatment_tags":[],"created_utc":1753340565,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4uti2l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CaslerTheTesticle","can_mod_post":false,"created_utc":1753338906,"send_replies":true,"parent_id":"t1_n4ut5jd","score":1,"author_fullname":"t2_4iu4e2ma","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4uti2l","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7pn05","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/n4uti2l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753338906,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ut5jd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"created_utc":1753338718,"send_replies":true,"parent_id":"t3_1m7pn05","score":-1,"author_fullname":"t2_1tpuoj72sa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"IMHO, anyone whos buys apple does not know what their logo means... + anyone who buys devices containing lithium ion batteries does not know how dangerous these batteries are (avoid at all cost...).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ut5jd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IMHO, anyone whos buys apple does not know what their logo means... + anyone who buys devices containing lithium ion batteries does not know how dangerous these batteries are (avoid at all cost...).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7pn05/ml_on_macbook/n4ut5jd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753338718,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7pn05","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
