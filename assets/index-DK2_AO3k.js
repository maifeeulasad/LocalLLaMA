const e=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Huawei releases an open weight model Pangu Pro 72B A16B. Weights are on HF. It should be competitive with Qwen3 32B and it was trained entirely on Huawei Ascend NPUs. (2505.21411)","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1lp9gh2","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":379,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_9s7pmakgx","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":379,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=cdd7cf8a2002d72c1a2a37a8f23acfa4d1952c22","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751394651,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"huggingface.co","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/IntervitensInc/pangu-pro-moe-model","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?auto=webp&amp;s=192b3d3e9c02a82a06d21d0bae530698ffef8dc3","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fa50f130c1d12794fe17be8766a2c4749d61f5a","width":108,"height":58},{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc158227d51a8b988d7232029edea6b3b7fbf734","width":216,"height":116},{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a5ff1813a9a4dc8452b94c5ff74ce5bebf716297","width":320,"height":172},{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd39a4d6488e7f71969bdc8665d7c2dbe902c2b5","width":640,"height":345},{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=65e8e5e6138c705563eb6eca5921c617f5071ab4","width":960,"height":518},{"url":"https://external-preview.redd.it/KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c0c728888e14c64c37ad356f82ee2cc33223ddf6","width":1080,"height":583}],"variants":{},"id":"KKUaRRu1NZXsmquOk2Id9DRnEhBD6P6w5Y5xZQur5Yc"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1lp9gh2","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"FullOf_Bad_Ideas","discussion_type":null,"num_comments":58,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/","stickied":false,"url":"https://huggingface.co/IntervitensInc/pangu-pro-moe-model","subreddit_subscribers":493457,"created_utc":1751394651,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0uwrtn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Severin_Suveren","can_mod_post":false,"created_utc":1751416022,"send_replies":true,"parent_id":"t1_n0um97t","score":2,"author_fullname":"t2_vfpsd1c8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\**random pop corn chillin gif*\\\\*","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0uwrtn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;*&lt;em&gt;random pop corn chillin gif&lt;/em&gt;*&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0uwrtn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751416022,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0vn62w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"created_utc":1751425414,"send_replies":true,"parent_id":"t1_n0um97t","score":-3,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"are the downvotes in the room with us right now?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0vn62w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are the downvotes in the room with us right now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0vn62w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751425414,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0um97t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Orolol","can_mod_post":false,"created_utc":1751412393,"send_replies":true,"parent_id":"t1_n0ujt6o","score":6,"author_fullname":"t2_fbzx9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"You got triggered by downvotes.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n0um97t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You got triggered by downvotes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lp9gh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0um97t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751412393,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ujt6o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0u2bk4","score":2,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"caps are for emphasis in this case. People on the internet are a bunch of snowflakes that gets triggered by anything","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n0ujt6o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;caps are for emphasis in this case. People on the internet are a bunch of snowflakes that gets triggered by anything&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lp9gh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ujt6o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751411589,"author_flair_text":null,"treatment_tags":[],"created_utc":1751411589,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0u2bk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Orolol","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tnvgs","score":17,"author_fullname":"t2_fbzx9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; respectfully   \\n  \\nAll caps suggested otherwise.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0u2bk4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;respectfully   &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;All caps suggested otherwise.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lp9gh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u2bk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751405973,"author_flair_text":null,"treatment_tags":[],"created_utc":1751405973,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tnvgs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dugavo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tnofs","score":20,"author_fullname":"t2_1nge67um4h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're welcome.\\n\\nI don't get all the people downvoting me, how can we improve ourselves without respectfully correcting each other?","edited":false,"author_flair_css_class":null,"name":"t1_n0tnvgs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re welcome.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t get all the people downvoting me, how can we improve ourselves without respectfully correcting each other?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lp9gh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tnvgs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751401773,"author_flair_text":null,"collapsed":false,"created_utc":1751401773,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tnofs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tlb4k","score":21,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah you're right, I corrected it. Thanks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tnofs","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah you&amp;#39;re right, I corrected it. Thanks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tnofs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751401718,"author_flair_text":null,"treatment_tags":[],"created_utc":1751401718,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ucwfs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jbutlerdev","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tlb4k","score":1,"author_fullname":"t2_azse6ibv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is weights though...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ucwfs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is weights though...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ucwfs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751409306,"author_flair_text":null,"treatment_tags":[],"created_utc":1751409306,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tlb4k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dugavo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t2uws","score":16,"author_fullname":"t2_1nge67um4h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IT'S means IT IS\\n\\nYou probably mean: \\"its weights\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0tlb4k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IT&amp;#39;S means IT IS&lt;/p&gt;\\n\\n&lt;p&gt;You probably mean: &amp;quot;its weights&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tlb4k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751401056,"author_flair_text":null,"treatment_tags":[],"created_utc":1751401056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t2uws","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751395741,"send_replies":true,"parent_id":"t1_n0t0na8","score":57,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They also trained Pangu Ultra 718B A39B on their own chips, here's a paper - https://huggingface.co/papers/2505.04519\\n\\nIt's close to DeepSeek R1 on evals. \\n\\nI don't think its weights were released, but maybe I just don't know the right places to look for it.","edited":1751401697,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t2uws","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They also trained Pangu Ultra 718B A39B on their own chips, here&amp;#39;s a paper - &lt;a href=\\"https://huggingface.co/papers/2505.04519\\"&gt;https://huggingface.co/papers/2505.04519&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s close to DeepSeek R1 on evals. &lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think its weights were released, but maybe I just don&amp;#39;t know the right places to look for it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t2uws/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395741,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":57}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0u1apd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mission_tiefsee","can_mod_post":false,"created_utc":1751405665,"send_replies":true,"parent_id":"t1_n0t0na8","score":9,"author_fullname":"t2_1l0xi85fdm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i wonder if it is all china from here. Best models (or close eg deepseek), best open source(qwen) and now also chips? Thumbs up! Hope to see more hardware and more competition to nvidia!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u1apd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i wonder if it is all china from here. Best models (or close eg deepseek), best open source(qwen) and now also chips? Thumbs up! Hope to see more hardware and more competition to nvidia!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u1apd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751405665,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t0na8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"atape_1","can_mod_post":false,"created_utc":1751395118,"send_replies":true,"parent_id":"t3_1lp9gh2","score":172,"author_fullname":"t2_k35bw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"First models trained on Huawei chips, nice. Can't wait to see more. We need more competition in the hardware space.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t0na8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;First models trained on Huawei chips, nice. Can&amp;#39;t wait to see more. We need more competition in the hardware space.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t0na8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395118,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":172}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0upc2b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ugkva","score":3,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree in principle.\\n\\nWe get many different models in various sizes, and everyone is free to pick the model that works for their usecase. If you have a task that requires heavy parallelization, you might like MoEs since less activated parameters means less compute needed per each forward pass, which means that you can squeeze in more throughput, if you have the VRAM for it. There are hundreds of usecases for LLMs and hundreds of different hardware configurations, more choice is good. 32B dense is nice, but I don't want all models to be 32B dense.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0upc2b","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree in principle.&lt;/p&gt;\\n\\n&lt;p&gt;We get many different models in various sizes, and everyone is free to pick the model that works for their usecase. If you have a task that requires heavy parallelization, you might like MoEs since less activated parameters means less compute needed per each forward pass, which means that you can squeeze in more throughput, if you have the VRAM for it. There are hundreds of usecases for LLMs and hundreds of different hardware configurations, more choice is good. 32B dense is nice, but I don&amp;#39;t want all models to be 32B dense.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0upc2b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751413416,"author_flair_text":null,"treatment_tags":[],"created_utc":1751413416,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ugkva","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1751410519,"send_replies":true,"parent_id":"t1_n0t13nf","score":15,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;smaller 32B dense models leave some VRAM unused\\n\\nThere's no such thing as useless VRAM; each GB that is not filled by weights can be filled by activations and KV cache to either handle long contextes or multiple requests in parallel, or it can be allocated for embedding model, draft model, tts/stt models, etc. So trading off 2x larger weight memory for up to 2x performance uplift is kinda too niche usecase; especially given that with speculative decoding you get more favourable memory/speed uplift ratio. A good 70B MoE needs either less active parameters or significantly better task performance to be a true substitution for 32B dense model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ugkva","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;smaller 32B dense models leave some VRAM unused&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;There&amp;#39;s no such thing as useless VRAM; each GB that is not filled by weights can be filled by activations and KV cache to either handle long contextes or multiple requests in parallel, or it can be allocated for embedding model, draft model, tts/stt models, etc. So trading off 2x larger weight memory for up to 2x performance uplift is kinda too niche usecase; especially given that with speculative decoding you get more favourable memory/speed uplift ratio. A good 70B MoE needs either less active parameters or significantly better task performance to be a true substitution for 32B dense model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ugkva/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410519,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0w14xk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1751431266,"send_replies":true,"parent_id":"t1_n0t13nf","score":1,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Groovy.  Looking forward to GGUFs so I can evaluate it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0w14xk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Groovy.  Looking forward to GGUFs so I can evaluate it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0w14xk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751431266,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t13nf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751395245,"send_replies":true,"parent_id":"t3_1lp9gh2","score":55,"author_fullname":"t2_9s7pmakgx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"link to paper: https://arxiv.org/abs/2505.21411\\n\\nIt's MoE architecture with special focus on expert grouping for increased enterprise-grade inference throughput on multi-accelerator deployment. No GGUF, support in vLLM and SGLang is uncertain - both vLLM and SGLang have transformers inference compatibility layer by now, but I would expect to run into some issues when trying to use it with this model.\\n\\nI think it's close to perfect size for enthusiast-grade local reasoning LLMs. 70B dense models are often too slow during reasoning to be useful, and smaller 32B dense models leave some VRAM unused when you're using a quant that's close to 4-bits and you have 48GB VRAM budget. I hope to see more open weight models trained on non-Nvidia accelerators - as they get more competitive, hopefully we'll see A100/H100 prices crash to the point of becoming affordable for enthusiasts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t13nf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;link to paper: &lt;a href=\\"https://arxiv.org/abs/2505.21411\\"&gt;https://arxiv.org/abs/2505.21411&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s MoE architecture with special focus on expert grouping for increased enterprise-grade inference throughput on multi-accelerator deployment. No GGUF, support in vLLM and SGLang is uncertain - both vLLM and SGLang have transformers inference compatibility layer by now, but I would expect to run into some issues when trying to use it with this model.&lt;/p&gt;\\n\\n&lt;p&gt;I think it&amp;#39;s close to perfect size for enthusiast-grade local reasoning LLMs. 70B dense models are often too slow during reasoning to be useful, and smaller 32B dense models leave some VRAM unused when you&amp;#39;re using a quant that&amp;#39;s close to 4-bits and you have 48GB VRAM budget. I hope to see more open weight models trained on non-Nvidia accelerators - as they get more competitive, hopefully we&amp;#39;ll see A100/H100 prices crash to the point of becoming affordable for enthusiasts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t13nf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395245,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":55}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0u9129","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iory1998","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tqn5n","score":7,"author_fullname":"t2_byt5wa14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let's wait until we tried the models and see.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0u9129","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let&amp;#39;s wait until we tried the models and see.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u9129/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751408048,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751408048,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tqn5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrjackspade","can_mod_post":false,"created_utc":1751402554,"send_replies":true,"parent_id":"t1_n0tjca9","score":18,"author_fullname":"t2_5ow51","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its pretty good if you're running on full CPU, because you'll get more speed for the same scores.\\n\\nAll things being equal I'd rather use the 72B with 16B active, than the 32B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tqn5n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its pretty good if you&amp;#39;re running on full CPU, because you&amp;#39;ll get more speed for the same scores.&lt;/p&gt;\\n\\n&lt;p&gt;All things being equal I&amp;#39;d rather use the 72B with 16B active, than the 32B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tqn5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751402554,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0twmsn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zc5Gwu","can_mod_post":false,"created_utc":1751404266,"send_replies":true,"parent_id":"t1_n0tjca9","score":3,"author_fullname":"t2_67qrvlir","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It might be much faster depending on how long its reasoning traces are.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0twmsn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It might be much faster depending on how long its reasoning traces are.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0twmsn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751404266,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0utc7p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ugzq5","score":11,"author_fullname":"t2_eerln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah because they are ram rich. You are ram poor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0utc7p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah because they are ram rich. You are ram poor.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0utc7p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751414794,"author_flair_text":null,"treatment_tags":[],"created_utc":1751414794,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ugzq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Refrigerator-1672","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tus5z","score":4,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But the performance is not the same, cause given the same amount of system memory, this MoE eats up a lot more space and thus is heavily slashing down effective context length. You aren't running a 70B model to process a tiny 4k long chat, are you?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ugzq5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But the performance is not the same, cause given the same amount of system memory, this MoE eats up a lot more space and thus is heavily slashing down effective context length. You aren&amp;#39;t running a 70B model to process a tiny 4k long chat, are you?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ugzq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410655,"author_flair_text":null,"treatment_tags":[],"created_utc":1751410655,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tus5z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1751403725,"send_replies":true,"parent_id":"t1_n0tjca9","score":9,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are trading more memory usage for much faster model, and 32B is quite slow already so this is arguably a better model, if the performance is the same.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tus5z","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are trading more memory usage for much faster model, and 32B is quite slow already so this is arguably a better model, if the performance is the same.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tus5z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751403725,"author_flair_text":"Alpaca","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0vcbqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Iory1998","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0v7706","score":2,"author_fullname":"t2_byt5wa14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Don't forget, it's the world's largest hardware manufacturer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0vcbqo","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t forget, it&amp;#39;s the world&amp;#39;s largest hardware manufacturer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0vcbqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751421529,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751421529,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0v7706","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jonas-reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0uk0pn","score":3,"author_fullname":"t2_vfaq1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Uhm. It’s China, we’d expected nothing less from the world’s second largest economy.  We’re not talking about Luxembourg.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0v7706","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Uhm. It’s China, we’d expected nothing less from the world’s second largest economy.  We’re not talking about Luxembourg.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0v7706/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751419740,"author_flair_text":null,"treatment_tags":[],"created_utc":1751419740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0uk0pn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffdy","can_mod_post":false,"created_utc":1751411657,"send_replies":true,"parent_id":"t1_n0tjca9","score":4,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; but the fact that it was trained on a home grown GPU, that is huge!\\n\\nyep, how many countries can boast of home-grown delevoped AI chips *and* robust models trained in such chips?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0uk0pn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;but the fact that it was trained on a home grown GPU, that is huge!&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;yep, how many countries can boast of home-grown delevoped AI chips &lt;em&gt;and&lt;/em&gt; robust models trained in such chips?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0uk0pn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751411657,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tjca9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iory1998","can_mod_post":false,"created_utc":1751400490,"send_replies":true,"parent_id":"t3_1lp9gh2","score":46,"author_fullname":"t2_byt5wa14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You see, a model that's 72B on par with a 32B model is not really stimulating even if it's an MoE one, but the fact that it was trained on a home grown GPU, that is huge!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tjca9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You see, a model that&amp;#39;s 72B on par with a 32B model is not really stimulating even if it&amp;#39;s an MoE one, but the fact that it was trained on a home grown GPU, that is huge!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tjca9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751400490,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t3eet","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noage","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t1tvc","score":6,"author_fullname":"t2_5ao30","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! That is cool to see. The paper definitely suggest they are trying to cement their technology and hardware, and it definitely seems reasonable for them to be focusing on that audience. It seems like they used a different architecture so I'll probably have to wait for some llama.cpp compatibility update.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0t3eet","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! That is cool to see. The paper definitely suggest they are trying to cement their technology and hardware, and it definitely seems reasonable for them to be focusing on that audience. It seems like they used a different architecture so I&amp;#39;ll probably have to wait for some llama.cpp compatibility update.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t3eet/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395892,"author_flair_text":null,"treatment_tags":[],"created_utc":1751395892,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t1tvc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751395449,"send_replies":true,"parent_id":"t1_n0szo8v","score":16,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"here's a paper - https://arxiv.org/abs/2505.21411\\n\\nI wasn't sure whether it's better to link to paper or model weights, but I figured the community would be more interested in using the model than reading a research paper. It's trained on English and performs better on English-oriented benchmarks than Llama 4 Scout.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t1tvc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;here&amp;#39;s a paper - &lt;a href=\\"https://arxiv.org/abs/2505.21411\\"&gt;https://arxiv.org/abs/2505.21411&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I wasn&amp;#39;t sure whether it&amp;#39;s better to link to paper or model weights, but I figured the community would be more interested in using the model than reading a research paper. It&amp;#39;s trained on English and performs better on English-oriented benchmarks than Llama 4 Scout.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t1tvc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395449,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tkg48","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"plankalkul-z1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t1kut","score":3,"author_fullname":"t2_w73n3yrsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;_x_tr_tl=en&amp;_x_tr_hl=en-US&amp;_x_tr_pto=wapp\\n\\n\\nThanks for the translation link, appreciated.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0tkg48","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;&lt;a href=\\"https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp\\"&gt;https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp&lt;/a&gt;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Thanks for the translation link, appreciated.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tkg48/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751400811,"author_flair_text":null,"treatment_tags":[],"created_utc":1751400811,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t1kut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Entubulated","can_mod_post":false,"created_utc":1751395379,"send_replies":true,"parent_id":"t1_n0szo8v","score":10,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Model technical report in English: [https://arxiv.org/abs/2505.21411](https://arxiv.org/abs/2505.21411)\\n\\nFound by feeding the HF page to google translate.  \\n[https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?\\\\_x\\\\_tr\\\\_sl=zh-CN&amp;\\\\_x\\\\_tr\\\\_tl=en&amp;\\\\_x\\\\_tr\\\\_hl=en-US&amp;\\\\_x\\\\_tr\\\\_pto=wapp](https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;_x_tr_tl=en&amp;_x_tr_hl=en-US&amp;_x_tr_pto=wapp)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t1kut","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Model technical report in English: &lt;a href=\\"https://arxiv.org/abs/2505.21411\\"&gt;https://arxiv.org/abs/2505.21411&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Found by feeding the HF page to google translate.&lt;br/&gt;\\n&lt;a href=\\"https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp\\"&gt;https://huggingface-co.translate.goog/IntervitensInc/pangu-pro-moe-model?_x_tr_sl=zh-CN&amp;amp;_x_tr_tl=en&amp;amp;_x_tr_hl=en-US&amp;amp;_x_tr_pto=wapp&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t1kut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395379,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n0szo8v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noage","can_mod_post":false,"created_utc":1751394842,"send_replies":true,"parent_id":"t3_1lp9gh2","score":16,"author_fullname":"t2_5ao30","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any English post about this? Is a model trained in English? This is the first post that I can recall for a big Chinese group that didn't have a concurrent English facing post as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0szo8v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any English post about this? Is a model trained in English? This is the first post that I can recall for a big Chinese group that didn&amp;#39;t have a concurrent English facing post as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0szo8v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751394842,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tejs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MMAgeezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t4q7w","score":6,"author_fullname":"t2_34hhuqbx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's just an MIT license. Which is very common. \\n\\nIt lets anyone use, copy, modify, merge, publish, distribute, sublicense and sell the software with almost no restrictions.\\n\\nIts warranty disclaimer says the software is provided:\\n\\n&gt; as is, without warranty of any kind… In no event shall the authors or copyright holders be liable for any claim, damages or other liability.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tejs8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s just an MIT license. Which is very common. &lt;/p&gt;\\n\\n&lt;p&gt;It lets anyone use, copy, modify, merge, publish, distribute, sublicense and sell the software with almost no restrictions.&lt;/p&gt;\\n\\n&lt;p&gt;Its warranty disclaimer says the software is provided:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;as is, without warranty of any kind… In no event shall the authors or copyright holders be liable for any claim, damages or other liability.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tejs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751399110,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751399110,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t4q7w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t3vnj","score":2,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I beat you with my comment :) \\n\\nI don’t get why this isn’t a more typical license: feel free to do what you want with this model as long as you recognize you’re responsible and you can’t take us to court.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0t4q7w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I beat you with my comment :) &lt;/p&gt;\\n\\n&lt;p&gt;I don’t get why this isn’t a more typical license: feel free to do what you want with this model as long as you recognize you’re responsible and you can’t take us to court.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t4q7w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396267,"author_flair_text":null,"treatment_tags":[],"created_utc":1751396267,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t3vnj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Alternative_Quote246","can_mod_post":false,"created_utc":1751396025,"send_replies":true,"parent_id":"t1_n0t0yfe","score":22,"author_fullname":"t2_4sfm1yax","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s pretty free except one can’t use it in EU. Maybe to avoid trouble for the EU AI act.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t3vnj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s pretty free except one can’t use it in EU. Maybe to avoid trouble for the EU AI act.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t3vnj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396025,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t5sk7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"created_utc":1751396573,"send_replies":true,"parent_id":"t1_n0t0yfe","score":5,"author_fullname":"t2_8jqx3m14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not great, but could be worse. It's a bit like the 4-clause BSD licnse with an EU ban and an indemnity clause.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t5sk7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not great, but could be worse. It&amp;#39;s a bit like the 4-clause BSD licnse with an EU ban and an indemnity clause.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t5sk7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396573,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t3lqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"created_utc":1751395949,"send_replies":true,"parent_id":"t1_n0t0yfe","score":10,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That said… it looks like it just has the new Europe Dunce Hat license… where it basically says you can use this model without restriction unless you are Europe, in which case you have to sit in a corner and think about what you’ve done. (That said I’m no lawyer and I was trying to read the license on my phone.)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t3lqu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That said… it looks like it just has the new Europe Dunce Hat license… where it basically says you can use this model without restriction unless you are Europe, in which case you have to sit in a corner and think about what you’ve done. (That said I’m no lawyer and I was trying to read the license on my phone.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t3lqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395949,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t0yfe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"created_utc":1751395204,"send_replies":true,"parent_id":"t3_1lp9gh2","score":9,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Disappointed that it isn’t Apache or MIT licensed.\\n\\nEDIT: it isn’t the worst license if you’re not in Europe.","edited":1751396896,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t0yfe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Disappointed that it isn’t Apache or MIT licensed.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: it isn’t the worst license if you’re not in Europe.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t0yfe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751395204,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0uomee","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751413179,"send_replies":true,"parent_id":"t1_n0ug0fb","score":9,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I meant competitive in quality of outputs.\\n\\nDepending on your hardware, it will be easier or harder to run then Qwen3 32B. If you have single 3090/4090, you'll have better time with Qwen3 32B. But, if you have 2 x 3090 setup, which is quite popular here, there might soon be a way of running this model on it and getting 2x faster inference than with Qwen3 32B, since the number of activated parameters is 2x smaller. And in that case, you might get the same quality, but with 2x faster output, which is in my opinion significant. If you have smaller GPU and you're offloading to CPU, there also might be a way to have Pangu Pro 72B run faster than Qwen3 32B.\\n\\nWhat I like is that we get models of various sizes and we can choose which one suits our hardware best, I think that's really good to see.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0uomee","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I meant competitive in quality of outputs.&lt;/p&gt;\\n\\n&lt;p&gt;Depending on your hardware, it will be easier or harder to run then Qwen3 32B. If you have single 3090/4090, you&amp;#39;ll have better time with Qwen3 32B. But, if you have 2 x 3090 setup, which is quite popular here, there might soon be a way of running this model on it and getting 2x faster inference than with Qwen3 32B, since the number of activated parameters is 2x smaller. And in that case, you might get the same quality, but with 2x faster output, which is in my opinion significant. If you have smaller GPU and you&amp;#39;re offloading to CPU, there also might be a way to have Pangu Pro 72B run faster than Qwen3 32B.&lt;/p&gt;\\n\\n&lt;p&gt;What I like is that we get models of various sizes and we can choose which one suits our hardware best, I think that&amp;#39;s really good to see.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0uomee/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751413179,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ug0fb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1751410331,"send_replies":true,"parent_id":"t3_1lp9gh2","score":4,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure how should I feel about that \\"It should be competitive with Qwen3 32B\\".\\n\\nIn case of my hardware it means that a 72B model which is too big for my hardware to even load let alone run at reasonable speed, is comparable to a model which I can at least load and run slowly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ug0fb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure how should I feel about that &amp;quot;It should be competitive with Qwen3 32B&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;In case of my hardware it means that a 72B model which is too big for my hardware to even load let alone run at reasonable speed, is comparable to a model which I can at least load and run slowly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ug0fb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410331,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0u0xxt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751405558,"send_replies":true,"parent_id":"t1_n0tx9kx","score":4,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They seem to be on the bleeding edge if you trust their benchmarks. Base model appears to be better than Llama 4 Scout and similar to Hunyuan 80B A13B released just a few days ago. Instruct model has reasoning, and again, appears similar to Hunyuan 80B A13B, while Llama 4 Scout has no reasoning support.\\n\\nI think Chinese AI labs will try to use those accelerators if they will find it easy to switch to them. I think it's moreso an ad for their hardware that is meant to show that it's possible to train a useful model on their hardware, and that by itself is really impressive. I don't remember seeing a model of this kind pre-trained on AMD Instruct accelerators, so there's that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u0xxt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They seem to be on the bleeding edge if you trust their benchmarks. Base model appears to be better than Llama 4 Scout and similar to Hunyuan 80B A13B released just a few days ago. Instruct model has reasoning, and again, appears similar to Hunyuan 80B A13B, while Llama 4 Scout has no reasoning support.&lt;/p&gt;\\n\\n&lt;p&gt;I think Chinese AI labs will try to use those accelerators if they will find it easy to switch to them. I think it&amp;#39;s moreso an ad for their hardware that is meant to show that it&amp;#39;s possible to train a useful model on their hardware, and that by itself is really impressive. I don&amp;#39;t remember seeing a model of this kind pre-trained on AMD Instruct accelerators, so there&amp;#39;s that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u0xxt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751405558,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tx9kx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Rich_Artist_8327","can_mod_post":false,"created_utc":1751404452,"send_replies":true,"parent_id":"t3_1lp9gh2","score":5,"author_fullname":"t2_1jk2ep8a52","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am sure after 3 years Huawei models are 1 year ahead of everyone else.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tx9kx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am sure after 3 years Huawei models are 1 year ahead of everyone else.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tx9kx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751404452,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0uzj80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751417015,"send_replies":true,"parent_id":"t1_n0tu62d","score":3,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"2 months ago Huawei released a paper where it described training 718B Pangu Ultra on their NPUs - https://arxiv.org/abs/2505.04519\\n\\nIf Nvidia stock were to crash because of losing dominance on training in the future, it would be May 7th when this paper came out. It didn't crash on that day.\\n\\nWe may very well be looking at this before analysts sweep in - DeepSeek showed me how people/bots who make those investment decisions are driven by word on the street moreso than actual information that could predict future. So, stock price doesn't seem as much driven by actual circumstances, it's driven by reporting on those circumstances.\\n\\nDeepSeek showed the world that you can train a great model on Nvidia GPUs for cheap.\\n\\nPangu Ultra showed that you can train a great model on non-Nvidia NPUs for even cheaper.\\n\\nNow that word is out in the technical science circles, people will start showing this to their managers, managers might start buying more Huawei Ascend NPUs, and then Nvidia forecasts for sales to China might start looking a tad bleak and then word on Wall Street will be negative on Nvidia. Just sharing my thoughts on the topic, if you disagree or agree here I am happy to continue discussion about it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0uzj80","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2 months ago Huawei released a paper where it described training 718B Pangu Ultra on their NPUs - &lt;a href=\\"https://arxiv.org/abs/2505.04519\\"&gt;https://arxiv.org/abs/2505.04519&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If Nvidia stock were to crash because of losing dominance on training in the future, it would be May 7th when this paper came out. It didn&amp;#39;t crash on that day.&lt;/p&gt;\\n\\n&lt;p&gt;We may very well be looking at this before analysts sweep in - DeepSeek showed me how people/bots who make those investment decisions are driven by word on the street moreso than actual information that could predict future. So, stock price doesn&amp;#39;t seem as much driven by actual circumstances, it&amp;#39;s driven by reporting on those circumstances.&lt;/p&gt;\\n\\n&lt;p&gt;DeepSeek showed the world that you can train a great model on Nvidia GPUs for cheap.&lt;/p&gt;\\n\\n&lt;p&gt;Pangu Ultra showed that you can train a great model on non-Nvidia NPUs for even cheaper.&lt;/p&gt;\\n\\n&lt;p&gt;Now that word is out in the technical science circles, people will start showing this to their managers, managers might start buying more Huawei Ascend NPUs, and then Nvidia forecasts for sales to China might start looking a tad bleak and then word on Wall Street will be negative on Nvidia. Just sharing my thoughts on the topic, if you disagree or agree here I am happy to continue discussion about it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0uzj80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751417015,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ua9v7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0u6k23","score":9,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nobody is surprised. Hell, I have a China-phone and run Qwen locally. The China pill tastes damn good.\\n\\nIt's still quite the story that a model like this came from China sourced hardware, it's a milestone, the start of the end for one of the USA's final monopolies that matter.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ua9v7","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nobody is surprised. Hell, I have a China-phone and run Qwen locally. The China pill tastes damn good.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s still quite the story that a model like this came from China sourced hardware, it&amp;#39;s a milestone, the start of the end for one of the USA&amp;#39;s final monopolies that matter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0ua9v7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751408449,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751408449,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n0u6k23","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emprahsFury","can_mod_post":false,"created_utc":1751407261,"send_replies":false,"parent_id":"t1_n0tu62d","score":-3,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"100% not a huge story. If you are still surprised that China is doing things in China then that's on you. Not only is it literally the second largest economy in the world (and the largest if you let them game the score w pop numbers)- the Chinese govt has been specifically pursuing \\"Made in China 2025\\" since 2015. Has designated AI a national endeavor [since 2017](https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/). You guys are simply not allowed to be surprised at this stuff. Pay better attention to the world around you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u6k23","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;100% not a huge story. If you are still surprised that China is doing things in China then that&amp;#39;s on you. Not only is it literally the second largest economy in the world (and the largest if you let them game the score w pop numbers)- the Chinese govt has been specifically pursuing &amp;quot;Made in China 2025&amp;quot; since 2015. Has designated AI a national endeavor &lt;a href=\\"https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/\\"&gt;since 2017&lt;/a&gt;. You guys are simply not allowed to be surprised at this stuff. Pay better attention to the world around you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u6k23/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751407261,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tu62d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1751403549,"send_replies":true,"parent_id":"t3_1lp9gh2","score":8,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This feels like a huge story even outside of this community. Why are none of the big business channels discussing this?\\n\\nIsn't a big chunk of the US economy propped up by monopoly on training?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tu62d","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This feels like a huge story even outside of this community. Why are none of the big business channels discussing this?&lt;/p&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t a big chunk of the US economy propped up by monopoly on training?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tu62d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751403549,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0v1ctb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DataLearnerAI","can_mod_post":false,"created_utc":1751417659,"send_replies":true,"parent_id":"t3_1lp9gh2","score":2,"author_fullname":"t2_ilxa9crpd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This model appears highly competitive at the 30B parameter scale. In benchmark tests, it achieves a score of 73.70 on the GPQA Diamond dataset, which is comparable to the performance of DeepSeek R1’s older version. The overall benchmark results closely resemble those of Qwen-32B. Notably, this is a Mixture-of-Experts (MoE) model, where only about 16.5B parameters are activated during inference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0v1ctb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This model appears highly competitive at the 30B parameter scale. In benchmark tests, it achieves a score of 73.70 on the GPQA Diamond dataset, which is comparable to the performance of DeepSeek R1’s older version. The overall benchmark results closely resemble those of Qwen-32B. Notably, this is a Mixture-of-Experts (MoE) model, where only about 16.5B parameters are activated during inference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0v1ctb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751417659,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tubab","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tjxcl","score":9,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Haha, that's kind of an ironic comment to make on a model released by Huawei that was designed rather specifically for a Huawei product :).  Which is, to be clear, completely reasonable and is literately stated in the paper: \\"The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and 800I A2\\".\\n\\nWhile much like the Nivida models they aren't tied to their arch, the goals of the model seem to be to balance the pros and cons of their platform.  What's the point of a 70B MoE that would give similar functional performance to a 32B dense model?  Ah, their product is a 48GB / 400GBps processor so it makes sense to trade size for bandwidth requirements vs say a ~3090 which has 24GB / 1000GBps.  It also has a similar interest in balancing MoE activation to not overload bandwidth on distributed inference.\\n\\nSo it's a cool model and would be great for the B60 (if those are ever affordable) since those are lower bandwidth cards that seem to target distributed inference too, but it's definitely designed with their own product in mind.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tubab","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haha, that&amp;#39;s kind of an ironic comment to make on a model released by Huawei that was designed rather specifically for a Huawei product :).  Which is, to be clear, completely reasonable and is literately stated in the paper: &amp;quot;The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and 800I A2&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;While much like the Nivida models they aren&amp;#39;t tied to their arch, the goals of the model seem to be to balance the pros and cons of their platform.  What&amp;#39;s the point of a 70B MoE that would give similar functional performance to a 32B dense model?  Ah, their product is a 48GB / 400GBps processor so it makes sense to trade size for bandwidth requirements vs say a ~3090 which has 24GB / 1000GBps.  It also has a similar interest in balancing MoE activation to not overload bandwidth on distributed inference.&lt;/p&gt;\\n\\n&lt;p&gt;So it&amp;#39;s a cool model and would be great for the B60 (if those are ever affordable) since those are lower bandwidth cards that seem to target distributed inference too, but it&amp;#39;s definitely designed with their own product in mind.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tubab/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751403590,"author_flair_text":null,"treatment_tags":[],"created_utc":1751403590,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tjxcl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"secopsml","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t7w2a","score":-5,"author_fullname":"t2_pmniwf57y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It just feels natural for NVIDIA to just use their own products better than anyone else?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0tjxcl","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It just feels natural for NVIDIA to just use their own products better than anyone else?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0tjxcl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751400659,"author_flair_text":null,"treatment_tags":[],"created_utc":1751400659,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t7w2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1751397176,"send_replies":true,"parent_id":"t1_n0t06zq","score":14,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you mean? [Nvidia has released quite a few LLMs](https://huggingface.co/nvidia/collections).  They're kind of done as a tech demo I guess (like this AFAICT) though are apparently quite usable.  I've heard good things about \`Llama-3_3-Nemotron-Super-49B-v1\` in particular.","edited":1751398232,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t7w2a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you mean? &lt;a href=\\"https://huggingface.co/nvidia/collections\\"&gt;Nvidia has released quite a few LLMs&lt;/a&gt;.  They&amp;#39;re kind of done as a tech demo I guess (like this AFAICT) though are apparently quite usable.  I&amp;#39;ve heard good things about &lt;code&gt;Llama-3_3-Nemotron-Super-49B-v1&lt;/code&gt; in particular.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t7w2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751397176,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0u1nqg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mission_tiefsee","can_mod_post":false,"created_utc":1751405775,"send_replies":true,"parent_id":"t1_n0t06zq","score":1,"author_fullname":"t2_1l0xi85fdm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"they are busy ripping us of with their hardware.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u1nqg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they are busy ripping us of with their hardware.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u1nqg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751405775,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t6wz0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"created_utc":1751396895,"send_replies":true,"parent_id":"t1_n0t06zq","score":-6,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep 👍 either own ‘compute as a service’ or get Snowflake’d ❄️ 📊","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t6wz0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep 👍 either own ‘compute as a service’ or get Snowflake’d ❄️ 📊&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t6wz0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396895,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t06zq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"secopsml","can_mod_post":false,"created_utc":1751394991,"send_replies":true,"parent_id":"t3_1lp9gh2","score":3,"author_fullname":"t2_pmniwf57y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is what Nvidia should do","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t06zq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is what Nvidia should do&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0t06zq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751394991,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0u9ri8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"digitaltransmutation","can_mod_post":false,"created_utc":1751408284,"send_replies":true,"parent_id":"t1_n0u2u1n","score":10,"author_fullname":"t2_490mm32t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Weights are the result of the training. \\n\\nImagine you have a handful of 6-sided dice. When you throw them, you a bunch of random numbers every time, right? But if you pop them in the microwave for a bit, they will become weighted towards a desired result. \\n\\nNow, make a computer file that describes the changes you've made to the dice. Other people can apply the file to their own dice and enjoy the results. This is the 'weights' and why we like them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u9ri8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Weights are the result of the training. &lt;/p&gt;\\n\\n&lt;p&gt;Imagine you have a handful of 6-sided dice. When you throw them, you a bunch of random numbers every time, right? But if you pop them in the microwave for a bit, they will become weighted towards a desired result. &lt;/p&gt;\\n\\n&lt;p&gt;Now, make a computer file that describes the changes you&amp;#39;ve made to the dice. Other people can apply the file to their own dice and enjoy the results. This is the &amp;#39;weights&amp;#39; and why we like them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp9gh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u9ri8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751408284,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n0u2u1n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lyth","can_mod_post":false,"created_utc":1751406129,"send_replies":true,"parent_id":"t3_1lp9gh2","score":1,"author_fullname":"t2_4gtur","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What are \\"weights\\"?  Is it the relative importance of individual training data sets?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u2u1n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are &amp;quot;weights&amp;quot;?  Is it the relative importance of individual training data sets?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0u2u1n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751406129,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0w50hj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Subject-Giraffe-3879","can_mod_post":false,"created_utc":1751433114,"send_replies":true,"parent_id":"t3_1lp9gh2","score":1,"author_fullname":"t2_1ctk9dia0f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There are a lot of chinese characters that I can't read. What are the pros and cons of this model? Like what is it good at?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0w50hj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are a lot of chinese characters that I can&amp;#39;t read. What are the pros and cons of this model? Like what is it good at?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp9gh2/huawei_releases_an_open_weight_model_pangu_pro/n0w50hj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751433114,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp9gh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`);export{e as default};
