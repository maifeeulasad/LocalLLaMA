import{j as e}from"./index-DLSqWzaI.js";import{R as l}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const t=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello everyone, I heard that advanced paid models can work with function calls. Is it possible to do something similar with local functions?\\n\\n\\n\\nI have a large video archive with meta descriptions of videos. For example, interviews, or videos of cities, etc. There is also the size of the videos, their width, creation date.\\n\\nMeta information is collected in the sqllite3 database.\\n\\n\\n\\nThe idea is that I would make a request to the AI assistant.\\n\\n\\n\\n\\"Give me a video from Paris filmed before 2022.\\"\\n\\n\\n\\nAnd it creates an SQL query, makes a query to the database and returns the result found.\\n\\n\\n\\nI can do something like this in stages, passing the database structure and asking to create a query, and then enter this query manually and find the video in the folder. But I would like to do this without unnecessary manipulations.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Local LLM with SQL function support.","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2z10w","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_t32q22c6j","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752835529,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello everyone, I heard that advanced paid models can work with function calls. Is it possible to do something similar with local functions?&lt;/p&gt;\\n\\n&lt;p&gt;I have a large video archive with meta descriptions of videos. For example, interviews, or videos of cities, etc. There is also the size of the videos, their width, creation date.&lt;/p&gt;\\n\\n&lt;p&gt;Meta information is collected in the sqllite3 database.&lt;/p&gt;\\n\\n&lt;p&gt;The idea is that I would make a request to the AI assistant.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Give me a video from Paris filmed before 2022.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;And it creates an SQL query, makes a query to the database and returns the result found.&lt;/p&gt;\\n\\n&lt;p&gt;I can do something like this in stages, passing the database structure and asking to create a query, and then enter this query manually and find the video in the folder. But I would like to do this without unnecessary manipulations.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m2z10w","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"RandyHandyBoy","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2z10w/local_llm_with_sql_function_support/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m2z10w/local_llm_with_sql_function_support/","subreddit_subscribers":501232,"created_utc":1752835529,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3t0sng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RandyHandyBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3sovjh","score":1,"author_fullname":"t2_t32q22c6j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you for your help.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3t0sng","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for your help.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2z10w","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2z10w/local_llm_with_sql_function_support/n3t0sng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752842058,"author_flair_text":null,"treatment_tags":[],"created_utc":1752842058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3sovjh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Strange_Test7665","can_mod_post":false,"created_utc":1752837335,"send_replies":true,"parent_id":"t1_n3soqmj","score":2,"author_fullname":"t2_t0zjq9mi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen 2.5 7B instruct is the model I use locally for functions","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sovjh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 2.5 7B instruct is the model I use locally for functions&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2z10w","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2z10w/local_llm_with_sql_function_support/n3sovjh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752837335,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3soqmj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Strange_Test7665","can_mod_post":false,"created_utc":1752837274,"send_replies":true,"parent_id":"t3_1m2z10w","score":1,"author_fullname":"t2_t0zjq9mi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes. Definitely. There are many options out there for something like this. I have a local Qwen tool use I have been experimenting with. Here is a [Claud output](https://claude.ai/share/dd717015-426b-4645-bcfe-620dc45eb84d) to do what you’re talking about . I don’t use ollama but that’s probably the most popular local option interface for what you want","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3soqmj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes. Definitely. There are many options out there for something like this. I have a local Qwen tool use I have been experimenting with. Here is a &lt;a href=\\"https://claude.ai/share/dd717015-426b-4645-bcfe-620dc45eb84d\\"&gt;Claud output&lt;/a&gt; to do what you’re talking about . I don’t use ollama but that’s probably the most popular local option interface for what you want&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2z10w/local_llm_with_sql_function_support/n3soqmj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752837274,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2z10w","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),s=()=>e.jsx(l,{data:t});export{s as default};
