import{j as e}from"./index-DLSqWzaI.js";import{R as l}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I've seen people say 60/s and i've seen 22000/sec, I don't even know who to believe anymore.\\n\\nAlso how much does optimizing boost the tokens output speed?  ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How fast is gemma 3 27b on an H100? how many tokens per second can I expect?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m55rrt","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.86,"author_flair_background_color":null,"subreddit_type":"public","ups":33,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_48vjfixh","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":33,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753060835,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve seen people say 60/s and i&amp;#39;ve seen 22000/sec, I don&amp;#39;t even know who to believe anymore.&lt;/p&gt;\\n\\n&lt;p&gt;Also how much does optimizing boost the tokens output speed?  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m55rrt","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ThatIsNotIllegal","discussion_type":null,"num_comments":19,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/","subreddit_subscribers":502722,"created_utc":1753060835,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49so3t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1753064260,"send_replies":true,"parent_id":"t1_n49obbi","score":19,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would also further clarify that regardless of what GPU you happen to have, token generation is considered to be a memory-bound operation, meaning that while serving a single request the gpu will spend significant amount of time doing nothing while waiting for the next batch of weights to arrive into cache. That's how it has extra free time to compute the tokens for multiple users in parallel almost at the same rate as for the single user.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49so3t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would also further clarify that regardless of what GPU you happen to have, token generation is considered to be a memory-bound operation, meaning that while serving a single request the gpu will spend significant amount of time doing nothing while waiting for the next batch of weights to arrive into cache. That&amp;#39;s how it has extra free time to compute the tokens for multiple users in parallel almost at the same rate as for the single user.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n49so3t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753064260,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ben28","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shing3232","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4b58zg","score":7,"author_fullname":"t2_ze4mg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you need rent one  just to bench it","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ben28","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you need rent one  just to bench it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4ben28/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753093299,"author_flair_text":null,"treatment_tags":[],"created_utc":1753093299,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fdthm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShengrenR","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4f7ezk","score":1,"author_fullname":"t2_ji4n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hard to say, that's a benchmarking and math question.  If the h200 can only run 10 at a time and the other can run 20 (just as example).. how fast is the total throughput by comparison.. if the h200 is more than 2x as fast, it'll still be the better option for speed.","edited":false,"author_flair_css_class":null,"name":"t1_n4fdthm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hard to say, that&amp;#39;s a benchmarking and math question.  If the h200 can only run 10 at a time and the other can run 20 (just as example).. how fast is the total throughput by comparison.. if the h200 is more than 2x as fast, it&amp;#39;ll still be the better option for speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m55rrt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4fdthm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753138252,"author_flair_text":null,"collapsed":false,"created_utc":1753138252,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4f7ezk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThatIsNotIllegal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4f4so6","score":1,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If VRAM is the thing that determines how many requests I can batch would it make more sense to rent 10 A40's for $4/h and get 480GB VRAM rather than rent an H200 for the same price but only 141GB VRAM if my main goal is batching tens of thousands of small requests?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f7ezk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If VRAM is the thing that determines how many requests I can batch would it make more sense to rent 10 A40&amp;#39;s for $4/h and get 480GB VRAM rather than rent an H200 for the same price but only 141GB VRAM if my main goal is batching tens of thousands of small requests?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4f7ezk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753136161,"author_flair_text":null,"treatment_tags":[],"created_utc":1753136161,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4f4so6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShengrenR","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4b58zg","score":1,"author_fullname":"t2_ji4n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's basically how the scaling works; one caveat to keep in mind, that's batch inference: that means each of those requests needs their own VRAM space for context - so if you have 1024 context size max, you miight fit those 100-1000 requests in, but if you have 64k for each, nosir.  So your scaling is the gist of it, but with a hard stop-sign somewhere that's the 'you ran out of memory'.. roughly N requests x context window cost.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4f4so6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s basically how the scaling works; one caveat to keep in mind, that&amp;#39;s batch inference: that means each of those requests needs their own VRAM space for context - so if you have 1024 context size max, you miight fit those 100-1000 requests in, but if you have 64k for each, nosir.  So your scaling is the gist of it, but with a hard stop-sign somewhere that&amp;#39;s the &amp;#39;you ran out of memory&amp;#39;.. roughly N requests x context window cost.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4f4so6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135306,"author_flair_text":null,"treatment_tags":[],"created_utc":1753135306,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4b58zg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThatIsNotIllegal","can_mod_post":false,"created_utc":1753087982,"send_replies":true,"parent_id":"t1_n49obbi","score":10,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh okay, that works perfectly for me since I have a huge batch of small requests, correct me if I'm wrong but does it basically work like this?\\n\\n\\\\-1 simultaneous request -&gt; 60t/s -&gt; total: 60t/s\\n\\n\\\\-10 simultaneous requests -&gt; 50t/s -&gt; total 400t/s\\n\\n\\\\-100 simultaneous requests -&gt; 20/s -&gt; total 2000t/s\\n\\n\\\\-1000 simultaneous requests -&gt; 5t/s -&gt; total 5000t/s\\n\\nthe numbers are random but is my understanding of how scaling simultaneous requests works correct?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4b58zg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh okay, that works perfectly for me since I have a huge batch of small requests, correct me if I&amp;#39;m wrong but does it basically work like this?&lt;/p&gt;\\n\\n&lt;p&gt;-1 simultaneous request -&amp;gt; 60t/s -&amp;gt; total: 60t/s&lt;/p&gt;\\n\\n&lt;p&gt;-10 simultaneous requests -&amp;gt; 50t/s -&amp;gt; total 400t/s&lt;/p&gt;\\n\\n&lt;p&gt;-100 simultaneous requests -&amp;gt; 20/s -&amp;gt; total 2000t/s&lt;/p&gt;\\n\\n&lt;p&gt;-1000 simultaneous requests -&amp;gt; 5t/s -&amp;gt; total 5000t/s&lt;/p&gt;\\n\\n&lt;p&gt;the numbers are random but is my understanding of how scaling simultaneous requests works correct?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4b58zg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753087982,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n49obbi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"youcef0w0","can_mod_post":false,"created_utc":1753062644,"send_replies":true,"parent_id":"t3_1m55rrt","score":41,"author_fullname":"t2_49fdoure","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The answer is complicated and depends on a lot of things, including the settings you choose, how large your input context is, and how many concurrent requests you're processing \\n\\n\\nfor a single request by a single user, 60 t/s sounds about right \\n\\n\\nthe very big number is likely the total concurrent tokens per second given that many requests are being processed at the same time\\n\\n100 requests running at the same time at 22 t/s is 2200 concurrent tokens per second \\n\\nthe more users / requests you have running at the same time, the slower they are, but it's not linear, so that's why the high concurrency requests per second is much higher than the single request","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49obbi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The answer is complicated and depends on a lot of things, including the settings you choose, how large your input context is, and how many concurrent requests you&amp;#39;re processing &lt;/p&gt;\\n\\n&lt;p&gt;for a single request by a single user, 60 t/s sounds about right &lt;/p&gt;\\n\\n&lt;p&gt;the very big number is likely the total concurrent tokens per second given that many requests are being processed at the same time&lt;/p&gt;\\n\\n&lt;p&gt;100 requests running at the same time at 22 t/s is 2200 concurrent tokens per second &lt;/p&gt;\\n\\n&lt;p&gt;the more users / requests you have running at the same time, the slower they are, but it&amp;#39;s not linear, so that&amp;#39;s why the high concurrency requests per second is much higher than the single request&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n49obbi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062644,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":10,"removal_reason":null,"link_id":"t3_1m55rrt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":7,"removal_reason":null,"link_id":"t3_1m55rrt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":4,"removal_reason":null,"link_id":"t3_1m55rrt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aqtjy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shivacious","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4aqc4c","score":0,"author_fullname":"t2_chxnc83m9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Did sent u some ideas","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4aqtjy","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did sent u some ideas&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m55rrt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4aqtjy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753079728,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1753079728,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4aqc4c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4aq79z","score":4,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4aqc4c/","num_reports":null,"locked":false,"name":"t1_n4aqc4c","created":1753079462,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1753079462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n4aq79z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shivacious","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49p1ax","score":1,"author_fullname":"t2_chxnc83m9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Giveeee meeeeeeee some accessss (preferably with root) i will run a fine tuning lab","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aq79z","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Giveeee meeeeeeee some accessss (preferably with root) i will run a fine tuning lab&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4aq79z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753079386,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1753079386,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49p1ax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1753062912,"send_replies":true,"parent_id":"t1_n49oej2","score":7,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n49p1ax/","num_reports":null,"locked":false,"name":"t1_n49p1ax","created":1753062912,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n49oej2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheLumpyAvenger","can_mod_post":false,"created_utc":1753062677,"send_replies":true,"parent_id":"t1_n49naul","score":18,"author_fullname":"t2_ab8x94q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"a ton of H100\\" so just over 1665 accelerators, not bad.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49oej2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;a ton of H100&amp;quot; so just over 1665 accelerators, not bad.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n49oej2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062677,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"n49naul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1m55rrt","score":10,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n49naul/","num_reports":null,"locked":false,"name":"t1_n49naul","created":1753062269,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1753062269,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4act4d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"juggarjew","can_mod_post":false,"created_utc":1753072580,"send_replies":true,"parent_id":"t1_n4a91a4","score":2,"author_fullname":"t2_i2ox1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same here","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4act4d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same here&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4act4d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753072580,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dzc22","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"created_utc":1753123258,"send_replies":true,"parent_id":"t1_n4a91a4","score":0,"author_fullname":"t2_1tpuoj72sa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wrong. 5090 is quicker with FP4 and slower with FP8 and FP16.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dzc22","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wrong. 5090 is quicker with FP4 and slower with FP8 and FP16.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4dzc22/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753123258,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4a91a4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SillyLilBear","can_mod_post":false,"created_utc":1753070875,"send_replies":true,"parent_id":"t3_1m55rrt","score":5,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I get 62 tokens/sec on  a 5090, so it will likely be at least that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a91a4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I get 62 tokens/sec on  a 5090, so it will likely be at least that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4a91a4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753070875,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4atuje","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_postgres_situation","can_mod_post":false,"created_utc":1753081390,"send_replies":true,"parent_id":"t3_1m55rrt","score":7,"author_fullname":"t2_neruppu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Model from https://huggingface.co/unsloth/gemma-3-27b-it-GGUF/tree/main\\n\\n    $ llama-bench -ngl 99 -m gemma-3-27b-it-Q4_K_M.gguf;  llama-bench -ngl 99 -m gemma-3-27b-it-Q8_0.gguf \\n    ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\\n    ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\\n    ggml_cuda_init: found 1 CUDA devices:\\n    Device 0: NVIDIA H100L-47C, compute capability 9.0, VMM: no\\n    | model                          |       size |     params | backend    | ngl |            test |                  t/s |\\n    | ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |\\n    | gemma3 27B Q4_K - Medium       |  15.40 GiB |    27.01 B | CUDA       |  99 |           pp512 |       2312.88 ± 7.02 |\\n    | gemma3 27B Q4_K - Medium       |  15.40 GiB |    27.01 B | CUDA       |  99 |           tg128 |         57.30 ± 0.19 |\\n    | gemma3 27B Q8_0                |  26.73 GiB |    27.01 B | CUDA       |  99 |           pp512 |      2576.78 ± 52.41 |\\n    | gemma3 27B Q8_0                |  26.73 GiB |    27.01 B | CUDA       |  99 |           tg128 |         52.35 ± 0.28 |\\n    build: 494c5899 (5894)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4atuje","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Model from &lt;a href=\\"https://huggingface.co/unsloth/gemma-3-27b-it-GGUF/tree/main\\"&gt;https://huggingface.co/unsloth/gemma-3-27b-it-GGUF/tree/main&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;$ llama-bench -ngl 99 -m gemma-3-27b-it-Q4_K_M.gguf;  llama-bench -ngl 99 -m gemma-3-27b-it-Q8_0.gguf \\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\\nggml_cuda_init: found 1 CUDA devices:\\nDevice 0: NVIDIA H100L-47C, compute capability 9.0, VMM: no\\n| model                          |       size |     params | backend    | ngl |            test |                  t/s |\\n| ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |\\n| gemma3 27B Q4_K - Medium       |  15.40 GiB |    27.01 B | CUDA       |  99 |           pp512 |       2312.88 ± 7.02 |\\n| gemma3 27B Q4_K - Medium       |  15.40 GiB |    27.01 B | CUDA       |  99 |           tg128 |         57.30 ± 0.19 |\\n| gemma3 27B Q8_0                |  26.73 GiB |    27.01 B | CUDA       |  99 |           pp512 |      2576.78 ± 52.41 |\\n| gemma3 27B Q8_0                |  26.73 GiB |    27.01 B | CUDA       |  99 |           tg128 |         52.35 ± 0.28 |\\nbuild: 494c5899 (5894)\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4atuje/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753081390,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4a9mv8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tonsui","can_mod_post":false,"created_utc":1753071140,"send_replies":true,"parent_id":"t3_1m55rrt","score":5,"author_fullname":"t2_9qgubggb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can make a rough estimate yourself.  \\nAssuming a single H100 PCIe 80GB card running Gemma-3-27b-f16:  \\n2TB Bandwidth / 60GB model = roughly 33 tokens per second.  \\n  \\nOf course, factors like multiple SXM cards running simultaneously or model quantization will change these numbers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a9mv8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can make a rough estimate yourself.&lt;br/&gt;\\nAssuming a single H100 PCIe 80GB card running Gemma-3-27b-f16:&lt;br/&gt;\\n2TB Bandwidth / 60GB model = roughly 33 tokens per second.  &lt;/p&gt;\\n\\n&lt;p&gt;Of course, factors like multiple SXM cards running simultaneously or model quantization will change these numbers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4a9mv8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753071140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4a8ahn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTshop_ai","can_mod_post":false,"created_utc":1753070548,"send_replies":true,"parent_id":"t3_1m55rrt","score":1,"author_fullname":"t2_rkmud0isr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"which quant? the question cannot be answered without...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a8ahn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;which quant? the question cannot be answered without...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4a8ahn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753070548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aq98u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shivacious","can_mod_post":false,"created_utc":1753079417,"send_replies":true,"parent_id":"t1_n4agn6h","score":2,"author_fullname":"t2_chxnc83m9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My old gtx 1650 still works for plex transcoding so all good","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aq98u","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My old gtx 1650 still works for plex transcoding so all good&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4aq98u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753079417,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4b6f7k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"freeo","can_mod_post":false,"created_utc":1753088676,"send_replies":true,"parent_id":"t1_n4agn6h","score":1,"author_fullname":"t2_gz6yh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They will become the Amiga of AI. Great for hobbyists and people squeezing ever more use cases out of them. Think of the demoscene on C64 and Amiga. H100 will probably be considered too wasteful with energy and ofc  low speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4b6f7k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They will become the Amiga of AI. Great for hobbyists and people squeezing ever more use cases out of them. Think of the demoscene on C64 and Amiga. H100 will probably be considered too wasteful with energy and ofc  low speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m55rrt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4b6f7k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753088676,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4agn6h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EffervescentFacade","can_mod_post":false,"created_utc":1753074404,"send_replies":true,"parent_id":"t3_1m55rrt","score":1,"author_fullname":"t2_3f0wcqwt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'll have an h100 in about 8 years when they are considered nearly obsolete and are almost given away. \\nWhat do you guys that have them do? Are they for work or play? I'm not asking for job title and income.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4agn6h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll have an h100 in about 8 years when they are considered nearly obsolete and are almost given away. \\nWhat do you guys that have them do? Are they for work or play? I&amp;#39;m not asking for job title and income.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m55rrt/how_fast_is_gemma_3_27b_on_an_h100_how_many/n4agn6h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753074404,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m55rrt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
