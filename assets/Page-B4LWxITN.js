import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi everyone, it's Alan from Menlo Research.\\n\\nSince Jan-Nano, we've been curious about how far you can push the search capabilities of a small model. So, we decided to build a toy model named **Lucy**\\\\-**a compact but capable 1.7B model focused on search and lightweight browsing.**\\n\\n**What this model is good at:**\\n\\n* Strong agentic search via MCP-enabled tools (e.g., Serper with Google Search)\\n* Basic browsing capabilities through Crawl4AI (we‚Äôll release the MCP server used in the demo)\\n* Lightweight enough to run on CPU or mobile devices with decent speed, based on Qwen3-1.7B\\n\\n**How did we achieve this?**   \\nA paper is coming soon, but here are a few highlights:\\n\\n* We heavily optimized the reward function, making it smooth across multiple categories instead of using rigid or binary rewards (like traditional \`if-else\` logic)\\n* We introduced a new concept called *machine-generated task vectors*, which allows us to optimize the contents inside \`&lt;think&gt;&lt;/think&gt;\` tags. These serve as dynamic task vector generators, effectively fine-tuning the model's thinking process using RLVR to be more focused rather than relying on generic reasoning\\n* No supervised fine-tuning (SFT) was involved, everything was done through RLVR (which is very good at keeping model degradation at bay)\\n\\nWe originally aimed to reach a score of 80 on SimpleQA, but during evaluation we hit a kind of ‚Äúcommon sense‚Äù ceiling typical for 1.7B models. Even with test-time compute optimizations, we landed at 78.\\n\\nThis release purpose is only to help us sharpen our optimization technique for task vectors, we will follow up with future models that will be using this technique so we decided to release this as a experiment/ research. We are glad if you try it and like it still !!!\\n\\n**Use-case??** \\n\\nImagine a workflow where you can talk to your phone, ask it to research something, and it seamlessly **offloads tasks to your desktop at home browsing the web or accessing personal data.**\\n\\nIn the demo, the model is hosted on vLLM and integrated into the Jan app for demonstration purposes, but you're free to run it yourself. It connects to a Google Search API and a remote browser hosted on a desktop using Crawl4AI.\\n\\n# Links to models \\n\\nThere are 2 ways to run the model: with, and without YaRN. The repo with YaRN configuration can have pretty long context window (128k) and the normal repo can do 40k. Both having the same weight.If you have issues running or configuring YaRN I highly recommend use the Lucy vs Lucy-128k\\n\\n**Lucy:** [**https://huggingface.co/Menlo/Lucy**](https://huggingface.co/Menlo/Lucy)  \\n**Lucy-128k:** [**https://huggingface.co/Menlo/Lucy-128k**](https://huggingface.co/Menlo/Lucy-128k)  \\n**Paper (coming soon will be updated in collection):** [**https://huggingface.co/collections/Menlo/lucy-6879d21ab9c82dd410b231ca**](https://huggingface.co/collections/Menlo/lucy-6879d21ab9c82dd410b231ca)  \\n\\\\- Lucy: edgerunning agentic web search on mobile with machine generated task vectors.\\n\\n# Benchmark result\\n\\n* OpenAI o1: 42.6\\n* Grok 3: 44.6\\n* 03: 49.4\\n* Claude-3.7-Sonnet: 50.0\\n* Gemini-2.5 pro: 52.9\\n* ChatGPT-4.5: 62.5\\n* deepseek-671B-with-MCP: 78.2 (we benchmark using openrouter)\\n* **lucy-with-MCP: 78.3**\\n* jan-nano-with-MCP: 80.7\\n* jan-nano-128k-with-MCP: 83.2\\n\\n# Acknowledgement\\n\\n\\\\- As usual this experiment is not possible without the **amazing Qwen contribution to open source ai community**. We want to give a big shoutout to Qwen team and their relentless work in pushing boundary of open research/ai. The model was RL-ed on Qwen3-1.7B base weight.\\n\\n\\\\-----  \\nNote: sorry for the music in all the demos, i'm just a fan of Navjaxx, Narvent, V√òJ,..... üòÇ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Lucy: A Mobile-Capable 1.7B Reasoning Model That Rivals Jan-Nano","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2tjjc","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"ups":243,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_16kjuck66n","secure_media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/jsuhtdbbekdf1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1920,"width":1080,"scrubber_media_url":"https://v.redd.it/jsuhtdbbekdf1/DASH_96.mp4","dash_url":"https://v.redd.it/jsuhtdbbekdf1/DASHPlaylist.mpd?a=1755606653%2CZjI2NTUxZjZiNzg0NmNjNjY1ODQ5YWExZTcwZTU5NWVhMTkxY2QxNTZmMzM0YWNmOGJmOWY3MTZkMjZiMWEyMQ%3D%3D&amp;v=1&amp;f=sd","duration":53,"hls_url":"https://v.redd.it/jsuhtdbbekdf1/HLSPlaylist.m3u8?a=1755606653%2CZjdiY2YyMDNiYjg1YzZmYTg2Yjg0NWQ1YzU4Y2JhMmNjNWY2ZDM4MDc5NWIxMjI1ZmE1M2EzMDJlOTdkMDg1YQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":243,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=ed8de4e6bf5b95a6c3965c18d443655ff6da4b8e","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752814976,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi everyone, it&amp;#39;s Alan from Menlo Research.&lt;/p&gt;\\n\\n&lt;p&gt;Since Jan-Nano, we&amp;#39;ve been curious about how far you can push the search capabilities of a small model. So, we decided to build a toy model named &lt;strong&gt;Lucy&lt;/strong&gt;-&lt;strong&gt;a compact but capable 1.7B model focused on search and lightweight browsing.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;What this model is good at:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Strong agentic search via MCP-enabled tools (e.g., Serper with Google Search)&lt;/li&gt;\\n&lt;li&gt;Basic browsing capabilities through Crawl4AI (we‚Äôll release the MCP server used in the demo)&lt;/li&gt;\\n&lt;li&gt;Lightweight enough to run on CPU or mobile devices with decent speed, based on Qwen3-1.7B&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;How did we achieve this?&lt;/strong&gt;&lt;br/&gt;\\nA paper is coming soon, but here are a few highlights:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;We heavily optimized the reward function, making it smooth across multiple categories instead of using rigid or binary rewards (like traditional &lt;code&gt;if-else&lt;/code&gt; logic)&lt;/li&gt;\\n&lt;li&gt;We introduced a new concept called &lt;em&gt;machine-generated task vectors&lt;/em&gt;, which allows us to optimize the contents inside &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; tags. These serve as dynamic task vector generators, effectively fine-tuning the model&amp;#39;s thinking process using RLVR to be more focused rather than relying on generic reasoning&lt;/li&gt;\\n&lt;li&gt;No supervised fine-tuning (SFT) was involved, everything was done through RLVR (which is very good at keeping model degradation at bay)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;We originally aimed to reach a score of 80 on SimpleQA, but during evaluation we hit a kind of ‚Äúcommon sense‚Äù ceiling typical for 1.7B models. Even with test-time compute optimizations, we landed at 78.&lt;/p&gt;\\n\\n&lt;p&gt;This release purpose is only to help us sharpen our optimization technique for task vectors, we will follow up with future models that will be using this technique so we decided to release this as a experiment/ research. We are glad if you try it and like it still !!!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Use-case??&lt;/strong&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Imagine a workflow where you can talk to your phone, ask it to research something, and it seamlessly &lt;strong&gt;offloads tasks to your desktop at home browsing the web or accessing personal data.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;In the demo, the model is hosted on vLLM and integrated into the Jan app for demonstration purposes, but you&amp;#39;re free to run it yourself. It connects to a Google Search API and a remote browser hosted on a desktop using Crawl4AI.&lt;/p&gt;\\n\\n&lt;h1&gt;Links to models&lt;/h1&gt;\\n\\n&lt;p&gt;There are 2 ways to run the model: with, and without YaRN. The repo with YaRN configuration can have pretty long context window (128k) and the normal repo can do 40k. Both having the same weight.If you have issues running or configuring YaRN I highly recommend use the Lucy vs Lucy-128k&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Lucy:&lt;/strong&gt; &lt;a href=\\"https://huggingface.co/Menlo/Lucy\\"&gt;&lt;strong&gt;https://huggingface.co/Menlo/Lucy&lt;/strong&gt;&lt;/a&gt;&lt;br/&gt;\\n&lt;strong&gt;Lucy-128k:&lt;/strong&gt; &lt;a href=\\"https://huggingface.co/Menlo/Lucy-128k\\"&gt;&lt;strong&gt;https://huggingface.co/Menlo/Lucy-128k&lt;/strong&gt;&lt;/a&gt;&lt;br/&gt;\\n&lt;strong&gt;Paper (coming soon will be updated in collection):&lt;/strong&gt; &lt;a href=\\"https://huggingface.co/collections/Menlo/lucy-6879d21ab9c82dd410b231ca\\"&gt;&lt;strong&gt;https://huggingface.co/collections/Menlo/lucy-6879d21ab9c82dd410b231ca&lt;/strong&gt;&lt;/a&gt;&lt;br/&gt;\\n- Lucy: edgerunning agentic web search on mobile with machine generated task vectors.&lt;/p&gt;\\n\\n&lt;h1&gt;Benchmark result&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;OpenAI o1: 42.6&lt;/li&gt;\\n&lt;li&gt;Grok 3: 44.6&lt;/li&gt;\\n&lt;li&gt;03: 49.4&lt;/li&gt;\\n&lt;li&gt;Claude-3.7-Sonnet: 50.0&lt;/li&gt;\\n&lt;li&gt;Gemini-2.5 pro: 52.9&lt;/li&gt;\\n&lt;li&gt;ChatGPT-4.5: 62.5&lt;/li&gt;\\n&lt;li&gt;deepseek-671B-with-MCP: 78.2 (we benchmark using openrouter)&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;lucy-with-MCP: 78.3&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;jan-nano-with-MCP: 80.7&lt;/li&gt;\\n&lt;li&gt;jan-nano-128k-with-MCP: 83.2&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;Acknowledgement&lt;/h1&gt;\\n\\n&lt;p&gt;- As usual this experiment is not possible without the &lt;strong&gt;amazing Qwen contribution to open source ai community&lt;/strong&gt;. We want to give a big shoutout to Qwen team and their relentless work in pushing boundary of open research/ai. The model was RL-ed on Qwen3-1.7B base weight.&lt;/p&gt;\\n\\n&lt;p&gt;-----&lt;br/&gt;\\nNote: sorry for the music in all the demos, i&amp;#39;m just a fan of Navjaxx, Narvent, V√òJ,..... üòÇ&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/jsuhtdbbekdf1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?format=pjpg&amp;auto=webp&amp;s=5329141d47cd6c0020910d46c109895fc1f98344","width":1080,"height":1920},"resolutions":[{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=bcc37a4be0006c67682eddacbb8a34a4f028f800","width":108,"height":192},{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2d3768f368114f0e29d30c9096021787f335a890","width":216,"height":384},{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=af62e35789baac54a37eced414ac03ded47ca9f8","width":320,"height":568},{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2e6fdb8ca5998f999db7dbdc8734476d9d66e0d7","width":640,"height":1137},{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6bcb75175fbe1a08178d4c414988fa19dcb9d3b1","width":960,"height":1706},{"url":"https://external-preview.redd.it/NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=85dfbc9300990d6e4aabd6e87fef0d8bece89c9c","width":1080,"height":1920}],"variants":{},"id":"NW11ZTU4ZGRla2RmMRgI3SJPXdfuQ9Uf_Cd9X7MtqdJcOeQzkrhllhdwrzrv"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1m2tjjc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Kooky-Somewhere-2883","discussion_type":null,"num_comments":57,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/jsuhtdbbekdf1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1920,"width":1080,"scrubber_media_url":"https://v.redd.it/jsuhtdbbekdf1/DASH_96.mp4","dash_url":"https://v.redd.it/jsuhtdbbekdf1/DASHPlaylist.mpd?a=1755606653%2CZjI2NTUxZjZiNzg0NmNjNjY1ODQ5YWExZTcwZTU5NWVhMTkxY2QxNTZmMzM0YWNmOGJmOWY3MTZkMjZiMWEyMQ%3D%3D&amp;v=1&amp;f=sd","duration":53,"hls_url":"https://v.redd.it/jsuhtdbbekdf1/HLSPlaylist.m3u8?a=1755606653%2CZjdiY2YyMDNiYjg1YzZmYTg2Yjg0NWQ1YzU4Y2JhMmNjNWY2ZDM4MDc5NWIxMjI1ZmE1M2EzMDJlOTdkMDg1YQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/","stickied":false,"url":"https://v.redd.it/jsuhtdbbekdf1","subreddit_subscribers":501752,"created_utc":1752814976,"num_crossposts":0,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uc3rw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3tmssa","score":1,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep. I understood that, thanks.","edited":false,"author_flair_css_class":null,"name":"t1_n3uc3rw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep. I understood that, thanks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2tjjc","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3uc3rw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752856130,"author_flair_text":null,"collapsed":false,"created_utc":1752856130,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3tmssa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3tlkzs","score":6,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jan-nano is a model, Jan is the app, 2 things","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tmssa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan-nano is a model, Jan is the app, 2 things&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3tmssa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752848994,"author_flair_text":null,"treatment_tags":[],"created_utc":1752848994,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3tlkzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"waescher","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rnsw5","score":4,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is Jan? Might need to look into it, has been a long time.\\nWell I read about Jan-nano but I thought you‚Äôre just referring to a model. Thanks!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3tlkzs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is Jan? Might need to look into it, has been a long time.\\nWell I read about Jan-nano but I thought you‚Äôre just referring to a model. Thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3tlkzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752848644,"author_flair_text":null,"treatment_tags":[],"created_utc":1752848644,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rnsw5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752817431,"send_replies":true,"parent_id":"t1_n3rnhav","score":13,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ah yeah i mentioned in the content, it's Jan, but i connect it to a vLLM server.\\n\\nunfortunately it seems there is no jan mobile atm i just scale down the window.","edited":1752847852,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rnsw5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ah yeah i mentioned in the content, it&amp;#39;s Jan, but i connect it to a vLLM server.&lt;/p&gt;\\n\\n&lt;p&gt;unfortunately it seems there is no jan mobile atm i just scale down the window.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rnsw5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752817431,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rnhav","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"waescher","can_mod_post":false,"created_utc":1752817268,"send_replies":true,"parent_id":"t3_1m2tjjc","score":19,"author_fullname":"t2_1gpif4cz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sorry but what is this gorgeous looking chat client?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rnhav","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry but what is this gorgeous looking chat client?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rnhav/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752817268,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":7,"removal_reason":null,"link_id":"t3_1m2tjjc","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s12r9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752824532,"send_replies":true,"parent_id":"t1_n3s0v92","score":6,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm very happy that you found the model working well ! &lt;3 stay tuned for the paper and upcoming models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s12r9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m very happy that you found the model working well ! &amp;lt;3 stay tuned for the paper and upcoming models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3s12r9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752824532,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s0v92","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1m2tjjc","score":7,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3s0v92/","num_reports":null,"locked":false,"name":"t1_n3s0v92","created":1752824412,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1752824412,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rkcy1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752815716,"send_replies":true,"parent_id":"t1_n3rkc73","score":12,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We will follow up with a gguf soon","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rkcy1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We will follow up with a gguf soon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rkcy1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752815716,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sev04","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zestyclose_Yak_3174","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3sdtdy","score":2,"author_fullname":"t2_o0jgdhlij","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gotcha. Appreciate your elaborate response. Have been following your teams works since day 1.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3sev04","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gotcha. Appreciate your elaborate response. Have been following your teams works since day 1.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2tjjc","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sev04/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752832363,"author_flair_text":null,"treatment_tags":[],"created_utc":1752832363,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3sdtdy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3sczf7","score":2,"author_fullname":"t2_16kjuck66n","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I noticed this i think its a black hole in how we understand LLM.\\n\\n‚ÄúL and L Building‚Äù for example this single phrase will be treated entirely different depending on the size of the models and the change will be more drastic when the model is smaller\\n\\nIn a sense its not even possible to just do RL and expect the snall model to grasp the idea, but when RL happen its more like pushing whatever potential still there within the model.\\n\\nWhich means that 1.7B limitation will still be there under current scheme, but we have pushed all the possible ways to make every other paths that are possible to be better, to be, better (under the training scheme and same data).\\n\\nSo its better when its inherently capable of, and its the same where limitation is overally still huge improvement over baseline.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3sdtdy","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I noticed this i think its a black hole in how we understand LLM.&lt;/p&gt;\\n\\n&lt;p&gt;‚ÄúL and L Building‚Äù for example this single phrase will be treated entirely different depending on the size of the models and the change will be more drastic when the model is smaller&lt;/p&gt;\\n\\n&lt;p&gt;In a sense its not even possible to just do RL and expect the snall model to grasp the idea, but when RL happen its more like pushing whatever potential still there within the model.&lt;/p&gt;\\n\\n&lt;p&gt;Which means that 1.7B limitation will still be there under current scheme, but we have pushed all the possible ways to make every other paths that are possible to be better, to be, better (under the training scheme and same data).&lt;/p&gt;\\n\\n&lt;p&gt;So its better when its inherently capable of, and its the same where limitation is overally still huge improvement over baseline.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2tjjc","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sdtdy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752831798,"author_flair_text":null,"treatment_tags":[],"created_utc":1752831798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3sczf7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zestyclose_Yak_3174","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3scndu","score":2,"author_fullname":"t2_o0jgdhlij","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gotcha. So great proof of concept, decent for research and surprisably usable, yet not necessarily better than Nano yet.. Looking forward to testing this, although I've read there are some MacOS bugs currently with this setup.","edited":false,"author_flair_css_class":null,"name":"t1_n3sczf7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gotcha. So great proof of concept, decent for research and surprisably usable, yet not necessarily better than Nano yet.. Looking forward to testing this, although I&amp;#39;ve read there are some MacOS bugs currently with this setup.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2tjjc","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sczf7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752831329,"author_flair_text":null,"collapsed":false,"created_utc":1752831329,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3scndu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3scawq","score":4,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes and no, since the reward and training of this model is entirely different from jan-nano. We are trying to do a thing called ‚Äúmachine generated task vector optimization‚Äù which basically de-noise the reasoning process.\\n\\nThis whole premise can benefits many other things than just search, its just so happen that we decided to do this cuz we can leverage some data and code for training and learn the fastest.\\n\\nI think it will be clearer what im trying to say when the paper is out!\\n\\nBut again from a practical perspective yes, its pretty cool to reduce 65% params and still somewhat having relatively the same ability (not really but still in information extraction yes)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3scndu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and no, since the reward and training of this model is entirely different from jan-nano. We are trying to do a thing called ‚Äúmachine generated task vector optimization‚Äù which basically de-noise the reasoning process.&lt;/p&gt;\\n\\n&lt;p&gt;This whole premise can benefits many other things than just search, its just so happen that we decided to do this cuz we can leverage some data and code for training and learn the fastest.&lt;/p&gt;\\n\\n&lt;p&gt;I think it will be clearer what im trying to say when the paper is out!&lt;/p&gt;\\n\\n&lt;p&gt;But again from a practical perspective yes, its pretty cool to reduce 65% params and still somewhat having relatively the same ability (not really but still in information extraction yes)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3scndu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752831136,"author_flair_text":null,"treatment_tags":[],"created_utc":1752831136,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3scawq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zestyclose_Yak_3174","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3sa0ou","score":2,"author_fullname":"t2_o0jgdhlij","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is it considered better because it's approaching your earlier model yet smaller? Or because it's faster, less demanding? I understand that this size can be trained to work as an agent for web search but wouldn't intelligence be messed up? Especially for deep research? Would it have enough common sense and reasoning ability to be really useful or do you guys still recommend the larger Nano?","edited":1752831230,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3scawq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it considered better because it&amp;#39;s approaching your earlier model yet smaller? Or because it&amp;#39;s faster, less demanding? I understand that this size can be trained to work as an agent for web search but wouldn&amp;#39;t intelligence be messed up? Especially for deep research? Would it have enough common sense and reasoning ability to be really useful or do you guys still recommend the larger Nano?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3scawq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752830939,"author_flair_text":null,"treatment_tags":[],"created_utc":1752830939,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3sa0ou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752829616,"send_replies":true,"parent_id":"t1_n3rkc73","score":9,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"GGUF:  \\n[https://huggingface.co/Menlo/Lucy-gguf](https://huggingface.co/Menlo/Lucy-gguf)  \\n[https://huggingface.co/Menlo/Lucy-128k-gguf](https://huggingface.co/Menlo/Lucy-128k-gguf)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sa0ou","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GGUF:&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/Menlo/Lucy-gguf\\"&gt;https://huggingface.co/Menlo/Lucy-gguf&lt;/a&gt;&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/Menlo/Lucy-128k-gguf\\"&gt;https://huggingface.co/Menlo/Lucy-128k-gguf&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sa0ou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752829616,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3suvar","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3stw08","score":2,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hi we did in fact also benchmarked 8b and 14b last time. But right now due to a lot of changes in MCP and benchmarking code it's not equivalent to show anymore.\\n\\nThing is running 4k questions with mcp is quite costly (in term of api and gpu cost) so we only show some of relevant results.\\n\\nAt the end of the day, we don't have a plan to get 1.7B to beat the 32B model, like at all, our priority is based on the learning we target and want to learn, we will publish the benchmark code soon if someone want to contribute on that front.\\n\\nStay tuned since we will train 8B and 14B models very very soon with Jan and we will include the relevant size accordingly!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3suvar","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi we did in fact also benchmarked 8b and 14b last time. But right now due to a lot of changes in MCP and benchmarking code it&amp;#39;s not equivalent to show anymore.&lt;/p&gt;\\n\\n&lt;p&gt;Thing is running 4k questions with mcp is quite costly (in term of api and gpu cost) so we only show some of relevant results.&lt;/p&gt;\\n\\n&lt;p&gt;At the end of the day, we don&amp;#39;t have a plan to get 1.7B to beat the 32B model, like at all, our priority is based on the learning we target and want to learn, we will publish the benchmark code soon if someone want to contribute on that front.&lt;/p&gt;\\n\\n&lt;p&gt;Stay tuned since we will train 8B and 14B models very very soon with Jan and we will include the relevant size accordingly!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3suvar/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752839842,"author_flair_text":null,"treatment_tags":[],"created_utc":1752839842,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3stw08","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cms2307","can_mod_post":false,"created_utc":1752839454,"send_replies":true,"parent_id":"t1_n3rkc73","score":2,"author_fullname":"t2_1otju2ya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You need to evaluate frontier models using the same mcp servers and prompts as the smaller ones for an actual comparison. I would also be interested in seeing models like qwen3 14b/a3b/32b and Gemma 12b/27b benchmarked by you guys with the same conditions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3stw08","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need to evaluate frontier models using the same mcp servers and prompts as the smaller ones for an actual comparison. I would also be interested in seeing models like qwen3 14b/a3b/32b and Gemma 12b/27b benchmarked by you guys with the same conditions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3stw08/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752839454,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uowg3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RobbinDeBank","can_mod_post":false,"created_utc":1752859710,"send_replies":true,"parent_id":"t1_n3rkc73","score":1,"author_fullname":"t2_5dt1knqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are all the small models dominating all the leading proprietary models in this benchmark?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uowg3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are all the small models dominating all the leading proprietary models in this benchmark?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3uowg3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859710,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rkc73","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752815706,"send_replies":true,"parent_id":"t3_1m2tjjc","score":21,"author_fullname":"t2_16kjuck66n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/ci42b8e0hkdf1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=a44c83b3949b9b6c77f1e7ce0bbfc7aba21470f1\\n\\nBenchmark result","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rkc73","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/ci42b8e0hkdf1.png?width=1284&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a44c83b3949b9b6c77f1e7ce0bbfc7aba21470f1\\"&gt;https://preview.redd.it/ci42b8e0hkdf1.png?width=1284&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a44c83b3949b9b6c77f1e7ce0bbfc7aba21470f1&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Benchmark result&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rkc73/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752815706,"media_metadata":{"ci42b8e0hkdf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":106,"x":108,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eba289b65f46b4e1016672821f4f2fd7b635d891"},{"y":213,"x":216,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=390acf1c5525d931cfe712e5c30475eb1f1ddfd7"},{"y":316,"x":320,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d530be3706fc1b09cc0644b70c72ea0d4c5bf961"},{"y":632,"x":640,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=48c8c3aaa5c68ebef782a19f2ccc678694db9072"},{"y":948,"x":960,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=01f76ee7ef905a596972159a0dcbd0f9d0a1f760"},{"y":1066,"x":1080,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8573d28b19fc252fc43abeeb45eeb94f5c563da9"}],"s":{"y":1268,"x":1284,"u":"https://preview.redd.it/ci42b8e0hkdf1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=a44c83b3949b9b6c77f1e7ce0bbfc7aba21470f1"},"id":"ci42b8e0hkdf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sqimw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752838051,"send_replies":true,"parent_id":"t1_n3sml4a","score":2,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sqimw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sqimw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752838051,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3sml4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ArcaneThoughts","can_mod_post":false,"created_utc":1752836301,"send_replies":true,"parent_id":"t3_1m2tjjc","score":6,"author_fullname":"t2_hgivzvub","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3-1.7B is an insane model for its size, I'm glad to see people taking advantage of it, will try this today.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sml4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3-1.7B is an insane model for its size, I&amp;#39;m glad to see people taking advantage of it, will try this today.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sml4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752836301,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rp7iz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Valuable-Run2129","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rp5k2","score":2,"author_fullname":"t2_n1rqaeut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! Will do","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rp7iz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! Will do&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rp7iz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752818138,"author_flair_text":null,"treatment_tags":[],"created_utc":1752818138,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rp5k2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752818111,"send_replies":true,"parent_id":"t1_n3rp00e","score":4,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can join our discord they will actively support you to debug","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rp5k2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can join our discord they will actively support you to debug&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rp5k2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752818111,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rp00e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Valuable-Run2129","can_mod_post":false,"created_utc":1752818033,"send_replies":true,"parent_id":"t3_1m2tjjc","score":9,"author_fullname":"t2_n1rqaeut","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I look forward to trying it! But I still have an issue on Jan for mac. I can‚Äôt activate any mcps apart from fetch. I keep on getting errors, serper search in particular.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rp00e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I look forward to trying it! But I still have an issue on Jan for mac. I can‚Äôt activate any mcps apart from fetch. I keep on getting errors, serper search in particular.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rp00e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752818033,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rwiav","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rv6wo","score":2,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh even maybe not possible at all cuz RL is supposed to bring out the hidden ability of the model","edited":false,"author_flair_css_class":null,"name":"t1_n3rwiav","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh even maybe not possible at all cuz RL is supposed to bring out the hidden ability of the model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2tjjc","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rwiav/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752821986,"author_flair_text":null,"collapsed":false,"created_utc":1752821986,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rv6wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rtlrn","score":3,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ü§£we had to run &gt;100 diff training runs to get it right on the RL settings\\n\\nFor smaller i think there must be change or a total pretrain or very big sft finetune to basically teach the model to do a niche case otherwise i can see the pain of RL on 600M model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rv6wo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ü§£we had to run &amp;gt;100 diff training runs to get it right on the RL settings&lt;/p&gt;\\n\\n&lt;p&gt;For smaller i think there must be change or a total pretrain or very big sft finetune to basically teach the model to do a niche case otherwise i can see the pain of RL on 600M model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rv6wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752821285,"author_flair_text":null,"treatment_tags":[],"created_utc":1752821285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rtlrn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nixellion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rt1b6","score":4,"author_fullname":"t2_12fajr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nono, its great, dont get me wrong.\\n\\nI wonder though if it would be feasible to experiment with small MoE models? Something with &lt;=1B experts.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rtlrn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nono, its great, dont get me wrong.&lt;/p&gt;\\n\\n&lt;p&gt;I wonder though if it would be feasible to experiment with small MoE models? Something with &amp;lt;=1B experts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rtlrn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820442,"author_flair_text":null,"treatment_tags":[],"created_utc":1752820442,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rt1b6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752820140,"send_replies":true,"parent_id":"t1_n3rsar2","score":3,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah i understand, but 1.7B is also approaching the limit of current AI model as well\\n\\nits still running much better than the 4B tho","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rt1b6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah i understand, but 1.7B is also approaching the limit of current AI model as well&lt;/p&gt;\\n\\n&lt;p&gt;its still running much better than the 4B tho&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rt1b6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820140,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rsar2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nixellion","can_mod_post":false,"created_utc":1752819749,"send_replies":true,"parent_id":"t3_1m2tjjc","score":3,"author_fullname":"t2_12fajr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, I guess it means modern flagships.\\n\\nFold 5, for example, can run 1B at Q4 but its a bit on the slower side and it gets really hot. 1.7B will be slower and worse, especially with reasoning it will take a while to get a reply.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rsar2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, I guess it means modern flagships.&lt;/p&gt;\\n\\n&lt;p&gt;Fold 5, for example, can run 1B at Q4 but its a bit on the slower side and it gets really hot. 1.7B will be slower and worse, especially with reasoning it will take a while to get a reply.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rsar2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819749,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tejof","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"created_utc":1752846547,"send_replies":true,"parent_id":"t3_1m2tjjc","score":3,"author_fullname":"t2_86dk0gye","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jan Nano was a letdown in my custom MCP use cases (Autogen SelectorGroupChat).  \\nWhat about this one? had you tried multi-agent collaboration?  \\nI don't think small models can understand much about multi-agent approaches.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tejof","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan Nano was a letdown in my custom MCP use cases (Autogen SelectorGroupChat).&lt;br/&gt;\\nWhat about this one? had you tried multi-agent collaboration?&lt;br/&gt;\\nI don&amp;#39;t think small models can understand much about multi-agent approaches.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3tejof/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752846547,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3y25p4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752901492,"send_replies":true,"parent_id":"t1_n3twlhg","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i have 20 toks on my iphone 14","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y25p4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i have 20 toks on my iphone 14&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3y25p4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752901492,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3twlhg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xrailgun","can_mod_post":false,"created_utc":1752851752,"send_replies":true,"parent_id":"t3_1m2tjjc","score":3,"author_fullname":"t2_kggm5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably out of scope for this investigation, but FYI most modern phones, even midrange ones, can run Qwen 3 4B, at least at Q4_KM. I used it on ChatterUI app while on some flights without wifi. I imagine this would be a more capable size that *most* devices that can run 1.7B models can also run.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3twlhg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably out of scope for this investigation, but FYI most modern phones, even midrange ones, can run Qwen 3 4B, at least at Q4_KM. I used it on ChatterUI app while on some flights without wifi. I imagine this would be a more capable size that &lt;em&gt;most&lt;/em&gt; devices that can run 1.7B models can also run.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3twlhg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752851752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wipn1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u1j9s","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thank you","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wipn1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3wipn1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752879740,"author_flair_text":null,"treatment_tags":[],"created_utc":1752879740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u1j9s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lesser-than","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s0ovn","score":2,"author_fullname":"t2_98d256k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see, I had some luck with having the .6b delegated to by a planner llm but I didnt fully read what you were up to with the training for specific use case. 1.7 is still a great size for speed and cpu use, keep up the great work!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3u1j9s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see, I had some luck with having the .6b delegated to by a planner llm but I didnt fully read what you were up to with the training for specific use case. 1.7 is still a great size for speed and cpu use, keep up the great work!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3u1j9s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752853131,"author_flair_text":null,"treatment_tags":[],"created_utc":1752853131,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s0ovn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752824313,"send_replies":true,"parent_id":"t1_n3rwuf7","score":8,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We did analyze the response of multiple models size before making the decision.\\n\\nThe issue we're facing is that with extremely small model like 600M, the model will have some tendency to be confused on some \\"common sense\\".\\n\\nFor example it's very hard to get a model at a size of 600M to understand \\"L and L Building\\" is in fact one single entity or to treat it as such but it will tend to combine or separate the concept randomly leading to incorrect query, 4B or bigger models will have less and less of similar issue.\\n\\nThat makes 600M will likely be extremely hard to train with just RL, or not even possible at all because inherently the model is incapable of such behaviors or just \\"don't get it\\" and require bigger fixes than RL.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s0ovn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We did analyze the response of multiple models size before making the decision.&lt;/p&gt;\\n\\n&lt;p&gt;The issue we&amp;#39;re facing is that with extremely small model like 600M, the model will have some tendency to be confused on some &amp;quot;common sense&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;For example it&amp;#39;s very hard to get a model at a size of 600M to understand &amp;quot;L and L Building&amp;quot; is in fact one single entity or to treat it as such but it will tend to combine or separate the concept randomly leading to incorrect query, 4B or bigger models will have less and less of similar issue.&lt;/p&gt;\\n\\n&lt;p&gt;That makes 600M will likely be extremely hard to train with just RL, or not even possible at all because inherently the model is incapable of such behaviors or just &amp;quot;don&amp;#39;t get it&amp;quot; and require bigger fixes than RL.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3s0ovn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752824313,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rwuf7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lesser-than","can_mod_post":false,"created_utc":1752822168,"send_replies":true,"parent_id":"t3_1m2tjjc","score":4,"author_fullname":"t2_98d256k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"cool why not go all the way down to .6b qwen3? It can handle the tool calling too I think.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rwuf7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;cool why not go all the way down to .6b qwen3? It can handle the tool calling too I think.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rwuf7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752822168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sqmwz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752838101,"send_replies":true,"parent_id":"t1_n3silcr","score":2,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"to my experience it should run fine on pi5 \\n\\nmake sure to power it properly","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sqmwz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;to my experience it should run fine on pi5 &lt;/p&gt;\\n\\n&lt;p&gt;make sure to power it properly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3sqmwz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752838101,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3silcr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Akos-","can_mod_post":false,"created_utc":1752834337,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_3xk4s4iv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I‚Äôm impressed, and 1.7B parameters feels like I could comfortably run this on a Raspberry Pi 5. Can I, or does this secretly need an NVidia 5090 somewhere after all?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3silcr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I‚Äôm impressed, and 1.7B parameters feels like I could comfortably run this on a Raspberry Pi 5. Can I, or does this secretly need an NVidia 5090 somewhere after all?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3silcr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752834337,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wiz9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uzf25","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"oh nice will check","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wiz9h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh nice will check&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3wiz9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752879833,"author_flair_text":null,"treatment_tags":[],"created_utc":1752879833,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uzf25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fatihmtlm","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3t874r","score":2,"author_fullname":"t2_2l6wzu3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is Crosstalk app that has MCP SSE but I think SSE may require a proxy to connect regular MCP servers.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3uzf25","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is Crosstalk app that has MCP SSE but I think SSE may require a proxy to connect regular MCP servers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3uzf25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862690,"author_flair_text":null,"treatment_tags":[],"created_utc":1752862690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3t874r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752844549,"send_replies":true,"parent_id":"t1_n3t4a9t","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"issue is there is no mcp client on mobile.\\n\\nFor purely running the model you can do llamacpp on Android or similar options. You can also find any app that supports gguf","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3t874r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;issue is there is no mcp client on mobile.&lt;/p&gt;\\n\\n&lt;p&gt;For purely running the model you can do llamacpp on Android or similar options. You can also find any app that supports gguf&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3t874r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752844549,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3t4a9t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KanyeWestLover232","can_mod_post":false,"created_utc":1752843265,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_1n1epyvdzk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Guide on installing on phone?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3t4a9t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Guide on installing on phone?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3t4a9t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752843265,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3th3bk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752847315,"send_replies":true,"parent_id":"t1_n3tezjx","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you, we really spent a lot of time on that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3th3bk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you, we really spent a lot of time on that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3th3bk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752847315,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3tezjx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"viag","can_mod_post":false,"created_utc":1752846682,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_i3e2x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is super cool! I'm doing something very similar with RLVR for search on small models. I'm really looking forward to your paper! Very intrigued by what you did with task vectors. We have a PhD in our team working on this but not applied on reasoning","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tezjx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is super cool! I&amp;#39;m doing something very similar with RLVR for search on small models. I&amp;#39;m really looking forward to your paper! Very intrigued by what you did with task vectors. We have a PhD in our team working on this but not applied on reasoning&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3tezjx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752846682,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xi6gq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752892760,"send_replies":true,"parent_id":"t1_n3vd39v","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe if you have an MCP server that can run on the phone at the same time, you can browse your own phone content or search or have a Siri without internet connection at all, there are many possibilities.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xi6gq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe if you have an MCP server that can run on the phone at the same time, you can browse your own phone content or search or have a Siri without internet connection at all, there are many possibilities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3xi6gq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752892760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vd39v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CritStarrHD","can_mod_post":false,"created_utc":1752866719,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_174ex9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm curious, what's the point of using a smaller model on mobile? Wouldn't it be better to use something better on your pc or laptop? I don't really understand what's the point tbh, although it seems pretty cool","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vd39v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m curious, what&amp;#39;s the point of using a smaller model on mobile? Wouldn&amp;#39;t it be better to use something better on your pc or laptop? I don&amp;#39;t really understand what&amp;#39;s the point tbh, although it seems pretty cool&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3vd39v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866719,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3yc1d9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752906588,"send_replies":true,"parent_id":"t1_n3ybn6a","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"hi it should have thinking? have you checked anythingllm setting of displaying think tag?\\n\\ni heard many app using llamacpp having issue with think tag after recent version","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yc1d9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hi it should have thinking? have you checked anythingllm setting of displaying think tag?&lt;/p&gt;\\n\\n&lt;p&gt;i heard many app using llamacpp having issue with think tag after recent version&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3yc1d9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752906588,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n43zfgm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tcarambat","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yc39r","score":1,"author_fullname":"t2_1hrhzufptk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yep!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n43zfgm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yep!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n43zfgm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752983775,"author_flair_text":null,"treatment_tags":[],"created_utc":1752983775,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yc39r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752906617,"send_replies":true,"parent_id":"t1_n3ybn6a","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you for trying it out im very happy that the someone tested it on mobile , dows anythingllm support mcp?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yc39r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you for trying it out im very happy that the someone tested it on mobile , dows anythingllm support mcp?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3yc39r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752906617,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ybn6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tcarambat","can_mod_post":false,"created_utc":1752906377,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_1hrhzufptk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Got Lucy 1.7B running on AnythingLLM mobile on device - runs pretty fast (about on par with Qwen 1.7B as one would expect). A couple of notes/findings:\\n\\n* I do not have \`/no_think\` in the prompt, but i dont get thoughts, ever - even on many other prompts. Is that intentional?\\n* Tool calling works great, honestly.,\\n* There is some weird quirk where it *always* returns with a JSON text string for some reason - no idea why that is. I have looked all over but this is the only model having this issue.,\\n\\nEither way, totally awesome model. I tried to run Jan nano and it was just too much for my device and the performance vs output quality for a phone just wasnt worth it. Happy to see a 1.7B variant - hopefully a 0.6B coming?? Might include this as a default extra model when we ship the app later this month!\\n\\nVideo Demo: [https://youtube.com/shorts/9J5j58Fdz-k?feature=share](https://youtube.com/shorts/9J5j58Fdz-k?feature=share)\\n\\nhttps://preview.redd.it/z5uixpjwxrdf1.png?width=369&amp;format=png&amp;auto=webp&amp;s=5064452fadad287bd97d8e7b8f3f11cff69c95a6","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ybn6a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Got Lucy 1.7B running on AnythingLLM mobile on device - runs pretty fast (about on par with Qwen 1.7B as one would expect). A couple of notes/findings:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;I do not have &lt;code&gt;/no_think&lt;/code&gt; in the prompt, but i dont get thoughts, ever - even on many other prompts. Is that intentional?&lt;/li&gt;\\n&lt;li&gt;Tool calling works great, honestly.,&lt;/li&gt;\\n&lt;li&gt;There is some weird quirk where it &lt;em&gt;always&lt;/em&gt; returns with a JSON text string for some reason - no idea why that is. I have looked all over but this is the only model having this issue.,&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Either way, totally awesome model. I tried to run Jan nano and it was just too much for my device and the performance vs output quality for a phone just wasnt worth it. Happy to see a 1.7B variant - hopefully a 0.6B coming?? Might include this as a default extra model when we ship the app later this month!&lt;/p&gt;\\n\\n&lt;p&gt;Video Demo: &lt;a href=\\"https://youtube.com/shorts/9J5j58Fdz-k?feature=share\\"&gt;https://youtube.com/shorts/9J5j58Fdz-k?feature=share&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/z5uixpjwxrdf1.png?width=369&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5064452fadad287bd97d8e7b8f3f11cff69c95a6\\"&gt;https://preview.redd.it/z5uixpjwxrdf1.png?width=369&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5064452fadad287bd97d8e7b8f3f11cff69c95a6&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3ybn6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752906377,"media_metadata":{"z5uixpjwxrdf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":216,"x":108,"u":"https://preview.redd.it/z5uixpjwxrdf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=180c0f87d2fca192931615306da8ba31f44a9724"},{"y":432,"x":216,"u":"https://preview.redd.it/z5uixpjwxrdf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=533b42d4927f259408eae579bacb82b3c925fe32"},{"y":640,"x":320,"u":"https://preview.redd.it/z5uixpjwxrdf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d18b5f76c2e85a426e96dbbd73c8e3842b5dbf53"}],"s":{"y":800,"x":369,"u":"https://preview.redd.it/z5uixpjwxrdf1.png?width=369&amp;format=png&amp;auto=webp&amp;s=5064452fadad287bd97d8e7b8f3f11cff69c95a6"},"id":"z5uixpjwxrdf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n43t3mf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752981075,"send_replies":true,"parent_id":"t1_n41lvpx","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"on the demo it‚Äôs just to make it look nice.\\n\\nyou can run on phone, if you have an mcp enabled client.\\n\\nI tested on iphone 14 , around 20 toks per second still pretty high","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n43t3mf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;on the demo it‚Äôs just to make it look nice.&lt;/p&gt;\\n\\n&lt;p&gt;you can run on phone, if you have an mcp enabled client.&lt;/p&gt;\\n\\n&lt;p&gt;I tested on iphone 14 , around 20 toks per second still pretty high&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n43t3mf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752981075,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n41lvpx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lyth","can_mod_post":false,"created_utc":1752952915,"send_replies":true,"parent_id":"t3_1m2tjjc","score":2,"author_fullname":"t2_4gtur","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sorry for the noob question here.\\n\\nIf I'm understanding correctly, \\n\\nvLLM is an app for running an LLM on your desktop computer in a docker container.\\n\\nYou've got a mobile phone chat client, (in the video) that you're using to connect to that desktop computer. I assume through an OpenAI.v1 compatible endpoint?\\n\\nIs that correct?\\n\\nI'm seeing about 50 TPS on output. How beefy is the machine that's running this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n41lvpx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry for the noob question here.&lt;/p&gt;\\n\\n&lt;p&gt;If I&amp;#39;m understanding correctly, &lt;/p&gt;\\n\\n&lt;p&gt;vLLM is an app for running an LLM on your desktop computer in a docker container.&lt;/p&gt;\\n\\n&lt;p&gt;You&amp;#39;ve got a mobile phone chat client, (in the video) that you&amp;#39;re using to connect to that desktop computer. I assume through an OpenAI.v1 compatible endpoint?&lt;/p&gt;\\n\\n&lt;p&gt;Is that correct?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m seeing about 50 TPS on output. How beefy is the machine that&amp;#39;s running this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n41lvpx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752952915,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rmesk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"created_utc":1752816728,"send_replies":true,"parent_id":"t1_n3rlplb","score":11,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well actually it can run on llama.cpp on Android tho, i tested it ran fine\\n\\nBut there wont be a CLI client for MCP and it's quite tedious to code that yourself.\\n\\nHopefully there will be a mobile app with local AI and MCP client ability","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rmesk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well actually it can run on llama.cpp on Android tho, i tested it ran fine&lt;/p&gt;\\n\\n&lt;p&gt;But there wont be a CLI client for MCP and it&amp;#39;s quite tedious to code that yourself.&lt;/p&gt;\\n\\n&lt;p&gt;Hopefully there will be a mobile app with local AI and MCP client ability&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rmesk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752816728,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3secfh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s38xu","score":3,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow this is nice, can you point me to what this is","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3secfh","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow this is nice, can you point me to what this is&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3secfh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752832086,"author_flair_text":null,"treatment_tags":[],"created_utc":1752832086,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3secxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kooky-Somewhere-2883","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s38xu","score":1,"author_fullname":"t2_16kjuck66n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you a lot for trying out","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3secxk","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you a lot for trying out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3secxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752832094,"author_flair_text":null,"treatment_tags":[],"created_utc":1752832094,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s38xu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"beppled","can_mod_post":false,"created_utc":1752825743,"send_replies":true,"parent_id":"t1_n3rlplb","score":4,"author_fullname":"t2_uz4r9x7v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Runs great on pocketpal, working on remote MCP integration on a fork of it ..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s38xu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Runs great on pocketpal, working on remote MCP integration on a fork of it ..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2tjjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3s38xu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752825743,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rlplb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RickyRickC137","can_mod_post":false,"created_utc":1752816378,"send_replies":true,"parent_id":"t3_1m2tjjc","score":3,"author_fullname":"t2_mhdt7ir5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do we currently have an option to run this on mobile?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rlplb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do we currently have an option to run this on mobile?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2tjjc/lucy_a_mobilecapable_17b_reasoning_model_that/n3rlplb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752816378,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2tjjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
