import{j as e}from"./index-xfnGEtuL.js";import{R as t}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"There's a thing I don't understand about optimisation in DSPy: the documentation says that \\"A DSPy module has **learnable parameters** (i.e., the little pieces comprising the prompt and the LM weights)\\" (from [Learn DSPy → Modules](https://dspy.ai/learn/programming/modules/)).\\n\\nI understand optimising the phrasing in the prompt, but the LM weights... What does that mean? Am I actually **training/fine-tuning the model itself** there? This would only work for models that I host myself, i.e., if I have access to the model weights directly, I suppose? And it would not work for hosted models like a Lllama3.1 running at a generative API provider?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"DSPy Optimisation: What does \\"learning LM weights\\" mean?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7y3kl","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_mryyvspqj","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1753342776,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a thing I don&amp;#39;t understand about optimisation in DSPy: the documentation says that &amp;quot;A DSPy module has &lt;strong&gt;learnable parameters&lt;/strong&gt; (i.e., the little pieces comprising the prompt and the LM weights)&amp;quot; (from &lt;a href=\\"https://dspy.ai/learn/programming/modules/\\"&gt;Learn DSPy → Modules&lt;/a&gt;).&lt;/p&gt;\\n\\n&lt;p&gt;I understand optimising the phrasing in the prompt, but the LM weights... What does that mean? Am I actually &lt;strong&gt;training/fine-tuning the model itself&lt;/strong&gt; there? This would only work for models that I host myself, i.e., if I have access to the model weights directly, I suppose? And it would not work for hosted models like a Lllama3.1 running at a generative API provider?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?auto=webp&amp;s=58869403975928c74efe052d591cf82b456715d5","width":1200,"height":630},"resolutions":[{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbb37880d15b944e0f2a776bad7806b28cc013cf","width":108,"height":56},{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f6479238f7ab7ae51742a55d317d95cbb265dc79","width":216,"height":113},{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e8577aebcc7675fdb29e9e375864f76f3ab5c74c","width":320,"height":168},{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=224133edd8168702c2e5dc751ac17fd9a50b2fcb","width":640,"height":336},{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9001c17e93fe5127457807e69c2d5ab2e191d404","width":960,"height":504},{"url":"https://external-preview.redd.it/8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c712812a0310a9dca59e09ace836c2bd7afb7d5","width":1080,"height":567}],"variants":{},"id":"8BsuZmkFQPtfqVb3hZUPUQ_kVyVDX-opwB9Gb2-qh0o"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m7y3kl","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"soyokaze42","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7y3kl/dspy_optimisation_what_does_learning_lm_weights/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7y3kl/dspy_optimisation_what_does_learning_lm_weights/","subreddit_subscribers":503759,"created_utc":1753342776,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vdcv5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BenniB99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4vaj47","score":1,"author_fullname":"t2_17xncyy5vl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep you are right!  \\nLooks like it also works with the databricks provider or openai one via their API:   \\n[https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/databricks.py#L168](https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/databricks.py#L168)\\n\\n[https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/openai.py#L121](https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/openai.py#L121)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4vdcv5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep you are right!&lt;br/&gt;\\nLooks like it also works with the databricks provider or openai one via their API:&lt;br/&gt;\\n&lt;a href=\\"https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/databricks.py#L168\\"&gt;https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/databricks.py#L168&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/openai.py#L121\\"&gt;https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/openai.py#L121&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7y3kl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7y3kl/dspy_optimisation_what_does_learning_lm_weights/n4vdcv5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753350088,"author_flair_text":null,"treatment_tags":[],"created_utc":1753350088,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4vaj47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ClearApartment2627","can_mod_post":false,"created_utc":1753348487,"send_replies":true,"parent_id":"t1_n4v3ehf","score":1,"author_fullname":"t2_1p0o7y7278","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That method is overwritten with a proper implementation in some derived classes, e.g. the lm\\\\_local class:\\n\\n[https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/lm\\\\_local.py](https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/lm_local.py)\\n\\nIn theory, you should be able to finetune with the appropriate optimizer, BootstrapFinetune. I have never used it, though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vaj47","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That method is overwritten with a proper implementation in some derived classes, e.g. the lm_local class:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/lm_local.py\\"&gt;https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/lm_local.py&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;In theory, you should be able to finetune with the appropriate optimizer, BootstrapFinetune. I have never used it, though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7y3kl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7y3kl/dspy_optimisation_what_does_learning_lm_weights/n4vaj47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753348487,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4v3ehf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BenniB99","can_mod_post":false,"created_utc":1753344396,"send_replies":true,"parent_id":"t3_1m7y3kl","score":1,"author_fullname":"t2_17xncyy5vl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like they do support fine-tuning the model (at least the locally running ones): [https://dspy.ai/learn/optimization/optimizers/](https://dspy.ai/learn/optimization/optimizers/)\\n\\nThis can work if the provider in question has finetuning endpoints / services (like openai for instance).  \\nHowever it looks like that is not supported yet: [https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/provider.py#L101](https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/provider.py#L101)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4v3ehf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like they do support fine-tuning the model (at least the locally running ones): &lt;a href=\\"https://dspy.ai/learn/optimization/optimizers/\\"&gt;https://dspy.ai/learn/optimization/optimizers/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This can work if the provider in question has finetuning endpoints / services (like openai for instance).&lt;br/&gt;\\nHowever it looks like that is not supported yet: &lt;a href=\\"https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/provider.py#L101\\"&gt;https://github.com/stanfordnlp/dspy/blob/80412ce96d70fdb64dcf2c63940f511d6f89ca44/dspy/clients/provider.py#L101&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7y3kl/dspy_optimisation_what_does_learning_lm_weights/n4v3ehf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753344396,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7y3kl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),i=()=>e.jsx(t,{data:l});export{i as default};
