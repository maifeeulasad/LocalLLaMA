import{j as e}from"./index-BUtHYhT3.js";import{R as l}from"./RedditPostRenderer-BaN1Fn7z.js";import"./index-Cli9kp5v.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I am trying to figure out a way on how to teach ai to read help websites about software, like [Obsidian Help](https://help.obsidian.md/), [Python Dev Guide](https://devguide.python.org/), K[DEnlive Manual](https://docs.kdenlive.org/en/), [Inkscape Manual (latest version) ](https://inkscape-manuals.readthedocs.io/en/latest/index.html)or other guides/manuals/help websites.\\n\\nMy goal is to solve problems more efficient, but couldn't find a way to do so.\\n\\nI only figured out that ai can read websites, if you use # followed by a link, but it doesn't follow implemented links. Is there a way on following internal links (only links to the same website) and ask ai within this context or even save the knowledge to ask it even more in future?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How to teach AI to read a complete guide/manual/help website to ask questions about it?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lnbru7","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.44,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_5uy1ftuw","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751197842,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751194088,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I am trying to figure out a way on how to teach ai to read help websites about software, like &lt;a href=\\"https://help.obsidian.md/\\"&gt;Obsidian Help&lt;/a&gt;, &lt;a href=\\"https://devguide.python.org/\\"&gt;Python Dev Guide&lt;/a&gt;, K&lt;a href=\\"https://docs.kdenlive.org/en/\\"&gt;DEnlive Manual&lt;/a&gt;, &lt;a href=\\"https://inkscape-manuals.readthedocs.io/en/latest/index.html\\"&gt;Inkscape Manual (latest version) &lt;/a&gt;or other guides/manuals/help websites.&lt;/p&gt;\\n\\n&lt;p&gt;My goal is to solve problems more efficient, but couldn&amp;#39;t find a way to do so.&lt;/p&gt;\\n\\n&lt;p&gt;I only figured out that ai can read websites, if you use # followed by a link, but it doesn&amp;#39;t follow implemented links. Is there a way on following internal links (only links to the same website) and ask ai within this context or even save the knowledge to ask it even more in future?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lnbru7","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"utopify_org","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/","subreddit_subscribers":492929,"created_utc":1751194088,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0gijz2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"minnsoup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0gcxls","score":2,"author_fullname":"t2_ba9bm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I found that when trying to do it in a way that I'd find beneficial (providing hundreds of PDFs and then aggregating information across them) OpenWebUI will grab k number of chunks *from each document* rather than k top chunks. In this case it also fills the context super fast and then just fails to return anything. \\n\\nIf that's the use case or goal, better to make your own chunker and chromadb type thing then query that.","edited":false,"author_flair_css_class":null,"name":"t1_n0gijz2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found that when trying to do it in a way that I&amp;#39;d find beneficial (providing hundreds of PDFs and then aggregating information across them) OpenWebUI will grab k number of chunks &lt;em&gt;from each document&lt;/em&gt; rather than k top chunks. In this case it also fills the context super fast and then just fails to return anything. &lt;/p&gt;\\n\\n&lt;p&gt;If that&amp;#39;s the use case or goal, better to make your own chunker and chromadb type thing then query that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lnbru7","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0gijz2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751226158,"author_flair_text":null,"collapsed":false,"created_utc":1751226158,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0gcxls","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TjFr00","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0f03lu","score":1,"author_fullname":"t2_5lmlxzw0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for the explanation. OpenWebUI seems to stream the chunks non selectively … I’ve chunked them with 500 (128 overlap)… but yea. That „preselect“ would be my issue. … I’ll take the rabbit hole. Thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0gcxls","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the explanation. OpenWebUI seems to stream the chunks non selectively … I’ve chunked them with 500 (128 overlap)… but yea. That „preselect“ would be my issue. … I’ll take the rabbit hole. Thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0gcxls/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751224335,"author_flair_text":null,"treatment_tags":[],"created_utc":1751224335,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0f03lu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"minnsoup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0eqgla","score":2,"author_fullname":"t2_ba9bm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For RAG, you should be chunking the document. Meaning, the document gets \\"sliced\\" up into blocks of some size (say 500 words). These blocks can be set to overlap (and should). Then, when you ask your question some number of blocks are added to the models context. \\n\\nIf you're using RAG and the context is being filled then it sounds like chunk size is too big, too many chunks are being added to the context, or the full document is attempting to be added to context. Would need to play around with settings to make sure only relevant chunks are being used.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0f03lu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For RAG, you should be chunking the document. Meaning, the document gets &amp;quot;sliced&amp;quot; up into blocks of some size (say 500 words). These blocks can be set to overlap (and should). Then, when you ask your question some number of blocks are added to the models context. &lt;/p&gt;\\n\\n&lt;p&gt;If you&amp;#39;re using RAG and the context is being filled then it sounds like chunk size is too big, too many chunks are being added to the context, or the full document is attempting to be added to context. Would need to play around with settings to make sure only relevant chunks are being used.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0f03lu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751208962,"author_flair_text":null,"treatment_tags":[],"created_utc":1751208962,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0eqgla","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TjFr00","can_mod_post":false,"created_utc":1751205770,"send_replies":true,"parent_id":"t1_n0e3vfr","score":2,"author_fullname":"t2_5lmlxzw0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When doing this, even a 128k context model gets overloaded instantly. What’s your recommendation to solve that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0eqgla","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When doing this, even a 128k context model gets overloaded instantly. What’s your recommendation to solve that?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0eqgla/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751205770,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0eokoz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ec3q5","score":2,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You don't understand how information retrieval works for these pipelines, RAG is literally adding that vectorized data to the context window for you.\\n\\nWhat you are trying to achieve is instruction following, where the model calls each tool iteratively having 'scanned' each website.\\n\\nInstead you should [KBLaM your model](https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/) (read: ELT your data) or use Markdown to copy/paste for ICL (In-Context Learning)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0eokoz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don&amp;#39;t understand how information retrieval works for these pipelines, RAG is literally adding that vectorized data to the context window for you.&lt;/p&gt;\\n\\n&lt;p&gt;What you are trying to achieve is instruction following, where the model calls each tool iteratively having &amp;#39;scanned&amp;#39; each website.&lt;/p&gt;\\n\\n&lt;p&gt;Instead you should &lt;a href=\\"https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/\\"&gt;KBLaM your model&lt;/a&gt; (read: ELT your data) or use Markdown to copy/paste for ICL (In-Context Learning)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0eokoz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751205113,"author_flair_text":null,"treatment_tags":[],"created_utc":1751205113,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0gua1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"perelmanych","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ec3q5","score":1,"author_fullname":"t2_63q8kong","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or you have to write a script to scrap all the webpages you want and then upload them to RAG database, or what I would personally do is to find good books on subject in PDF format and feed them to Gemini PRO with 1mln context.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0gua1c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or you have to write a script to scrap all the webpages you want and then upload them to RAG database, or what I would personally do is to find good books on subject in PDF format and feed them to Gemini PRO with 1mln context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0gua1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751229882,"author_flair_text":null,"treatment_tags":[],"created_utc":1751229882,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ec3q5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"utopify_org","can_mod_post":false,"created_utc":1751200303,"send_replies":true,"parent_id":"t1_n0e3vfr","score":1,"author_fullname":"t2_5uy1ftuw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It doesn't work with a rag, because I have to visit every website by my own and copy every single link by hand.\\n\\nAnd Open Web-UI only supports files and directories for workspaces.\\n\\nMy goal is that the ai will recursively follow every link on the main page (only internal links) and get all information automatically. Copying by hand would be a very long task.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ec3q5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t work with a rag, because I have to visit every website by my own and copy every single link by hand.&lt;/p&gt;\\n\\n&lt;p&gt;And Open Web-UI only supports files and directories for workspaces.&lt;/p&gt;\\n\\n&lt;p&gt;My goal is that the ai will recursively follow every link on the main page (only internal links) and get all information automatically. Copying by hand would be a very long task.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnbru7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0ec3q5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751200303,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0e3vfr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Porespellar","can_mod_post":false,"created_utc":1751196454,"send_replies":true,"parent_id":"t3_1lnbru7","score":3,"author_fullname":"t2_y35oj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Setup RAG in Open WebUI. Load the manuals into a knowledge base. Connect the knowledge base to a custom model .\\n\\nStart here:\\nhttps://docs.openwebui.com/features/rag","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0e3vfr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Setup RAG in Open WebUI. Load the manuals into a knowledge base. Connect the knowledge base to a custom model .&lt;/p&gt;\\n\\n&lt;p&gt;Start here:\\n&lt;a href=\\"https://docs.openwebui.com/features/rag\\"&gt;https://docs.openwebui.com/features/rag&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnbru7/how_to_teach_ai_to_read_a_complete/n0e3vfr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751196454,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnbru7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
