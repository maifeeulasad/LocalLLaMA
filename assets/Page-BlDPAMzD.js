import{j as e}from"./index-CqAPCjw5.js";import{R as t}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Spent hours banging my head on the wall (and chatGPT and gemini not helping)\\n\\nI deployed Whisper-large-v3 in Vertex AI GCP:\\n\\n[https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/whisper-large](https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/whisper-large)\\n\\nVibe coded a script:\\n\\n\\n\\n    def transcribe_long_audio_correctly(\\n        project_id: str,\\n        region: str,\\n        endpoint_id: str,\\n        gcs_uri: str\\n    ):\\n        try:\\n            aiplatform.init(project=project_id, location=region)\\n            endpoint = aiplatform.Endpoint(endpoint_name=endpoint_id)\\n    \\n            instances = [\\n                {\\"audio\\": gcs_uri}\\n            ]\\n    \\n            # The \\"parameters\\" dictionary contains instructions for the model.\\n            parameters = {\\n                # \\"return_timestamps\\": True  &lt;-- THE PROBLEMATIC LINE\\n            }\\n    \\n            print(\\"Sending request with correct parameters...\\")\\n            \\n            prediction = endpoint.predict(instances=instances, parameters=parameters)\\n    \\n            print(\\"\\\\n✅ Transcription Result:\\")\\n            print(prediction.predictions[0])\\n    \\n        except Exception as e:\\n            print(f\\"An error occurred: {e}\\")\\n    \\n\\n  \\nIt works find for &lt;30 second files but fails with 500 error for &gt; 30 second files.\\n\\nThe solution apparently is to specify \\"return\\\\_timestamp\\": True but when I uncommend \\"THE PROBLEMATIC LINE\\" above it hates it:\\n\\n    Status code:422, response: {\\n    \\"deployedModelId\\" : \\"2999469919596183552\\",\\n    \\"detail\\" : \\n    [\\n    {\\n    \\"ctx\\" : \\n    {\\n    \\"error\\" : {}\\n    },\\n    \\"input\\" : \\n    {\\n    \\"return_timestamps\\" : true\\n    },\\n    \\"loc\\" : \\n    [\\n    \\"body\\",\\n    \\"parameters\\"\\n    ],\\n    \\"msg\\" : \\"Value error, Invalid return_timestamps: True\\",\\n    \\"type\\" : \\"value_error\\"\\n    }\\n    ],\\n    \\"model\\" : \\"projects/.../locations/europe-west2/models/openai_whisper-large-v3-1751953849719\\",\\n    \\"modelDisplayName\\" : \\"openai_whisper-large-v3-1751953849719\\",\\n    \\"modelVersionId\\" : \\"1\\"\\n    }\\n\\nIt definitely recognizes the \\"return\\\\_timestamps\\": parameter eg. renaming it with a typo it ignores it. \\n\\n  \\nI cannot understand how to set the correct \\"return\\\\_timestamps\\" parameter value - tried True, \\"True\\", \\"true\\", 1, 2, 0, \\"quack\\" and everything. It seems to require a Truthy string or bool but when i give it a valid value I get th errror above.\\n\\n  \\nheeeeelllpp???","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Whisper-large-v3 on VertexAI not supporting return_timstamps: True ?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":true,"name":"t3_1luig63","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_151nflle7h","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751959913,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Spent hours banging my head on the wall (and chatGPT and gemini not helping)&lt;/p&gt;\\n\\n&lt;p&gt;I deployed Whisper-large-v3 in Vertex AI GCP:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/whisper-large\\"&gt;https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/whisper-large&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Vibe coded a script:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;def transcribe_long_audio_correctly(\\n    project_id: str,\\n    region: str,\\n    endpoint_id: str,\\n    gcs_uri: str\\n):\\n    try:\\n        aiplatform.init(project=project_id, location=region)\\n        endpoint = aiplatform.Endpoint(endpoint_name=endpoint_id)\\n\\n        instances = [\\n            {&amp;quot;audio&amp;quot;: gcs_uri}\\n        ]\\n\\n        # The &amp;quot;parameters&amp;quot; dictionary contains instructions for the model.\\n        parameters = {\\n            # &amp;quot;return_timestamps&amp;quot;: True  &amp;lt;-- THE PROBLEMATIC LINE\\n        }\\n\\n        print(&amp;quot;Sending request with correct parameters...&amp;quot;)\\n        \\n        prediction = endpoint.predict(instances=instances, parameters=parameters)\\n\\n        print(&amp;quot;\\\\n✅ Transcription Result:&amp;quot;)\\n        print(prediction.predictions[0])\\n\\n    except Exception as e:\\n        print(f&amp;quot;An error occurred: {e}&amp;quot;)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;It works find for &amp;lt;30 second files but fails with 500 error for &amp;gt; 30 second files.&lt;/p&gt;\\n\\n&lt;p&gt;The solution apparently is to specify &amp;quot;return_timestamp&amp;quot;: True but when I uncommend &amp;quot;THE PROBLEMATIC LINE&amp;quot; above it hates it:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Status code:422, response: {\\n&amp;quot;deployedModelId&amp;quot; : &amp;quot;2999469919596183552&amp;quot;,\\n&amp;quot;detail&amp;quot; : \\n[\\n{\\n&amp;quot;ctx&amp;quot; : \\n{\\n&amp;quot;error&amp;quot; : {}\\n},\\n&amp;quot;input&amp;quot; : \\n{\\n&amp;quot;return_timestamps&amp;quot; : true\\n},\\n&amp;quot;loc&amp;quot; : \\n[\\n&amp;quot;body&amp;quot;,\\n&amp;quot;parameters&amp;quot;\\n],\\n&amp;quot;msg&amp;quot; : &amp;quot;Value error, Invalid return_timestamps: True&amp;quot;,\\n&amp;quot;type&amp;quot; : &amp;quot;value_error&amp;quot;\\n}\\n],\\n&amp;quot;model&amp;quot; : &amp;quot;projects/.../locations/europe-west2/models/openai_whisper-large-v3-1751953849719&amp;quot;,\\n&amp;quot;modelDisplayName&amp;quot; : &amp;quot;openai_whisper-large-v3-1751953849719&amp;quot;,\\n&amp;quot;modelVersionId&amp;quot; : &amp;quot;1&amp;quot;\\n}\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;It definitely recognizes the &amp;quot;return_timestamps&amp;quot;: parameter eg. renaming it with a typo it ignores it. &lt;/p&gt;\\n\\n&lt;p&gt;I cannot understand how to set the correct &amp;quot;return_timestamps&amp;quot; parameter value - tried True, &amp;quot;True&amp;quot;, &amp;quot;true&amp;quot;, 1, 2, 0, &amp;quot;quack&amp;quot; and everything. It seems to require a Truthy string or bool but when i give it a valid value I get th errror above.&lt;/p&gt;\\n\\n&lt;p&gt;heeeeelllpp???&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1luig63","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Worldly-Side9489","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1luig63/whisperlargev3_on_vertexai_not_supporting_return/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1luig63/whisperlargev3_on_vertexai_not_supporting_return/","subreddit_subscribers":496036,"created_utc":1751959913,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1y68sf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Worldly-Side9489","can_mod_post":false,"created_utc":1751960696,"send_replies":true,"parent_id":"t3_1luig63","score":1,"author_fullname":"t2_151nflle7h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OK scrap all that\\n\\nSetting \\"return\\\\_timestamps\\": \\"word\\" cleared this error (yay for vibe coding) but now the 500 errors I'm getting are because of some internal bug oh joy,\\n\\nAny tips on resolving or avoiding this?\\n\\nhttps://preview.redd.it/1sgrznsjulbf1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=9fc516a6485c49694e7c050b05c2f0344a67fba5","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1y68sf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OK scrap all that&lt;/p&gt;\\n\\n&lt;p&gt;Setting &amp;quot;return_timestamps&amp;quot;: &amp;quot;word&amp;quot; cleared this error (yay for vibe coding) but now the 500 errors I&amp;#39;m getting are because of some internal bug oh joy,&lt;/p&gt;\\n\\n&lt;p&gt;Any tips on resolving or avoiding this?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/1sgrznsjulbf1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fc516a6485c49694e7c050b05c2f0344a67fba5\\"&gt;https://preview.redd.it/1sgrznsjulbf1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9fc516a6485c49694e7c050b05c2f0344a67fba5&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luig63/whisperlargev3_on_vertexai_not_supporting_return/n1y68sf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751960696,"media_metadata":{"1sgrznsjulbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":53,"x":108,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddd1cbd718365de8abf801247d02a6b8b167e204"},{"y":107,"x":216,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e442339783a7af5b1195277939b3e0551e22192c"},{"y":158,"x":320,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e65f13e711774679b11a57330601e7179ff7714"},{"y":317,"x":640,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cec7f2c87c61c7f1bd3091e22b13bd255829fcfa"},{"y":476,"x":960,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6b37c4a5cd18e59d60fd1d54ead14a57f7aaff78"},{"y":535,"x":1080,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e9174ee844b890e3f1c926a5cb27a27e4f1965c1"}],"s":{"y":767,"x":1546,"u":"https://preview.redd.it/1sgrznsjulbf1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=9fc516a6485c49694e7c050b05c2f0344a67fba5"},"id":"1sgrznsjulbf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luig63","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1y9px3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LinkSea8324","can_mod_post":false,"created_utc":1751962729,"send_replies":true,"parent_id":"t3_1luig63","score":2,"author_fullname":"t2_152zyn72n4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Asking for help on locallama about a paid SST API ??\\n\\njust ask them directly ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1y9px3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Asking for help on locallama about a paid SST API ??&lt;/p&gt;\\n\\n&lt;p&gt;just ask them directly ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luig63/whisperlargev3_on_vertexai_not_supporting_return/n1y9px3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751962729,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1luig63","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),o=()=>e.jsx(t,{data:a});export{o as default};
