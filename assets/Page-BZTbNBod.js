import{j as e}from"./index-Bu7qcPAU.js";import{R as l}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I just had a $10k Mac Studio arrive. The first thing I installed was LM Studio. I downloaded qwen3-235b-a22b and fired it up. Fantastic performance with a small system prompt. I fired up devstral and tried to use it with Cline (a large system prompt agent) and very quickly discovered limitations. I managed to instruct the poor LLM to load the memory bank but it lacked all the comprehension that I get from google gemini. Next I'm going to try to use devstral in Act mode only and see if I can at least get some tool usage and code generation out of it, but I have serious doubts it will even work. I think a bigger reasoning model is needed for my use cases and this system would just be too slow to accomplish that.\\n\\nThat said, I wanted to share my experiences with the community. If anyone is thinking about buying a mac studio for LLMs, I'm happy to run any sort of use case evaluation for you to help you make your decision. Just comment in here and be sure to upvote if you do so other people see the post and can ask questions too.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Mac Studio 512GB online!","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lumsd2","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.89,"author_flair_background_color":null,"subreddit_type":"public","ups":178,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_cbxyn","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":178,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","author_cakeday":true,"edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751976260,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I just had a $10k Mac Studio arrive. The first thing I installed was LM Studio. I downloaded qwen3-235b-a22b and fired it up. Fantastic performance with a small system prompt. I fired up devstral and tried to use it with Cline (a large system prompt agent) and very quickly discovered limitations. I managed to instruct the poor LLM to load the memory bank but it lacked all the comprehension that I get from google gemini. Next I&amp;#39;m going to try to use devstral in Act mode only and see if I can at least get some tool usage and code generation out of it, but I have serious doubts it will even work. I think a bigger reasoning model is needed for my use cases and this system would just be too slow to accomplish that.&lt;/p&gt;\\n\\n&lt;p&gt;That said, I wanted to share my experiences with the community. If anyone is thinking about buying a mac studio for LLMs, I&amp;#39;m happy to run any sort of use case evaluation for you to help you make your decision. Just comment in here and be sure to upvote if you do so other people see the post and can ask questions too.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lumsd2","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"chisleu","discussion_type":null,"num_comments":144,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/","subreddit_subscribers":497025,"created_utc":1751976260,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"The first thing I want to point out is the load speed. It only takes 3 seconds to load the 132GB qwen3-235b-a22b.\\n\\nI gave Qwen a prompt:\\nHello Gwen. I'm working on a JRPG with combat similar to final fantasy 1. It's gameplay and storyline are going to be infused with LLM generated text and an optional AI narrator.\\n\\n27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.\\n\\nI'm going to need some help with giving you results for other models. When I search for llama 3.1 405b in lm studio, I get hundreds of results.\\n\\nedit: I'm downloading mlx-community/Metal-Llama-3.1-405b-4bit","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Maybe that is the case, but it sure seems to load in LM Studio. I do see memory usage go through the roof as the model loads and once it's loaded, I'm seeing under 2 seconds before first token. I bought the 4TB SSD model because it has maxed out SSD throughput. (8 chips on two modules in the unit).\\n\\nI will run an SSD benchmark for our edification. It should be crazy fast.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n205bwp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jsebrech","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zf01a","score":8,"author_fullname":"t2_13xekk","approved_by":null,"mod_note":null,"all_awardings":[],"body":"They wouldn't even need to load it before. If they downloaded the model and then immediately loaded it in LM Studio it would be loaded from MacOS in-memory file cache instead of from disk. MacOS will use all unused RAM for caching files if it can.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n205bwp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They wouldn&amp;#39;t even need to load it before. If they downloaded the model and then immediately loaded it in LM Studio it would be loaded from MacOS in-memory file cache instead of from disk. MacOS will use all unused RAM for caching files if it can.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n205bwp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751989538,"author_flair_text":null,"treatment_tags":[],"created_utc":1751989538,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zf01a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tomz17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zdmb8","score":9,"author_fullname":"t2_1mhx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My guess is that you loaded it at least once before (and ran a prompt) so that everything is still in memory.  Cold-reboot the machine and then measure t/s for the first few paragraphs (while watching disk reads) if you want to see the effect in action.\\n\\n&gt; I will run an SSD benchmark for our edification. It should be crazy fast.\\n\\nPrediction: nowhere remotely close to 44GB/s...    (i.e. 132GB / 3seconds)","edited":false,"author_flair_css_class":null,"name":"t1_n1zf01a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My guess is that you loaded it at least once before (and ran a prompt) so that everything is still in memory.  Cold-reboot the machine and then measure t/s for the first few paragraphs (while watching disk reads) if you want to see the effect in action.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;I will run an SSD benchmark for our edification. It should be crazy fast.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Prediction: nowhere remotely close to 44GB/s...    (i.e. 132GB / 3seconds)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zf01a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981757,"author_flair_text":null,"collapsed":false,"created_utc":1751981757,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zdmb8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z98sq","score":6,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zdmb8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe that is the case, but it sure seems to load in LM Studio. I do see memory usage go through the roof as the model loads and once it&amp;#39;s loaded, I&amp;#39;m seeing under 2 seconds before first token. I bought the 4TB SSD model because it has maxed out SSD throughput. (8 chips on two modules in the unit).&lt;/p&gt;\\n\\n&lt;p&gt;I will run an SSD benchmark for our edification. It should be crazy fast.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zdmb8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981297,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981297,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z98sq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tomz17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z5jof","score":18,"author_fullname":"t2_1mhx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;It only takes 3 seconds to load the 132GB qwen3-235b-a22b.\\n\\nThat is unlikely to be actually true.  The backed is most certainly just memory-mapping the file(s), which means that when you read a block the first time it still needs to be loaded from disk (unless it has been previously read and is still in memory).  So yeah, the prompt that says \\"loading\\" is quick, but the bits you need are still on the disk.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1z98sq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;It only takes 3 seconds to load the 132GB qwen3-235b-a22b.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That is unlikely to be actually true.  The backed is most certainly just memory-mapping the file(s), which means that when you read a block the first time it still needs to be loaded from disk (unless it has been previously read and is still in memory).  So yeah, the prompt that says &amp;quot;loading&amp;quot; is quick, but the bits you need are still on the disk.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z98sq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979796,"author_flair_text":null,"treatment_tags":[],"created_utc":1751979796,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Roger, I seem to be limited to 60MB/s. I really need to relocate this thing to the living room next to the router so it can be hard wired. wifi is trash around here.\\n\\nI'm downloading two models right now. When it's done I'll download the one you mentioned. \\n\\nI hope that MLX is higher performance than GGUF. I'll give some direct comparisons a try, but honestly for my purposes, performance is only important on tiny models (like gemma3n) and performance is great for my purposes there. Now I can stop using gemini (and stop getting tier limit errors and paying $$ as a result).\\n\\nThe real purpose for this purchase was to see if I could get some of the reasoning tool models like qwen to function with my Cline agent. It doesn't matter if it's too slow for real use. If I can get it to function for my purposes, then that means I can order a big GPU rig to replace my use of Anthropic Claude Sonnet 4.0 for Act mode in Cline. Then I can stop sending my data to anthropic and start being self reliant WRT LLM usage.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zaa7j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z7nnz","score":5,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":1751980404,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zaa7j","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Roger, I seem to be limited to 60MB/s. I really need to relocate this thing to the living room next to the router so it can be hard wired. wifi is trash around here.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m downloading two models right now. When it&amp;#39;s done I&amp;#39;ll download the one you mentioned. &lt;/p&gt;\\n\\n&lt;p&gt;I hope that MLX is higher performance than GGUF. I&amp;#39;ll give some direct comparisons a try, but honestly for my purposes, performance is only important on tiny models (like gemma3n) and performance is great for my purposes there. Now I can stop using gemini (and stop getting tier limit errors and paying $$ as a result).&lt;/p&gt;\\n\\n&lt;p&gt;The real purpose for this purchase was to see if I could get some of the reasoning tool models like qwen to function with my Cline agent. It doesn&amp;#39;t matter if it&amp;#39;s too slow for real use. If I can get it to function for my purposes, then that means I can order a big GPU rig to replace my use of Anthropic Claude Sonnet 4.0 for Act mode in Cline. Then I can stop sending my data to anthropic and start being self reliant WRT LLM usage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zaa7j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980162,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z7nnz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"s101c","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z5jof","score":4,"author_fullname":"t2_rg6hb6my5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"With MLX (I personally haven't tested) there are reports of it being slower than regular GGUFs (llama.cpp) with large models:\\n\\nhttps://github.com/lmstudio-ai/mlx-engine/issues/101\\n\\nBasically, your LM Studio installation includes two engines: mlx and llama.cpp. They are updated frequently, independently from LM Studio itself.\\n\\nFor Llama 3.1 405B I would recommend this quant:\\n\\nmradermacher/Meta-Llama-3.1-405B-Instruct-i1-GGUF\\n\\nIf you select Q4_K_M, it will be around 250 GB in size.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1z7nnz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With MLX (I personally haven&amp;#39;t tested) there are reports of it being slower than regular GGUFs (llama.cpp) with large models:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lmstudio-ai/mlx-engine/issues/101\\"&gt;https://github.com/lmstudio-ai/mlx-engine/issues/101&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Basically, your LM Studio installation includes two engines: mlx and llama.cpp. They are updated frequently, independently from LM Studio itself.&lt;/p&gt;\\n\\n&lt;p&gt;For Llama 3.1 405B I would recommend this quant:&lt;/p&gt;\\n\\n&lt;p&gt;mradermacher/Meta-Llama-3.1-405B-Instruct-i1-GGUF&lt;/p&gt;\\n\\n&lt;p&gt;If you select Q4_K_M, it will be around 250 GB in size.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z7nnz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979234,"author_flair_text":null,"treatment_tags":[],"created_utc":1751979234,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n277zy4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Danfhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_n272c7n","score":1,"author_fullname":"t2_7nl3j","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I want to do more comparisons for speed, because with does appear some cases similar-sized GGUF quants still outperform the MLX quants on my M1 ultra.\\n\\nMy biggest joy is being able to quantize models directly from HF and not needing to rely on others, which I know could easily be done with llama.cpp but hey. A drawback is that MLX-LM is still super young so it takes a bit longer for newer models to be supported; I just saw a merge today for Dots support.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n277zy4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to do more comparisons for speed, because with does appear some cases similar-sized GGUF quants still outperform the MLX quants on my M1 ultra.&lt;/p&gt;\\n\\n&lt;p&gt;My biggest joy is being able to quantize models directly from HF and not needing to rely on others, which I know could easily be done with llama.cpp but hey. A drawback is that MLX-LM is still super young so it takes a bit longer for newer models to be supported; I just saw a merge today for Dots support.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n277zy4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752078061,"author_flair_text":null,"treatment_tags":[],"created_utc":1752078061,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n272c7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RagingAnemone","can_mod_post":false,"send_replies":true,"parent_id":"t1_n25o6zm","score":2,"author_fullname":"t2_3l83h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting.  Looks like I need to try MLX.  I've been using llamacpp since I started on linux.","edited":false,"author_flair_css_class":null,"name":"t1_n272c7n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting.  Looks like I need to try MLX.  I&amp;#39;ve been using llamacpp since I started on linux.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n272c7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752076502,"author_flair_text":null,"collapsed":false,"created_utc":1752076502,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n25o6zm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Danfhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_n23kx5f","score":1,"author_fullname":"t2_7nl3j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I picked up a used m1 ultra 64c 128GB/4TB\\n\\nQwen3 235 A22B MLX 3/4bit mixed quant (100.70 GB model)\\n\\nSame prompt:\\n\\n    \\"tokensPerSecond\\": 18.83903183848165, \\n    \\"timeToFirstTokenSec\\": 0.384,\\n    \\"promptTokensCount\\": 48,\\n    \\"predictedTokensCount\\": 1136,\\n    \\"totalTokensCount\\": 1184","edited":1752061119,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25o6zm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I picked up a used m1 ultra 64c 128GB/4TB&lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 235 A22B MLX 3/4bit mixed quant (100.70 GB model)&lt;/p&gt;\\n\\n&lt;p&gt;Same prompt:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;&amp;quot;tokensPerSecond&amp;quot;: 18.83903183848165, \\n&amp;quot;timeToFirstTokenSec&amp;quot;: 0.384,\\n&amp;quot;promptTokensCount&amp;quot;: 48,\\n&amp;quot;predictedTokensCount&amp;quot;: 1136,\\n&amp;quot;totalTokensCount&amp;quot;: 1184\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n25o6zm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752060892,"author_flair_text":null,"treatment_tags":[],"created_utc":1752060892,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n23kx5f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RagingAnemone","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z5jof","score":2,"author_fullname":"t2_3l83h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice.  I went with the $6k Mac Studio and this is what I got with the same prompt on Qwen.\\n\\n\\n\\nprompt eval time =    4569.80 ms /    48 tokens (   95.20 ms per token,    10.50 tokens per second)\\n\\neval time =  101055.88 ms /  1620 tokens (   62.38 ms per token,    16.03 tokens per second)\\n\\ntotal time =  105625.68 ms /  1668 tokens","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n23kx5f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice.  I went with the $6k Mac Studio and this is what I got with the same prompt on Qwen.&lt;/p&gt;\\n\\n&lt;p&gt;prompt eval time =    4569.80 ms /    48 tokens (   95.20 ms per token,    10.50 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;eval time =  101055.88 ms /  1620 tokens (   62.38 ms per token,    16.03 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;total time =  105625.68 ms /  1668 tokens&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n23kx5f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752025861,"author_flair_text":null,"treatment_tags":[],"created_utc":1752025861,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z5jof","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751978478,"send_replies":true,"parent_id":"t1_n1z2i8t","score":28,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":1751978854,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z5jof","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The first thing I want to point out is the load speed. It only takes 3 seconds to load the 132GB qwen3-235b-a22b.&lt;/p&gt;\\n\\n&lt;p&gt;I gave Qwen a prompt:\\nHello Gwen. I&amp;#39;m working on a JRPG with combat similar to final fantasy 1. It&amp;#39;s gameplay and storyline are going to be infused with LLM generated text and an optional AI narrator.&lt;/p&gt;\\n\\n&lt;p&gt;27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m going to need some help with giving you results for other models. When I search for llama 3.1 405b in lm studio, I get hundreds of results.&lt;/p&gt;\\n\\n&lt;p&gt;edit: I&amp;#39;m downloading mlx-community/Metal-Llama-3.1-405b-4bit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z5jof/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751978478,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"body":"mlx-community/meta-llama-3.1-405b\\n\\nReally slow... 2.91 tok/sec, 55 tokens, 7.59s to first token","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20tr9w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"s101c","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20myaz","score":2,"author_fullname":"t2_rg6hb6my5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you so much for the answer. For the sake of the experiment, is it also possible to download the GGUF version and test it also? To determine the difference in speed between MLX and GGUF for the largest dense model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n20tr9w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you so much for the answer. For the sake of the experiment, is it also possible to download the GGUF version and test it also? To determine the difference in speed between MLX and GGUF for the largest dense model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20tr9w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751996359,"author_flair_text":null,"treatment_tags":[],"created_utc":1751996359,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n20myaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751994505,"send_replies":true,"parent_id":"t1_n1z2i8t","score":5,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20myaz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mlx-community/meta-llama-3.1-405b&lt;/p&gt;\\n\\n&lt;p&gt;Really slow... 2.91 tok/sec, 55 tokens, 7.59s to first token&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20myaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751994505,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22blgf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n228pg8","score":2,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I haven't done extensive testing, just some usual prompts I'm leveraging when I want first tests done, so far id place it midway between mistral medium and deepseek v3.\\n\\nI'll try it in my coding workflow tomorrow, I'll update this.\\n\\nGreat stuff is that it is really fast on 2x3090 (so far I'm testing it with tp 2 and seq len 8196, I'll try to extend context tomorrow, but it might require disabling cuda graphs or quantizing the kV cache)\\n\\nEdit: I'm using directly the gptq version dropped by tencent.\\n\\nEdit 2: plus for the style, it has a style kinda similar to early llama 3 models, with a slight bit of humour and enthousiasm","edited":1752011333,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22blgf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I haven&amp;#39;t done extensive testing, just some usual prompts I&amp;#39;m leveraging when I want first tests done, so far id place it midway between mistral medium and deepseek v3.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll try it in my coding workflow tomorrow, I&amp;#39;ll update this.&lt;/p&gt;\\n\\n&lt;p&gt;Great stuff is that it is really fast on 2x3090 (so far I&amp;#39;m testing it with tp 2 and seq len 8196, I&amp;#39;ll try to extend context tomorrow, but it might require disabling cuda graphs or quantizing the kV cache)&lt;/p&gt;\\n\\n&lt;p&gt;Edit: I&amp;#39;m using directly the gptq version dropped by tencent.&lt;/p&gt;\\n\\n&lt;p&gt;Edit 2: plus for the style, it has a style kinda similar to early llama 3 models, with a slight bit of humour and enthousiasm&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22blgf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752011142,"author_flair_text":null,"treatment_tags":[],"created_utc":1752011142,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n228pg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z3r0h","score":1,"author_fullname":"t2_zws5yqyow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How good is the new hunyuan model? I have dual 3090's going to give it a go but would like to see other opinions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n228pg8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How good is the new hunyuan model? I have dual 3090&amp;#39;s going to give it a go but would like to see other opinions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n228pg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752010293,"author_flair_text":null,"treatment_tags":[],"created_utc":1752010293,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z3r0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"created_utc":1751977812,"send_replies":true,"parent_id":"t1_n1z2i8t","score":3,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For hunyuan, you can try the gptq quant on vllm, they just added support.\\n\\nTried it on 2x3090 and got a nice 75 tokens / seconds in génération, and perf is up to the benchmark.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z3r0h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For hunyuan, you can try the gptq quant on vllm, they just added support.&lt;/p&gt;\\n\\n&lt;p&gt;Tried it on 2x3090 and got a nice 75 tokens / seconds in génération, and perf is up to the benchmark.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z3r0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751977812,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z2i8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"s101c","can_mod_post":false,"created_utc":1751977340,"send_replies":true,"parent_id":"t3_1lumsd2","score":44,"author_fullname":"t2_rg6hb6my5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It would be very interesting to know the token/sec speed for:\\n\\n* Llama 3.1 405B (yes, it's old but still the largest dense model available)\\n* R1 or V3 0324\\n* Hunyuan A13B (the GGUFs are expected to be available very soon)\\n\\nBy the way, what was the exact speed with Q3-235B-A22B, considering that you've tested it?","edited":1751977608,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z2i8t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It would be very interesting to know the token/sec speed for:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Llama 3.1 405B (yes, it&amp;#39;s old but still the largest dense model available)&lt;/li&gt;\\n&lt;li&gt;R1 or V3 0324&lt;/li&gt;\\n&lt;li&gt;Hunyuan A13B (the GGUFs are expected to be available very soon)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;By the way, what was the exact speed with Q3-235B-A22B, considering that you&amp;#39;ve tested it?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z2i8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751977340,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":44}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm more likely to donate it to the school or something. It's a really great teaching machine.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2385zg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"samus003","can_mod_post":false,"send_replies":true,"parent_id":"t1_n201lpa","score":12,"author_fullname":"t2_i6llu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi, it's me your friend 'the school'","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2385zg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, it&amp;#39;s me your friend &amp;#39;the school&amp;#39;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n2385zg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752021554,"author_flair_text":null,"treatment_tags":[],"created_utc":1752021554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n201lpa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zoh7q","score":5,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n201lpa","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m more likely to donate it to the school or something. It&amp;#39;s a really great teaching machine.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n201lpa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988481,"author_flair_text":null,"treatment_tags":[],"created_utc":1751988481,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zoh7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TableSurface","can_mod_post":false,"created_utc":1751984707,"send_replies":true,"parent_id":"t1_n1zf4zs","score":11,"author_fullname":"t2_r5ot7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"People also tend to forget that you have the option of re-selling these machines, and high-spec ones seem to hold their value pretty well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zoh7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People also tend to forget that you have the option of re-selling these machines, and high-spec ones seem to hold their value pretty well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zoh7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751984707,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"body":"Hell ya brother! I'm trying to write my own inference engine in golang to embed gemma 3n LLMs into my game to make use of 3d hardware while the CPU renders the 2d sprites/animations in the game.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"https://foreverfantasy.org\\n\\nI put a parade of the 46 different characters I've integrated on the website for now. I'll post something once it's playable.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27svwp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Background_Put_4978","can_mod_post":false,"send_replies":true,"parent_id":"t1_n25arbd","score":1,"author_fullname":"t2_ap0qx6cm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh hell yes. I need this game.","edited":false,"author_flair_css_class":null,"name":"t1_n27svwp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh hell yes. I need this game.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n27svwp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083683,"author_flair_text":null,"collapsed":false,"created_utc":1752083683,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n25arbd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2412qa","score":2,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25arbd","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://foreverfantasy.org\\"&gt;https://foreverfantasy.org&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I put a parade of the 46 different characters I&amp;#39;ve integrated on the website for now. I&amp;#39;ll post something once it&amp;#39;s playable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n25arbd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752054728,"author_flair_text":null,"treatment_tags":[],"created_utc":1752054728,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2412qa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mzbacd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n201hl3","score":1,"author_fullname":"t2_1laz57as","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Awesome idea! I have been thinking about an AI-enabled game for Apple Silicon for a while, but I don't have much knowledge of game development. Keep us posted on your game!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2412qa","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome idea! I have been thinking about an AI-enabled game for Apple Silicon for a while, but I don&amp;#39;t have much knowledge of game development. Keep us posted on your game!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n2412qa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752031630,"author_flair_text":null,"treatment_tags":[],"created_utc":1752031630,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n201hl3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751988448,"send_replies":true,"parent_id":"t1_n1zf4zs","score":5,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n201hl3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hell ya brother! I&amp;#39;m trying to write my own inference engine in golang to embed gemma 3n LLMs into my game to make use of 3d hardware while the CPU renders the 2d sprites/animations in the game.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n201hl3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988448,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27rozw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Conversation9561","can_mod_post":false,"created_utc":1752083364,"send_replies":true,"parent_id":"t1_n1zf4zs","score":1,"author_fullname":"t2_jqxb4pte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you cluster them together in order to run bigger models? If so, do you use mlx distributed or exo?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27rozw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you cluster them together in order to run bigger models? If so, do you use mlx distributed or exo?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n27rozw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083364,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zf4zs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mzbacd","can_mod_post":false,"created_utc":1751981804,"send_replies":true,"parent_id":"t3_1lumsd2","score":18,"author_fullname":"t2_1laz57as","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't understand why people downvote it. I have two M2 Ultra machines, which I had to save up for a while to purchase. But with those machines, you can experiment with many things and explore different ideas., learn how to full fine-tune the models, write your own inference engine/lib using mlx) Besides, they provide perfect privacy since you don't need to send everything to OpenAI/Gemini/Claude.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zf4zs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t understand why people downvote it. I have two M2 Ultra machines, which I had to save up for a while to purchase. But with those machines, you can experiment with many things and explore different ideas., learn how to full fine-tune the models, write your own inference engine/lib using mlx) Besides, they provide perfect privacy since you don&amp;#39;t need to send everything to OpenAI/Gemini/Claude.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zf4zs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981804,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm downloading the unsloth DeepSeek R1 0528 GGUF now.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I will report back performance. IIRC, this model performs slower with better results than Qwen, but I might be misremembering.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Excited to see results. I understand it's kind of a neutered comparison. I've found the r1 model with the inference provider I used (lambda.ai) to be too slow to use as a replacement for Anthropic.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n253wfp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dugavo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ztzj5","score":1,"author_fullname":"t2_1nge67um4h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"FYI there are many inference providers; last time I checked, the official DeepSeek inference was the cheapest by a large margin (they accept PayPal)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n253wfp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;FYI there are many inference providers; last time I checked, the official DeepSeek inference was the cheapest by a large margin (they accept PayPal)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n253wfp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752050884,"author_flair_text":null,"treatment_tags":[],"created_utc":1752050884,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ztzj5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zi6nk","score":2,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1ztzj5","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Excited to see results. I understand it&amp;#39;s kind of a neutered comparison. I&amp;#39;ve found the r1 model with the inference provider I used (lambda.ai) to be too slow to use as a replacement for Anthropic.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1ztzj5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751986289,"author_flair_text":null,"treatment_tags":[],"created_utc":1751986289,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zi6nk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dugavo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zcp0z","score":7,"author_fullname":"t2_1nge67um4h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's one of the best models for coding. WAAAY better than Qwen.","edited":false,"author_flair_css_class":null,"name":"t1_n1zi6nk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s one of the best models for coding. WAAAY better than Qwen.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zi6nk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751982783,"author_flair_text":null,"collapsed":false,"created_utc":1751982783,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zcp0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z6nuh","score":7,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zcp0z","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will report back performance. IIRC, this model performs slower with better results than Qwen, but I might be misremembering.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zcp0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980987,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980987,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"body":"16.14 tps\\n2.28s to first token","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20ost8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20hse9","score":7,"author_fullname":"t2_2m3au2xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice. Thanks. What quant did you use? Context size? Sorry I'm poking. I wish I would be able to run it.","edited":false,"author_flair_css_class":null,"name":"t1_n20ost8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice. Thanks. What quant did you use? Context size? Sorry I&amp;#39;m poking. I wish I would be able to run it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20ost8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751995009,"author_flair_text":null,"collapsed":false,"created_utc":1751995009,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20rgse","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20hse9","score":3,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"how good it is for your use case? I expect it to not be as good as Claude4/Gemini at coding, but maybe it's close?","edited":false,"author_flair_css_class":null,"name":"t1_n20rgse","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how good it is for your use case? I expect it to not be as good as Claude4/Gemini at coding, but maybe it&amp;#39;s close?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20rgse/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751995732,"author_flair_text":null,"collapsed":false,"created_utc":1751995732,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n20hse9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z6nuh","score":6,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20hse9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;16.14 tps\\n2.28s to first token&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20hse9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751993076,"author_flair_text":null,"treatment_tags":[],"created_utc":1751993076,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z6nuh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z67dk","score":9,"author_fullname":"t2_2m3au2xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let us know how it goes!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1z6nuh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let us know how it goes!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z6nuh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751978881,"author_flair_text":null,"treatment_tags":[],"created_utc":1751978881,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z67dk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751978716,"send_replies":true,"parent_id":"t1_n1z3pqu","score":25,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z67dk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m downloading the unsloth DeepSeek R1 0528 GGUF now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z67dk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751978716,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zd198","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zc2jx","score":4,"author_fullname":"t2_2m3au2xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They should be able to run a q4.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zd198","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They should be able to run a q4.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zd198/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981101,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981101,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zlki1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zc2jx","score":2,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There has been a lot of progress on quantization techniques lately and larger models compress better. I would think that a good dynamic quant of R1 is actually very close to the original.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zlki1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There has been a lot of progress on quantization techniques lately and larger models compress better. I would think that a good dynamic quant of R1 is actually very close to the original.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zlki1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751983837,"author_flair_text":null,"treatment_tags":[],"created_utc":1751983837,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zqqju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panchovix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zc2jx","score":1,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"At least in PPL comparisons and newer quantizations (unsloth or ubergamm quants), they are really close, like, at the point of margin of error (less than 0.5%) at 4bpw.\\n\\nI guess since DeepSeek is trained at FP8 natively, it may be different.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zqqju","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At least in PPL comparisons and newer quantizations (unsloth or ubergamm quants), they are really close, like, at the point of margin of error (less than 0.5%) at 4bpw.&lt;/p&gt;\\n\\n&lt;p&gt;I guess since DeepSeek is trained at FP8 natively, it may be different.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zqqju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985365,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1751985365,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zc2jx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cergorach","can_mod_post":false,"created_utc":1751980778,"send_replies":true,"parent_id":"t1_n1z3pqu","score":8,"author_fullname":"t2_cs4w88d2l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because the 'real' DeepSeek r1 671b unquantized doesn't fit in 512GB of RAM,only the 4q model fits in there with very little room to spare. I'm told that differences are noticeable between the quantized and unquantized models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zc2jx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because the &amp;#39;real&amp;#39; DeepSeek r1 671b unquantized doesn&amp;#39;t fit in 512GB of RAM,only the 4q model fits in there with very little room to spare. I&amp;#39;m told that differences are noticeable between the quantized and unquantized models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zc2jx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980778,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20ziep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"marhalt","can_mod_post":false,"created_utc":1751997921,"send_replies":true,"parent_id":"t1_n1z3pqu","score":2,"author_fullname":"t2_674pf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have the same machine and do run Deepseek R1 at Q4. Max context length is around 40k, but with KV cache quant it seems more than enough. I have to shut down most other apps to make it work, though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20ziep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have the same machine and do run Deepseek R1 at Q4. Max context length is around 40k, but with KV cache quant it seems more than enough. I have to shut down most other apps to make it work, though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20ziep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751997921,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z3pqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"created_utc":1751977799,"send_replies":true,"parent_id":"t3_1lumsd2","score":16,"author_fullname":"t2_2m3au2xb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With the 512GB, why not run the real Deepseek R1?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z3pqu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With the 512GB, why not run the real Deepseek R1?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z3pqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751977799,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"This wasn't a big investment for me. I use Gemini 2.5 pro for plan mode and Claude 4.0 Sonnet for act mode. Like most, I've found anthropic to be far superior to gemini for tool usage.\\n\\nThe goal here was to see if local models could work for some of my more complex use cases. I've successfully used it for small use cases like: ETLing 1TB of &gt;9400 individual slides of animation cells for 46 different characters. including compression and file normalization.\\n\\nNext is to convert the cells into sprite sheets for efficient loading and display of animations.\\n\\nThe next big purchase will be a $120k GPU machine if I can prove that local models can handle Act mode tool usage and code generation in my Cline agent.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zdpwe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ultrapcb","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zc534","score":7,"author_fullname":"t2_66nlg9we","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; Get that Dopamine, my guy\\n\\ni mean that's exactly the main thing driving OP and i don't blame him haha","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zdpwe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Get that Dopamine, my guy&lt;/p&gt;\\n\\n&lt;p&gt;i mean that&amp;#39;s exactly the main thing driving OP and i don&amp;#39;t blame him haha&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zdpwe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981330,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981330,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zc534","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"colin_colout","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":18,"author_fullname":"t2_14l4ya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;This wasn't a big investment for me\\n\\nAlex Ziskind....is that you? lol\\n\\n&gt;The next big purchase will be a $120k GPU machine if I can prove that local models can handle Act mode tool usage and code generation in my Cline agent.\\n\\nAs others said, you can use one of the many hosting providers to test the exact same models you plan to run locally.\\n\\n...though to be honest if I had hundreds of thousands of dollars to burn, I'd totally do exactly what you did so take my upvote. Get that Dopamine, my guy.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zc534","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;This wasn&amp;#39;t a big investment for me&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Alex Ziskind....is that you? lol&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The next big purchase will be a $120k GPU machine if I can prove that local models can handle Act mode tool usage and code generation in my Cline agent.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;As others said, you can use one of the many hosting providers to test the exact same models you plan to run locally.&lt;/p&gt;\\n\\n&lt;p&gt;...though to be honest if I had hundreds of thousands of dollars to burn, I&amp;#39;d totally do exactly what you did so take my upvote. Get that Dopamine, my guy.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zc534/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980801,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980801,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm using commercial APIs. I've tried 4 of them, and settled on using Gemini 2.5 pro for planning and Claude 4.0 Sonnet for Act mode (in Cline, my coding agent).\\n\\nLots of my use cases work great on local LLMs. I'm making a JRPG with LLM narration, storytelling, and interaction. Gemma 3n is kicking ass at that. I have a pretty big (12k) procedurally generated prompt for making a single sentence output. Gemma is great and really easy to interact with as a non reasoning model.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Oh I see, no I wanted to be able to run LLMs on my own hardware, and I have other uses for the machine. It's absolutely fantastic at running ViaCAD, my prefered 3d modeling interface for my 3d printer.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zreq8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zosao","score":11,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1zreq8","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh I see, no I wanted to be able to run LLMs on my own hardware, and I have other uses for the machine. It&amp;#39;s absolutely fantastic at running ViaCAD, my prefered 3d modeling interface for my 3d printer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zreq8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985559,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985559,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zosao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"runner2012","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zcgcv","score":5,"author_fullname":"t2_7zgfi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the previous commenter meant why not \\"only\\" use commercial APIs as you can get absolutely any model from qwen to anthropic using only commercial APIs. Especially since cost is of no concern to you AND takes less time to setup as you don't have to deal with your own infrastructure. ","edited":false,"author_flair_css_class":null,"name":"t1_n1zosao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the previous commenter meant why not &amp;quot;only&amp;quot; use commercial APIs as you can get absolutely any model from qwen to anthropic using only commercial APIs. Especially since cost is of no concern to you AND takes less time to setup as you don&amp;#39;t have to deal with your own infrastructure. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zosao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751984798,"author_flair_text":null,"collapsed":false,"created_utc":1751984798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zcgcv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1za5g6","score":11,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zcgcv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m using commercial APIs. I&amp;#39;ve tried 4 of them, and settled on using Gemini 2.5 pro for planning and Claude 4.0 Sonnet for Act mode (in Cline, my coding agent).&lt;/p&gt;\\n\\n&lt;p&gt;Lots of my use cases work great on local LLMs. I&amp;#39;m making a JRPG with LLM narration, storytelling, and interaction. Gemma 3n is kicking ass at that. I have a pretty big (12k) procedurally generated prompt for making a single sentence output. Gemma is great and really easy to interact with as a non reasoning model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zcgcv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980906,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980906,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I have been using Claude 4.0 Sonnet for 2 weeks and have already spent almost $1k. My eventual goal is to be able to replace that $500/week with a single $120k purchase and electricity bills instead.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"claude max would be nice, but I would still be paying for all this API usage on top of that. For what? Priority processing during peak usage times? I'll admit that's frustrating, but Anthropic did a good job of setting their price high enough that people don't use it for nothing. I've not had many issues with Anthropic being slow or unresponsive.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21unh5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20zldo","score":3,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n21unh5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;claude max would be nice, but I would still be paying for all this API usage on top of that. For what? Priority processing during peak usage times? I&amp;#39;ll admit that&amp;#39;s frustrating, but Anthropic did a good job of setting their price high enough that people don&amp;#39;t use it for nothing. I&amp;#39;ve not had many issues with Anthropic being slow or unresponsive.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21unh5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752006433,"author_flair_text":null,"treatment_tags":[],"created_utc":1752006433,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n20zldo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iamnotthatreal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zrwdm","score":1,"author_fullname":"t2_1f8i4jgkfh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"you should get claude max then.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n20zldo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you should get claude max then.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20zldo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751997942,"author_flair_text":null,"treatment_tags":[],"created_utc":1751997942,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zrwdm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zlhz3","score":5,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"author_flair_css_class":null,"name":"t1_n1zrwdm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been using Claude 4.0 Sonnet for 2 weeks and have already spent almost $1k. My eventual goal is to be able to replace that $500/week with a single $120k purchase and electricity bills instead.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zrwdm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985698,"author_flair_text":null,"collapsed":false,"created_utc":1751985698,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zqjjz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"juggarjew","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zlhz3","score":7,"author_fullname":"t2_i2ox1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree, its why I wont go farther than using my RTX 5090, which I initially got for gaming. I love to tinker but spending $10k on a Mac Studio just to play around with LLMs that ultimately are inferior to cloud solutions is kind of questionable.","edited":false,"author_flair_css_class":null,"name":"t1_n1zqjjz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree, its why I wont go farther than using my RTX 5090, which I initially got for gaming. I love to tinker but spending $10k on a Mac Studio just to play around with LLMs that ultimately are inferior to cloud solutions is kind of questionable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zqjjz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985310,"author_flair_text":null,"collapsed":false,"created_utc":1751985310,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22sw70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sp3kter","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zlhz3","score":3,"author_fullname":"t2_3hy4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Uncensored models would be excellent at finding loop holes and flaws in laws and tax codes","edited":false,"author_flair_css_class":null,"name":"t1_n22sw70","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Uncensored models would be excellent at finding loop holes and flaws in laws and tax codes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22sw70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752016517,"author_flair_text":null,"collapsed":false,"created_utc":1752016517,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zlhz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iamnotthatreal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1za5g6","score":10,"author_fullname":"t2_1f8i4jgkfh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"local llm users actually seemed rich to me because pay as you go is usually more affordable than paying tens of thousands of dollars for a machine only to get subpar performance to sota propriety llms.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zlhz3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;local llm users actually seemed rich to me because pay as you go is usually more affordable than paying tens of thousands of dollars for a machine only to get subpar performance to sota propriety llms.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zlhz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751983816,"author_flair_text":null,"treatment_tags":[],"created_utc":1751983816,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n202xmr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Single-Blackberry866","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1za5g6","score":4,"author_fullname":"t2_kfk098v2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You're clearly not a paranoid person.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n202xmr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re clearly not a paranoid person.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n202xmr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988859,"author_flair_text":null,"treatment_tags":[],"created_utc":1751988859,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1za5g6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eaz135","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":18,"author_fullname":"t2_721mb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If price isn't really a concern, I'm curious what is driving you to a local LLM setup rather than using commercial models over API?\\n\\nI don't mean this is a troll question to diss local llm users, I'm experimenting with local llms myself (just on an M4 MAX 64GB MBP), but I'm still figuring out if its really worth pursuing any more advanced hardware than what I currently have.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1za5g6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If price isn&amp;#39;t really a concern, I&amp;#39;m curious what is driving you to a local LLM setup rather than using commercial models over API?&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t mean this is a troll question to diss local llm users, I&amp;#39;m experimenting with local llms myself (just on an M4 MAX 64GB MBP), but I&amp;#39;m still figuring out if its really worth pursuing any more advanced hardware than what I currently have.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1za5g6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980116,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980116,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1z9lze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GPU-Appreciator","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z8w37","score":25,"author_fullname":"t2_1it6qdpjps","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"we love our rich people, someone's gotta figure out what all this fancy hardware is good for","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z9lze","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;we love our rich people, someone&amp;#39;s gotta figure out what all this fancy hardware is good for&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z9lze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979926,"author_flair_text":null,"treatment_tags":[],"created_utc":1751979926,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Yeah. I priced out 4u's last week through new egg b2b. it's cheaper to build a single 8x GPU box than to build 4 2x machines and network them with infiniband.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zq9fo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zicwq","score":5,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1zq9fo","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. I priced out 4u&amp;#39;s last week through new egg b2b. it&amp;#39;s cheaper to build a single 8x GPU box than to build 4 2x machines and network them with infiniband.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zq9fo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985228,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985228,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28iad2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vsoul","can_mod_post":false,"created_utc":1752090717,"send_replies":true,"parent_id":"t1_n212fsf","score":3,"author_fullname":"t2_3bmb4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"You give me $120k and you’ll never see me again","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n28iad2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You give me $120k and you’ll never see me again&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n28iad2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752090717,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n212fsf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpicyWangz","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20rxgc","score":2,"author_fullname":"t2_6c8oxr1n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You give me $120k and I'll give you a server box with $100k of computer parts","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n212fsf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You give me $120k and I&amp;#39;ll give you a server box with $100k of computer parts&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n212fsf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751998697,"author_flair_text":null,"treatment_tags":[],"created_utc":1751998697,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n20rxgc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LightShadow","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zicwq","score":2,"author_fullname":"t2_3056m","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; there is no machine for $120k\\n\\nYou give me $120k and I'll give you a server box with $120k of computer parts inside lol","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n20rxgc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;there is no machine for $120k&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;You give me $120k and I&amp;#39;ll give you a server box with $120k of computer parts inside lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20rxgc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751995856,"author_flair_text":null,"treatment_tags":[],"created_utc":1751995856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n229jh1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zicwq","score":1,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"body":"quite a few in fact","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n229jh1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;quite a few in fact&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n229jh1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752010536,"author_flair_text":null,"treatment_tags":[],"created_utc":1752010536,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zicwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sage-longhorn","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zad72","score":15,"author_fullname":"t2_8fpi9yx1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;there is no machine for $120k\\n\\nSpend some time in a data center, there is indeed a machine for $120k. More than one in fact","edited":false,"author_flair_css_class":null,"name":"t1_n1zicwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;there is no machine for $120k&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Spend some time in a data center, there is indeed a machine for $120k. More than one in fact&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zicwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751982836,"author_flair_text":null,"collapsed":false,"created_utc":1751982836,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Exactly this. I'm a principal engineer in the daytime, but at night I'm working on a passion project. It's a JRPG with turn based combat and LLM powered storytelling, narration, and dialogue. I need to be able to run 10-12k prompts through small models at a speed that isn't going to piss me off and I wanted to use my own hardware for it. I knew it was not a good investment, but I can use it for all sorts of things. I like 3d modeling and have a Makerbot Method X Carbon Fiber printer. I use it to build custom parts for my RC planes.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22akwf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zr612","score":2,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a chat between Gemini 2.5 pro and I that is many weeks old that I use daily and it has reached over 500k tokens without any coding questions. I noticed anytime I load up that chat for the first time it forgets some crucial details and I have to remind it what it forgot to get it back on track. Acts a bit dumb when you first load it up for the day and if you load that same chat on a different device you still have to remind it most of the time for it to regain context. Interesting indeed.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n22akwf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a chat between Gemini 2.5 pro and I that is many weeks old that I use daily and it has reached over 500k tokens without any coding questions. I noticed anytime I load up that chat for the first time it forgets some crucial details and I have to remind it what it forgot to get it back on track. Acts a bit dumb when you first load it up for the day and if you load that same chat on a different device you still have to remind it most of the time for it to regain context. Interesting indeed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22akwf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752010845,"author_flair_text":null,"treatment_tags":[],"created_utc":1752010845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zr612","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zn6a6","score":12,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1zr612","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly this. I&amp;#39;m a principal engineer in the daytime, but at night I&amp;#39;m working on a passion project. It&amp;#39;s a JRPG with turn based combat and LLM powered storytelling, narration, and dialogue. I need to be able to run 10-12k prompts through small models at a speed that isn&amp;#39;t going to piss me off and I wanted to use my own hardware for it. I knew it was not a good investment, but I can use it for all sorts of things. I like 3d modeling and have a Makerbot Method X Carbon Fiber printer. I use it to build custom parts for my RC planes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zr612/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985490,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985490,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zn6a6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zad72","score":5,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see your point.  I think OP is just having fun experimenting, not trying to maximize value or anything.  We can never beat multimillion/billion dollar companies in public retail hardware but it's fun to mess around, despite knowing it will be outdated in a year or two.  But with that said I did contemplate getting the 512gb macmini and testing out the mlx models out there just to see how close it gets to programming against things like openAI grok and Gemini. \\n\\nI do notice that the subscription AIs seem to get dumber at peak times, I wouldn't be surprised if they throttle people to lower quants to prevent showing error or busy dialogs.","edited":false,"author_flair_css_class":null,"name":"t1_n1zn6a6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see your point.  I think OP is just having fun experimenting, not trying to maximize value or anything.  We can never beat multimillion/billion dollar companies in public retail hardware but it&amp;#39;s fun to mess around, despite knowing it will be outdated in a year or two.  But with that said I did contemplate getting the 512gb macmini and testing out the mlx models out there just to see how close it gets to programming against things like openAI grok and Gemini. &lt;/p&gt;\\n\\n&lt;p&gt;I do notice that the subscription AIs seem to get dumber at peak times, I wouldn&amp;#39;t be surprised if they throttle people to lower quants to prevent showing error or busy dialogs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zn6a6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751984324,"author_flair_text":null,"collapsed":false,"created_utc":1751984324,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"body":"Blah Blah Blah. I priced out GPU rigs this week. You are talking out of your ass.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"praise be the FLOP","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22ifac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1752013196,"send_replies":true,"parent_id":"t1_n22b079","score":2,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Blessed be the machine","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n22ifac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Blessed be the machine&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22ifac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752013196,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n22b079","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n22aov8","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n22b079","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;praise be the FLOP&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22b079/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752010970,"author_flair_text":null,"treatment_tags":[],"created_utc":1752010970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n22aov8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zb58z","score":2,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"body":"eh don't worry about haters","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n22aov8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;eh don&amp;#39;t worry about haters&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22aov8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752010876,"author_flair_text":null,"treatment_tags":[],"created_utc":1752010876,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-11,"removal_reason":null,"link_id":"t3_1lumsd2","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zgdmo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PM_ME_UR_COFFEE_CUPS","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbw2b","score":12,"author_fullname":"t2_42210fdq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is r/LocalLlama","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1zgdmo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is &lt;a href=\\"/r/LocalLlama\\"&gt;r/LocalLlama&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zgdmo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751982209,"author_flair_text":null,"treatment_tags":[],"created_utc":1751982209,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zrreb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bderken","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbw2b","score":1,"author_fullname":"t2_gr131","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Reddit final boss troll","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1zrreb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Reddit final boss troll&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zrreb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985659,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985659,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zbw2b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1751980717,"send_replies":true,"parent_id":"t1_n1zb58z","score":-11,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zbw2b/","num_reports":null,"locked":false,"name":"t1_n1zbw2b","created":1751980717,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zb58z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zad72","score":10,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"author_flair_css_class":null,"name":"t1_n1zb58z","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Blah Blah Blah. I priced out GPU rigs this week. You are talking out of your ass.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zb58z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980462,"author_flair_text":null,"collapsed":false,"created_utc":1751980462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n200cht","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zad72","score":2,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's possible the Mac isn't just for trying to self host LLMs.  They're useful for other things. \\n\\nYou can build a workstation or server with a number of RTX 6000 Pro cards, H200 NVL (PCIe) without jumping all the way to the  8xSXM setup that is $300k+.\\n\\nhttps://www.pny.com/nvidia-h200-nvl\\n\\nI think these are ~$30-40k a pop?  Two of them in an Epyc 1S could be in the $80-150k range depending on which CPU and how much sys ram you wanted.\\n\\nThere are many vendors out there selling ML workstations that can support 4 gpus, and pick whatever GPU.  H200 NVL, RTX 6000 Pro Blackwell, etc.\\n\\nedit: I just went to bizon-tech.com and priced their top end water-cooled workstation with 7xRTX 6000 Pro , 1TB sys ram, ~$125-140k depending on cpu and sys ram, or two H200 NVL 141GB with the NVLink pretty much same price.","edited":1751989059,"author_flair_css_class":null,"name":"t1_n200cht","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s possible the Mac isn&amp;#39;t just for trying to self host LLMs.  They&amp;#39;re useful for other things. &lt;/p&gt;\\n\\n&lt;p&gt;You can build a workstation or server with a number of RTX 6000 Pro cards, H200 NVL (PCIe) without jumping all the way to the  8xSXM setup that is $300k+.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.pny.com/nvidia-h200-nvl\\"&gt;https://www.pny.com/nvidia-h200-nvl&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I think these are ~$30-40k a pop?  Two of them in an Epyc 1S could be in the $80-150k range depending on which CPU and how much sys ram you wanted.&lt;/p&gt;\\n\\n&lt;p&gt;There are many vendors out there selling ML workstations that can support 4 gpus, and pick whatever GPU.  H200 NVL, RTX 6000 Pro Blackwell, etc.&lt;/p&gt;\\n\\n&lt;p&gt;edit: I just went to bizon-tech.com and priced their top end water-cooled workstation with 7xRTX 6000 Pro , 1TB sys ram, ~$125-140k depending on cpu and sys ram, or two H200 NVL 141GB with the NVLink pretty much same price.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n200cht/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988123,"author_flair_text":null,"collapsed":false,"created_utc":1751988123,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20yoje","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"davikrehalt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zad72","score":1,"author_fullname":"t2_6okc6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's the point of having money if you can't spend it \\"suboptimal ly\\"","edited":false,"author_flair_css_class":null,"name":"t1_n20yoje","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s the point of having money if you can&amp;#39;t spend it &amp;quot;suboptimal ly&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20yoje/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751997704,"author_flair_text":null,"collapsed":false,"created_utc":1751997704,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zad72","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ultrapcb","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z8w37","score":1,"author_fullname":"t2_66nlg9we","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no because of what he wrote doesn't make any sense:\\n\\n* if 10k is nothing for him he would just burn gemini credits and doesn't think twice but not order some slow mac studio not able to handle something in the gemini league\\n* \\"The goal here was to see if local models could work for some of my more complex use cases.\\", he then continues with some odd use case (non-llm probably in the context of gaming but why does he then test ai coding in the initial post) but doesn't tell us why it has to be local; again, instead of just burning openrouter credits (remember, 10k isn't a big investment for him)\\n* then \\" $120k GPU machine\\", there is no such thing, either you have a 8-gpu module in a rack or a single h100/h100/b100/b200; whatever, there is no machine for $120k; just another flex for no reason","edited":1751980424,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zad72","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no because of what he wrote doesn&amp;#39;t make any sense:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;if 10k is nothing for him he would just burn gemini credits and doesn&amp;#39;t think twice but not order some slow mac studio not able to handle something in the gemini league&lt;/li&gt;\\n&lt;li&gt;&amp;quot;The goal here was to see if local models could work for some of my more complex use cases.&amp;quot;, he then continues with some odd use case (non-llm probably in the context of gaming but why does he then test ai coding in the initial post) but doesn&amp;#39;t tell us why it has to be local; again, instead of just burning openrouter credits (remember, 10k isn&amp;#39;t a big investment for him)&lt;/li&gt;\\n&lt;li&gt;then &amp;quot; $120k GPU machine&amp;quot;, there is no such thing, either you have a 8-gpu module in a rack or a single h100/h100/b100/b200; whatever, there is no machine for $120k; just another flex for no reason&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zad72/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980191,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980191,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z8w37","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":19,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why are you getting downvoted?  Ppl salty you rich?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1z8w37","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why are you getting downvoted?  Ppl salty you rich?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z8w37/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979670,"author_flair_text":null,"treatment_tags":[],"created_utc":1751979670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I've not seen good results. Someone tried doing this with exo: https://github.com/exo-explore/exo\\nThey made a video on the youtubes: https://www.youtube.com/watch?v=Ju0ndy2kwlw\\n\\nI would love it if the performance was enough to justify the cost, but it really looks like nvidia has a lock on performance per $$. GPU boxes with 8x blackwells costs $120-200k which would be a huge investment for me. More that my house. But it looks like that would be the only way to get acceptable token throughput and latency for larger tool usage LLMs like V3.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Yeah, pipeline parallelization seems like it improves system throughput but not query throughput.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n25b3c6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n242q0b","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n25b3c6","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, pipeline parallelization seems like it improves system throughput but not query throughput.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n25b3c6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752054901,"author_flair_text":null,"treatment_tags":[],"created_utc":1752054901,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n242q0b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mzbacd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbr1h","score":2,"author_fullname":"t2_1laz57as","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Due to the cross-machine communication bandwidth limitation, most of the clustering currently relies on pipeline parallelization, which is very inefficient since only one machine processes a portion of the weights before passing them on to another machine.  \\nI have built a small example project with mlx, if you are interested see how it imp:  \\n[https://github.com/mzbac/mlx\\\\_sharding](https://github.com/mzbac/mlx_sharding)","edited":false,"author_flair_css_class":null,"name":"t1_n242q0b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Due to the cross-machine communication bandwidth limitation, most of the clustering currently relies on pipeline parallelization, which is very inefficient since only one machine processes a portion of the weights before passing them on to another machine.&lt;br/&gt;\\nI have built a small example project with mlx, if you are interested see how it imp:&lt;br/&gt;\\n&lt;a href=\\"https://github.com/mzbac/mlx_sharding\\"&gt;https://github.com/mzbac/mlx_sharding&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n242q0b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752032279,"author_flair_text":null,"collapsed":false,"created_utc":1752032279,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"AWS Wanted a contract to give me a single 8x h200 machine. I ended up getting some instances through Lambda.ai which was the inspiration for trying to run one locally on a mac studio (at any throughput, just to see if it was possible yet w/ consumer hardware).\\n\\nI would have purchased a studio anyways because I needed a replacement for my aging windows PC and I really prefer macs for general use and no longer game. I likely wouldn't have gotten the maximum RAM upgrade if I wasn't planning to run LLMs, but it seems like a reasonable investment. I've got a crazy good machine here.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zt8gg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zdj29","score":2,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1zt8gg","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AWS Wanted a contract to give me a single 8x h200 machine. I ended up getting some instances through Lambda.ai which was the inspiration for trying to run one locally on a mac studio (at any throughput, just to see if it was possible yet w/ consumer hardware).&lt;/p&gt;\\n\\n&lt;p&gt;I would have purchased a studio anyways because I needed a replacement for my aging windows PC and I really prefer macs for general use and no longer game. I likely wouldn&amp;#39;t have gotten the maximum RAM upgrade if I wasn&amp;#39;t planning to run LLMs, but it seems like a reasonable investment. I&amp;#39;ve got a crazy good machine here.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zt8gg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751986078,"author_flair_text":null,"treatment_tags":[],"created_utc":1751986078,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zdj29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cergorach","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbr1h","score":1,"author_fullname":"t2_cs4w88d2l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, speed will not be great, but it's good to proof your proof-of-concept or not. Another $30k is significantly less then an additional $120k. What I would advise your try before you buy any of it, is rent a similar cloud hosted setup for a few hours. Also keep in mind that an RTX 6000 Pro only has a memory bandwidth of 1.8TB/s (the same as a 5090), only something like a H200 has 4.8TB/s, which is a LOT more expensive...","edited":false,"author_flair_css_class":null,"name":"t1_n1zdj29","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, speed will not be great, but it&amp;#39;s good to proof your proof-of-concept or not. Another $30k is significantly less then an additional $120k. What I would advise your try before you buy any of it, is rent a similar cloud hosted setup for a few hours. Also keep in mind that an RTX 6000 Pro only has a memory bandwidth of 1.8TB/s (the same as a 5090), only something like a H200 has 4.8TB/s, which is a LOT more expensive...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zdj29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981267,"author_flair_text":null,"collapsed":false,"created_utc":1751981267,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24wkip","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cergorach","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbr1h","score":1,"author_fullname":"t2_cs4w88d2l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"An RTX 6000 Pro costs \\\\~$8500, 8x that is about $70k, while a modern Threadripper with a ton of memory isn't cheap. You are paying $30k-$40k for them to build it for you... As for renting H200, look at [https://www.runpod.io/gpu-models/h200-sxm](https://www.runpod.io/gpu-models/h200-sxm) or [https://vast.ai/pricing](https://vast.ai/pricing) or [https://www.cerebrium.ai/pricing](https://www.cerebrium.ai/pricing)\\n\\n8xH200 =&gt; \\\\~$25/hour","edited":false,"author_flair_css_class":null,"name":"t1_n24wkip","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An RTX 6000 Pro costs ~$8500, 8x that is about $70k, while a modern Threadripper with a ton of memory isn&amp;#39;t cheap. You are paying $30k-$40k for them to build it for you... As for renting H200, look at &lt;a href=\\"https://www.runpod.io/gpu-models/h200-sxm\\"&gt;https://www.runpod.io/gpu-models/h200-sxm&lt;/a&gt; or &lt;a href=\\"https://vast.ai/pricing\\"&gt;https://vast.ai/pricing&lt;/a&gt; or &lt;a href=\\"https://www.cerebrium.ai/pricing\\"&gt;https://www.cerebrium.ai/pricing&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;8xH200 =&amp;gt; ~$25/hour&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n24wkip/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752046675,"author_flair_text":null,"collapsed":false,"created_utc":1752046675,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2039dp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zcqa9","score":1,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was able to spec a watercooled 7x RTX 6000 Pro Blackwell + Threadripper workstation out at about $128k here: https://bizon-tech.com/\\n\\nThere are bunches of ML workstation/server builders out there, that's just one example, you can spend pretty much any amount of money you want from $1k to $400k+","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2039dp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was able to spec a watercooled 7x RTX 6000 Pro Blackwell + Threadripper workstation out at about $128k here: &lt;a href=\\"https://bizon-tech.com/\\"&gt;https://bizon-tech.com/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;There are bunches of ML workstation/server builders out there, that&amp;#39;s just one example, you can spend pretty much any amount of money you want from $1k to $400k+&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n2039dp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988952,"author_flair_text":null,"treatment_tags":[],"created_utc":1751988952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"body":"Newegg business2business is happy to help you spec them out if you want to buy one yourself. I've spent almost $1k on Anthropic in the last two weeks. It's really not that big of an investment if it proves to suit my purposes. The Mac Studio is just a step in that direction, but I've got tons of other uses for it, from 3d modeling for my 3d printer, to tons of LLM use cases.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zsh58","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zcqa9","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1zsh58","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Newegg business2business is happy to help you spec them out if you want to buy one yourself. I&amp;#39;ve spent almost $1k on Anthropic in the last two weeks. It&amp;#39;s really not that big of an investment if it proves to suit my purposes. The Mac Studio is just a step in that direction, but I&amp;#39;ve got tons of other uses for it, from 3d modeling for my 3d printer, to tons of LLM use cases.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zsh58/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985862,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985862,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zcqa9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ultrapcb","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zbr1h","score":1,"author_fullname":"t2_66nlg9we","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt; GPU boxes with 8x blackwells costs $120\\\\[k\\\\]-\\n\\nsure","edited":false,"author_flair_css_class":null,"name":"t1_n1zcqa9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; GPU boxes with 8x blackwells costs $120[k]-&lt;/p&gt;\\n\\n&lt;p&gt;sure&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zcqa9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980999,"author_flair_text":null,"collapsed":false,"created_utc":1751980999,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zbr1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zasl5","score":4,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zbr1h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve not seen good results. Someone tried doing this with exo: &lt;a href=\\"https://github.com/exo-explore/exo\\"&gt;https://github.com/exo-explore/exo&lt;/a&gt;\\nThey made a video on the youtubes: &lt;a href=\\"https://www.youtube.com/watch?v=Ju0ndy2kwlw\\"&gt;https://www.youtube.com/watch?v=Ju0ndy2kwlw&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I would love it if the performance was enough to justify the cost, but it really looks like nvidia has a lock on performance per $$. GPU boxes with 8x blackwells costs $120-200k which would be a huge investment for me. More that my house. But it looks like that would be the only way to get acceptable token throughput and latency for larger tool usage LLMs like V3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zbr1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980670,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zasl5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cergorach","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":5,"author_fullname":"t2_cs4w88d2l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Before you start spending $120k for a very hefty space heater. You might try clustering multiple M3 Ultra 512GB machines to get larger models to load. The issue is that smaller models that are quantized are just lobotomized compared to the full models that run on premium services. You could probably load the full DS r1 671b unquantized into four clustered Macs (2TB of unified memory) with it only taking 1Kw+ when it's inferring... Compared to the $120k space heater that's probably requiring multiple Kw when inferring. GPUs *can* be a lot faster, though, but are also a LOT more power hungry.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zasl5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Before you start spending $120k for a very hefty space heater. You might try clustering multiple M3 Ultra 512GB machines to get larger models to load. The issue is that smaller models that are quantized are just lobotomized compared to the full models that run on premium services. You could probably load the full DS r1 671b unquantized into four clustered Macs (2TB of unified memory) with it only taking 1Kw+ when it&amp;#39;s inferring... Compared to the $120k space heater that&amp;#39;s probably requiring multiple Kw when inferring. GPUs &lt;em&gt;can&lt;/em&gt; be a lot faster, though, but are also a LOT more power hungry.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zasl5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980342,"author_flair_text":null,"treatment_tags":[],"created_utc":1751980342,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I've had the same results with Gemini. It's happy to tell me of alternatives to the methodologies I present (honestly, trying to do something good).\\n\\nIt's also very verbose in it's output, which is helpful for building context for the \\"dumber\\" tool model. Sonnet 4 is just the best thing since sliced bread for execution when editing files, generating code/docs, etc.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c9a5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NinjaK3ys","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ztjsq","score":1,"author_fullname":"t2_3dec46nr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"haha ! love the sliced bread bits.\\nSonnet 4 is basically my brains working 24/7 on caffeine lol.","edited":false,"author_flair_css_class":null,"name":"t1_n2c9a5m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;haha ! love the sliced bread bits.\\nSonnet 4 is basically my brains working 24/7 on caffeine lol.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n2c9a5m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752143968,"author_flair_text":null,"collapsed":false,"created_utc":1752143968,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ztjsq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zdvyk","score":2,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ztjsq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve had the same results with Gemini. It&amp;#39;s happy to tell me of alternatives to the methodologies I present (honestly, trying to do something good).&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s also very verbose in it&amp;#39;s output, which is helpful for building context for the &amp;quot;dumber&amp;quot; tool model. Sonnet 4 is just the best thing since sliced bread for execution when editing files, generating code/docs, etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1ztjsq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751986166,"author_flair_text":null,"treatment_tags":[],"created_utc":1751986166,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zdvyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NinjaK3ys","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":1,"author_fullname":"t2_3dec46nr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Doing the same and using Gemini as plan and architect.\\nSonnet to execute on the code.\\n\\nSo far Gemini is the only model which will question and disagree when given ideas to implement poo practices.\\n\\nOther models like even sonnet 4 would just execute on it and lacks an ability to criticially reason unless it's something established in its training data.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zdvyk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doing the same and using Gemini as plan and architect.\\nSonnet to execute on the code.&lt;/p&gt;\\n\\n&lt;p&gt;So far Gemini is the only model which will question and disagree when given ideas to implement poo practices.&lt;/p&gt;\\n\\n&lt;p&gt;Other models like even sonnet 4 would just execute on it and lacks an ability to criticially reason unless it&amp;#39;s something established in its training data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zdvyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981386,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981386,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20q8qg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z4aw5","score":1,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I use Gemini 2.5 pro for plan mode and Claude 4.0 Sonnet for act mode\\n\\nI'm out of the loop. What is **Act Mode/Plan mode**?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n20q8qg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I use Gemini 2.5 pro for plan mode and Claude 4.0 Sonnet for act mode&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m out of the loop. What is &lt;strong&gt;Act Mode/Plan mode&lt;/strong&gt;?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20q8qg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751995400,"author_flair_text":null,"treatment_tags":[],"created_utc":1751995400,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z4aw5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751978021,"send_replies":true,"parent_id":"t1_n1z0t6d","score":54,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z4aw5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This wasn&amp;#39;t a big investment for me. I use Gemini 2.5 pro for plan mode and Claude 4.0 Sonnet for act mode. Like most, I&amp;#39;ve found anthropic to be far superior to gemini for tool usage.&lt;/p&gt;\\n\\n&lt;p&gt;The goal here was to see if local models could work for some of my more complex use cases. I&amp;#39;ve successfully used it for small use cases like: ETLing 1TB of &amp;gt;9400 individual slides of animation cells for 46 different characters. including compression and file normalization.&lt;/p&gt;\\n\\n&lt;p&gt;Next is to convert the cells into sprite sheets for efficient loading and display of animations.&lt;/p&gt;\\n\\n&lt;p&gt;The next big purchase will be a $120k GPU machine if I can prove that local models can handle Act mode tool usage and code generation in my Cline agent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z4aw5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751978021,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zrp9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ii_social","can_mod_post":false,"created_utc":1751985642,"send_replies":true,"parent_id":"t1_n1z0t6d","score":2,"author_fullname":"t2_tohvxz80x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"or 20$/m on copilot and getting near infinite AI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zrp9h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;or 20$/m on copilot and getting near infinite AI&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zrp9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985642,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z0t6d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ultrapcb","can_mod_post":false,"created_utc":1751976677,"send_replies":true,"parent_id":"t3_1lumsd2","score":25,"author_fullname":"t2_66nlg9we","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; but it lacked all the comprehension that I get from google gemini\\n\\nthere's no model which comes close to gemini re coding, so not sure if it's your mac and some related flaw or just qwen3 being very much inferior, i mean just try cline with qwen via openrouter or so, i guess you'll get the same subpar results\\n\\nout of curiosity, you knew (i assume) that these models are night and day to gemini + a mac actually being slow, so why drop $10k for some mac studio instead burning gemini credits for a year (and getting best coding capabilities)?","edited":1751976858,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z0t6d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; but it lacked all the comprehension that I get from google gemini&lt;/p&gt;\\n\\n&lt;p&gt;there&amp;#39;s no model which comes close to gemini re coding, so not sure if it&amp;#39;s your mac and some related flaw or just qwen3 being very much inferior, i mean just try cline with qwen via openrouter or so, i guess you&amp;#39;ll get the same subpar results&lt;/p&gt;\\n\\n&lt;p&gt;out of curiosity, you knew (i assume) that these models are night and day to gemini + a mac actually being slow, so why drop $10k for some mac studio instead burning gemini credits for a year (and getting best coding capabilities)?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z0t6d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751976677,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"LMFAO","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zzicd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751987886,"send_replies":true,"parent_id":"t1_n1zyvy6","score":4,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zzicd","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LMFAO&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zzicd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751987886,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zyvy6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fooo12gh","can_mod_post":false,"created_utc":1751987705,"send_replies":true,"parent_id":"t3_1lumsd2","score":8,"author_fullname":"t2_3vvvbmh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=527&amp;format=pjpg&amp;auto=webp&amp;s=c43d8f716941543f9f329b994191cec039b5b6cb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zyvy6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=527&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c43d8f716941543f9f329b994191cec039b5b6cb\\"&gt;https://preview.redd.it/ph44fkfx2obf1.jpeg?width=527&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c43d8f716941543f9f329b994191cec039b5b6cb&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zyvy6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751987705,"media_metadata":{"ph44fkfx2obf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":102,"x":108,"u":"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e98bc1beb018326c73d00994a80c3a8dc4c8695"},{"y":204,"x":216,"u":"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c9b46882fd4eecb85b4915daaf86f7b8c9dd8a3"},{"y":303,"x":320,"u":"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b4b528c64d3172c84790f327bcba0d62c19c9574"}],"s":{"y":500,"x":527,"u":"https://preview.redd.it/ph44fkfx2obf1.jpeg?width=527&amp;format=pjpg&amp;auto=webp&amp;s=c43d8f716941543f9f329b994191cec039b5b6cb"},"id":"ph44fkfx2obf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm using the latest gemma3-12b and getting FANTASTIC results for one of my use cases. I'm building a JRPG with turn based combat similar to final fantasy 1. However, the game itself is infused with LLM narration and storytelling.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm just using 1.0 temp, no special params, but my prompts are procedurally generated and like 10-12k long, instructing the model to output only a single descriptive sentence (\\"The party, weary from travel, is attacked by a group of 3 green goblins with rusty knifes\\")\\n\\nShit like that. Gemma has been rocking it.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Yes, I thought about using JSON or similar IF I go past generating specific texts and start getting the LLM to do more complex tasks. What did you have in mind exactly? Got a link to a blog post or similar?","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n200ei7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1znfv5","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n200ei7","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, I thought about using JSON or similar IF I go past generating specific texts and start getting the LLM to do more complex tasks. What did you have in mind exactly? Got a link to a blog post or similar?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n200ei7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988139,"author_flair_text":null,"treatment_tags":[],"created_utc":1751988139,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1znfv5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Cacique","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zd1uf","score":1,"author_fullname":"t2_ghhr800u8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You should look into structured outputs for your use case.","edited":false,"author_flair_css_class":null,"name":"t1_n1znfv5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should look into structured outputs for your use case.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1znfv5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751984404,"author_flair_text":null,"collapsed":false,"created_utc":1751984404,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zd1uf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z8yfn","score":4,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zd1uf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m just using 1.0 temp, no special params, but my prompts are procedurally generated and like 10-12k long, instructing the model to output only a single descriptive sentence (&amp;quot;The party, weary from travel, is attacked by a group of 3 green goblins with rusty knifes&amp;quot;)&lt;/p&gt;\\n\\n&lt;p&gt;Shit like that. Gemma has been rocking it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zd1uf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981107,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981107,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z8yfn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thisisntmethisisme","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z8k9h","score":1,"author_fullname":"t2_hket8q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what configs/advanced parameters are you using?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1z8yfn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what configs/advanced parameters are you using?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z8yfn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979693,"author_flair_text":null,"treatment_tags":[],"created_utc":1751979693,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"\\"You're having sex with the computer aren't you?\\"","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20hwz8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zq99o","score":3,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"author_flair_css_class":null,"name":"t1_n20hwz8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;You&amp;#39;re having sex with the computer aren&amp;#39;t you?&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20hwz8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751993112,"author_flair_text":null,"collapsed":false,"created_utc":1751993112,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21jxuc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pkdc0001","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zq99o","score":1,"author_fullname":"t2_yh1y8mfje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have some user usage stats that I pass to Gemma, it creates a 200 - 300 word text profile of the users in a story telling kind of text, it also creates with the same information a video script and an audio story.\\n\\nSo I got the text, the audio (using another tool) and a video (another tool) and put them together into a landing page, send an email to our steak holders saying \\"this is how our users are behaving this week\\" and they see it as a story which is nice :)\\n\\nSo far all the scripts and stories are engaging :)","edited":false,"author_flair_css_class":null,"name":"t1_n21jxuc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have some user usage stats that I pass to Gemma, it creates a 200 - 300 word text profile of the users in a story telling kind of text, it also creates with the same information a video script and an audio story.&lt;/p&gt;\\n\\n&lt;p&gt;So I got the text, the audio (using another tool) and a video (another tool) and put them together into a landing page, send an email to our steak holders saying &amp;quot;this is how our users are behaving this week&amp;quot; and they see it as a story which is nice :)&lt;/p&gt;\\n\\n&lt;p&gt;So far all the scripts and stories are engaging :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lumsd2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21jxuc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752003478,"author_flair_text":null,"collapsed":false,"created_utc":1752003478,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zq99o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thisisntmethisisme","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zhni3","score":1,"author_fullname":"t2_hket8q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what is it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zq99o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what is it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zq99o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985226,"author_flair_text":null,"treatment_tags":[],"created_utc":1751985226,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zhni3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pkdc0001","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z8k9h","score":1,"author_fullname":"t2_yh1y8mfje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For my use case Gemma3-12b is doing wonders but my use case is just lame 🤣","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zhni3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For my use case Gemma3-12b is doing wonders but my use case is just lame 🤣&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zhni3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751982616,"author_flair_text":null,"treatment_tags":[],"created_utc":1751982616,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z8k9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751979552,"send_replies":true,"parent_id":"t1_n1z6ud4","score":8,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z8k9h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m using the latest gemma3-12b and getting FANTASTIC results for one of my use cases. I&amp;#39;m building a JRPG with turn based combat similar to final fantasy 1. However, the game itself is infused with LLM narration and storytelling.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z8k9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979552,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z6ud4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thisisntmethisisme","can_mod_post":false,"created_utc":1751978945,"send_replies":true,"parent_id":"t3_1lumsd2","score":3,"author_fullname":"t2_hket8q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma3 and talk therapy 🙇‍♂️ been trying with gemma27b Q4 but it’s been eh","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z6ud4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma3 and talk therapy 🙇‍♂️ been trying with gemma27b Q4 but it’s been eh&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z6ud4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751978945,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I'm happy to give it a shot. Let me do that after work. I've been wanting a local way to generate images because I'm limited with the chat gpt quotas.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20d9kg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jack_Fryy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n201t5n","score":1,"author_fullname":"t2_1ofgmyf994","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you! When you test it hope you can share with us details like steps, model version and other settings you used","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n20d9kg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you! When you test it hope you can share with us details like steps, model version and other settings you used&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20d9kg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751991797,"author_flair_text":null,"treatment_tags":[],"created_utc":1751991797,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n25u228","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tiny_Judge_2119","can_mod_post":false,"send_replies":true,"parent_id":"t1_n201t5n","score":1,"author_fullname":"t2_aqcxxu50","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Please give this a try if you don't hate the command line,  https://github.com/mzbac/flux.swift.cli","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n25u228","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please give this a try if you don&amp;#39;t hate the command line,  &lt;a href=\\"https://github.com/mzbac/flux.swift.cli\\"&gt;https://github.com/mzbac/flux.swift.cli&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n25u228/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752063129,"author_flair_text":null,"treatment_tags":[],"created_utc":1752063129,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n201t5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751988540,"send_replies":true,"parent_id":"t1_n1zbth5","score":3,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n201t5n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m happy to give it a shot. Let me do that after work. I&amp;#39;ve been wanting a local way to generate images because I&amp;#39;m limited with the chat gpt quotas.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n201t5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751988540,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"body":"Alrighty. I downloaded the app. There are a ton of models to choose from. I'm going to try to hack my way through this. FLUX.1 [schnell] was the most downloaded I saw. It takes about 25s to generate a 1024x1024 image. It does an amazing job BTW\\n\\nI'm downloading the WAN 2.1 14b 720p q8p model now to try generating with it. I've never done video generation before","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I used the default number of steps. I'll check and see what it's set to.\\n\\nIt was set to 8","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21urbq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20yw3n","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":1752009763,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21urbq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I used the default number of steps. I&amp;#39;ll check and see what it&amp;#39;s set to.&lt;/p&gt;\\n\\n&lt;p&gt;It was set to 8&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21urbq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752006462,"author_flair_text":null,"treatment_tags":[],"created_utc":1752006462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n20yw3n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jack_Fryy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n20wrsu","score":1,"author_fullname":"t2_1ofgmyf994","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you, would love to know for flux dev as well if possible on fp16, and number steps you used","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n20yw3n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you, would love to know for flux dev as well if possible on fp16, and number steps you used&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20yw3n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751997760,"author_flair_text":null,"treatment_tags":[],"created_utc":1751997760,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n20wrsu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751997189,"send_replies":true,"parent_id":"t1_n1zbth5","score":3,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":1751997608,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20wrsu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Alrighty. I downloaded the app. There are a ton of models to choose from. I&amp;#39;m going to try to hack my way through this. FLUX.1 [schnell] was the most downloaded I saw. It takes about 25s to generate a 1024x1024 image. It does an amazing job BTW&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m downloading the WAN 2.1 14b 720p q8p model now to try generating with it. I&amp;#39;ve never done video generation before&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20wrsu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751997189,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zbth5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Jack_Fryy","can_mod_post":false,"created_utc":1751980693,"send_replies":true,"parent_id":"t3_1lumsd2","score":4,"author_fullname":"t2_1ofgmyf994","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is your mac M3 ultra chip? Would love to know how fast it takes to generate a 1024 by 1024 Flux image and a Wan 2.1 14b 5 second video both in the draw things app.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zbth5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is your mac M3 ultra chip? Would love to know how fast it takes to generate a 1024 by 1024 Flux image and a Wan 2.1 14b 5 second video both in the draw things app.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zbth5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980693,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ze78q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nologai","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zd15d","score":1,"author_fullname":"t2_1t4breoji4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exactly my thoughts. In my experience with 7900 xtx and mi300x there's not much need for nvidia if you don't want to spend too much. For LLMs everything is pretty much out of the box already","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1ze78q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly my thoughts. In my experience with 7900 xtx and mi300x there&amp;#39;s not much need for nvidia if you don&amp;#39;t want to spend too much. For LLMs everything is pretty much out of the box already&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1ze78q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981490,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981490,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zd15d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"s101c","can_mod_post":false,"created_utc":1751981100,"send_replies":true,"parent_id":"t1_n1zca2r","score":2,"author_fullname":"t2_rg6hb6my5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Medusa Halo 256 GB is the point when shit will get very real for many of us.\\n\\nIt could serve both as a powerful gaming computer and an inference machine for large models. Especially MoE models. It could also serve as the main workstation, unless you really need Nvidia GPUs specifically.\\n\\nIf the price tag eventually gets below $2500, it will be a very efficient choice.","edited":1751981285,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zd15d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Medusa Halo 256 GB is the point when shit will get very real for many of us.&lt;/p&gt;\\n\\n&lt;p&gt;It could serve both as a powerful gaming computer and an inference machine for large models. Especially MoE models. It could also serve as the main workstation, unless you really need Nvidia GPUs specifically.&lt;/p&gt;\\n\\n&lt;p&gt;If the price tag eventually gets below $2500, it will be a very efficient choice.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zd15d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981100,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zca2r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nologai","can_mod_post":false,"created_utc":1751980847,"send_replies":true,"parent_id":"t3_1lumsd2","score":3,"author_fullname":"t2_1t4breoji4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome, I'm personally waiting for zen 6 medusa halo 128/256gb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zca2r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome, I&amp;#39;m personally waiting for zen 6 medusa halo 128/256gb&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zca2r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751980847,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"They really are, but I'm getting fantastic results for certain use cases with gemma 3n","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zu8i7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751986360,"send_replies":true,"parent_id":"t1_n1zh8f5","score":3,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zu8i7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They really are, but I&amp;#39;m getting fantastic results for certain use cases with gemma 3n&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zu8i7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751986360,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zh8f5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bene_42069","can_mod_post":false,"created_utc":1751982483,"send_replies":true,"parent_id":"t3_1lumsd2","score":3,"author_fullname":"t2_9yo3ah1u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt;but it lacked all the comprehension that I get from google gemini\\n\\nLatest R1 &amp; Kimi-Dev-72B might be the closest choice, but indeed closed-weight APIs are still pretty hard to beat at least for now.","edited":1751983003,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zh8f5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt;but it lacked all the comprehension that I get from google gemini&lt;/p&gt;\\n\\n&lt;p&gt;Latest R1 &amp;amp; Kimi-Dev-72B might be the closest choice, but indeed closed-weight APIs are still pretty hard to beat at least for now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zh8f5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751982483,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zrw2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BumbleSlob","can_mod_post":false,"created_utc":1751985696,"send_replies":true,"parent_id":"t3_1lumsd2","score":3,"author_fullname":"t2_1j7fhlcqkp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You might wanna try fiddling with speculative decoding fwiw","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zrw2p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You might wanna try fiddling with speculative decoding fwiw&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zrw2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985696,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Oh this is really interesting. I'm happy to help. I'm using LM Studio, so it's kind of hard to search for models. Do you have specific models you want to see performance metrics for?","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"R1 or V3? I've not found a V3 model that works yet. I posted the R1 results in another thread","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22719n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n21zf3p","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22719n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 or V3? I&amp;#39;ve not found a V3 model that works yet. I posted the R1 results in another thread&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22719n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752009808,"author_flair_text":null,"treatment_tags":[],"created_utc":1752009808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"body":"Give me specific GGUF or MLX models on hugging face and I can give you any comparison you want. I just have to be able to find it on lm studio.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22bgzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n21zf3p","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22bgzf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Give me specific GGUF or MLX models on hugging face and I can give you any comparison you want. I just have to be able to find it on lm studio.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22bgzf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752011106,"author_flair_text":null,"treatment_tags":[],"created_utc":1752011106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n21zf3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maboesanman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zznll","score":1,"author_fullname":"t2_8c8bz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I haven’t dug too deep into them yet, since I don’t have any hardware to run heavy models, but I’m curious about the comparison for performance of 70b models vs q4 deepseek","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n21zf3p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I haven’t dug too deep into them yet, since I don’t have any hardware to run heavy models, but I’m curious about the comparison for performance of 70b models vs q4 deepseek&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21zf3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752007699,"author_flair_text":null,"treatment_tags":[],"created_utc":1752007699,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zznll","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751987928,"send_replies":true,"parent_id":"t1_n1zet59","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zznll","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh this is really interesting. I&amp;#39;m happy to help. I&amp;#39;m using LM Studio, so it&amp;#39;s kind of hard to search for models. Do you have specific models you want to see performance metrics for?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zznll/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751987928,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zet59","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maboesanman","can_mod_post":false,"created_utc":1751981694,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_8c8bz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The thing id be interested in is performance comparison between models that fit in 256 vs models that fit in 512, to evaluate how useful that last giant ram upgrade is.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zet59","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The thing id be interested in is performance comparison between models that fit in 256 vs models that fit in 512, to evaluate how useful that last giant ram upgrade is.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zet59/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981694,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"&gt; 27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.\\n&gt; \\n&gt; \\n\\n27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21b711","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThenExtension9196","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1zu3ld","score":1,"author_fullname":"t2_ess5kaos","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice. If it’s over 15 it’s good to go.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n21b711","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice. If it’s over 15 it’s good to go.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21b711/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752001058,"author_flair_text":null,"treatment_tags":[],"created_utc":1752001058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zu3ld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751986321,"send_replies":true,"parent_id":"t1_n1zpc6p","score":4,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zu3ld","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;27.36 tok/sec. 1752 tokens, 1.73s to first token. It thought for 23 seconds before responding.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zu3ld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751986321,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1zpc6p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThenExtension9196","can_mod_post":false,"created_utc":1751984959,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_ess5kaos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the toks?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zpc6p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the toks?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zpc6p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751984959,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20ixnk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1751993399,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; It lacked the understanding that I get from Google Gemini\\n\\nThere's definitely a difference between frontier API models and open source models, pretty much no matter what you do.\\n\\nWith that said, the beauty of open source models is you can customize them.\\n\\nFor instance, you can give them knowledge graphs and integrate them directly via GNNs, or you can train adapter components, or any other number of things which give you a huge edge.\\n\\nPlus, you have no usage limitations, so you can do really custom agentic stuff that can be difficult to handle with API models.\\n\\nIt's a bit of a \\"build the tool so you can build the product\\" situation, but you can get great results even with quite modest models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20ixnk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; It lacked the understanding that I get from Google Gemini&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s definitely a difference between frontier API models and open source models, pretty much no matter what you do.&lt;/p&gt;\\n\\n&lt;p&gt;With that said, the beauty of open source models is you can customize them.&lt;/p&gt;\\n\\n&lt;p&gt;For instance, you can give them knowledge graphs and integrate them directly via GNNs, or you can train adapter components, or any other number of things which give you a huge edge.&lt;/p&gt;\\n\\n&lt;p&gt;Plus, you have no usage limitations, so you can do really custom agentic stuff that can be difficult to handle with API models.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a bit of a &amp;quot;build the tool so you can build the product&amp;quot; situation, but you can get great results even with quite modest models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20ixnk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751993399,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20r0da","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WishIWasOnACatamaran","can_mod_post":false,"created_utc":1751995607,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_bqvcy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here I am stoked for my $5k MBP. Congrats and fuck you as always lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20r0da","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here I am stoked for my $5k MBP. Congrats and fuck you as always lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20r0da/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751995607,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21fzff","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bornfree4ever","can_mod_post":false,"created_utc":1752002376,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_12einrypio","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"id be interested to know how fast it can do voice cloning. for example with this project\\n\\nhttps://github.com/senstella/csm-mlx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21fzff","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;id be interested to know how fast it can do voice cloning. for example with this project&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/senstella/csm-mlx\\"&gt;https://github.com/senstella/csm-mlx&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21fzff/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752002376,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"LOL, I love your enthusiasm.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21stan","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1752005947,"send_replies":true,"parent_id":"t1_n21nbss","score":2,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21stan","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LOL, I love your enthusiasm.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21stan/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752005947,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n21nbss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArchdukeofHyperbole","can_mod_post":false,"created_utc":1752004401,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_1p41v97q5d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Get some of those i/o usb sticks, some servos, some ir sensors, batteries, and make yerself a robot. You could have it out on a busy intersection selling bottles of water in no time. Might take a while for it to make +10k roi though. Set it up so it has some situational awareness and can avoid obstacles, maybe some self defense subroutines or at least know when to run tf away from a situation (like if someone's trying to steal it) and prompt for aggresive sell tactics.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21nbss","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Get some of those i/o usb sticks, some servos, some ir sensors, batteries, and make yerself a robot. You could have it out on a busy intersection selling bottles of water in no time. Might take a while for it to make +10k roi though. Set it up so it has some situational awareness and can avoid obstacles, maybe some self defense subroutines or at least know when to run tf away from a situation (like if someone&amp;#39;s trying to steal it) and prompt for aggresive sell tactics.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21nbss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752004401,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22g6mm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Spanky2k","can_mod_post":false,"created_utc":1752012509,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_lodzt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Could you try the DWQ 4 bit version of 235b? Qwen3-235B-A22B-4bit-DWQ. It should run at about the same speed as the 4bit MLX version but it has close to the same complexity as the 6bit MLX version.\\n\\nI'm tempted with a M3 Ultra but I'm still kind of gutted that it wasn't an M4 Ultra and so might just wait to see what the M5 is like when the MBPs with it come out late this year (currently running my old M1 ultra with Qwen3 32b for internal usage).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22g6mm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you try the DWQ 4 bit version of 235b? Qwen3-235B-A22B-4bit-DWQ. It should run at about the same speed as the 4bit MLX version but it has close to the same complexity as the 6bit MLX version.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m tempted with a M3 Ultra but I&amp;#39;m still kind of gutted that it wasn&amp;#39;t an M4 Ultra and so might just wait to see what the M5 is like when the MBPs with it come out late this year (currently running my old M1 ultra with Qwen3 32b for internal usage).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22g6mm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752012509,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Yeah, I'm getting about 20tok/s with the 8bit gwen3. It's much better than the 4 bit at what I've been throwing at it.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"definitely getting some reliably good results from gwen3-235b-122b 8bit","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n25amli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n23pwms","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25amli","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;definitely getting some reliably good results from gwen3-235b-122b 8bit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n25amli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752054659,"author_flair_text":null,"treatment_tags":[],"created_utc":1752054659,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n23pwms","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JBManos","can_mod_post":false,"send_replies":true,"parent_id":"t1_n23le8h","score":1,"author_fullname":"t2_ps74i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’ve been tempted to try rolling my own mixed quant mlx but I got sidetracked into Ernie 4.5 for now.  It won’t run straight in lm studio yet but there are mlx quants of the 300B-a47b model so I’ve been toying with that and sticking with the qwen3 8bit mlx","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n23pwms","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve been tempted to try rolling my own mixed quant mlx but I got sidetracked into Ernie 4.5 for now.  It won’t run straight in lm studio yet but there are mlx quants of the 300B-a47b model so I’ve been toying with that and sticking with the qwen3 8bit mlx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n23pwms/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752027542,"author_flair_text":null,"treatment_tags":[],"created_utc":1752027542,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n23le8h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1752026021,"send_replies":true,"parent_id":"t1_n236bdx","score":2,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n23le8h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I&amp;#39;m getting about 20tok/s with the 8bit gwen3. It&amp;#39;s much better than the 4 bit at what I&amp;#39;ve been throwing at it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n23le8h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752026021,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n236bdx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JBManos","can_mod_post":false,"created_utc":1752020925,"send_replies":true,"parent_id":"t3_1lumsd2","score":2,"author_fullname":"t2_ps74i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Be sure you got a good quantization of the model, preferably a good mlx variant.     You should be seeing decent and sometimes excellent performance for what you described.    Also, the qwen3 model has an mlx instruct variant at 8bit and another at 4bit.    Try those.  They run at 20tok/s easy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n236bdx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Be sure you got a good quantization of the model, preferably a good mlx variant.     You should be seeing decent and sometimes excellent performance for what you described.    Also, the qwen3 model has an mlx instruct variant at 8bit and another at 4bit.    Try those.  They run at 20tok/s easy&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n236bdx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752020925,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Cool deal brother. I'll check out the models. I was just using the LM Studio recommended models at first. I haven't played with the others on the new machine yet.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n20ikn6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1751993298,"send_replies":true,"parent_id":"t1_n20dqei","score":1,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20ikn6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool deal brother. I&amp;#39;ll check out the models. I was just using the LM Studio recommended models at first. I haven&amp;#39;t played with the others on the new machine yet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20ikn6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751993298,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n20dqei","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_hephaestus","can_mod_post":false,"created_utc":1751991929,"send_replies":true,"parent_id":"t3_1lumsd2","score":1,"author_fullname":"t2_158x8q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also got one recently, curious what you end up doing for software/workflow stuff, have been too busy to do anything beyond lmstudio exposed via openai api to open-webui, but ollama seems to be what a bunch of tools like homeassistant are built around and the lack of mlx there without forking is a pain. I found the 8q qwen3-235 better than the 4q but beyond that haven’t ran any other models. Thinking takes a while.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n20dqei","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also got one recently, curious what you end up doing for software/workflow stuff, have been too busy to do anything beyond lmstudio exposed via openai api to open-webui, but ollama seems to be what a bunch of tools like homeassistant are built around and the lack of mlx there without forking is a pain. I found the 8q qwen3-235 better than the 4q but beyond that haven’t ran any other models. Thinking takes a while.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n20dqei/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751991929,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Oh interesting. This is another use case of mine. I've got to batch process custom texts to use as backups in case the live system is offline (because my internet is out or something.)\\n\\nI'll be able to document this and make a blog post / reddit post about it.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21tq3a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1752006187,"send_replies":true,"parent_id":"t1_n21howt","score":2,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21tq3a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh interesting. This is another use case of mine. I&amp;#39;ve got to batch process custom texts to use as backups in case the live system is offline (because my internet is out or something.)&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll be able to document this and make a blog post / reddit post about it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21tq3a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752006187,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n21howt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Guilty-Enthusiasm-50","can_mod_post":false,"created_utc":1752002854,"send_replies":true,"parent_id":"t3_1lumsd2","score":1,"author_fullname":"t2_3kzri34s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've been eyeing a similar setup for a while. Might i ask how is the parallelization when running small ones like gemma3-27b or big ones like qwen-deepseek etc? \\n\\nMy use case involves around a 100 concurrent users, and i wonder how would the speed be impacted? \\n\\nMaybe increase the load eventually for 10-30-50-80-100 concurrent users?","edited":1752003110,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21howt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve been eyeing a similar setup for a while. Might i ask how is the parallelization when running small ones like gemma3-27b or big ones like qwen-deepseek etc? &lt;/p&gt;\\n\\n&lt;p&gt;My use case involves around a 100 concurrent users, and i wonder how would the speed be impacted? &lt;/p&gt;\\n\\n&lt;p&gt;Maybe increase the load eventually for 10-30-50-80-100 concurrent users?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n21howt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752002854,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22rcz0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"himey72","can_mod_post":false,"created_utc":1752016027,"send_replies":true,"parent_id":"t3_1lumsd2","score":1,"author_fullname":"t2_7i23q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m certain that you’ll find a $10k Mac Studio to be disappointing for everything you’re trying to accomplish.  I’d like to help you out.  How about I trade you a Toshiba laptop for it?  :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22rcz0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m certain that you’ll find a $10k Mac Studio to be disappointing for everything you’re trying to accomplish.  I’d like to help you out.  How about I trade you a Toshiba laptop for it?  :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n22rcz0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752016027,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24qza8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rm-rf-rm","can_mod_post":false,"created_utc":1752043594,"send_replies":true,"parent_id":"t3_1lumsd2","score":1,"author_fullname":"t2_xucqa0ilr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mac Studio with M3 Ultra and 256GB here.\\n\\nI also have the same experience with Cline. Quite crestfallen but good to see that even 2x the RAM doesnt seem to solve it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n24qza8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mac Studio with M3 Ultra and 256GB here.&lt;/p&gt;\\n\\n&lt;p&gt;I also have the same experience with Cline. Quite crestfallen but good to see that even 2x the RAM doesnt seem to solve it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n24qza8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752043594,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"LM Studio does everything I need. All I need is an openAI compatible interface, and LM Studio is a great interface for that need.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zdaeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Crinkez","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1z88is","score":1,"author_fullname":"t2_1l1e573g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you tried AnythingLM?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1zdaeg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried AnythingLM?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zdaeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751981187,"author_flair_text":null,"treatment_tags":[],"created_utc":1751981187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z88is","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1751979435,"send_replies":true,"parent_id":"t1_n1z71mm","score":7,"author_fullname":"t2_cbxyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z88is","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LM Studio does everything I need. All I need is an openAI compatible interface, and LM Studio is a great interface for that need.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z88is/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979435,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1zrsl7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BumbleSlob","can_mod_post":false,"created_utc":1751985668,"send_replies":true,"parent_id":"t1_n1z71mm","score":3,"author_fullname":"t2_1j7fhlcqkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Closed source, confusing menus, I didn’t like it personally. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1zrsl7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Closed source, confusing menus, I didn’t like it personally. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lumsd2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1zrsl7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751985668,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1z71mm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Intelligent-Dust1715","can_mod_post":false,"created_utc":1751979018,"send_replies":true,"parent_id":"t3_1lumsd2","score":0,"author_fullname":"t2_1m6ab9ywlu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any of you tried using Msty?  What do you think of it compared to LM Studio?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1z71mm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any of you tried using Msty?  What do you think of it compared to LM Studio?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lumsd2/mac_studio_512gb_online/n1z71mm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751979018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lumsd2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
