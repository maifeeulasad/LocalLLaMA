import{j as e}from"./index-CeRg6Q3f.js";import{R as a}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const t=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"MMLU-ProX is a multilingual benchmark that extends the challenging MMLU-Pro benchmark to 29 typologically diverse languages, designed to evaluate the cross-lingual reasoning capabilities of large language models (LLMs). Built through a rigorous four-stage translation pipeline using state-of-the-art LLMs (primarily Claude Sonnet 3.7) combined with expert verification, the benchmark contains 11,829 identical questions per language (with a lite version of 658 questions), covering 57 subjects across multiple disciplines with complex reasoning-focused multiple-choice questions featuring 10 answer options and chain-of-thought prompting support.\\n\\nThe benchmark reveals significant performance disparities across languages when evaluating 36 state-of-the-art LLMs, with models achieving strong performance on high-resource Western European languages (often 75%+ accuracy) but substantially lower scores on low-resource African languages like Wolof (as low as 0.6% to 58.6%), highlighting persistent challenges in multilingual AI development and the need for more inclusive language model capabilities across global contexts.​​​​​​​​​​​​​​​​\\n\\n- Website: https://mmluprox.github.io\\n- Paper: https://arxiv.org/abs/2503.10497\\n- Code: https://github.com/weihao1115/MMLU-ProX (still empty)\\n- Full dataset: https://huggingface.co/datasets/li-lab/MMLU-ProX\\n- Lite dataset: https://huggingface.co/datasets/li-lab/MMLU-ProX-Lite","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"is_gallery":true,"title":"MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"name":"t3_1lzzcje","media_metadata":{"wgsfm22gswcf1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":141,"x":108,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=691617a7ea37d1a5091179464ab143f85468a96e"},{"y":282,"x":216,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=13438d7635ba748f597b00003f2864927e862a0d"},{"y":419,"x":320,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=90ce8e777b58617edab45238b32011b2a0fc2fd4"},{"y":838,"x":640,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c6764ec9b355c53fe2ad3069ae65b2d7c965c24"},{"y":1257,"x":960,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c1ab9f3f6ff3057a8109d9ef7b40dba9f332b1b"},{"y":1414,"x":1080,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2a7d29c5d99c65d37649c143640f1837355e5883"}],"s":{"y":2416,"x":1845,"u":"https://preview.redd.it/wgsfm22gswcf1.jpg?width=1845&amp;format=pjpg&amp;auto=webp&amp;s=af2d88a2d17ea254a0dc776e725953027aba90ff"},"id":"wgsfm22gswcf1"},"cepva22gswcf1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":63,"x":108,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=721ac7c709c4f0f3960a92c4ac1130823c849949"},{"y":127,"x":216,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=755aa779fcf53987afe487b20786abae4bc317d9"},{"y":189,"x":320,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6000d6aff7a8d8ad61eb3a2b8e7911338a22ac9"},{"y":378,"x":640,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36ca8dc0910cc79159f24e3b974fd7d8611a534e"},{"y":568,"x":960,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3be6352cc43e102dca25a7edef1e96677ce41f3b"},{"y":639,"x":1080,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56c643abe61beffd12a31324ef3eb83028bfb195"}],"s":{"y":1498,"x":2531,"u":"https://preview.redd.it/cepva22gswcf1.jpg?width=2531&amp;format=pjpg&amp;auto=webp&amp;s=2b6a4c92395db017d8d7ecc8c4ff995541355888"},"id":"cepva22gswcf1"},"jy1gl22gswcf1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":123,"x":108,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d501900b8ce2284997bbb24f0cb60d3663d6132"},{"y":247,"x":216,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76b73821477a93932f341bda7a8514ead81853ee"},{"y":367,"x":320,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd43ee53d37519462ce42c539e56fc3699ffeb63"},{"y":734,"x":640,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d93023b31b27e8ca98a804b8c4e3a459b3c6d4dd"},{"y":1101,"x":960,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=42183f8dcbc95702fcd7ba98a5d06493b984431a"},{"y":1239,"x":1080,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e56314bcacb6ec3529a7ef5f17364fd2d2a328dd"}],"s":{"y":2226,"x":1940,"u":"https://preview.redd.it/jy1gl22gswcf1.jpg?width=1940&amp;format=pjpg&amp;auto=webp&amp;s=ab8a55e2c76f7c0820b0122d79426fa515025fdf"},"id":"jy1gl22gswcf1"},"o9ysd22gswcf1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":131,"x":108,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92f7a072ea75bf25c6613c54363b3a8816f1cf02"},{"y":263,"x":216,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92ee3fb3d1922992a2f6e4d93b59033511ef3db1"},{"y":390,"x":320,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=300e2152a2bd5d1540651f68670f0caed16c004c"},{"y":780,"x":640,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=971ae8d2b089a6c4d2729a733f501b03dc04a648"},{"y":1171,"x":960,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a146661a61e9a38380b2be4a25658ceda38e580"},{"y":1317,"x":1080,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb15168f0b557c684059fb4d5262e3bb5de2fc56"}],"s":{"y":2367,"x":1940,"u":"https://preview.redd.it/o9ysd22gswcf1.jpg?width=1940&amp;format=pjpg&amp;auto=webp&amp;s=caa08ce1445257b1a6bd05e754731bb29f7bb6f7"},"id":"o9ysd22gswcf1"}},"hide_score":false,"quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"ups":31,"domain":"reddit.com","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_14okit","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"gallery_data":{"items":[{"media_id":"o9ysd22gswcf1","id":706015027},{"media_id":"wgsfm22gswcf1","id":706015028},{"media_id":"cepva22gswcf1","id":706015029},{"media_id":"jy1gl22gswcf1","id":706015030}]},"link_flair_text":"Resources","can_mod_post":false,"score":31,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/irH_IxYHAQEjBGgXU_AOln_EsxdXVQKIs5z4JjXsVfc.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"subreddit_type":"public","created":1752528984,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;MMLU-ProX is a multilingual benchmark that extends the challenging MMLU-Pro benchmark to 29 typologically diverse languages, designed to evaluate the cross-lingual reasoning capabilities of large language models (LLMs). Built through a rigorous four-stage translation pipeline using state-of-the-art LLMs (primarily Claude Sonnet 3.7) combined with expert verification, the benchmark contains 11,829 identical questions per language (with a lite version of 658 questions), covering 57 subjects across multiple disciplines with complex reasoning-focused multiple-choice questions featuring 10 answer options and chain-of-thought prompting support.&lt;/p&gt;\\n\\n&lt;p&gt;The benchmark reveals significant performance disparities across languages when evaluating 36 state-of-the-art LLMs, with models achieving strong performance on high-resource Western European languages (often 75%+ accuracy) but substantially lower scores on low-resource African languages like Wolof (as low as 0.6% to 58.6%), highlighting persistent challenges in multilingual AI development and the need for more inclusive language model capabilities across global contexts.​​​​​​​​​​​​​​​​&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Website: &lt;a href=\\"https://mmluprox.github.io\\"&gt;https://mmluprox.github.io&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Paper: &lt;a href=\\"https://arxiv.org/abs/2503.10497\\"&gt;https://arxiv.org/abs/2503.10497&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Code: &lt;a href=\\"https://github.com/weihao1115/MMLU-ProX\\"&gt;https://github.com/weihao1115/MMLU-ProX&lt;/a&gt; (still empty)&lt;/li&gt;\\n&lt;li&gt;Full dataset: &lt;a href=\\"https://huggingface.co/datasets/li-lab/MMLU-ProX\\"&gt;https://huggingface.co/datasets/li-lab/MMLU-ProX&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Lite dataset: &lt;a href=\\"https://huggingface.co/datasets/li-lab/MMLU-ProX-Lite\\"&gt;https://huggingface.co/datasets/li-lab/MMLU-ProX-Lite&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.reddit.com/gallery/1lzzcje","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lzzcje","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Balance-","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/","stickied":false,"url":"https://www.reddit.com/gallery/1lzzcje","subreddit_subscribers":499295,"created_utc":1752528984,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"609bf7d4-01f3-11f0-9760-5611c8333bee","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36dv6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"random-tomato","can_mod_post":false,"created_utc":1752539588,"send_replies":true,"parent_id":"t1_n35wckk","score":2,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol came here to say the same thing. These benchmark names are getting super weird.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36dv6t","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol came here to say the same thing. These benchmark names are getting super weird.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzzcje","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n36dv6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752539588,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n35wckk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"You_Wen_AzzHu","can_mod_post":false,"created_utc":1752533775,"send_replies":true,"parent_id":"t3_1lzzcje","score":7,"author_fullname":"t2_p4oxcufl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We need a Pro Max.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35wckk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"exllama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need a Pro Max.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n35wckk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533775,"author_flair_text":"exllama","treatment_tags":[],"link_id":"t3_1lzzcje","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35xs26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Street_Teaching_7434","can_mod_post":false,"created_utc":1752534240,"send_replies":true,"parent_id":"t3_1lzzcje","score":6,"author_fullname":"t2_11pjlvmnnv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All Benchmarks that are effectively just a large dataset of questions have two major poeblems which make them not reprensentative:\\n- the questions will eventually leak into the training data for LLMs\\n- such benchmarks can easily be trained for (or on) to artificially boost score figures, even on models that, in practical use case, are not very good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35xs26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All Benchmarks that are effectively just a large dataset of questions have two major poeblems which make them not reprensentative:\\n- the questions will eventually leak into the training data for LLMs\\n- such benchmarks can easily be trained for (or on) to artificially boost score figures, even on models that, in practical use case, are not very good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n35xs26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752534240,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzzcje","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37q9ng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"created_utc":1752558868,"send_replies":true,"parent_id":"t3_1lzzcje","score":2,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is there a way to run this or other benchmarks yourself using llama.cpp?\\n\\nI want to see how well the quantized versions of the models I use actually perform.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37q9ng","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there a way to run this or other benchmarks yourself using llama.cpp?&lt;/p&gt;\\n\\n&lt;p&gt;I want to see how well the quantized versions of the models I use actually perform.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n37q9ng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752558868,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzzcje","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zdpz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AFAIX","can_mod_post":false,"created_utc":1752563791,"send_replies":true,"parent_id":"t3_1lzzcje","score":1,"author_fullname":"t2_8i8xi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder if anyone makes a distinction between Portuguese from Brazil and from Portugal, they are distinct enough that Portuguese guys constantly get annoyed by Brazilian version being the default (and often the only) version.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zdpz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if anyone makes a distinction between Portuguese from Brazil and from Portugal, they are distinct enough that Portuguese guys constantly get annoyed by Brazilian version being the default (and often the only) version.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n37zdpz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752563791,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzzcje","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3887s2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bullerwins","can_mod_post":false,"created_utc":1752568963,"send_replies":true,"parent_id":"t3_1lzzcje","score":1,"author_fullname":"t2_d3wk5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wen an openai compatible api tool to benchmark it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3887s2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wen an openai compatible api tool to benchmark it?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzzcje/mmluprox_a_multilingual_benchmark_for_advanced/n3887s2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752568963,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzzcje","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),o=()=>e.jsx(a,{data:t});export{o as default};
