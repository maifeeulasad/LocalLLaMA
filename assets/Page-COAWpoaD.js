import{j as e}from"./index-DLSqWzaI.js";import{R as l}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hunyuan-A13B is now available for LM Studio with Unsloth GGUF. I am on the Beta track for both LM Studio and llama.cpp backend. Here are my initial impression:\\n\\nIt is fast! I am getting 40 tokens per second initially dropping to maybe 30 tokens per second when the context has build up some. This is on M4 Max Macbook Pro and q4.\\n\\nThe context is HUGE. 256k. I don't expect I will be using that much, but it is nice that I am unlikely to hit the ceiling in practical use.\\n\\nIt made a chess game for me and it did ok. No errors but the game was not complete. It did complete it after a few prompts and it also fixed one error that happened in the javascript console.\\n\\nIt did spend some time thinking, but not as much as I have seen other models do. I would say it is doing the middle ground here, but I am still to test this extensively. The model card claims you can somehow influence how much thinking it will do. But I am not sure how yet.\\n\\nIt appears to wrap the final answer in &lt;answer&gt;the answer here&lt;/answer&gt; just like it does for &lt;think&gt;&lt;/think&gt;. This may or may not be a problem for tools? Maybe we need to update our software to strip this out.\\n\\nThe total memory usage for the Unsloth 4 bit UD quant is 61 GB. I will test 6 bit and 8 bit also, but I am quite in love with the speed of the 4 bit and it appears to have good quality regardless. So maybe I will just stick with 4 bit?\\n\\nThis is a 80b model that is very fast. Feels like the future.\\n\\nEdit: The 61 GB size is with 8 bit KV cache quantization. However I just noticed that they claim this is bad in the model card, so I disabled KV cache quantization. This increased memory usage to 76 GB. That is with the full 256k context size enabled. I expect you can just lower that if you don't have enough memory. Or stay with KV cache quantization because it did appear to work just fine. I would say this could work on a 64 GB machine if you just use KV cache quantization and maybe lower the context size to 128k. ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Hunyuan-A13B is here for real!","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvvkh2","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.94,"author_flair_background_color":null,"subreddit_type":"public","ups":170,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_bvqb8ng0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":170,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752099902,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752098151,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hunyuan-A13B is now available for LM Studio with Unsloth GGUF. I am on the Beta track for both LM Studio and llama.cpp backend. Here are my initial impression:&lt;/p&gt;\\n\\n&lt;p&gt;It is fast! I am getting 40 tokens per second initially dropping to maybe 30 tokens per second when the context has build up some. This is on M4 Max Macbook Pro and q4.&lt;/p&gt;\\n\\n&lt;p&gt;The context is HUGE. 256k. I don&amp;#39;t expect I will be using that much, but it is nice that I am unlikely to hit the ceiling in practical use.&lt;/p&gt;\\n\\n&lt;p&gt;It made a chess game for me and it did ok. No errors but the game was not complete. It did complete it after a few prompts and it also fixed one error that happened in the javascript console.&lt;/p&gt;\\n\\n&lt;p&gt;It did spend some time thinking, but not as much as I have seen other models do. I would say it is doing the middle ground here, but I am still to test this extensively. The model card claims you can somehow influence how much thinking it will do. But I am not sure how yet.&lt;/p&gt;\\n\\n&lt;p&gt;It appears to wrap the final answer in &amp;lt;answer&amp;gt;the answer here&amp;lt;/answer&amp;gt; just like it does for &amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;. This may or may not be a problem for tools? Maybe we need to update our software to strip this out.&lt;/p&gt;\\n\\n&lt;p&gt;The total memory usage for the Unsloth 4 bit UD quant is 61 GB. I will test 6 bit and 8 bit also, but I am quite in love with the speed of the 4 bit and it appears to have good quality regardless. So maybe I will just stick with 4 bit?&lt;/p&gt;\\n\\n&lt;p&gt;This is a 80b model that is very fast. Feels like the future.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: The 61 GB size is with 8 bit KV cache quantization. However I just noticed that they claim this is bad in the model card, so I disabled KV cache quantization. This increased memory usage to 76 GB. That is with the full 256k context size enabled. I expect you can just lower that if you don&amp;#39;t have enough memory. Or stay with KV cache quantization because it did appear to work just fine. I would say this could work on a 64 GB machine if you just use KV cache quantization and maybe lower the context size to 128k. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1lvvkh2","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Baldur-Norddahl","discussion_type":null,"num_comments":107,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/","subreddit_subscribers":497354,"created_utc":1752098151,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ch2gg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iq1pl","can_mod_post":false,"created_utc":1752147485,"send_replies":true,"parent_id":"t1_n299gks","score":13,"author_fullname":"t2_rxgre5u8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Honestly i would prefer it if it was \`/think\` to start thinking not the other way around, most of the times you just want a quick answer","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ch2gg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly i would prefer it if it was &lt;code&gt;/think&lt;/code&gt; to start thinking not the other way around, most of the times you just want a quick answer&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ch2gg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147485,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n299gks","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LocoMod","can_mod_post":false,"created_utc":1752098358,"send_replies":true,"parent_id":"t3_1lvvkh2","score":27,"author_fullname":"t2_6uuoq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can also pass in \`/no_think\` in your prompt to disable thinking mode and have it respond even faster.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n299gks","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can also pass in &lt;code&gt;/no_think&lt;/code&gt; in your prompt to disable thinking mode and have it respond even faster.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n299gks/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752098358,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2dsit6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zestyclose_Yak_3174","can_mod_post":false,"created_utc":1752162556,"send_replies":true,"parent_id":"t1_n2cofso","score":1,"author_fullname":"t2_o0jgdhlij","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately confirms my suspicion","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2dsit6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately confirms my suspicion&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2dsit6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752162556,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2gocy4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2fy5mc","score":2,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe this is the case, I will wait a bit so lama.cpp devs cook it more.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2gocy4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe this is the case, I will wait a bit so lama.cpp devs cook it more.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2gocy4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752193238,"author_flair_text":null,"treatment_tags":[],"created_utc":1752193238,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2fy5mc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LogicalAnimation","can_mod_post":false,"created_utc":1752184611,"send_replies":true,"parent_id":"t1_n2cofso","score":1,"author_fullname":"t2_625i4zoy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"have you tried the offical q4 k\\\\_m quant? it was made public a few hours ago by tencent. [https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF](https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF)  \\nI have been following the llama.cpp pr dissusion and appearently the unoffical models have a lot of problems. I have tried the unoffical q3 k\\\\_s and it was much worse than gemma 3 12b in translation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2fy5mc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;have you tried the offical q4 k_m quant? it was made public a few hours ago by tencent. &lt;a href=\\"https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF\\"&gt;https://huggingface.co/tencent/Hunyuan-A13B-Instruct-GGUF&lt;/a&gt;&lt;br/&gt;\\nI have been following the llama.cpp pr dissusion and appearently the unoffical models have a lot of problems. I have tried the unoffical q3 k_s and it was much worse than gemma 3 12b in translation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2fy5mc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752184611,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cofso","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"created_utc":1752150363,"send_replies":true,"parent_id":"t3_1lvvkh2","score":7,"author_fullname":"t2_s4zzntp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've tested this model at Q4KS and I kinda get better results from Gemma 3 12b tbh,  \\nEven small Gemma 3n E4B give me more stable results and better English without Chinese symbols etc.  \\nOnly coding was a bit better at Gemma 3 27b level.\\n\\nhttps://preview.redd.it/9idwfe0bi1cf1.png?width=1221&amp;format=png&amp;auto=webp&amp;s=21e4f09edd6cea9e9df0dc78a1721f5a22ac04cd","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cofso","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tested this model at Q4KS and I kinda get better results from Gemma 3 12b tbh,&lt;br/&gt;\\nEven small Gemma 3n E4B give me more stable results and better English without Chinese symbols etc.&lt;br/&gt;\\nOnly coding was a bit better at Gemma 3 27b level.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/9idwfe0bi1cf1.png?width=1221&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21e4f09edd6cea9e9df0dc78a1721f5a22ac04cd\\"&gt;https://preview.redd.it/9idwfe0bi1cf1.png?width=1221&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21e4f09edd6cea9e9df0dc78a1721f5a22ac04cd&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cofso/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150363,"media_metadata":{"9idwfe0bi1cf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":59,"x":108,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c63c3756c2de478c6f621d8f359bc8f87502a8e"},{"y":119,"x":216,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae01c8de83a3cb5dc491ca2f9321749ae19bd8c6"},{"y":176,"x":320,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=339e9b310007ebe5a9ee52e73a6966afcffb4e2f"},{"y":353,"x":640,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=96d828f863ae2ab09f7da4c27af428243e269659"},{"y":529,"x":960,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3e940891f083af91ab795f01d346540e66934e9"},{"y":596,"x":1080,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d89b5a3d3c41aeccd68726ca2e78a9a2c40bab33"}],"s":{"y":674,"x":1221,"u":"https://preview.redd.it/9idwfe0bi1cf1.png?width=1221&amp;format=png&amp;auto=webp&amp;s=21e4f09edd6cea9e9df0dc78a1721f5a22ac04cd"},"id":"9idwfe0bi1cf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2flwi6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"reginakinhi","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2fkl6d","score":5,"author_fullname":"t2_47jf22jq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It gives all the information needed for memory usage, generation speed and pp speed. Which seems to be all they're after.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2flwi6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It gives all the information needed for memory usage, generation speed and pp speed. Which seems to be all they&amp;#39;re after.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2flwi6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752180947,"author_flair_text":null,"treatment_tags":[],"created_utc":1752180947,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2fkl6d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Susp-icious_-31User","can_mod_post":false,"send_replies":false,"parent_id":"t1_n2d9wew","score":2,"author_fullname":"t2_8wt4gn6f5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They're trying to tell you your test doesn't tell you anything at all.","edited":false,"author_flair_css_class":null,"name":"t1_n2fkl6d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;re trying to tell you your test doesn&amp;#39;t tell you anything at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2fkl6d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752180575,"author_flair_text":null,"collapsed":false,"created_utc":1752180575,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2d9wew","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2d7zqn","score":3,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This was purely a convenient context test.  Performance better left to proper benchmarks than my smoke tests.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2d9wew","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was purely a convenient context test.  Performance better left to proper benchmarks than my smoke tests.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2d9wew/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752157300,"author_flair_text":null,"treatment_tags":[],"created_utc":1752157300,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2d7zqn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tomz17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29wxyb","score":7,"author_fullname":"t2_1mhx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IMHO, you need to find-replace \\"Adam\\" with \\"Steve\\", and see if the model still provides the correct answer  (i.e. the bible was likely in some upstream training set, so it is almost certainly able to provide those answers without any context input whatsoever)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2d7zqn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IMHO, you need to find-replace &amp;quot;Adam&amp;quot; with &amp;quot;Steve&amp;quot;, and see if the model still provides the correct answer  (i.e. the bible was likely in some upstream training set, so it is almost certainly able to provide those answers without any context input whatsoever)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2d7zqn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752156734,"author_flair_text":null,"treatment_tags":[],"created_utc":1752156734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cwi8v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2c1gxa","score":3,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It was purely something easy to find online that was very large and in raw text to test out the context windows.\\n\\nThe answer looked reasonable I suppose?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cwi8v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It was purely something easy to find online that was very large and in raw text to test out the context windows.&lt;/p&gt;\\n\\n&lt;p&gt;The answer looked reasonable I suppose?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cwi8v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752153175,"author_flair_text":null,"treatment_tags":[],"created_utc":1752153175,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2c1gxa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-lq_pl-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29wxyb","score":1,"author_fullname":"t2_16rvbe","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And? Was the answer correct? :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2c1gxa","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And? Was the answer correct? :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c1gxa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752139799,"author_flair_text":null,"treatment_tags":[],"created_utc":1752139799,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29wxyb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1752105956,"send_replies":true,"parent_id":"t1_n29rpfq","score":12,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So sticking with unsloth, set to context to 65536, pasted in the first ~63k tokens of the bible and asked it who Adam is. \\n\\nhttps://imgur.com/a/vkJMq8Z\\n\\n55 tok/s and ~27s to PP all of that so around 2300-2400 tok/s PP? \\n\\nContext is 97.1% full at end.\\n\\nEdit, added 128k test with about 124k input,  38 tok/s and 1600 PP, ending at 97.2% full\\n\\n... and added test with full 262k and filled to 99.9% by the end of output.  21.5 tok/s, ~920 PP, 99.9% full","edited":1752107476,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29wxyb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So sticking with unsloth, set to context to 65536, pasted in the first ~63k tokens of the bible and asked it who Adam is. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://imgur.com/a/vkJMq8Z\\"&gt;https://imgur.com/a/vkJMq8Z&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;55 tok/s and ~27s to PP all of that so around 2300-2400 tok/s PP? &lt;/p&gt;\\n\\n&lt;p&gt;Context is 97.1% full at end.&lt;/p&gt;\\n\\n&lt;p&gt;Edit, added 128k test with about 124k input,  38 tok/s and 1600 PP, ending at 97.2% full&lt;/p&gt;\\n\\n&lt;p&gt;... and added test with full 262k and filled to 99.9% by the end of output.  21.5 tok/s, ~920 PP, 99.9% full&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29wxyb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105956,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29ui7g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1752105131,"send_replies":true,"parent_id":"t1_n29rpfq","score":9,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ok, unsloth Q5_K_XL seems to be fine.  Still 85-90 tok/s for shorter interactions.","edited":1752105979,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29ui7g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok, unsloth Q5_K_XL seems to be fine.  Still 85-90 tok/s for shorter interactions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29ui7g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105131,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2csst8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kitchen-Year-8434","can_mod_post":false,"created_utc":1752151928,"send_replies":true,"parent_id":"t1_n29rpfq","score":5,"author_fullname":"t2_b78412ov","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;  fp16 kv cache which is what I use with everything\\n\\nCould you say more about why on this? I deep researched (Gemini) the history of kv cache quant, perplexity implications, and compounding effects over long context generation and honestly it's hard to find non-anecdotal information around this. Plus just tried to read the hell out of a lot of this over the past couple weeks as I was setting up a Blackwell RTX 6000 rig.\\n\\nIt seems like the general distillation of kv cache quantization is:\\n\\n- int4, int6, problematic for long context and detailed tasks (drift, loss, etc)\\n\\n- k quant more sensitive than V; go FP16 K 5_1 V in llama.cpp for instance ok for coding\\n\\n- int8 statistically indistinguishable from fp16\\n\\n- fp4, fp8 support non-existent but who knows. Given how nvfp4 seems to perform compared to bf16 there's a chance that might be the magic bullet for hardware that supports it\\n\\n- vaguely, coding tasks suffer more from kv cache quant than more semantically loose summarization, however multi-step agentic workflows like in Roo / Zed plus compiler feedback more or less mitigate this\\n\\n- exllama w/the [Q4 + Hadamard rotation magic](https://github.com/turboderp-org/exllamav2/blob/master/doc/qcache_eval.md) shows a Q4 cache indistinguishable from FP16\\n\\nSo... yeah. :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2csst8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;fp16 kv cache which is what I use with everything&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Could you say more about why on this? I deep researched (Gemini) the history of kv cache quant, perplexity implications, and compounding effects over long context generation and honestly it&amp;#39;s hard to find non-anecdotal information around this. Plus just tried to read the hell out of a lot of this over the past couple weeks as I was setting up a Blackwell RTX 6000 rig.&lt;/p&gt;\\n\\n&lt;p&gt;It seems like the general distillation of kv cache quantization is:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;int4, int6, problematic for long context and detailed tasks (drift, loss, etc)&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;k quant more sensitive than V; go FP16 K 5_1 V in llama.cpp for instance ok for coding&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;int8 statistically indistinguishable from fp16&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;fp4, fp8 support non-existent but who knows. Given how nvfp4 seems to perform compared to bf16 there&amp;#39;s a chance that might be the magic bullet for hardware that supports it&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;vaguely, coding tasks suffer more from kv cache quant than more semantically loose summarization, however multi-step agentic workflows like in Roo / Zed plus compiler feedback more or less mitigate this&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;exllama w/the &lt;a href=\\"https://github.com/turboderp-org/exllamav2/blob/master/doc/qcache_eval.md\\"&gt;Q4 + Hadamard rotation magic&lt;/a&gt; shows a Q4 cache indistinguishable from FP16&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;So... yeah. :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2csst8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151928,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2d87rn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LocoMod","can_mod_post":false,"created_utc":1752156801,"send_replies":true,"parent_id":"t1_n29rpfq","score":3,"author_fullname":"t2_6uuoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unlsoth has the suggested params:\\n\\n\`\`\`\\n./llama.cpp/llama-cli -hf unsloth/Hunyuan-A13B-Instruct-GGUF:Q4_K_XL -ngl 99 --jinja --temp 0.7 --top-k 20 --top-p 0.8 --min-p 0.05 --repeat-penalty 1.05\\n\`\`\`\\n\\nSource (at the very top):\\n\\nhttps://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2d87rn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unlsoth has the suggested params:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;\\n./llama.cpp/llama-cli -hf unsloth/Hunyuan-A13B-Instruct-GGUF:Q4_K_XL -ngl 99 --jinja --temp 0.7 --top-k 20 --top-p 0.8 --min-p 0.05 --repeat-penalty 1.05\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Source (at the very top):&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF\\"&gt;https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2d87rn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752156801,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29rpfq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1752104211,"send_replies":true,"parent_id":"t3_1lvvkh2","score":15,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Quick smoke test.  Q6_K (bullerwins gguf that I downloaded last week?) on a Blackwell Pro 6000, ~85-90 token/s, similar to Llama 4 Scout. ~66 GB used, context set to 16384. \\n\\n/no_think works\\n\\nGettting endless repetition a lot, not sure what suggested sampling params are.  Tried playing with them a bit, no dice on fixing it.\\n\\nhttps://imgur.com/a/y8DDumr\\n\\nedit: fp16 kv cache which is what I use with everything","edited":1752104688,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29rpfq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Quick smoke test.  Q6_K (bullerwins gguf that I downloaded last week?) on a Blackwell Pro 6000, ~85-90 token/s, similar to Llama 4 Scout. ~66 GB used, context set to 16384. &lt;/p&gt;\\n\\n&lt;p&gt;/no_think works&lt;/p&gt;\\n\\n&lt;p&gt;Gettting endless repetition a lot, not sure what suggested sampling params are.  Tried playing with them a bit, no dice on fixing it.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://imgur.com/a/y8DDumr\\"&gt;https://imgur.com/a/y8DDumr&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;edit: fp16 kv cache which is what I use with everything&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29rpfq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104211,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2dxkfx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VoidAlchemy","can_mod_post":false,"created_utc":1752163973,"send_replies":true,"parent_id":"t1_n29uuvs","score":3,"author_fullname":"t2_n321yfw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For you ik_llama.cpp fans support is there and I'm getting over 1800 tok/sec PP and 24 tok/sec TG on my high end gaming rig (AMD 9950X + 2x48GB DDR5@6400MT/s and 3090TI FE GPU 24GB VRAM @ 450 Watts)\\n\\nhttps://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2dxkfx","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For you ik_llama.cpp fans support is there and I&amp;#39;m getting over 1800 tok/sec PP and 24 tok/sec TG on my high end gaming rig (AMD 9950X + 2x48GB DDR5@6400MT/s and 3090TI FE GPU 24GB VRAM @ 450 Watts)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF\\"&gt;https://huggingface.co/ubergarm/Hunyuan-A13B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2dxkfx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752163973,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29uuvs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1752105247,"send_replies":true,"parent_id":"t3_1lvvkh2","score":10,"author_fullname":"t2_1162lx9rgr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for posting. Here's a direct link to the GGUFs btw: https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29uuvs","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for posting. Here&amp;#39;s a direct link to the GGUFs btw: &lt;a href=\\"https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF\\"&gt;https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29uuvs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105247,"author_flair_text":"Llama 2","treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2eovs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zestyclose_Yak_3174","can_mod_post":false,"created_utc":1752171481,"send_replies":true,"parent_id":"t3_1lvvkh2","score":5,"author_fullname":"t2_o0jgdhlij","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've tested almost all LLM models over the last three years and I can say that unless there is something wrong with Llama.cpp and/or quantization, this model is very disappointing. Not smart, outputs weird/unrelated content and Chinese characters. I have low expectations for a \\"fix\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2eovs8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tested almost all LLM models over the last three years and I can say that unless there is something wrong with Llama.cpp and/or quantization, this model is very disappointing. Not smart, outputs weird/unrelated content and Chinese characters. I have low expectations for a &amp;quot;fix&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2eovs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752171481,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bsonm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1752134676,"send_replies":true,"parent_id":"t1_n2b23fk","score":2,"author_fullname":"t2_zws5yqyow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Damn that's disappointing was also looking for something to replace qwen3 30b that's also fast","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bsonm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn that&amp;#39;s disappointing was also looking for something to replace qwen3 30b that&amp;#39;s also fast&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2bsonm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752134676,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cpaah","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Cow1976","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2chuxp","score":4,"author_fullname":"t2_3pwbsmdr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Possibly very personal, I focus on stem and so 30b is very good in terms of quality and speed.  I just wish I could run qwen3 235b with acceptable speed. But obviously not possible. I was hoping hunyuan could be btw 30b and 235b.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cpaah","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Possibly very personal, I focus on stem and so 30b is very good in terms of quality and speed.  I just wish I could run qwen3 235b with acceptable speed. But obviously not possible. I was hoping hunyuan could be btw 30b and 235b.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cpaah/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150674,"author_flair_text":null,"treatment_tags":[],"created_utc":1752150674,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2chuxp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"created_utc":1752147814,"send_replies":true,"parent_id":"t1_n2b23fk","score":2,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Unfortunately, in my limited tests, not even better than qwen3 30b moe.\\n\\nOh dear. And that's a low bar.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2chuxp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Unfortunately, in my limited tests, not even better than qwen3 30b moe.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Oh dear. And that&amp;#39;s a low bar.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2chuxp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2db1q4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Cow1976","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2d0awx","score":2,"author_fullname":"t2_3pwbsmdr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tried no config but just the default llama cpp, and also the config recommended by unsloth. I ran q4_1 and q4 k xl by unsloth. To be fair, my  tests are mainly in stem. I had high hope for it to be a substitute for 235b because my vram is 64gb.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2db1q4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried no config but just the default llama cpp, and also the config recommended by unsloth. I ran q4_1 and q4 k xl by unsloth. To be fair, my  tests are mainly in stem. I had high hope for it to be a substitute for 235b because my vram is 64gb.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2db1q4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752157632,"author_flair_text":null,"treatment_tags":[],"created_utc":1752157632,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2d0awx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"created_utc":1752154407,"send_replies":true,"parent_id":"t1_n2b23fk","score":2,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Weird, in my testing, it is about the same quality as Qwen3 235B, what generation config do you use?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2d0awx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Weird, in my testing, it is about the same quality as Qwen3 235B, what generation config do you use?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2d0awx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154407,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2eqqdv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ardalok","can_mod_post":false,"created_utc":1752172002,"send_replies":true,"parent_id":"t1_n2b23fk","score":1,"author_fullname":"t2_vgnewja","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"have you tried this thing? \\nhttps://huggingface.co/DavidAU/Qwen3-30B-A6B-16-Extreme","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2eqqdv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;have you tried this thing? \\n&lt;a href=\\"https://huggingface.co/DavidAU/Qwen3-30B-A6B-16-Extreme\\"&gt;https://huggingface.co/DavidAU/Qwen3-30B-A6B-16-Extreme&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2eqqdv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752172002,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2b23fk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Cow1976","can_mod_post":false,"created_utc":1752121094,"send_replies":true,"parent_id":"t3_1lvvkh2","score":12,"author_fullname":"t2_3pwbsmdr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unfortunately, in my limited tests, not even better than qwen3 30b moe. A bit disappointed actually, thought it could replace qwen3 30b moe and become an all round daily model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b23fk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately, in my limited tests, not even better than qwen3 30b moe. A bit disappointed actually, thought it could replace qwen3 30b moe and become an all round daily model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2b23fk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752121094,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2chhtg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PurpleUpbeat2820","can_mod_post":false,"created_utc":1752147664,"send_replies":true,"parent_id":"t1_n29grm0","score":4,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; According to their benchmarks it has better score than Qwen-235B.\\n\\nI've found q4 qwen3:32b outperforms q3 qwen3:235b in practice.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2chhtg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;According to their benchmarks it has better score than Qwen-235B.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;ve found q4 qwen3:32b outperforms q3 qwen3:235b in practice.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2chhtg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147664,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29ii41","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"created_utc":1752101231,"send_replies":true,"parent_id":"t1_n29grm0","score":7,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"we are going to have to see.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29ii41","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;we are going to have to see.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29ii41/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101231,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2czgk6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752154132,"send_replies":true,"parent_id":"t1_n29grm0","score":2,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not sure if I am alone in this, but the model feels broken. Like, it is much worse than 30B A3B (both at Q4). And in my native language it breaks completely making up every second word.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2czgk6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure if I am alone in this, but the model feels broken. Like, it is much worse than 30B A3B (both at Q4). And in my native language it breaks completely making up every second word.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2czgk6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154132,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n29grm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1752100663,"send_replies":true,"parent_id":"t3_1lvvkh2","score":14,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"According to their benchmarks it has better score than Qwen-235B. If it's true then it's quite impressive as this LLM can run fast on a 96GB mac.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29grm0","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;According to their benchmarks it has better score than Qwen-235B. If it&amp;#39;s true then it&amp;#39;s quite impressive as this LLM can run fast on a 96GB mac.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29grm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752100663,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2b71r7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"madsheep","can_mod_post":false,"created_utc":1752123297,"send_replies":true,"parent_id":"t1_n29c3ut","score":5,"author_fullname":"t2_3hlhf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think that the best outcome so far of the multibillion dollar investment that all the companies are doing into AI, is the fact that they got us all talking about how fast our PP is.","edited":1752163510,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b71r7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think that the best outcome so far of the multibillion dollar investment that all the companies are doing into AI, is the fact that they got us all talking about how fast our PP is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2b71r7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752123297,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29zqed","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"molbal","can_mod_post":false,"created_utc":1752106919,"send_replies":true,"parent_id":"t1_n29c3ut","score":14,"author_fullname":"t2_g1srl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"PP speed hehe","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29zqed","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;PP speed hehe&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29zqed/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106919,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n29c3ut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"json12","can_mod_post":false,"created_utc":1752099175,"send_replies":true,"parent_id":"t3_1lvvkh2","score":10,"author_fullname":"t2_13ljzj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"MLX variant will probably give you faster PP speed on Mac.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29c3ut","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MLX variant will probably give you faster PP speed on Mac.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29c3ut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099175,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ark9b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1752116783,"send_replies":true,"parent_id":"t3_1lvvkh2","score":3,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope its actually better than other models in that parameter range and not like most releases that just benchmaxx and perform meh in real world applications. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ark9b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope its actually better than other models in that parameter range and not like most releases that just benchmaxx and perform meh in real world applications. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ark9b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116783,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2addz9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29lrpl","score":3,"author_fullname":"t2_a2uzegb8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And for what it's worth, I really appreciate those who do and talk about it! With the oddball models people tend to forget about them pretty quickly which can leave some quality stuff to fade away. I almost missed out on Ling Lite for example and I wound up really loving it even if qwen 3 30b kind of overshadowed it shortly after. \\n\\nI've been waiting for people to have a chance to really test this out and figure out the best approach before giving it a shot since it'd be pushing the limits of my hardware to a pretty extreme degree.","edited":false,"author_flair_css_class":null,"name":"t1_n2addz9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And for what it&amp;#39;s worth, I really appreciate those who do and talk about it! With the oddball models people tend to forget about them pretty quickly which can leave some quality stuff to fade away. I almost missed out on Ling Lite for example and I wound up really loving it even if qwen 3 30b kind of overshadowed it shortly after. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been waiting for people to have a chance to really test this out and figure out the best approach before giving it a shot since it&amp;#39;d be pushing the limits of my hardware to a pretty extreme degree.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2addz9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111663,"author_flair_text":null,"collapsed":false,"created_utc":1752111663,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aarcu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29lrpl","score":1,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm downloading it, but I'll bet it doesn't match qwen3-235b at all.","edited":false,"author_flair_css_class":null,"name":"t1_n2aarcu","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m downloading it, but I&amp;#39;ll bet it doesn&amp;#39;t match qwen3-235b at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2aarcu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752110742,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1752110742,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29lrpl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29ko3f","score":6,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree on that. I am going to do my own testing :-)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29lrpl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree on that. I am going to do my own testing :-)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29lrpl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102289,"author_flair_text":null,"treatment_tags":[],"created_utc":1752102289,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n29ko3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29j1bh","score":10,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"At this point I assume everyone just benchmaxxes and take them with a huge grain of salt.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29ko3f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At this point I assume everyone just benchmaxxes and take them with a huge grain of salt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29ko3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101930,"author_flair_text":null,"treatment_tags":[],"created_utc":1752101930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ciauh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29j1bh","score":1,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; As a ratio 13b/80b is better than Qwen3 22b/235b or Qwen3 3b/30b. As for intelligence the jury is still out on that. \\n\\nIs the jury still out? I think the number of active parameters clearly dominates the intelligence and, consequently, qwen 22/235b is almost acceptable but not good enough to be interesting and the others will only be much worse. In particular, qwen3:30b is terrible whereas qwen3:32b is great.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ciauh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;As a ratio 13b/80b is better than Qwen3 22b/235b or Qwen3 3b/30b. As for intelligence the jury is still out on that. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Is the jury still out? I think the number of active parameters clearly dominates the intelligence and, consequently, qwen 22/235b is almost acceptable but not good enough to be interesting and the others will only be much worse. In particular, qwen3:30b is terrible whereas qwen3:32b is great.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ciauh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147993,"author_flair_text":null,"treatment_tags":[],"created_utc":1752147993,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29j1bh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752101402,"send_replies":true,"parent_id":"t1_n29hwm6","score":13,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As a ratio 13b/80b is better than Qwen3 22b/235b or Qwen3 3b/30b. As for intelligence the jury is still out on that. The benchmarks sure look promising.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29j1bh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a ratio 13b/80b is better than Qwen3 22b/235b or Qwen3 3b/30b. As for intelligence the jury is still out on that. The benchmarks sure look promising.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29j1bh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101402,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n29hwm6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752101037,"send_replies":true,"parent_id":"t3_1lvvkh2","score":8,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"13b active... my hopes are pinned on ernie as a smaller deepseek. Enjoy your honeymoon :P","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29hwm6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;13b active... my hopes are pinned on ernie as a smaller deepseek. Enjoy your honeymoon :P&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29hwm6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101037,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2grd3y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MLDataScientist","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2b7v98","score":1,"author_fullname":"t2_3zy7pnf1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh nice! thanks! I did not know this existed. Why don't llama.cpp devs just add this functionality by default for moe models?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2grd3y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh nice! thanks! I did not know this existed. Why don&amp;#39;t llama.cpp devs just add this functionality by default for moe models?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2grd3y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752194303,"author_flair_text":null,"treatment_tags":[],"created_utc":1752194303,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2b7v98","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kevin_1994","can_mod_post":false,"created_utc":1752123675,"send_replies":true,"parent_id":"t1_n29mykx","score":4,"author_fullname":"t2_o015g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I just merged hunyuan support to https://github.com/k-koehler/gguf-tensor-overrider. Maybe it will help","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b7v98","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just merged hunyuan support to &lt;a href=\\"https://github.com/k-koehler/gguf-tensor-overrider\\"&gt;https://github.com/k-koehler/gguf-tensor-overrider&lt;/a&gt;. Maybe it will help&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2b7v98/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752123675,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2h8k1e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2g9w2c","score":1,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh neat, some new parameters I haven't seen. Do these all also work with llama server?\\n\\nI think I've downloaded it by now. I'll try and give it a go. Thanks for the commands. Helps get me up to speed quick.\\n\\nWait wait.. is CTV and ctk commands to change quant on the context? If so I read this model doesn't support it well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h8k1e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh neat, some new parameters I haven&amp;#39;t seen. Do these all also work with llama server?&lt;/p&gt;\\n\\n&lt;p&gt;I think I&amp;#39;ve downloaded it by now. I&amp;#39;ll try and give it a go. Thanks for the commands. Helps get me up to speed quick.&lt;/p&gt;\\n\\n&lt;p&gt;Wait wait.. is CTV and ctk commands to change quant on the context? If so I read this model doesn&amp;#39;t support it well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2h8k1e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752200302,"author_flair_text":null,"treatment_tags":[],"created_utc":1752200302,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2g9w2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"popecostea","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aolfd","score":1,"author_fullname":"t2_a8xhk1ib","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure. \\\\\`./llama-cli -c 32768 -m /bank/models/Hunyuan/Hunyuan-A13B-Instruct-UD-Q5\\\\_K\\\\_XL-00001-of-00002.gguf -fa -ctk q4\\\\_0 -ctv q4\\\\_0 -t 32 -ngl 99 --jinja --no-context-shift --no-op-offload --numa distribute -ot '.\\\\*(\\\\[0-9\\\\]\\\\[0-9\\\\]).ffn\\\\_.\\\\*\\\\_exps.=CPU'\\\\\`","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2g9w2c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure. \`./llama-cli -c 32768 -m /bank/models/Hunyuan/Hunyuan-A13B-Instruct-UD-Q5_K_XL-00001-of-00002.gguf -fa -ctk q4_0 -ctv q4_0 -t 32 -ngl 99 --jinja --no-context-shift --no-op-offload --numa distribute -ot &amp;#39;.*([0-9][0-9]).ffn_.*_exps.=CPU&amp;#39;\`&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2g9w2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752188378,"author_flair_text":null,"treatment_tags":[],"created_utc":1752188378,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aolfd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1752115647,"send_replies":true,"parent_id":"t1_n29mykx","score":2,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey can you share your full command? Assume your using llama server?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aolfd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey can you share your full command? Assume your using llama server?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2aolfd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115647,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n29mykx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"popecostea","can_mod_post":false,"created_utc":1752102679,"send_replies":true,"parent_id":"t3_1lvvkh2","score":2,"author_fullname":"t2_a8xhk1ib","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does anyone use the -ot parameter on llama.cop for the selective offload? I’ve found that if I offload all ffn tensors I get about 23GB VRAM usage which is higher than I expected for this model (q5 quant, 32k context). Does this match with any other findings?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29mykx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does anyone use the -ot parameter on llama.cop for the selective offload? I’ve found that if I offload all ffn tensors I get about 23GB VRAM usage which is higher than I expected for this model (q5 quant, 32k context). Does this match with any other findings?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29mykx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102679,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2e4lpn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752165969,"send_replies":true,"parent_id":"t3_1lvvkh2","score":2,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've been trying it at Q8. It starts off strong but somewhere along the line it goes off the rails. It starts with proper think/donethinking and answer/doneanswering tags. But at some point it just does a thinking tag and then a doneanswering tag. This problem has been described in the PR. The answer is still good but the process seems faulty.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2e4lpn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve been trying it at Q8. It starts off strong but somewhere along the line it goes off the rails. It starts with proper think/donethinking and answer/doneanswering tags. But at some point it just does a thinking tag and then a doneanswering tag. This problem has been described in the PR. The answer is still good but the process seems faulty.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2e4lpn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752165969,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2eoatd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FabioTR","can_mod_post":false,"created_utc":1752171316,"send_replies":true,"parent_id":"t3_1lvvkh2","score":2,"author_fullname":"t2_2w8bv1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just tested, the speed is quite good for the size (7 tps in my dual 3060-14600 rig).  \\nI tested some general culture questions but the answer are pretty bad unfortunately. Much worse than smaller models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2eoatd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just tested, the speed is quite good for the size (7 tps in my dual 3060-14600 rig).&lt;br/&gt;\\nI tested some general culture questions but the answer are pretty bad unfortunately. Much worse than smaller models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2eoatd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752171316,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ggy3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mitchins-au","can_mod_post":false,"created_utc":1752190693,"send_replies":true,"parent_id":"t3_1lvvkh2","score":2,"author_fullname":"t2_4hjtgq5u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Everything I’ve read about this model seems to indicate that it’s not performing well for its sized compared to Qwen3 models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ggy3f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everything I’ve read about this model seems to indicate that it’s not performing well for its sized compared to Qwen3 models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ggy3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752190693,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29g9ku","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29cish","score":7,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cool, it doesn't use YARN to extend the context like most other LLMs, that usually decrease the quality a bit.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29g9ku","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool, it doesn&amp;#39;t use YARN to extend the context like most other LLMs, that usually decrease the quality a bit.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29g9ku/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752100502,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1752100502,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n29cish","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752099305,"send_replies":true,"parent_id":"t1_n29b0zo","score":9,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you sure? The model card has the following text:\\n\\n# Model Context Length Support\\n\\nThe Hunyuan A13B model supports a maximum context length of **256K tokens (262,144 tokens)**. However, due to GPU memory constraints on most hardware setups, the default configuration in \`config.json\` limits the context length to **32K tokens** to prevent out-of-memory (OOM) errors.\\n\\n# Extending Context Length to 256K\\n\\nTo enable full 256K context support, you can manually modify the \`max_position_embeddings\` field in the model's \`config.json\` file as follows:\\n\\n    {\\n      ...\\n      \\"max_position_embeddings\\": 262144,\\n      ...\\n    }","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29cish","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you sure? The model card has the following text:&lt;/p&gt;\\n\\n&lt;h1&gt;Model Context Length Support&lt;/h1&gt;\\n\\n&lt;p&gt;The Hunyuan A13B model supports a maximum context length of &lt;strong&gt;256K tokens (262,144 tokens)&lt;/strong&gt;. However, due to GPU memory constraints on most hardware setups, the default configuration in &lt;code&gt;config.json&lt;/code&gt; limits the context length to &lt;strong&gt;32K tokens&lt;/strong&gt; to prevent out-of-memory (OOM) errors.&lt;/p&gt;\\n\\n&lt;h1&gt;Extending Context Length to 256K&lt;/h1&gt;\\n\\n&lt;p&gt;To enable full 256K context support, you can manually modify the &lt;code&gt;max_position_embeddings&lt;/code&gt; field in the model&amp;#39;s &lt;code&gt;config.json&lt;/code&gt; file as follows:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;{\\n  ...\\n  &amp;quot;max_position_embeddings&amp;quot;: 262144,\\n  ...\\n}\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29cish/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099305,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2dsiwu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LocoMod","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ddk3b","score":1,"author_fullname":"t2_6uuoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Got it. That makes perfect sense now.","edited":false,"author_flair_css_class":null,"name":"t1_n2dsiwu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Got it. That makes perfect sense now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2dsiwu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752162557,"author_flair_text":null,"collapsed":false,"created_utc":1752162557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ddk3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2dbia7","score":2,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You're missing the point, this is purely a smoke test to make sure the full context works.\\n\\nWhether or not it is properly identifying text in context and using it is a different question and best left to proper benchmarks suites.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ddk3b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re missing the point, this is purely a smoke test to make sure the full context works.&lt;/p&gt;\\n\\n&lt;p&gt;Whether or not it is properly identifying text in context and using it is a different question and best left to proper benchmarks suites.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ddk3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752158358,"author_flair_text":null,"treatment_tags":[],"created_utc":1752158358,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2dbia7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LocoMod","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a0yxk","score":3,"author_fullname":"t2_6uuoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is not a good test because the Bible is one of the most popular books in history and it is already likely in its training data. Have you tried without passing in the text and just asking directly?\\n\\nIn my testing, it degrades significantly with large context on tasks that are unknown to it and verifiable. For example, if I configure a bunch of MCP servers with tool schemas which balloons the prompt, it fails to follow instructions for something as simple as \\"return the files in X path\\".\\n\\nBut if I ONLY configure a filesystem MCP server, it succeeds. The prompt is significantly smaller.\\n\\nTry long context on something niche. Like some obscure book no one knows about, and run your test on that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2dbia7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is not a good test because the Bible is one of the most popular books in history and it is already likely in its training data. Have you tried without passing in the text and just asking directly?&lt;/p&gt;\\n\\n&lt;p&gt;In my testing, it degrades significantly with large context on tasks that are unknown to it and verifiable. For example, if I configure a bunch of MCP servers with tool schemas which balloons the prompt, it fails to follow instructions for something as simple as &amp;quot;return the files in X path&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;But if I ONLY configure a filesystem MCP server, it succeeds. The prompt is significantly smaller.&lt;/p&gt;\\n\\n&lt;p&gt;Try long context on something niche. Like some obscure book no one knows about, and run your test on that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2dbia7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752157766,"author_flair_text":null,"treatment_tags":[],"created_utc":1752157766,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a0yxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1752107351,"send_replies":true,"parent_id":"t1_n29b0zo","score":3,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"unsloth ggufs in lm studio show 262144 out of the box.  I tested, filling it up to 99.9% and it works, and I got at least reasonable output.  It recognized I pasted in a giant portion of the work (highlighted in thinking block)\\n\\nhttps://imgur.com/YRHsHMH","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a0yxk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;unsloth ggufs in lm studio show 262144 out of the box.  I tested, filling it up to 99.9% and it works, and I got at least reasonable output.  It recognized I pasted in a giant portion of the work (highlighted in thinking block)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://imgur.com/YRHsHMH\\"&gt;https://imgur.com/YRHsHMH&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2a0yxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107351,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29b0zo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmilPi","can_mod_post":false,"created_utc":1752098839,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_jti45lwl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[https://huggingface.co/tencent/Hunyuan-A13B-Instruct/blob/main/config.json](https://huggingface.co/tencent/Hunyuan-A13B-Instruct/blob/main/config.json)\\n\\nit says \\\\\`\\"max\\\\_position\\\\_embeddings\\": 32768,\\\\\`, so extended context will come at reduced performance cost.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29b0zo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/tencent/Hunyuan-A13B-Instruct/blob/main/config.json\\"&gt;https://huggingface.co/tencent/Hunyuan-A13B-Instruct/blob/main/config.json&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;it says \`&amp;quot;max_position_embeddings&amp;quot;: 32768,\`, so extended context will come at reduced performance cost.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29b0zo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752098839,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29joxg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dundell","can_mod_post":false,"created_utc":1752101614,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_3gl53gi6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just upgraded to a 5th 3060 12gb for 60GBs vram to test this with... Find out later this week :/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29joxg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just upgraded to a 5th 3060 12gb for 60GBs vram to test this with... Find out later this week :/&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29joxg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101614,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2acgyf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HilLiedTroopsDied","can_mod_post":false,"created_utc":1752111341,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_1snfn3ui","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wish llamacpp would give a command arg for --no-think","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2acgyf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wish llamacpp would give a command arg for --no-think&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2acgyf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111341,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2e7fpg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lostnuclues","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cgrvh","score":1,"author_fullname":"t2_7spksnox","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was using HuggingFace chat online.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2e7fpg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was using HuggingFace chat online.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2e7fpg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752166758,"author_flair_text":null,"treatment_tags":[],"created_utc":1752166758,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cgrvh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752147362,"send_replies":true,"parent_id":"t1_n2c83sw","score":1,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What quantization are you using? My experience is that the models do that when the brain damage is too much from a bad quant.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cgrvh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What quantization are you using? My experience is that the models do that when the brain damage is too much from a bad quant.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cgrvh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147362,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2e4r1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752166011,"send_replies":true,"parent_id":"t1_n2c83sw","score":1,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah... that's Korean dude.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2e4r1m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah... that&amp;#39;s Korean dude.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2e4r1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752166011,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ckllq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Iq1pl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cj1e7","score":3,"author_fullname":"t2_rxgre5u8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I meant to write korean, didn't notice i wrote indian","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ckllq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I meant to write korean, didn&amp;#39;t notice i wrote indian&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ckllq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752148905,"author_flair_text":null,"treatment_tags":[],"created_utc":1752148905,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cj1e7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lostnuclues","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2chloe","score":4,"author_fullname":"t2_7spksnox","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its definitely not Indian, maybe Korean.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cj1e7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its definitely not Indian, maybe Korean.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cj1e7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752148285,"author_flair_text":null,"treatment_tags":[],"created_utc":1752148285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2chloe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Iq1pl","can_mod_post":false,"created_utc":1752147708,"send_replies":true,"parent_id":"t1_n2c83sw","score":0,"author_fullname":"t2_rxgre5u8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's indian not Chinese","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2chloe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s indian not Chinese&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2chloe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147708,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2c83sw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lostnuclues","can_mod_post":false,"created_utc":1752143373,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_7spksnox","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It sometimes include Chinese in between its English response \\" 경량화하면서 효율적으로 모델을 커스터마이징할 수 있습니다.\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2c83sw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It sometimes include Chinese in between its English response &amp;quot; 경량화하면서 효율적으로 모델을 커스터마이징할 수 있습니다.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c83sw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752143373,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hsm1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752208282,"send_replies":true,"parent_id":"t1_n2fodg6","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Why I think?? I own a business in the EU, so I know exactly what the rules are.\\n\\nAnd if you knew anything about GDPR, then you would know that doing business in EU or not doesn't matter. You could own a business in the US and still be bound to it. Since it's effectively global. Since if you knew anything about GDPR then you would know it's not based on a geographic location. It's based on whether any EU citizen is using your site. Whether that EU citizen is in the EU or on the moon. That's what you would know if you knew anything about GDPR. You wouldn't make a big show of owning a business in the EU. Since that's besides the point.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hsm1t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Why I think?? I own a business in the EU, so I know exactly what the rules are.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;And if you knew anything about GDPR, then you would know that doing business in EU or not doesn&amp;#39;t matter. You could own a business in the US and still be bound to it. Since it&amp;#39;s effectively global. Since if you knew anything about GDPR then you would know it&amp;#39;s not based on a geographic location. It&amp;#39;s based on whether any EU citizen is using your site. Whether that EU citizen is in the EU or on the moon. That&amp;#39;s what you would know if you knew anything about GDPR. You wouldn&amp;#39;t make a big show of owning a business in the EU. Since that&amp;#39;s besides the point.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2hsm1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752208282,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2fodg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752181658,"send_replies":true,"parent_id":"t1_n2fjapg","score":1,"author_fullname":"t2_bvqb8ng0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why I think?? I own a business in the EU, so I _know_ exactly what the rules are. We are GDPR compliant and have no problem with it. American big tech are not compliant because the law was more or less made to stop them from doing as they please with our data and so they are not happy.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2fodg6","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why I think?? I own a business in the EU, so I &lt;em&gt;know&lt;/em&gt; exactly what the rules are. We are GDPR compliant and have no problem with it. American big tech are not compliant because the law was more or less made to stop them from doing as they please with our data and so they are not happy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2fodg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752181658,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2fjapg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752180211,"send_replies":true,"parent_id":"t1_n2famxm","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Again.\\n\\nhttps://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en\\n\\nAnd also.\\n\\nhttps://www.dw.com/en/top-eu-court-rules-against-meta-over-facebook-targeting-ads/a-70406926\\n\\nThat just a sample, there are others.\\n\\nWhy do you think pretty much every single website has a popup asking for your permission to use your data?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2fjapg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Again.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en\\"&gt;https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;And also.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.dw.com/en/top-eu-court-rules-against-meta-over-facebook-targeting-ads/a-70406926\\"&gt;https://www.dw.com/en/top-eu-court-rules-against-meta-over-facebook-targeting-ads/a-70406926&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;That just a sample, there are others.&lt;/p&gt;\\n\\n&lt;p&gt;Why do you think pretty much every single website has a popup asking for your permission to use your data?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2fjapg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752180211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2famxm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2etupn","score":1,"author_fullname":"t2_bvqb8ng0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In relation to Facebook, the only problem is that the GDPR is not being enforced enough against big tech. They are shitting all over the laws and our private data and getting away with it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2famxm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In relation to Facebook, the only problem is that the GDPR is not being enforced enough against big tech. They are shitting all over the laws and our private data and getting away with it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2famxm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752177734,"author_flair_text":null,"treatment_tags":[],"created_utc":1752177734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2etupn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ejskb","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; GDPR is also not a problem. \\n\\nLOL. I guess you don't consider 1.2B to be a problem. Man, it must be nice to have such a fat wallet that a billion is just lost spare change.\\n\\nhttps://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2etupn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;GDPR is also not a problem. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;LOL. I guess you don&amp;#39;t consider 1.2B to be a problem. Man, it must be nice to have such a fat wallet that a billion is just lost spare change.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en\\"&gt;https://www.edpb.europa.eu/news/news/2023/12-billion-euro-fine-facebook-result-edpb-binding-decision_en&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2etupn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752172894,"author_flair_text":null,"treatment_tags":[],"created_utc":1752172894,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2fa4zl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2f2plh","score":1,"author_fullname":"t2_bvqb8ng0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No I am expecting that we will not have a problem being compliant to the law. Which part of the AI act is going to limit local use? For example to use the model as a coding assistant?\\n\\nIf you are going to use the model for problematic use, such as to treat peoples private data and make decisions on them, then I absolutely expect that you will get in trouble. But that will be true no matter what model you use.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2fa4zl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No I am expecting that we will not have a problem being compliant to the law. Which part of the AI act is going to limit local use? For example to use the model as a coding assistant?&lt;/p&gt;\\n\\n&lt;p&gt;If you are going to use the model for problematic use, such as to treat peoples private data and make decisions on them, then I absolutely expect that you will get in trouble. But that will be true no matter what model you use.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2fa4zl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752177586,"author_flair_text":null,"treatment_tags":[],"created_utc":1752177586,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2f2plh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jamais_Vu206","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ejskb","score":1,"author_fullname":"t2_w6pcflikg","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Private use is excepted. Otherwise, you are just expecting that laws will not be enforced.\\n\\nLaws that are enforced based on the unpredictable whims of distant bureaucrats are a recipe for corruption, at best. You can't run a country like that.\\n\\nThe GDPR is enforced against small businesses, once in a while. I remember a case where data protectors raided a pizzeria and fined the owner because they hadn't disposed of the receipts (with customer names) properly.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2f2plh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Private use is excepted. Otherwise, you are just expecting that laws will not be enforced.&lt;/p&gt;\\n\\n&lt;p&gt;Laws that are enforced based on the unpredictable whims of distant bureaucrats are a recipe for corruption, at best. You can&amp;#39;t run a country like that.&lt;/p&gt;\\n\\n&lt;p&gt;The GDPR is enforced against small businesses, once in a while. I remember a case where data protectors raided a pizzeria and fined the owner because they hadn&amp;#39;t disposed of the receipts (with customer names) properly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2f2plh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752175426,"author_flair_text":null,"treatment_tags":[],"created_utc":1752175426,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ejskb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2e503u","score":1,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"GDPR is also not a problem. Neither will the AI act be. Nothing stops me from using local models. I can also use local models in my business. If I however make a chatbot on a website it will be completely different. But then that is by definition not local LLM anymore.","edited":false,"author_flair_css_class":null,"name":"t1_n2ejskb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GDPR is also not a problem. Neither will the AI act be. Nothing stops me from using local models. I can also use local models in my business. If I however make a chatbot on a website it will be completely different. But then that is by definition not local LLM anymore.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ejskb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752170074,"author_flair_text":null,"collapsed":false,"created_utc":1752170074,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2e503u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cjj5q","score":1,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Exactly. People also blew off GDPR. Until they started enforcing it. People don't blow it off anymore.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2e503u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly. People also blew off GDPR. Until they started enforcing it. People don&amp;#39;t blow it off anymore.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2e503u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752166083,"author_flair_text":null,"treatment_tags":[],"created_utc":1752166083,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cjj5q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jamais_Vu206","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2chvmf","score":0,"author_fullname":"t2_w6pcflikg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;What EU cares about is the online service. Not the open weight local models.\\n\\nRemains to be seen. The relevant AI Act rules only start to apply next month. When these will be actually enforced is another matter. Most open models will be off the table. Professional use will be under the threat of heavy fines (private use excepted).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cjj5q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;What EU cares about is the online service. Not the open weight local models.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Remains to be seen. The relevant AI Act rules only start to apply next month. When these will be actually enforced is another matter. Most open models will be off the table. Professional use will be under the threat of heavy fines (private use excepted).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cjj5q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752148481,"author_flair_text":null,"treatment_tags":[],"created_utc":1752148481,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2chvmf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752147822,"send_replies":true,"parent_id":"t1_n2cg9ye","score":5,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am in the EU and couldn't care less. They don't actually mean that. The purpose of that text is to say we can't be sued in the EU because we said you couldn't use it there. There is probably a sense in China that the EU has strict rules about AI and they don't want to deal with that.\\n\\nThe license won't actually shield them from that. What EU cares about is the online service. Not the open weight local models.\\n\\nThis is only a problem if you are working for a larger company ruled by lawyers. They might tell you, you can't use it. For everyone else it's a meh, who cares.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2chvmf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am in the EU and couldn&amp;#39;t care less. They don&amp;#39;t actually mean that. The purpose of that text is to say we can&amp;#39;t be sued in the EU because we said you couldn&amp;#39;t use it there. There is probably a sense in China that the EU has strict rules about AI and they don&amp;#39;t want to deal with that.&lt;/p&gt;\\n\\n&lt;p&gt;The license won&amp;#39;t actually shield them from that. What EU cares about is the online service. Not the open weight local models.&lt;/p&gt;\\n\\n&lt;p&gt;This is only a problem if you are working for a larger company ruled by lawyers. They might tell you, you can&amp;#39;t use it. For everyone else it&amp;#39;s a meh, who cares.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2chvmf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147822,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cg9ye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jamais_Vu206","can_mod_post":false,"created_utc":1752147149,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_w6pcflikg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Don't want to open a new thread on this, but what do people think about the license?\\n\\nIn particular: *THIS LICENSE AGREEMENT DOES NOT APPLY IN THE EUROPEAN UNION, UNITED KINGDOM AND SOUTH KOREA AND IS EXPRESSLY LIMITED TO THE TERRITORY, AS DEFINED BELOW.*\\n\\nWhat LM Studio is going to do about regulations is also a question.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cg9ye","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t want to open a new thread on this, but what do people think about the license?&lt;/p&gt;\\n\\n&lt;p&gt;In particular: &lt;em&gt;THIS LICENSE AGREEMENT DOES NOT APPLY IN THE EUROPEAN UNION, UNITED KINGDOM AND SOUTH KOREA AND IS EXPRESSLY LIMITED TO THE TERRITORY, AS DEFINED BELOW.&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;What LM Studio is going to do about regulations is also a question.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2cg9ye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147149,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2crwna","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Resident_Wallaby8463","can_mod_post":false,"created_utc":1752151615,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_dcs91mk2p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anyone knows why the model wouldn't load or what I am missing on my side? \\n\\nI am using LM Studio 3.18 beta with 32GB VRAM, 128 RAM on windows.\\nModel: Unsloth's Q6_K_XL","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2crwna","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone knows why the model wouldn&amp;#39;t load or what I am missing on my side? &lt;/p&gt;\\n\\n&lt;p&gt;I am using LM Studio 3.18 beta with 32GB VRAM, 128 RAM on windows.\\nModel: Unsloth&amp;#39;s Q6_K_XL&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2crwna/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151615,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2dxtuz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cbutters2000","can_mod_post":false,"created_utc":1752164046,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_fh9e4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm using this model inside sillytavern, so far with 32768 context and 1024 response length. (Temperature 1.0, Top P 1.0) Using \\\\[Mistral-V7-Tekken-T8-XML System Prompt\\\\]  \\n*Allowing thinking  using &lt;think&gt; and &lt;/think&gt;\\n\\n*The Following Context Template:\\n\\n&gt;&lt;|im\\\\_start|&gt;system\\n&gt;\\n&gt;{{#if system}}{{system}}\\n&gt;\\n&gt;{{/if}}{{#if wiBefore}}{{wiBefore}}\\n&gt;\\n&gt;{{/if}}{{#if description}}{{description}}\\n&gt;\\n&gt;{{/if}}{{#if personality}}{{char}}'s personality: {{personality}}\\n&gt;\\n&gt;{{/if}}{{#if scenario}}Scenario: {{scenario}}\\n&gt;\\n&gt;{{/if}}{{#if wiAfter}}{{wiAfter}}\\n&gt;\\n&gt;{{/if}}{{#if persona}}{{persona}}\\n&gt;\\n&gt;{{/if}}{{trim}}\\n\\nI have no idea if these are ideal settings, but it is what is working best so far for me.\\n\\nAllowing it to think really helps this model so far (at least if you are using it in the context of having it stick to a specific type of response / character.)\\n\\nGetting \\\\~35 Tokens / sec on an M1 Mac Studio. (Q4_K_S) using lmstudio. (Enable beta channels for both LM studio and llama.cpp)\\n\\nPros so far: I've found it much better than qwen3-235b-a22b at asking it to generate data inside a chart using ASCII characters so far. (edge case) When I've let it think first, I've found it does this fairly concisely rather than running on and on and on forever. (usually just thinks for 6-12 seconds before responding) And then the responses are usually quite good while also staying in \\"character\\".\\n\\nCons so far: I've had it just respond with null responses sometimes. Not sure why, but this was while I was playing with various settings, so still dialing things in.\\nAlso, just to note; while I've mentioned it is good at providing responses in \\"character\\" I don't mean that this model isn't great for \\"roleplaying\\" in story form, as it wants to insert chinese characters and adjust formatting quite often. It seems to excel in acting as a coding or informational assistant. (If that makes sense.)\\n\\nStill need to do more testing, but so far I think this model size with some refinements would be really quite nice. (faster than qwen3-235B-a22b, and so far, seems just as competent / more competent at some tasks.)\\n\\nEdit: Tried financial advice questions, and Qwen3-235B is way more competent at this task than hunyuan.\\n\\nEdit 2: Now after playing with this for a few more hours; While this model occasionally surprises with competency, it very often also spectacularly fails. (Agreeing with u/DragonfruitIll660 's comments) If you regenerate enough it sometimes does very well, but it is definitely difficult to wrangle.","edited":1752180292,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2dxtuz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m using this model inside sillytavern, so far with 32768 context and 1024 response length. (Temperature 1.0, Top P 1.0) Using [Mistral-V7-Tekken-T8-XML System Prompt]&lt;br/&gt;\\n*Allowing thinking  using &amp;lt;think&amp;gt; and &amp;lt;/think&amp;gt;&lt;/p&gt;\\n\\n&lt;p&gt;*The Following Context Template:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;&amp;lt;|im_start|&amp;gt;system&lt;/p&gt;\\n\\n&lt;p&gt;{{#if system}}{{system}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if wiBefore}}{{wiBefore}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if description}}{{description}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if personality}}{{char}}&amp;#39;s personality: {{personality}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if scenario}}Scenario: {{scenario}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if wiAfter}}{{wiAfter}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{#if persona}}{{persona}}&lt;/p&gt;\\n\\n&lt;p&gt;{{/if}}{{trim}}&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I have no idea if these are ideal settings, but it is what is working best so far for me.&lt;/p&gt;\\n\\n&lt;p&gt;Allowing it to think really helps this model so far (at least if you are using it in the context of having it stick to a specific type of response / character.)&lt;/p&gt;\\n\\n&lt;p&gt;Getting ~35 Tokens / sec on an M1 Mac Studio. (Q4_K_S) using lmstudio. (Enable beta channels for both LM studio and llama.cpp)&lt;/p&gt;\\n\\n&lt;p&gt;Pros so far: I&amp;#39;ve found it much better than qwen3-235b-a22b at asking it to generate data inside a chart using ASCII characters so far. (edge case) When I&amp;#39;ve let it think first, I&amp;#39;ve found it does this fairly concisely rather than running on and on and on forever. (usually just thinks for 6-12 seconds before responding) And then the responses are usually quite good while also staying in &amp;quot;character&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;Cons so far: I&amp;#39;ve had it just respond with null responses sometimes. Not sure why, but this was while I was playing with various settings, so still dialing things in.\\nAlso, just to note; while I&amp;#39;ve mentioned it is good at providing responses in &amp;quot;character&amp;quot; I don&amp;#39;t mean that this model isn&amp;#39;t great for &amp;quot;roleplaying&amp;quot; in story form, as it wants to insert chinese characters and adjust formatting quite often. It seems to excel in acting as a coding or informational assistant. (If that makes sense.)&lt;/p&gt;\\n\\n&lt;p&gt;Still need to do more testing, but so far I think this model size with some refinements would be really quite nice. (faster than qwen3-235B-a22b, and so far, seems just as competent / more competent at some tasks.)&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Tried financial advice questions, and Qwen3-235B is way more competent at this task than hunyuan.&lt;/p&gt;\\n\\n&lt;p&gt;Edit 2: Now after playing with this for a few more hours; While this model occasionally surprises with competency, it very often also spectacularly fails. (Agreeing with &lt;a href=\\"/u/DragonfruitIll660\\"&gt;u/DragonfruitIll660&lt;/a&gt; &amp;#39;s comments) If you regenerate enough it sometimes does very well, but it is definitely difficult to wrangle.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2dxtuz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752164046,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2f2rux","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DragonfruitIll660","can_mod_post":false,"created_utc":1752175444,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_duscbn82","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Initial impression at Q4KM are not great, I'd guess its roughly or perhaps below an Q8 8B which is quite odd. Unable to maintain format or output reasonable text (though oddly enough sometimes the thinking is coherent then the message is somewhat random/unrelated). Using settings recommended by cbutters2000 on this thread, gonna attempt a higher quant and see if it just got hit hard.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2f2rux","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Initial impression at Q4KM are not great, I&amp;#39;d guess its roughly or perhaps below an Q8 8B which is quite odd. Unable to maintain format or output reasonable text (though oddly enough sometimes the thinking is coherent then the message is somewhat random/unrelated). Using settings recommended by cbutters2000 on this thread, gonna attempt a higher quant and see if it just got hit hard.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2f2rux/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752175444,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ibwys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zugzwang_CYOA","can_mod_post":false,"created_utc":1752217923,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_mzaab62c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I must have the wrong settings in Sillytavern, because I'm getting unusably stupid answers with the UD-IQ4\\\\_K\\\\_L quant. If anybody here uses ST, could you share your instruct and context templates?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ibwys","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I must have the wrong settings in Sillytavern, because I&amp;#39;m getting unusably stupid answers with the UD-IQ4_K_L quant. If anybody here uses ST, could you share your instruct and context templates?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ibwys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752217923,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aqb1s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__JockY__","can_mod_post":false,"created_utc":1752116298,"send_replies":true,"parent_id":"t3_1lvvkh2","score":1,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow, 80B A13 parameters and scores similarly to Qwen3 235B A22 in all but coding. Not only that, they've provided FP8 and INT4 w4a16 quants for us! Baller move. As a vLLM user I'm very happy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aqb1s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, 80B A13 parameters and scores similarly to Qwen3 235B A22 in all but coding. Not only that, they&amp;#39;ve provided FP8 and INT4 w4a16 quants for us! Baller move. As a vLLM user I&amp;#39;m very happy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2aqb1s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116298,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c3hsf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2c2g3p","score":1,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/c330rvbjq0cf1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=5f0f16de47d35cd3a7f3ee26b37ae098a01866cc","edited":false,"author_flair_css_class":null,"name":"t1_n2c3hsf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/c330rvbjq0cf1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f0f16de47d35cd3a7f3ee26b37ae098a01866cc\\"&gt;https://preview.redd.it/c330rvbjq0cf1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f0f16de47d35cd3a7f3ee26b37ae098a01866cc&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c3hsf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752140934,"media_metadata":{"c330rvbjq0cf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":8,"x":108,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cf2afa694c1781547b30377c40fe7dec1f7d55a"},{"y":17,"x":216,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=971758764bb3a74fac44bbe464c73031a8470962"},{"y":25,"x":320,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce1d62c47573a1b67ed2b7e9a3cfa250f15851c7"},{"y":50,"x":640,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31452cce28e6796459355340dc2e707d1146abbd"},{"y":75,"x":960,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f8e8737e498d51a71b06b7ed9b098bdc5f722e36"},{"y":85,"x":1080,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=107a623f33a1ea5812811faaaca464226b0aa74b"}],"s":{"y":88,"x":1113,"u":"https://preview.redd.it/c330rvbjq0cf1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=5f0f16de47d35cd3a7f3ee26b37ae098a01866cc"},"id":"c330rvbjq0cf1"}},"author_flair_text":null,"collapsed":false,"created_utc":1752140934,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c3igu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2c2g3p","score":1,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/q07510mlq0cf1.png?width=1022&amp;format=png&amp;auto=webp&amp;s=0b1d2961dbc984f076bd7a84eff49ba367cdefda","edited":false,"author_flair_css_class":null,"name":"t1_n2c3igu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/q07510mlq0cf1.png?width=1022&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b1d2961dbc984f076bd7a84eff49ba367cdefda\\"&gt;https://preview.redd.it/q07510mlq0cf1.png?width=1022&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b1d2961dbc984f076bd7a84eff49ba367cdefda&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c3igu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752140944,"media_metadata":{"q07510mlq0cf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":41,"x":108,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4495c877f0280c3164d8efb7e768b62b0d205f04"},{"y":83,"x":216,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e26991ecbec17d06801b4ea22a9b724b63a5af81"},{"y":123,"x":320,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc44c38b783a9e7c85679403225f2521d92fd0d3"},{"y":247,"x":640,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3982a9acc681e29d86f43efca1bc8114ac4728ec"},{"y":371,"x":960,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2676fe9f708c322f6823dd4989334aecf8e79edb"}],"s":{"y":395,"x":1022,"u":"https://preview.redd.it/q07510mlq0cf1.png?width=1022&amp;format=png&amp;auto=webp&amp;s=0b1d2961dbc984f076bd7a84eff49ba367cdefda"},"id":"q07510mlq0cf1"}},"author_flair_text":null,"collapsed":false,"created_utc":1752140944,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c3k7i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2c2g3p","score":1,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=999&amp;format=png&amp;auto=webp&amp;s=900feeeed2be01ed9706f5e927c23dbb395ea19f","edited":false,"author_flair_css_class":null,"name":"t1_n2c3k7i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/6ud2aaeoq0cf1.png?width=999&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=900feeeed2be01ed9706f5e927c23dbb395ea19f\\"&gt;https://preview.redd.it/6ud2aaeoq0cf1.png?width=999&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=900feeeed2be01ed9706f5e927c23dbb395ea19f&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c3k7i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752140970,"media_metadata":{"6ud2aaeoq0cf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":128,"x":108,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=845e1a7c0b748d755720cf0260fd42b34b86fd33"},{"y":257,"x":216,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2652105a4cb8438d099d5c9e7e0adcfa8ecb0e90"},{"y":381,"x":320,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=21dc48632d4c3433130125229dceac74dcf66e6c"},{"y":762,"x":640,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c431e79e2c423533a6f2d107a46337338767795"},{"y":1143,"x":960,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9cbf987cb25e5d6ffbeb1c698b1ce28a80d29ea1"}],"s":{"y":1190,"x":999,"u":"https://preview.redd.it/6ud2aaeoq0cf1.png?width=999&amp;format=png&amp;auto=webp&amp;s=900feeeed2be01ed9706f5e927c23dbb395ea19f"},"id":"6ud2aaeoq0cf1"}},"author_flair_text":null,"collapsed":false,"created_utc":1752140970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2c2g3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdventurousSwim1312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aiajz","score":1,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sure, here you go (think to upgrade vllm to latest version first):\\n\\nexport MODEL\\\\_NAME=\\"Hunyuan-A13B-Instruct-GPTQ-Int4\\"\\n\\nvllm serve \\"$MODEL\\\\_NAME\\" \\\\\\\\\\n\\n\\\\--served-model-name gpt-4 \\\\\\\\\\n\\n\\\\--port 5000 \\\\\\\\\\n\\n\\\\--dtype bfloat16  \\\\\\\\\\n\\n\\\\--max-model-len 8196 \\\\\\\\\\n\\n\\\\--tensor-parallel-size 2 \\\\\\\\\\n\\n\\\\--pipeline-parallel-size 1 \\\\\\\\\\n\\n\\\\--gpu-memory-utilization 0.97 \\\\\\\\\\n\\n\\\\--enable-chunked-prefill \\\\\\\\\\n\\n\\\\--use-v2-block-manager \\\\\\\\\\n\\n\\\\--trust\\\\_remote\\\\_code \\\\\\\\\\n\\n\\\\--quantization gptq\\\\_marlin \\\\\\\\\\n\\n\\\\--max-seq-len-to-capture 2048 \\\\\\\\\\n\\n\\\\--kv-cache-dtype fp8\\\\_e5m2\\n\\nI run it with low context (8196) cause it triggers OOM errors if not, but you should be able to extend to 32k running in eager mode (capturing cuda graphs is intensive). Also, gptq is around 4.65 bpw, i will retry once proper exllama v3 implementation exist in 4.0bpw for extended contexte.\\n\\nComplete config for reference:  \\n\\\\- OS : Ubuntu 22.04\\n\\n\\\\- CPU : Ryzen 9 3950X (16 cores / 32 threads - 24 Channels)\\n\\n\\\\- RAM : 128go DDR4 3600ghz\\n\\n\\\\- GPU1 : Rtx 3090 turbo edition de gigabyte, blower style (loud but helps with thermal management)\\n\\n\\\\- GPU2 : Rtx 3090 founder edition\\n\\nNote, i experienced some issues at first because current release of flash attention is not recognized by vllm, if it happens, downgrade flash attention to 2.7.x","edited":1752140903,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2c2g3p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, here you go (think to upgrade vllm to latest version first):&lt;/p&gt;\\n\\n&lt;p&gt;export MODEL_NAME=&amp;quot;Hunyuan-A13B-Instruct-GPTQ-Int4&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;vllm serve &amp;quot;$MODEL_NAME&amp;quot; \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--served-model-name gpt-4 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--port 5000 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--dtype bfloat16  \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--max-model-len 8196 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--tensor-parallel-size 2 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--pipeline-parallel-size 1 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--gpu-memory-utilization 0.97 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--enable-chunked-prefill \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--use-v2-block-manager \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--trust_remote_code \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--quantization gptq_marlin \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--max-seq-len-to-capture 2048 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--kv-cache-dtype fp8_e5m2&lt;/p&gt;\\n\\n&lt;p&gt;I run it with low context (8196) cause it triggers OOM errors if not, but you should be able to extend to 32k running in eager mode (capturing cuda graphs is intensive). Also, gptq is around 4.65 bpw, i will retry once proper exllama v3 implementation exist in 4.0bpw for extended contexte.&lt;/p&gt;\\n\\n&lt;p&gt;Complete config for reference:&lt;br/&gt;\\n- OS : Ubuntu 22.04&lt;/p&gt;\\n\\n&lt;p&gt;- CPU : Ryzen 9 3950X (16 cores / 32 threads - 24 Channels)&lt;/p&gt;\\n\\n&lt;p&gt;- RAM : 128go DDR4 3600ghz&lt;/p&gt;\\n\\n&lt;p&gt;- GPU1 : Rtx 3090 turbo edition de gigabyte, blower style (loud but helps with thermal management)&lt;/p&gt;\\n\\n&lt;p&gt;- GPU2 : Rtx 3090 founder edition&lt;/p&gt;\\n\\n&lt;p&gt;Note, i experienced some issues at first because current release of flash attention is not recognized by vllm, if it happens, downgrade flash attention to 2.7.x&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c2g3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752140357,"author_flair_text":null,"treatment_tags":[],"created_utc":1752140357,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aiajz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bladstal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29ehtr","score":1,"author_fullname":"t2_2y71022v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you please show a line to start it with vllm?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2aiajz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you please show a line to start it with vllm?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2aiajz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752113381,"author_flair_text":null,"treatment_tags":[],"created_utc":1752113381,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29ehtr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AdventurousSwim1312","can_mod_post":false,"created_utc":1752099931,"send_replies":true,"parent_id":"t1_n29dnfa","score":4,"author_fullname":"t2_nqj4dsg7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does, I'm using it on 2*3090 with up to 16k contexte (maybe 32k with a few optimisation).\\n\\nSpeed is around 75t/s in inference\\n\\nEngine: vllm\\nQuant: official gptq","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29ehtr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does, I&amp;#39;m using it on 2*3090 with up to 16k contexte (maybe 32k with a few optimisation).&lt;/p&gt;\\n\\n&lt;p&gt;Speed is around 75t/s in inference&lt;/p&gt;\\n\\n&lt;p&gt;Engine: vllm\\nQuant: official gptq&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29ehtr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099931,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2d0gpd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29kyu8","score":1,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How? The model alone takes 55GB RAM at q4 on my setup. (That said, it works from CPU alone, so why not just offload some layers to RAM? It will be fast anyway.)","edited":1752154674,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2d0gpd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How? The model alone takes 55GB RAM at q4 on my setup. (That said, it works from CPU alone, so why not just offload some layers to RAM? It will be fast anyway.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2d0gpd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154458,"author_flair_text":null,"treatment_tags":[],"created_utc":1752154458,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29kyu8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752102026,"send_replies":true,"parent_id":"t1_n29dnfa","score":5,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"With 8 bit KV cache and 64k context it will use about 48 GB VRAM on my Mac. 32k context uses 46 GB VRAM, so it appears you can barely fit it on a 2x 24GB GPU setup but a bit uncertain about how much context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29kyu8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With 8 bit KV cache and 64k context it will use about 48 GB VRAM on my Mac. 32k context uses 46 GB VRAM, so it appears you can barely fit it on a 2x 24GB GPU setup but a bit uncertain about how much context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29kyu8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102026,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2a28vh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1752107797,"send_replies":true,"parent_id":"t1_n29dnfa","score":5,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To add a datapoint from my testing, Q5_K_XL is ~57.6GB for the model and with full 262k and fp16 kv cache its up to ~88GB used.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a28vh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To add a datapoint from my testing, Q5_K_XL is ~57.6GB for the model and with full 262k and fp16 kv cache its up to ~88GB used.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2a28vh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107797,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aotkn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1752115731,"send_replies":true,"parent_id":"t1_n29dnfa","score":4,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Offload static layers to GPU and experts to CPU. It'll fly","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aotkn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Offload static layers to GPU and experts to CPU. It&amp;#39;ll fly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2aotkn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115731,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c44h4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29p5cc","score":3,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I know. I'm just annoyed when models have fat KV caches.","edited":false,"author_flair_css_class":null,"name":"t1_n2c44h4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know. I&amp;#39;m just annoyed when models have fat KV caches.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvvkh2","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2c44h4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752141275,"author_flair_text":null,"collapsed":false,"created_utc":1752141275,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29p5cc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PmMeForPCBuilds","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29hmla","score":3,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s MLA, which is much more memory efficient than other implementations for KV cache","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29p5cc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s MLA, which is much more memory efficient than other implementations for KV cache&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29p5cc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103382,"author_flair_text":null,"treatment_tags":[],"created_utc":1752103382,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29hmla","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29dz5b","score":-5,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s still disappointing. Deepseek R1 fits 128k context into 7gb.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29hmla","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s still disappointing. Deepseek R1 fits 128k context into 7gb.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29hmla/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752100945,"author_flair_text":null,"treatment_tags":[],"created_utc":1752100945,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n29dz5b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fireflykid1","can_mod_post":false,"created_utc":1752099765,"send_replies":true,"parent_id":"t1_n29dnfa","score":2,"author_fullname":"t2_15sr10","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s probably including the 256k context","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29dz5b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s probably including the 256k context&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29dz5b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099765,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n29dnfa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1752099661,"send_replies":true,"parent_id":"t3_1lvvkh2","score":0,"author_fullname":"t2_t6glzswk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Haven’t tested it yet, but 61gb at Q4 for a 80b model? That’s disappointing, I was hoping it’d fit into 48gb vram.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29dnfa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haven’t tested it yet, but 61gb at Q4 for a 80b model? That’s disappointing, I was hoping it’d fit into 48gb vram.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29dnfa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099661,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ej8a0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DragonfruitIll660","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29uakk","score":2,"author_fullname":"t2_duscbn82","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Super helpful, ty","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ej8a0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Super helpful, ty&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2ej8a0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752169923,"author_flair_text":null,"treatment_tags":[],"created_utc":1752169923,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2df4sk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2arcdu","score":2,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Did you change the entire app to the beta channel?  Should be 0.3.18 (build 2). If you are still on 0.3.17 you need to switch to beta release.  Gear icon at bottom right, App Settings at bottom left.  Under App Update, there is a dropdown to swap between Stable and Beta.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2df4sk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did you change the entire app to the beta channel?  Should be 0.3.18 (build 2). If you are still on 0.3.17 you need to switch to beta release.  Gear icon at bottom right, App Settings at bottom left.  Under App Update, there is a dropdown to swap between Stable and Beta.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2df4sk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752158808,"author_flair_text":null,"treatment_tags":[],"created_utc":1752158808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2arcdu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Turbulent_Jump_2000","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29uakk","score":0,"author_fullname":"t2_15l7mwafch","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not working for me either.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2arcdu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not working for me either.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n2arcdu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116699,"author_flair_text":null,"treatment_tags":[],"created_utc":1752116699,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n29uakk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752105061,"send_replies":true,"parent_id":"t1_n29rvqt","score":13,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You need the latest llama.cpp backend. If using LM Studio go to settings (Mission Control) -&gt; Runtime -&gt; Runtime Extension Pack: select Beta, then press refresh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29uakk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need the latest llama.cpp backend. If using LM Studio go to settings (Mission Control) -&amp;gt; Runtime -&amp;gt; Runtime Extension Pack: select Beta, then press refresh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvvkh2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29uakk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105061,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n29rvqt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bahablaskawitz","can_mod_post":false,"created_utc":1752104268,"send_replies":true,"parent_id":"t3_1lvvkh2","score":0,"author_fullname":"t2_1kl0vl0osf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"🥲 Failed to load the model\\n\\nFailed to load model\\n\\nerror loading model: error loading model architecture: unknown model architecture: 'hunyuan-moe'\\n\\nDownloaded the Q3 to run on 3090x2, getting this error message. What update am I waiting on to be able to run this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29rvqt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;🥲 Failed to load the model&lt;/p&gt;\\n\\n&lt;p&gt;Failed to load model&lt;/p&gt;\\n\\n&lt;p&gt;error loading model: error loading model architecture: unknown model architecture: &amp;#39;hunyuan-moe&amp;#39;&lt;/p&gt;\\n\\n&lt;p&gt;Downloaded the Q3 to run on 3090x2, getting this error message. What update am I waiting on to be able to run this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvvkh2/hunyuana13b_is_here_for_real/n29rvqt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104268,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvvkh2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
