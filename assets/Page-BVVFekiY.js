import{j as e}from"./index-Bu7qcPAU.js";import{R as l}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello, I posted that I wanted to train an LLM for under $1000 here:  [https://www.reddit.com/r/LocalLLaMA/comments/1lmbtvg/attempting\\\\_to\\\\_train\\\\_a\\\\_model\\\\_from\\\\_scratch\\\\_for\\\\_less/](https://www.reddit.com/r/LocalLLaMA/comments/1lmbtvg/attempting_to_train_a_model_from_scratch_for_less/)\\n\\nI had to crunch a lot to fit in 24gb of ram. The final project is a 960M model trained on 19.2B tokens ( chinchilla optimal).  Cost projection is about $500 for this run.   It has flash attention 2, a 3:1 GQA,  a 3k context window. and sink tokens. Training is 70% project gutenberg and 30% US congressional reports ( the Govremorts dataset).   The corpus is english only, which I'm hoping will give it an edge.\\n\\nI have had two false starts where I had to restart training. The first because I set up my streaming datasets wrong, and the model kep training on the same thing due to restarts. The second because the LR was too high and my loss curve was all fucked up.\\n\\nNow at about 2% on the 3rd run, the loss looks textbook, and I am letting it run till the tokens are done. Projections show a final loss around 2.6-2.3 which is great.\\n\\nHappy to answer any questions! Pic is the beautiful loss curve.\\n\\nEdit: It's called Libremodel I, codename Gigi, and I made a website with more info here: [https://libremodel.xyz](https://libremodel.xyz)\\n\\nhttps://preview.redd.it/lf78xbsfy3ef1.png?width=711&amp;format=png&amp;auto=webp&amp;s=1fc75b919255aa91b8cbf0b65b1420cb43fe26a1","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I posted 3 weeks ago about training my own model. Progress report.","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":69,"top_awarded_type":null,"hide_score":false,"media_metadata":{"lf78xbsfy3ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":53,"x":108,"u":"https://preview.redd.it/lf78xbsfy3ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=36ad333eaf2d759d9b745f45f702461135100a1a"},{"y":107,"x":216,"u":"https://preview.redd.it/lf78xbsfy3ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb1c9a95a8af42b94154d7f01e49b4731e052e5c"},{"y":159,"x":320,"u":"https://preview.redd.it/lf78xbsfy3ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91b4c8642acf7701da8d782aa9ce125107f00dd1"},{"y":319,"x":640,"u":"https://preview.redd.it/lf78xbsfy3ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8517a175f4e44e1ff1b186c44a329b861671f778"}],"s":{"y":355,"x":711,"u":"https://preview.redd.it/lf78xbsfy3ef1.png?width=711&amp;format=png&amp;auto=webp&amp;s=1fc75b919255aa91b8cbf0b65b1420cb43fe26a1"},"id":"lf78xbsfy3ef1"}},"name":"t3_1m52h10","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"subreddit_type":"public","ups":214,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_i5os0v0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":214,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/tGNWILy7NUwjWBRL__Qs6HOJImwQ5Z22Np_wBFcIDdM.jpg","edited":1753128481,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753051615,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello, I posted that I wanted to train an LLM for under $1000 here:  &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lmbtvg/attempting_to_train_a_model_from_scratch_for_less/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1lmbtvg/attempting_to_train_a_model_from_scratch_for_less/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I had to crunch a lot to fit in 24gb of ram. The final project is a 960M model trained on 19.2B tokens ( chinchilla optimal).  Cost projection is about $500 for this run.   It has flash attention 2, a 3:1 GQA,  a 3k context window. and sink tokens. Training is 70% project gutenberg and 30% US congressional reports ( the Govremorts dataset).   The corpus is english only, which I&amp;#39;m hoping will give it an edge.&lt;/p&gt;\\n\\n&lt;p&gt;I have had two false starts where I had to restart training. The first because I set up my streaming datasets wrong, and the model kep training on the same thing due to restarts. The second because the LR was too high and my loss curve was all fucked up.&lt;/p&gt;\\n\\n&lt;p&gt;Now at about 2% on the 3rd run, the loss looks textbook, and I am letting it run till the tokens are done. Projections show a final loss around 2.6-2.3 which is great.&lt;/p&gt;\\n\\n&lt;p&gt;Happy to answer any questions! Pic is the beautiful loss curve.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: It&amp;#39;s called Libremodel I, codename Gigi, and I made a website with more info here: &lt;a href=\\"https://libremodel.xyz\\"&gt;https://libremodel.xyz&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/lf78xbsfy3ef1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1fc75b919255aa91b8cbf0b65b1420cb43fe26a1\\"&gt;https://preview.redd.it/lf78xbsfy3ef1.png?width=711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1fc75b919255aa91b8cbf0b65b1420cb43fe26a1&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m52h10","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"thebadslime","discussion_type":null,"num_comments":53,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/","subreddit_subscribers":502516,"created_utc":1753051615,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n493vgu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"send_replies":true,"parent_id":"t1_n490ktq","score":18,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"nah, I', resuing the data. If you wanted to train a 1B with my setup on 100gb of data, it would cost maybe $700.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n493vgu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nah, I&amp;#39;, resuing the data. If you wanted to train a 1B with my setup on 100gb of data, it would cost maybe $700.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n493vgu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753055072,"author_flair_text":null,"treatment_tags":[],"created_utc":1753055072,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"n490ktq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dontrackonme","can_mod_post":false,"send_replies":true,"parent_id":"t1_n48y4c9","score":17,"author_fullname":"t2_2g5ftq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much , do you estimate, would it cost for 100 GB of data? Is it just $6000 or is there some sort of exponential costs involved?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n490ktq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much , do you estimate, would it cost for 100 GB of data? Is it just $6000 or is there some sort of exponential costs involved?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n490ktq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753053917,"author_flair_text":null,"treatment_tags":[],"created_utc":1753053917,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"n48y4c9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753053064,"send_replies":true,"parent_id":"t1_n48wy9m","score":27,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"about 15gb, enough for almost 5 epochs on my token budget.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48y4c9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;about 15gb, enough for almost 5 epochs on my token budget.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n48y4c9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753053064,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}}],"before":null}},"user_reports":[],"saved":false,"id":"n48wy9m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dontrackonme","can_mod_post":false,"created_utc":1753052661,"send_replies":true,"parent_id":"t3_1m52h10","score":34,"author_fullname":"t2_2g5ftq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How many GB is your training data?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48wy9m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How many GB is your training data?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n48wy9m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753052661,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49xp0u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oodelay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49h7oo","score":29,"author_fullname":"t2_6q32j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not all heroes wear capes and have 24x H100","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n49xp0u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not all heroes wear capes and have 24x H100&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n49xp0u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066186,"author_flair_text":null,"treatment_tags":[],"created_utc":1753066186,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}}],"before":null}},"user_reports":[],"saved":false,"id":"n49h7oo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753059991,"send_replies":true,"parent_id":"t1_n4971mh","score":44,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Once I'm done the model and the scripts are opensource.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49h7oo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Once I&amp;#39;m done the model and the scripts are opensource.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n49h7oo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753059991,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":44}}],"before":null}},"user_reports":[],"saved":false,"id":"n4971mh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"created_utc":1753056208,"send_replies":true,"parent_id":"t3_1m52h10","score":23,"author_fullname":"t2_fmd6oq5v6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very cool! Can't wait to try out the model when done. Do you plan on opensourcing the codebase soon?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4971mh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very cool! Can&amp;#39;t wait to try out the model when done. Do you plan on opensourcing the codebase soon?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4971mh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753056208,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49cspw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"created_utc":1753058348,"send_replies":true,"parent_id":"t3_1m52h10","score":13,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"beautiful curve","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49cspw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;beautiful curve&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n49cspw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753058348,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4b891v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Echo9Zulu-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49orrd","score":11,"author_fullname":"t2_pw77g8dq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Glad to hear others take this approach to learning as well. Have been learning training the same way, though I have chosen to datasets using my own inference stack for my a770s, also built using an LLM + primary source approach.\\n\\nI love learning using LLMs and ignore the hate easily. Frankly, building stuff like this project proves so many doomers wrong. Great work!\\n\\nI see you plan to opensource the code. It would be valuable to try and document your learning process in some way- hit a snag? What did the prompt look like? Prompts which probe and don't merely accept answers naively are the kind that I think encourages how AI tools ought to be used. \\n\\nAnyway awesome project, definitely share the results here when you are done cooking!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4b891v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Glad to hear others take this approach to learning as well. Have been learning training the same way, though I have chosen to datasets using my own inference stack for my a770s, also built using an LLM + primary source approach.&lt;/p&gt;\\n\\n&lt;p&gt;I love learning using LLMs and ignore the hate easily. Frankly, building stuff like this project proves so many doomers wrong. Great work!&lt;/p&gt;\\n\\n&lt;p&gt;I see you plan to opensource the code. It would be valuable to try and document your learning process in some way- hit a snag? What did the prompt look like? Prompts which probe and don&amp;#39;t merely accept answers naively are the kind that I think encourages how AI tools ought to be used. &lt;/p&gt;\\n\\n&lt;p&gt;Anyway awesome project, definitely share the results here when you are done cooking!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4b891v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753089752,"author_flair_text":null,"treatment_tags":[],"created_utc":1753089752,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n49orrd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753062816,"send_replies":true,"parent_id":"t1_n49i6ev","score":33,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I asked LLMs a lot, they did the python for me, I have been reading a shit-ton of papers trying to stay on top of what's current.  The graph is made from a program called tensorboard. It just connects to huggingface transformers the library that is doing most  ot the heavy lifting.   I know what to look for from readfig papers about other LLMS and their training.   The loss is how I knew I messed up my last training run, tensorboard is great.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49orrd","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I asked LLMs a lot, they did the python for me, I have been reading a shit-ton of papers trying to stay on top of what&amp;#39;s current.  The graph is made from a program called tensorboard. It just connects to huggingface transformers the library that is doing most  ot the heavy lifting.   I know what to look for from readfig papers about other LLMS and their training.   The loss is how I knew I messed up my last training run, tensorboard is great.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n49orrd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062816,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}}],"before":null}},"user_reports":[],"saved":false,"id":"n49i6ev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffdy","can_mod_post":false,"created_utc":1753060350,"send_replies":true,"parent_id":"t3_1m52h10","score":9,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how do you start with this? how do you make that graph? how do you know what to look for?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49i6ev","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how do you start with this? how do you make that graph? how do you know what to look for?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n49i6ev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753060350,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bxw2y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753101658,"send_replies":true,"parent_id":"t1_n4agymm","score":7,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This post actually made me realize I don't have enough data.  I'm adding in Wikipedia so that were only looking at 1.7 epoch.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bxw2y","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This post actually made me realize I don&amp;#39;t have enough data.  I&amp;#39;m adding in Wikipedia so that were only looking at 1.7 epoch.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bxw2y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101658,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bzzug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753102405,"send_replies":true,"parent_id":"t1_n4agymm","score":3,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"not tracking yet, and YES this thread made me aware I dint have enough data, weaving in wikipedia after it hits 10% or so.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bzzug","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;not tracking yet, and YES this thread made me aware I dint have enough data, weaving in wikipedia after it hits 10% or so.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bzzug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102405,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bqi6x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wheynelau","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bkczw","score":3,"author_fullname":"t2_vezlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree due to the multiple epochs being used in this case. For single epoch runs there would be no need for validations. \\n\\nBut let's see how it goes, it the end even if its gibberish you can tell people you trained a model from scratch","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqi6x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree due to the multiple epochs being used in this case. For single epoch runs there would be no need for validations. &lt;/p&gt;\\n\\n&lt;p&gt;But let&amp;#39;s see how it goes, it the end even if its gibberish you can tell people you trained a model from scratch&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bqi6x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098808,"author_flair_text":null,"treatment_tags":[],"created_utc":1753098808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bkczw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HiddenoO","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bjri0","score":4,"author_fullname":"t2_8127x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Smaller datasets make overfitting even more likely though. At worst, you'll end up with a model that just repeats the training data closest to your question verbatim. At that point, you might as well put your data into a vector DB and query that DB.\\n\\nOn the other hand, if OP had a data set large enough that they'd barely finish one epoch, not having a validation set could actually make sense since your loss would practically never be on previously-seen data.","edited":1753096332,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4bkczw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Smaller datasets make overfitting even more likely though. At worst, you&amp;#39;ll end up with a model that just repeats the training data closest to your question verbatim. At that point, you might as well put your data into a vector DB and query that DB.&lt;/p&gt;\\n\\n&lt;p&gt;On the other hand, if OP had a data set large enough that they&amp;#39;d barely finish one epoch, not having a validation set could actually make sense since your loss would practically never be on previously-seen data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bkczw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753096106,"author_flair_text":null,"treatment_tags":[],"created_utc":1753096106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4brd9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Yes_but_I_think","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bjri0","score":3,"author_fullname":"t2_rea1qh6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"960M parameters and 19.2 B tokens. That's 20.5 tokens per parameter- a good number, matching regular models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4brd9h","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;960M parameters and 19.2 B tokens. That&amp;#39;s 20.5 tokens per parameter- a good number, matching regular models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4brd9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753099159,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753099159,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bjri0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnomalyNexus","can_mod_post":false,"created_utc":1753095824,"send_replies":true,"parent_id":"t1_n4agymm","score":2,"author_fullname":"t2_3q8dd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"15gb dataset means it’s going to be pretty narrow scope anyway","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bjri0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;15gb dataset means it’s going to be pretty narrow scope anyway&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bjri0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095824,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4b1ybe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"created_utc":1753086027,"send_replies":true,"parent_id":"t1_n4agymm","score":1,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Validation loss? /s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4b1ybe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Validation loss? /s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4b1ybe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753086027,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4agymm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HiddenoO","can_mod_post":false,"created_utc":1753074560,"send_replies":true,"parent_id":"t3_1m52h10","score":9,"author_fullname":"t2_8127x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What does your validation loss look like? I'd be worried about overfitting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4agymm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What does your validation loss look like? I&amp;#39;d be worried about overfitting.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4agymm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753074560,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48ydi3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753053151,"send_replies":true,"parent_id":"t1_n48y2gv","score":7,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That would really be cool, If you like I can post a screenshot of my sagemaker stats shpwing how much resources the training run is taking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48ydi3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would really be cool, If you like I can post a screenshot of my sagemaker stats shpwing how much resources the training run is taking.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n48ydi3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753053151,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bbw7x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoobMLDude","can_mod_post":false,"created_utc":1753091826,"send_replies":true,"parent_id":"t1_n48y2gv","score":3,"author_fullname":"t2_t0syffr8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Some of those numbers can be calculated using this playbook which has a ton of calculators:\\n\\nhttps://huggingface.co/spaces/nanotron/ultrascale-playbook","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bbw7x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some of those numbers can be calculated using this playbook which has a ton of calculators:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/spaces/nanotron/ultrascale-playbook\\"&gt;https://huggingface.co/spaces/nanotron/ultrascale-playbook&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bbw7x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753091826,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ae04m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"johnerp","can_mod_post":false,"created_utc":1753073136,"send_replies":true,"parent_id":"t1_n48y2gv","score":1,"author_fullname":"t2_100h8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sounds like a great vibe coding opportunity, if you have a paper with the calcs even better, point Claude to it, I’d love to know if you can get a local model running, reading and coding this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ae04m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sounds like a great vibe coding opportunity, if you have a paper with the calcs even better, point Claude to it, I’d love to know if you can get a local model running, reading and coding this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4ae04m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753073136,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n48y2gv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1753053046,"send_replies":true,"parent_id":"t3_1m52h10","score":3,"author_fullname":"t2_8lvrytgw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most interesting!\\nWhat I would love is to have a calculator taking VRAM , bandwidth, computing power and allowed training time as input and model size, dataset size, context lengths tuples as output.\\nDo you think that it would be possible?\\nMaybe if enough participants would try and provide data points.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48y2gv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most interesting!\\nWhat I would love is to have a calculator taking VRAM , bandwidth, computing power and allowed training time as input and model size, dataset size, context lengths tuples as output.\\nDo you think that it would be possible?\\nMaybe if enough participants would try and provide data points.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n48y2gv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753053046,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aoqgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"schlammsuhler","can_mod_post":false,"created_utc":1753078588,"send_replies":true,"parent_id":"t3_1m52h10","score":3,"author_fullname":"t2_cx7q6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://huggingface.co/datasets/institutional/institutional-books-1.0","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aoqgd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/datasets/institutional/institutional-books-1.0\\"&gt;https://huggingface.co/datasets/institutional/institutional-books-1.0&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4aoqgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753078588,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bp6et","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wheynelau","can_mod_post":false,"created_utc":1753098263,"send_replies":true,"parent_id":"t3_1m52h10","score":3,"author_fullname":"t2_vezlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting, haven't seen a pretrained model done on &gt;1 epochs in awhile, would be interesting to see the evaluation results. Definitely seems like a good experiment.\\n\\nAre you using HF trainer?  \\n\\nI found the batch size a little unusual, what was the effective tokens 3072*18?  \\n\\nCould have done wandb with a public profile, that way everyone can admire the training curve haha","edited":1753098606,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bp6et","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting, haven&amp;#39;t seen a pretrained model done on &amp;gt;1 epochs in awhile, would be interesting to see the evaluation results. Definitely seems like a good experiment.&lt;/p&gt;\\n\\n&lt;p&gt;Are you using HF trainer?  &lt;/p&gt;\\n\\n&lt;p&gt;I found the batch size a little unusual, what was the effective tokens 3072*18?  &lt;/p&gt;\\n\\n&lt;p&gt;Could have done wandb with a public profile, that way everyone can admire the training curve haha&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bp6et/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098263,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4e7vkm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Independent_Aside225","can_mod_post":false,"created_utc":1753125673,"send_replies":true,"parent_id":"t3_1m52h10","score":3,"author_fullname":"t2_bfr1vge1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just a heads up that might potentially save you time: When you have such a small dataset, linear attention models actually converge much faster. You can look into Mamba2 to test a linear attention model that can be trained in a parallel manner.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e7vkm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just a heads up that might potentially save you time: When you have such a small dataset, linear attention models actually converge much faster. You can look into Mamba2 to test a linear attention model that can be trained in a parallel manner.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4e7vkm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753125673,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bxbg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753101450,"send_replies":true,"parent_id":"t1_n4b7of2","score":6,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"About 30 cents per hour on average. Haven't looked into vast. Next model is muon or apollo.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bxbg8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;About 30 cents per hour on average. Haven&amp;#39;t looked into vast. Next model is muon or apollo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bxbg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101450,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4b7of2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OkStatement3655","can_mod_post":false,"created_utc":1753089419,"send_replies":true,"parent_id":"t3_1m52h10","score":4,"author_fullname":"t2_e91kxnzq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is your GPU cost per hour? You could probably lower your costs using vast.ai. Also do you mind lpoking at the Muon optimizer, maybe it will speed up your training.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4b7of2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is your GPU cost per hour? You could probably lower your costs using vast.ai. Also do you mind lpoking at the Muon optimizer, maybe it will speed up your training.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4b7of2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753089419,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bjtr9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnomalyNexus","can_mod_post":false,"created_utc":1753095854,"send_replies":true,"parent_id":"t3_1m52h10","score":2,"author_fullname":"t2_3q8dd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice project!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bjtr9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice project!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bjtr9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095854,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bw3yt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753101002,"send_replies":true,"parent_id":"t1_n4bqu21","score":3,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a great idea!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bw3yt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a great idea!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bw3yt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101002,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bqu21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Yes_but_I_think","can_mod_post":false,"created_utc":1753098944,"send_replies":true,"parent_id":"t3_1m52h10","score":2,"author_fullname":"t2_rea1qh6m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Will you be creating a diary of your failures and successes for us to learn from?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqu21","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will you be creating a diary of your failures and successes for us to learn from?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bqu21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098944,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4enp8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1753130200,"send_replies":true,"parent_id":"t3_1m52h10","score":2,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"excellent job dude, this is what local llama is for","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4enp8t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;excellent job dude, this is what local llama is for&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4enp8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753130200,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bwzpo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753101328,"send_replies":true,"parent_id":"t1_n4bbzuc","score":2,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just hf transformers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bwzpo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just hf transformers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bwzpo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101328,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bbzuc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoobMLDude","can_mod_post":false,"created_utc":1753091881,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_t0syffr8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What’s you training framework?\\nTransformers, unsloth, deepspeed, ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bbzuc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What’s you training framework?\\nTransformers, unsloth, deepspeed, ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bbzuc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753091881,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bqq13","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wheynelau","can_mod_post":false,"created_utc":1753098897,"send_replies":true,"parent_id":"t1_n4bf47r","score":2,"author_fullname":"t2_vezlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This should be a base model based on his input data, not suitable for QA yet","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqq13","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This should be a base model based on his input data, not suitable for QA yet&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bqq13/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098897,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bf47r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Papabear3339","can_mod_post":false,"created_utc":1753093544,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_7iw5w8ac","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does it work?\\nfitting training data vs able to give reasonable answers to inquires.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bf47r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it work?\\nfitting training data vs able to give reasonable answers to inquires.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bf47r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753093544,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bzs3x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753102329,"send_replies":true,"parent_id":"t1_n4by4zf","score":3,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am renting a sagemaker instance from amazon, data is free. I dont have the hardware to do this at home.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bzs3x","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am renting a sagemaker instance from amazon, data is free. I dont have the hardware to do this at home.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bzs3x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102329,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4by4zf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Top9254","can_mod_post":false,"created_utc":1753101746,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_1e4s71l3kv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The cost is just from electricity or did the data collection cost anything? I'll be mounting solar on my roof soon so I thought I might give it a shot too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4by4zf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The cost is just from electricity or did the data collection cost anything? I&amp;#39;ll be mounting solar on my roof soon so I thought I might give it a shot too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4by4zf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101746,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dmocw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753119741,"send_replies":true,"parent_id":"t1_n4czhfo","score":2,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"About $100 for my mistakes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dmocw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;About $100 for my mistakes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4dmocw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119741,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4czhfo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"akashdeepjassal","can_mod_post":false,"created_utc":1753113306,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_1drelerb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the total cost incurred till now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4czhfo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the total cost incurred till now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4czhfo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753113306,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dpdog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753120474,"send_replies":true,"parent_id":"t1_n4dn08d","score":1,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm using flash attention 2","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dpdog","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m using flash attention 2&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4dpdog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120474,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dn08d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rzvzn","can_mod_post":false,"created_utc":1753119831,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_1e2jjp1mqg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In your previous linked post you mentioned intending to train \\"with differential Attention\\". Did you end up doing that, or are you using vanilla attention?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dn08d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In your previous linked post you mentioned intending to train &amp;quot;with differential Attention&amp;quot;. Did you end up doing that, or are you using vanilla attention?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4dn08d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119831,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cokmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bxnx0","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Darn. I have an rtx 8000 and was planning to build a small ai model around 300m parameters. I was hoping the training would be a week at most.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4cokmx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Darn. I have an rtx 8000 and was planning to build a small ai model around 300m parameters. I was hoping the training would be a week at most.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4cokmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753110197,"author_flair_text":null,"treatment_tags":[],"created_utc":1753110197,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bxnx0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753101575,"send_replies":true,"parent_id":"t1_n4al6a2","score":2,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Still training. A10G, and its going to take like 40 days.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bxnx0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still training. A10G, and its going to take like 40 days.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bxnx0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101575,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4al6a2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1753076710,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What GPU was this made on? And how long did inferencing take? A week, Day, month?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4al6a2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What GPU was this made on? And how long did inferencing take? A week, Day, month?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4al6a2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753076710,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aoh6j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"schlammsuhler","can_mod_post":false,"created_utc":1753078452,"send_replies":true,"parent_id":"t1_n4aflvl","score":4,"author_fullname":"t2_cx7q6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He is still in the first epoch. I do hope he has validation set up to watch out for overfitting. When finetuning i often have to stop after 2 epochs, but thats much less data","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aoh6j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He is still in the first epoch. I do hope he has validation set up to watch out for overfitting. When finetuning i often have to stop after 2 epochs, but thats much less data&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4aoh6j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753078452,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c087t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753102486,"send_replies":true,"parent_id":"t1_n4aflvl","score":1,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am adding mroe data to get down to 2 epochs, which should be fine. Overfitting is just caused my seeing the same data too many times,","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c087t","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am adding mroe data to get down to 2 epochs, which should be fine. Overfitting is just caused my seeing the same data too many times,&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4c087t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102486,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4aflvl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sure_Explorer_6698","can_mod_post":false,"created_utc":1753073899,"send_replies":true,"parent_id":"t3_1m52h10","score":1,"author_fullname":"t2_nmk9dlpa9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had to put my training project on hold for a while, but my loss dropped from 13 to 0.0044, and my research said I was overfitting. Thus, the pause. How were you able to correct that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aflvl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had to put my training project on hold for a while, but my loss dropped from 13 to 0.0044, and my research said I was overfitting. Thus, the pause. How were you able to correct that?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4aflvl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753073899,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4f4yl9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4en7kj","score":1,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's free, I applied for free startup credits. I'm on SSDI, can't afford a real gpu. I do my inference on a 4gb gpu.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f4yl9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s free, I applied for free startup credits. I&amp;#39;m on SSDI, can&amp;#39;t afford a real gpu. I do my inference on a 4gb gpu.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4f4yl9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135361,"author_flair_text":null,"treatment_tags":[],"created_utc":1753135361,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4en7kj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bxepz","score":1,"author_fullname":"t2_zws5yqyow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"NGL if I was training and saw it cost $1000 on a cloud service I'd just use it as an excuse to buy more 3090's lol","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4en7kj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;NGL if I was training and saw it cost $1000 on a cloud service I&amp;#39;d just use it as an excuse to buy more 3090&amp;#39;s lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4en7kj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753130060,"author_flair_text":null,"treatment_tags":[],"created_utc":1753130060,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bxepz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753101482,"send_replies":true,"parent_id":"t1_n4atlnk","score":2,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its HD transformers on Amazon sagemaker.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bxepz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its HD transformers on Amazon sagemaker.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m52h10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4bxepz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101482,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4atlnk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1753081251,"send_replies":true,"parent_id":"t3_1m52h10","score":0,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Was this trained on runpod/other services?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4atlnk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Was this trained on runpod/other services?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4atlnk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753081251,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aagyp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Murky-Service-1013","can_mod_post":false,"created_utc":1753071513,"send_replies":true,"parent_id":"t3_1m52h10","score":-16,"author_fullname":"t2_1suvc8x0xa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Are you going to fine tune it to be extremely racist or will I have to do that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aagyp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you going to fine tune it to be extremely racist or will I have to do that&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m52h10/i_posted_3_weeks_ago_about_training_my_own_model/n4aagyp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753071513,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m52h10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-16}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
