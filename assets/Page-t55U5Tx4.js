import{j as e}from"./index-DQXiEb7D.js";import{R as l}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=4080&amp;format=pjpg&amp;auto=webp&amp;s=75899651ae7b2f3408b852ae298d78e3502b6664\\n\\n\\n\\nI found that ik\\\\_llama.cpp is faster(faster on prefill ,roughly the same on  decode) and much easier to install than ktransformers. No need for conda and no more worry about dependency errors !! (If you had ever built ktransformers you know what I'm talking about)\\n\\n[https://github.com/ikawrakow/ik\\\\_llama.cpp](https://github.com/ikawrakow/ik_llama.cpp)\\n\\nIt's a perfect replacement for ktransformers.\\n\\nMy hareware: epyc 7b13, 512gb 3200mhz ddr4, dual 5070ti  \\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Amazing performance! Kimi K2 on ik_llama.cpp","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"media_metadata":{"8685rjwu0kdf1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":81,"x":108,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f24ab5be5d3657f830ad37f5c7b5f3030266b4d1"},{"y":162,"x":216,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=572c0d18cd8dfadd6d2f7fff0849973e73d28369"},{"y":240,"x":320,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=613abb81181ac59b82d1b4829fbdff69bc5802ff"},{"y":481,"x":640,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51cc65c1621e268ca08e484ff0233df156ef5f72"},{"y":722,"x":960,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4edb8cf7534a223c808f6c09238458e843eea319"},{"y":813,"x":1080,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6e3a1ecb4c44ced2ce2a6509153308f086c002c8"}],"s":{"y":3072,"x":4080,"u":"https://preview.redd.it/8685rjwu0kdf1.jpg?width=4080&amp;format=pjpg&amp;auto=webp&amp;s=75899651ae7b2f3408b852ae298d78e3502b6664"},"id":"8685rjwu0kdf1"}},"name":"t3_1m2s686","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"ups":58,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vi73k","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":58,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=4ac05c91d895ec6e3a3525643680170d18da96bd","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1752810550,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/8685rjwu0kdf1.jpg?width=4080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=75899651ae7b2f3408b852ae298d78e3502b6664\\"&gt;https://preview.redd.it/8685rjwu0kdf1.jpg?width=4080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=75899651ae7b2f3408b852ae298d78e3502b6664&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I found that ik_llama.cpp is faster(faster on prefill ,roughly the same on  decode) and much easier to install than ktransformers. No need for conda and no more worry about dependency errors !! (If you had ever built ktransformers you know what I&amp;#39;m talking about)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ikawrakow/ik_llama.cpp\\"&gt;https://github.com/ikawrakow/ik_llama.cpp&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a perfect replacement for ktransformers.&lt;/p&gt;\\n\\n&lt;p&gt;My hareware: epyc 7b13, 512gb 3200mhz ddr4, dual 5070ti  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?auto=webp&amp;s=de3aef486d5275f64fb7a2997b18a85f309d4d35","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=915707b6fa6423f963fe5c710121891264c06ce8","width":108,"height":54},{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=00a74870997385dd082267764b54a5231a3412f7","width":216,"height":108},{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=28c6ecb4c8504bbe167016d200b5ba83b7653999","width":320,"height":160},{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=af7e06b1e31f22e6366e10579021d8702da59ec9","width":640,"height":320},{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f8c33cb21e473c79f851d3c1ac9c096e8299226","width":960,"height":480},{"url":"https://external-preview.redd.it/mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e37cc5874855b2f9255ddd8382a734227e19ed2","width":1080,"height":540}],"variants":{},"id":"mbqL7tVnx0USUgmIfTfH3gk6Pper9a5zZIt2Et32S4Q"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m2s686","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"timmytimmy01","discussion_type":null,"num_comments":64,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/","subreddit_subscribers":501232,"created_utc":1752810550,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3t5n0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sixx7","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rdbvn","score":2,"author_fullname":"t2_jxjl6u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"wow that's pretty solid performance for the size.  I have a 7c13 and I'm regretting getting 256gb instead of 512","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3t5n0o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wow that&amp;#39;s pretty solid performance for the size.  I have a 7c13 and I&amp;#39;m regretting getting 256gb instead of 512&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3t5n0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752843716,"author_flair_text":null,"treatment_tags":[],"created_utc":1752843716,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rdbvn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752812459,"send_replies":true,"parent_id":"t1_n3rbzyl","score":6,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ud-q3\\\\_k\\\\_xl","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rdbvn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ud-q3_k_xl&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rdbvn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752812459,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rbzyl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResearchCrafty1804","can_mod_post":false,"created_utc":1752811877,"send_replies":true,"parent_id":"t3_1m2s686","score":6,"author_fullname":"t2_c705ri9b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Which quant were you running for this token generation speed?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rbzyl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which quant were you running for this token generation speed?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rbzyl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752811877,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ri3aa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glittering-Call8746","can_mod_post":false,"created_utc":1752814628,"send_replies":true,"parent_id":"t1_n3rhk9w","score":1,"author_fullname":"t2_tqwl6sawb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can u elaborate? Sorry noob here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ri3aa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can u elaborate? Sorry noob here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3ri3aa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752814628,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rhk9w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Defiant_Diet9085","can_mod_post":false,"created_utc":1752814381,"send_replies":true,"parent_id":"t3_1m2s686","score":4,"author_fullname":"t2_1airv0szt9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ik\\\\_llama.cpp is installed in two steps.\\n\\n1. copy the .devops/cuda.Dockerfile file from the parent project llama.cpp\\n\\n2. run the command\\n\\ndocker build -t my\\\\_cuda12.8:250716 --target server -f .devops/cuda.Dockerfile .\\n\\n\\n\\nbut I don't like the web interface ik\\\\_llama.cpp.\\n\\nIs it possible to copy it from the llama.cpp project?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rhk9w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ik_llama.cpp is installed in two steps.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;copy the .devops/cuda.Dockerfile file from the parent project llama.cpp&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;run the command&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;docker build -t my_cuda12.8:250716 --target server -f .devops/cuda.Dockerfile .&lt;/p&gt;\\n\\n&lt;p&gt;but I don&amp;#39;t like the web interface ik_llama.cpp.&lt;/p&gt;\\n\\n&lt;p&gt;Is it possible to copy it from the llama.cpp project?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rhk9w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752814381,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s78oz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mpthouse","can_mod_post":false,"created_utc":1752828029,"send_replies":true,"parent_id":"t3_1m2s686","score":4,"author_fullname":"t2_1ft86zbrel","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good to know! I'll definitely check out ik\\\\_llama.cpp, especially if it's easier to set up.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s78oz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good to know! I&amp;#39;ll definitely check out ik_llama.cpp, especially if it&amp;#39;s easier to set up.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s78oz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828029,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rx2ty","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"created_utc":1752822295,"send_replies":true,"parent_id":"t3_1m2s686","score":2,"author_fullname":"t2_j1i0o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I couldn't get ktransformers to run after a full day of debugging so I just gave up. ik is definitely much easier to setup","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rx2ty","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I couldn&amp;#39;t get ktransformers to run after a full day of debugging so I just gave up. ik is definitely much easier to setup&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rx2ty/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752822295,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vi17n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VoidAlchemy","can_mod_post":false,"created_utc":1752868190,"send_replies":true,"parent_id":"t1_n3u6fpr","score":1,"author_fullname":"t2_n321yfw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It has the basic RPC backend you can compile yes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vi17n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It has the basic RPC backend you can compile yes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vi17n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868190,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u6fpr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752854506,"send_replies":true,"parent_id":"t3_1m2s686","score":2,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"very nice!   does ik support rpc?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u6fpr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;very nice!   does ik support rpc?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u6fpr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854506,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uemhe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752856861,"send_replies":true,"parent_id":"t3_1m2s686","score":2,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The generation/processing performance is good, but how is the output quality?  Are you seeing it to be better than DeepseeK (v3/r1/r1.5), qwen3-235b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uemhe","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The generation/processing performance is good, but how is the output quality?  Are you seeing it to be better than DeepseeK (v3/r1/r1.5), qwen3-235b?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uemhe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752856861,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s1hlp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752824764,"send_replies":true,"parent_id":"t1_n3rbypx","score":3,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A single 5070ti with 16gb vram is not enough,a single 3090 is ok","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s1hlp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A single 5070ti with 16gb vram is not enough,a single 3090 is ok&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s1hlp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752824764,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rbypx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glittering-Call8746","can_mod_post":false,"created_utc":1752811862,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_tqwl6sawb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How much ram are you using ? And can u run off single gpu ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rbypx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much ram are you using ? And can u run off single gpu ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rbypx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752811862,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s1m9g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752824835,"send_replies":true,"parent_id":"t1_n3rzkeg","score":2,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Context can be up to 120k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s1m9g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Context can be up to 120k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s1m9g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752824835,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rzkeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waiting_for_zban","can_mod_post":false,"created_utc":1752823669,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_13yxr6ze7l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's the Q3_K_XL quant? How much context? Although 512gb + 32 Vram is just so out of my consumer budget.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rzkeg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s the Q3_K_XL quant? How much context? Although 512gb + 32 Vram is just so out of my consumer budget.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rzkeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752823669,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s7bdn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Saruphon","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s6u0o","score":1,"author_fullname":"t2_bkb0tcya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you. Guess RTX5090 is way to go for me then. Also more pixel when gaming.\\n\\nPs thank you for the post, this really help me a lot.","edited":false,"author_flair_css_class":null,"name":"t1_n3s7bdn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. Guess RTX5090 is way to go for me then. Also more pixel when gaming.&lt;/p&gt;\\n\\n&lt;p&gt;Ps thank you for the post, this really help me a lot.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s7bdn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828072,"author_flair_text":null,"collapsed":false,"created_utc":1752828072,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s6u0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s60vk","score":1,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's right.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s6u0o","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s right.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s6u0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752827794,"author_flair_text":null,"treatment_tags":[],"created_utc":1752827794,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s60vk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Saruphon","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s3qo8","score":1,"author_fullname":"t2_bkb0tcya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In my country I can RTX 5090 is about 550 USD more expensive than getting x2 RTX 5070ti.\\n\\nFrom my understanding, dual GPU doesn't increase GPU processing speed, only add more into VRAM so might as well pay a bit extra for more omph. Please let me know if my assumption is wrong or not","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3s60vk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my country I can RTX 5090 is about 550 USD more expensive than getting x2 RTX 5070ti.&lt;/p&gt;\\n\\n&lt;p&gt;From my understanding, dual GPU doesn&amp;#39;t increase GPU processing speed, only add more into VRAM so might as well pay a bit extra for more omph. Please let me know if my assumption is wrong or not&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s60vk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752827329,"author_flair_text":null,"treatment_tags":[],"created_utc":1752827329,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s3qo8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752826024,"send_replies":true,"parent_id":"t1_n3s27mr","score":2,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On dual 5070ti the gpu usage is very low, about 60-70 watts per gpu. So I'm not certain if you can gain from one 5090.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s3qo8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On dual 5070ti the gpu usage is very low, about 60-70 watts per gpu. So I&amp;#39;m not certain if you can gain from one 5090.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s3qo8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752826024,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tya4l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panchovix","can_mod_post":false,"created_utc":1752852226,"send_replies":true,"parent_id":"t1_n3s27mr","score":2,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not faster. 2x5070Ti vs 1x5090 is about equal probably for TG but PP would be about as half as fast. lcpp/iklcpp don't have TP.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tya4l","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not faster. 2x5070Ti vs 1x5090 is about equal probably for TG but PP would be about as half as fast. lcpp/iklcpp don&amp;#39;t have TP.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3tya4l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752852226,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s27mr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Saruphon","can_mod_post":false,"created_utc":1752825164,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_bkb0tcya","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just want to check, since this can be run on x2 RTX5070 Ti, it would run faster on RTX 5090 right?  \\nWould appreciate your reply, considering whether to get RTX5070Ti, RTX5070Ti x2, or RTX 5090 setup for my new PC. (First hand GPU only, also need to buy my PC via BTO shop in Singapore).\\n\\nPlanning to get RTX5090 with 256 GB Ram to run 1.8-bit version of K2 atm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s27mr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just want to check, since this can be run on x2 RTX5070 Ti, it would run faster on RTX 5090 right?&lt;br/&gt;\\nWould appreciate your reply, considering whether to get RTX5070Ti, RTX5070Ti x2, or RTX 5090 setup for my new PC. (First hand GPU only, also need to buy my PC via BTO shop in Singapore).&lt;/p&gt;\\n\\n&lt;p&gt;Planning to get RTX5090 with 256 GB Ram to run 1.8-bit version of K2 atm.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s27mr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752825164,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3u7jik","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s714r","score":1,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"very nice, I didn't know huanana made epyc boards, i use their x99 boards for my rig.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3u7jik","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;very nice, I didn&amp;#39;t know huanana made epyc boards, i use their x99 boards for my rig.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u7jik/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854823,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752854823,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s714r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752827909,"send_replies":true,"parent_id":"t1_n3s39i7","score":3,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mb:huanan h12d-8d. The machine costs me about $3500.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s714r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mb:huanan h12d-8d. The machine costs me about $3500.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s714r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752827909,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s39i7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MidnightProgrammer","can_mod_post":false,"created_utc":1752825752,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_ijzb7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What motherboard you running with that cpu?  \\nWhat you spend on the system?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s39i7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What motherboard you running with that cpu?&lt;br/&gt;\\nWhat you spend on the system?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s39i7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752825752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s78lf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Such_Advantage_6949","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s77gh","score":1,"author_fullname":"t2_a548b491","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3s78lf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s78lf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828027,"author_flair_text":null,"treatment_tags":[],"created_utc":1752828027,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s77gh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752828009,"send_replies":true,"parent_id":"t1_n3s5v3y","score":1,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A little bit faster than deepseek q4, deepseek r1 q4 is about 9 tokens/s decode.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s77gh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A little bit faster than deepseek q4, deepseek r1 q4 is about 9 tokens/s decode.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s77gh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828009,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s5v3y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Such_Advantage_6949","can_mod_post":false,"created_utc":1752827235,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_a548b491","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That is very good speed for ddr4! How does it compare to deepseek","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s5v3y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That is very good speed for ddr4! How does it compare to deepseek&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s5v3y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752827235,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tp2vk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poli-cya","can_mod_post":false,"created_utc":1752849639,"send_replies":true,"parent_id":"t1_n3su3j6","score":2,"author_fullname":"t2_q8g93lhv4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's the magic of MoE, looks like the right play might have been avoiding the 10+ GPUs cobbled together.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tp2vk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s the magic of MoE, looks like the right play might have been avoiding the 10+ GPUs cobbled together.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3tp2vk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752849639,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3su3j6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1752839537,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_p45er6oo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Okay so now that convinced me: Im going to buy a new/used motherboard with as many channels as I can get at least 512 gb ram!\\n\\n\\nJust to be sure again: 80 tok/sec prompt processing and 11 tok/sec generation speed?\\n\\n\\nThats nearly not believable to me, if I consider we are actually talking about a 1 trillion parameter model!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3su3j6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay so now that convinced me: Im going to buy a new/used motherboard with as many channels as I can get at least 512 gb ram!&lt;/p&gt;\\n\\n&lt;p&gt;Just to be sure again: 80 tok/sec prompt processing and 11 tok/sec generation speed?&lt;/p&gt;\\n\\n&lt;p&gt;Thats nearly not believable to me, if I consider we are actually talking about a 1 trillion parameter model!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3su3j6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752839537,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uzkuh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uogoh","score":3,"author_fullname":"t2_3rrw4qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; DGGML_SCHED_MAX_COPIES=1\\n\\nAha! thank you very much for this, it does make a huge difference, esp. combined with -ub 10240 -b 10240 I now get 287 prompt processing tk/s on 3x 4090. gpu use on one of those sshots to 88% and the other to 16 while prompt processing too, so that's quite good I guess and explains why it's so high.\\n\\nThe VRAM utilization remains low though and as such I only get 4.9 tk/sec still on actual output. But tht is still enough to drop 30+ minutes processing time in my 35k prompt to 5:34 which is a huge win o course. Now to see if I can improve the other part of it.","edited":1752863365,"author_flair_css_class":null,"name":"t1_n3uzkuh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;DGGML_SCHED_MAX_COPIES=1&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Aha! thank you very much for this, it does make a huge difference, esp. combined with -ub 10240 -b 10240 I now get 287 prompt processing tk/s on 3x 4090. gpu use on one of those sshots to 88% and the other to 16 while prompt processing too, so that&amp;#39;s quite good I guess and explains why it&amp;#39;s so high.&lt;/p&gt;\\n\\n&lt;p&gt;The VRAM utilization remains low though and as such I only get 4.9 tk/sec still on actual output. But tht is still enough to drop 30+ minutes processing time in my 35k prompt to 5:34 which is a huge win o course. Now to see if I can improve the other part of it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uzkuh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862737,"author_flair_text":null,"collapsed":false,"created_utc":1752862737,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3v8w7o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sixx7","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uogoh","score":2,"author_fullname":"t2_jxjl6u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"add another thank you for this!  I gave up on ik_llama quickly when I couldn't get it to work with multi gpu + CPU","edited":false,"author_flair_css_class":null,"name":"t1_n3v8w7o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;add another thank you for this!  I gave up on ik_llama quickly when I couldn&amp;#39;t get it to work with multi gpu + CPU&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3v8w7o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865463,"author_flair_text":null,"collapsed":false,"created_utc":1752865463,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vwhgz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752872455,"send_replies":true,"parent_id":"t1_n3vqvj2","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/ikawrakow/ik\\\\_llama.cpp/issues/500](https://github.com/ikawrakow/ik_llama.cpp/issues/500)\\n\\n  \\nIt's a bug which is not fixed yet.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3vwhgz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/ikawrakow/ik_llama.cpp/issues/500\\"&gt;https://github.com/ikawrakow/ik_llama.cpp/issues/500&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a bug which is not fixed yet.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vwhgz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752872455,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vqvj2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vpgb0","score":1,"author_fullname":"t2_j1i0o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I did some calculations and realised it wasn't offloading right. For the Q3 XL it was loading 400GB to CPU and 140GB to GPU even though the model is just 460GB. Seems like compute buffer is duplicated massively across all cards","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3vqvj2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did some calculations and realised it wasn&amp;#39;t offloading right. For the Q3 XL it was loading 400GB to CPU and 140GB to GPU even though the model is just 460GB. Seems like compute buffer is duplicated massively across all cards&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vqvj2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752870796,"author_flair_text":null,"treatment_tags":[],"created_utc":1752870796,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vpgb0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vnopz","score":1,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I hit it without -ub / -b set because it's still too high at times and so I arrived at some google solution to reduce the value and had to set it to like 128, but turns out without that option only one card is used for processing or some such? And then in tiny batches so everything is superslow. With teh compile option specified and large batch size I got 1000%+ speedup, so can't complain about that!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3vpgb0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hit it without -ub / -b set because it&amp;#39;s still too high at times and so I arrived at some google solution to reduce the value and had to set it to like 128, but turns out without that option only one card is used for processing or some such? And then in tiny batches so everything is superslow. With teh compile option specified and large batch size I got 1000%+ speedup, so can&amp;#39;t complain about that!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vpgb0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752870378,"author_flair_text":null,"treatment_tags":[],"created_utc":1752870378,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vnopz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uogoh","score":1,"author_fullname":"t2_j1i0o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why is it this error only shows with -ub 10k and -b 10k? Leaving it unset allows it to load everything evenly","edited":false,"author_flair_css_class":null,"name":"t1_n3vnopz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why is it this error only shows with -ub 10k and -b 10k? Leaving it unset allows it to load everything evenly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vnopz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752869862,"author_flair_text":null,"collapsed":false,"created_utc":1752869862,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x7gkn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3x7cfk","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It only occurs on Kimi k2.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3x7gkn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It only occurs on Kimi k2.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3x7gkn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888629,"author_flair_text":null,"treatment_tags":[],"created_utc":1752888629,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3x7cfk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3w1je7","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I found that when the context is above about 7k(the vlue is not fixed,sometimes higher and sometImes lower), my decode speed also drop to 5 toks/s. It's not only on ik\\\\_llama. The same issue occurs on fastllm (https://github.com/ztxz16/fastllm). So I think it's a feature of KIMI K2, which may need to be opmitized by these opensource localLLM structures.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3x7cfk","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found that when the context is above about 7k(the vlue is not fixed,sometimes higher and sometImes lower), my decode speed also drop to 5 toks/s. It&amp;#39;s not only on ik_llama. The same issue occurs on fastllm (&lt;a href=\\"https://github.com/ztxz16/fastllm\\"&gt;https://github.com/ztxz16/fastllm&lt;/a&gt;). So I think it&amp;#39;s a feature of KIMI K2, which may need to be opmitized by these opensource localLLM structures.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3x7cfk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888585,"author_flair_text":null,"treatment_tags":[],"created_utc":1752888585,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n3y45zx","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n3y45zx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752902477,"send_replies":true,"parent_id":"t1_n3xsxrz","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No,I got no pp or tg speedup, the extra gpu only give me extra content. I can run by one gpu with smaller content at same speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y45zx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No,I got no pp or tg speedup, the extra gpu only give me extra content. I can run by one gpu with smaller content at same speed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3y45zx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752902477,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n3y4h37","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n3y4h37","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752902629,"send_replies":true,"parent_id":"t1_n3xsxrz","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried smaller -b and -ub with -fmoe off","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y4h37","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried smaller -b and -ub with -fmoe off&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3y4h37/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752902629,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xsxrz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"created_utc":1752897270,"send_replies":true,"parent_id":"t1_n3xrli3","score":1,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"interesting, I tried a slightly smaller prompt and I still observe the same ~5 tk/sec.\\n\\nConsidering we have almost identical CPU/RAM properties and the only difference in the GPUs, the disparities are strange, I get 3x prompt processing time speedup, but you get 2x generation speedup.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3xsxrz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;interesting, I tried a slightly smaller prompt and I still observe the same ~5 tk/sec.&lt;/p&gt;\\n\\n&lt;p&gt;Considering we have almost identical CPU/RAM properties and the only difference in the GPUs, the disparities are strange, I get 3x prompt processing time speedup, but you get 2x generation speedup.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3xsxrz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752897270,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xrli3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752896693,"send_replies":true,"parent_id":"t1_n3xnclc","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"In my machine by removing - fmoe gpu use almost doubled from below 10%, and decode speed came back to normal( 10 tk /s at 21k prompt)\\n\\nhttps://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=4080&amp;format=pjpg&amp;auto=webp&amp;s=7fe759df95c9526406947f0e951c98d09a9c6933","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3xrli3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my machine by removing - fmoe gpu use almost doubled from below 10%, and decode speed came back to normal( 10 tk /s at 21k prompt)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=4080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7fe759df95c9526406947f0e951c98d09a9c6933\\"&gt;https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=4080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7fe759df95c9526406947f0e951c98d09a9c6933&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3xrli3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752896693,"media_metadata":{"5p6qxr3t5rdf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":81,"x":108,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fcd38b24bc7c9473e9d639a7bc0e0c61cbce9b90"},{"y":162,"x":216,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68793424d8a77bad490ecfc1f5ce831dcfb89955"},{"y":240,"x":320,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7792baec71e74d4a790b5bbfff78204405a1534"},{"y":481,"x":640,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=70266ffe99a841ab95831014f8fc6244608d1a36"},{"y":722,"x":960,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb64b1201d7cec190e05b710453c82d44504101d"},{"y":813,"x":1080,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eee7224786e7345fd53d63a26f28327ac24fcbce"}],"s":{"y":3072,"x":4080,"u":"https://preview.redd.it/5p6qxr3t5rdf1.jpeg?width=4080&amp;format=pjpg&amp;auto=webp&amp;s=7fe759df95c9526406947f0e951c98d09a9c6933"},"id":"5p6qxr3t5rdf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xnclc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xjp3z","score":1,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hm, I am unable to replicate this. Removing this option had no visible changes, still stuck around 5 for the 36k token summarization task.\\n\\nIt's interesting that by removing that option GPU use stays steady at 4-5% at all of them where as before it's jump around 0-2 randomly. But alas this did not transform into any visible decoding speed increase.\\n\\n    INFO [           print_timings] prompt eval time     =  152804.51 ms / 35736 tokens (    4.28 ms per token,   233.87 tokens per second) | tid=\\"139666309812224\\" timestamp=1752894767 id_slot=0 id_task=0 t_prompt_processing=152804.508 n_prompt_tokens_processed=35736 t_token=4.275926460711887 n_tokens_second=233.8674458478673\\n    INFO [           print_timings] generation eval time =  189234.22 ms /   905 runs   (  209.10 ms per token,     4.78 tokens per second) | tid=\\"139666309812224\\" timestamp=1752894767 id_slot=0 id_task=0 t_token_generation=189234.222 n_decoded=905 t_token=209.09858784530388 n_tokens_second=4.782433063296553","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3xnclc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hm, I am unable to replicate this. Removing this option had no visible changes, still stuck around 5 for the 36k token summarization task.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s interesting that by removing that option GPU use stays steady at 4-5% at all of them where as before it&amp;#39;s jump around 0-2 randomly. But alas this did not transform into any visible decoding speed increase.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;INFO [           print_timings] prompt eval time     =  152804.51 ms / 35736 tokens (    4.28 ms per token,   233.87 tokens per second) | tid=&amp;quot;139666309812224&amp;quot; timestamp=1752894767 id_slot=0 id_task=0 t_prompt_processing=152804.508 n_prompt_tokens_processed=35736 t_token=4.275926460711887 n_tokens_second=233.8674458478673\\nINFO [           print_timings] generation eval time =  189234.22 ms /   905 runs   (  209.10 ms per token,     4.78 tokens per second) | tid=&amp;quot;139666309812224&amp;quot; timestamp=1752894767 id_slot=0 id_task=0 t_token_generation=189234.222 n_decoded=905 t_token=209.09858784530388 n_tokens_second=4.782433063296553\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3xnclc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752894883,"author_flair_text":null,"treatment_tags":[],"created_utc":1752894883,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xjp3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3w1je7","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"update: remove -fmoe seems solve it.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3xjp3z","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;update: remove -fmoe seems solve it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3xjp3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752893372,"author_flair_text":null,"treatment_tags":[],"created_utc":1752893372,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3w1je7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uogoh","score":1,"author_fullname":"t2_3rrw4qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"so after some mucking around, I still cannot get measurably above 5 tk/sec on actual processing, may be there;s an easy fix there as well that you know of, since your rate it still double that of mine?","edited":false,"author_flair_css_class":null,"name":"t1_n3w1je7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so after some mucking around, I still cannot get measurably above 5 tk/sec on actual processing, may be there;s an easy fix there as well that you know of, since your rate it still double that of mine?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3w1je7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752874027,"author_flair_text":null,"collapsed":false,"created_utc":1752874027,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wavvq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"apodicity","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uogoh","score":1,"author_fullname":"t2_r0x1k85","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"omg THANK YOU! lolol.   THIS.  THIS.  I'm sure it was documented and I missed it.","edited":false,"author_flair_css_class":null,"name":"t1_n3wavvq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;omg THANK YOU! lolol.   THIS.  THIS.  I&amp;#39;m sure it was documented and I missed it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3wavvq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752877052,"author_flair_text":null,"collapsed":false,"created_utc":1752877052,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uogoh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uk1gt","score":2,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have this issue when i use ik first time. In order to use more than 1 card on ik, you have to recompile ik by adding -DGGML\\\\_SCHED\\\\_MAX\\\\_COPIES=1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uogoh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have this issue when i use ik first time. In order to use more than 1 card on ik, you have to recompile ik by adding -DGGML_SCHED_MAX_COPIES=1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uogoh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859587,"author_flair_text":null,"treatment_tags":[],"created_utc":1752859587,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uk1gt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u9wxk","score":1,"author_fullname":"t2_3rrw4qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well, this one does not work for me, fails with cuda memory allocation:\\n\\n    ggml_backend_cuda_buffer_type_alloc_buffer: allocating 18931.26 MiB on device 0: cudaMalloc failed: out of memory\\n    ggml_gallocr_reserve_n: failed to allocate CUDA0 buffer of size 19850862592\\n    llama_new_context_with_model: failed to allocate compute buffers\\n    llama_init_from_gpt_params: error: failed to create context with model '/usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf'\\n     ERR [              load_model] unable to load model | tid=\\"139942691606528\\" timestamp=1752858179 model=\\"/usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3uk1gt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well, this one does not work for me, fails with cuda memory allocation:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;ggml_backend_cuda_buffer_type_alloc_buffer: allocating 18931.26 MiB on device 0: cudaMalloc failed: out of memory\\nggml_gallocr_reserve_n: failed to allocate CUDA0 buffer of size 19850862592\\nllama_new_context_with_model: failed to allocate compute buffers\\nllama_init_from_gpt_params: error: failed to create context with model &amp;#39;/usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf&amp;#39;\\n ERR [              load_model] unable to load model | tid=&amp;quot;139942691606528&amp;quot; timestamp=1752858179 model=&amp;quot;/usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uk1gt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752858361,"author_flair_text":null,"treatment_tags":[],"created_utc":1752858361,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u9wxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752855501,"send_replies":true,"parent_id":"t1_n3u514y","score":3,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"/home/ee/ik\\\\_llama.cpp/ik\\\\_llama.cpp/build/bin/llama-server \\\\\\\\\\n\\n\\\\--model /home/ee/models/Kimi-K2-Instruct-UD-Q3\\\\_K\\\\_XL/UD-Q3\\\\_K\\\\_XL/Kimi-K2-Instruct-UD-Q3\\\\_K\\\\_XL-00001-of-00010.gguf \\\\\\\\\\n\\n\\\\--alias k2 \\\\\\\\\\n\\n\\\\-c 100000 \\\\\\\\\\n\\n\\\\-ctk q8\\\\_0 \\\\\\\\\\n\\n\\\\-mla 3 -fa \\\\\\\\\\n\\n\\\\-amb 512 \\\\\\\\\\n\\n\\\\--threads 56 \\\\\\\\\\n\\n\\\\--host [0.0.0.0](http://0.0.0.0) \\\\\\\\\\n\\n\\\\--port 8000 \\\\\\\\\\n\\n\\\\--parallel 2 \\\\\\\\\\n\\n\\\\-ts 1,1 \\\\\\\\\\n\\n\\\\-ngl 99 \\\\\\\\\\n\\n\\\\-fmoe \\\\\\\\\\n\\n\\\\-ot \\".ffn\\\\_.\\\\*\\\\_exps.\\"=CPU","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u9wxk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;/home/ee/ik_llama.cpp/ik_llama.cpp/build/bin/llama-server \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--model /home/ee/models/Kimi-K2-Instruct-UD-Q3_K_XL/UD-Q3_K_XL/Kimi-K2-Instruct-UD-Q3_K_XL-00001-of-00010.gguf \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--alias k2 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-c 100000 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-ctk q8_0 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-mla 3 -fa \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-amb 512 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--threads 56 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--host &lt;a href=\\"http://0.0.0.0\\"&gt;0.0.0.0&lt;/a&gt; \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--port 8000 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;--parallel 2 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-ts 1,1 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-ngl 99 \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-fmoe \\\\&lt;/p&gt;\\n\\n&lt;p&gt;-ot &amp;quot;.ffn_.*_exps.&amp;quot;=CPU&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u9wxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752855501,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3unudd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"created_utc":1752859416,"send_replies":true,"parent_id":"t1_n3umhug","score":2,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"    cmake -B build -DGGML_CUDA=ON\\n\\n    -- OpenMP found\\n    -- Using optimized iqk matrix multiplications\\n    -- Enabling IQK Flash Attention kernels\\n    -- Using llamafile\\n    -- CUDA found\\n    -- Using CUDA architectures: native\\n    -- CUDA host compiler is GNU 14.3.1\\n\\n    -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\\n    -- CMAKE_SYSTEM_PROCESSOR: x86_64\\n    -- x86 detected\\n    -- ARCH_FLAGS = -march=native\\n    -- Configuring done (0.2s)\\n    -- Generating done (0.1s)\\n\\n    cmake --build build --config Release -j 12\\n\\nAnd yes, I had to reduce ub and b from 10240 in the original example because again cuda out of memory owuld have occured even despite teh other example had fewer GPUs with less VRAM and RAM, which is a bit strange (there were other reports of teh same in that thread)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3unudd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;pre&gt;&lt;code&gt;cmake -B build -DGGML_CUDA=ON\\n\\n-- OpenMP found\\n-- Using optimized iqk matrix multiplications\\n-- Enabling IQK Flash Attention kernels\\n-- Using llamafile\\n-- CUDA found\\n-- Using CUDA architectures: native\\n-- CUDA host compiler is GNU 14.3.1\\n\\n-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\\n-- CMAKE_SYSTEM_PROCESSOR: x86_64\\n-- x86 detected\\n-- ARCH_FLAGS = -march=native\\n-- Configuring done (0.2s)\\n-- Generating done (0.1s)\\n\\ncmake --build build --config Release -j 12\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;And yes, I had to reduce ub and b from 10240 in the original example because again cuda out of memory owuld have occured even despite teh other example had fewer GPUs with less VRAM and RAM, which is a bit strange (there were other reports of teh same in that thread)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3unudd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859416,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3umhug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752859045,"send_replies":true,"parent_id":"t1_n3uff2p","score":2,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Seems ok and you can delete -ub -b,since they are small,it will affect pp speed.\\n\\ndecrease ctx\\\\_size to 60k may help.\\n\\nsince you have 3 cards you can add -ts 1,1,1 on bigger ctx\\\\_size.\\n\\ncan you show your ik\\\\_llama build parameters","edited":1752859418,"gildings":{},"author_flair_css_class":null,"name":"t1_n3umhug","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems ok and you can delete -ub -b,since they are small,it will affect pp speed.&lt;/p&gt;\\n\\n&lt;p&gt;decrease ctx_size to 60k may help.&lt;/p&gt;\\n\\n&lt;p&gt;since you have 3 cards you can add -ts 1,1,1 on bigger ctx_size.&lt;/p&gt;\\n\\n&lt;p&gt;can you show your ik_llama build parameters&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3umhug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859045,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uff2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3ue2n5","score":1,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"just amost verbatim from that other post:\\n\\n    CUDA_VISIBLE_DEVICES=0,1,2 ./build/bin/llama-server \\\\\\n    --model /usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf \\\\\\n    --alias Kimi-K2-1T \\\\\\n    --threads 48 \\\\\\n    --cache-type-k q8_0 \\\\\\n    --cache-type-v q8_0 \\\\\\n    --temp 0.6 \\\\\\n    --ctx-size 131072 \\\\\\n    --prompt-cache \\\\\\n    --parallel=3 \\\\\\n    --metrics \\\\\\n    --n-gpu-layers 99 \\\\\\n    -ot \\".ffn_.*_exps.=CPU\\" \\\\\\n    -mla 3 -fa -fmoe \\\\\\n    -ub 128 -b 128 \\\\\\n    -amb 512 \\\\\\n    --host 0.0.0.0 \\\\\\n    --port 8080 \\\\\\n    -cb \\\\\\n    -v","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3uff2p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just amost verbatim from that other post:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0,1,2 ./build/bin/llama-server \\\\\\n--model /usr/local/ai/models/kimi2/UD-Q2_K_XL/Kimi-K2-Instruct-UD-Q2_K_XL-00001-of-00008.gguf \\\\\\n--alias Kimi-K2-1T \\\\\\n--threads 48 \\\\\\n--cache-type-k q8_0 \\\\\\n--cache-type-v q8_0 \\\\\\n--temp 0.6 \\\\\\n--ctx-size 131072 \\\\\\n--prompt-cache \\\\\\n--parallel=3 \\\\\\n--metrics \\\\\\n--n-gpu-layers 99 \\\\\\n-ot &amp;quot;.ffn_.*_exps.=CPU&amp;quot; \\\\\\n-mla 3 -fa -fmoe \\\\\\n-ub 128 -b 128 \\\\\\n-amb 512 \\\\\\n--host 0.0.0.0 \\\\\\n--port 8080 \\\\\\n-cb \\\\\\n-v\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uff2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752857087,"author_flair_text":null,"treatment_tags":[],"created_utc":1752857087,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ue2n5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3ubnsu","score":1,"author_fullname":"t2_vi73k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the problem is your build parameters or running parameters. Can you show your parameters","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3ue2n5","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the problem is your build parameters or running parameters. Can you show your parameters&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3ue2n5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752856703,"author_flair_text":null,"treatment_tags":[],"created_utc":1752856703,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ubnsu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uanxz","score":1,"author_fullname":"t2_3rrw4qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, I am sure it stabilizes at some point, 36k is just something I had at the ready.\\n\\nThis is still so much higher than what I am seeing out of my config and that's what I am ryign to understand. Is it the 5070Ti vs 4090? or is it something else?","edited":false,"author_flair_css_class":null,"name":"t1_n3ubnsu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, I am sure it stabilizes at some point, 36k is just something I had at the ready.&lt;/p&gt;\\n\\n&lt;p&gt;This is still so much higher than what I am seeing out of my config and that&amp;#39;s what I am ryign to understand. Is it the 5070Ti vs 4090? or is it something else?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2s686","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3ubnsu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752856002,"author_flair_text":null,"collapsed":false,"created_utc":1752856002,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uanxz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u7zgr","score":1,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've never try any prompt as long as 36k70-80tk/s is on 2k-10k prompt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uanxz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve never try any prompt as long as 36k70-80tk/s is on 2k-10k prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3uanxz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752855715,"author_flair_text":null,"treatment_tags":[],"created_utc":1752855715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xjtli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timmytimmy01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u7zgr","score":1,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"update: remove -fmoe seems solve it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xjtli","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;update: remove -fmoe seems solve it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3xjtli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752893422,"author_flair_text":null,"treatment_tags":[],"created_utc":1752893422,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u7zgr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u6rkx","score":1,"author_fullname":"t2_3rrw4qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes. that's what I am doing with my large 36k prompt. (basically a \\"summarize this jira ticket with all it's comments\\" task).\\n\\nBut it's interesting that a 2-3 line sentence is very consistent on prompt processing too, just the actual eval is floating, not too much, but in like 4.8-5.2 range no matter the gpu config too, where as gpu config makes a very noticeable difference with long prompt seemingly? I guess I'll do another round just to make sure. takes 30-50 minutes per attempt though)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3u7zgr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes. that&amp;#39;s what I am doing with my large 36k prompt. (basically a &amp;quot;summarize this jira ticket with all it&amp;#39;s comments&amp;quot; task).&lt;/p&gt;\\n\\n&lt;p&gt;But it&amp;#39;s interesting that a 2-3 line sentence is very consistent on prompt processing too, just the actual eval is floating, not too much, but in like 4.8-5.2 range no matter the gpu config too, where as gpu config makes a very noticeable difference with long prompt seemingly? I guess I&amp;#39;ll do another round just to make sure. takes 30-50 minutes per attempt though)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u7zgr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854950,"author_flair_text":null,"treatment_tags":[],"created_utc":1752854950,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u6rkx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752854599,"send_replies":true,"parent_id":"t1_n3u514y","score":1,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"don't use small context to test.   have a repeatable test with a large prompt.   giving a 2-3 line sentence and the prompt processing will be all over the place.  have a ready 4k-10k prompt that you can repeatedly use for testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u6rkx","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;don&amp;#39;t use small context to test.   have a repeatable test with a large prompt.   giving a 2-3 line sentence and the prompt processing will be all over the place.  have a ready 4k-10k prompt that you can repeatedly use for testing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u6rkx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854599,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u514y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentheonly","can_mod_post":false,"created_utc":1752854107,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_3rrw4qm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hm, what are the ik llama parameters are you using?\\n\\nI have 7663 with 1T DDR4-3200 RAM and seeing another report from the other day https://www.reddit.com/r/LocalLLaMA/comments/1m0lyjn/kimi_has_impressive_coding_performance_even_deep/  and thought I'd replicate it and I did, sorta.\\n\\nBut the numbers there are much lower than yours despite doing Q2_K_XL,. Sure, over there it's 3090, but here I have 3x 4090 + 1x 3090.\\n\\nAfter some experimenting I found that 3090 really drags everything down A LOT and if I remove it (with CUDA_VISIBLE_DEVICES omitting it) then I basically get  ~21 tk/sec prompt processing and around 5.1 for eval on short context (4.9 on long context, ~35.5k, hm in fact I jut tested again and the numbers are not very stable so I just got 4.9 omn short context too, but prompt processing dropped to 13.3 which I thin matches my earlier short context numbers).\\n\\nIt obviously goed downhill as I go for bigger quants. It could not really be 5070Ti having this much effect, or could it?\\n\\nOn a side note I also tried to scale down the number of 4090 I give the system from 3 to 1 and the performance drop was as big on small context, but bigger on small context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u514y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hm, what are the ik llama parameters are you using?&lt;/p&gt;\\n\\n&lt;p&gt;I have 7663 with 1T DDR4-3200 RAM and seeing another report from the other day &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1m0lyjn/kimi_has_impressive_coding_performance_even_deep/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1m0lyjn/kimi_has_impressive_coding_performance_even_deep/&lt;/a&gt;  and thought I&amp;#39;d replicate it and I did, sorta.&lt;/p&gt;\\n\\n&lt;p&gt;But the numbers there are much lower than yours despite doing Q2_K_XL,. Sure, over there it&amp;#39;s 3090, but here I have 3x 4090 + 1x 3090.&lt;/p&gt;\\n\\n&lt;p&gt;After some experimenting I found that 3090 really drags everything down A LOT and if I remove it (with CUDA_VISIBLE_DEVICES omitting it) then I basically get  ~21 tk/sec prompt processing and around 5.1 for eval on short context (4.9 on long context, ~35.5k, hm in fact I jut tested again and the numbers are not very stable so I just got 4.9 omn short context too, but prompt processing dropped to 13.3 which I thin matches my earlier short context numbers).&lt;/p&gt;\\n\\n&lt;p&gt;It obviously goed downhill as I go for bigger quants. It could not really be 5070Ti having this much effect, or could it?&lt;/p&gt;\\n\\n&lt;p&gt;On a side note I also tried to scale down the number of 4090 I give the system from 3 to 1 and the performance drop was as big on small context, but bigger on small context.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3u514y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854107,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vig3m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VoidAlchemy","can_mod_post":false,"created_utc":1752868312,"send_replies":true,"parent_id":"t3_1m2s686","score":1,"author_fullname":"t2_n321yfw5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for spreading the good word. You can also try out some new quant types that ik has developed. (If you don't know, ik wrote most of newer quant types for mainline llama.cpp which is used in ollama / kobo etc). You can find many of them using the tag \\"ik\\\\_llama.cpp\\" on huggingface like so: [https://huggingface.co/models?other=ik\\\\_llama.cpp](https://huggingface.co/models?other=ik_llama.cpp)\\n\\nHave fun!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vig3m","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for spreading the good word. You can also try out some new quant types that ik has developed. (If you don&amp;#39;t know, ik wrote most of newer quant types for mainline llama.cpp which is used in ollama / kobo etc). You can find many of them using the tag &amp;quot;ik_llama.cpp&amp;quot; on huggingface like so: &lt;a href=\\"https://huggingface.co/models?other=ik_llama.cpp\\"&gt;https://huggingface.co/models?other=ik_llama.cpp&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Have fun!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3vig3m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868312,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s4ams","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"timmytimmy01","can_mod_post":false,"created_utc":1752826341,"send_replies":true,"parent_id":"t1_n3rdcnl","score":6,"author_fullname":"t2_vi73k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ktransformers only support amx on int8 and fp16 quantazation. So it's more expensive to use amx on large models like kimi k2. Hence amx only improve prefill speed, decode speed is limited by ram bandwidth.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s4ams","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ktransformers only support amx on int8 and fp16 quantazation. So it&amp;#39;s more expensive to use amx on large models like kimi k2. Hence amx only improve prefill speed, decode speed is limited by ram bandwidth.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3s4ams/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752826341,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3riqsw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glittering-Call8746","can_mod_post":false,"created_utc":1752814935,"send_replies":true,"parent_id":"t1_n3rdcnl","score":1,"author_fullname":"t2_tqwl6sawb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's the token generation/s for amx ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3riqsw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s the token generation/s for amx ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2s686","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3riqsw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752814935,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rdcnl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hankdabits","can_mod_post":false,"created_utc":1752812468,"send_replies":true,"parent_id":"t3_1m2s686","score":0,"author_fullname":"t2_gzfsn1z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For intel amx users ktransformers likely still has the edge in speed. Maybe dual socket users as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rdcnl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For intel amx users ktransformers likely still has the edge in speed. Maybe dual socket users as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3rdcnl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752812468,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tg6s8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pokemonplayer2001","can_mod_post":false,"created_utc":1752847045,"send_replies":true,"parent_id":"t3_1m2s686","score":0,"author_fullname":"t2_11qjf3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"r/screenshotsarehard","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tg6s8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"/r/screenshotsarehard\\"&gt;r/screenshotsarehard&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2s686/amazing_performance_kimi_k2_on_ik_llamacpp/n3tg6s8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752847045,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2s686","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
