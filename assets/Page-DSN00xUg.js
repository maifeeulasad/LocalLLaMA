import{j as e}from"./index-BOnf-UhU.js";import{R as l}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"We had a lot of posts about the updated [235b model](https://x.com/Alibaba_Qwen/status/1947344511988076547) and the [Unsloth quants](https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF). I tested it with my Mac Studio and decided to merge the Q3 K XL ggufs and upload them to Ollama in case someone es might find this useful.\\n\\nRuns great with up to 18 tokens per second and consuming 108 to 117 GB VRAM.\\n\\n[More details on the Ollama library page](https://ollama.com/awaescher/qwen3-235b-2507-unsloth-q3-k-xl), performance benchmarks included.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"The LLM for M4 Max 128GB: Unsloth Qwen3-235B-A22B-Instruct-2507 Q3 K XL for Ollama","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":87,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6ocfd","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.81,"author_flair_background_color":null,"ups":29,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1gpif4cz","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":29,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://a.thumbs.redditmedia.com/FGAC4_FgxMG-7e9w8V8PkDHHC0Spkue03KT-5Vo9mU4.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753214166,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;We had a lot of posts about the updated &lt;a href=\\"https://x.com/Alibaba_Qwen/status/1947344511988076547\\"&gt;235b model&lt;/a&gt; and the &lt;a href=\\"https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF\\"&gt;Unsloth quants&lt;/a&gt;. I tested it with my Mac Studio and decided to merge the Q3 K XL ggufs and upload them to Ollama in case someone es might find this useful.&lt;/p&gt;\\n\\n&lt;p&gt;Runs great with up to 18 tokens per second and consuming 108 to 117 GB VRAM.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ollama.com/awaescher/qwen3-235b-2507-unsloth-q3-k-xl\\"&gt;More details on the Ollama library page&lt;/a&gt;, performance benchmarks included.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/y3x24rxqchef1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/y3x24rxqchef1.png?auto=webp&amp;s=8871c292b16bce4a1a3ebad50bdc70a4755edfb1","width":1119,"height":699},"resolutions":[{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e41bb7b82dd23ca399246b0ad273bfca55313312","width":108,"height":67},{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8196b3b26f6cebea121b85e8d13e70ccede750b","width":216,"height":134},{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=71b905987f840aecad2d4d33ebe4b67e00e55446","width":320,"height":199},{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c4dd5da6091ae77e58d63dfd95935c34e266d7e","width":640,"height":399},{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d2b6677488033099a15dec1df1c7088540544b7","width":960,"height":599},{"url":"https://preview.redd.it/y3x24rxqchef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96a500d949b1758bb6f522dd4c3912c8e4c57f64","width":1080,"height":674}],"variants":{},"id":"65hJ7hQzTtv2DTpl4kNAtfCBSaTl0aIGG0bqSxzPvcM"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m6ocfd","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"waescher","discussion_type":null,"num_comments":38,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/","stickied":false,"url":"https://i.redd.it/y3x24rxqchef1.png","subreddit_subscribers":503519,"created_utc":1753214166,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4pdc64","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tomz17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ny1ex","score":1,"author_fullname":"t2_1mhx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, PC workstations are energy pigs.  My M1 Max, in comparison, uses 70-80 watts while inferencing.  Both 3090's + the 9684x in the workstation require a 1600watt power supply.  \\n\\n  \\nThat being said, if you can get a PC workstation with 8 or 12 channel DDR5 for a good price, it is a good alternative (esp. since you can typically scale the ram up to well over 1TB)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4pdc64","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, PC workstations are energy pigs.  My M1 Max, in comparison, uses 70-80 watts while inferencing.  Both 3090&amp;#39;s + the 9684x in the workstation require a 1600watt power supply.  &lt;/p&gt;\\n\\n&lt;p&gt;That being said, if you can get a PC workstation with 8 or 12 channel DDR5 for a good price, it is a good alternative (esp. since you can typically scale the ram up to well over 1TB)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4pdc64/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753275136,"author_flair_text":null,"treatment_tags":[],"created_utc":1753275136,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ny1ex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"waescher","can_mod_post":false,"created_utc":1753249775,"send_replies":true,"parent_id":"t1_n4n1gnx","score":6,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This machine idles between 1 and 18 watts (even though I have the usual apps open). During inference it goes up to 90-95 watts and stays there constantly. It pretty much goes down to the idle consumption  the second it finished token generation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ny1ex","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This machine idles between 1 and 18 watts (even though I have the usual apps open). During inference it goes up to 90-95 watts and stays there constantly. It pretty much goes down to the idle consumption  the second it finished token generation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4ny1ex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753249775,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4n1gnx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tomz17","can_mod_post":false,"created_utc":1753236190,"send_replies":true,"parent_id":"t3_1m6ocfd","score":5,"author_fullname":"t2_1mhx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interestingly the tg/s is almost identical to a Genoa Epyc w/ 12-channel DDR5 4800MT/s + a single 3090   (on a slightly higher quant).\\n\\nI am seeing 82t/s pp  (about double the M4 Max) and 17.5t/s tg (about the same) @ Q4K\\\\_XL.  (llama.cpp, Qwen3-235B-A22B-Instruct-2507-UD-Q4\\\\_K\\\\_XL-00001-of-0000x.gguf , ot= ffn\\\\_.\\\\*\\\\_exps.=CPU)\\n\\nOnly downside is that this machine is pulling like 800 watts from the wall when running.  The M4 Max is going to be way more power efficient.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4n1gnx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interestingly the tg/s is almost identical to a Genoa Epyc w/ 12-channel DDR5 4800MT/s + a single 3090   (on a slightly higher quant).&lt;/p&gt;\\n\\n&lt;p&gt;I am seeing 82t/s pp  (about double the M4 Max) and 17.5t/s tg (about the same) @ Q4K_XL.  (llama.cpp, Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL-00001-of-0000x.gguf , ot= ffn_.*_exps.=CPU)&lt;/p&gt;\\n\\n&lt;p&gt;Only downside is that this machine is pulling like 800 watts from the wall when running.  The M4 Max is going to be way more power efficient.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4n1gnx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753236190,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ncivc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SandboChang","can_mod_post":false,"created_utc":1753240235,"send_replies":true,"parent_id":"t3_1m6ocfd","score":2,"author_fullname":"t2_10icmj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also just tried the 2-bit quant from Unsloth, works well on my M4 Max 128 GB giving similar performance. It still one-shot the bouncing ball prompt.\\n\\nTo test if it was just remembering things, I then followed up to change the polygon to a octagon, change ball colors to follow a rainbow pattern, and ask for a speed scale bar - another one-shot success!\\n\\nAt this point, the context is around 6k, it still gives roughly 13 t/s. I think this model for the first time makes me thing buying M4 Max 128 GB was a right decision.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ncivc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also just tried the 2-bit quant from Unsloth, works well on my M4 Max 128 GB giving similar performance. It still one-shot the bouncing ball prompt.&lt;/p&gt;\\n\\n&lt;p&gt;To test if it was just remembering things, I then followed up to change the polygon to a octagon, change ball colors to follow a rainbow pattern, and ask for a speed scale bar - another one-shot success!&lt;/p&gt;\\n\\n&lt;p&gt;At this point, the context is around 6k, it still gives roughly 13 t/s. I think this model for the first time makes me thing buying M4 Max 128 GB was a right decision.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4ncivc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753240235,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4mvahi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lfbjo","score":0,"author_fullname":"t2_wjjtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; and now we're looking at Qwen3-Coder at 408B so it's not like a 1T model is so silly.\\n\\nSure but that 1M context window will take 5TB of ram at Q8","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mvahi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; and now we&amp;#39;re looking at Qwen3-Coder at 408B so it&amp;#39;s not like a 1T model is so silly.&lt;/p&gt;\\n\\n&lt;p&gt;Sure but that 1M context window will take 5TB of ram at Q8&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4mvahi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753234050,"author_flair_text":null,"treatment_tags":[],"created_utc":1753234050,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lfbjo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4l6bto","score":4,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If I was going to buy 128GB of soldered down memory, I'd probably get an AMD AI Max 395+.  It's ~half the price (though half the bandwidth), so half the money to waste /s.\\n\\nReally, I would try and stretch the budget for an M3 Ultra 256GB.  It's more money for sure, but higher performance and you have a lot more memory for large MoEs.  Even with 256GB you need unsloth's most brain damaged quant to try and run Kimi-K2, and now we're looking at Qwen3-Coder at 408B so it's not like a 1T model is so silly.\\n\\nPersonally I went with and recommend Epyc Genoa.  If you start with 6 channels of 64GB that should come in around $4k.  The bandwidth will be lackluster but you'll have 384GB and room to grow to a 768GB system with the ~same bandwidth as the M4 128GB but now enough memory to run &gt;=Q4 of any model released to date.  (If you want to save some money, Sapphire Rapids has some super cheap engineering samples, but they max out at 8 channels so I feel like that's a bit of a dead end, though most of the spend is on memory which you could reuse if you flip to AMD later)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lfbjo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I was going to buy 128GB of soldered down memory, I&amp;#39;d probably get an AMD AI Max 395+.  It&amp;#39;s ~half the price (though half the bandwidth), so half the money to waste /s.&lt;/p&gt;\\n\\n&lt;p&gt;Really, I would try and stretch the budget for an M3 Ultra 256GB.  It&amp;#39;s more money for sure, but higher performance and you have a lot more memory for large MoEs.  Even with 256GB you need unsloth&amp;#39;s most brain damaged quant to try and run Kimi-K2, and now we&amp;#39;re looking at Qwen3-Coder at 408B so it&amp;#39;s not like a 1T model is so silly.&lt;/p&gt;\\n\\n&lt;p&gt;Personally I went with and recommend Epyc Genoa.  If you start with 6 channels of 64GB that should come in around $4k.  The bandwidth will be lackluster but you&amp;#39;ll have 384GB and room to grow to a 768GB system with the ~same bandwidth as the M4 128GB but now enough memory to run &amp;gt;=Q4 of any model released to date.  (If you want to save some money, Sapphire Rapids has some super cheap engineering samples, but they max out at 8 channels so I feel like that&amp;#39;s a bit of a dead end, though most of the spend is on memory which you could reuse if you flip to AMD later)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4lfbjo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217432,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217432,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n4ndjrq","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ndjrq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"created_utc":1753240636,"send_replies":true,"parent_id":"t1_n4ncs2w","score":1,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I haven't used an MI50, but I did see some performance results about it, especially the 11 Mi50/3090 build.  Prompt processing is where it seems to suffer.  I was considering some MI50's myself, but to do what I want to do, would require way too many of them.\\n\\nI think the M3 Ultra is the ideal Mac for this sort of thing, but it is expensive and still slow but a lot faster ram than most.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ndjrq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I haven&amp;#39;t used an MI50, but I did see some performance results about it, especially the 11 Mi50/3090 build.  Prompt processing is where it seems to suffer.  I was considering some MI50&amp;#39;s myself, but to do what I want to do, would require way too many of them.&lt;/p&gt;\\n\\n&lt;p&gt;I think the M3 Ultra is the ideal Mac for this sort of thing, but it is expensive and still slow but a lot faster ram than most.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4ndjrq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753240636,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ncs2w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"created_utc":1753240336,"send_replies":true,"parent_id":"t1_n4n88o0","score":1,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let's say the Mi50 rig costs an extra 30/month in electricity. That's 360/year. You're looking at 8 years of use before break even with the Mac studio.\\n\\nFor PP, did you actually check? It might have been slow one year ago, but recent posts using it suggest very different figures. [With five Mi50, you get 200+ tk/s PP and 19tk/s TG on 235B Q4\\\\_1](https://www.reddit.com/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/) (which is 137GB vs 104GB for Q3\\\\_K\\\\_XL). The Ollama page OP linked to says M4 Max does 57 tk/s PP, and 18tk/s TG.\\n\\nI don't know about you, but the math I was taught in school says that slow Mi50 is 3.5 times faster than the M4 Max at PP, and 5% faster in TG. IMHO, an extra 30/month of electricity isn't a bad deal for something that costs 3k less.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4ncs2w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let&amp;#39;s say the Mi50 rig costs an extra 30/month in electricity. That&amp;#39;s 360/year. You&amp;#39;re looking at 8 years of use before break even with the Mac studio.&lt;/p&gt;\\n\\n&lt;p&gt;For PP, did you actually check? It might have been slow one year ago, but recent posts using it suggest very different figures. &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/\\"&gt;With five Mi50, you get 200+ tk/s PP and 19tk/s TG on 235B Q4_1&lt;/a&gt; (which is 137GB vs 104GB for Q3_K_XL). The Ollama page OP linked to says M4 Max does 57 tk/s PP, and 18tk/s TG.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t know about you, but the math I was taught in school says that slow Mi50 is 3.5 times faster than the M4 Max at PP, and 5% faster in TG. IMHO, an extra 30/month of electricity isn&amp;#39;t a bad deal for something that costs 3k less.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4ncs2w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753240336,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4n88o0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"created_utc":1753238610,"send_replies":true,"parent_id":"t1_n4myzhu","score":1,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt; Fair enough, but slow for you does not mean slow for everyone else.\\n\\nAgreed, but anything below 20 just isn't usable for me.\\n\\n\\\\&gt; No matter how you look at it, OP's M4 Max isn't a better deal than Mi50 + Epyc, which costs 1/4 of that Mac Studio, which is the **only** point I was making.\\n\\nMaybe, but any savings you get you will lose in electricity compared to a M4 Max. A MI50 build will likely cost you $20-50/m in electricity alone, where a M4 MAX will cost you around $10.  MI50 is very slow at prompt processing so you kind of need a 3090 or better as well.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4n88o0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Fair enough, but slow for you does not mean slow for everyone else.&lt;/p&gt;\\n\\n&lt;p&gt;Agreed, but anything below 20 just isn&amp;#39;t usable for me.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; No matter how you look at it, OP&amp;#39;s M4 Max isn&amp;#39;t a better deal than Mi50 + Epyc, which costs 1/4 of that Mac Studio, which is the &lt;strong&gt;only&lt;/strong&gt; point I was making.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe, but any savings you get you will lose in electricity compared to a M4 Max. A MI50 build will likely cost you $20-50/m in electricity alone, where a M4 MAX will cost you around $10.  MI50 is very slow at prompt processing so you kind of need a 3090 or better as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4n88o0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753238610,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4odej9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"created_utc":1753258218,"send_replies":true,"parent_id":"t1_n4oaxai","score":1,"author_fullname":"t2_1gpif4cz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; You didn't have to post here about how it performs on Qwen3 235B.\\n\\nThe first thing people ask if you write anything about model usage here is how it performs so what are you even talking about?\\n\\nWhy the hell are you so offended how this model runs on my machine? Just go on with your life, leave the mac users chatting here and be happy with your own rig, is it so hard?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4odej9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; You didn&amp;#39;t have to post here about how it performs on Qwen3 235B.&lt;/p&gt;\\n\\n&lt;p&gt;The first thing people ask if you write anything about model usage here is how it performs so what are you even talking about?&lt;/p&gt;\\n\\n&lt;p&gt;Why the hell are you so offended how this model runs on my machine? Just go on with your life, leave the mac users chatting here and be happy with your own rig, is it so hard?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4odej9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753258218,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4oaxai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"created_utc":1753256802,"send_replies":true,"parent_id":"t1_n4nzdyw","score":0,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nothing. All I said was that I'm not impressed with the performance for a 4k machine.\\nYou didn't have to post here about how it performs on Qwen3 235B.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4oaxai","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nothing. All I said was that I&amp;#39;m not impressed with the performance for a 4k machine.\\nYou didn&amp;#39;t have to post here about how it performs on Qwen3 235B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4oaxai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753256802,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nzdyw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"created_utc":1753250468,"send_replies":true,"parent_id":"t1_n4myzhu","score":1,"author_fullname":"t2_1gpif4cz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would love to know what my M4 Max did to you.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4nzdyw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would love to know what my M4 Max did to you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4nzdyw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753250468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4myzhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4mx3ap","score":1,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fair enough, but slow for you does not mean slow for everyone else. Though there have been [some recent posts](https://www.reddit.com/r/LocalLLaMA/comments/1ky7diy/2x_instinct_mi50_32g_running_vllm_results/) showing the Mi50 doing very decently at prefill and token generation on dense models.\\n\\nNo matter how you look at it, OP's M4 Max isn't a better deal than Mi50 + Epyc, which costs 1/4 of that Mac Studio, which is the **only** point I was making.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4myzhu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fair enough, but slow for you does not mean slow for everyone else. Though there have been &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1ky7diy/2x_instinct_mi50_32g_running_vllm_results/\\"&gt;some recent posts&lt;/a&gt; showing the Mi50 doing very decently at prefill and token generation on dense models.&lt;/p&gt;\\n\\n&lt;p&gt;No matter how you look at it, OP&amp;#39;s M4 Max isn&amp;#39;t a better deal than Mi50 + Epyc, which costs 1/4 of that Mac Studio, which is the &lt;strong&gt;only&lt;/strong&gt; point I was making.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4myzhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753235331,"author_flair_text":null,"treatment_tags":[],"created_utc":1753235331,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mx3ap","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4mwuvg","score":-1,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"There have been tons of comments/posts about the Mi50/60 and Epycs.  On anything serious, it won't get near 20 tokens/second which is the minimum i\\"d consider usable for interactive work.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4mx3ap","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There have been tons of comments/posts about the Mi50/60 and Epycs.  On anything serious, it won&amp;#39;t get near 20 tokens/second which is the minimum i&amp;quot;d consider usable for interactive work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4mx3ap/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753234679,"author_flair_text":null,"treatment_tags":[],"created_utc":1753234679,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mwuvg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4mvcvn","score":2,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you have any numbers to back that up?\\n\\nMi50 has 1TB/s memory bandwidth. Epyc is not slow. I have 48 core Rome Epycs and they're anything but with MoE models, at least compared to the M4 Max OP is using.","edited":false,"author_flair_css_class":null,"name":"t1_n4mwuvg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have any numbers to back that up?&lt;/p&gt;\\n\\n&lt;p&gt;Mi50 has 1TB/s memory bandwidth. Epyc is not slow. I have 48 core Rome Epycs and they&amp;#39;re anything but with MoE models, at least compared to the M4 Max OP is using.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4mwuvg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753234598,"author_flair_text":null,"collapsed":false,"created_utc":1753234598,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mvcvn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ldgpn","score":-1,"author_fullname":"t2_wjjtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mi50 and Epyc Rome are going to be dog slow too","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mvcvn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mi50 and Epyc Rome are going to be dog slow too&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4mvcvn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753234073,"author_flair_text":null,"treatment_tags":[],"created_utc":1753234073,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ldgpn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4l6bto","score":1,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mi50 costs ~150 for 32GB VRAM. You can get 128GB VRAM system for a little over 1k.\\nA single 3090 with an Epyc Rome will also get close to that Mac Studio if you're fine with Q3 while costing ~1.5k. Mind you, that will be with 256GB at 3200 or 512GB at 2666 (which you might be able to overclock to 2933 with a bit of luck). The latter will also run higher quants or bigger models, something the Studio won't be able to do with 128GB.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ldgpn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mi50 costs ~150 for 32GB VRAM. You can get 128GB VRAM system for a little over 1k.\\nA single 3090 with an Epyc Rome will also get close to that Mac Studio if you&amp;#39;re fine with Q3 while costing ~1.5k. Mind you, that will be with 256GB at 3200 or 512GB at 2666 (which you might be able to overclock to 2933 with a bit of luck). The latter will also run higher quants or bigger models, something the Studio won&amp;#39;t be able to do with 128GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4ldgpn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753216922,"author_flair_text":null,"treatment_tags":[],"created_utc":1753216922,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l6bto","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jeremyckahn","can_mod_post":false,"created_utc":1753214947,"send_replies":true,"parent_id":"t1_n4l59p3","score":7,"author_fullname":"t2_4ii5q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are there more cost effective options?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l6bto","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are there more cost effective options?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4l6bto/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753214947,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rqnjz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rb3y7","score":1,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In the world I live in, I see 3090s I can get at that price all the time. I can get 3 or 4 more within a week or even less if I wanted to. If you have some personal reasons why you don't want to do that, that's up to you. But those prices are very much real world on planet earth.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4rqnjz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In the world I live in, I see 3090s I can get at that price all the time. I can get 3 or 4 more within a week or even less if I wanted to. If you have some personal reasons why you don&amp;#39;t want to do that, that&amp;#39;s up to you. But those prices are very much real world on planet earth.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4rqnjz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299337,"author_flair_text":null,"treatment_tags":[],"created_utc":1753299337,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rb3y7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ElementNumber6","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4oeoc8","score":1,"author_fullname":"t2_qzoa22cr","approved_by":null,"mod_note":null,"all_awardings":[],"body":"So not really representative of real world costs at all.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4rb3y7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So not really representative of real world costs at all.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4rb3y7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753294971,"author_flair_text":null,"treatment_tags":[],"created_utc":1753294971,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4oeoc8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4oec2d","score":1,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Three were bought in the small window after the crypto crash and before the AI boom. The fourth was bought recently. All bought locally searching classifieds, and negotiated price down on all four. 3090 prices are down now when I look locally.","edited":false,"author_flair_css_class":null,"name":"t1_n4oeoc8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Three were bought in the small window after the crypto crash and before the AI boom. The fourth was bought recently. All bought locally searching classifieds, and negotiated price down on all four. 3090 prices are down now when I look locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4oeoc8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753258958,"author_flair_text":null,"collapsed":false,"created_utc":1753258958,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4oec2d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cleverusernametry","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lgqrd","score":2,"author_fullname":"t2_17bfjs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How did you manage to get 4 3090s for so cheap?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oec2d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you manage to get 4 3090s for so cheap?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4oec2d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753258758,"author_flair_text":null,"treatment_tags":[],"created_utc":1753258758,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4nw331","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lt2iz","score":1,"author_fullname":"t2_1gpif4cz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah and I am missing the point while you're trying desperately to render someone else's machine useless like your religion is based on this.\\n\\nI still wonder how uploading a an AI model for others brought me your presence here complaining about Macs.\\n\\nNo, you're missing the point: Some people are happy with their Macs and might be happy to run a really great model on their machines. These people exist and this post is for them. Noone cares that you paid $1k less for your self-built machine. Yes you did well I guess but I don't even want your rig as gift, so what's the point of this?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4nw331","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah and I am missing the point while you&amp;#39;re trying desperately to render someone else&amp;#39;s machine useless like your religion is based on this.&lt;/p&gt;\\n\\n&lt;p&gt;I still wonder how uploading a an AI model for others brought me your presence here complaining about Macs.&lt;/p&gt;\\n\\n&lt;p&gt;No, you&amp;#39;re missing the point: Some people are happy with their Macs and might be happy to run a really great model on their machines. These people exist and this post is for them. Noone cares that you paid $1k less for your self-built machine. Yes you did well I guess but I don&amp;#39;t even want your rig as gift, so what&amp;#39;s the point of this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4nw331/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753248785,"author_flair_text":null,"treatment_tags":[],"created_utc":1753248785,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lt2iz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lprkr","score":0,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're completely missing the point. Model score is irrelevant here. I am talking about model size in GB. Kimi K2 at Q2_K_XL is 380GB, while Qwen3 235B at Q3_K_XL is 104GB. I can run a 3.5x larger model at almost 5tk/s. I can run the just announced Qwen3 Coder 480B at Q8, with plenty of room for KV cache on the GPU for at least 128k context. Meanwhile 480B won't run on that Mac studio even at Q2_K_M.\\n\\nThe only unimpressive part is how what you get for the money with that Mac studio. Heck, I can get a base M4 mini with my rig and it'd still cost less than that Mac studio, to answer your comment about not solely serving LLMs.","edited":false,"author_flair_css_class":null,"name":"t1_n4lt2iz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re completely missing the point. Model score is irrelevant here. I am talking about model size in GB. Kimi K2 at Q2_K_XL is 380GB, while Qwen3 235B at Q3_K_XL is 104GB. I can run a 3.5x larger model at almost 5tk/s. I can run the just announced Qwen3 Coder 480B at Q8, with plenty of room for KV cache on the GPU for at least 128k context. Meanwhile 480B won&amp;#39;t run on that Mac studio even at Q2_K_M.&lt;/p&gt;\\n\\n&lt;p&gt;The only unimpressive part is how what you get for the money with that Mac studio. Heck, I can get a base M4 mini with my rig and it&amp;#39;d still cost less than that Mac studio, to answer your comment about not solely serving LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6ocfd","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4lt2iz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753221438,"author_flair_text":null,"collapsed":false,"created_utc":1753221438,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lprkr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lgqrd","score":1,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe those machines are more than VRAM per $$$ and not everyone runs a computer solely for serving LLMs but hey.\\n\\nI found it amusing that a lower scoring Kimi Q2 seems to be impressive while the higher scoring 235b at Q3 is so unimpressive that a comment had to be written.\\n\\nNice rig tho, hope you have some PV.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lprkr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe those machines are more than VRAM per $$$ and not everyone runs a computer solely for serving LLMs but hey.&lt;/p&gt;\\n\\n&lt;p&gt;I found it amusing that a lower scoring Kimi Q2 seems to be impressive while the higher scoring 235b at Q3 is so unimpressive that a comment had to be written.&lt;/p&gt;\\n\\n&lt;p&gt;Nice rig tho, hope you have some PV.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4lprkr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753220450,"author_flair_text":null,"treatment_tags":[],"created_utc":1753220450,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lgqrd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4l87lc","score":2,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes and that machine cost me 3.3k with four 3090s. That same machine runs Qwen3 235B at Q8 or Kimi K2, which the Mac Studio can't do.\\n\\nNot sure what's so contradicting here.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lgqrd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and that machine cost me 3.3k with four 3090s. That same machine runs Qwen3 235B at Q8 or Kimi K2, which the Mac Studio can&amp;#39;t do.&lt;/p&gt;\\n\\n&lt;p&gt;Not sure what&amp;#39;s so contradicting here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4lgqrd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217820,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217820,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l87lc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"created_utc":1753215469,"send_replies":true,"parent_id":"t1_n4l59p3","score":-1,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This you? 😄\\n\\nhttps://preview.redd.it/tgusippkhhef1.png?width=673&amp;format=png&amp;auto=webp&amp;s=aad888c5b489bb03ce77161b14a1a19779a54641","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l87lc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This you? 😄&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/tgusippkhhef1.png?width=673&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aad888c5b489bb03ce77161b14a1a19779a54641\\"&gt;https://preview.redd.it/tgusippkhhef1.png?width=673&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aad888c5b489bb03ce77161b14a1a19779a54641&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4l87lc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753215469,"media_metadata":{"tgusippkhhef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":15,"x":108,"u":"https://preview.redd.it/tgusippkhhef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f357c83097d3a408e65003f97c3a988fdfa353a"},{"y":30,"x":216,"u":"https://preview.redd.it/tgusippkhhef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=67593fcb0b6ed03cf006e549f80847d4eebd767b"},{"y":44,"x":320,"u":"https://preview.redd.it/tgusippkhhef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fdbe4623954a2bb6301a7c5b5a1cf665d7a12442"},{"y":89,"x":640,"u":"https://preview.redd.it/tgusippkhhef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=642a62bbfa04a267ff9918aff2741574ef61133d"}],"s":{"y":94,"x":673,"u":"https://preview.redd.it/tgusippkhhef1.png?width=673&amp;format=png&amp;auto=webp&amp;s=aad888c5b489bb03ce77161b14a1a19779a54641"},"id":"tgusippkhhef1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lg7mh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4l7ace","score":0,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"True, but that's also a bad decision IMO if you're not actually making money out of those tokens.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lg7mh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;True, but that&amp;#39;s also a bad decision IMO if you&amp;#39;re not actually making money out of those tokens.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4lg7mh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217673,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217673,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l7ace","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"created_utc":1753215214,"send_replies":true,"parent_id":"t1_n4l59p3","score":-1,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not worse than than buying a 2.5k GPU to run qwen3:32b Q4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l7ace","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not worse than than buying a 2.5k GPU to run qwen3:32b Q4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4l7ace/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753215214,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l59p3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1753214653,"send_replies":true,"parent_id":"t3_1m6ocfd","score":3,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"4k to run at Q3. Color me unimpressed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l59p3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4k to run at Q3. Color me unimpressed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4l59p3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753214653,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4oeqd2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waescher","can_mod_post":false,"created_utc":1753258989,"send_replies":true,"parent_id":"t1_n4oekjk","score":2,"author_fullname":"t2_1gpif4cz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Larger context only up to 8192 tokens. Pretty sure Q4 will easily fit your M3 Ultra.\\n\\nEdit: Check the Ollama library link, I added some details there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oeqd2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Larger context only up to 8192 tokens. Pretty sure Q4 will easily fit your M3 Ultra.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Check the Ollama library link, I added some details there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6ocfd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4oeqd2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753258989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4oekjk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cleverusernametry","can_mod_post":false,"created_utc":1753258896,"send_replies":true,"parent_id":"t3_1m6ocfd","score":1,"author_fullname":"t2_17bfjs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it worth going to Q4 on my M3 Ultra 256GB? \\n\\nDid you test performance and memory uaabe With a large context?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oekjk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it worth going to Q4 on my M3 Ultra 256GB? &lt;/p&gt;\\n\\n&lt;p&gt;Did you test performance and memory uaabe With a large context?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6ocfd/the_llm_for_m4_max_128gb_unsloth/n4oekjk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753258896,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6ocfd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
