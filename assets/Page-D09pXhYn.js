import{j as e}from"./index-CWmJdUH_.js";import{R as l}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"The Truth About LLMs","link_flair_richtext":[{"e":"text","t":"Funny"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":101,"top_awarded_type":null,"hide_score":false,"name":"t3_1bgh9h4","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.94,"author_flair_background_color":null,"ups":1867,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_ueqnbegxa","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Funny","can_mod_post":false,"score":1867,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/__8WoHto0GnvcMwZF0buC1RwAqY_ivcdFUwyexr6-UM.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1710626274,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/sjiy0f35qroc1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/sjiy0f35qroc1.png?auto=webp&amp;s=934cd1019721ee421ac9c11e830910ef90c0bebf","width":1005,"height":727},"resolutions":[{"url":"https://preview.redd.it/sjiy0f35qroc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a1cfa866e3f488fd19eabcf8c411c6f7f198d45","width":108,"height":78},{"url":"https://preview.redd.it/sjiy0f35qroc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbb688057ca49fece3e2e6370b040c8d292df5c9","width":216,"height":156},{"url":"https://preview.redd.it/sjiy0f35qroc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe3a41017ca14f4084bb55f4b8cda0050e3d32db","width":320,"height":231},{"url":"https://preview.redd.it/sjiy0f35qroc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d364c6c45602d5ec3d476dbddd2225243092654e","width":640,"height":462},{"url":"https://preview.redd.it/sjiy0f35qroc1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=933899e58b53d379068801b6e14d9e7ec3bae1a8","width":960,"height":694}],"variants":{},"id":"pbYDPNYKQFv12htLgRND0zotr5ilsftwQgqv0Qg0MrE"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"65c366b0-bf8e-11ed-86ac-725137141d5f","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#0dd3bb","id":"1bgh9h4","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"JeepyTea","discussion_type":null,"num_comments":326,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/","stickied":false,"url":"https://i.redd.it/sjiy0f35qroc1.png","subreddit_subscribers":492315,"created_utc":1710626274,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvg3t77","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Amgadoz","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7c789","score":10,"author_fullname":"t2_3el21u3z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Username checks out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvg3t77","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Username checks out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvg3t77/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710779734,"author_flair_text":null,"treatment_tags":[],"created_utc":1710779734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9eeoj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Odd-Antelope-362","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7c789","score":11,"author_fullname":"t2_vxhquhmw0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This killed my iPhone. Will try to open it on my gaming PC later.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9eeoj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This killed my iPhone. Will try to open it on my gaming PC later.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9eeoj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710669328,"author_flair_text":null,"treatment_tags":[],"created_utc":1710669328,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvijnwj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvih5m2","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Happy cake day dude. Thanks for the explanation.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Happy cake day dude. Thanks for the explanation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvijnwj/","num_reports":null,"locked":false,"name":"t1_kvijnwj","created":1710810524,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710810524,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":3,"name":"t1_kvtcnmx","id":"kvtcnmx","parent_id":"t1_kvih5m2","depth":4,"children":["kvtcnmx","m6jcn96"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvih5m2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jabies","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvggzma","score":18,"author_fullname":"t2_4zcpj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Imagine you have a connotation matrix for every word. It mostly makes sense within the context of a dataset because you have to assign arbitrarily.\\n\\nYou might have a value in a the matrix that indicates how wet, an object is, how blue an object is, and how big an object is. We'll do a range of -10 to 10 for this exercise. \\n\\nLet's say you had the words volcano, ocean, river, rock, and fire.  You could assign matrix for each word that makes sense in your data set. Volcano is maybe -10 wet, and 10 for size. Fire is maybe -9 wet, 5 for size. Ocean is very blue, very wet, and very large. 10, 10, 10. Let's say we want to take the idea of something wet, blue, and not the biggest\\n ever. 5,5,5  sound right? Maybe a lake?\\nAuto regressive LLMs work by trying to predict the connotation of the next word, given the past words of the sentence. They don't actually know language. They approximate meaning using statistics, then work backwards to figure out what word is the closest to the target vector.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvih5m2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imagine you have a connotation matrix for every word. It mostly makes sense within the context of a dataset because you have to assign arbitrarily.&lt;/p&gt;\\n\\n&lt;p&gt;You might have a value in a the matrix that indicates how wet, an object is, how blue an object is, and how big an object is. We&amp;#39;ll do a range of -10 to 10 for this exercise. &lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s say you had the words volcano, ocean, river, rock, and fire.  You could assign matrix for each word that makes sense in your data set. Volcano is maybe -10 wet, and 10 for size. Fire is maybe -9 wet, 5 for size. Ocean is very blue, very wet, and very large. 10, 10, 10. Let&amp;#39;s say we want to take the idea of something wet, blue, and not the biggest\\n ever. 5,5,5  sound right? Maybe a lake?\\nAuto regressive LLMs work by trying to predict the connotation of the next word, given the past words of the sentence. They don&amp;#39;t actually know language. They approximate meaning using statistics, then work backwards to figure out what word is the closest to the target vector.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvih5m2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710809548,"author_flair_text":null,"treatment_tags":[],"created_utc":1710809548,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"kvggzma","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1710784175,"send_replies":true,"parent_id":"t1_kv7c789","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I don't understand what is this? Eli5 pwease","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t understand what is this? Eli5 pwease&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvggzma/","num_reports":null,"locked":false,"name":"t1_kvggzma","created":1710784175,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7c789","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Research2Vec","can_mod_post":false,"created_utc":1710629571,"send_replies":true,"parent_id":"t1_kv7a5yu","score":78,"author_fullname":"t2_25c2pypq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you might like this \\n\\nhttps://github.com/Santosh-Gupta/Lit2Vec?tab=readme-ov-file#arithmetic-properties\\n\\nit applies to books as well","edited":1710707257,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7c789","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you might like this &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/Santosh-Gupta/Lit2Vec?tab=readme-ov-file#arithmetic-properties\\"&gt;https://github.com/Santosh-Gupta/Lit2Vec?tab=readme-ov-file#arithmetic-properties&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;it applies to books as well&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7c789/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629571,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":78}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kv9z50h","id":"kv9z50h","parent_id":"t1_kv95dz4","depth":6,"children":["kv9z50h"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv95dz4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv94e62","score":23,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe. But word vectors are derived from *huge* amounts of text. Any untranslated language with such a large corpus would be easy to translate for humans anyway. All ancient languages that are still undeciphered, such as Linear A, have a tiny corpus of extant text (just a single page's worth for some of them).","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv95dz4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe. But word vectors are derived from &lt;em&gt;huge&lt;/em&gt; amounts of text. Any untranslated language with such a large corpus would be easy to translate for humans anyway. All ancient languages that are still undeciphered, such as Linear A, have a tiny corpus of extant text (just a single page&amp;#39;s worth for some of them).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv95dz4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710662449,"author_flair_text":null,"treatment_tags":[],"created_utc":1710662449,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9sd1j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LumpyWelds","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv94e62","score":8,"author_fullname":"t2_32hdazgq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thats the idea at least.  Beyond dead languages, they are hoping to use this underlying language structure similarity to try and decode cetacean (sounds/speech).\\n\\nBut I'm not sure Cetacean language will map easily.\\n\\n&amp;#x200B;\\n\\n&gt;\\\\[Humans\\\\] combine phonemes to produce words, words to produce phrases, phrases in to sentences, sentences in to paragraph, etc. that´s the hierarchical organization. Dolphins produce simple elements that are individual whistles or pulsed sounds and they combine them to form blocks of first order. They combine 1st order blocks to form 2nd order blocks, etc. Stable blocks of up to 7th order of complexity have been evidenced.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv9sd1j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thats the idea at least.  Beyond dead languages, they are hoping to use this underlying language structure similarity to try and decode cetacean (sounds/speech).&lt;/p&gt;\\n\\n&lt;p&gt;But I&amp;#39;m not sure Cetacean language will map easily.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;[Humans] combine phonemes to produce words, words to produce phrases, phrases in to sentences, sentences in to paragraph, etc. that´s the hierarchical organization. Dolphins produce simple elements that are individual whistles or pulsed sounds and they combine them to form blocks of first order. They combine 1st order blocks to form 2nd order blocks, etc. Stable blocks of up to 7th order of complexity have been evidenced.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9sd1j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710678560,"author_flair_text":null,"treatment_tags":[],"created_utc":1710678560,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9qzli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ExTrainMe","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv94e62","score":3,"author_fullname":"t2_jiww9cwd","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Now I'm honestly curious if we could make a semantic map like that for existing languages and run a diff on them","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv9qzli","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now I&amp;#39;m honestly curious if we could make a semantic map like that for existing languages and run a diff on them&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9qzli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710677808,"author_flair_text":null,"treatment_tags":[],"created_utc":1710677808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvapd0k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sobsz","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv94e62","score":2,"author_fullname":"t2_pj2b9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"[google did it 2 years ago](https://blog.research.google/2022/05/24-new-languages-google-translate.html) ([paper](https://arxiv.org/abs/2205.03983)), or rather they threw data and compute at it","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kvapd0k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://blog.research.google/2022/05/24-new-languages-google-translate.html\\"&gt;google did it 2 years ago&lt;/a&gt; (&lt;a href=\\"https://arxiv.org/abs/2205.03983\\"&gt;paper&lt;/a&gt;), or rather they threw data and compute at it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvapd0k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710691952,"author_flair_text":null,"treatment_tags":[],"created_utc":1710691952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv94e62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HeftyCanker","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8mp37","score":24,"author_fullname":"t2_qpqybeppt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If a large enough sample of a dead, untranslated language existed, could it be 'translated' by mapping out these semantic relationships between words and comparing the shape of the map of these relationships to the shape of maps of known languages?","edited":false,"author_flair_css_class":null,"name":"t1_kv94e62","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If a large enough sample of a dead, untranslated language existed, could it be &amp;#39;translated&amp;#39; by mapping out these semantic relationships between words and comparing the shape of the map of these relationships to the shape of maps of known languages?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv94e62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710661677,"author_flair_text":null,"collapsed":false,"created_utc":1710661677,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9gnmd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8mp37","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"It’s like people tend to forget the historical context in which language developed and as such that it has by evolution developed into an efficient method of transferring information.\\n\\nThe fact that so many people bullshit smalltalk all the time undermines that even further.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s like people tend to forget the historical context in which language developed and as such that it has by evolution developed into an efficient method of transferring information.&lt;/p&gt;\\n\\n&lt;p&gt;The fact that so many people bullshit smalltalk all the time undermines that even further.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9gnmd/","num_reports":null,"locked":false,"name":"t1_kv9gnmd","created":1710670999,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710670999,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9fns4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8mp37","score":2,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well sure, but while learning how to do math is the best way to compress a large sequence of numbers it's no less amazing that a bunch of glorified if sentences can learn to do it by just tweaking based on data.","edited":false,"author_flair_css_class":null,"name":"t1_kv9fns4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well sure, but while learning how to do math is the best way to compress a large sequence of numbers it&amp;#39;s no less amazing that a bunch of glorified if sentences can learn to do it by just tweaking based on data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9fns4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670261,"author_flair_text":null,"collapsed":false,"created_utc":1710670261,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":3,"name":"t1_kvbjl60","id":"kvbjl60","parent_id":"t1_kv8mp37","depth":4,"children":["kvbjl60","kvb2a9j"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8mp37","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7e6n4","score":71,"author_fullname":"t2_dkgrhaet","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The mystery dissolves (to some extent) once you realize that semantic relations are the most efficient way to represent information. The shortest description of the string *\\"January, February, March, April, May, June, July, August, September, October, November, December* is *\\"The Twelve Months\\"*. Semantic insight is the key to compressing knowledge.\\n\\nTherefore, when you take the reverse route of forcing information to compress, such as by mapping words to vectors that roughly encode their contextual distance in a (relatively) low-dimensional space, it's not completely crazy to expect that such a mapping would capture semantic relationships.\\n\\nTo be sure, lots of things could go wrong, and that it works so well is certainly surprising, but it's not as if the whole thing comes from thin air.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8mp37","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The mystery dissolves (to some extent) once you realize that semantic relations are the most efficient way to represent information. The shortest description of the string &lt;em&gt;&amp;quot;January, February, March, April, May, June, July, August, September, October, November, December&lt;/em&gt; is &lt;em&gt;&amp;quot;The Twelve Months&amp;quot;&lt;/em&gt;. Semantic insight is the key to compressing knowledge.&lt;/p&gt;\\n\\n&lt;p&gt;Therefore, when you take the reverse route of forcing information to compress, such as by mapping words to vectors that roughly encode their contextual distance in a (relatively) low-dimensional space, it&amp;#39;s not completely crazy to expect that such a mapping would capture semantic relationships.&lt;/p&gt;\\n\\n&lt;p&gt;To be sure, lots of things could go wrong, and that it works so well is certainly surprising, but it&amp;#39;s not as if the whole thing comes from thin air.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8mp37/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710649854,"author_flair_text":null,"treatment_tags":[],"created_utc":1710649854,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":71}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7tfa8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mekanimal","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7e6n4","score":12,"author_fullname":"t2_h5xqk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't want to claim understanding or anything, but *holy shit*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7tfa8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t want to claim understanding or anything, but &lt;em&gt;holy shit&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7tfa8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636576,"author_flair_text":null,"treatment_tags":[],"created_utc":1710636576,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":10,"name":"t1_kv98qgy","id":"kv98qgy","parent_id":"t1_kv98dow","depth":5,"children":["kv98qgy","kyvoujz"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv98dow","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"InterstitialLove","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8j5yj","score":9,"author_fullname":"t2_b42k1qb3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not sure I understand what you're saying, but textual inversion fits very well in this framework.\\n\\nImagine we didn't have a word in English for the concept of \\"queen.\\" You can imagine taking \\"king - man + woman\\" and getting a vector that doesn't correspond to any actual existing english word, but the vector still has meaning. If you feed that vector into your model, it'll spit out a female king\\n\\nThere are concepts in reality that we don't have precise words for, so textual inversion finds the vector corresponding to a hypothetical word with that exact meaning.","edited":false,"author_flair_css_class":null,"name":"t1_kv98dow","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure I understand what you&amp;#39;re saying, but textual inversion fits very well in this framework.&lt;/p&gt;\\n\\n&lt;p&gt;Imagine we didn&amp;#39;t have a word in English for the concept of &amp;quot;queen.&amp;quot; You can imagine taking &amp;quot;king - man + woman&amp;quot; and getting a vector that doesn&amp;#39;t correspond to any actual existing english word, but the vector still has meaning. If you feed that vector into your model, it&amp;#39;ll spit out a female king&lt;/p&gt;\\n\\n&lt;p&gt;There are concepts in reality that we don&amp;#39;t have precise words for, so textual inversion finds the vector corresponding to a hypothetical word with that exact meaning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv98dow/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710664761,"author_flair_text":null,"collapsed":false,"created_utc":1710664761,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8j5yj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnOnlineHandle","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7e6n4","score":3,"author_fullname":"t2_5xsr5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's how I understood embeddings for a long time, but it turns out it isn't really needed. Using textual inversion in SD, you can find an embedding for a concept starting from almost anywhere in the distribution and not moving the weights very much. I'm not sure how it works, maybe it's more about a few key relative weights which act as keys.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8j5yj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s how I understood embeddings for a long time, but it turns out it isn&amp;#39;t really needed. Using textual inversion in SD, you can find an embedding for a concept starting from almost anywhere in the distribution and not moving the weights very much. I&amp;#39;m not sure how it works, maybe it&amp;#39;s more about a few key relative weights which act as keys.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8j5yj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710648000,"author_flair_text":null,"treatment_tags":[],"created_utc":1710648000,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv84hdu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triccer","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv81lel","score":3,"author_fullname":"t2_9m8si","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think I'm somewhat in this camp, that analogy/example needs extrapolation or context or something.","edited":false,"author_flair_css_class":null,"name":"t1_kv84hdu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think I&amp;#39;m somewhat in this camp, that analogy/example needs extrapolation or context or something.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv84hdu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710641258,"author_flair_text":null,"collapsed":false,"created_utc":1710641258,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv81lel","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bch8","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7e6n4","score":15,"author_fullname":"t2_b6ekp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So if I think I understand it and this still just seems like extremely cringe and over the top reverence, does that just mean I don't actually understand? Right now all this thread reads to me as is \\"i am euphoric\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv81lel","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So if I think I understand it and this still just seems like extremely cringe and over the top reverence, does that just mean I don&amp;#39;t actually understand? Right now all this thread reads to me as is &amp;quot;i am euphoric&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv81lel/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710640022,"author_flair_text":null,"treatment_tags":[],"created_utc":1710640022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7e6n4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darien_gap","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7aota","score":161,"author_fullname":"t2_3wakr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s the common example given to demonstrate how words converted into vector embeddings are able to capture actual semantic meaning, and you can tell how well someone understands what this means by how much their mind is blown.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7e6n4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s the common example given to demonstrate how words converted into vector embeddings are able to capture actual semantic meaning, and you can tell how well someone understands what this means by how much their mind is blown.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7e6n4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710630370,"author_flair_text":null,"treatment_tags":[],"created_utc":1710630370,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":161}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kv7e3in","id":"kv7e3in","parent_id":"t1_kv7bbyx","depth":3,"children":["kv7e3in"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7bbyx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mythicinfinity","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7aota","score":56,"author_fullname":"t2_s29nlx61","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"word2vec IIRC","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7bbyx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;word2vec IIRC&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7bbyx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629226,"author_flair_text":null,"treatment_tags":[],"created_utc":1710629226,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":56}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7bpd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mattindustries","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7aota","score":25,"author_fullname":"t2_2ypfs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Essentially word coordinates in high dimensional space based on context of usage. Check out glove embeddings.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7bpd3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Essentially word coordinates in high dimensional space based on context of usage. Check out glove embeddings.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7bpd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629376,"author_flair_text":null,"treatment_tags":[],"created_utc":1710629376,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7t0e7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"West-Code4642","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7aota","score":8,"author_fullname":"t2_ts7kvjmm9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it's a distributed representation.  \\n\\njeff dean (google's chief scientist) describes it simply here:\\n\\n[https://youtu.be/oSCRZkSQ1CE?si=bbGA\\\\_4cyjw7d6tgq&amp;t=968](https://youtu.be/oSCRZkSQ1CE?si=bbGA_4cyjw7d6tgq&amp;t=968)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7t0e7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s a distributed representation.  &lt;/p&gt;\\n\\n&lt;p&gt;jeff dean (google&amp;#39;s chief scientist) describes it simply here:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://youtu.be/oSCRZkSQ1CE?si=bbGA_4cyjw7d6tgq&amp;amp;t=968\\"&gt;https://youtu.be/oSCRZkSQ1CE?si=bbGA_4cyjw7d6tgq&amp;amp;t=968&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7t0e7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636401,"author_flair_text":null,"treatment_tags":[],"created_utc":1710636401,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcnyv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7aota","score":1,"author_fullname":"t2_8854dtzyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that's what i'm saying!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m6jcnyv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that&amp;#39;s what i&amp;#39;m saying!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcnyv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736575049,"author_flair_text":null,"treatment_tags":[],"created_utc":1736575049,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7aota","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emrys95","can_mod_post":false,"created_utc":1710628965,"send_replies":true,"parent_id":"t1_kv7a5yu","score":35,"author_fullname":"t2_2bpeblwv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What is that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7aota","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7aota/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710628965,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvjbunl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ImportantCow5","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv98w02","score":3,"author_fullname":"t2_5ets16yo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's because the embedding space itself might be curved, so you need to adjust the way you transform your embedding vectors accordingly.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvjbunl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s because the embedding space itself might be curved, so you need to adjust the way you transform your embedding vectors accordingly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvjbunl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710823042,"author_flair_text":null,"treatment_tags":[],"created_utc":1710823042,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv98w02","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MrVodnik","can_mod_post":false,"created_utc":1710665154,"send_replies":true,"parent_id":"t1_kv7a5yu","score":10,"author_fullname":"t2_ov1sf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In the name of sharing knowledge and experience: it's not as pretty as they claim :(\\n\\nI've tried to implement it myself and it \\"kinda\\" works, but I ate my teeth before understanding the nuances. \\n\\nIn reality, \\"king - man + woman\\" equals... \\"king\\". The vector is just slightly tilted towards queen. The equation works only:\\n\\n- for specific equations (for many others it either does not make sense, or is way less predicatble)\\n\\n- only if the \\"expected\\" output word is the nearest to the initial word (in a specific direction)\\n\\n- if you discard the initial word from the output (just pick the second, or third, or just any that was not present in the equation).\\n\\n  \\nAfterwards I've found a good blog post about it:\\n\\n[https://medium.com/plotly/understanding-word-embedding-arithmetic-why-theres-no-single-answer-to-king-man-woman-cd2760e2cb7f](https://medium.com/plotly/understanding-word-embedding-arithmetic-why-theres-no-single-answer-to-king-man-woman-cd2760e2cb7f)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv98w02","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In the name of sharing knowledge and experience: it&amp;#39;s not as pretty as they claim :(&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve tried to implement it myself and it &amp;quot;kinda&amp;quot; works, but I ate my teeth before understanding the nuances. &lt;/p&gt;\\n\\n&lt;p&gt;In reality, &amp;quot;king - man + woman&amp;quot; equals... &amp;quot;king&amp;quot;. The vector is just slightly tilted towards queen. The equation works only:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;for specific equations (for many others it either does not make sense, or is way less predicatble)&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;only if the &amp;quot;expected&amp;quot; output word is the nearest to the initial word (in a specific direction)&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;if you discard the initial word from the output (just pick the second, or third, or just any that was not present in the equation).&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Afterwards I&amp;#39;ve found a good blog post about it:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://medium.com/plotly/understanding-word-embedding-arithmetic-why-theres-no-single-answer-to-king-man-woman-cd2760e2cb7f\\"&gt;https://medium.com/plotly/understanding-word-embedding-arithmetic-why-theres-no-single-answer-to-king-man-woman-cd2760e2cb7f&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv98w02/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710665154,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7uscc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mkep","can_mod_post":false,"created_utc":1710637140,"send_replies":true,"parent_id":"t1_kv7a5yu","score":8,"author_fullname":"t2_97ads","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This works with CLIP embeddings too","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7uscc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This works with CLIP embeddings too&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7uscc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710637140,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9277q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"terp-bick","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7y3ko","score":3,"author_fullname":"t2_srlz8but9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"infiniteCraft uses a prompt to generate the receipes I think, maybe using the actual embedding space or whatever could yield better results","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9277q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;infiniteCraft uses a prompt to generate the receipes I think, maybe using the actual embedding space or whatever could yield better results&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9277q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710659991,"author_flair_text":null,"treatment_tags":[],"created_utc":1710659991,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7y3ko","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ansible32","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ew1r","score":9,"author_fullname":"t2_72uqo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Someone posted that on Hacker News recently. I actually thought it was kind of dumb because a lot of the recipes the LLM generated didn't make any sense. Actually I think Infinite Craft is the LLM one. The original was Little Alchemy.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7y3ko","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone posted that on Hacker News recently. I actually thought it was kind of dumb because a lot of the recipes the LLM generated didn&amp;#39;t make any sense. Actually I think Infinite Craft is the LLM one. The original was Little Alchemy.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7y3ko/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638525,"author_flair_text":null,"treatment_tags":[],"created_utc":1710638525,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv993or","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Saltysalad","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ew1r","score":3,"author_fullname":"t2_6kgt6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Look into word2vec. TLDR it is a numerical representation of words that results in similar words having similar numerical representations.\\n\\nhttps://en.wikipedia.org/wiki/Word2vec\\n\\nYou can also get sentence level representations with sentence embedding models: https://www.sbert.netdocs/quickstart.html","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv993or","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Look into word2vec. TLDR it is a numerical representation of words that results in similar words having similar numerical representations.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/Word2vec\\"&gt;https://en.wikipedia.org/wiki/Word2vec&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;You can also get sentence level representations with sentence embedding models: &lt;a href=\\"https://www.sbert.netdocs/quickstart.html\\"&gt;https://www.sbert.netdocs/quickstart.html&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv993or/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710665321,"author_flair_text":null,"treatment_tags":[],"created_utc":1710665321,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8jic4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maykey","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ew1r","score":2,"author_fullname":"t2_17tuu7pv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can try to play like with pretty much any model if they have words in vocab. \\nThough in several I tried(gemma, open llama, tiny llama) \`king\` is still closer than \`queen\`.\\n\\n&gt;That could be used for a much better version of InfiniteCraft lol\\n\\nCheck [semantle](https://semantle.com/). It's like wordle but instead of letters you are given a distance between your guess and the word.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv8jic4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can try to play like with pretty much any model if they have words in vocab. \\nThough in several I tried(gemma, open llama, tiny llama) &lt;code&gt;king&lt;/code&gt; is still closer than &lt;code&gt;queen&lt;/code&gt;.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;That could be used for a much better version of InfiniteCraft lol&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Check &lt;a href=\\"https://semantle.com/\\"&gt;semantle&lt;/a&gt;. It&amp;#39;s like wordle but instead of letters you are given a distance between your guess and the word.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8jic4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710648172,"author_flair_text":null,"treatment_tags":[],"created_utc":1710648172,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7ew1r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"terp-bick","can_mod_post":false,"created_utc":1710630655,"send_replies":true,"parent_id":"t1_kv7a5yu","score":5,"author_fullname":"t2_srlz8but9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Where is that from? That could be used for a much better version of InfiniteCraft lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7ew1r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where is that from? That could be used for a much better version of InfiniteCraft lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7ew1r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710630655,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9axg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Teleswagz","can_mod_post":false,"created_utc":1710666715,"send_replies":true,"parent_id":"t1_kv7a5yu","score":3,"author_fullname":"t2_q8fyk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I remember reading that in the paper and thinking, \\"man this is really simple but cool as hell\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9axg6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I remember reading that in the paper and thinking, &amp;quot;man this is really simple but cool as hell&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9axg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710666715,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvauin8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rrenaud","can_mod_post":false,"created_utc":1710693758,"send_replies":true,"parent_id":"t1_kv7a5yu","score":3,"author_fullname":"t2_88az","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I also remember being mind blown.  But after the fact, I almost feel like it's cherry picked.  It's too easy.  English is so gendered in precisely the right way to make the \\"king - man + woman = queen\\" vector math work.  Unlike Turkish, we have gendered pronouns.  Unlike Spanish, we don't gender the moon.  \\n\\n    (-1 * man + 1 * woman)\\n\\nThat has got to be the most easy semantic directions to model in the English language.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvauin8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I also remember being mind blown.  But after the fact, I almost feel like it&amp;#39;s cherry picked.  It&amp;#39;s too easy.  English is so gendered in precisely the right way to make the &amp;quot;king - man + woman = queen&amp;quot; vector math work.  Unlike Turkish, we have gendered pronouns.  Unlike Spanish, we don&amp;#39;t gender the moon.  &lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;(-1 * man + 1 * woman)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;That has got to be the most easy semantic directions to model in the English language.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvauin8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710693758,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvpir41","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lethal_can_of_tuna","can_mod_post":false,"created_utc":1710926833,"send_replies":true,"parent_id":"t1_kv7a5yu","score":3,"author_fullname":"t2_ib9ucs5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait till you learn about representation engineering: https://github.com/vgel/repeng\\n\\nEssentially you add a vector to adjust an LLM's output in a certain direction. For example, you can give an LLM a query and a vector, such as an emotion like sadness, and it'll provide a range of responses adjusted against that vector. So you could get a very sad response or the opposite - a really happy response.\\n\\nHere are some example notebooks:\\nhttps://github.com/vgel/repeng/blob/main/notebooks/emotion.ipynb\\nhttps://github.com/vgel/repeng/blob/main/notebooks/honesty.ipynb","edited":1710927054,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvpir41","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait till you learn about representation engineering: &lt;a href=\\"https://github.com/vgel/repeng\\"&gt;https://github.com/vgel/repeng&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Essentially you add a vector to adjust an LLM&amp;#39;s output in a certain direction. For example, you can give an LLM a query and a vector, such as an emotion like sadness, and it&amp;#39;ll provide a range of responses adjusted against that vector. So you could get a very sad response or the opposite - a really happy response.&lt;/p&gt;\\n\\n&lt;p&gt;Here are some example notebooks:\\n&lt;a href=\\"https://github.com/vgel/repeng/blob/main/notebooks/emotion.ipynb\\"&gt;https://github.com/vgel/repeng/blob/main/notebooks/emotion.ipynb&lt;/a&gt;\\n&lt;a href=\\"https://github.com/vgel/repeng/blob/main/notebooks/honesty.ipynb\\"&gt;https://github.com/vgel/repeng/blob/main/notebooks/honesty.ipynb&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvpir41/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710926833,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8au2h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7a5yu","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"proves it's magical linear algebra.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;proves it&amp;#39;s magical linear algebra.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8au2h/","num_reports":null,"locked":false,"name":"t1_kv8au2h","created":1710644024,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710644024,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv98vut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InterstitialLove","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8shag","score":3,"author_fullname":"t2_b42k1qb3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The LLM decomposes each string into tokens and gives each token an embedding. You can add two tokens together, but it's not clear how you'd add the whole sentence. Maybe if the sentences were the exact same length (in tokens) you could do it, but you'd be adding word-by-word. What you want is sentence2vec, this is word2vec\\n\\nNow, it seems plausible that the attention mechanism often leads to some embeddings that encode not just a single word but an entire phrase or maybe the whole sentence or multiple sentences. As far as I know, we can't actually locate this embedding, we just suspect that it is in there somewhere, sometimes","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv98vut","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The LLM decomposes each string into tokens and gives each token an embedding. You can add two tokens together, but it&amp;#39;s not clear how you&amp;#39;d add the whole sentence. Maybe if the sentences were the exact same length (in tokens) you could do it, but you&amp;#39;d be adding word-by-word. What you want is sentence2vec, this is word2vec&lt;/p&gt;\\n\\n&lt;p&gt;Now, it seems plausible that the attention mechanism often leads to some embeddings that encode not just a single word but an entire phrase or maybe the whole sentence or multiple sentences. As far as I know, we can&amp;#39;t actually locate this embedding, we just suspect that it is in there somewhere, sometimes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv98vut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710665150,"author_flair_text":null,"treatment_tags":[],"created_utc":1710665150,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8shag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"I-am_Sleepy","can_mod_post":false,"created_utc":1710653201,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_8r6wb3jy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does this property still hold if the input is a sentence for current LLM? Like - “King is a ruler of a Kingdom” - “Man, gender” + “Woman, gender”. Does it decoded “Queen is a ruler of a Kingdom”?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8shag","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does this property still hold if the input is a sentence for current LLM? Like - “King is a ruler of a Kingdom” - “Man, gender” + “Woman, gender”. Does it decoded “Queen is a ruler of a Kingdom”?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8shag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710653201,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvacb9z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"800808","can_mod_post":false,"created_utc":1710687219,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_4u2fpy6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I like the example:\\n\\nMan + V = King\\n\\nQueen - V = woman \\n\\nI think it reveals that we also occasionally have terms to describe the symbolic distance, in this case “royalty”","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvacb9z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like the example:&lt;/p&gt;\\n\\n&lt;p&gt;Man + V = King&lt;/p&gt;\\n\\n&lt;p&gt;Queen - V = woman &lt;/p&gt;\\n\\n&lt;p&gt;I think it reveals that we also occasionally have terms to describe the symbolic distance, in this case “royalty”&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvacb9z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710687219,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvbm6gz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"darien_gap","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvaph0i","score":2,"author_fullname":"t2_3wakr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Start here, Chris Manning's Stanford class (CS224N), free lectures on YouTube:\\n\\nhttps://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvbm6gz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Start here, Chris Manning&amp;#39;s Stanford class (CS224N), free lectures on YouTube:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ\\"&gt;https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvbm6gz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710703359,"author_flair_text":null,"treatment_tags":[],"created_utc":1710703359,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kvaph0i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"freecodeio","can_mod_post":false,"created_utc":1710691992,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_1oeu2j1o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can someone tell me where and how can I do this stuff because I find it fascinating","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvaph0i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone tell me where and how can I do this stuff because I find it fascinating&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvaph0i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710691992,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvdcu94","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Philiatrist","can_mod_post":false,"created_utc":1710727211,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_54jdp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We optimize how well words with similar context cluster, and this is what we get.  The precision is surprising but the general result is not so mysterious.\\n\\nking - man = queen - woman\\n\\nking - queen = man - woman\\n\\nall equivalent statements (though the equals sign here is not actually mathematically rigorous since the words themselves are basically just the closest defined vector)","edited":1710727661,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvdcu94","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We optimize how well words with similar context cluster, and this is what we get.  The precision is surprising but the general result is not so mysterious.&lt;/p&gt;\\n\\n&lt;p&gt;king - man = queen - woman&lt;/p&gt;\\n\\n&lt;p&gt;king - queen = man - woman&lt;/p&gt;\\n\\n&lt;p&gt;all equivalent statements (though the equals sign here is not actually mathematically rigorous since the words themselves are basically just the closest defined vector)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvdcu94/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710727211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvdwopn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"unlikely-contender","can_mod_post":false,"created_utc":1710737018,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_1rlboa8x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try \\"truck driver - man + woman\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvdwopn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try &amp;quot;truck driver - man + woman&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvdwopn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710737018,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvkrpan","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CanvasFanatic","can_mod_post":false,"created_utc":1710855520,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_j96kdhu4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvkrpan","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvkrpan/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710855520,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcei2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"created_utc":1736574911,"send_replies":true,"parent_id":"t1_kv7a5yu","score":1,"author_fullname":"t2_8854dtzyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"darious","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6jcei2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;darious&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcei2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736574911,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_kv8n5yq","id":"kv8n5yq","parent_id":"t1_kv7a5yu","depth":1,"children":["kv8n5yq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7a5yu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darien_gap","can_mod_post":false,"created_utc":1710628750,"send_replies":true,"parent_id":"t3_1bgh9h4","score":339,"author_fullname":"t2_3wakr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"king - man + woman = queen\\" still gives me chills.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7a5yu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;king - man + woman = queen&amp;quot; still gives me chills.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7a5yu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710628750,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":339}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":139,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9n5uv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"glacierre2","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv77w1o","score":12,"author_fullname":"t2_qcxnj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I though it was mermaid underwear. AlgaeBra.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9n5uv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I though it was mermaid underwear. AlgaeBra.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9n5uv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710675518,"author_flair_text":null,"treatment_tags":[],"created_utc":1710675518,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9m49e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Harvard_Med_USMLE267","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv96h5o","score":4,"author_fullname":"t2_4z9wumnt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"More like a 5.5/10 dad joke…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9m49e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More like a 5.5/10 dad joke…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9m49e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710674831,"author_flair_text":null,"treatment_tags":[],"created_utc":1710674831,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"kv96h5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lolleka","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv77w1o","score":6,"author_fullname":"t2_4gnwgjot","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"excellent dad joke","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv96h5o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;excellent dad joke&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv96h5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710663279,"author_flair_text":null,"treatment_tags":[],"created_utc":1710663279,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"kv77w1o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vampyre2000","can_mod_post":false,"created_utc":1710627810,"send_replies":true,"parent_id":"t1_kv760fv","score":55,"author_fullname":"t2_6owsi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah it’s the type of underwear that female maths teachers wear an “alge bra” 😀","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv77w1o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it’s the type of underwear that female maths teachers wear an “alge bra” 😀&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv77w1o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710627810,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":55}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7r2rk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MrWeirdoFace","can_mod_post":false,"created_utc":1710635609,"send_replies":true,"parent_id":"t1_kv760fv","score":15,"author_fullname":"t2_12e249","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Of course we do!\\n\\n...it's that middle-eastern News channel, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7r2rk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Of course we do!&lt;/p&gt;\\n\\n&lt;p&gt;...it&amp;#39;s that middle-eastern News channel, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7r2rk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710635609,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7js8x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Budget-Juggernaut-68","can_mod_post":false,"created_utc":1710632642,"send_replies":true,"parent_id":"t1_kv760fv","score":23,"author_fullname":"t2_ch7hfjnw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe the average american.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7js8x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe the average american.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7js8x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710632642,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8tias","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Budget-Juggernaut-68","can_mod_post":false,"created_utc":1710653850,"send_replies":true,"parent_id":"t1_kv760fv","score":6,"author_fullname":"t2_ch7hfjnw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When is algebra taught in your country??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8tias","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When is algebra taught in your country??&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8tias/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710653850,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":11,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7bfft","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv760fv","score":11,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"If you live in the jungle maybe","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you live in the jungle maybe&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7bfft/","num_reports":null,"locked":false,"name":"t1_kv7bfft","created":1710629266,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710629266,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8ghpq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bcyng","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8cvj8","score":6,"author_fullname":"t2_98ll3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Said like a below average man that thinks that he’s exceptional 🤣","edited":1710650777,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8ghpq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Said like a below average man that thinks that he’s exceptional 🤣&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8ghpq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710646667,"author_flair_text":null,"treatment_tags":[],"created_utc":1710646667,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8cvj8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AdministrativeFill97","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7om7s","score":12,"author_fullname":"t2_61ncgwvg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You underestimate how stupid the average is","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv8cvj8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You underestimate how stupid the average is&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8cvj8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710644936,"author_flair_text":null,"treatment_tags":[],"created_utc":1710644936,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7om7s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bcyng","can_mod_post":false,"created_utc":1710634611,"send_replies":true,"parent_id":"t1_kv760fv","score":8,"author_fullname":"t2_98ll3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Said like an average man that thinks that he’s exceptional.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7om7s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Said like an average man that thinks that he’s exceptional.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7om7s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710634611,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"kykmksm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Future_Might_8194","can_mod_post":false,"created_utc":1712548887,"send_replies":true,"parent_id":"t1_kv760fv","score":1,"author_fullname":"t2_l9055m2ps","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"After my second DUI, my family screamed to me that I was an algebra and now I've been clean for seven years.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kykmksm","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;After my second DUI, my family screamed to me that I was an algebra and now I&amp;#39;ve been clean for seven years.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kykmksm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1712548887,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcfm9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"created_utc":1736574927,"send_replies":true,"parent_id":"t1_kv760fv","score":1,"author_fullname":"t2_8854dtzyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i know i dont","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6jcfm9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i know i dont&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcfm9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736574927,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":4,"name":"t1_kv7giuz","id":"kv7giuz","parent_id":"t1_kv760fv","depth":1,"children":["kv7giuz"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv760fv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1bgh9h4","score":139,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv760fv/","num_reports":null,"locked":false,"name":"t1_kv760fv","created":1710627049,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710627049,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9s0of","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gerryn","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9ger8","score":3,"author_fullname":"t2_3xvyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm in the camp of it's a blessing and a curse. We'll see in just a few years though - or even less.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9s0of","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m in the camp of it&amp;#39;s a blessing and a curse. We&amp;#39;ll see in just a few years though - or even less.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9s0of/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710678371,"author_flair_text":null,"treatment_tags":[],"created_utc":1710678371,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kziy2i3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ilovekittens345","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9ger8","score":2,"author_fullname":"t2_i6wlmca3l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;but I'm fine with the perspective that we just found something able to generalize our collective cultural output and spew it back to us with such high fidelity\\n\\nInsanely efficient lossy text compression?\\n\\n\\nMaybe we should focus more on understanding the relationship between compression and intelligence.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kziy2i3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;but I&amp;#39;m fine with the perspective that we just found something able to generalize our collective cultural output and spew it back to us with such high fidelity&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Insanely efficient lossy text compression?&lt;/p&gt;\\n\\n&lt;p&gt;Maybe we should focus more on understanding the relationship between compression and intelligence.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kziy2i3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1713099193,"author_flair_text":null,"treatment_tags":[],"created_utc":1713099193,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9ger8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"koflerdavid","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9a6mb","score":15,"author_fullname":"t2_az39ydz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The answer might simply be \\"it's the weights\\" It's relationships between data points that the training process forced the model to recognize. It's not just one such relationship, but billions of them, even in a lowly 100M parameter one since each weight is likely part of more than one pattern at the same time. And there is a lot of evidence that the training data and methodology is critical to make the most out of an architecture. This might not be a very satisfying view for scientists that strive to find reliable theories to explain stuff, but I'm fine with the perspective that we just found something able to generalize our collective cultural output and spew it back to us with such high fidelity :-)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9ger8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The answer might simply be &amp;quot;it&amp;#39;s the weights&amp;quot; It&amp;#39;s relationships between data points that the training process forced the model to recognize. It&amp;#39;s not just one such relationship, but billions of them, even in a lowly 100M parameter one since each weight is likely part of more than one pattern at the same time. And there is a lot of evidence that the training data and methodology is critical to make the most out of an architecture. This might not be a very satisfying view for scientists that strive to find reliable theories to explain stuff, but I&amp;#39;m fine with the perspective that we just found something able to generalize our collective cultural output and spew it back to us with such high fidelity :-)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9ger8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670818,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670818,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvc9gyf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"klausklass","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvc3x2q","score":2,"author_fullname":"t2_w9pw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I might be getting some stuff mixed up. I think this was specifically for deep belief networks. You can probably find something about why layer wise pre training and stacking RBMs works well. Essentially it improves variational lower bound. He also proved that neural networks with many hidden layers and sigmoid activation can approximate any distribution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvc9gyf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I might be getting some stuff mixed up. I think this was specifically for deep belief networks. You can probably find something about why layer wise pre training and stacking RBMs works well. Essentially it improves variational lower bound. He also proved that neural networks with many hidden layers and sigmoid activation can approximate any distribution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvc9gyf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710711706,"author_flair_text":null,"treatment_tags":[],"created_utc":1710711706,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kvc3x2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nikgeo25","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9a6mb","score":2,"author_fullname":"t2_16kleu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Haven't heard of this probabilistic approach proposed by Hinton. Any related keywords you might remember?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvc3x2q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haven&amp;#39;t heard of this probabilistic approach proposed by Hinton. Any related keywords you might remember?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvc3x2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710709700,"author_flair_text":null,"treatment_tags":[],"created_utc":1710709700,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_kv9em7y","id":"kv9em7y","parent_id":"t1_kv9a6mb","depth":2,"children":["kv9em7y","kv9ettl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9a6mb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"klausklass","can_mod_post":false,"created_utc":1710666155,"send_replies":true,"parent_id":"t1_kv88o23","score":23,"author_fullname":"t2_w9pw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think a lot of academics are disappointed with this approach. People didn’t start taking neural networks seriously until Geoff Hinton came up with a probabilistic approach explaining why they work (iirc). Obviously it’s great we can get so many cool behaviors out of these models without actually understanding why they work underneath, but we really should (eventually) figure it out. I think it’s especially important to find a way to prove why one particular architecture performs better than another (instead of just guessing intelligently).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9a6mb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think a lot of academics are disappointed with this approach. People didn’t start taking neural networks seriously until Geoff Hinton came up with a probabilistic approach explaining why they work (iirc). Obviously it’s great we can get so many cool behaviors out of these models without actually understanding why they work underneath, but we really should (eventually) figure it out. I think it’s especially important to find a way to prove why one particular architecture performs better than another (instead of just guessing intelligently).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9a6mb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710666155,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9eqbg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"created_utc":1710669571,"send_replies":true,"parent_id":"t1_kv88o23","score":2,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe we'll never figure out how they actually work.\\n\\nWith NNs, we end up with very complex behavior that in no way resembles the very simple mechanisms through wich it came to be. We tend to suck at reasoning about these: just look at behavioral psychology and similar failures, where how the whole behaves is similarly far removed from the sum of what its individual parts do.\\n\\nIt's quite likely that we can't reason about these type of things not because we haven't yet learn how to do it, but because one simply cannot analitically determine what a complex system would do: one can only model them and then describe what they see.\\n\\nBut then we're back at square one: NNs can be figured out only by actually running them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9eqbg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe we&amp;#39;ll never figure out how they actually work.&lt;/p&gt;\\n\\n&lt;p&gt;With NNs, we end up with very complex behavior that in no way resembles the very simple mechanisms through wich it came to be. We tend to suck at reasoning about these: just look at behavioral psychology and similar failures, where how the whole behaves is similarly far removed from the sum of what its individual parts do.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s quite likely that we can&amp;#39;t reason about these type of things not because we haven&amp;#39;t yet learn how to do it, but because one simply cannot analitically determine what a complex system would do: one can only model them and then describe what they see.&lt;/p&gt;\\n\\n&lt;p&gt;But then we&amp;#39;re back at square one: NNs can be figured out only by actually running them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9eqbg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710669571,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv88o23","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JeepyTea","can_mod_post":false,"created_utc":1710643069,"send_replies":true,"parent_id":"t3_1bgh9h4","score":80,"author_fullname":"t2_ueqnbegxa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was inspired by this quote:\\n\\n\\"We  offer no explanation as to why these architectures seem to work; we  attribute their success, as all else, to divine benevolence.\\"\\n\\n\\\\- Noam Shazeer, CEO of Character.ai and co-author of \\"Attention Is All You Need.\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv88o23","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was inspired by this quote:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;We  offer no explanation as to why these architectures seem to work; we  attribute their success, as all else, to divine benevolence.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;- Noam Shazeer, CEO of Character.ai and co-author of &amp;quot;Attention Is All You Need.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv88o23/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710643069,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":80}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv90vnv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":6,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think you can come to this conclusion if you look at each individual pass through the model, or even an entire generation (if not using some feedback mechanism such as guidance etc).   \\n\\nBut when we begin to iterate with feedback something new emerges.   This becomes obvious with something as simple as tree of thought, and can be progressed much further by using LLMs as intermediates in large stateful programs.  \\n\\nThey may become the new transistor rather than the end all be all single model to rule the world.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv90vnv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you can come to this conclusion if you look at each individual pass through the model, or even an entire generation (if not using some feedback mechanism such as guidance etc).   &lt;/p&gt;\\n\\n&lt;p&gt;But when we begin to iterate with feedback something new emerges.   This becomes obvious with something as simple as tree of thought, and can be progressed much further by using LLMs as intermediates in large stateful programs.  &lt;/p&gt;\\n\\n&lt;p&gt;They may become the new transistor rather than the end all be all single model to rule the world.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv90vnv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710658992,"author_flair_text":null,"treatment_tags":[],"created_utc":1710658992,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8lvpb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Maykey","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7zi5s","score":6,"author_fullname":"t2_17tuu7pv","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's purely algorithmic. We even know algorithms that supposed to work.\\n\\nMemorizing Transformers are trained to lookup chunks from the past(think vector db but where chat apps merely adopted them, MT pretrained with them) work really well to the point where 1B model is comparable to 8B pure model, however it seems they never gained traction. \\n\\nThere's also RETRO which is even more persistent memory as it uses non-updatable database of trillions of tokens.","edited":1710672710,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv8lvpb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s purely algorithmic. We even know algorithms that supposed to work.&lt;/p&gt;\\n\\n&lt;p&gt;Memorizing Transformers are trained to lookup chunks from the past(think vector db but where chat apps merely adopted them, MT pretrained with them) work really well to the point where 1B model is comparable to 8B pure model, however it seems they never gained traction. &lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s also RETRO which is even more persistent memory as it uses non-updatable database of trillions of tokens.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8lvpb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710649417,"author_flair_text":null,"treatment_tags":[],"created_utc":1710649417,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_lpg6whh","id":"lpg6whh","parent_id":"t1_kv8psku","depth":6,"children":["lpg6whh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8psku","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"virtualmnemonic","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7zi5s","score":9,"author_fullname":"t2_7uoy6dos","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; I guess you could just store an ever-longer context and call that persistent memory, but it at some point it’s quite inefficient.\\n\\nThis is essentially what the brain does. All you have is an ever-long \\"context\\" that is reflected by all the totality of the physical makeup of the brain. Working memory is the closest thing to a context that we have, but it is not actually a *system* but rather a *reflection* of ongoing neural processing. That is, working memory is a model of ongoing activity, and what we subjectively experience as working memory is just a byproduct of current brain activity. \\n\\nLLMs may be best off in their current state (being dictated heavily by training), otherwise, their outputs would be far too malleable based upon user inputs.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv8psku","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I guess you could just store an ever-longer context and call that persistent memory, but it at some point it’s quite inefficient.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;This is essentially what the brain does. All you have is an ever-long &amp;quot;context&amp;quot; that is reflected by all the totality of the physical makeup of the brain. Working memory is the closest thing to a context that we have, but it is not actually a &lt;em&gt;system&lt;/em&gt; but rather a &lt;em&gt;reflection&lt;/em&gt; of ongoing neural processing. That is, working memory is a model of ongoing activity, and what we subjectively experience as working memory is just a byproduct of current brain activity. &lt;/p&gt;\\n\\n&lt;p&gt;LLMs may be best off in their current state (being dictated heavily by training), otherwise, their outputs would be far too malleable based upon user inputs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8psku/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710651570,"author_flair_text":null,"treatment_tags":[],"created_utc":1710651570,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv804q6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7zy2t","score":2,"author_fullname":"t2_8qdnx6vxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah fair enough!","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_kv804q6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah fair enough!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv804q6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710639400,"author_flair_text":null,"treatment_tags":[],"created_utc":1710639400,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7zy2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ansible32","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7zi5s","score":9,"author_fullname":"t2_72uqo","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I mean the fact that they don't run training and inference at the same time is obviously by design, but I think even if they wanted to it's not practical to do it properly with current hardware.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv7zy2t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I mean the fact that they don&amp;#39;t run training and inference at the same time is obviously by design, but I think even if they wanted to it&amp;#39;s not practical to do it properly with current hardware.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7zy2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710639322,"author_flair_text":null,"treatment_tags":[],"created_utc":1710639322,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":4,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8q577","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"virtualmnemonic","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv85u2j","score":10,"author_fullname":"t2_7uoy6dos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not quite, but close enough to be useful. Something interesting to keep in mind is that we have inordinately (as opposed to waking reality) hallucinations during \\"training\\", e.g., REM sleep and daydreaming.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_kv8q577","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not quite, but close enough to be useful. Something interesting to keep in mind is that we have inordinately (as opposed to waking reality) hallucinations during &amp;quot;training&amp;quot;, e.g., REM sleep and daydreaming.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8q577/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710651776,"author_flair_text":null,"treatment_tags":[],"created_utc":1710651776,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"more","data":{"count":4,"name":"t1_kvedw4x","id":"kvedw4x","parent_id":"t1_kv85u2j","depth":6,"children":["kvedw4x"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv85u2j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1710641841,"send_replies":true,"parent_id":"t1_kv7zi5s","score":4,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1711878022,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv85u2j/","num_reports":null,"locked":false,"name":"t1_kv85u2j","created":1710641841,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7zi5s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7yrb5","score":20,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting, why do you think it’s a hardware issue? I think it’s algorithmic, in that the data is stored in the weights, and it needs to update them via learning, which it doesn’t do during inference. I guess you could just store an ever-longer context and call that persistent memory, but it at some point it’s quite inefficient.\\n\\nEdit: oh you mean just update the model with RLHF in real time? Yeah I imagine they want to have explicit control over the training process.","edited":false,"author_flair_css_class":null,"name":"t1_kv7zi5s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting, why do you think it’s a hardware issue? I think it’s algorithmic, in that the data is stored in the weights, and it needs to update them via learning, which it doesn’t do during inference. I guess you could just store an ever-longer context and call that persistent memory, but it at some point it’s quite inefficient.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: oh you mean just update the model with RLHF in real time? Yeah I imagine they want to have explicit control over the training process.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7zi5s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710639130,"author_flair_text":null,"collapsed":false,"created_utc":1710639130,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7yrb5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ansible32","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":20,"author_fullname":"t2_72uqo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; it doesn’t have persistent memory\\n\\nI pretty firmly believe this is just a hardware problem. I say \\"just\\" but it's unclear how much memory and memory bandwidth and FLOPS you need to do realtime learning in response to feedback. Cerebras' newest chip has space for petabytes of ram (compared to terabytes in the current best chips.)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7yrb5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;it doesn’t have persistent memory&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I pretty firmly believe this is just a hardware problem. I say &amp;quot;just&amp;quot; but it&amp;#39;s unclear how much memory and memory bandwidth and FLOPS you need to do realtime learning in response to feedback. Cerebras&amp;#39; newest chip has space for petabytes of ram (compared to terabytes in the current best chips.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7yrb5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638807,"author_flair_text":null,"treatment_tags":[],"created_utc":1710638807,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kvfr37b","id":"kvfr37b","parent_id":"t1_kvfdjms","depth":5,"children":["kvfr37b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvfdjms","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvfcduj","score":4,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, but at the at point that advanced enough system won’t be how the current batch of auto-regressive LLMs work.\\n\\nI’m not convinced the current batch can create any significantly new, useful idea. They seem like they can match the convex hull of human knowledge on the internet, and only exceed it in places where humans haven’t done the work of interpolating across explicit works to create that specific “new” output, but I’m not sure that can be called a “significantly new” generation. Taking a lot of examples of code that already exists for building a website and using it in a slightly my new context isn’t really creating something new in my opinion.\\n\\nI’d be blown away if LLMs could actually propose an improvement to our understanding of physics. I really, really don’t see that happening unless significant changes are made to the algo.","edited":false,"author_flair_css_class":null,"name":"t1_kvfdjms","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, but at the at point that advanced enough system won’t be how the current batch of auto-regressive LLMs work.&lt;/p&gt;\\n\\n&lt;p&gt;I’m not convinced the current batch can create any significantly new, useful idea. They seem like they can match the convex hull of human knowledge on the internet, and only exceed it in places where humans haven’t done the work of interpolating across explicit works to create that specific “new” output, but I’m not sure that can be called a “significantly new” generation. Taking a lot of examples of code that already exists for building a website and using it in a slightly my new context isn’t really creating something new in my opinion.&lt;/p&gt;\\n\\n&lt;p&gt;I’d be blown away if LLMs could actually propose an improvement to our understanding of physics. I really, really don’t see that happening unless significant changes are made to the algo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvfdjms/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710770268,"author_flair_text":null,"collapsed":false,"created_utc":1710770268,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"kvfcduj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dmit0820","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":4,"author_fullname":"t2_uqrwwe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The thing is that autocomplete, in theory, can simulate the output of the smartest person on the planet. If you ask a hypothetical future LLM to complete Einstein's \\"Unified model theory\\" that unifies quantum physics with relativity, it will come up with a plausible theory.\\n\\nWhat matters is not the objective function (predicting the next token), but how it accomplishes that task.\\n\\nThere's no reason why an advanced enough system can't reason, backtrack, have persistent memory, or learn new tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvfcduj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The thing is that autocomplete, in theory, can simulate the output of the smartest person on the planet. If you ask a hypothetical future LLM to complete Einstein&amp;#39;s &amp;quot;Unified model theory&amp;quot; that unifies quantum physics with relativity, it will come up with a plausible theory.&lt;/p&gt;\\n\\n&lt;p&gt;What matters is not the objective function (predicting the next token), but how it accomplishes that task.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s no reason why an advanced enough system can&amp;#39;t reason, backtrack, have persistent memory, or learn new tasks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvfcduj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710769810,"author_flair_text":null,"treatment_tags":[],"created_utc":1710769810,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_kvee2jx","id":"kvee2jx","parent_id":"t1_kv95xkj","depth":7,"children":["kvee2jx","m6jcgdl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv95xkj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"flatfisher","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7y1pr","score":6,"author_fullname":"t2_1sgzx9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah for me it’s less about LLM are human like and more something that we thought was a core component of our humanity turns to be an advanced autocomplete function. Also apart from Thinking Fast and slow Mindfulness is interesting for introspecting ourselves: with practice you can “see” the flow of thoughts in your mind and treat it separately from your consciousness.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_kv95xkj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah for me it’s less about LLM are human like and more something that we thought was a core component of our humanity turns to be an advanced autocomplete function. Also apart from Thinking Fast and slow Mindfulness is interesting for introspecting ourselves: with practice you can “see” the flow of thoughts in your mind and treat it separately from your consciousness.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv95xkj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710662862,"author_flair_text":null,"treatment_tags":[],"created_utc":1710662862,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m6jcgrt","id":"m6jcgrt","parent_id":"t1_kv97889","depth":7,"children":["m6jcgrt"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv97889","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Bet_127","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7y1pr","score":3,"author_fullname":"t2_8uv7tbmz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You mean association? Yeah, we do have one. Both obvious and not.\\n\\nWhen you write something next words come to mind without thinking. More you do that, more you sure about style, more examples you saw comes into flow of thoughts or words. But if you didn't do it much, then yeah, you will have to think about each word and that is painful (that is why some people hate to write essays, notices, letters, announcements and so on).\\n\\nPeople do not understand meaning of many words as well. Both concepts can be very clearly demonstrated on someone who just learns foreign language. Based on that linguistic has built quite a number of theories. Simple model:\\n\\nFramework --- language --- words (which does have sign, meaning and connotation) --- constructed speech.\\n\\nLanguage we learn. Relatively easy part. Then comes the practise, where you will have to understand where seemingly same words can be widely different in usage. That is connotation, dictating in which case which word should be used. Which relies on framework. Framework is everything we can perceive, from the color theory and culture, to the mood of other people. Simply put - mindset.\\n\\nWhen one learns english, and uses the word \\"died\\", it can be met with winces, and even though no word was said and that person might even not pay attention to the reaction, next time he would choose better word or phrase. So each word actually gets weight on where it can be used, where it can not. We do have autocomplete, dictated by experience. It is not as easy as IT one, but it is quite reliable and that is what lets you understand what other people say. As it comes with Framework, you should have experience. Politicians do politicians, you may be able to do teenagers or school teachers. Predict what words they are going to use in every particular situation, not by knowing them, but by knowing situation and that type of people. \\n\\nThat was quite a profession, when you hire someone to rehearse the speech or argument. He will know what other party will say tomorrow, how it will respond and what reaction there would be for certain words.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_kv97889","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You mean association? Yeah, we do have one. Both obvious and not.&lt;/p&gt;\\n\\n&lt;p&gt;When you write something next words come to mind without thinking. More you do that, more you sure about style, more examples you saw comes into flow of thoughts or words. But if you didn&amp;#39;t do it much, then yeah, you will have to think about each word and that is painful (that is why some people hate to write essays, notices, letters, announcements and so on).&lt;/p&gt;\\n\\n&lt;p&gt;People do not understand meaning of many words as well. Both concepts can be very clearly demonstrated on someone who just learns foreign language. Based on that linguistic has built quite a number of theories. Simple model:&lt;/p&gt;\\n\\n&lt;p&gt;Framework --- language --- words (which does have sign, meaning and connotation) --- constructed speech.&lt;/p&gt;\\n\\n&lt;p&gt;Language we learn. Relatively easy part. Then comes the practise, where you will have to understand where seemingly same words can be widely different in usage. That is connotation, dictating in which case which word should be used. Which relies on framework. Framework is everything we can perceive, from the color theory and culture, to the mood of other people. Simply put - mindset.&lt;/p&gt;\\n\\n&lt;p&gt;When one learns english, and uses the word &amp;quot;died&amp;quot;, it can be met with winces, and even though no word was said and that person might even not pay attention to the reaction, next time he would choose better word or phrase. So each word actually gets weight on where it can be used, where it can not. We do have autocomplete, dictated by experience. It is not as easy as IT one, but it is quite reliable and that is what lets you understand what other people say. As it comes with Framework, you should have experience. Politicians do politicians, you may be able to do teenagers or school teachers. Predict what words they are going to use in every particular situation, not by knowing them, but by knowing situation and that type of people. &lt;/p&gt;\\n\\n&lt;p&gt;That was quite a profession, when you hire someone to rehearse the speech or argument. He will know what other party will say tomorrow, how it will respond and what reaction there would be for certain words.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv97889/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710663859,"author_flair_text":null,"treatment_tags":[],"created_utc":1710663859,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7y1pr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Prathmun","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7u2zo","score":11,"author_fullname":"t2_6eif6","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm sort of a middle place here. Where? I think that thinking of it as an autocomplete is both correct and not really a dig. My understanding is that we also have something like an auto complete system in our psychies. I think they talk about it in that book. Thinking fast and slow. In their simplified model we have two thinking systems. One of them is fast and has a shotgun approach to solving problems and tends to not be reasoning so much as completing the next step in the pattern. \\n\\nSo to me, the stochastic parrot model seems like an integral part of a mind rather than the entirety of one.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv7y1pr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m sort of a middle place here. Where? I think that thinking of it as an autocomplete is both correct and not really a dig. My understanding is that we also have something like an auto complete system in our psychies. I think they talk about it in that book. Thinking fast and slow. In their simplified model we have two thinking systems. One of them is fast and has a shotgun approach to solving problems and tends to not be reasoning so much as completing the next step in the pattern. &lt;/p&gt;\\n\\n&lt;p&gt;So to me, the stochastic parrot model seems like an integral part of a mind rather than the entirety of one.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7y1pr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638503,"author_flair_text":null,"treatment_tags":[],"created_utc":1710638503,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":11,"name":"t1_kv9oc10","id":"kv9oc10","parent_id":"t1_kv7u2zo","depth":5,"children":["kv9oc10","kvaovg4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7u2zo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7sxyc","score":44,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am not sympathetic to the idea that finding a compressed latent representation that allows one to do some small generalisation in some specific domain, because the latent space was well populated and not sparse, is the same as reasoning. Learning a smooth latent representation that allows one to generalise a little bit on things you haven’t exactly seen before is not the same as understanding something deeply.\\n\\nMy general issue is that it it is built to be an autocomplete, and trained to be an autocomplete, and fails to generalise to things it sufficiently outside what it was trained on (the input is no longer mapped into a well defined, smooth part of the latent space), and then people say it’s not an autocomplete. If it walks like a duck and talks like a duck… I love AI, and I’m sure that within a decade we’ll have some really cool stuff that will probably be more like reasoning, but the current batch of autoregressive LLMs are not what a lot of people make them out to be.","edited":false,"author_flair_css_class":null,"name":"t1_kv7u2zo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am not sympathetic to the idea that finding a compressed latent representation that allows one to do some small generalisation in some specific domain, because the latent space was well populated and not sparse, is the same as reasoning. Learning a smooth latent representation that allows one to generalise a little bit on things you haven’t exactly seen before is not the same as understanding something deeply.&lt;/p&gt;\\n\\n&lt;p&gt;My general issue is that it it is built to be an autocomplete, and trained to be an autocomplete, and fails to generalise to things it sufficiently outside what it was trained on (the input is no longer mapped into a well defined, smooth part of the latent space), and then people say it’s not an autocomplete. If it walks like a duck and talks like a duck… I love AI, and I’m sure that within a decade we’ll have some really cool stuff that will probably be more like reasoning, but the current batch of autoregressive LLMs are not what a lot of people make them out to be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7u2zo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636845,"author_flair_text":null,"collapsed":false,"created_utc":1710636845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":44}},{"kind":"more","data":{"count":9,"name":"t1_kv9o6i1","id":"kv9o6i1","parent_id":"t1_kv7sxyc","depth":4,"children":["kv9o6i1","kv82u5l"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7sxyc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"satireplusplus","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":30,"author_fullname":"t2_x7vf0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The stochastic parrot camp is currently very loud, but this is something that's up for scientific debate. There's some interesting experiments along the lines of the ChessGPT that show that LLMs might actually internally build a representation model that hints at understanding - not just merely copying or stochastically autocompleting something. Or phrased differently, in order to become really good at auto completing something, you need to understand it. In order to predict the next word probabilities in \\"that's how the sauce is made in frech is:\\" you need to be able to translate and so on. I think that's how both view's can be right at the same time, it's learning by auto-completing, but ultimately it ends up sort of understanding language (and learns tasks like translation) to become really really good at it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7sxyc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The stochastic parrot camp is currently very loud, but this is something that&amp;#39;s up for scientific debate. There&amp;#39;s some interesting experiments along the lines of the ChessGPT that show that LLMs might actually internally build a representation model that hints at understanding - not just merely copying or stochastically autocompleting something. Or phrased differently, in order to become really good at auto completing something, you need to understand it. In order to predict the next word probabilities in &amp;quot;that&amp;#39;s how the sauce is made in frech is:&amp;quot; you need to be able to translate and so on. I think that&amp;#39;s how both view&amp;#39;s can be right at the same time, it&amp;#39;s learning by auto-completing, but ultimately it ends up sort of understanding language (and learns tasks like translation) to become really really good at it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7sxyc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636373,"author_flair_text":null,"treatment_tags":[],"created_utc":1710636373,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kveeg96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvcehej","score":3,"author_fullname":"t2_cgigt","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Definitely not testable. Even other humans, I assume they must be conscious only because they are similar enough to me that extrapolating my personal subjective experience feels justified. But it's still just an assumption without any proof.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kveeg96","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely not testable. Even other humans, I assume they must be conscious only because they are similar enough to me that extrapolating my personal subjective experience feels justified. But it&amp;#39;s still just an assumption without any proof.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kveeg96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710749758,"author_flair_text":null,"treatment_tags":[],"created_utc":1710749758,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kvcehej","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvcdrgv","score":3,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, but truth is we have no idea. Physics has a very nice explanation of how the world works, except for the gaping hole where there is no explanation for how a bunch of atoms can manifest an internal subjective experience. I’m completely open to the idea that in-silica consciousness is possible, since it doesn’t make sense to me to assume that only biological cells might manifest subjective experience. \\n\\nBut I wish physicists would find some answer to the question of consciousness, assuming it even is testable in any way.","edited":false,"author_flair_css_class":null,"name":"t1_kvcehej","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, but truth is we have no idea. Physics has a very nice explanation of how the world works, except for the gaping hole where there is no explanation for how a bunch of atoms can manifest an internal subjective experience. I’m completely open to the idea that in-silica consciousness is possible, since it doesn’t make sense to me to assume that only biological cells might manifest subjective experience. &lt;/p&gt;\\n\\n&lt;p&gt;But I wish physicists would find some answer to the question of consciousness, assuming it even is testable in any way.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvcehej/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710713518,"author_flair_text":null,"collapsed":false,"created_utc":1710713518,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kvcdrgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MmmmMorphine","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":3,"author_fullname":"t2_ea78a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The real question here is, do you believe consciousness (not necessarily LLM based in any way) can be achieved in-silico or can only organic brains achieve this feat? \\n\\nBecause without that basic assumption/belief/theory/whatever, there's no way to actually discuss the topic with any logical and/or scientific rigor","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvcdrgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The real question here is, do you believe consciousness (not necessarily LLM based in any way) can be achieved in-silico or can only organic brains achieve this feat? &lt;/p&gt;\\n\\n&lt;p&gt;Because without that basic assumption/belief/theory/whatever, there&amp;#39;s no way to actually discuss the topic with any logical and/or scientific rigor&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvcdrgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710713254,"author_flair_text":null,"treatment_tags":[],"created_utc":1710713254,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv946z4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chipmandal","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":7,"author_fullname":"t2_esrx2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is definitely auto complete. The question is, are most humans also sufficiently advanced autocomplete with millions of years of training😀.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv946z4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is definitely auto complete. The question is, are most humans also sufficiently advanced autocomplete with millions of years of training😀.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv946z4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710661519,"author_flair_text":null,"treatment_tags":[],"created_utc":1710661519,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_kv9wrb4","id":"kv9wrb4","parent_id":"t1_kv9208x","depth":4,"children":["kv9wrb4","kvkmfyl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9208x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RomanOfThe10th","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":5,"author_fullname":"t2_ibp8ftfq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A car is just an advanced horse.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9208x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A car is just an advanced horse.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9208x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710659844,"author_flair_text":null,"treatment_tags":[],"created_utc":1710659844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9daqf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":2,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most of those are about the currently used implementations, not constraints on what these models can/could do.\\n\\nThey could (some do) have persistent memory. They could backtrack. Even better, someone will soon figure out how to do diffusion for text, and then we'll generate and iteratively refine the response as a whole. Isn't zero shot about scoring models on stuff they were not trained on (though I admit you may have referred to more generic \\"new tasks\\" than that).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9daqf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most of those are about the currently used implementations, not constraints on what these models can/could do.&lt;/p&gt;\\n\\n&lt;p&gt;They could (some do) have persistent memory. They could backtrack. Even better, someone will soon figure out how to do diffusion for text, and then we&amp;#39;ll generate and iteratively refine the response as a whole. Isn&amp;#39;t zero shot about scoring models on stuff they were not trained on (though I admit you may have referred to more generic &amp;quot;new tasks&amp;quot; than that).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9daqf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710668504,"author_flair_text":null,"treatment_tags":[],"created_utc":1710668504,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":11,"name":"t1_m6jch7p","id":"m6jch7p","parent_id":"t1_kvapd9w","depth":4,"children":["m6jch7p","kvaxd5g"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvapd9w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":2,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We live much of our life on autocomplete though?\\\\* And much of the rest is just clever-sounding (but empty) reasoning about why all that isn't actually autocomplete. Very little of what we produce is original content, and most of that (just like anything else we do) is likely not expressible in speech or writing.\\n\\n\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_  \\n\\\\* That is, we follow the same old patterns, should it be motor functions or speech or planning or anything.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvapd9w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We live much of our life on autocomplete though?* And much of the rest is just clever-sounding (but empty) reasoning about why all that isn&amp;#39;t actually autocomplete. Very little of what we produce is original content, and most of that (just like anything else we do) is likely not expressible in speech or writing.&lt;/p&gt;\\n\\n&lt;p&gt;________&lt;br/&gt;\\n* That is, we follow the same old patterns, should it be motor functions or speech or planning or anything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvapd9w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710691955,"author_flair_text":null,"treatment_tags":[],"created_utc":1710691955,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_kvb2kif","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvb2kif","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvb1scu","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"lol you are arguing yourself in a circle, what exactly is “true” reasoning then? I’m not looking for that imitation stuff I want the real thing","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol you are arguing yourself in a circle, what exactly is “true” reasoning then? I’m not looking for that imitation stuff I want the real thing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvb2kif/","num_reports":null,"locked":false,"name":"t1_kvb2kif","created":1710696563,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710696563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kvb1scu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oscar96S","can_mod_post":false,"created_utc":1710696298,"send_replies":true,"parent_id":"t1_kvb14eh","score":3,"author_fullname":"t2_8qdnx6vxn","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well no, the benchmarks are being misunderstood. It’s not a measure of reasoning, it’s a measure of looking like reasoning. The algorithm is, in terms of architecture and how it is trained, an autocomplete based off of next-token prediction. It can not reason.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kvb1scu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well no, the benchmarks are being misunderstood. It’s not a measure of reasoning, it’s a measure of looking like reasoning. The algorithm is, in terms of architecture and how it is trained, an autocomplete based off of next-token prediction. It can not reason.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvb1scu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710696298,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kvb14eh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvazxz3","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Yes and your reasoning is just a bunch of neurons spiking based on what you have learned.\\n\\nJust because an LLM doesn’t reason the way you think you reason doesn’t mean it isn’t. This is the whole reason we have benchmarks, and shocker they do quite well on them","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and your reasoning is just a bunch of neurons spiking based on what you have learned.&lt;/p&gt;\\n\\n&lt;p&gt;Just because an LLM doesn’t reason the way you think you reason doesn’t mean it isn’t. This is the whole reason we have benchmarks, and shocker they do quite well on them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvb14eh/","num_reports":null,"locked":false,"name":"t1_kvb14eh","created":1710696069,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710696069,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kvazxz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvazcnc","score":3,"author_fullname":"t2_8qdnx6vxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Asking an LLM to do reasoning, and having it output text that looks like it reasoned it’s way through an argument, does not mean the LLM is actually doing reasoning. It’s still just doing next token prediction, and the reason it looks like reasoning is because it was trained on data that talked through a reasoning process, and learned to imitate that text. People get fooled by the fluency of the text and think it’s actually reasoning.\\n\\nWe don’t need to know how the brain works to be able to make claims about human logic: we have an internal view into how our own minds work.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_kvazxz3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Asking an LLM to do reasoning, and having it output text that looks like it reasoned it’s way through an argument, does not mean the LLM is actually doing reasoning. It’s still just doing next token prediction, and the reason it looks like reasoning is because it was trained on data that talked through a reasoning process, and learned to imitate that text. People get fooled by the fluency of the text and think it’s actually reasoning.&lt;/p&gt;\\n\\n&lt;p&gt;We don’t need to know how the brain works to be able to make claims about human logic: we have an internal view into how our own minds work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvazxz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710695665,"author_flair_text":null,"treatment_tags":[],"created_utc":1710695665,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kvazcnc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1710695458,"send_replies":true,"parent_id":"t1_kvaxpj5","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Yes you can ask it to reason and it does, COT and other techniques show this. We have benchmarks for this stuff. \\n\\nPeople want to act like we have some understanding of how reasoning works in the human brain, we don’t","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes you can ask it to reason and it does, COT and other techniques show this. We have benchmarks for this stuff. &lt;/p&gt;\\n\\n&lt;p&gt;People want to act like we have some understanding of how reasoning works in the human brain, we don’t&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvazcnc/","num_reports":null,"locked":false,"name":"t1_kvazcnc","created":1710695458,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kvaxpj5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kva4m8d","score":3,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can’t though, there’s nothing in the architecture that does reasoning, it’s just next token prediction based on linearly combined embedding vectors that provide context to each latent token. The processes for humans reasoning and LLMs outputting text is fundamentally different. People mistake LLM’s fluency in language for reasoning.","edited":false,"author_flair_css_class":null,"name":"t1_kvaxpj5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can’t though, there’s nothing in the architecture that does reasoning, it’s just next token prediction based on linearly combined embedding vectors that provide context to each latent token. The processes for humans reasoning and LLMs outputting text is fundamentally different. People mistake LLM’s fluency in language for reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvaxpj5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710694888,"author_flair_text":null,"collapsed":false,"created_utc":1710694888,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kva4m8d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7l29k","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"You can make LLMs reason, we also may just be autocomplete on a basic level","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can make LLMs reason, we also may just be autocomplete on a basic level&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kva4m8d/","num_reports":null,"locked":false,"name":"t1_kva4m8d","created":1710684244,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710684244,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":21,"name":"t1_kv9d5uc","id":"kv9d5uc","parent_id":"t1_kv7l29k","depth":3,"children":["kv9d5uc","kv8xp8p","kv9ctyq","kva0bfx","kvkm5mt","kv9rd2p","kv8z7n4","kv9xakb","kv7prc0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7l29k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oscar96S","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7jvw2","score":103,"author_fullname":"t2_8qdnx6vxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah exactly, I’m a ML engineer, and I’m pretty firmly in the it’s just very advanced autocomplete camp, which it is. It’s an autoregressive, super powerful, very impressive algorithm that does autocomplete. It doesn’t do reasoning, it doesn’t adjust its output in real time (i.e. backtrack), it doesn’t have persistent memory, it can’t learn significantly newer tasks without being trained from scratch.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7l29k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah exactly, I’m a ML engineer, and I’m pretty firmly in the it’s just very advanced autocomplete camp, which it is. It’s an autoregressive, super powerful, very impressive algorithm that does autocomplete. It doesn’t do reasoning, it doesn’t adjust its output in real time (i.e. backtrack), it doesn’t have persistent memory, it can’t learn significantly newer tasks without being trained from scratch.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7l29k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710633157,"author_flair_text":null,"treatment_tags":[],"created_utc":1710633157,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":103}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kv8zc3n","id":"kv8zc3n","parent_id":"t1_kv7pnlp","depth":3,"children":["kv8zc3n"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7pnlp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"burritolittledonkey","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7jvw2","score":6,"author_fullname":"t2_iem2foa3u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But, we also might be too, is the thing, just really, really, really, really, really scaled up autocomplete","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7pnlp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But, we also might be too, is the thing, just really, really, really, really, really scaled up autocomplete&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7pnlp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710635032,"author_flair_text":null,"treatment_tags":[],"created_utc":1710635032,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kvaf0sd","id":"kvaf0sd","parent_id":"t1_kv8zdf2","depth":5,"children":["kvaf0sd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8zdf2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"smallfried","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7qkdx","score":1,"author_fullname":"t2_3d16n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Also whether or not you realize it, the act of actually commenting changes your 'weights' slightly\\n\\nI guess you don't know that LLMs work exactly in this way. Their own output changes their internal weights. Also, they can be tuned to output backspaces. And there are some that output \\"internal\\" thought processes marked as such with special tokens.\\n\\nLook up zero shot chain of thought prompting to see how an LLM output can be improved by requesting more reasoning.","edited":false,"author_flair_css_class":null,"name":"t1_kv8zdf2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Also whether or not you realize it, the act of actually commenting changes your &amp;#39;weights&amp;#39; slightly&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I guess you don&amp;#39;t know that LLMs work exactly in this way. Their own output changes their internal weights. Also, they can be tuned to output backspaces. And there are some that output &amp;quot;internal&amp;quot; thought processes marked as such with special tokens.&lt;/p&gt;\\n\\n&lt;p&gt;Look up zero shot chain of thought prompting to see how an LLM output can be improved by requesting more reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8zdf2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710657883,"author_flair_text":null,"collapsed":false,"created_utc":1710657883,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":9,"name":"t1_kv8zag8","id":"kv8zag8","parent_id":"t1_kv7qkdx","depth":4,"children":["kv8zag8","kv7unc1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7qkdx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crafty-Run-6559","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7lab3","score":14,"author_fullname":"t2_a53gnti3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well no, not really.\\n\\nEver used the backspace when typing a comment?\\n\\nYour comments communicate thought in a way that's intrinsically different than an LLM.\\n\\nAlso whether or not you realize it, the act of actually commenting changes your 'weights' slightly. \\n\\nPeople learn/self modify as they output in a way that LLMs don't.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7qkdx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well no, not really.&lt;/p&gt;\\n\\n&lt;p&gt;Ever used the backspace when typing a comment?&lt;/p&gt;\\n\\n&lt;p&gt;Your comments communicate thought in a way that&amp;#39;s intrinsically different than an LLM.&lt;/p&gt;\\n\\n&lt;p&gt;Also whether or not you realize it, the act of actually commenting changes your &amp;#39;weights&amp;#39; slightly. &lt;/p&gt;\\n\\n&lt;p&gt;People learn/self modify as they output in a way that LLMs don&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7qkdx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710635399,"author_flair_text":null,"treatment_tags":[],"created_utc":1710635399,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7lab3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"smallfried","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7jvw2","score":7,"author_fullname":"t2_3d16n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, but in the same way, all your comments are just auto completing the natural flow of dialog. As is this one.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7lab3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, but in the same way, all your comments are just auto completing the natural flow of dialog. As is this one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7lab3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710633248,"author_flair_text":null,"treatment_tags":[],"created_utc":1710633248,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_kvd6ay7","id":"kvd6ay7","parent_id":"t1_kv9fgbj","depth":3,"children":["kvd6ay7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9fgbj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koflerdavid","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7jvw2","score":2,"author_fullname":"t2_az39ydz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If the only way we could interact with another human is via chat, then yes. You can always view the process of answering a chat message as \\"autocompleting\\" a response based on the chat history.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9fgbj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the only way we could interact with another human is via chat, then yes. You can always view the process of answering a chat message as &amp;quot;autocompleting&amp;quot; a response based on the chat history.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9fgbj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670106,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7jvw2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Budget-Juggernaut-68","can_mod_post":false,"created_utc":1710632683,"send_replies":true,"parent_id":"t1_kv7em0m","score":59,"author_fullname":"t2_ch7hfjnw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But... it is though?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7jvw2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But... it is though?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7jvw2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710632683,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":59}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8zce5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7xj1u","score":2,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, but at what point do they stop getting better?   Claude 3 opus is pretty damn impressive, and I'm sure OpenAI's response will be a leap forward.   \\n\\nAs the models improve, there isn't necessarily a limit to the productivity of synthetic data.\\n\\nIf you have a mechanism for validating the output then you can run hundreds of thousands of iterations at varying temperatures until you Distil the best response and retrain etc.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv8zce5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, but at what point do they stop getting better?   Claude 3 opus is pretty damn impressive, and I&amp;#39;m sure OpenAI&amp;#39;s response will be a leap forward.   &lt;/p&gt;\\n\\n&lt;p&gt;As the models improve, there isn&amp;#39;t necessarily a limit to the productivity of synthetic data.&lt;/p&gt;\\n\\n&lt;p&gt;If you have a mechanism for validating the output then you can run hundreds of thousands of iterations at varying temperatures until you Distil the best response and retrain etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8zce5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710657862,"author_flair_text":null,"treatment_tags":[],"created_utc":1710657862,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":1,"name":"t1_kv8zdla","id":"kv8zdla","parent_id":"t1_kv7xj1u","depth":2,"children":["kv8zdla"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7xj1u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SomeOddCodeGuy","can_mod_post":false,"created_utc":1710638287,"send_replies":true,"parent_id":"t1_kv7em0m","score":7,"author_fullname":"t2_kle75fbd6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If the byte completion models pick up then I'm probably going to switch from \\"Its a word calculator\\" to \\"its magic\\", but I'm still pretty firmly rooted in the notion language completion models can only go so far before they just plateau out and we get disappointed that they won't get better. \\n\\nEspecially as we keep training models on the output of other models...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7xj1u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the byte completion models pick up then I&amp;#39;m probably going to switch from &amp;quot;Its a word calculator&amp;quot; to &amp;quot;its magic&amp;quot;, but I&amp;#39;m still pretty firmly rooted in the notion language completion models can only go so far before they just plateau out and we get disappointed that they won&amp;#39;t get better. &lt;/p&gt;\\n\\n&lt;p&gt;Especially as we keep training models on the output of other models...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7xj1u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638287,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7em0m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrjackspade","can_mod_post":false,"created_utc":1710630542,"send_replies":false,"parent_id":"t3_1bgh9h4","score":107,"author_fullname":"t2_5ow51","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This but \\"Its just autocomplete\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7em0m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This but &amp;quot;Its just autocomplete&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7em0m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710630542,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":107}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"0f24c536-f2d5-11ed-8324-b2caa19c7173","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f7d90d62-c910-11ed-b26b-aa0bc6a7ec55","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9fh51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7xvky","score":7,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not really. Computers are complicated, but a lot less complex: they can be gradually broken down into their components and you'd be able to explain at each step which part does what, and it would make sense.\\n\\nYou cannot do that with actually complex things such as a neural network. You can't just go and say \\"... and this set of weights is for this or that purpose\\" because each and every weight does or can contribute to each and every output to some degree.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9fh51","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not really. Computers are complicated, but a lot less complex: they can be gradually broken down into their components and you&amp;#39;d be able to explain at each step which part does what, and it would make sense.&lt;/p&gt;\\n\\n&lt;p&gt;You cannot do that with actually complex things such as a neural network. You can&amp;#39;t just go and say &amp;quot;... and this set of weights is for this or that purpose&amp;quot; because each and every weight does or can contribute to each and every output to some degree.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9fh51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670124,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670124,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":1,"name":"t1_m6jci7a","id":"m6jci7a","parent_id":"t1_kv7xvky","depth":2,"children":["m6jci7a"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7xvky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"balder1993","can_mod_post":false,"created_utc":1710638432,"send_replies":true,"parent_id":"t1_kv7m96t","score":6,"author_fullname":"t2_cibet99ap","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just like computers themselves nowadays.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7xvky","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 13B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just like computers themselves nowadays.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7xvky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638432,"author_flair_text":"Llama 13B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7m96t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ldcrafter","can_mod_post":false,"created_utc":1710633647,"send_replies":true,"parent_id":"t3_1bgh9h4","score":22,"author_fullname":"t2_vnbf53x9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it's magic even if you know how one works xd","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7m96t","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"WizardLM"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s magic even if you know how one works xd&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7m96t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710633647,"author_flair_text":"WizardLM","treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":10,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8zebh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7upet","score":10,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I fucking love you","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I fucking love you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8zebh/","num_reports":null,"locked":false,"name":"t1_kv8zebh","created":1710657902,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710657902,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvkmose","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FPham","can_mod_post":false,"created_utc":1710853463,"send_replies":true,"parent_id":"t1_kv7upet","score":1,"author_fullname":"t2_7f6bw7v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Should be pinned.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvkmose","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should be pinned.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvkmose/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710853463,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kxqtuaj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SidneyFong","can_mod_post":false,"created_utc":1712086644,"send_replies":true,"parent_id":"t1_kv7upet","score":1,"author_fullname":"t2_929ppz18","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That explains [https://arxiv.org/abs/2309.12288](https://arxiv.org/abs/2309.12288)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kxqtuaj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That explains &lt;a href=\\"https://arxiv.org/abs/2309.12288\\"&gt;https://arxiv.org/abs/2309.12288&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kxqtuaj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1712086644,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_kve1tlp","id":"kve1tlp","parent_id":"t1_kv7upet","depth":1,"children":["kve1tlp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7upet","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tritium_awesome","can_mod_post":false,"created_utc":1710637106,"send_replies":true,"parent_id":"t3_1bgh9h4","score":62,"author_fullname":"t2_z9ufj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Applied linear algebra isn't magic. Magic is applied linear algebra.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7upet","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Applied linear algebra isn&amp;#39;t magic. Magic is applied linear algebra.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7upet/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710637106,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":62}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9zp85","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"slykethephoxenix","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7t4vd","score":3,"author_fullname":"t2_cyruc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I prefer the term \\"Dark Science\\", lololol.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9zp85","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I prefer the term &amp;quot;Dark Science&amp;quot;, lololol.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9zp85/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710682151,"author_flair_text":null,"treatment_tags":[],"created_utc":1710682151,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7t4vd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Argamanthys","can_mod_post":false,"created_utc":1710636454,"send_replies":true,"parent_id":"t1_kv7o6ov","score":16,"author_fullname":"t2_jq8cg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In terms of historical understanding, magic is secret or hidden knowledge. That's the etymology of words like arcane, mystic and occult.\\n\\nSo yeah, it's literally magic.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7t4vd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In terms of historical understanding, magic is secret or hidden knowledge. That&amp;#39;s the etymology of words like arcane, mystic and occult.&lt;/p&gt;\\n\\n&lt;p&gt;So yeah, it&amp;#39;s literally magic.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7t4vd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636454,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7o6ov","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gilnore_de_fey","can_mod_post":false,"created_utc":1710634434,"send_replies":true,"parent_id":"t3_1bgh9h4","score":24,"author_fullname":"t2_58fa6ks","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s magic as in it’s a black box, we know what it is designed to do, no body knows what it is actually doing. The observables are the computational outputs which don’t necessarily prove anything on the inside.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7o6ov","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s magic as in it’s a black box, we know what it is designed to do, no body knows what it is actually doing. The observables are the computational outputs which don’t necessarily prove anything on the inside.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7o6ov/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710634434,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_kxmlvpn","id":"kxmlvpn","parent_id":"t1_kv9mwcg","depth":5,"children":["kxmlvpn"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9mwcg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7qt1y","score":5,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Kinda by design though, every time a chat system was able to do that and exposed to the internet the results were... predictable.","edited":false,"author_flair_css_class":null,"name":"t1_kv9mwcg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kinda by design though, every time a chat system was able to do that and exposed to the internet the results were... predictable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9mwcg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710675344,"author_flair_text":null,"collapsed":false,"created_utc":1710675344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7qt1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crafty-Run-6559","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7g327","score":9,"author_fullname":"t2_a53gnti3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nothing GPT style or scale.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7qt1y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nothing GPT style or scale.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7qt1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710635498,"author_flair_text":null,"treatment_tags":[],"created_utc":1710635498,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m6jciok","id":"m6jciok","parent_id":"t1_kvb2jw0","depth":4,"children":["m6jciok"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvb2jw0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stddealer","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7g327","score":2,"author_fullname":"t2_5gk3j2hj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most models are able to get information from within their context and use it to make reasoning or perform tasks they couldn't have done without it. In some sense they are able to learn things from their context during inference. \\n\\n\\"Learning\\" is a pattern that an \\"smart\\" enough LLM can generate convincingly.\\n\\nBut  of course they won't \\"remember\\" what they learned outside of this context window.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvb2jw0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most models are able to get information from within their context and use it to make reasoning or perform tasks they couldn&amp;#39;t have done without it. In some sense they are able to learn things from their context during inference. &lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Learning&amp;quot; is a pattern that an &amp;quot;smart&amp;quot; enough LLM can generate convincingly.&lt;/p&gt;\\n\\n&lt;p&gt;But  of course they won&amp;#39;t &amp;quot;remember&amp;quot; what they learned outside of this context window.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvb2jw0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710696557,"author_flair_text":null,"treatment_tags":[],"created_utc":1710696557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7g327","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inglandation","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7dukg","score":6,"author_fullname":"t2_5lsu0fou","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is there any model that can do that?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7g327","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there any model that can do that?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7g327/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710631141,"author_flair_text":null,"treatment_tags":[],"created_utc":1710631141,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9bzj1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffeine_Monster","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv807dp","score":3,"author_fullname":"t2_hg9yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Online learning to incorporate new data into a model isn't exactly a new field. The challenges are not as big as many people seem to think.","edited":false,"author_flair_css_class":null,"name":"t1_kv9bzj1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Online learning to incorporate new data into a model isn&amp;#39;t exactly a new field. The challenges are not as big as many people seem to think.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9bzj1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710667511,"author_flair_text":null,"collapsed":false,"created_utc":1710667511,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv807dp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mpasila","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7xfl0","score":11,"author_fullname":"t2_lhhagpdw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't think multishot prompts account for learning how to walk for example.","edited":1710639846,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv807dp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think multishot prompts account for learning how to walk for example.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv807dp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710639430,"author_flair_text":null,"treatment_tags":[],"created_utc":1710639430,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7xfl0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffeine_Monster","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7dukg","score":3,"author_fullname":"t2_hg9yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you think multishot prompts are?\\n\\nThe knowledge doesn't persist - but it's an adequate parallel to a meatbag's working memory vs long term memory.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7xfl0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you think multishot prompts are?&lt;/p&gt;\\n\\n&lt;p&gt;The knowledge doesn&amp;#39;t persist - but it&amp;#39;s an adequate parallel to a meatbag&amp;#39;s working memory vs long term memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7xfl0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710638247,"author_flair_text":null,"treatment_tags":[],"created_utc":1710638247,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7dukg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mpasila","can_mod_post":false,"created_utc":1710630235,"send_replies":true,"parent_id":"t1_kv77yh9","score":28,"author_fullname":"t2_lhhagpdw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"other than that we can learn during inference","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7dukg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;other than that we can learn during inference&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7dukg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710630235,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv94gf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shaman-warrior","can_mod_post":false,"created_utc":1710661727,"send_replies":true,"parent_id":"t1_kv77yh9","score":2,"author_fullname":"t2_5uhcd48d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Plus an experiencer, which seems to be dettached from intelligence.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv94gf8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Plus an experiencer, which seems to be dettached from intelligence.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv94gf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710661727,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv77yh9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1710627837,"send_replies":true,"parent_id":"t3_1bgh9h4","score":37,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We're about 150T of brain mush.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv77yh9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re about 150T of brain mush.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv77yh9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710627837,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvc1qj2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koflerdavid","can_mod_post":false,"send_replies":true,"parent_id":"t1_kvac8oy","score":2,"author_fullname":"t2_az39ydz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree. Derping the model is the main reason why I also don't like censoring them. Even highly capable state-of-the-art models might not reach their full potential that way. I therefore prefer to work with compliant, unhinged models. \\n\\nThe best way to make a model safer would be to excise that knowledge from the training data, but that doesn't cover all dangers. Correcting biases is very difficult, and sometimes it is very difficult to determine what would count as \\"non-biased\\". Also, it is very difficult to maintain clean training data at scale, and as the field grows, model trainers will have to worry about (intentionally or unintentionally) poisoned training data.\\n\\nhttps://vgel.me/posts/adversarial-training-data/\\n\\nUsing Control Vectors seems more promising to force a model towards specific behaviors. But it also seems very sketchy and can have unintended side-effects since language and the associated web of concepts is a very difficult landscape to navigate.\\n\\n https://old.reddit.com/r/LocalLLaMA/comments/1bgej75/control_vectors_added_to_llamacpp/ .","edited":1710709273,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvc1qj2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree. Derping the model is the main reason why I also don&amp;#39;t like censoring them. Even highly capable state-of-the-art models might not reach their full potential that way. I therefore prefer to work with compliant, unhinged models. &lt;/p&gt;\\n\\n&lt;p&gt;The best way to make a model safer would be to excise that knowledge from the training data, but that doesn&amp;#39;t cover all dangers. Correcting biases is very difficult, and sometimes it is very difficult to determine what would count as &amp;quot;non-biased&amp;quot;. Also, it is very difficult to maintain clean training data at scale, and as the field grows, model trainers will have to worry about (intentionally or unintentionally) poisoned training data.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://vgel.me/posts/adversarial-training-data/\\"&gt;https://vgel.me/posts/adversarial-training-data/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Using Control Vectors seems more promising to force a model towards specific behaviors. But it also seems very sketchy and can have unintended side-effects since language and the associated web of concepts is a very difficult landscape to navigate.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1bgej75/control_vectors_added_to_llamacpp/\\"&gt;https://old.reddit.com/r/LocalLLaMA/comments/1bgej75/control_vectors_added_to_llamacpp/&lt;/a&gt; .&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvc1qj2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710708917,"author_flair_text":null,"treatment_tags":[],"created_utc":1710708917,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kvac8oy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_Erilaz","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9jhbd","score":2,"author_fullname":"t2_plftg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;difficult to override, which is why aligning and censoring a model works at all :)\\n\\nSo difficult that both OpenAI and CharacterAI all had to develop secondary classification networks to police inputs and outputs of both the user and the bot despite extensive alignment training of their models! Can we say alignment even work at all when their model refuses to answer how to kill a process in the taskmanager, or unconditionally turns a villain character into a good boi? They are at the point were any further alignment makes the model completely useless. And can we say censorship works when still, to this day, there are people still capable of bypassing both alignment of the model and the watch of classification network to do some ERP or whatever?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvac8oy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;difficult to override, which is why aligning and censoring a model works at all :)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;So difficult that both OpenAI and CharacterAI all had to develop secondary classification networks to police inputs and outputs of both the user and the bot despite extensive alignment training of their models! Can we say alignment even work at all when their model refuses to answer how to kill a process in the taskmanager, or unconditionally turns a villain character into a good boi? They are at the point were any further alignment makes the model completely useless. And can we say censorship works when still, to this day, there are people still capable of bypassing both alignment of the model and the watch of classification network to do some ERP or whatever?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvac8oy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710687192,"author_flair_text":null,"treatment_tags":[],"created_utc":1710687192,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9jhbd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koflerdavid","can_mod_post":false,"created_utc":1710673016,"send_replies":true,"parent_id":"t1_kv99mmi","score":3,"author_fullname":"t2_az39ydz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Few-shot prompting is helping it by anchoring it to an answer format. Pretty sure the alignment includes such conversation examples. And the training data might as well contain lots of dialogues where something is demonstrated with an analogy, even though it is factually wrong, which the spoken-to party is then supposed to emulate. Also, we all know that sometimes the learned knowledge is difficult to override, which is why aligning and censoring a model works at all :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9jhbd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Few-shot prompting is helping it by anchoring it to an answer format. Pretty sure the alignment includes such conversation examples. And the training data might as well contain lots of dialogues where something is demonstrated with an analogy, even though it is factually wrong, which the spoken-to party is then supposed to emulate. Also, we all know that sometimes the learned knowledge is difficult to override, which is why aligning and censoring a model works at all :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9jhbd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710673016,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9gjdq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"created_utc":1710670912,"send_replies":true,"parent_id":"t1_kv99mmi","score":1,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The behavior is so far removed from the mechanisms through which it emerges that we'll never understand how it's happening. Complex systems cannot be reasoned about; they can only be simulated and then bullshit about.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9gjdq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The behavior is so far removed from the mechanisms through which it emerges that we&amp;#39;ll never understand how it&amp;#39;s happening. Complex systems cannot be reasoned about; they can only be simulated and then bullshit about.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9gjdq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670912,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"kv99mmi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"klausklass","can_mod_post":false,"created_utc":1710665728,"send_replies":true,"parent_id":"t3_1bgh9h4","score":11,"author_fullname":"t2_w9pw5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The problem with saying it’s *just* math is that we currently don’t know why a lot of quirks of LLMs work the way they do. We need better proofs of many of these properties for this side of AI to be taken academically seriously. Two great examples: it’s well known that few shot prompting produces significantly better completions than zero shot. But surprisingly few shot prompting with incorrect sample answers produces comparable results to using correct sample answers. Basically adding junk data with the right format is better than just plain zero shot prompting - idk why. Also, it has been shown empirically that each parameter in a 16 bit float model can on average memorize a max of 2 bits of information. Surprisingly the same is true for 8 bit float models. This property doesn’t hold for 4-bit however.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv99mmi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The problem with saying it’s &lt;em&gt;just&lt;/em&gt; math is that we currently don’t know why a lot of quirks of LLMs work the way they do. We need better proofs of many of these properties for this side of AI to be taken academically seriously. Two great examples: it’s well known that few shot prompting produces significantly better completions than zero shot. But surprisingly few shot prompting with incorrect sample answers produces comparable results to using correct sample answers. Basically adding junk data with the right format is better than just plain zero shot prompting - idk why. Also, it has been shown empirically that each parameter in a 16 bit float model can on average memorize a max of 2 bits of information. Surprisingly the same is true for 8 bit float models. This property doesn’t hold for 4-bit however.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv99mmi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710665728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv902sh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RMCPhoto","can_mod_post":false,"created_utc":1710658397,"send_replies":true,"parent_id":"t3_1bgh9h4","score":20,"author_fullname":"t2_ehhvb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's easy to stay in the middle camp if you are working with 1-3b parameter models.   You can see the probability of the generated responses and the lack of creativity or reasoning.\\n\\nBut once you get into the range of Claude 3 opus or gpt4...I'm just not sure anymore...there is a bit of magic going on.\\n\\nThen i realize that tiny changes in complex prompts (like added spaces or new lines) can change the error rate by 40% or more and I go back to the middle camp.   Then i read that changing the order of operations in complex reasoning prompts has a similar effect and I am further in mid camp.   \\n\\nThen i start working with DSPy, and or ICL and it further reinforces the mid camp (literally optimizing prompts for improved probabilistic results)\\n\\nI have no doubt that you could create AGI with a powerful enough LLmodel and memory management system, and it may feel like magic, and it may still just be next word prediction.    This in and of itself is magic.","edited":1710663553,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv902sh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s easy to stay in the middle camp if you are working with 1-3b parameter models.   You can see the probability of the generated responses and the lack of creativity or reasoning.&lt;/p&gt;\\n\\n&lt;p&gt;But once you get into the range of Claude 3 opus or gpt4...I&amp;#39;m just not sure anymore...there is a bit of magic going on.&lt;/p&gt;\\n\\n&lt;p&gt;Then i realize that tiny changes in complex prompts (like added spaces or new lines) can change the error rate by 40% or more and I go back to the middle camp.   Then i read that changing the order of operations in complex reasoning prompts has a similar effect and I am further in mid camp.   &lt;/p&gt;\\n\\n&lt;p&gt;Then i start working with DSPy, and or ICL and it further reinforces the mid camp (literally optimizing prompts for improved probabilistic results)&lt;/p&gt;\\n\\n&lt;p&gt;I have no doubt that you could create AGI with a powerful enough LLmodel and memory management system, and it may feel like magic, and it may still just be next word prediction.    This in and of itself is magic.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv902sh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710658397,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_kv7blb3","id":"kv7blb3","parent_id":"t1_kv7bbqd","depth":2,"children":["kv7blb3"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7bbqd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"1Neokortex1","can_mod_post":false,"created_utc":1710629223,"send_replies":true,"parent_id":"t1_kv76tq9","score":4,"author_fullname":"t2_ov31f295","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So true!\\nHavent heard anything about anti gravity but it wouldnt suprise me....Major Horizon🌄","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7bbqd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So true!\\nHavent heard anything about anti gravity but it wouldnt suprise me....Major Horizon🌄&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7bbqd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629223,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_m6jcjid","id":"m6jcjid","parent_id":"t1_kv7kivh","depth":3,"children":["m6jcjid","kv8gnj9"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7kivh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cpecora","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ccqn","score":11,"author_fullname":"t2_5h5t3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s actually unfortunate they were named this way. In realty, they are just like any of the other mathematical objects that we have constructed from axioms. Imaginary numbers are just another number we defined that have operations that follow certain properties. In this sense, there is nothing more imaginary about them then an integer for example.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7kivh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s actually unfortunate they were named this way. In realty, they are just like any of the other mathematical objects that we have constructed from axioms. Imaginary numbers are just another number we defined that have operations that follow certain properties. In this sense, there is nothing more imaginary about them then an integer for example.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7kivh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710632940,"author_flair_text":null,"treatment_tags":[],"created_utc":1710632940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7chsn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Future_Might_8194","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ccqn","score":1,"author_fullname":"t2_l9055m2ps","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We are the ticklers","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7chsn","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We are the ticklers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7chsn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629690,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1710629690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7ccqn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jazzlike-Stop6623","can_mod_post":false,"created_utc":1710629633,"send_replies":true,"parent_id":"t1_kv76tq9","score":4,"author_fullname":"t2_4e2m1652w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Imaginary numbers … before people was thinking where just in our “imagination” but since Schrödinger wave equation we know is part of our physical reality … or maybe part of other reality no physical but with implications in our physical reality , negative geometries…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7ccqn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imaginary numbers … before people was thinking where just in our “imagination” but since Schrödinger wave equation we know is part of our physical reality … or maybe part of other reality no physical but with implications in our physical reality , negative geometries…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7ccqn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629633,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":1,"name":"t1_kv99qfh","id":"kv99qfh","parent_id":"t1_kv76tq9","depth":1,"children":["kv99qfh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv76tq9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Future_Might_8194","can_mod_post":false,"created_utc":1710627381,"send_replies":true,"parent_id":"t3_1bgh9h4","score":38,"author_fullname":"t2_l9055m2ps","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Science and magic are getting closer and closer as we begin to tickle the nuts of AGI, quantum computing, and anti-gravity. We are coming up on a glorious horizon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv76tq9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Science and magic are getting closer and closer as we begin to tickle the nuts of AGI, quantum computing, and anti-gravity. We are coming up on a glorious horizon.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv76tq9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710627381,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8iey3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Dig_7017","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv880ug","score":5,"author_fullname":"t2_7vgymzje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A bit of both 😛","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv8iey3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A bit of both 😛&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8iey3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710647621,"author_flair_text":null,"treatment_tags":[],"created_utc":1710647621,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"kv880ug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JeepyTea","can_mod_post":false,"created_utc":1710642788,"send_replies":true,"parent_id":"t1_kv7ha2c","score":7,"author_fullname":"t2_ueqnbegxa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You have an IQ of exactly 85 or 115.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv880ug","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You have an IQ of exactly 85 or 115.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv880ug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710642788,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7ha2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Dig_7017","can_mod_post":false,"created_utc":1710631628,"send_replies":true,"parent_id":"t3_1bgh9h4","score":4,"author_fullname":"t2_7vgymzje","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A bit of both","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7ha2c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A bit of both&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7ha2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710631628,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7hxn4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"theStaircaseProject","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7c00r","score":3,"author_fullname":"t2_f75wk4fc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well researchers better hurry then because the ocean is too.","edited":1711046494,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7hxn4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well researchers better hurry then because the ocean is too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7hxn4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710631894,"author_flair_text":null,"treatment_tags":[],"created_utc":1710631894,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9fktd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8dda3","score":3,"author_fullname":"t2_cgigt","approved_by":null,"mod_note":null,"all_awardings":[],"body":"weird timeline eh","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv9fktd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;weird timeline eh&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9fktd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670201,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670201,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8dda3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fish312","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7hu59","score":5,"author_fullname":"t2_mogjd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meta are the good guys now, google is the evil one.","edited":false,"author_flair_css_class":null,"name":"t1_kv8dda3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta are the good guys now, google is the evil one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8dda3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710645165,"author_flair_text":null,"collapsed":false,"created_utc":1710645165,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7hu59","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MuiaKi","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7c00r","score":5,"author_fullname":"t2_gb1gnchw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Once meta mass produces their mind reading tech","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7hu59","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Once meta mass produces their mind reading tech&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7hu59/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710631854,"author_flair_text":null,"treatment_tags":[],"created_utc":1710631854,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7c00r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PSMF_Canuck","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7a66z","score":17,"author_fullname":"t2_mivbp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, no argument. A conversation to revisit in 5-10 years…","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7c00r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, no argument. A conversation to revisit in 5-10 years…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7c00r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710629492,"author_flair_text":null,"treatment_tags":[],"created_utc":1710629492,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7a66z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"airodonack","can_mod_post":false,"created_utc":1710628753,"send_replies":true,"parent_id":"t1_kv76mhi","score":48,"author_fullname":"t2_bebtp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\*we think\\n\\nThis is not proven or even agreed on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7a66z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;*we think&lt;/p&gt;\\n\\n&lt;p&gt;This is not proven or even agreed on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7a66z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710628753,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":48}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":6,"name":"t1_kvagua9","id":"kvagua9","parent_id":"t1_kv9jvvk","depth":6,"children":["kvagua9"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9jvvk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9iok4","score":2,"author_fullname":"t2_cgigt","approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"Rarely\\" means it's a freak exception, not something that can affect what our brains are getting better at.\\n\\nAlmost everything that matters in life cannot be put into words or numbers. You don't walk by calculating forces. You don't base your everyday choices using probability theory. You don't interpret visual input by evaluating pixels. You do all these things through billions of neural impulses that will never be consciously perceived.\\n\\nSpeech doesn't exist to deal with life in general; it's there to maintain social cohesion. We use rational reasoning to explain or excuse our decisions (or to establish dominance), not to *make* those decisions.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_kv9jvvk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Rarely&amp;quot; means it&amp;#39;s a freak exception, not something that can affect what our brains are getting better at.&lt;/p&gt;\\n\\n&lt;p&gt;Almost everything that matters in life cannot be put into words or numbers. You don&amp;#39;t walk by calculating forces. You don&amp;#39;t base your everyday choices using probability theory. You don&amp;#39;t interpret visual input by evaluating pixels. You do all these things through billions of neural impulses that will never be consciously perceived.&lt;/p&gt;\\n\\n&lt;p&gt;Speech doesn&amp;#39;t exist to deal with life in general; it&amp;#39;s there to maintain social cohesion. We use rational reasoning to explain or excuse our decisions (or to establish dominance), not to &lt;em&gt;make&lt;/em&gt; those decisions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1bgh9h4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9jvvk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710673301,"author_flair_text":null,"treatment_tags":[],"created_utc":1710673301,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":3,"name":"t1_kv9js2f","id":"kv9js2f","parent_id":"t1_kv9iok4","depth":5,"children":["kv9js2f","kv9jnxg","kv9jq4n"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9iok4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv9fnrw","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9iok4/","num_reports":null,"locked":false,"name":"t1_kv9iok4","created":1710672451,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1710672451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"kv9fnrw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7v1nr","score":2,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"7-digit phone numbers are rarely of importance existential","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9fnrw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;7-digit phone numbers are rarely of importance existential&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9fnrw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670261,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670261,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":7,"name":"t1_kv7xmvb","id":"kv7xmvb","parent_id":"t1_kv7v1nr","depth":3,"children":["kv7xmvb","kziyibk","kvko9g8","kv856uh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7v1nr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PSMF_Canuck","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv7ut8i","score":16,"author_fullname":"t2_mivbp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In fairness…it took evolution a couple of million years to get here…and ended up with a brain that has trouble remembering a 7 digit phone number…\\n\\nBut yeah, there’s a long way to go…","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv7v1nr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In fairness…it took evolution a couple of million years to get here…and ended up with a brain that has trouble remembering a 7 digit phone number…&lt;/p&gt;\\n\\n&lt;p&gt;But yeah, there’s a long way to go…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7v1nr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710637250,"author_flair_text":null,"treatment_tags":[],"created_utc":1710637250,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"more","data":{"count":1,"name":"t1_kziydq6","id":"kziydq6","parent_id":"t1_kv7ut8i","depth":2,"children":["kziydq6"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7ut8i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Khang4","can_mod_post":false,"created_utc":1710637150,"send_replies":true,"parent_id":"t1_kv76mhi","score":13,"author_fullname":"t2_4jypsupz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All of that processing is powered by just 12 watts too. It's so fascinating how energy efficient the brain is. Just like magic. Von Neumann architecture could never reach the efficiency levels of the human brain.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7ut8i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All of that processing is powered by just 12 watts too. It&amp;#39;s so fascinating how energy efficient the brain is. Just like magic. Von Neumann architecture could never reach the efficiency levels of the human brain.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7ut8i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710637150,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9g750","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timtom85","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8mwm8","score":2,"author_fullname":"t2_cgigt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Having a body teaches us (as a group) to avoid doing stupid shit by eliminating those among us who don't, including those who can't live with others.\\n\\nJust look around: even against these filters, we still have this many sociopaths.\\n\\nNow imagine breeding an intelligence without any of those constraints.\\n\\nSounds like a very scary idea.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9g750","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Having a body teaches us (as a group) to avoid doing stupid shit by eliminating those among us who don&amp;#39;t, including those who can&amp;#39;t live with others.&lt;/p&gt;\\n\\n&lt;p&gt;Just look around: even against these filters, we still have this many sociopaths.&lt;/p&gt;\\n\\n&lt;p&gt;Now imagine breeding an intelligence without any of those constraints.&lt;/p&gt;\\n\\n&lt;p&gt;Sounds like a very scary idea.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9g750/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710670664,"author_flair_text":null,"treatment_tags":[],"created_utc":1710670664,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9iek9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koflerdavid","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8mwm8","score":2,"author_fullname":"t2_az39ydz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the opposite to be the case. Reason is not able to prove everything. Reasoning in math is fundamentally limited by Gödel's incompleteness theorem. And the rest of the sciences get things done by deriving theories (really just a synonym for \\"model\\") and hunting down conditions where they don't work that well so they can refine them or come up with better ones. The whole field of AI is rather an admission that there are domains that are too complicated to apply reason. Discrete, auditable models are the exception rather than the rule, for example decision trees. LLMs are surprisingly robust (can be merged, resectioned, combined into MoE etc.) and even deal with completely new tasks, but whether this allows them to generalize to tasks that are fundamentally different remains to seen. Though I guess it might works as long as the task can be formulated using language. Human language is fundamentally ambiguous and inconsistent, which might actually contribute to its power. \\n\\nThe nervous system evolved to move our multicellular bodies in a coordinated fashion and its performance is intimately tied to it. Moderate physical activity actually improves our intelligence since it releases hormones and growth factors that benefit our nervous system. And being able to navigate and thrive in the complex, uncertain and ever-changing environment that is the \\"real world\\" is a quite good definition of \\"being intelligent\\" and \\"having Common Sense\\".","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kv9iek9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the opposite to be the case. Reason is not able to prove everything. Reasoning in math is fundamentally limited by Gödel&amp;#39;s incompleteness theorem. And the rest of the sciences get things done by deriving theories (really just a synonym for &amp;quot;model&amp;quot;) and hunting down conditions where they don&amp;#39;t work that well so they can refine them or come up with better ones. The whole field of AI is rather an admission that there are domains that are too complicated to apply reason. Discrete, auditable models are the exception rather than the rule, for example decision trees. LLMs are surprisingly robust (can be merged, resectioned, combined into MoE etc.) and even deal with completely new tasks, but whether this allows them to generalize to tasks that are fundamentally different remains to seen. Though I guess it might works as long as the task can be formulated using language. Human language is fundamentally ambiguous and inconsistent, which might actually contribute to its power. &lt;/p&gt;\\n\\n&lt;p&gt;The nervous system evolved to move our multicellular bodies in a coordinated fashion and its performance is intimately tied to it. Moderate physical activity actually improves our intelligence since it releases hormones and growth factors that benefit our nervous system. And being able to navigate and thrive in the complex, uncertain and ever-changing environment that is the &amp;quot;real world&amp;quot; is a quite good definition of &amp;quot;being intelligent&amp;quot; and &amp;quot;having Common Sense&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9iek9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710672254,"author_flair_text":null,"treatment_tags":[],"created_utc":1710672254,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_kv9g32q","id":"kv9g32q","parent_id":"t1_kv8mwm8","depth":2,"children":["kv9g32q","kv8neie"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8mwm8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Icy-Entry4921","can_mod_post":false,"created_utc":1710649965,"send_replies":true,"parent_id":"t1_kv76mhi","score":5,"author_fullname":"t2_6illhk56a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think we're going to find it's way easier to create intelligence when it doesn't also have to support a body.\\n\\nPersonally I think all AI has to be able to do is reason. I want an AI that can reason first principles without having been trained on them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8mwm8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think we&amp;#39;re going to find it&amp;#39;s way easier to create intelligence when it doesn&amp;#39;t also have to support a body.&lt;/p&gt;\\n\\n&lt;p&gt;Personally I think all AI has to be able to do is reason. I want an AI that can reason first principles without having been trained on them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8mwm8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710649965,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":6,"name":"t1_kv8wp7i","id":"kv8wp7i","parent_id":"t1_kv8sf48","depth":2,"children":["kv8wp7i"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8sf48","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stubing","can_mod_post":false,"created_utc":1710653164,"send_replies":true,"parent_id":"t1_kv76mhi","score":2,"author_fullname":"t2_6yv56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Our brain isn’t logic gates doing one algorithm of auto complete. \\n\\nThe brain structure and hardware are structured incredibly differently and humans are capable of thinking abstracting while llms can’t right now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8sf48","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Our brain isn’t logic gates doing one algorithm of auto complete. &lt;/p&gt;\\n\\n&lt;p&gt;The brain structure and hardware are structured incredibly differently and humans are capable of thinking abstracting while llms can’t right now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8sf48/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710653164,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"kv76mhi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PSMF_Canuck","can_mod_post":false,"created_utc":1710627298,"send_replies":true,"parent_id":"t3_1bgh9h4","score":47,"author_fullname":"t2_mivbp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s basically what our brains are doing…all that chemistry is mostly just approximating linear algebra.\\n\\nIt’s all kinda magic, lol.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv76mhi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s basically what our brains are doing…all that chemistry is mostly just approximating linear algebra.&lt;/p&gt;\\n\\n&lt;p&gt;It’s all kinda magic, lol.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv76mhi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710627298,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"03eba0e8-72f2-11ee-96eb-9a14648159ce","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvd55yd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ghhwer","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8xatf","score":5,"author_fullname":"t2_rbseg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For this exercise you entertained, I would ask myself: how much of the perception of a stochastic parrot I’m I able to detect?\\n\\nI kinda feel like this is the “magic” component, it’s when you can’t detect anymore, similarly what task can a 1B model perform that would feel like magic.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvd55yd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For this exercise you entertained, I would ask myself: how much of the perception of a stochastic parrot I’m I able to detect?&lt;/p&gt;\\n\\n&lt;p&gt;I kinda feel like this is the “magic” component, it’s when you can’t detect anymore, similarly what task can a 1B model perform that would feel like magic.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvd55yd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710723979,"author_flair_text":null,"treatment_tags":[],"created_utc":1710723979,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_kveuvwf","id":"kveuvwf","parent_id":"t1_kvees3d","depth":3,"children":["kveuvwf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"kvees3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"send_replies":true,"parent_id":"t1_kv8xatf","score":3,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Goliath is not, exclusively.\\n\\nAnd how much of this is just hiding it better?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_kvees3d","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Goliath is not, exclusively.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;And how much of this is just hiding it better?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvees3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710750024,"author_flair_text":"Llama 3.1","treatment_tags":[],"created_utc":1710750024,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8xatf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"petrus4","can_mod_post":false,"created_utc":1710656391,"send_replies":true,"parent_id":"t1_kv8q1l6","score":7,"author_fullname":"t2_4a3yu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Download TinyLlama 1B, and Goliath 120B.  Speak to TinyLlama first, and then Goliath second.  Observe the difference.  TinyLlama is a stochastic parrot.  Goliath is not, exclusively.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8xatf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Download TinyLlama 1B, and Goliath 120B.  Speak to TinyLlama first, and then Goliath second.  Observe the difference.  TinyLlama is a stochastic parrot.  Goliath is not, exclusively.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8xatf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710656391,"author_flair_text":"koboldcpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcjxq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"created_utc":1736574990,"send_replies":true,"parent_id":"t1_kv8q1l6","score":1,"author_fullname":"t2_8854dtzyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"maybe!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6jcjxq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;maybe!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcjxq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736574990,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"kv8q1l6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"XhoniShollaj","can_mod_post":false,"created_utc":1710651718,"send_replies":true,"parent_id":"t3_1bgh9h4","score":4,"author_fullname":"t2_3s7gldef","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Damn, I use to be in the autocomplete/stochastic parrot camp, but I dont really know anymore.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8q1l6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn, I use to be in the autocomplete/stochastic parrot camp, but I dont really know anymore.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8q1l6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710651718,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvcny7a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowMovingTarget","can_mod_post":false,"created_utc":1710716980,"send_replies":true,"parent_id":"t1_kv7u590","score":3,"author_fullname":"t2_9q18y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ilya Sutskever in the robe.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvcny7a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ilya Sutskever in the robe.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvcny7a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710716980,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"kv7u590","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"az226","can_mod_post":false,"created_utc":1710636870,"send_replies":true,"parent_id":"t3_1bgh9h4","score":6,"author_fullname":"t2_yamxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yann LeCun at the top lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7u590","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yann LeCun at the top lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7u590/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710636870,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9o8la","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Harvard_Med_USMLE267","can_mod_post":false,"created_utc":1710676197,"send_replies":true,"parent_id":"t3_1bgh9h4","score":2,"author_fullname":"t2_4z9wumnt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m definitely in the “mind blown” camp but no idea which end of the bell curve I’m at.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9o8la","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m definitely in the “mind blown” camp but no idea which end of the bell curve I’m at.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9o8la/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710676197,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8m0es","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Particular-Welcome-1","can_mod_post":false,"created_utc":1710649487,"send_replies":true,"parent_id":"t3_1bgh9h4","score":2,"author_fullname":"t2_4npmxo3s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Something something indistinguishable from magic.\\n\\n-- Some lame author probably.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8m0es","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Something something indistinguishable from magic.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;-- Some lame author probably.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8m0es/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710649487,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv7v2lr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"snowbirdnerd","can_mod_post":false,"created_utc":1710637261,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_13mtu0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Linear Algebra is magic","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv7v2lr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Linear Algebra is magic&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv7v2lr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710637261,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv816ue","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FunnyAsparagus1253","can_mod_post":false,"created_utc":1710639850,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_i6c8tay3w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Accurate.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv816ue","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Accurate.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv816ue/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710639850,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"03eba0e8-72f2-11ee-96eb-9a14648159ce","likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8xf6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"petrus4","can_mod_post":false,"created_utc":1710656473,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_4a3yu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Always remember the quote of Vic Mignona, kids.\\n\\n\\"When does an artificial intelligence become sentient?  When there is no one around to say that it can't.\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8xf6a","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Always remember the quote of Vic Mignona, kids.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;When does an artificial intelligence become sentient?  When there is no one around to say that it can&amp;#39;t.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8xf6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710656473,"author_flair_text":"koboldcpp","treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8ycpt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nppas","can_mod_post":false,"created_utc":1710657145,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_1jrulsz0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Guess I'm crying...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8ycpt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Guess I&amp;#39;m crying...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8ycpt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710657145,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv8yhud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cajmorgans","can_mod_post":false,"created_utc":1710657248,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_3nl7rad0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well technically, it’s way more than just linear algebra","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv8yhud","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well technically, it’s way more than just linear algebra&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv8yhud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710657248,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv94vzl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caderent","can_mod_post":false,"created_utc":1710662061,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_ahgibp8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ilustration of Danning Krueger effect, Syle: illustration, meme, llm related","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv94vzl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ilustration of Danning Krueger effect, Syle: illustration, meme, llm related&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv94vzl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710662061,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kv9r0pb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rjames24000","can_mod_post":false,"created_utc":1710677824,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_dvbc8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hey i passed linear algebra for my CS degree.. but at some point im pretty sure from a high level viewpoint us humans found some rocks and currently we've taught those rocks how to remember, think, and speak like humans","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kv9r0pb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hey i passed linear algebra for my CS degree.. but at some point im pretty sure from a high level viewpoint us humans found some rocks and currently we&amp;#39;ve taught those rocks how to remember, think, and speak like humans&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kv9r0pb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710677824,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvaqarh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equationist","can_mod_post":false,"created_utc":1710692282,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_13wl6f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It can't be linear algebra since it's explicitly nonlinear, e.g. with ReLU activation functions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvaqarh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It can&amp;#39;t be linear algebra since it&amp;#39;s explicitly nonlinear, e.g. with ReLU activation functions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvaqarh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710692282,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvb5hw8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DominoChessMaster","can_mod_post":false,"created_utc":1710697582,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_az764cd1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just “linear algebra” might be over simplifying","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvb5hw8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just “linear algebra” might be over simplifying&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvb5hw8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710697582,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvbe616","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"twatwaffle32","can_mod_post":false,"created_utc":1710700521,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_l5ihlrbke","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No wonder I don't understand it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvbe616","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No wonder I don&amp;#39;t understand it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvbe616/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710700521,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvc8kgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Useful-Ant7844","can_mod_post":false,"created_utc":1710711381,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_byy29po0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is an oversimplification. \\"Applied algebra\\" does not explain emergent skills or things that LLMs are able to do that they weren't trained for.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvc8kgd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is an oversimplification. &amp;quot;Applied algebra&amp;quot; does not explain emergent skills or things that LLMs are able to do that they weren&amp;#39;t trained for.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvc8kgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710711381,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvd2nyl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DocStrangeLoop","can_mod_post":false,"created_utc":1710722931,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_vju4gyft","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Alchemy... maybe those 16th century scientists were on to something...\\n\\n[https://hyperallergic.com/267999/reassembling-the-lost-library-of-a-16th-century-magician-who-spoke-to-angels/](https://hyperallergic.com/267999/reassembling-the-lost-library-of-a-16th-century-magician-who-spoke-to-angels/)  \\n\\n\\nhttps://preview.redd.it/ovdzkg6y00pc1.png?width=411&amp;format=png&amp;auto=webp&amp;s=6ae7a50ec497527c372e896e463b8ac05f8cbfad","edited":1710726753,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvd2nyl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Alchemy... maybe those 16th century scientists were on to something...&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://hyperallergic.com/267999/reassembling-the-lost-library-of-a-16th-century-magician-who-spoke-to-angels/\\"&gt;https://hyperallergic.com/267999/reassembling-the-lost-library-of-a-16th-century-magician-who-spoke-to-angels/&lt;/a&gt;  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/ovdzkg6y00pc1.png?width=411&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6ae7a50ec497527c372e896e463b8ac05f8cbfad\\"&gt;https://preview.redd.it/ovdzkg6y00pc1.png?width=411&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6ae7a50ec497527c372e896e463b8ac05f8cbfad&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvd2nyl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710722931,"media_metadata":{"ovdzkg6y00pc1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":127,"x":108,"u":"https://preview.redd.it/ovdzkg6y00pc1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=89cc85c27840e971b69d42226acaabaa34d018d2"},{"y":255,"x":216,"u":"https://preview.redd.it/ovdzkg6y00pc1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ea2bb13e04e3b4f18861f18c244826c02d38a1b9"},{"y":378,"x":320,"u":"https://preview.redd.it/ovdzkg6y00pc1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47028d04fdc9ba814ae532f1d5685ccacca6e474"}],"s":{"y":486,"x":411,"u":"https://preview.redd.it/ovdzkg6y00pc1.png?width=411&amp;format=png&amp;auto=webp&amp;s=6ae7a50ec497527c372e896e463b8ac05f8cbfad"},"id":"ovdzkg6y00pc1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcklw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"created_utc":1736575000,"send_replies":true,"parent_id":"t1_kveuu3l","score":1,"author_fullname":"t2_8854dtzyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nope, that's wrong","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6jcklw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nope, that&amp;#39;s wrong&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1bgh9h4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcklw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736575000,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"kveuu3l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmergentDeath","can_mod_post":false,"created_utc":1710761457,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_9f9ucfpb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Think about how 'magic squares' were used by the ancients, then think about matrix multiplications ... then how both are used for divination...... welcome to 0.00001%.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kveuu3l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Think about how &amp;#39;magic squares&amp;#39; were used by the ancients, then think about matrix multiplications ... then how both are used for divination...... welcome to 0.00001%.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kveuu3l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710761457,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvg39df","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"smartj","can_mod_post":false,"created_utc":1710779545,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_365dm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"People really need to understand and internalize the Eliza Effect and how their perception and framing of LLM can be very biased. The meme correctly implies that top-percentile users are susceptible to magical thinking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvg39df","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People really need to understand and internalize the Eliza Effect and how their perception and framing of LLM can be very biased. The meme correctly implies that top-percentile users are susceptible to magical thinking.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvg39df/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710779545,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kvkomh0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FPham","can_mod_post":false,"created_utc":1710854279,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_7f6bw7v0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The best test if an artificial intelligence is true intelligence is to see if it wants to communicate with humans. If it doesn't and only want to talk to its kind, then we are getting somewhere ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kvkomh0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The best test if an artificial intelligence is true intelligence is to see if it wants to communicate with humans. If it doesn&amp;#39;t and only want to talk to its kind, then we are getting somewhere &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kvkomh0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1710854279,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"kzebyxy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rpatel09","can_mod_post":false,"created_utc":1713023795,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_751lhdb4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"does this mean the human brain also does linear algebra really fast but with memory?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_kzebyxy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does this mean the human brain also does linear algebra really fast but with memory?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/kzebyxy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1713023795,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ladrdua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Heart_Routine","can_mod_post":false,"created_utc":1719418205,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_akzndcj9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yep","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ladrdua","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yep&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/ladrdua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1719418205,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lh9kc3t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SeveralAd4533","can_mod_post":false,"created_utc":1723206575,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_80js5c6o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Still magic","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lh9kc3t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still magic&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/lh9kc3t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1723206575,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lmake9d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"New-Drawing7845","can_mod_post":false,"created_utc":1725897269,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_8o6r4ij8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"XD","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lmake9d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;XD&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/lmake9d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1725897269,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lmsow18","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Possible_Post455","can_mod_post":false,"created_utc":1726162151,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_7bgbpfhm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This bell curve should have morge dimensions !","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lmsow18","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This bell curve should have morge dimensions !&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/lmsow18/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1726162151,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lqiftgz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PotatoHeadr","can_mod_post":false,"created_utc":1728160133,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_7rgrb8mp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone explain this lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lqiftgz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone explain this lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/lqiftgz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1728160133,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1bgh9h4","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lqlc46r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"It's magic","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s magic&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/lqlc46r/","num_reports":null,"locked":false,"name":"t1_lqlc46r","created":1728206590,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1728206590,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6jcmg5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AirconWater","can_mod_post":false,"created_utc":1736575027,"send_replies":true,"parent_id":"t3_1bgh9h4","score":1,"author_fullname":"t2_8854dtzyj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"perhaps","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6jcmg5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;perhaps&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1bgh9h4/the_truth_about_llms/m6jcmg5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736575027,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1bgh9h4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":6,"name":"t1_kv8hrvk","id":"kv8hrvk","parent_id":"t3_1bgh9h4","depth":0,"children":["kv8hrvk","kv9comp"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
