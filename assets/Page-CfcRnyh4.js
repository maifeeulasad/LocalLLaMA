import{j as e}from"./index-BpC9hjVs.js";import{R as t}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"\\nHey guys,\\n\\nI am starting to get into using local models and I wondered what the smallest model I can use that is knowledgeable about countries and doesn't hallucinate that much. I heard Gemma3n is good but I don't really need multimodal.\\n\\nIt's for a trivia game where users guess the country and ask questions to try and narrow down the answer. So for example someone could be asking, did this country recently win the world cup or what the national dish is etc. I'll try and add some system prompts to make sure the LLM never names the country in its responses for example.\\n\\n Technically I have a PC that has 6GB memory but I want to make a game everyone can play on most people's computers.\\n\\n Thanks all.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Smallest Model For A Trivia Game On Countries?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lozri7","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vmtcerol","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751371140,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\\n\\n&lt;p&gt;I am starting to get into using local models and I wondered what the smallest model I can use that is knowledgeable about countries and doesn&amp;#39;t hallucinate that much. I heard Gemma3n is good but I don&amp;#39;t really need multimodal.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s for a trivia game where users guess the country and ask questions to try and narrow down the answer. So for example someone could be asking, did this country recently win the world cup or what the national dish is etc. I&amp;#39;ll try and add some system prompts to make sure the LLM never names the country in its responses for example.&lt;/p&gt;\\n\\n&lt;p&gt;Technically I have a PC that has 6GB memory but I want to make a game everyone can play on most people&amp;#39;s computers.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks all.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lozri7","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"redandwhitearsenal","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/","subreddit_subscribers":493458,"created_utc":1751371140,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qyxpp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redandwhitearsenal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qyl3p","score":1,"author_fullname":"t2_vmtcerol","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Much appreciated!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qyxpp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Much appreciated!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lozri7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qyxpp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373631,"author_flair_text":null,"treatment_tags":[],"created_utc":1751373631,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qyl3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qw4kg","score":2,"author_fullname":"t2_idhb522c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; It's so odd that models trained on basically the entire internet don't do basic trivia that well.\\n\\nWhile it might be simply information, its not a basic task. Humans find trivia challenging enough to make a game out of it. Models that run in 6GB are tiny, they will have read enough trivia questions to respond in a way that sounds like trivia facts, but they dont have the space in their \\"mind\\" to remember any actual facts.\\n\\nI would recommend you try out models in the 7B-9B range at q4\\\\_k\\\\_m. That should fit in your desired space constraints while being at least usable. Dont go with models that are smaller, even a 4B model as q8 will be far worse than an 8B at q4 for most tasks.\\n\\nThe following are benchmarks that measure hallucinations and how well the models work with RAG. Check them out to see what you want to try.\\n\\n[https://github.com/lechmazur/confabulations](https://github.com/lechmazur/confabulations)\\n\\n[https://github.com/vectara/hallucination-leaderboard](https://github.com/vectara/hallucination-leaderboard)\\n\\nI have heard good things about GLM4 9B but havent personally tried it.\\n\\n[https://huggingface.co/THUDM/glm-4-9b-chat](https://huggingface.co/THUDM/glm-4-9b-chat)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qyl3p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt; It&amp;#39;s so odd that models trained on basically the entire internet don&amp;#39;t do basic trivia that well.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;While it might be simply information, its not a basic task. Humans find trivia challenging enough to make a game out of it. Models that run in 6GB are tiny, they will have read enough trivia questions to respond in a way that sounds like trivia facts, but they dont have the space in their &amp;quot;mind&amp;quot; to remember any actual facts.&lt;/p&gt;\\n\\n&lt;p&gt;I would recommend you try out models in the 7B-9B range at q4_k_m. That should fit in your desired space constraints while being at least usable. Dont go with models that are smaller, even a 4B model as q8 will be far worse than an 8B at q4 for most tasks.&lt;/p&gt;\\n\\n&lt;p&gt;The following are benchmarks that measure hallucinations and how well the models work with RAG. Check them out to see what you want to try.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lechmazur/confabulations\\"&gt;https://github.com/lechmazur/confabulations&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/vectara/hallucination-leaderboard\\"&gt;https://github.com/vectara/hallucination-leaderboard&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I have heard good things about GLM4 9B but havent personally tried it.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/THUDM/glm-4-9b-chat\\"&gt;https://huggingface.co/THUDM/glm-4-9b-chat&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lozri7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qyl3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373502,"author_flair_text":null,"treatment_tags":[],"created_utc":1751373502,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0sejbw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IJOY94","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qw4kg","score":2,"author_fullname":"t2_cq3rs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LLMs are modeling language sequences, not facts and ideas. That we sometimes get coherent facts and ideas is a nifty side-effect.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0sejbw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LLMs are modeling language sequences, not facts and ideas. That we sometimes get coherent facts and ideas is a nifty side-effect.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lozri7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0sejbw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751389069,"author_flair_text":null,"treatment_tags":[],"created_utc":1751389069,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qw4kg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redandwhitearsenal","can_mod_post":false,"created_utc":1751372567,"send_replies":true,"parent_id":"t1_n0qv3pl","score":1,"author_fullname":"t2_vmtcerol","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This was what I was afraid of to be honest. It's so odd that models trained on basically the entire internet don't do basic trivia that well. Any recommendations for model + RAG setups?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qw4kg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was what I was afraid of to be honest. It&amp;#39;s so odd that models trained on basically the entire internet don&amp;#39;t do basic trivia that well. Any recommendations for model + RAG setups?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lozri7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qw4kg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372567,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qv3pl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"created_utc":1751372168,"send_replies":true,"parent_id":"t3_1lozri7","score":3,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not even large open source models can reliably retell trivia. The largest Deepseek/Qwen model are pretty good at general knowledge but even then, they make shit up very readily.\\n\\nThis wont work if you want to just use a model \\"raw\\". You need supporting software.\\n\\nYou would be better served using RAG to provide a huge list of trivia that a small model could then choose from and formulate dialogue.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qv3pl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not even large open source models can reliably retell trivia. The largest Deepseek/Qwen model are pretty good at general knowledge but even then, they make shit up very readily.&lt;/p&gt;\\n\\n&lt;p&gt;This wont work if you want to just use a model &amp;quot;raw&amp;quot;. You need supporting software.&lt;/p&gt;\\n\\n&lt;p&gt;You would be better served using RAG to provide a huge list of trivia that a small model could then choose from and formulate dialogue.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qv3pl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lozri7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qz5w4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redandwhitearsenal","can_mod_post":false,"created_utc":1751373713,"send_replies":true,"parent_id":"t1_n0qybyk","score":1,"author_fullname":"t2_vmtcerol","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah It's starting to look like I might either have to use RAG or pass the info for that country into the context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qz5w4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah It&amp;#39;s starting to look like I might either have to use RAG or pass the info for that country into the context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lozri7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qz5w4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373713,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qybyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"notsosleepy","can_mod_post":false,"created_utc":1751373409,"send_replies":true,"parent_id":"t3_1lozri7","score":3,"author_fullname":"t2_7odip","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I built something like this but for guessing personalities. I achieved this by passing the Wikipedia article to the system prompt. But for countries it might be hit or miss as it could cover a lot of details. \\n You can check it out here https://ai-charades.com/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qybyk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I built something like this but for guessing personalities. I achieved this by passing the Wikipedia article to the system prompt. But for countries it might be hit or miss as it could cover a lot of details. \\n You can check it out here &lt;a href=\\"https://ai-charades.com/\\"&gt;https://ai-charades.com/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0qybyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373409,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lozri7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0r7jqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Needleworker_5247","can_mod_post":false,"created_utc":1751376604,"send_replies":true,"parent_id":"t3_1lozri7","score":2,"author_fullname":"t2_1gmprv51a1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you're leaning towards Retrieval-Augmented Generation (RAG) for your trivia game, consider exploring vector search options. Efficient indexing can significantly enhance performance even on constrained hardware. Check out [this article](https://pub.towardsai.net/unlocking-the-power-of-efficient-vector-search-in-rag-applications-c2e3a0c551d5) on vector search for RAG, which covers index choices and tuning, helping ensure minimal latency and effective retrieval within your memory limits. Might be useful paired with your trivia database to keep responses grounded.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0r7jqk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re leaning towards Retrieval-Augmented Generation (RAG) for your trivia game, consider exploring vector search options. Efficient indexing can significantly enhance performance even on constrained hardware. Check out &lt;a href=\\"https://pub.towardsai.net/unlocking-the-power-of-efficient-vector-search-in-rag-applications-c2e3a0c551d5\\"&gt;this article&lt;/a&gt; on vector search for RAG, which covers index choices and tuning, helping ensure minimal latency and effective retrieval within your memory limits. Might be useful paired with your trivia database to keep responses grounded.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lozri7/smallest_model_for_a_trivia_game_on_countries/n0r7jqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751376604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lozri7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
