import{j as e}from"./index-xfnGEtuL.js";import{R as t}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I uploaded a 10 second clip of myself playing minigolf, and it could even tell that I hit a hole in one. It gave me an accurate timeline description of the clip. I know it has to do with multi-modal capabilities but I am still somewhat confused from a technical perspective?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How do tools like ChatGPT, Gemini, and Grok derive context from a video?","link_flair_richtext":[{"e":"text","t":"Tutorial | Guide"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lr2z7q","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.77,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dmh5cakj","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Tutorial | Guide","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751582262,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I uploaded a 10 second clip of myself playing minigolf, and it could even tell that I hit a hole in one. It gave me an accurate timeline description of the clip. I know it has to do with multi-modal capabilities but I am still somewhat confused from a technical perspective?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"449b05a6-bf8e-11ed-b4bd-66961e47bd50","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#0079d3","id":"1lr2z7q","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Familiar_Engine718","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/","subreddit_subscribers":494198,"created_utc":1751582262,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17y9zu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UnreasonableEconomy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n17sjsp","score":1,"author_fullname":"t2_88lwr6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the late fusion approach works unreasonably well.\\n\\nBut it makes sense: each model already has its own concept of the world, and all you need to do is \\"fix\\" the embedding interface. \\n\\nI think Aza Raskin's team showed (or maybe it was someone else's work and he relayed it) that languages, no matter which, are approximately isomorphic in embedding space. Looks like it turns out that perhaps any world embedding tends to be approximately isomorphic as long as we live in the same world.\\n\\nIt's pretty crazy, if we take this to the limits it would imply that we might theoretically be able to graft a distant alien's mind to a human's, and it *could just work*.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n17y9zu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the late fusion approach works unreasonably well.&lt;/p&gt;\\n\\n&lt;p&gt;But it makes sense: each model already has its own concept of the world, and all you need to do is &amp;quot;fix&amp;quot; the embedding interface. &lt;/p&gt;\\n\\n&lt;p&gt;I think Aza Raskin&amp;#39;s team showed (or maybe it was someone else&amp;#39;s work and he relayed it) that languages, no matter which, are approximately isomorphic in embedding space. Looks like it turns out that perhaps any world embedding tends to be approximately isomorphic as long as we live in the same world.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s pretty crazy, if we take this to the limits it would imply that we might theoretically be able to graft a distant alien&amp;#39;s mind to a human&amp;#39;s, and it &lt;em&gt;could just work&lt;/em&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lr2z7q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/n17y9zu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751587167,"author_flair_text":null,"treatment_tags":[],"created_utc":1751587167,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n17sjsp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1751585161,"send_replies":true,"parent_id":"t1_n17ld8y","score":3,"author_fullname":"t2_131eezppgs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes it’s likely late fusion where they train separate LLM and vision encoders which are then combined later, with some further training after.\\n\\n\\nThe majority of strong multimodal projects used late fusion. It is enormously easier because you are training the LLM and vision encoders normally.\\n\\n\\nIf you follow the long chain of papers trying to make multimodal image generation, models like Bagel and Lumina mGPT, what you often find is late fusion methods work better. The appeal of early fusion though is that it is more “inherently multimodal” which will probably eventually produce very large benefits. It’s a very hard nut to crack. \\n\\n\\nFeels notable that Llama 4 used early fusion and somewhat flopped. (It’s stronger than its reputation though.)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17sjsp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes it’s likely late fusion where they train separate LLM and vision encoders which are then combined later, with some further training after.&lt;/p&gt;\\n\\n&lt;p&gt;The majority of strong multimodal projects used late fusion. It is enormously easier because you are training the LLM and vision encoders normally.&lt;/p&gt;\\n\\n&lt;p&gt;If you follow the long chain of papers trying to make multimodal image generation, models like Bagel and Lumina mGPT, what you often find is late fusion methods work better. The appeal of early fusion though is that it is more “inherently multimodal” which will probably eventually produce very large benefits. It’s a very hard nut to crack. &lt;/p&gt;\\n\\n&lt;p&gt;Feels notable that Llama 4 used early fusion and somewhat flopped. (It’s stronger than its reputation though.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lr2z7q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/n17sjsp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751585161,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n17ld8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"x0wl","can_mod_post":false,"created_utc":1751582729,"send_replies":true,"parent_id":"t3_1lr2z7q","score":10,"author_fullname":"t2_bzlmh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We don't know (closed source), but they most likely have an encoder that encodes both the video and audio into a sequence of (continuous) tokens that then are injected into model input (after the text embedding layer). \\n\\nHere's a paper on how it's done in Qwen: [https://arxiv.org/pdf/2503.20215](https://arxiv.org/pdf/2503.20215)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17ld8y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We don&amp;#39;t know (closed source), but they most likely have an encoder that encodes both the video and audio into a sequence of (continuous) tokens that then are injected into model input (after the text embedding layer). &lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s a paper on how it&amp;#39;s done in Qwen: &lt;a href=\\"https://arxiv.org/pdf/2503.20215\\"&gt;https://arxiv.org/pdf/2503.20215&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/n17ld8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751582729,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr2z7q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17m1pe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"colin_colout","can_mod_post":false,"created_utc":1751582957,"send_replies":true,"parent_id":"t3_1lr2z7q","score":1,"author_fullname":"t2_14l4ya","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The same magic where they can gain context from words. Tokenize the words (or chunks of frames of video) and do attention magic so it gets the context. \\n\\nSame idea as text.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17m1pe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The same magic where they can gain context from words. Tokenize the words (or chunks of frames of video) and do attention magic so it gets the context. &lt;/p&gt;\\n\\n&lt;p&gt;Same idea as text.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/n17m1pe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751582957,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr2z7q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17rhdt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1751584796,"send_replies":true,"parent_id":"t3_1lr2z7q","score":1,"author_fullname":"t2_131eezppgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As stated, we don’t know as they are closed.\\n\\n\\nNeed to be open to the idea that their methodologies are completely different to what is currently publicly known.\\n\\n\\nGPT o1 possibly existed internally one year prior to release as that rumoured Q-star project.\\n\\n\\nAlthough I must add it is perfectly plausible that Q-star was in fact some other reinforcement learning project such as self-play which we know Google works on also.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17rhdt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As stated, we don’t know as they are closed.&lt;/p&gt;\\n\\n&lt;p&gt;Need to be open to the idea that their methodologies are completely different to what is currently publicly known.&lt;/p&gt;\\n\\n&lt;p&gt;GPT o1 possibly existed internally one year prior to release as that rumoured Q-star project.&lt;/p&gt;\\n\\n&lt;p&gt;Although I must add it is perfectly plausible that Q-star was in fact some other reinforcement learning project such as self-play which we know Google works on also.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lr2z7q/how_do_tools_like_chatgpt_gemini_and_grok_derive/n17rhdt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751584796,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lr2z7q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
