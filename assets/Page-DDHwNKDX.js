import{j as e}from"./index-DUHdgJkW.js";import{R as l}from"./RedditPostRenderer-GnJ0dXKI.js";import"./index-DQ2a53Cm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Pretty much what the subject says \\\\^\\\\^\\n\\nGetting started with prompting a \\"naked\\" open-source LLM (Gemma 3) for function calling using a simple LangChain/Ollama setup in python and wondering what is the best prompt to maximize tool calling accuracy.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Is ReAct still the best prompt template?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ln5jqr","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.78,"author_flair_background_color":null,"subreddit_type":"public","ups":5,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1c7x793800","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":5,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751169850,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty much what the subject says ^^&lt;/p&gt;\\n\\n&lt;p&gt;Getting started with prompting a &amp;quot;naked&amp;quot; open-source LLM (Gemma 3) for function calling using a simple LangChain/Ollama setup in python and wondering what is the best prompt to maximize tool calling accuracy.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ln5jqr","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Kooky-Net784","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/","subreddit_subscribers":492625,"created_utc":1751169850,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0duhom","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Corporate_Drone31","can_mod_post":false,"created_utc":1751191188,"send_replies":true,"parent_id":"t3_1ln5jqr","score":2,"author_fullname":"t2_32o8hu91","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most models are only trained on one prompt template and *may* work OK on deviations from that template, but you're running the risk of leaving model performance on the table.\\n\\nI'm not really sure what you're doing based on your description, but you really should be following whatever prompt template the creators specified in the Jinja template, if you aren't doing it already. Otherwise, you're running the risk of confusing the model and reducing performance.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0duhom","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most models are only trained on one prompt template and &lt;em&gt;may&lt;/em&gt; work OK on deviations from that template, but you&amp;#39;re running the risk of leaving model performance on the table.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m not really sure what you&amp;#39;re doing based on your description, but you really should be following whatever prompt template the creators specified in the Jinja template, if you aren&amp;#39;t doing it already. Otherwise, you&amp;#39;re running the risk of confusing the model and reducing performance.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0duhom/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751191188,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln5jqr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ebouo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlaveZelda","can_mod_post":false,"created_utc":1751200122,"send_replies":true,"parent_id":"t3_1ln5jqr","score":2,"author_fullname":"t2_7cbr10bw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what is ReAct ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ebouo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what is ReAct ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0ebouo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751200122,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln5jqr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f9lu0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lazy-Pattern-5171","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0e15yi","score":1,"author_fullname":"t2_1lyjk8is25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0f9lu0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln5jqr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0f9lu0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751211982,"author_flair_text":null,"treatment_tags":[],"created_utc":1751211982,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0e5myo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FriskyFennecFox","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0e15yi","score":0,"author_fullname":"t2_1fqk2ehg7e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sphynx LLM","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0e5myo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sphynx LLM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln5jqr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0e5myo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751197341,"author_flair_text":null,"treatment_tags":[],"created_utc":1751197341,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0e15yi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JFHermes","can_mod_post":false,"created_utc":1751195037,"send_replies":true,"parent_id":"t1_n0dbfve","score":2,"author_fullname":"t2_cww41","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think he means the LLM is without clothes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0e15yi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think he means the LLM is without clothes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln5jqr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0e15yi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751195037,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dbfve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lazy-Pattern-5171","can_mod_post":false,"created_utc":1751179664,"send_replies":true,"parent_id":"t3_1ln5jqr","score":1,"author_fullname":"t2_1lyjk8is25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s ubiquitous, not necessarily best. What’s a “naked” LLM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dbfve","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s ubiquitous, not necessarily best. What’s a “naked” LLM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln5jqr/is_react_still_the_best_prompt_template/n0dbfve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751179664,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln5jqr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
