import{j as e}from"./index-DLSqWzaI.js";import{R as t}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Going to get one for the whole office to use. My research indicates CPU and GPU are critical. Planning on using Jan AI, but open to other suggestions. Wanting to spend $1,000 -&gt; $2,000 on a PC, but not sure at what point we'd start hitting diminishing returns as far as CPU and GPU go. Any advice is welcome.\\n\\nAs an additional question: what are the downsides of using just the CPU? Does it just take longer?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"offline AI for sensitive data processing like client bank statements PDFs to CSV - recommend me a solution","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvm3tl","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_pruyzkp","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752075831,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Going to get one for the whole office to use. My research indicates CPU and GPU are critical. Planning on using Jan AI, but open to other suggestions. Wanting to spend $1,000 -&amp;gt; $2,000 on a PC, but not sure at what point we&amp;#39;d start hitting diminishing returns as far as CPU and GPU go. Any advice is welcome.&lt;/p&gt;\\n\\n&lt;p&gt;As an additional question: what are the downsides of using just the CPU? Does it just take longer?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lvm3tl","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"GetInHereStalker","discussion_type":null,"num_comments":18,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/","subreddit_subscribers":497025,"created_utc":1752075831,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n278sgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2780c1","score":2,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP said \\"client bank statements\\" and that's what I want to discourage.","edited":false,"author_flair_css_class":null,"name":"t1_n278sgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP said &amp;quot;client bank statements&amp;quot; and that&amp;#39;s what I want to discourage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n278sgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752078278,"author_flair_text":null,"collapsed":false,"created_utc":1752078278,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2780c1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PromiseAcceptable","can_mod_post":false,"send_replies":true,"parent_id":"t1_n277lof","score":1,"author_fullname":"t2_73n3uc0l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What I used it for was for personal categorization of a project, not for something like banking, obviously you will have to do manual checks for something so important.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2780c1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What I used it for was for personal categorization of a project, not for something like banking, obviously you will have to do manual checks for something so important.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n2780c1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752078064,"author_flair_text":null,"treatment_tags":[],"created_utc":1752078064,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28rej1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"send_replies":true,"parent_id":"t1_n28poox","score":1,"author_fullname":"t2_t6m6d9my","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not?\\n\\nLLM's are not going to give the same output each time\\n\\nif you ask it \\"how to make a stone house\\", you will have different instructions then me.\\n\\nremember that google ai used to tell people to eat rocks for a healthy diet.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n28rej1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not?&lt;/p&gt;\\n\\n&lt;p&gt;LLM&amp;#39;s are not going to give the same output each time&lt;/p&gt;\\n\\n&lt;p&gt;if you ask it &amp;quot;how to make a stone house&amp;quot;, you will have different instructions then me.&lt;/p&gt;\\n\\n&lt;p&gt;remember that google ai used to tell people to eat rocks for a healthy diet.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28rej1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752093228,"author_flair_text":null,"treatment_tags":[],"created_utc":1752093228,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n28poox","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"send_replies":true,"parent_id":"t1_n28o5m0","score":2,"author_fullname":"t2_pruyzkp","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because we get to work with whatever they send us. If it's paper, it's paper.\\n\\nAlso, don't take tax advice from the Joker.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n28poox","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because we get to work with whatever they send us. If it&amp;#39;s paper, it&amp;#39;s paper.&lt;/p&gt;\\n\\n&lt;p&gt;Also, don&amp;#39;t take tax advice from the Joker.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28poox/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752092763,"author_flair_text":null,"treatment_tags":[],"created_utc":1752092763,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n28o5m0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"send_replies":true,"parent_id":"t1_n28hp21","score":1,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"last time I checked, banks already do all the work through Excel and other stuff.\\n\\nWhy involve a LLM that has a higher error rate?\\n\\nif the IRS finds out you have a 0.5% diff, then they will hunt you.\\n\\nthere is a short clip on the Joker, who is more scared of the IRS then batman. it was a old cartoon, but still, funny","edited":false,"author_flair_css_class":null,"name":"t1_n28o5m0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;last time I checked, banks already do all the work through Excel and other stuff.&lt;/p&gt;\\n\\n&lt;p&gt;Why involve a LLM that has a higher error rate?&lt;/p&gt;\\n\\n&lt;p&gt;if the IRS finds out you have a 0.5% diff, then they will hunt you.&lt;/p&gt;\\n\\n&lt;p&gt;there is a short clip on the Joker, who is more scared of the IRS then batman. it was a old cartoon, but still, funny&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28o5m0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752092344,"author_flair_text":null,"collapsed":false,"created_utc":1752092344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n28hp21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"send_replies":true,"parent_id":"t1_n277lof","score":1,"author_fullname":"t2_pruyzkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That would likely be way better of an error rate than having a human doing it. Just saying.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28hp21","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would likely be way better of an error rate than having a human doing it. Just saying.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28hp21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752090556,"author_flair_text":null,"treatment_tags":[],"created_utc":1752090556,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n277lof","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2768nq","score":5,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;if the comparison is &gt;99% then it's alright to save the output\\n\\nYou do you, but I'm pretty sure the IRS or other government agency is still going to hold you responsible for that &lt;1% error rate.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n277lof","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;if the comparison is &amp;gt;99% then it&amp;#39;s alright to save the output&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;You do you, but I&amp;#39;m pretty sure the IRS or other government agency is still going to hold you responsible for that &amp;lt;1% error rate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n277lof/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077951,"author_flair_text":null,"treatment_tags":[],"created_utc":1752077951,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2768nq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PromiseAcceptable","can_mod_post":false,"created_utc":1752077579,"send_replies":true,"parent_id":"t1_n272ml2","score":1,"author_fullname":"t2_73n3uc0l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean, he could compare with 3 different LLM that are known for their accuracy, that would be a plus and after that then do a match and if the comparison is &gt;99% then it's alright to save the output, I have done that for some image comparison using smolvlm2 and gemma and the results were quite good, only had to process each request 2-3 times.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2768nq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, he could compare with 3 different LLM that are known for their accuracy, that would be a plus and after that then do a match and if the comparison is &amp;gt;99% then it&amp;#39;s alright to save the output, I have done that for some image comparison using smolvlm2 and gemma and the results were quite good, only had to process each request 2-3 times.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n2768nq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077579,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n279mw6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"send_replies":true,"parent_id":"t1_n278d9g","score":1,"author_fullname":"t2_pruyzkp","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n279mw6","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n279mw6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752078511,"author_flair_text":null,"treatment_tags":[],"created_utc":1752078511,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n278d9g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n277j7r","score":1,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not particulary, and I have no idea what \\"Jan DB\\" is.  Personally I use either llama or qwen with llama.cpp.  You can look at a selection of models here:  https://huggingface.co/unsloth/collections","edited":false,"author_flair_css_class":null,"name":"t1_n278d9g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not particulary, and I have no idea what &amp;quot;Jan DB&amp;quot; is.  Personally I use either llama or qwen with llama.cpp.  You can look at a selection of models here:  &lt;a href=\\"https://huggingface.co/unsloth/collections\\"&gt;https://huggingface.co/unsloth/collections&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvm3tl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n278d9g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752078162,"author_flair_text":null,"collapsed":false,"created_utc":1752078162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n277j7r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"send_replies":true,"parent_id":"t1_n276v27","score":0,"author_fullname":"t2_pruyzkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you recommend me a 7B? Is there one on the Jan DB?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n277j7r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you recommend me a 7B? Is there one on the Jan DB?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n277j7r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077932,"author_flair_text":null,"treatment_tags":[],"created_utc":1752077932,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n276v27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n274d2k","score":1,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't know, I just wouldn't be using an LLM.  Things like double checking for errors or quickly looking over legalese, I can see.  Don't use it for direct conversion.\\n\\nIf you really want to give it a try, I would recommend that you try out a 7B or other small model.  You can easily run it CPU only on pretty modest hardware and it will let you get your feet wet.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n276v27","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t know, I just wouldn&amp;#39;t be using an LLM.  Things like double checking for errors or quickly looking over legalese, I can see.  Don&amp;#39;t use it for direct conversion.&lt;/p&gt;\\n\\n&lt;p&gt;If you really want to give it a try, I would recommend that you try out a 7B or other small model.  You can easily run it CPU only on pretty modest hardware and it will let you get your feet wet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n276v27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077749,"author_flair_text":null,"treatment_tags":[],"created_utc":1752077749,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n274d2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"created_utc":1752077057,"send_replies":true,"parent_id":"t1_n272ml2","score":1,"author_fullname":"t2_pruyzkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We're going to be looking over the output.\\n\\nWhat would you recommend as an alternative?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n274d2k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re going to be looking over the output.&lt;/p&gt;\\n\\n&lt;p&gt;What would you recommend as an alternative?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n274d2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077057,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n272ml2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752076581,"send_replies":true,"parent_id":"t3_1lvm3tl","score":6,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;data processing like client bank statements\\n\\nDon't.  Seriously don't use the LLM's for anything that requires accuracy.  If it's something you don't mind it being wrong once in a while, LLM's are great, otherwise just no.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n272ml2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;data processing like client bank statements&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Don&amp;#39;t.  Seriously don&amp;#39;t use the LLM&amp;#39;s for anything that requires accuracy.  If it&amp;#39;s something you don&amp;#39;t mind it being wrong once in a while, LLM&amp;#39;s are great, otherwise just no.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n272ml2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752076581,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvm3tl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27ccea","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jonahbenton","can_mod_post":false,"created_utc":1752079259,"send_replies":true,"parent_id":"t3_1lvm3tl","score":3,"author_fullname":"t2_17c5jy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I do this at home for personal statements from several banks, have a bit of a workflow to do pdf to text, then do some mechanical cleanup of the text, then use an llm to turn hard to parse tabular plain text into json, validated by confirming balances. Works reliably with qwen 2.5 32b at low temperature. I know many folks just use vision models directly on the statements but statement formats have a way of changing out from under you and I prefer to have some machinery there to simplify troubleshooting and to be asking less of the models rather than more.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27ccea","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I do this at home for personal statements from several banks, have a bit of a workflow to do pdf to text, then do some mechanical cleanup of the text, then use an llm to turn hard to parse tabular plain text into json, validated by confirming balances. Works reliably with qwen 2.5 32b at low temperature. I know many folks just use vision models directly on the statements but statement formats have a way of changing out from under you and I prefer to have some machinery there to simplify troubleshooting and to be asking less of the models rather than more.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n27ccea/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752079259,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvm3tl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2886vo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thecodemustflow","can_mod_post":false,"created_utc":1752087924,"send_replies":true,"parent_id":"t3_1lvm3tl","score":1,"author_fullname":"t2_riild","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"First you can use JAN without a GPU on any random computer using CPU, so you don't need to buy anything yet. but if you do want to buy something now, then if you want used then a 3090, if you want new get a Nvidia card with at least 16 gb of ram. AMD is fine but a less common apps it will struggle. but amd and rocm has made progress.\\n\\nMost desktop computers have 1 PCIe slot for a GPU, so you should be fine with any mid-size case / computer \\n\\nThe Workflow\\nThe model you select needs to be tested to see which one is best. You can preprocess all the pdfs using pandoc to pull out the data into text files.\\n\\nSo, you are taking PDF (not scanned statements) and processing them into a csv. This really is do able but maybe not consistently. \\n\\nIs this PDF an image-based pdf where you are going to have to process an image or is it a text-based PDF? \\n\\nPDF are a document display format and are not great for parsing data out of them.\\n\\nAre they all the same PDF ie the statement is from the same company?\\n\\nIf they are the same format then it is going to be easier.\\n\\nI processed Insurance Statement before and it's a pain, but I would think LLM have a chance at doing it well enough.\\n\\nThe First thing is how are you going to get the PDF into the chat prompt, via attaching the file which means JAN.ai is going to use a pdf library to read the file. Some pdf libraries only read the text part and not the tables parts, which are different. If the pdf is a scan, then you need to use an OCR model like Mistral OCR to get it into text.\\nOr the other way is to just select all the text and copy it and paste it into the prompt.\\n\\nNext is the focus would be on the system prompt; you want a custom prompt for each kind of statement with Few Shots Example. I would use chatgpt deep research or perplexity to help with the prompt. But is should have examples of the text and its output. You have to think clearly about which output format you want it to me in. XML tags, Json, text and Tables \\nWhen you are processing these pdfs, I would do 3 tries of the same pdf in a new chat for each try.\\n\\nYou can then use a text comparer to compare the 3 results or create another system prompt with examples to combine the results. \\n\\nBut any time you touch the llm you are only going to get a probabilistic result which can be wrong. \\n\\nOnce you have a workflow done that works 95%, I would try and do a finetune to focus the model on this one task and with the output you processed you already have the dataset for finetuning.\\n\\nthere is just a lot of copying and pasting and human work to process the pdfs, after you have something working you can hire a programmer to automate this.\\n\\nMessage me if you want to talk more about this, I have done this before but not with llms","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2886vo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;First you can use JAN without a GPU on any random computer using CPU, so you don&amp;#39;t need to buy anything yet. but if you do want to buy something now, then if you want used then a 3090, if you want new get a Nvidia card with at least 16 gb of ram. AMD is fine but a less common apps it will struggle. but amd and rocm has made progress.&lt;/p&gt;\\n\\n&lt;p&gt;Most desktop computers have 1 PCIe slot for a GPU, so you should be fine with any mid-size case / computer &lt;/p&gt;\\n\\n&lt;p&gt;The Workflow\\nThe model you select needs to be tested to see which one is best. You can preprocess all the pdfs using pandoc to pull out the data into text files.&lt;/p&gt;\\n\\n&lt;p&gt;So, you are taking PDF (not scanned statements) and processing them into a csv. This really is do able but maybe not consistently. &lt;/p&gt;\\n\\n&lt;p&gt;Is this PDF an image-based pdf where you are going to have to process an image or is it a text-based PDF? &lt;/p&gt;\\n\\n&lt;p&gt;PDF are a document display format and are not great for parsing data out of them.&lt;/p&gt;\\n\\n&lt;p&gt;Are they all the same PDF ie the statement is from the same company?&lt;/p&gt;\\n\\n&lt;p&gt;If they are the same format then it is going to be easier.&lt;/p&gt;\\n\\n&lt;p&gt;I processed Insurance Statement before and it&amp;#39;s a pain, but I would think LLM have a chance at doing it well enough.&lt;/p&gt;\\n\\n&lt;p&gt;The First thing is how are you going to get the PDF into the chat prompt, via attaching the file which means JAN.ai is going to use a pdf library to read the file. Some pdf libraries only read the text part and not the tables parts, which are different. If the pdf is a scan, then you need to use an OCR model like Mistral OCR to get it into text.\\nOr the other way is to just select all the text and copy it and paste it into the prompt.&lt;/p&gt;\\n\\n&lt;p&gt;Next is the focus would be on the system prompt; you want a custom prompt for each kind of statement with Few Shots Example. I would use chatgpt deep research or perplexity to help with the prompt. But is should have examples of the text and its output. You have to think clearly about which output format you want it to me in. XML tags, Json, text and Tables \\nWhen you are processing these pdfs, I would do 3 tries of the same pdf in a new chat for each try.&lt;/p&gt;\\n\\n&lt;p&gt;You can then use a text comparer to compare the 3 results or create another system prompt with examples to combine the results. &lt;/p&gt;\\n\\n&lt;p&gt;But any time you touch the llm you are only going to get a probabilistic result which can be wrong. &lt;/p&gt;\\n\\n&lt;p&gt;Once you have a workflow done that works 95%, I would try and do a finetune to focus the model on this one task and with the output you processed you already have the dataset for finetuning.&lt;/p&gt;\\n\\n&lt;p&gt;there is just a lot of copying and pasting and human work to process the pdfs, after you have something working you can hire a programmer to automate this.&lt;/p&gt;\\n\\n&lt;p&gt;Message me if you want to talk more about this, I have done this before but not with llms&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n2886vo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752087924,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvm3tl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28odvm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1752092406,"send_replies":true,"parent_id":"t1_n28i8i7","score":1,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it makes a lot of sense why someone would not just get access to their raw data, you know....\\n\\nit makes a lot of sense....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28odvm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it makes a lot of sense why someone would not just get access to their raw data, you know....&lt;/p&gt;\\n\\n&lt;p&gt;it makes a lot of sense....&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvm3tl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28odvm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752092406,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n28i8i7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GetInHereStalker","can_mod_post":false,"created_utc":1752090703,"send_replies":true,"parent_id":"t3_1lvm3tl","score":1,"author_fullname":"t2_pruyzkp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We work with both scanned paper pdfs and downloaded pdfs directly from the bank, so it will vary. Unfortunately not everyone wants to cooperate and we have to work with what we get. If I had it my way, I'd just download the excel history from the bank and not deal with any of this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28i8i7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We work with both scanned paper pdfs and downloaded pdfs directly from the bank, so it will vary. Unfortunately not everyone wants to cooperate and we have to work with what we get. If I had it my way, I&amp;#39;d just download the excel history from the bank and not deal with any of this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvm3tl/offline_ai_for_sensitive_data_processing_like/n28i8i7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752090703,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvm3tl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
