import{j as t}from"./index-CeRg6Q3f.js";import{R as e}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const a=[{kind:"Listing",data:{after:null,dist:1,modhash:"",geo_filter:"",children:[{kind:"t3",data:{approved_at_utc:null,subreddit:"LocalLLaMA",selftext:`OK, so I was playing around with classifier-free guidance, and it occurred to me:  Why not just put the whole damn string in there?  I loathe how programmatic the responses can be, so maybe that might give the poor thing some freaking room to breathe, lol.  Human beings do not acquire and use language that way, so why should my language model?  Better to let them percolate up through all that voodoo instead (?)

I'm using Qwen3-235B-A22 right now, but I don't see why it wouldn't work with any other model.

Just try it.  Disable all your samplers.  Use the entire string that you'd send to the model \\*including the instruct tags\\* as the guidance.  Depending on the model, you may want to try using e.g. "Continue" as the user prompt, and like "Continuing: " for the assistant response.  You may have to do a little wrangling to get it to work right, but it's a markedly different experience.  You'll see.

Caveat:  I couldn't fall asleep last night, so perhaps this is a subtle delusion.  I don't think so tho.  Try using the negative guidance, too, and watch it invert the ... umm, what should I call them, derr ... "homeostatic semantic property clusters" (?) in the output.  That is, it will flip the sexual orientation of characters, physical attributes, etc.

I'm aware that this is what CFG \\*does\\*, of course.  I'm just kinda nonplussed as to why it's never \\*applied\\* in this manner for instruct models.  UIs should have a knob you can fiddle with with 1 in the middle and then 0&lt;1 on one side and 1&lt;5  on the other which simply applies it to your ACTUAL PROMPT, period.  Don't submit the the actual tags/instructions to the model directly at all!  Don't use the chat API.  Don't use e.g. like koboldcpp "instruct" mode.  Use CFG to \\*guide\\* the model with its instructions instead and use "story" mode.  Then you could do even like sillytavern does and stack them.  Fold CFG into instruct.  Reserve the traditional instruct stuff for when you really need it.

For long-form, natural, \\*human\\* "free writing", this is clearly superior imho.  Maybe zillions of people have been doing this all along, but I've never seen this mentioned before.`,user_reports:[],saved:!1,mod_reason_title:null,gilded:0,clicked:!1,title:"Using classifier-free guidance to prompt instruct models (with the tags) works better for creative writing than prompting the model outright",link_flair_richtext:[{e:"text",t:"Generation"}],subreddit_name_prefixed:"r/LocalLLaMA",hidden:!1,pwls:6,link_flair_css_class:"",downs:0,thumbnail_height:null,top_awarded_type:null,hide_score:!1,name:"t3_1lnqtog",quarantine:!1,link_flair_text_color:"light",upvote_ratio:.5,author_flair_background_color:null,subreddit_type:"public",ups:0,total_awards_received:0,media_embed:{},thumbnail_width:null,author_flair_template_id:null,is_original_content:!1,author_fullname:"t2_r0x1k85",secure_media:null,is_reddit_media_domain:!1,is_meta:!1,category:null,secure_media_embed:{},link_flair_text:"Generation",can_mod_post:!1,score:0,approved_by:null,is_created_from_ads_ui:!1,author_premium:!1,thumbnail:"self",edited:1751234988,author_flair_css_class:null,author_flair_richtext:[],gildings:{},content_categories:null,is_self:!0,mod_note:null,created:1751234355,link_flair_type:"richtext",wls:6,removed_by_category:null,banned_by:null,author_flair_type:"text",domain:"self.LocalLLaMA",allow_live_comments:!1,selftext_html:`&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;OK, so I was playing around with classifier-free guidance, and it occurred to me:  Why not just put the whole damn string in there?  I loathe how programmatic the responses can be, so maybe that might give the poor thing some freaking room to breathe, lol.  Human beings do not acquire and use language that way, so why should my language model?  Better to let them percolate up through all that voodoo instead (?)&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using Qwen3-235B-A22 right now, but I don&amp;#39;t see why it wouldn&amp;#39;t work with any other model.&lt;/p&gt;

&lt;p&gt;Just try it.  Disable all your samplers.  Use the entire string that you&amp;#39;d send to the model *including the instruct tags* as the guidance.  Depending on the model, you may want to try using e.g. &amp;quot;Continue&amp;quot; as the user prompt, and like &amp;quot;Continuing: &amp;quot; for the assistant response.  You may have to do a little wrangling to get it to work right, but it&amp;#39;s a markedly different experience.  You&amp;#39;ll see.&lt;/p&gt;

&lt;p&gt;Caveat:  I couldn&amp;#39;t fall asleep last night, so perhaps this is a subtle delusion.  I don&amp;#39;t think so tho.  Try using the negative guidance, too, and watch it invert the ... umm, what should I call them, derr ... &amp;quot;homeostatic semantic property clusters&amp;quot; (?) in the output.  That is, it will flip the sexual orientation of characters, physical attributes, etc.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m aware that this is what CFG *does*, of course.  I&amp;#39;m just kinda nonplussed as to why it&amp;#39;s never *applied* in this manner for instruct models.  UIs should have a knob you can fiddle with with 1 in the middle and then 0&amp;lt;1 on one side and 1&amp;lt;5  on the other which simply applies it to your ACTUAL PROMPT, period.  Don&amp;#39;t submit the the actual tags/instructions to the model directly at all!  Don&amp;#39;t use the chat API.  Don&amp;#39;t use e.g. like koboldcpp &amp;quot;instruct&amp;quot; mode.  Use CFG to *guide* the model with its instructions instead and use &amp;quot;story&amp;quot; mode.  Then you could do even like sillytavern does and stack them.  Fold CFG into instruct.  Reserve the traditional instruct stuff for when you really need it.&lt;/p&gt;

&lt;p&gt;For long-form, natural, *human* &amp;quot;free writing&amp;quot;, this is clearly superior imho.  Maybe zillions of people have been doing this all along, but I&amp;#39;ve never seen this mentioned before.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;`,likes:null,suggested_sort:null,banned_at_utc:null,view_count:null,archived:!1,no_follow:!0,is_crosspostable:!1,pinned:!1,over_18:!1,all_awardings:[],awarders:[],media_only:!1,link_flair_template_id:"23bddba8-ff56-11ed-9688-1a11994b71f7",can_gild:!1,spoiler:!1,locked:!1,author_flair_text:null,treatment_tags:[],visited:!1,removed_by:null,num_reports:null,distinguished:null,subreddit_id:"t5_81eyvm",author_is_blocked:!1,mod_reason_by:null,removal_reason:null,link_flair_background_color:"#b5a3d0",id:"1lnqtog",is_robot_indexable:!0,num_duplicates:0,report_reasons:null,author:"apodicity",discussion_type:null,num_comments:0,send_replies:!0,media:null,contest_mode:!1,author_patreon_flair:!1,author_flair_text_color:null,permalink:"/r/LocalLLaMA/comments/1lnqtog/using_classifierfree_guidance_to_prompt_instruct/",stickied:!1,url:"https://www.reddit.com/r/LocalLLaMA/comments/1lnqtog/using_classifierfree_guidance_to_prompt_instruct/",subreddit_subscribers:492929,created_utc:1751234355,num_crossposts:0,mod_reports:[],is_video:!1}}],before:null}},{kind:"Listing",data:{after:null,dist:null,modhash:"",geo_filter:"",children:[],before:null}}],l=()=>t.jsx(e,{data:a});export{l as default};
