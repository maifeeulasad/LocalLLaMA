import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm new to running LLM's locally and have been working on a new project that has an \\"AI powered\\" requirement... I've learned a ton in the process but feel like I'm missing something.\\n\\nThe idea is to take a large csv that has been aggregated and formatted from various other sources, then feed that to an LLM that can identify trends, flag items that need attention, allow queries etc... but it can't use 3rd party API's\\n\\nI'm using self hosted Open Web UI API as my backend with Ollama and Mistral behind it all running on a 64GB AWS EC2 instance CPU only.   \\n  \\nThe file is too large to fit into the context window alone so I tried using the Files / Knowledge / RAG functionality that comes with OpenWebUI but that seems to really struggle to understand the entire dataset. \\n\\nFor example it's unable to tell me how many lines are in the file, or which item ID appears most often. \\n\\nJust curious if I'm going about this all wrong. Is this even realistic?\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Analyzing CSV and structured data - RAG, MCP, tools, or plain old scripting?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7mu6e","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_jlnyy","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753308541,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m new to running LLM&amp;#39;s locally and have been working on a new project that has an &amp;quot;AI powered&amp;quot; requirement... I&amp;#39;ve learned a ton in the process but feel like I&amp;#39;m missing something.&lt;/p&gt;\\n\\n&lt;p&gt;The idea is to take a large csv that has been aggregated and formatted from various other sources, then feed that to an LLM that can identify trends, flag items that need attention, allow queries etc... but it can&amp;#39;t use 3rd party API&amp;#39;s&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m using self hosted Open Web UI API as my backend with Ollama and Mistral behind it all running on a 64GB AWS EC2 instance CPU only.   &lt;/p&gt;\\n\\n&lt;p&gt;The file is too large to fit into the context window alone so I tried using the Files / Knowledge / RAG functionality that comes with OpenWebUI but that seems to really struggle to understand the entire dataset. &lt;/p&gt;\\n\\n&lt;p&gt;For example it&amp;#39;s unable to tell me how many lines are in the file, or which item ID appears most often. &lt;/p&gt;\\n\\n&lt;p&gt;Just curious if I&amp;#39;m going about this all wrong. Is this even realistic?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m7mu6e","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Tactical_Chicken","discussion_type":null,"num_comments":1,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7mu6e/analyzing_csv_and_structured_data_rag_mcp_tools/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7mu6e/analyzing_csv_and_structured_data_rag_mcp_tools/","subreddit_subscribers":503516,"created_utc":1753308541,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4tauha","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1753316514,"send_replies":true,"parent_id":"t3_1m7mu6e","score":2,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Some of those things (like counting lines and how many IDs appear most often) are tasks for which LLMs are not very good, but are simple and easy to do with scripting.\\n\\nAs a general rule, if something is easy and obvious to do with scripting, you should go ahead and script it.  It will work more reliably, orders of magnitude more quickly, and with a lot less compute and RAM.  If a task is too vague, fluid, or hard to define to allow for an obvious scripting solution, try LLM inference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4tauha","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some of those things (like counting lines and how many IDs appear most often) are tasks for which LLMs are not very good, but are simple and easy to do with scripting.&lt;/p&gt;\\n\\n&lt;p&gt;As a general rule, if something is easy and obvious to do with scripting, you should go ahead and script it.  It will work more reliably, orders of magnitude more quickly, and with a lot less compute and RAM.  If a task is too vague, fluid, or hard to define to allow for an obvious scripting solution, try LLM inference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7mu6e/analyzing_csv_and_structured_data_rag_mcp_tools/n4tauha/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753316514,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m7mu6e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
