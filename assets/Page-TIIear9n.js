import{j as e}from"./index-BgwOAK4-.js";import{R as t}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey all,Â  Iâ€™m doing user research around **how developers maintain consistent â€œpersonalityâ€ across time and context in LLM applications.**\\n\\nIf youâ€™ve ever built:\\n\\nAn AI tutor, assistant, therapist, or customer-facing chatbot\\n\\nA long-term memory agent, role-playing app, or character\\n\\nAnything where *how the AI acts or remembers* mattersâ€¦\\n\\nâ€¦Iâ€™d love to hear:\\n\\nWhat tools/hacks have you tried (e.g., prompt engineering, memory chaining, fine-tuning)\\n\\nWhere things broke down\\n\\nWhat you wish existed to make it easier","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Help me, I'm struggling with maintaining personality in LLMs? Iâ€™d love to learn from your experience!","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvydpk","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_yzj2i9o3k","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752105575,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey all,Â  Iâ€™m doing user research around &lt;strong&gt;how developers maintain consistent â€œpersonalityâ€ across time and context in LLM applications.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If youâ€™ve ever built:&lt;/p&gt;\\n\\n&lt;p&gt;An AI tutor, assistant, therapist, or customer-facing chatbot&lt;/p&gt;\\n\\n&lt;p&gt;A long-term memory agent, role-playing app, or character&lt;/p&gt;\\n\\n&lt;p&gt;Anything where &lt;em&gt;how the AI acts or remembers&lt;/em&gt; mattersâ€¦&lt;/p&gt;\\n\\n&lt;p&gt;â€¦Iâ€™d love to hear:&lt;/p&gt;\\n\\n&lt;p&gt;What tools/hacks have you tried (e.g., prompt engineering, memory chaining, fine-tuning)&lt;/p&gt;\\n\\n&lt;p&gt;Where things broke down&lt;/p&gt;\\n\\n&lt;p&gt;What you wish existed to make it easier&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lvydpk","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ApartFerret1850","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/","subreddit_subscribers":497354,"created_utc":1752105575,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2axjkc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ae71s","score":1,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh I only tried it on local models, I triedn gemma 1b, 4b, llama 3,2 1b, 4b, qwen3 30ba3b was the winner, but I had to hide the &lt;think&gt; portion","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2axjkc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh I only tried it on local models, I triedn gemma 1b, 4b, llama 3,2 1b, 4b, qwen3 30ba3b was the winner, but I had to hide the &amp;lt;think&amp;gt; portion&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2axjkc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752119184,"author_flair_text":null,"treatment_tags":[],"created_utc":1752119184,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ae71s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ApartFerret1850","can_mod_post":false,"created_utc":1752111946,"send_replies":true,"parent_id":"t1_n29wjk0","score":0,"author_fullname":"t2_yzj2i9o3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" This is helpful, no such thing as a â€œdumb little appâ€ when youâ€™re pressure-testing what works across models ðŸ‘ŠðŸ¾\\n\\nIâ€™ve been building a Personality API to solve that exact pain: models drifting out of character,  \\nInconsistent tone, memory loss across sessions.\\n\\nWhat kind of models were you testing with? Curious if you saw better results with Claude, GPT, or open weights like Mistral/LLaMA?\\n\\nAlso, did you try any tricks like:\\n\\nâ€œThought scaffoldingâ€?\\n\\nSystem prompt reinforcement every few turns?\\n\\nRoleplay tokens or signature tags? \\n\\nWould love to hear more, youâ€™re hitting the exact edge cases that matter for long-term personality alignment. Letâ€™s keep this convo going.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ae71s","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is helpful, no such thing as a â€œdumb little appâ€ when youâ€™re pressure-testing what works across models ðŸ‘ŠðŸ¾&lt;/p&gt;\\n\\n&lt;p&gt;Iâ€™ve been building a Personality API to solve that exact pain: models drifting out of character,&lt;br/&gt;\\nInconsistent tone, memory loss across sessions.&lt;/p&gt;\\n\\n&lt;p&gt;What kind of models were you testing with? Curious if you saw better results with Claude, GPT, or open weights like Mistral/LLaMA?&lt;/p&gt;\\n\\n&lt;p&gt;Also, did you try any tricks like:&lt;/p&gt;\\n\\n&lt;p&gt;â€œThought scaffoldingâ€?&lt;/p&gt;\\n\\n&lt;p&gt;System prompt reinforcement every few turns?&lt;/p&gt;\\n\\n&lt;p&gt;Roleplay tokens or signature tags? &lt;/p&gt;\\n\\n&lt;p&gt;Would love to hear more, youâ€™re hitting the exact edge cases that matter for long-term personality alignment. Letâ€™s keep this convo going.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2ae71s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111946,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n29wjk0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1752105819,"send_replies":true,"parent_id":"t3_1lvydpk","score":1,"author_fullname":"t2_i5os0v0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I made a character system for a dumb little app I made.\\n\\nIt was just simple prompting, different models handle the rolelpay very differently though, Some can't remember to stay in character very long.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29wjk0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I made a character system for a dumb little app I made.&lt;/p&gt;\\n\\n&lt;p&gt;It was just simple prompting, different models handle the rolelpay very differently though, Some can&amp;#39;t remember to stay in character very long.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n29wjk0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105819,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvydpk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2afptn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ApartFerret1850","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aem6z","score":-1,"author_fullname":"t2_yzj2i9o3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All good, not trying to shill, just vibing with folks whoâ€™ve run into the same pain points Iâ€™ve seen in the wild. If your setupâ€™s already locking in solid personality, thatâ€™s dope. Most of what Iâ€™ve seen (especially on Reddit) is people hacking it together with memory logs, prompt stacking, or XML wrappers just to stay in character. Not every tool is for everyone, but itâ€™s dope to hear local models are working smoothly for you. Might hit you up to learn more about your setup.\\n\\nRespect.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2afptn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All good, not trying to shill, just vibing with folks whoâ€™ve run into the same pain points Iâ€™ve seen in the wild. If your setupâ€™s already locking in solid personality, thatâ€™s dope. Most of what Iâ€™ve seen (especially on Reddit) is people hacking it together with memory logs, prompt stacking, or XML wrappers just to stay in character. Not every tool is for everyone, but itâ€™s dope to hear local models are working smoothly for you. Might hit you up to learn more about your setup.&lt;/p&gt;\\n\\n&lt;p&gt;Respect.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2afptn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112478,"author_flair_text":null,"treatment_tags":[],"created_utc":1752112478,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aem6z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tat_tvam_asshole","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aefno","score":1,"author_fullname":"t2_jxuvgdyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tbh, I never have this issue, even with local models. please shill elsewhere.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2aem6z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tbh, I never have this issue, even with local models. please shill elsewhere.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2aem6z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112093,"author_flair_text":null,"treatment_tags":[],"created_utc":1752112093,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aefno","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ApartFerret1850","can_mod_post":false,"created_utc":1752112029,"send_replies":true,"parent_id":"t1_n29wmhu","score":-2,"author_fullname":"t2_yzj2i9o3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, Iâ€™ve been doing that too, but it starts to fall apart fast.\\n\\nBurns tokens and still loses the character sometimes.\\n\\nThatâ€™s actually why Iâ€™m building a Personality API (Clueo), so you donâ€™t have to inject the same identity over and over again. It just *remembers*. What model are you using for this setup? And have you noticed it drifts more in longer conversations or topic switches?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aefno","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, Iâ€™ve been doing that too, but it starts to fall apart fast.&lt;/p&gt;\\n\\n&lt;p&gt;Burns tokens and still loses the character sometimes.&lt;/p&gt;\\n\\n&lt;p&gt;Thatâ€™s actually why Iâ€™m building a Personality API (Clueo), so you donâ€™t have to inject the same identity over and over again. It just &lt;em&gt;remembers&lt;/em&gt;. What model are you using for this setup? And have you noticed it drifts more in longer conversations or topic switches?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2aefno/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112029,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n29wmhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tat_tvam_asshole","can_mod_post":false,"created_utc":1752105846,"send_replies":true,"parent_id":"t3_1lvydpk","score":1,"author_fullname":"t2_jxuvgdyj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"long context history + system instructions injected on every turn","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29wmhu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;long context history + system instructions injected on every turn&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n29wmhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105846,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvydpk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2admm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ApartFerret1850","can_mod_post":false,"created_utc":1752111746,"send_replies":true,"parent_id":"t1_n2a6mu7","score":0,"author_fullname":"t2_yzj2i9o3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yo, this is ðŸ”¥. You broke it down like an ops manual. Iâ€™ve been working on building a Personality API that abstracts away a lot of what youâ€™re describing (memory chains, entropy tuning, dynamic system injections, etc). \\n\\n Curious about a few things:\\n\\nHave you noticed certain *models* (e.g., Mistral, LLaMA-3, Claude) handle the &lt;private thoughts&gt; schema better than others? Or is that more about how aggressively they weigh system prompts?\\n\\nFor the temperature sweep, any heuristics for what ranges typically keep the persona from degrading? Or is it case-by-case, based on prompt density?\\n\\nLastly, you mentioned â€œprepping phaseâ€ before production. Are you simulating this *with user input* (like onboarding), or is it more about frontloading a bunch of persona turns in the background?\\n\\n\\n\\n\\n\\nAppreciate this breakdown. Letâ€™s keep riffing â€” you clearly understand the edge cases most people overlook.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2admm0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yo, this is ðŸ”¥. You broke it down like an ops manual. Iâ€™ve been working on building a Personality API that abstracts away a lot of what youâ€™re describing (memory chains, entropy tuning, dynamic system injections, etc). &lt;/p&gt;\\n\\n&lt;p&gt;Curious about a few things:&lt;/p&gt;\\n\\n&lt;p&gt;Have you noticed certain &lt;em&gt;models&lt;/em&gt; (e.g., Mistral, LLaMA-3, Claude) handle the &amp;lt;private thoughts&amp;gt; schema better than others? Or is that more about how aggressively they weigh system prompts?&lt;/p&gt;\\n\\n&lt;p&gt;For the temperature sweep, any heuristics for what ranges typically keep the persona from degrading? Or is it case-by-case, based on prompt density?&lt;/p&gt;\\n\\n&lt;p&gt;Lastly, you mentioned â€œprepping phaseâ€ before production. Are you simulating this &lt;em&gt;with user input&lt;/em&gt; (like onboarding), or is it more about frontloading a bunch of persona turns in the background?&lt;/p&gt;\\n\\n&lt;p&gt;Appreciate this breakdown. Letâ€™s keep riffing â€” you clearly understand the edge cases most people overlook.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvydpk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2admm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111746,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a6mu7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sgt_brutal","can_mod_post":false,"created_utc":1752109314,"send_replies":true,"parent_id":"t3_1lvydpk","score":1,"author_fullname":"t2_hbdl8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Assuming you use models in chat mode, define the persona/identity using a first-person narrative in a lengthy content block. Enclose this block in \\"&lt;private thoughts&gt;\\" XML tags so you can parse and cull it from the text proper. Generate and/or prefill a few turns of conversation, making sure the persona uses the \\"private thoughts\\" regime liberally, alternating with explicit writing / roleplay behavior in a non-patterned way. You may do this in a context of simulating a prepping or interview phase before the production/proper stage. Just make it long enough to ensure the persona sticks. \\n\\nNext, calibrate entropy. I recommend fixing top\\\\_p at 0.99 and performing a temperature sweep. You want to find the temperature where the model can sustain the persona for the longest without collapsing into \\"schizo\\" (high temperature) or \\"loopy\\" (low temperature) modes. Every model will eventually succumb to one of these failure modes, but with larger models, there is a reasonable chance that the user terminates the session long before. You could produce more authentic personalities in completion mode or using base models, but they require longer preparation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a6mu7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Assuming you use models in chat mode, define the persona/identity using a first-person narrative in a lengthy content block. Enclose this block in &amp;quot;&amp;lt;private thoughts&amp;gt;&amp;quot; XML tags so you can parse and cull it from the text proper. Generate and/or prefill a few turns of conversation, making sure the persona uses the &amp;quot;private thoughts&amp;quot; regime liberally, alternating with explicit writing / roleplay behavior in a non-patterned way. You may do this in a context of simulating a prepping or interview phase before the production/proper stage. Just make it long enough to ensure the persona sticks. &lt;/p&gt;\\n\\n&lt;p&gt;Next, calibrate entropy. I recommend fixing top_p at 0.99 and performing a temperature sweep. You want to find the temperature where the model can sustain the persona for the longest without collapsing into &amp;quot;schizo&amp;quot; (high temperature) or &amp;quot;loopy&amp;quot; (low temperature) modes. Every model will eventually succumb to one of these failure modes, but with larger models, there is a reasonable chance that the user terminates the session long before. You could produce more authentic personalities in completion mode or using base models, but they require longer preparation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2a6mu7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752109314,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvydpk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ambjg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SAPPHIR3ROS3","can_mod_post":false,"created_utc":1752114818,"send_replies":true,"parent_id":"t3_1lvydpk","score":1,"author_fullname":"t2_2vre9dh1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The simplest way to implement it without any external system is with a telos file like [this](https://github.com/danielmiessler/Telos) but you write the info of the character there","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ambjg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The simplest way to implement it without any external system is with a telos file like &lt;a href=\\"https://github.com/danielmiessler/Telos\\"&gt;this&lt;/a&gt; but you write the info of the character there&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2ambjg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752114818,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvydpk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2gc03l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Physical-Ad-7770","can_mod_post":false,"created_utc":1752189056,"send_replies":true,"parent_id":"t3_1lvydpk","score":1,"author_fullname":"t2_9fppyyst","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2gc03l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvydpk/help_me_im_struggling_with_maintaining/n2gc03l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752189056,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvydpk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
