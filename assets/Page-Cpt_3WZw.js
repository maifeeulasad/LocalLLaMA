import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"What will be better?  \\nIQ3\\\\_M 24B mistral small 3.1/3.2 vs Q5\\\\_K\\\\_M 12B mistral nemo","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"24B IQ3_M vs 12B Q5_K_M","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lq3urv","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1irjq3mta2","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751481864,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;What will be better?&lt;br/&gt;\\nIQ3_M 24B mistral small 3.1/3.2 vs Q5_K_M 12B mistral nemo&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lq3urv","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Longjumping_Bee_6825","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/","subreddit_subscribers":494198,"created_utc":1751481864,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zrcsq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1751482936,"send_replies":true,"parent_id":"t3_1lq3urv","score":17,"author_fullname":"t2_lpdsy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably 24B @ IQ3_M.  Generally larger models perform better than smaller, given the same quant target size.\\n\\nHowever, you should definitely test.  Sometimes using higher quants will actually improve performance in specific scenarios but other times they can tank it (relatively).  So while the 24B is _probably_ better, I can't say what will work better for you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zrcsq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably 24B @ IQ3_M.  Generally larger models perform better than smaller, given the same quant target size.&lt;/p&gt;\\n\\n&lt;p&gt;However, you should definitely test.  Sometimes using higher quants will actually improve performance in specific scenarios but other times they can tank it (relatively).  So while the 24B is &lt;em&gt;probably&lt;/em&gt; better, I can&amp;#39;t say what will work better for you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n0zrcsq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751482936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zs3fx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fizzy1242","can_mod_post":false,"created_utc":1751483161,"send_replies":true,"parent_id":"t3_1lq3urv","score":4,"author_fullname":"t2_16zcsx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Test it out. Depends on your use case, 24b is probably better for conversing but the 12b might be better for higher precision tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zs3fx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Test it out. Depends on your use case, 24b is probably better for conversing but the 12b might be better for higher precision tasks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n0zs3fx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751483161,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n11sai3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lemon07r","can_mod_post":false,"created_utc":1751505712,"send_replies":true,"parent_id":"t3_1lq3urv","score":2,"author_fullname":"t2_i697e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"mistral nemo is terrible. There are several 8/9b models that are better. mistral small 3.2 is very good for its size. so this isnt even a competition. but if we pretend youre comparing two models from the same family, and model series, like gemma 3 24b vs 12b if we pretended they existed, the 24b at iq3\\\\_m will still be much better than the 12b q5\\\\_K\\\\_M.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11sai3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mistral nemo is terrible. There are several 8/9b models that are better. mistral small 3.2 is very good for its size. so this isnt even a competition. but if we pretend youre comparing two models from the same family, and model series, like gemma 3 24b vs 12b if we pretended they existed, the 24b at iq3_m will still be much better than the 12b q5_K_M.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n11sai3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751505712,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zpv9v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LicensedTerrapin","can_mod_post":false,"created_utc":1751482494,"send_replies":true,"parent_id":"t3_1lq3urv","score":5,"author_fullname":"t2_97zi8wea","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"24b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zpv9v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;24b&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n0zpv9v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751482494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n11otgo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RiskyBizz216","can_mod_post":false,"created_utc":1751504574,"send_replies":true,"parent_id":"t3_1lq3urv","score":1,"author_fullname":"t2_4eu8nupk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"depends on your use case, nemo sucks at tool calling and following instructions, I would not recommend it for coding.\\n\\nin my tests mistral small 3.1 outperforms 3.2\\n\\nmagistral was surprisingly the worst.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11otgo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;depends on your use case, nemo sucks at tool calling and following instructions, I would not recommend it for coding.&lt;/p&gt;\\n\\n&lt;p&gt;in my tests mistral small 3.1 outperforms 3.2&lt;/p&gt;\\n\\n&lt;p&gt;magistral was surprisingly the worst.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n11otgo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751504574,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n121chi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Majestical-psyche","can_mod_post":false,"created_utc":1751508703,"send_replies":true,"parent_id":"t3_1lq3urv","score":1,"author_fullname":"t2_5nb53p53","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They're different models. They perform differently. But personally I prefer Nemo 8Q over small 8Q. Nemo is just easier to work with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n121chi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;re different models. They perform differently. But personally I prefer Nemo 8Q over small 8Q. Nemo is just easier to work with.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n121chi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751508703,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n100zs6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751485860,"send_replies":true,"parent_id":"t3_1lq3urv","score":1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For what? Those are different model, with different use cases.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n100zs6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For what? Those are different model, with different use cases.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq3urv/24b_iq3_m_vs_12b_q5_k_m/n100zs6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751485860,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq3urv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),_=()=>e.jsx(l,{data:t});export{_ as default};
