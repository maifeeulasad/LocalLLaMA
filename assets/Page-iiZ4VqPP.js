import{j as e}from"./index-DQXiEb7D.js";import{R as l}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Been here since llama1 area.. what a crazy ride!  \\nNow we have that little devstral 2507.  \\nTo me it feels as good as deepseek R1 the first but runs on dual 3090 ! (Ofc q8 with 45k ctx).  \\nDo you feel the same thing? Ho my.. open weights models won't be as fun without Mistral ðŸ‡¨ðŸ‡µ\\n\\n(To me it feels like 8x7b again but better ðŸ˜† )","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Have you tried that new devstral?! Myyy! The next 8x7b?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxyg6z","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.87,"author_flair_background_color":"#bbbdbf","subreddit_type":"public","ups":51,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_cj9kap4bx","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":51,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752320636,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Been here since llama1 area.. what a crazy ride!&lt;br/&gt;\\nNow we have that little devstral 2507.&lt;br/&gt;\\nTo me it feels as good as deepseek R1 the first but runs on dual 3090 ! (Ofc q8 with 45k ctx).&lt;br/&gt;\\nDo you feel the same thing? Ho my.. open weights models won&amp;#39;t be as fun without Mistral ðŸ‡¨ðŸ‡µ&lt;/p&gt;\\n\\n&lt;p&gt;(To me it feels like 8x7b again but better ðŸ˜† )&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lxyg6z","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"No_Afternoon_4260","discussion_type":null,"num_comments":44,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/","subreddit_subscribers":498345,"created_utc":1752320636,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2tkqfm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Environmental-Metal9","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2t6ak5","score":1,"author_fullname":"t2_6x9o42az","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can see it. Iâ€™d pay a developer friendly price for weights that I can run locally and are particularly good at swift and SwiftUI. Toss some extra apple frameworks in there and some knowledge of the wider ecosystem in a non rent seeking way, and Iâ€™d even pay a premium price. Old school pricing though, I donâ€™t want more subscriptions","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2tkqfm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can see it. Iâ€™d pay a developer friendly price for weights that I can run locally and are particularly good at swift and SwiftUI. Toss some extra apple frameworks in there and some knowledge of the wider ecosystem in a non rent seeking way, and Iâ€™d even pay a premium price. Old school pricing though, I donâ€™t want more subscriptions&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2tkqfm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752368009,"author_flair_text":null,"treatment_tags":[],"created_utc":1752368009,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vnyrv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752404626,"send_replies":true,"parent_id":"t1_n2uyaor","score":1,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah they published some interesting papers, mostly edge models afaik. Funny that they chose a diffusion model (or they poorly chose the name haha)\\n\\nThanks for the precisions","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2vnyrv","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah they published some interesting papers, mostly edge models afaik. Funny that they chose a diffusion model (or they poorly chose the name haha)&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for the precisions&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vnyrv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404626,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uyaor","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2tlice","score":1,"author_fullname":"t2_1f3xb4r4ae","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They published a small coding model recently, based on the Dream architecture and Qwen2.5, called DiffuCoder. Apple is not in the LLM business, and IMO it's not their profession. But they provide excellent tools for LLM developers (CoreML, MLX, etc.). \\n\\nATM, they are working on reducing the size of training data and models. They often publish papers on the topic if you want to check. But they are mostly quiet about it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2uyaor","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They published a small coding model recently, based on the Dream architecture and Qwen2.5, called DiffuCoder. Apple is not in the LLM business, and IMO it&amp;#39;s not their profession. But they provide excellent tools for LLM developers (CoreML, MLX, etc.). &lt;/p&gt;\\n\\n&lt;p&gt;ATM, they are working on reducing the size of training data and models. They often publish papers on the topic if you want to check. But they are mostly quiet about it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2uyaor/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752389857,"author_flair_text":null,"treatment_tags":[],"created_utc":1752389857,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2tlice","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2t6ak5","score":1,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sorry never been interested in the dev side on apple platforms, I see xcode as a vscode for apple tailored for there framework. So they've implemented some sort of copilot/cline/roo code right? Showcasing claude or lmstudio, but no special apple made model, right?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2tlice","is_submitter":true,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry never been interested in the dev side on apple platforms, I see xcode as a vscode for apple tailored for there framework. So they&amp;#39;ve implemented some sort of copilot/cline/roo code right? Showcasing claude or lmstudio, but no special apple made model, right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2tlice/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752368298,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752368298,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2t6ak5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ribua","score":3,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Check the WWDC 2025 videos if you want to learn more, but Apple basically added support for agent coding in Xcode. They showcased Claude and LMStudio (with Qwen and Devstral) as providers. Which (IMO) means LLM creators will compete for this lucrative environment.","edited":false,"author_flair_css_class":null,"name":"t1_n2t6ak5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Check the WWDC 2025 videos if you want to learn more, but Apple basically added support for agent coding in Xcode. They showcased Claude and LMStudio (with Qwen and Devstral) as providers. Which (IMO) means LLM creators will compete for this lucrative environment.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2t6ak5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752362716,"author_flair_text":null,"collapsed":false,"created_utc":1752362716,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ribua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ql33y","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sorry I'm not aware about that apple speciality, seems interesting, care to elaborate?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ribua","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry I&amp;#39;m not aware about that apple speciality, seems interesting, care to elaborate?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2ribua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752342974,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752342974,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ql33y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2qbzaq","score":8,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IMO Apple's decision to add local agents to Xcode will have a significant impact on how models are trained on Apple's programming languages and frameworks. Apple definitely has an interest in pushing the usage of local models. They can capitalize on their memory offer and push users toward higher-end configurations, while stressing their privacy moto.\\n\\nThe next 12 months will be very interesting!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ql33y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IMO Apple&amp;#39;s decision to add local agents to Xcode will have a significant impact on how models are trained on Apple&amp;#39;s programming languages and frameworks. Apple definitely has an interest in pushing the usage of local models. They can capitalize on their memory offer and push users toward higher-end configurations, while stressing their privacy moto.&lt;/p&gt;\\n\\n&lt;p&gt;The next 12 months will be very interesting!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2ql33y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752332739,"author_flair_text":null,"treatment_tags":[],"created_utc":1752332739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n2qbzaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Environmental-Metal9","can_mod_post":false,"created_utc":1752329783,"send_replies":true,"parent_id":"t1_n2pyri8","score":5,"author_fullname":"t2_6x9o42az","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wouldnâ€™t it be nice to finetune devstral for swift and run it through Xcode? Swiftstral could be a great FIM replacement for the well intentioned but really not that useful option that ships by default","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qbzaq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wouldnâ€™t it be nice to finetune devstral for swift and run it through Xcode? Swiftstral could be a great FIM replacement for the well intentioned but really not that useful option that ships by default&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2qbzaq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752329783,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rlt5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robiinn","can_mod_post":false,"created_utc":1752344055,"send_replies":true,"parent_id":"t1_n2pyri8","score":2,"author_fullname":"t2_709lt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh nice, I have to check it out with Zed!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rlt5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh nice, I have to check it out with Zed!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2rlt5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752344055,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vkg8u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vism2","score":1,"author_fullname":"t2_1f3xb4r4ae","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not very surprising for a beta then.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2vkg8u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not very surprising for a beta then.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vkg8u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752402741,"author_flair_text":null,"treatment_tags":[],"created_utc":1752402741,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vism2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"And-Bee","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ve4qd","score":1,"author_fullname":"t2_a81fjhk","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes I was using the beta 26 version.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2vism2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes I was using the beta 26 version.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vism2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752401792,"author_flair_text":null,"treatment_tags":[],"created_utc":1752401792,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ve4qd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2v3s6a","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In Xcode 16? To my knowledge there's no built-in solution to do that. Do you have a link? It's only available in Xcode 26, which is currently in beta.","edited":false,"author_flair_css_class":null,"name":"t1_n2ve4qd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In Xcode 16? To my knowledge there&amp;#39;s no built-in solution to do that. Do you have a link? It&amp;#39;s only available in Xcode 26, which is currently in beta.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2ve4qd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752399058,"author_flair_text":null,"collapsed":false,"created_utc":1752399058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2v3s6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"And-Bee","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2t50jd","score":1,"author_fullname":"t2_a81fjhk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think you misunderstood, Xcode intelligence is different to Apple intelligence, in Xcode you can use chat gpt or another LLM provider to behave like Cline but it doesnâ€™t work well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v3s6a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you misunderstood, Xcode intelligence is different to Apple intelligence, in Xcode you can use chat gpt or another LLM provider to behave like Cline but it doesnâ€™t work well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2v3s6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752392967,"author_flair_text":null,"treatment_tags":[],"created_utc":1752392967,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vyw96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2t50jd","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think they will once the tech is really mature, we're still in the middle ages. Imho one more gpu generation and soon the renaissance.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vyw96","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think they will once the tech is really mature, we&amp;#39;re still in the middle ages. Imho one more gpu generation and soon the renaissance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vyw96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752409762,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752409762,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2t50jd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2spstr","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah Apple Intelligence in Xcode 16 is lame. But to be fair it's not even a 7B model behind it so it's not very surprising. And honestly I don't think Apple should bother much about creating their own models, as long as they provide ways to plug the model you like - which is exactly what they did with Xcode 26.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2t50jd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah Apple Intelligence in Xcode 16 is lame. But to be fair it&amp;#39;s not even a 7B model behind it so it&amp;#39;s not very surprising. And honestly I don&amp;#39;t think Apple should bother much about creating their own models, as long as they provide ways to plug the model you like - which is exactly what they did with Xcode 26.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2t50jd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752362269,"author_flair_text":null,"treatment_tags":[],"created_utc":1752362269,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2spstr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"And-Bee","can_mod_post":false,"created_utc":1752356983,"send_replies":true,"parent_id":"t1_n2pyri8","score":1,"author_fullname":"t2_a81fjhk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They need to fix Xcode intelligence as it takes forever to do something Cline could do in minutes, and Xcode intelligence couldnâ€™t even finish the task before I got frustrated and closed it down. Also I canâ€™t get any Google models to show as available either.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2spstr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They need to fix Xcode intelligence as it takes forever to do something Cline could do in minutes, and Xcode intelligence couldnâ€™t even finish the task before I got frustrated and closed it down. Also I canâ€™t get any Google models to show as available either.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2spstr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752356983,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vrtcd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nindaleth","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vej46","score":2,"author_fullname":"t2_7oygu","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the tip, that's exactly the version I tried (0.3.18-3).\\n\\nSo I've tried a bit more and here's what I saw on repeated attempts:\\n\\n* Mistral's own Q5\\\\_K\\\\_M + llama.cpp -&gt; failed using param correctly\\n* Mistral's own Q5\\\\_K\\\\_M + LM Studio -&gt; failed making the tool call\\n* Unsloth's Q5\\\\_K\\\\_XL + llama.cpp -&gt; failed using the param correctly\\n* Unsloth's Q5\\\\_K\\\\_XL + LM Studio -&gt; failed making the tool call\\n* Unsloth's Q4\\\\_K\\\\_XL + llama.cpp -&gt; failed using the param correctly\\n* Unsloth's Q4\\\\_K\\\\_XL + LM Studio -&gt; failed making the tool call\\n* Unsloth's Q4\\\\_K\\\\_M + llama.cpp -&gt; failed using the param correctly\\n* Unsloth's Q4\\\\_K\\\\_M + LM Studio -&gt; failed making the tool call\\n* Mistral's own Q4\\\\_K\\\\_M + llama.cpp -&gt; failed using the param correctly\\n* Mistral's own Q4\\\\_K\\\\_M + LM Studio -&gt; PASS ðŸŽ‰\\n\\nSuddenly there were absolutely no issues when running that combo. Thank you for giving me a positive data point, I'd have given up otherwise!\\n\\nu/danielhanchen sorry for bothering you - is this something you can reproduce? I've given an example of Zed's valid but problematic tool definition [here](https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/comment/n2g44go/).","edited":1752411766,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2vrtcd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the tip, that&amp;#39;s exactly the version I tried (0.3.18-3).&lt;/p&gt;\\n\\n&lt;p&gt;So I&amp;#39;ve tried a bit more and here&amp;#39;s what I saw on repeated attempts:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Mistral&amp;#39;s own Q5_K_M + llama.cpp -&amp;gt; failed using param correctly&lt;/li&gt;\\n&lt;li&gt;Mistral&amp;#39;s own Q5_K_M + LM Studio -&amp;gt; failed making the tool call&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q5_K_XL + llama.cpp -&amp;gt; failed using the param correctly&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q5_K_XL + LM Studio -&amp;gt; failed making the tool call&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q4_K_XL + llama.cpp -&amp;gt; failed using the param correctly&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q4_K_XL + LM Studio -&amp;gt; failed making the tool call&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q4_K_M + llama.cpp -&amp;gt; failed using the param correctly&lt;/li&gt;\\n&lt;li&gt;Unsloth&amp;#39;s Q4_K_M + LM Studio -&amp;gt; failed making the tool call&lt;/li&gt;\\n&lt;li&gt;Mistral&amp;#39;s own Q4_K_M + llama.cpp -&amp;gt; failed using the param correctly&lt;/li&gt;\\n&lt;li&gt;Mistral&amp;#39;s own Q4_K_M + LM Studio -&amp;gt; PASS ðŸŽ‰&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Suddenly there were absolutely no issues when running that combo. Thank you for giving me a positive data point, I&amp;#39;d have given up otherwise!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"/u/danielhanchen\\"&gt;u/danielhanchen&lt;/a&gt; sorry for bothering you - is this something you can reproduce? I&amp;#39;ve given an example of Zed&amp;#39;s valid but problematic tool definition &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/comment/n2g44go/\\"&gt;here&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vrtcd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752406581,"author_flair_text":null,"treatment_tags":[],"created_utc":1752406581,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vej46","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2v93jv","score":2,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LMStudio has been updated recently. I couldn't make it work before that. Make sure your version of the app is up to date. It should be 0.3.18","edited":false,"author_flair_css_class":null,"name":"t1_n2vej46","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LMStudio has been updated recently. I couldn&amp;#39;t make it work before that. Make sure your version of the app is up to date. It should be 0.3.18&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vej46/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752399299,"author_flair_text":null,"collapsed":false,"created_utc":1752399299,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2v93jv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nindaleth","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2uxg0l","score":1,"author_fullname":"t2_7oygu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OK, that's encouraging. I've played with it for a bit and wasn't able to make it work, not even once (with the \`now\` and \`edit_file\` tools). With both Mistral's [Q5\\\\_K\\\\_M](https://huggingface.co/mistralai/Devstral-Small-2507_gguf/blob/main/Devstral-Small-2507-Q5_K_M.gguf) and Unsloth's [UD\\\\_Q5\\\\_K\\\\_XL](https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/blob/main/Devstral-Small-2507-UD-Q5_K_XL.gguf) GGUFs I get the same failure.\\n\\nLlama.cpp doesn't interpret the JSON properly, it fails giving correct parameters to tasks like \\"create a new file in \`Downloads/trythis/file.txt\`\\" or \\"use the \`now\` tool to get the current time\\".\\n\\nMeanwhile LM Studio finds out correctly that the first tool should use \`\\"mode\\": \\"create\\"\` and the second one could use \`\\"timezone\\": \\"UTC\\"\`, but the tool call is only said in chat instead of executed: \`[TOOL_CALLS]edit_file[ARGS]{\\"display_description\\": \\"Create a new file at Downloads/trythis/file.txt\\", \\"path\\": \\"Downloads/trythis/file.txt\\", \\"mode\\": \\"create\\"}\`\\n\\nI wonder what I'm doing wrong.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v93jv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OK, that&amp;#39;s encouraging. I&amp;#39;ve played with it for a bit and wasn&amp;#39;t able to make it work, not even once (with the &lt;code&gt;now&lt;/code&gt; and &lt;code&gt;edit_file&lt;/code&gt; tools). With both Mistral&amp;#39;s &lt;a href=\\"https://huggingface.co/mistralai/Devstral-Small-2507_gguf/blob/main/Devstral-Small-2507-Q5_K_M.gguf\\"&gt;Q5_K_M&lt;/a&gt; and Unsloth&amp;#39;s &lt;a href=\\"https://huggingface.co/unsloth/Devstral-Small-2507-GGUF/blob/main/Devstral-Small-2507-UD-Q5_K_XL.gguf\\"&gt;UD_Q5_K_XL&lt;/a&gt; GGUFs I get the same failure.&lt;/p&gt;\\n\\n&lt;p&gt;Llama.cpp doesn&amp;#39;t interpret the JSON properly, it fails giving correct parameters to tasks like &amp;quot;create a new file in &lt;code&gt;Downloads/trythis/file.txt&lt;/code&gt;&amp;quot; or &amp;quot;use the &lt;code&gt;now&lt;/code&gt; tool to get the current time&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;Meanwhile LM Studio finds out correctly that the first tool should use &lt;code&gt;&amp;quot;mode&amp;quot;: &amp;quot;create&amp;quot;&lt;/code&gt; and the second one could use &lt;code&gt;&amp;quot;timezone&amp;quot;: &amp;quot;UTC&amp;quot;&lt;/code&gt;, but the tool call is only said in chat instead of executed: &lt;code&gt;[TOOL_CALLS]edit_file[ARGS]{&amp;quot;display_description&amp;quot;: &amp;quot;Create a new file at Downloads/trythis/file.txt&amp;quot;, &amp;quot;path&amp;quot;: &amp;quot;Downloads/trythis/file.txt&amp;quot;, &amp;quot;mode&amp;quot;: &amp;quot;create&amp;quot;}&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I wonder what I&amp;#39;m doing wrong.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2v93jv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752396080,"author_flair_text":null,"treatment_tags":[],"created_utc":1752396080,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uxg0l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2uuyt7","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I use tools, and I never encountered a problem since the last update of LMStudio (I use the MLX version)\\n\\nIf I need to get the current date, I just tell Devstral to use the terminal to get it, but generally it finds it without help. As a very recent example, I made a simple static blog engine with a markdown parser, with an indexes.txt that looks like this:\\n\\n\`\`\`\\n{\\n    \\"tags\\": [\\"javascript\\", \\"swift\\", \\"tests\\", \\"devstral\\"],\\n    \\"articles\\": [\\n        [\\"2025-07-11\\", \\"devstral\\"],\\n        [\\"2025-06-16\\", \\"tests\\"],\\n        [\\"2024-04-06\\", \\"javascript\\"],\\n        [\\"2023-05-20\\", \\"tests\\"],\\n        [\\"2023-05-18\\", \\"tests\\"],\\n        [\\"2023-05-16\\", \\"tests, javascript\\"],\\n        [\\"2023-05-05\\", \\"javascript\\"],\\n        [\\"2023-05-04\\", \\"swift\\"]\\n    ]\\n}\\n\`\`\`\\n\\nI asked Devstral to read the codebase to understand how it works, and then create an article about how it. It did it without issue using this structure (it even created the *devstral* tag) and without me telling it to get the current date.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2uxg0l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use tools, and I never encountered a problem since the last update of LMStudio (I use the MLX version)&lt;/p&gt;\\n\\n&lt;p&gt;If I need to get the current date, I just tell Devstral to use the terminal to get it, but generally it finds it without help. As a very recent example, I made a simple static blog engine with a markdown parser, with an indexes.txt that looks like this:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;\\n{\\n    &amp;quot;tags&amp;quot;: [&amp;quot;javascript&amp;quot;, &amp;quot;swift&amp;quot;, &amp;quot;tests&amp;quot;, &amp;quot;devstral&amp;quot;],\\n    &amp;quot;articles&amp;quot;: [\\n        [&amp;quot;2025-07-11&amp;quot;, &amp;quot;devstral&amp;quot;],\\n        [&amp;quot;2025-06-16&amp;quot;, &amp;quot;tests&amp;quot;],\\n        [&amp;quot;2024-04-06&amp;quot;, &amp;quot;javascript&amp;quot;],\\n        [&amp;quot;2023-05-20&amp;quot;, &amp;quot;tests&amp;quot;],\\n        [&amp;quot;2023-05-18&amp;quot;, &amp;quot;tests&amp;quot;],\\n        [&amp;quot;2023-05-16&amp;quot;, &amp;quot;tests, javascript&amp;quot;],\\n        [&amp;quot;2023-05-05&amp;quot;, &amp;quot;javascript&amp;quot;],\\n        [&amp;quot;2023-05-04&amp;quot;, &amp;quot;swift&amp;quot;]\\n    ]\\n}\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I asked Devstral to read the codebase to understand how it works, and then create an article about how it. It did it without issue using this structure (it even created the &lt;em&gt;devstral&lt;/em&gt; tag) and without me telling it to get the current date.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2uxg0l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752389384,"author_flair_text":null,"treatment_tags":[],"created_utc":1752389384,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uuyt7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nindaleth","can_mod_post":false,"created_utc":1752387950,"send_replies":true,"parent_id":"t1_n2pyri8","score":1,"author_fullname":"t2_7oygu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you just chat with it in Zed (or use \\"ask\\" profile) or do you also use tools? I've had [no success](https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/comment/n2g44go/) using some of the tools in Zed with Devstral but it sounds it works for you well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uuyt7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you just chat with it in Zed (or use &amp;quot;ask&amp;quot; profile) or do you also use tools? I&amp;#39;ve had &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lwe5y8/comment/n2g44go/\\"&gt;no success&lt;/a&gt; using some of the tools in Zed with Devstral but it sounds it works for you well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2uuyt7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387950,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pyri8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Creative-Size2658","can_mod_post":false,"created_utc":1752325012,"send_replies":true,"parent_id":"t3_1lxyg6z","score":11,"author_fullname":"t2_1f3xb4r4ae","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried 2505 in an OpenHands environment first, and now I'm using 2507 in Zed for web development and it's been awesome so far. And now I can't wait to try it with Xcode 26. Since it was used during WWDC to showcase Xcode local agent, I have hope it will perform well on Swift and SwiftUI projects.\\n\\nGranted it's not as good as Claude, but it can still make me save a lot of time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pyri8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried 2505 in an OpenHands environment first, and now I&amp;#39;m using 2507 in Zed for web development and it&amp;#39;s been awesome so far. And now I can&amp;#39;t wait to try it with Xcode 26. Since it was used during WWDC to showcase Xcode local agent, I have hope it will perform well on Swift and SwiftUI projects.&lt;/p&gt;\\n\\n&lt;p&gt;Granted it&amp;#39;s not as good as Claude, but it can still make me save a lot of time.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2pyri8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752325012,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2tnani","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2t70l5","score":2,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Idk just spin a llama cpp instance,  set the api url in roo code. Normal stuff. \\nI use q8xl from unsloth.  \\nUnsloth's hugging face model card suggests to use the --jinja flag with llama.cpp ðŸ¤·.  \\nMay be something to do with your inference engine default parameters, what backend are you using?  \\nCurious to know how that happens, don't hesitate to get back to us.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2tnani","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Idk just spin a llama cpp instance,  set the api url in roo code. Normal stuff. \\nI use q8xl from unsloth.&lt;br/&gt;\\nUnsloth&amp;#39;s hugging face model card suggests to use the --jinja flag with llama.cpp ðŸ¤·.&lt;br/&gt;\\nMay be something to do with your inference engine default parameters, what backend are you using?&lt;br/&gt;\\nCurious to know how that happens, don&amp;#39;t hesitate to get back to us.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2tnani/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752368973,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752368973,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2t70l5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zdy1995","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pu4qi","score":1,"author_fullname":"t2_ok06y1b2i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hi Op may i know how do you use it with Roo? i tried yesterday and it failed with single request: translate codebase codes comments to englishâ€¦ died at the first stepâ€¦â€¦","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2t70l5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi Op may i know how do you use it with Roo? i tried yesterday and it failed with single request: translate codebase codes comments to englishâ€¦ died at the first stepâ€¦â€¦&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2t70l5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752362967,"author_flair_text":null,"treatment_tags":[],"created_utc":1752362967,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pu4qi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752323165,"send_replies":true,"parent_id":"t1_n2pr6ab","score":6,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I use it with roo code and keep the leash tight. I prefer doing quick simple interations than giving it too much freedom","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pu4qi","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use it with roo code and keep the leash tight. I prefer doing quick simple interations than giving it too much freedom&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2pu4qi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752323165,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pr6ab","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Silver_Treat2345","can_mod_post":false,"created_utc":1752321904,"send_replies":true,"parent_id":"t3_1lxyg6z","score":10,"author_fullname":"t2_1bbsqu65nu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have let it run on a dual RTX 3060 yesterday in q4 with vllm. Running it with OpenHands produces lightweight ugly javascript apps. I wasn't able so far to run it in q8 or even full weights (will try next days on an 8xRTX A5000 Setup). For its size and within experimental Environments (schools, labs) it makes a lot of sense, but it surely doesn't create the next ERP (which luckily still requires huge portions of developer experience and software architecturing knowhow, even if done with claude, gemini and chatgpt).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2pr6ab","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have let it run on a dual RTX 3060 yesterday in q4 with vllm. Running it with OpenHands produces lightweight ugly javascript apps. I wasn&amp;#39;t able so far to run it in q8 or even full weights (will try next days on an 8xRTX A5000 Setup). For its size and within experimental Environments (schools, labs) it makes a lot of sense, but it surely doesn&amp;#39;t create the next ERP (which luckily still requires huge portions of developer experience and software architecturing knowhow, even if done with claude, gemini and chatgpt).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2pr6ab/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752321904,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rk490","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752343524,"send_replies":true,"parent_id":"t1_n2r4cj7","score":2,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah clearly it's not perfect but, for such a small model still very impressive.\\n\\nI don't remember having failed tool calling, maybe something about cline, maybe I'm lucky, I'm using roo code in vscode.\\n\\nClearly when they'll build the dataset to train it for vision applied to UI creation.. that will be beautiful","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rk490","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah clearly it&amp;#39;s not perfect but, for such a small model still very impressive.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t remember having failed tool calling, maybe something about cline, maybe I&amp;#39;m lucky, I&amp;#39;m using roo code in vscode.&lt;/p&gt;\\n\\n&lt;p&gt;Clearly when they&amp;#39;ll build the dataset to train it for vision applied to UI creation.. that will be beautiful&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2rk490/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752343524,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2r4cj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1752338755,"send_replies":true,"parent_id":"t3_1lxyg6z","score":3,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It doesn't compete with the big boys, but it is solid for a local model. \\n\\nI've still had hit or miss issues using it even on on relatively simple tasks, like add a single UI control and connect to to the endpoint in an API on a small and relatively simple python flask api + react app. Sometimes it works, sometimes not.  The type of tasks Sonnet 4 will get right every time.  Sometimes it just screws up the tool call, looks like it misses a &lt; character and cannot recover without resetting context and trying again, and it sometimes struggles to rearrange UI elements properly. \\n\\nI'm using unsloth Q8_K_XL and LM studio to host and Cline extension in VS code. \\n\\nI tried the vision and non-vision models (unsloth added the vision projector back on one of their uploads), trying the vision enabled one to see if it can look at a screenshot of the app layout to correct, doesn't seem to help with it fixing up layout issues.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2r4cj7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t compete with the big boys, but it is solid for a local model. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve still had hit or miss issues using it even on on relatively simple tasks, like add a single UI control and connect to to the endpoint in an API on a small and relatively simple python flask api + react app. Sometimes it works, sometimes not.  The type of tasks Sonnet 4 will get right every time.  Sometimes it just screws up the tool call, looks like it misses a &amp;lt; character and cannot recover without resetting context and trying again, and it sometimes struggles to rearrange UI elements properly. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m using unsloth Q8_K_XL and LM studio to host and Cline extension in VS code. &lt;/p&gt;\\n\\n&lt;p&gt;I tried the vision and non-vision models (unsloth added the vision projector back on one of their uploads), trying the vision enabled one to see if it can look at a screenshot of the app layout to correct, doesn&amp;#39;t seem to help with it fixing up layout issues.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2r4cj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752338755,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2q7741","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1752328143,"send_replies":true,"parent_id":"t3_1lxyg6z","score":2,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"make sure to also try mistral small 2506 and magistral","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2q7741","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;make sure to also try mistral small 2506 and magistral&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2q7741/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752328143,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wqa6v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2wo7sd","score":1,"author_fullname":"t2_bvqb8ng0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Apple Silicon. This is implied because we are talking about MLX which only runs on Apple Silicon. To be precise, it is a M4 Max MacBook Pro.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2wqa6v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apple Silicon. This is implied because we are talking about MLX which only runs on Apple Silicon. To be precise, it is a M4 Max MacBook Pro.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2wqa6v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752419244,"author_flair_text":null,"treatment_tags":[],"created_utc":1752419244,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2wo7sd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"markole","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vfchg","score":1,"author_fullname":"t2_jeggn","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which GPUs actually?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2wo7sd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which GPUs actually?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2wo7sd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752418620,"author_flair_text":null,"treatment_tags":[],"created_utc":1752418620,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vfchg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2uz8pn","score":1,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"128 GB","edited":false,"author_flair_css_class":null,"name":"t1_n2vfchg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;128 GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vfchg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752399784,"author_flair_text":null,"collapsed":false,"created_utc":1752399784,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uz8pn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"markole","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2rtpc8","score":1,"author_fullname":"t2_jeggn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How much vram do you have?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uz8pn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much vram do you have?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2uz8pn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752390381,"author_flair_text":null,"treatment_tags":[],"created_utc":1752390381,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2rtpc8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2rqk04","score":2,"author_fullname":"t2_bvqb8ng0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is not out of context. This can happen even when we are in the beginning of processing the task. Context is set to 128k and very rarely do I even come near that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2rtpc8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is not out of context. This can happen even when we are in the beginning of processing the task. Context is set to 128k and very rarely do I even come near that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2rtpc8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752346555,"author_flair_text":null,"treatment_tags":[],"created_utc":1752346555,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2rqk04","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hainesk","can_mod_post":false,"created_utc":1752345566,"send_replies":true,"parent_id":"t1_n2rp0lq","score":1,"author_fullname":"t2_5rprd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could be out of context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rqk04","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could be out of context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2rqk04/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752345566,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2s6eug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752350681,"send_replies":true,"parent_id":"t1_n2rp0lq","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Strange I'm not having this kind of troubles, can you try regular gguf ðŸ¤·","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2s6eug","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Strange I&amp;#39;m not having this kind of troubles, can you try regular gguf ðŸ¤·&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2s6eug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752350681,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2rp0lq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Baldur-Norddahl","can_mod_post":false,"created_utc":1752345073,"send_replies":true,"parent_id":"t3_1lxyg6z","score":2,"author_fullname":"t2_bvqb8ng0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It will randomly fail with this kind of errors:\\n\\n&gt;Let me try to read the file content again:\\\\[TOOL\\\\_CALLS\\\\]read\\\\_file&gt;  \\n  \\njavascript/CircuitLog.jsx  \\n&lt;/read\\\\_file&gt;\\n\\n&gt;Roo is having trouble...\\n\\n&gt;This may indicate a failure in the model's thought process or inability to use a tool properly, which can be mitigated with some user guidance (e.g. \\"Try breaking down the task into smaller steps\\").\\n\\n&gt;\\n\\nIt keeps looping until I start all over. This happens with q4, q8, dwq etc. All MLX quants. I am unsure if it is the MLX quants that are bad, so will try a GGUF next.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rp0lq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will randomly fail with this kind of errors:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Let me try to read the file content again:[TOOL_CALLS]read_file&amp;gt;  &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;javascript/CircuitLog.jsx&lt;br/&gt;\\n&amp;lt;/read\\\\_file&amp;gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Roo is having trouble...&lt;/p&gt;\\n\\n&lt;p&gt;This may indicate a failure in the model&amp;#39;s thought process or inability to use a tool properly, which can be mitigated with some user guidance (e.g. &amp;quot;Try breaking down the task into smaller steps&amp;quot;).&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It keeps looping until I start all over. This happens with q4, q8, dwq etc. All MLX quants. I am unsure if it is the MLX quants that are bad, so will try a GGUF next.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2rp0lq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752345073,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2v666z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robiinn","can_mod_post":false,"created_utc":1752394338,"send_replies":true,"parent_id":"t1_n2txxtc","score":1,"author_fullname":"t2_709lt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just a fyi, q4 kv cache can give quite bad output. I would rather use a bit smaller context and instead use q8 kv cache or not change it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v666z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just a fyi, q4 kv cache can give quite bad output. I would rather use a bit smaller context and instead use q8 kv cache or not change it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2v666z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752394338,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2txxtc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1752372985,"send_replies":true,"parent_id":"t3_1lxyg6z","score":2,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tried it on roocode with q4 and q4 kv cache get the full 132k context. On a 3090. I use it in lmstudio. I wanted it to make a additional py file to make an lmstudio compatible. After a bit of to a frow it succeeded. Tested context7 calls had to help it a bit with my own web search but it got there. \\n\\nVery good at tool calling and apply_diff.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2txxtc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried it on roocode with q4 and q4 kv cache get the full 132k context. On a 3090. I use it in lmstudio. I wanted it to make a additional py file to make an lmstudio compatible. After a bit of to a frow it succeeded. Tested context7 calls had to help it a bit with my own web search but it got there. &lt;/p&gt;\\n\\n&lt;p&gt;Very good at tool calling and apply_diff.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2txxtc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752372985,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vsg7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vobnx","score":1,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"8 hours at 8cent is 64 cents which would never happen if you're vibe coding","edited":false,"author_flair_css_class":null,"name":"t1_n2vsg7n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;8 hours at 8cent is 64 cents which would never happen if you&amp;#39;re vibe coding&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxyg6z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vsg7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752406883,"author_flair_text":null,"collapsed":false,"created_utc":1752406883,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vobnx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2tybem","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah let say you use 2 for 8 hours at full blast you still at 1$30 lol. Thank god inference machine consume may be 10% of that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vobnx","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah let say you use 2 for 8 hours at full blast you still at 1$30 lol. Thank god inference machine consume may be 10% of that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2vobnx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404814,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752404814,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2tybem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2tltk0","score":1,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think a 3090 is 8 cents an hour at full 300w usage.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2tybem","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think a 3090 is 8 cents an hour at full 300w usage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2tybem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752373134,"author_flair_text":null,"treatment_tags":[],"created_utc":1752373134,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2tltk0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752368415,"send_replies":true,"parent_id":"t1_n2sg466","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can give grok 30 bucks of credit per day, devstral I feed it cents of electricity at most ðŸ˜…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2tltk0","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can give grok 30 bucks of credit per day, devstral I feed it cents of electricity at most ðŸ˜…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxyg6z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2tltk0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752368415,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2sg466","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"created_utc":1752353774,"send_replies":true,"parent_id":"t3_1lxyg6z","score":1,"author_fullname":"t2_g8xg6sut","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's good, but not better than grok4.  But internet was down and I was glad I had it installed to help out with coding for a little while","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2sg466","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s good, but not better than grok4.  But internet was down and I was glad I had it installed to help out with coding for a little while&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxyg6z/have_you_tried_that_new_devstral_myyy_the_next/n2sg466/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752353774,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxyg6z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
