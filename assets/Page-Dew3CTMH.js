import{j as e}from"./index-BOnf-UhU.js";import{R as l}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I have been using RAG with open ai over a product description document which is rather technical. I chunked up sections of my document and then do hybrid search with weaviate. It does good but sometimes certain queries require retrieval from more than 1 sections and then it's 50/50. Will fine-tuning solve this? What model should I look into?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Rag vs fine-tuning.","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6qb6p","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vdwm0f4m","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753218703,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been using RAG with open ai over a product description document which is rather technical. I chunked up sections of my document and then do hybrid search with weaviate. It does good but sometimes certain queries require retrieval from more than 1 sections and then it&amp;#39;s 50/50. Will fine-tuning solve this? What model should I look into?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m6qb6p","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Parking_Bluebird826","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/","subreddit_subscribers":503253,"created_utc":1753218703,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4p7w9e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Parking_Bluebird826","can_mod_post":false,"created_utc":1753273230,"send_replies":true,"parent_id":"t1_n4lrn4z","score":1,"author_fullname":"t2_vdwm0f4m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let's say I have said number of examples , should I do instruction fine tuning or?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4p7w9e","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let&amp;#39;s say I have said number of examples , should I do instruction fine tuning or?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6qb6p","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/n4p7w9e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753273230,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lrn4z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"herovals","can_mod_post":false,"created_utc":1753221006,"send_replies":true,"parent_id":"t3_1m6qb6p","score":3,"author_fullname":"t2_qjh5qyek","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fine tuning is not relevant to this, and for future reference isn't relevant unless you have hundreds of thousands of examples of the data you need to train / improve on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lrn4z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fine tuning is not relevant to this, and for future reference isn&amp;#39;t relevant unless you have hundreds of thousands of examples of the data you need to train / improve on.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/n4lrn4z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753221006,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6qb6p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4llfwk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Market-692","can_mod_post":false,"created_utc":1753219173,"send_replies":true,"parent_id":"t3_1m6qb6p","score":1,"author_fullname":"t2_ajuhoi00","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"just use IBM Granite models with RAGFlow, this will probably run on any typical PC, Granite are small models and very effective for RAG","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4llfwk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just use IBM Granite models with RAGFlow, this will probably run on any typical PC, Granite are small models and very effective for RAG&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/n4llfwk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219173,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6qb6p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4n0553","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HistorianPotential48","can_mod_post":false,"created_utc":1753235734,"send_replies":true,"parent_id":"t3_1m6qb6p","score":1,"author_fullname":"t2_4dzthia7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Where did it went wrong? Did wanted sections show up in Top-Ks but not high enough (Rerank)? Or never showed up (Retrieval issue)? Is vector length configured correctly when comparing embedding model spec and database schema (Storing issue)? Is query format correct, does it need query expansion (Augment issue)?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4n0553","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where did it went wrong? Did wanted sections show up in Top-Ks but not high enough (Rerank)? Or never showed up (Retrieval issue)? Is vector length configured correctly when comparing embedding model spec and database schema (Storing issue)? Is query format correct, does it need query expansion (Augment issue)?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/n4n0553/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753235734,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6qb6p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4o7xp6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SvenVargHimmel","can_mod_post":false,"created_utc":1753255091,"send_replies":true,"parent_id":"t3_1m6qb6p","score":1,"author_fullname":"t2_orer5qiaz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Before you fine tune, optimise your prompts. Don't do it by hand, you will never get there if there is a prompt that will improve your results.  I haven't used Vertex to optimise prompts which I believe is google's cloud offering but dspy is very very good for this kind of thing. \\n\\n  \\nEDIT:  So i found this example.  [https://dspy.ai/tutorials/rag/](https://dspy.ai/tutorials/rag/)  , even if you don't use dspy it gives a good overview of why your RAG may not be performing well.","edited":1753255277,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4o7xp6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Before you fine tune, optimise your prompts. Don&amp;#39;t do it by hand, you will never get there if there is a prompt that will improve your results.  I haven&amp;#39;t used Vertex to optimise prompts which I believe is google&amp;#39;s cloud offering but dspy is very very good for this kind of thing. &lt;/p&gt;\\n\\n&lt;p&gt;EDIT:  So i found this example.  &lt;a href=\\"https://dspy.ai/tutorials/rag/\\"&gt;https://dspy.ai/tutorials/rag/&lt;/a&gt;  , even if you don&amp;#39;t use dspy it gives a good overview of why your RAG may not be performing well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6qb6p/rag_vs_finetuning/n4o7xp6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753255091,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6qb6p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
