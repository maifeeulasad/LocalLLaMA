import{j as e}from"./index-Bu7qcPAU.js";import{R as l}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi everyone, as the title says: is it possible to have real-time voice-to-voice interaction running locally, or are we still not there yet?  \\nI'd like to improve my speaking skills (including pronunciation) in English and Japanese, and I thought it would be great to have conversations with a local LLM.  \\nIt would also be nice to have something similar in Italian (my native language) for daily chats, but I assume it's not a very \\"popular\\" language to train on. lol\\n\\n  \\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Is real-time voice-to-voice still science fiction?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzts1z","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.76,"author_flair_background_color":null,"subreddit_type":"public","ups":24,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dlu9c","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":24,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752516472,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi everyone, as the title says: is it possible to have real-time voice-to-voice interaction running locally, or are we still not there yet?&lt;br/&gt;\\nI&amp;#39;d like to improve my speaking skills (including pronunciation) in English and Japanese, and I thought it would be great to have conversations with a local LLM.&lt;br/&gt;\\nIt would also be nice to have something similar in Italian (my native language) for daily chats, but I assume it&amp;#39;s not a very &amp;quot;popular&amp;quot; language to train on. lol&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lzts1z","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"junior600","discussion_type":null,"num_comments":39,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/","subreddit_subscribers":499295,"created_utc":1752516472,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35xd1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752534103,"send_replies":true,"parent_id":"t1_n34bo6o","score":2,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"+ one on the speculative decoding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35xd1m","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ul&gt;\\n&lt;li&gt;one on the speculative decoding.&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35xd1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752534103,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36kctj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RobXSIQ","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36iao4","score":2,"author_fullname":"t2_7y63dbvl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"voice cloning you're gonna need to go with Coqui. great little clonebot and quite nice. Remember to install deepspeed. Its my favorite overall, but for big blocks of text, thats where Kokoro really works well.   \\nI didn't have much luck getting Seseme working well, although I was trying it through Comfyui. Also don't like limitations of 40 seconds or less of audio (mostly if not a talking AI, then its audiobooks I go with)\\n\\nChatterbox is also a good one though. It does pretty well with the broken up context, but it can get glitchy...so yeah, Coqui TTS is the best for your use case for now","edited":false,"author_flair_css_class":null,"name":"t1_n36kctj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;voice cloning you&amp;#39;re gonna need to go with Coqui. great little clonebot and quite nice. Remember to install deepspeed. Its my favorite overall, but for big blocks of text, thats where Kokoro really works well.&lt;br/&gt;\\nI didn&amp;#39;t have much luck getting Seseme working well, although I was trying it through Comfyui. Also don&amp;#39;t like limitations of 40 seconds or less of audio (mostly if not a talking AI, then its audiobooks I go with)&lt;/p&gt;\\n\\n&lt;p&gt;Chatterbox is also a good one though. It does pretty well with the broken up context, but it can get glitchy...so yeah, Coqui TTS is the best for your use case for now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzts1z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36kctj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752541835,"author_flair_text":null,"collapsed":false,"created_utc":1752541835,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n36iao4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GrungeWerX","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ef9h","score":-1,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I read about kokoro last night. Heard it doesn’t have voice cloning which is what I’m interested in. The more natural the voice, the more realistic it sounds. I have curated voices that sound better than proprietary voice apps, just from random people Ive met, or random voices I hear.\\n\\nThat said, I will give kokoro a try just out of curiosity. I was impressed with chatterbox, but it has glitches","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36iao4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I read about kokoro last night. Heard it doesn’t have voice cloning which is what I’m interested in. The more natural the voice, the more realistic it sounds. I have curated voices that sound better than proprietary voice apps, just from random people Ive met, or random voices I hear.&lt;/p&gt;\\n\\n&lt;p&gt;That said, I will give kokoro a try just out of curiosity. I was impressed with chatterbox, but it has glitches&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36iao4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752541129,"author_flair_text":null,"treatment_tags":[],"created_utc":1752541129,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n36ef9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RobXSIQ","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35ufg1","score":4,"author_fullname":"t2_7y63dbvl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Kokoro is faster...blazingly fast, open source, simple to run, etc.  That + ST...voila","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36ef9h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kokoro is faster...blazingly fast, open source, simple to run, etc.  That + ST...voila&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36ef9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752539784,"author_flair_text":null,"treatment_tags":[],"created_utc":1752539784,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35uo34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GrungeWerX","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35ufg1","score":-1,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"While I agree with your second %, your first is ridiculous. I speak to Ai STS every day and it’s pretty darn near talking to a real person. The only problem is persistent memory and personality consistency, which has led me to try building my own genetic AI system to address these issues. But as far as voice itself, we’re more like 90% there, maybe slightly higher, if you’re using eleven labs in a local pipeline. \\n\\nNow, if you’re only rating open source voice models, then I would agree with you. I only referenced 11labs because you CAN use it in a local pipeline using your own LLMs.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35uo34","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While I agree with your second %, your first is ridiculous. I speak to Ai STS every day and it’s pretty darn near talking to a real person. The only problem is persistent memory and personality consistency, which has led me to try building my own genetic AI system to address these issues. But as far as voice itself, we’re more like 90% there, maybe slightly higher, if you’re using eleven labs in a local pipeline. &lt;/p&gt;\\n\\n&lt;p&gt;Now, if you’re only rating open source voice models, then I would agree with you. I only referenced 11labs because you CAN use it in a local pipeline using your own LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35uo34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533236,"author_flair_text":null,"treatment_tags":[],"created_utc":1752533236,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n35ufg1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GrungeWerX","can_mod_post":false,"created_utc":1752533160,"send_replies":true,"parent_id":"t1_n34bo6o","score":3,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"While I agree with your second %, your first is ridiculous. I speak to Ai STS every day and it’s pretty darn near talking to a real person. The only problem is persistent memory and personality consistency, which has led me to try building my own genetic AI system to address these issues. But as far as voice itself, we’re more like 90% there, maybe slightly higher, if you’re using eleven labs in a local pipeline. \\n\\nNow, if you’re only rating open source voice models, then I would agree with you. I only referenced 11labs because you CAN use it in a local pipeline using your own LLMs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35ufg1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While I agree with your second %, your first is ridiculous. I speak to Ai STS every day and it’s pretty darn near talking to a real person. The only problem is persistent memory and personality consistency, which has led me to try building my own genetic AI system to address these issues. But as far as voice itself, we’re more like 90% there, maybe slightly higher, if you’re using eleven labs in a local pipeline. &lt;/p&gt;\\n\\n&lt;p&gt;Now, if you’re only rating open source voice models, then I would agree with you. I only referenced 11labs because you CAN use it in a local pipeline using your own LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35ufg1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533160,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n34bo6o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1752517182,"send_replies":true,"parent_id":"t3_1lzts1z","score":25,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Science fiction\\" is a bit harsh.\\n\\nIt's also not a binary \\\\[yes/no\\\\] question; it's more of a spectrum.\\n\\nFor instance, does it count if you can do real time voice to voice with 8xH100? That can be \\"local\\". You can download the model...It's just...Really expensive.\\n\\nSimilarly, what about quality? You might get a model running in real time, but it has occasional hallucinations or artifacts. It's possible you may not want to pick those up unintentionally.\\n\\nI'd say we're probably 60-70% of the way to real-time accessible speech to speech models for casual conversation, and probably about 20-40% of the way to models of such quality and meta-cognition (with the ability to reflect on their own outputs for educational purposes, and be aware of their inflections, etc), that you would want to use them for language learning extensively.\\n\\nIt'll take a few more advancements, but we already know the way there, it's just we have to implement it.\\n\\nNotably, as soon as someone trains a speculative decoding head for any of the existing speech models that's probably what we need to really make it mostly viable, but a Diffusion speech to speech model would probably be ideal.\\n\\nI'd say we're maybe about a year out (at most) from real time speech to speech (with possibly some need to customize the pipeline to your needs and available hardware).\\n\\nSo, not quite 100% of the way there, but calling it science fiction isn't quite fair when all the tools are already there and just need to be put together in the right order.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34bo6o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Science fiction&amp;quot; is a bit harsh.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s also not a binary [yes/no] question; it&amp;#39;s more of a spectrum.&lt;/p&gt;\\n\\n&lt;p&gt;For instance, does it count if you can do real time voice to voice with 8xH100? That can be &amp;quot;local&amp;quot;. You can download the model...It&amp;#39;s just...Really expensive.&lt;/p&gt;\\n\\n&lt;p&gt;Similarly, what about quality? You might get a model running in real time, but it has occasional hallucinations or artifacts. It&amp;#39;s possible you may not want to pick those up unintentionally.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d say we&amp;#39;re probably 60-70% of the way to real-time accessible speech to speech models for casual conversation, and probably about 20-40% of the way to models of such quality and meta-cognition (with the ability to reflect on their own outputs for educational purposes, and be aware of their inflections, etc), that you would want to use them for language learning extensively.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;ll take a few more advancements, but we already know the way there, it&amp;#39;s just we have to implement it.&lt;/p&gt;\\n\\n&lt;p&gt;Notably, as soon as someone trains a speculative decoding head for any of the existing speech models that&amp;#39;s probably what we need to really make it mostly viable, but a Diffusion speech to speech model would probably be ideal.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d say we&amp;#39;re maybe about a year out (at most) from real time speech to speech (with possibly some need to customize the pipeline to your needs and available hardware).&lt;/p&gt;\\n\\n&lt;p&gt;So, not quite 100% of the way there, but calling it science fiction isn&amp;#39;t quite fair when all the tools are already there and just need to be put together in the right order.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34bo6o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517182,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n362vcw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harrro","can_mod_post":false,"created_utc":1752535884,"send_replies":true,"parent_id":"t1_n34bui2","score":9,"author_fullname":"t2_4axt7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"+1 for Unmute.\\n\\nTheir announcement thread here got buried because everybody complained about voice cloning not being released but the voice-to-voice is excellent and actually real-time.\\n\\nIt even allows you to use any LLM model (which I don't know how they managed to make real time) so I use a Qwen 14B on my RTX3090 with it.\\n\\nhttps://github.com/kyutai-labs/unmute if you're interested. It does take a bit of time to setup the first time (but if you have Docker, it's pretty much just a \`docker compose up\` to get started).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n362vcw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;+1 for Unmute.&lt;/p&gt;\\n\\n&lt;p&gt;Their announcement thread here got buried because everybody complained about voice cloning not being released but the voice-to-voice is excellent and actually real-time.&lt;/p&gt;\\n\\n&lt;p&gt;It even allows you to use any LLM model (which I don&amp;#39;t know how they managed to make real time) so I use a Qwen 14B on my RTX3090 with it.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/kyutai-labs/unmute\\"&gt;https://github.com/kyutai-labs/unmute&lt;/a&gt; if you&amp;#39;re interested. It does take a bit of time to setup the first time (but if you have Docker, it&amp;#39;s pretty much just a &lt;code&gt;docker compose up&lt;/code&gt; to get started).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n362vcw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752535884,"author_flair_text":"Alpaca","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n362ce3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harrro","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3582p9","score":4,"author_fullname":"t2_4axt7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep it's a French company.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n362ce3","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep it&amp;#39;s a French company.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n362ce3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752535711,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1752535711,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3582p9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AnotherAvery","can_mod_post":false,"created_utc":1752526423,"send_replies":true,"parent_id":"t1_n34bui2","score":4,"author_fullname":"t2_kktcpxzr5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And French I think?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3582p9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And French I think?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n3582p9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526423,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n34bui2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1752517232,"send_replies":true,"parent_id":"t3_1lzts1z","score":9,"author_fullname":"t2_9s7pmakgx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unmute is nice, but it's only English","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34bui2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unmute is nice, but it&amp;#39;s only English&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34bui2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517232,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36b5mj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ArsNeph","can_mod_post":false,"created_utc":1752538657,"send_replies":true,"parent_id":"t3_1lzts1z","score":5,"author_fullname":"t2_vt0xkv60d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As a Japanese speaker, I'd highly recommend against using any AI speech model to practice language learning. It will very seriously mess with your pronunciation. Japanese specifically has two aspects specific to pronunciation, namely the phonetics of the characters, and pitch accent. For example, 口内 (Kounai) means \\"Inside mouth\\", but because characters have an Onyomi and Kunyomi, most AI models are not perfectly trained on which is which, meaning it may read it as \\"Kuchinai\\", which is not a valid reading of this word. It will do the same with names.\\n\\nThe second aspect is pitch accent, in which the pitch follows one of four patterns depending on the word. For example, 昨日 (Kinou) and 機能 (Kinou) are pronounced the same phonetically, but you can only tell the different between them in speech by the pitch pattern. AI is not terrible at picking up the patterns, but it very often uses the wrong one, causing the word to sound unnatural. Using that as a reference will cause you to pick up strange habits.\\n\\nI know it can be embarrassing to practice your skills in front of a real person, but I highly recommend you use VRChat as a way to practice your conversation skills. It can be used on a desktop as long as you have a decent GPU and a mic. There are plenty of very kind and friendly native Japanese speakers looking to have conversations with any people from abroad, and they are there all day, so you can talk as long as you want. I'd recommend EN-JP Language Exchange world, as it is specifically for this purpose. \\n\\nIn the offcase your GPU can't handle it, there are also lots of language exchange apps you can use to try and talk to native speakers, though those aren't nearly as easy to find someone to practice with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36b5mj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a Japanese speaker, I&amp;#39;d highly recommend against using any AI speech model to practice language learning. It will very seriously mess with your pronunciation. Japanese specifically has two aspects specific to pronunciation, namely the phonetics of the characters, and pitch accent. For example, 口内 (Kounai) means &amp;quot;Inside mouth&amp;quot;, but because characters have an Onyomi and Kunyomi, most AI models are not perfectly trained on which is which, meaning it may read it as &amp;quot;Kuchinai&amp;quot;, which is not a valid reading of this word. It will do the same with names.&lt;/p&gt;\\n\\n&lt;p&gt;The second aspect is pitch accent, in which the pitch follows one of four patterns depending on the word. For example, 昨日 (Kinou) and 機能 (Kinou) are pronounced the same phonetically, but you can only tell the different between them in speech by the pitch pattern. AI is not terrible at picking up the patterns, but it very often uses the wrong one, causing the word to sound unnatural. Using that as a reference will cause you to pick up strange habits.&lt;/p&gt;\\n\\n&lt;p&gt;I know it can be embarrassing to practice your skills in front of a real person, but I highly recommend you use VRChat as a way to practice your conversation skills. It can be used on a desktop as long as you have a decent GPU and a mic. There are plenty of very kind and friendly native Japanese speakers looking to have conversations with any people from abroad, and they are there all day, so you can talk as long as you want. I&amp;#39;d recommend EN-JP Language Exchange world, as it is specifically for this purpose. &lt;/p&gt;\\n\\n&lt;p&gt;In the offcase your GPU can&amp;#39;t handle it, there are also lots of language exchange apps you can use to try and talk to native speakers, though those aren&amp;#39;t nearly as easy to find someone to practice with.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36b5mj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752538657,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34nfnv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teleprint-me","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34fj9r","score":1,"author_fullname":"t2_slcrtxpr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"🤣😅 I love this response.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34nfnv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;🤣😅 I love this response.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34nfnv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752520560,"author_flair_text":null,"treatment_tags":[],"created_utc":1752520560,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3808np","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"urekmazino_0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37idwn","score":1,"author_fullname":"t2_oebv0z6s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can show you how to","edited":false,"author_flair_css_class":null,"name":"t1_n3808np","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can show you how to&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzts1z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n3808np/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564276,"author_flair_text":null,"collapsed":false,"created_utc":1752564276,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n37idwn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Spellbonk90","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34fj9r","score":1,"author_fullname":"t2_p1gfswvnw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Which? Where ? How ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37idwn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which? Where ? How ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n37idwn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752554965,"author_flair_text":null,"treatment_tags":[],"created_utc":1752554965,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34fj9r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"urekmazino_0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34dwqz","score":4,"author_fullname":"t2_oebv0z6s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34fj9r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34fj9r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752518285,"author_flair_text":null,"treatment_tags":[],"created_utc":1752518285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n34dwqz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"junior600","can_mod_post":false,"created_utc":1752517816,"send_replies":true,"parent_id":"t1_n34ax4q","score":2,"author_fullname":"t2_dlu9c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you also use anime characters as live avatars?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34dwqz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you also use anime characters as live avatars?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34dwqz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517816,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n34ax4q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"urekmazino_0","can_mod_post":false,"created_utc":1752516972,"send_replies":true,"parent_id":"t3_1lzts1z","score":10,"author_fullname":"t2_oebv0z6s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its very much possible, I have several systems running realtime voice chat with live avatars, if you know what that’s for.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34ax4q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its very much possible, I have several systems running realtime voice chat with live avatars, if you know what that’s for.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34ax4q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752516972,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36e92a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RobXSIQ","can_mod_post":false,"created_utc":1752539724,"send_replies":true,"parent_id":"t3_1lzts1z","score":3,"author_fullname":"t2_7y63dbvl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Check out Voxta or Silly TavernAI.  its perfectly doable. You got whisper for hearing you and kokoro for quick translation back..the chat can be quick\\n\\nWhisper and Kokoro both take up a tiny bit of gpu, leaving the rest for whatever llm you want to run. dig into it...its 99% there for most folks hardware. I am looking through the comments and seeing you're getting some terrible advice based on very outdated info. We already crossed the threshold. \\n\\nSearch  Silly TavernAI. start there. in it, kokoro can auto install...enjoy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36e92a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Check out Voxta or Silly TavernAI.  its perfectly doable. You got whisper for hearing you and kokoro for quick translation back..the chat can be quick&lt;/p&gt;\\n\\n&lt;p&gt;Whisper and Kokoro both take up a tiny bit of gpu, leaving the rest for whatever llm you want to run. dig into it...its 99% there for most folks hardware. I am looking through the comments and seeing you&amp;#39;re getting some terrible advice based on very outdated info. We already crossed the threshold. &lt;/p&gt;\\n\\n&lt;p&gt;Search  Silly TavernAI. start there. in it, kokoro can auto install...enjoy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36e92a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752539724,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34g8w8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Not_your_guy_buddy42","can_mod_post":false,"created_utc":1752518490,"send_replies":true,"parent_id":"t3_1lzts1z","score":4,"author_fullname":"t2_4m6vm3ghs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try this one [https://github.com/Lex-au/Vocalis](https://github.com/Lex-au/Vocalis)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34g8w8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try this one &lt;a href=\\"https://github.com/Lex-au/Vocalis\\"&gt;https://github.com/Lex-au/Vocalis&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34g8w8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752518490,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35xsry","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n353b90","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey if you use groq as the llm provider it goes pretty fast! Still a lot of challenges on the way, saw a \\"Bud-e\\" project like that","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35xsry","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey if you use groq as the llm provider it goes pretty fast! Still a lot of challenges on the way, saw a &amp;quot;Bud-e&amp;quot; project like that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35xsry/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752534246,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752534246,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n353b90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1752525085,"send_replies":true,"parent_id":"t1_n34vcs5","score":2,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's not voice to voice. That's voice to STT to LLM to TTS to voice.  ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n353b90","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s not voice to voice. That&amp;#39;s voice to STT to LLM to TTS to voice.  &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n353b90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525085,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n34vcs5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"radianart","can_mod_post":false,"created_utc":1752522861,"send_replies":true,"parent_id":"t3_1lzts1z","score":4,"author_fullname":"t2_ikplmni","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As someone who is building project with llm and voice input\\\\\\\\output I'd say it's very possible. Depends on how you define real time. With strong gpu and enough vram whisper (probably best STT) and llm can be very fast. I can't really guess cuz I only have 8gb vram but second or two from your phrase to answer is reachable I think.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34vcs5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As someone who is building project with llm and voice input\\\\output I&amp;#39;d say it&amp;#39;s very possible. Depends on how you define real time. With strong gpu and enough vram whisper (probably best STT) and llm can be very fast. I can&amp;#39;t really guess cuz I only have 8gb vram but second or two from your phrase to answer is reachable I think.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34vcs5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752522861,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35ata3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AnotherAvery","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34pt1b","score":1,"author_fullname":"t2_kktcpxzr5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OuteTTS supports many languages and works well, but it's slow...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35ata3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OuteTTS supports many languages and works well, but it&amp;#39;s slow...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35ata3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752527198,"author_flair_text":null,"treatment_tags":[],"created_utc":1752527198,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34pt1b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_moria_","can_mod_post":false,"created_utc":1752521244,"send_replies":true,"parent_id":"t1_n34b93u","score":3,"author_fullname":"t2_10lot4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Whisper is a bomb. Using the various declinations (whisperX, fast whisper etc...) you can do 3/4x! (Oma fat ram with only s 2080). The tts part is terrible for everything that is no English or Chinese","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34pt1b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Whisper is a bomb. Using the various declinations (whisperX, fast whisper etc...) you can do 3/4x! (Oma fat ram with only s 2080). The tts part is terrible for everything that is no English or Chinese&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34pt1b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521244,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34dj4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"junior600","can_mod_post":false,"created_utc":1752517707,"send_replies":true,"parent_id":"t1_n34b93u","score":2,"author_fullname":"t2_dlu9c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh, thanks! I’ll take a look at it. Yeah, I know chatgpt app can do that and it’s amazing… but it’s time-limited, and I’d still prefer having something similar locally, haha.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34dj4e","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh, thanks! I’ll take a look at it. Yeah, I know chatgpt app can do that and it’s amazing… but it’s time-limited, and I’d still prefer having something similar locally, haha.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34dj4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517707,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n363esf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harrro","can_mod_post":false,"created_utc":1752536060,"send_replies":true,"parent_id":"t1_n34b93u","score":2,"author_fullname":"t2_4axt7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep open-webui is what I used for voice chat till unmute came out.\\n\\nIt's not real-time though since it just wires up Whisper (for speech to Text) to transcribe to text, then passes it to your LLM model, waits for the full response to generate, then passes the text to the TTS (I use Kokoro which is fast).\\n\\nIt's a bit of a pain to setup though since you have to setup 3 different services (openwebui, whisper, kokoro).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n363esf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep open-webui is what I used for voice chat till unmute came out.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s not real-time though since it just wires up Whisper (for speech to Text) to transcribe to text, then passes it to your LLM model, waits for the full response to generate, then passes the text to the TTS (I use Kokoro which is fast).&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a bit of a pain to setup though since you have to setup 3 different services (openwebui, whisper, kokoro).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n363esf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752536060,"author_flair_text":"Alpaca","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n34b93u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"guigouz","can_mod_post":false,"created_utc":1752517065,"send_replies":true,"parent_id":"t3_1lzts1z","score":2,"author_fullname":"t2_3de75","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The speech to text part works in open-webui, not sure which lib they use, but you can try whisper for the transcription and coqui-tts for the responses.\\n\\nAlthough not locally, the chatgpt app can do what you want even in the free plan, it does speak japanese and italian.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34b93u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The speech to text part works in open-webui, not sure which lib they use, but you can try whisper for the transcription and coqui-tts for the responses.&lt;/p&gt;\\n\\n&lt;p&gt;Although not locally, the chatgpt app can do what you want even in the free plan, it does speak japanese and italian.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34b93u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517065,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n373rix","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TFox17","can_mod_post":false,"created_utc":1752548764,"send_replies":true,"parent_id":"t3_1lzts1z","score":2,"author_fullname":"t2_63r61","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m doing this on a raspberry pi, via speech to text, local text LLM, then text to speech. Not a great model, and barely fast enough to be usefully interactive, but it does work. The STT and TTS models are monolingual, but setting it up for any particular language or pairs would be easy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n373rix","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m doing this on a raspberry pi, via speech to text, local text LLM, then text to speech. Not a great model, and barely fast enough to be usefully interactive, but it does work. The STT and TTS models are monolingual, but setting it up for any particular language or pairs would be easy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n373rix/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548764,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37glhv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teachersecret","can_mod_post":false,"created_utc":1752554145,"send_replies":true,"parent_id":"t3_1lzts1z","score":2,"author_fullname":"t2_ddyte","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I built on on a stack of parakeet (stt, extremely fast, 600x realtime), Kokoro (tts, 100x realtime), and a qwen 14b tune that all fits in 24gb on my 4090 and does fine. The hardest part is dialing everything in to work streaming - you need to be streaming the output of the text model directly to the speech model so it can output that first sentence asap and stack the rest afterward.\\n\\nYou can get latency in the .20-.50 second range with a stack like that and it works fairly well. Very conversational. Kokoro isn’t the ultimate, but it’s plenty functional.\\n\\nIf you try to go bigger in voice models or AI you’ll need more than a 4090.\\n\\nAnother way to do this is using groq. Groq has a generous free api tier with a whisper implementation and near instant responses on its smaller models, meaning you can set up a whole speech to text pipeline that works free there, and then you only have to figure out the text to speech and can push a bit higher. Latency won’t be as low but it’s still fine and you won’t even need hardware.\\n\\nFor now, Kokoro is, imho, the best option for voice output for something like this as long as emotion and intonation isn’t critical. It works well (better than the other fast and small models). If you need emotional reading, you’re probably going to have to wait for something better.\\n\\nAlternatives…\\n\\nKutai has a new release that does pretty well at this. Decent chatbot and they’ve got it fairly conversational as is.\\n\\nGemma released their tiny 3n model that can’t speak, but it -can- hear, eliminating the need for whisper or parakeet.\\n\\nQwen has released a small speech in speech out LLM that is reasonably fast.","edited":1752554410,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37glhv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I built on on a stack of parakeet (stt, extremely fast, 600x realtime), Kokoro (tts, 100x realtime), and a qwen 14b tune that all fits in 24gb on my 4090 and does fine. The hardest part is dialing everything in to work streaming - you need to be streaming the output of the text model directly to the speech model so it can output that first sentence asap and stack the rest afterward.&lt;/p&gt;\\n\\n&lt;p&gt;You can get latency in the .20-.50 second range with a stack like that and it works fairly well. Very conversational. Kokoro isn’t the ultimate, but it’s plenty functional.&lt;/p&gt;\\n\\n&lt;p&gt;If you try to go bigger in voice models or AI you’ll need more than a 4090.&lt;/p&gt;\\n\\n&lt;p&gt;Another way to do this is using groq. Groq has a generous free api tier with a whisper implementation and near instant responses on its smaller models, meaning you can set up a whole speech to text pipeline that works free there, and then you only have to figure out the text to speech and can push a bit higher. Latency won’t be as low but it’s still fine and you won’t even need hardware.&lt;/p&gt;\\n\\n&lt;p&gt;For now, Kokoro is, imho, the best option for voice output for something like this as long as emotion and intonation isn’t critical. It works well (better than the other fast and small models). If you need emotional reading, you’re probably going to have to wait for something better.&lt;/p&gt;\\n\\n&lt;p&gt;Alternatives…&lt;/p&gt;\\n\\n&lt;p&gt;Kutai has a new release that does pretty well at this. Decent chatbot and they’ve got it fairly conversational as is.&lt;/p&gt;\\n\\n&lt;p&gt;Gemma released their tiny 3n model that can’t speak, but it -can- hear, eliminating the need for whisper or parakeet.&lt;/p&gt;\\n\\n&lt;p&gt;Qwen has released a small speech in speech out LLM that is reasonably fast.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n37glhv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752554145,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34g6tf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mbanana","can_mod_post":false,"created_utc":1752518474,"send_replies":true,"parent_id":"t3_1lzts1z","score":1,"author_fullname":"t2_flii","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[This ](https://github.com/dnhkng/GlaDOS)is basically a toy system, but it works quite well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34g6tf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/dnhkng/GlaDOS\\"&gt;This &lt;/a&gt;is basically a toy system, but it works quite well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n34g6tf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752518474,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35s8jb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rainbowColoredBalls","can_mod_post":false,"created_utc":1752532460,"send_replies":true,"parent_id":"t3_1lzts1z","score":1,"author_fullname":"t2_23ovx259","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unrelated but what's the sota on tokenizing voice without going through the STT route?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35s8jb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unrelated but what&amp;#39;s the sota on tokenizing voice without going through the STT route?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n35s8jb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752532460,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n382l93","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harlekinrains","can_mod_post":false,"created_utc":1752565614,"send_replies":true,"parent_id":"t3_1lzts1z","score":1,"author_fullname":"t2_4296b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"MNN just implemented it in their Android App (Alpha) so, ...\\n\\n(english/chinese only)\\n\\nThey use a 1,3GB TTS model, and a 400MB ASR Model, so maybe 5 years from now this will become sensible.. ;)\\n\\nThat said, the Qwen 2.5 3B omni model is valid to use on smartphones right now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n382l93","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MNN just implemented it in their Android App (Alpha) so, ...&lt;/p&gt;\\n\\n&lt;p&gt;(english/chinese only)&lt;/p&gt;\\n\\n&lt;p&gt;They use a 1,3GB TTS model, and a 400MB ASR Model, so maybe 5 years from now this will become sensible.. ;)&lt;/p&gt;\\n\\n&lt;p&gt;That said, the Qwen 2.5 3B omni model is valid to use on smartphones right now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n382l93/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752565614,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38brc3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chisleu","can_mod_post":false,"created_utc":1752571057,"send_replies":true,"parent_id":"t3_1lzts1z","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't know of anyone who has optimized this. Most people are using whole command/sentence speech to text. Ideally you would want to speech to tokens in NRT and stream the tokens into a non reasoning model to minimize latency. Then you need a token to speech that can operate on streams that are fast enough. That doesn't exist AFAIK.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38brc3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t know of anyone who has optimized this. Most people are using whole command/sentence speech to text. Ideally you would want to speech to tokens in NRT and stream the tokens into a non reasoning model to minimize latency. Then you need a token to speech that can operate on streams that are fast enough. That doesn&amp;#39;t exist AFAIK.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n38brc3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752571057,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36zv1a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Traditional_Tap1708","can_mod_post":false,"send_replies":true,"parent_id":"t1_n357u0x","score":1,"author_fullname":"t2_aejvth7b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, livekit can be hosted locally as well.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36zv1a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, livekit can be hosted locally as well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n36zv1a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547306,"author_flair_text":null,"treatment_tags":[],"created_utc":1752547306,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n357u0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bio_risk","can_mod_post":false,"created_utc":1752526355,"send_replies":true,"parent_id":"t1_n353e8a","score":5,"author_fullname":"t2_ame4bow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Even if the model is local, the system is not local if you have to use livekit cloud.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n357u0x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even if the model is local, the system is not local if you have to use livekit cloud.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n357u0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526355,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n380j0d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"medtech-2716","can_mod_post":false,"created_utc":1752564438,"send_replies":true,"parent_id":"t1_n353e8a","score":1,"author_fullname":"t2_11uhk2sbog","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am working on a similar project but it's for a SaaS. Are you keen to collaborate?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n380j0d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am working on a similar project but it&amp;#39;s for a SaaS. Are you keen to collaborate?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzts1z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n380j0d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564438,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n353e8a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Traditional_Tap1708","can_mod_post":false,"created_utc":1752525108,"send_replies":true,"parent_id":"t3_1lzts1z","score":1,"author_fullname":"t2_aejvth7b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here’s how I built it. All local models and pretty much realtime (&lt;600ms response latency)\\n\\nhttps://github.com/taresh18/conversify","edited":1752525595,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n353e8a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here’s how I built it. All local models and pretty much realtime (&amp;lt;600ms response latency)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/taresh18/conversify\\"&gt;https://github.com/taresh18/conversify&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzts1z/is_realtime_voicetovoice_still_science_fiction/n353e8a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525108,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzts1z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
