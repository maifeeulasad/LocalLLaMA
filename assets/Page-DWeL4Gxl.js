import{j as e}from"./index-Bqs-ekb2.js";import{R as l}from"./RedditPostRenderer-DUVdf0-i.js";import"./index-D52ORTDm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I am a beginner and I want to start learning about LLMs and finetuning.  \\nI have an old laptop with just 4 gigabytes of VRAM (RTX 2050). I can't invest in new hardware. What is currently the best rental service available for getting a decent GPU/TPU that can handle finetuning and RL for small models?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What subscription to buy?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lny5qy","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.48,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_rl17i801d","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751256935,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751256478,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I am a beginner and I want to start learning about LLMs and finetuning.&lt;br/&gt;\\nI have an old laptop with just 4 gigabytes of VRAM (RTX 2050). I can&amp;#39;t invest in new hardware. What is currently the best rental service available for getting a decent GPU/TPU that can handle finetuning and RL for small models?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lny5qy","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ConsistentStruggle82","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/","subreddit_subscribers":493240,"created_utc":1751256478,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0klw98","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"colin_colout","can_mod_post":false,"created_utc":1751289273,"send_replies":true,"parent_id":"t1_n0iusi4","score":1,"author_fullname":"t2_14l4ya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can run the small models on 0gb vram and 16gb of regular RAM too (just depends on your patents )\\n\\nOnce you learn a bit about what is possible and what you're doing , you can figure out what to scale. \\n\\nIt's only an expensive hobby when people here want it to be (and that part is fun too... But you can get far with hardware you have)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0klw98","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can run the small models on 0gb vram and 16gb of regular RAM too (just depends on your patents )&lt;/p&gt;\\n\\n&lt;p&gt;Once you learn a bit about what is possible and what you&amp;#39;re doing , you can figure out what to scale. &lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s only an expensive hobby when people here want it to be (and that part is fun too... But you can get far with hardware you have)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lny5qy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0klw98/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751289273,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0iusi4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inevitable-publicn","can_mod_post":false,"created_utc":1751256766,"send_replies":true,"parent_id":"t3_1lny5qy","score":9,"author_fullname":"t2_1p5pzfbr46","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"None? Use free tiers of AI providers to experiment and play with.  \\nDo real stuff on local LLMs, 4GB of VRAM can run small models like Gemma 3 4B, Qwen 3 4B etc very well. They are quite capable, but not as generalized as larger LLMs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0iusi4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;None? Use free tiers of AI providers to experiment and play with.&lt;br/&gt;\\nDo real stuff on local LLMs, 4GB of VRAM can run small models like Gemma 3 4B, Qwen 3 4B etc very well. They are quite capable, but not as generalized as larger LLMs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0iusi4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751256766,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0k0kjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustImmunity","can_mod_post":false,"created_utc":1751280313,"send_replies":true,"parent_id":"t3_1lny5qy","score":3,"author_fullname":"t2_c4pwgz16","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"google collab or kaggle will provide some free compute, but it wont get you super far.\\n\\nfor a few dollars an hour, you can rent h100's for the amount of time you need them, and rent multiple 4090's for the same price as a single h100, and naturally can spread that usage out overtime.\\n\\n[https://app.hyperbolic.ai/?gpuCount=8](https://app.hyperbolic.ai/?gpuCount=8) \\\\-- h100 galore, they provide bare metal or jupyter notebooks depending on what you prefer\\n\\n[https://www.runpod.io/](https://www.runpod.io/) \\\\-- these guys allow a pretty good selection of cards to choose from for pretty cheap pricing, since they allow third party providers,\\n\\n[https://vast.ai/](https://vast.ai/) \\\\-- ive never used these guys, all i know is that they are a runpod competitor","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0k0kjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;google collab or kaggle will provide some free compute, but it wont get you super far.&lt;/p&gt;\\n\\n&lt;p&gt;for a few dollars an hour, you can rent h100&amp;#39;s for the amount of time you need them, and rent multiple 4090&amp;#39;s for the same price as a single h100, and naturally can spread that usage out overtime.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://app.hyperbolic.ai/?gpuCount=8\\"&gt;https://app.hyperbolic.ai/?gpuCount=8&lt;/a&gt; -- h100 galore, they provide bare metal or jupyter notebooks depending on what you prefer&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.runpod.io/\\"&gt;https://www.runpod.io/&lt;/a&gt; -- these guys allow a pretty good selection of cards to choose from for pretty cheap pricing, since they allow third party providers,&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://vast.ai/\\"&gt;https://vast.ai/&lt;/a&gt; -- ive never used these guys, all i know is that they are a runpod competitor&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0k0kjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751280313,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m0vzq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmergencyWater7782","can_mod_post":false,"created_utc":1751304431,"send_replies":true,"parent_id":"t3_1lny5qy","score":2,"author_fullname":"t2_1ppyfcozdy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Voltage Park has guaranteed on demand H100's, 24/7 expert support, and doesn't require a contract or minimums.  \\n   \\nYes, I work there.  \\n  \\nWe support a lot of small labs and researchers as well as enterprises. Our goal is to make AI compute accessible to everyone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m0vzq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Voltage Park has guaranteed on demand H100&amp;#39;s, 24/7 expert support, and doesn&amp;#39;t require a contract or minimums.  &lt;/p&gt;\\n\\n&lt;p&gt;Yes, I work there.  &lt;/p&gt;\\n\\n&lt;p&gt;We support a lot of small labs and researchers as well as enterprises. Our goal is to make AI compute accessible to everyone.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0m0vzq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751304431,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0mqp0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoVibeCoding","can_mod_post":false,"created_utc":1751311760,"send_replies":true,"parent_id":"t3_1lny5qy","score":2,"author_fullname":"t2_1neapdttam","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We offer RTX 4090 (24GB), RTX 5090 (32GB) GPU rentals in Tier 3 data centers—reliable and high-performance. The service is slightly more expensive than Vast AI, though.\\n\\n[https://www.cloudrift.ai/](https://www.cloudrift.ai/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0mqp0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We offer RTX 4090 (24GB), RTX 5090 (32GB) GPU rentals in Tier 3 data centers—reliable and high-performance. The service is slightly more expensive than Vast AI, though.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.cloudrift.ai/\\"&gt;https://www.cloudrift.ai/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0mqp0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751311760,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0iumw2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1751256695,"send_replies":true,"parent_id":"t3_1lny5qy","score":2,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The best way to learn is to use Kaggle. You don't need to buy any subscriptions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0iumw2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The best way to learn is to use Kaggle. You don&amp;#39;t need to buy any subscriptions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0iumw2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751256695,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0npcgt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1751322150,"send_replies":true,"parent_id":"t3_1lny5qy","score":1,"author_fullname":"t2_askwa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use Modal and you can get $30 free credit every month. Use free tiers of larger LLM providers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0npcgt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use Modal and you can get $30 free credit every month. Use free tiers of larger LLM providers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lny5qy/what_subscription_to_buy/n0npcgt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751322150,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lny5qy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
