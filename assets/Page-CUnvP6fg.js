import{j as e}from"./index-CWmJdUH_.js";import{R as l}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey,\\n\\nI'm curious, what are people fine-tuning their models for? \\n\\nI was working in a company where we fine-tuned models to better deal with product images, but the company couldn't keep the lights on. Most agencies, companies, freelancers, seem to use off-the-shelf models, which are getting \\"good enough\\" for the job. \\n\\nSo, what are people fine-tuning their models for? and which companies, or industries, are most likely to be fine-tuning models? \\n\\nThanks, just an idiot asking! ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What are people fine-tuning their models for?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5gmfr","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":21,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_at09kvrk","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":21,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753098077,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m curious, what are people fine-tuning their models for? &lt;/p&gt;\\n\\n&lt;p&gt;I was working in a company where we fine-tuned models to better deal with product images, but the company couldn&amp;#39;t keep the lights on. Most agencies, companies, freelancers, seem to use off-the-shelf models, which are getting &amp;quot;good enough&amp;quot; for the job. &lt;/p&gt;\\n\\n&lt;p&gt;So, what are people fine-tuning their models for? and which companies, or industries, are most likely to be fine-tuning models? &lt;/p&gt;\\n\\n&lt;p&gt;Thanks, just an idiot asking! &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m5gmfr","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"MKBSP","discussion_type":null,"num_comments":28,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/","subreddit_subscribers":502721,"created_utc":1753098077,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fu4ru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"g3t0nmyl3v3l","can_mod_post":false,"created_utc":1753143693,"send_replies":true,"parent_id":"t1_n4c3u9q","score":3,"author_fullname":"t2_66pyt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does this actually reliably give the information the users need without hallucinating? The benefits of rag is filling the context with explicit sources and linking, I would honestly be surprised if the goal was filling the model with domain specific knowledge that RAG wouldn‚Äôt still at least be necessary to combat hallucinations. But I guess not every tool requires the same fidelity","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fu4ru","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does this actually reliably give the information the users need without hallucinating? The benefits of rag is filling the context with explicit sources and linking, I would honestly be surprised if the goal was filling the model with domain specific knowledge that RAG wouldn‚Äôt still at least be necessary to combat hallucinations. But I guess not every tool requires the same fidelity&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4fu4ru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753143693,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4d65h2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fp4guru","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d24pa","score":2,"author_fullname":"t2_1tp8zldw5g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We made some attempts with it as well as the tokenizer extension. Didn't work well.","edited":1753130636,"author_flair_css_class":null,"name":"t1_n4d65h2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We made some attempts with it as well as the tokenizer extension. Didn&amp;#39;t work well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5gmfr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4d65h2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753115205,"author_flair_text":null,"collapsed":false,"created_utc":1753115205,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4guq22","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Adventurous_Pin6281","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d24pa","score":1,"author_fullname":"t2_1tdc5by9dj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This makes no sense because this isn't how finetuning works.¬†","edited":false,"author_flair_css_class":null,"name":"t1_n4guq22","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This makes no sense because this isn&amp;#39;t how finetuning works.¬†&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5gmfr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4guq22/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753157228,"author_flair_text":null,"collapsed":false,"created_utc":1753157228,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d24pa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ce44n","score":1,"author_fullname":"t2_8lvrytgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What about fine tuning the¬† embeddings?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4d24pa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about fine tuning the¬† embeddings?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4d24pa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753114062,"author_flair_text":null,"treatment_tags":[],"created_utc":1753114062,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ce44n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fp4guru","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cd9af","score":1,"author_fullname":"t2_1tp8zldw5g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The wordings of the questions are very similar. Rag doesn't work very well.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ce44n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The wordings of the questions are very similar. Rag doesn&amp;#39;t work very well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4ce44n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753107033,"author_flair_text":null,"treatment_tags":[],"created_utc":1753107033,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4cd9af","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1753106775,"send_replies":true,"parent_id":"t1_n4c3u9q","score":2,"author_fullname":"t2_8lvrytgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What about RAG?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cd9af","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about RAG?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4cd9af/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106775,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c3u9q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fp4guru","can_mod_post":false,"created_utc":1753103732,"send_replies":true,"parent_id":"t3_1m5gmfr","score":10,"author_fullname":"t2_1tp8zldw5g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Adding company specific knowledge to the models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c3u9q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Adding company specific knowledge to the models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4c3u9q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753103732,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c55e8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Better-Designer-8904","can_mod_post":false,"created_utc":1753104171,"send_replies":true,"parent_id":"t1_n4c4te8","score":1,"author_fullname":"t2_q32ab87w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you are interested to finetune local models etc. you can look into these:  \\n[axolotl](https://github.com/axolotl-ai-cloud/axolotl)\\n\\n[unsloth](https://github.com/unslothai/unsloth)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c55e8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you are interested to finetune local models etc. you can look into these:&lt;br/&gt;\\n&lt;a href=\\"https://github.com/axolotl-ai-cloud/axolotl\\"&gt;axolotl&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/unslothai/unsloth\\"&gt;unsloth&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4c55e8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104171,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c4te8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Better-Designer-8904","can_mod_post":false,"created_utc":1753104060,"send_replies":true,"parent_id":"t3_1m5gmfr","score":8,"author_fullname":"t2_q32ab87w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've personally just been experimenting with fine-tuning for the most part. There are many ways to fix a problem in tech, but here are some of the use cases for it:\\n\\n* Breaking a model is fun. Sometimes they give interesting results when you train them wrong. For example, one time I tried to fine-tune a Llama model, and it became depressed and questioned if I was human or not.\\n* You want a specific quality of output. For instance, if you know your work requires only certain types of answers. Lately, I was experimenting with document management and generating names for documents. It doesn't matter how strict you are or how well you explain to the models how the naming should work; there will always be inconsistency and slightly different results. For that, I'm trying to fine-tune an open-source model that is trained on a document's OCR and its name according to a standard naming schema. Stuff like that increases the quality massively.\\n* Or you're just adding more context, like your company's own info for a chatbot. You could fine-tune a model on your documentation so it's fluent in that specific branch. Or a law firm could do it with its client documents to have a model that \\"remembers\\" and can help the staff with simple stuff.\\n* Or maybe you want to add or remove the model's guardrails and censorship.\\n* Similar to getting a specific output, you can transfer or create a speaking style for the agent. For example, if you fine-tune a model specifically on all of Einstein's papers, and your data is good enough, the model can learn to write in his style. Or like an anime girl, same same.\\n\\n  \\nedit: just an idiot answering ;)","edited":1753104418,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c4te8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve personally just been experimenting with fine-tuning for the most part. There are many ways to fix a problem in tech, but here are some of the use cases for it:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Breaking a model is fun. Sometimes they give interesting results when you train them wrong. For example, one time I tried to fine-tune a Llama model, and it became depressed and questioned if I was human or not.&lt;/li&gt;\\n&lt;li&gt;You want a specific quality of output. For instance, if you know your work requires only certain types of answers. Lately, I was experimenting with document management and generating names for documents. It doesn&amp;#39;t matter how strict you are or how well you explain to the models how the naming should work; there will always be inconsistency and slightly different results. For that, I&amp;#39;m trying to fine-tune an open-source model that is trained on a document&amp;#39;s OCR and its name according to a standard naming schema. Stuff like that increases the quality massively.&lt;/li&gt;\\n&lt;li&gt;Or you&amp;#39;re just adding more context, like your company&amp;#39;s own info for a chatbot. You could fine-tune a model on your documentation so it&amp;#39;s fluent in that specific branch. Or a law firm could do it with its client documents to have a model that &amp;quot;remembers&amp;quot; and can help the staff with simple stuff.&lt;/li&gt;\\n&lt;li&gt;Or maybe you want to add or remove the model&amp;#39;s guardrails and censorship.&lt;/li&gt;\\n&lt;li&gt;Similar to getting a specific output, you can transfer or create a speaking style for the agent. For example, if you fine-tune a model specifically on all of Einstein&amp;#39;s papers, and your data is good enough, the model can learn to write in his style. Or like an anime girl, same same.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;edit: just an idiot answering ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4c4te8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104060,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cba8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MKBSP","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c455m","score":1,"author_fullname":"t2_at09kvrk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Got it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cba8k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Got it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4cba8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106166,"author_flair_text":null,"treatment_tags":[],"created_utc":1753106166,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c455m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maverick_soul_143747","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bvvre","score":2,"author_fullname":"t2_1af9q3qa0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Actually specifics on what I am working and my project data, writing style for documents. This is more of an experimentation to see if that works. It is more of an experiment to see how much customized can I make it","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4c455m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually specifics on what I am working and my project data, writing style for documents. This is more of an experimentation to see if that works. It is more of an experiment to see how much customized can I make it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4c455m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753103834,"author_flair_text":null,"treatment_tags":[],"created_utc":1753103834,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bvvre","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MKBSP","can_mod_post":false,"created_utc":1753100917,"send_replies":true,"parent_id":"t1_n4bqs4f","score":1,"author_fullname":"t2_at09kvrk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you want to fine-tune your own model for?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bvvre","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you want to fine-tune your own model for?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4bvvre/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100917,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bqs4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"maverick_soul_143747","can_mod_post":false,"created_utc":1753098921,"send_replies":true,"parent_id":"t3_1m5gmfr","score":4,"author_fullname":"t2_1af9q3qa0b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have the same question and curious to know how it is applied. I am looking to finetune one for my needs and sooner or later I will be poor to pay for cloud llms with the way the prices are going ü§∑üèΩ‚Äç‚ôÇÔ∏è","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqs4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have the same question and curious to know how it is applied. I am looking to finetune one for my needs and sooner or later I will be poor to pay for cloud llms with the way the prices are going ü§∑üèΩ‚Äç‚ôÇÔ∏è&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4bqs4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098921,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bwr0t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Relative-Pass-9836","can_mod_post":false,"created_utc":1753101240,"send_replies":true,"parent_id":"t3_1m5gmfr","score":2,"author_fullname":"t2_4rcufk42","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"for accuracy on  specific dataset or scene  what they care?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bwr0t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;for accuracy on  specific dataset or scene  what they care?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4bwr0t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101240,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4czhk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celsowm","can_mod_post":false,"created_utc":1753113307,"send_replies":true,"parent_id":"t3_1m5gmfr","score":2,"author_fullname":"t2_dyvrh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I want to fine-tuning to legal Brazilian specific issues","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4czhk4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to fine-tuning to legal Brazilian specific issues&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4czhk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753113307,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4e9ens","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FunnyAsparagus1253","can_mod_post":false,"created_utc":1753126113,"send_replies":true,"parent_id":"t1_n4dhf45","score":2,"author_fullname":"t2_i6c8tay3w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep! Also for running on edge devices. I‚Äôve seen 2b models fine-tuned for ‚Äòthe small subset of functions you might want a smartphone to do‚Äô","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e9ens","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep! Also for running on edge devices. I‚Äôve seen 2b models fine-tuned for ‚Äòthe small subset of functions you might want a smartphone to do‚Äô&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4e9ens/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753126113,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dhf45","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"abnormal_human","can_mod_post":false,"created_utc":1753118312,"send_replies":true,"parent_id":"t3_1m5gmfr","score":2,"author_fullname":"t2_5y02z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"While I'm sure there are a few people using fine tuning to do things that truly can't be done any other way, a lot of what I see happening now is basically cost optimization.\\n\\nMany of the things that can be done with LLMs can be done with zero-shot/few-shot techniques with SOTA LLMs for a price. If the price is too high, generate training data and try to get a cheaper LLM to do it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dhf45","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While I&amp;#39;m sure there are a few people using fine tuning to do things that truly can&amp;#39;t be done any other way, a lot of what I see happening now is basically cost optimization.&lt;/p&gt;\\n\\n&lt;p&gt;Many of the things that can be done with LLMs can be done with zero-shot/few-shot techniques with SOTA LLMs for a price. If the price is too high, generate training data and try to get a cheaper LLM to do it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4dhf45/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118312,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bwync","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rnosov","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bvpdy","score":5,"author_fullname":"t2_18x6fa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're asking \\"what are people fine-tuning their models for\\". I'm guessing (hence the question mark) that many people are fine-tuning to evade detectors. Personally, I think merging might be simpler way but fine-tuning would do the trick too. Ask me how I know.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4bwync","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re asking &amp;quot;what are people fine-tuning their models for&amp;quot;. I&amp;#39;m guessing (hence the question mark) that many people are fine-tuning to evade detectors. Personally, I think merging might be simpler way but fine-tuning would do the trick too. Ask me how I know.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4bwync/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101318,"author_flair_text":null,"treatment_tags":[],"created_utc":1753101318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bvpdy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MKBSP","can_mod_post":false,"created_utc":1753100850,"send_replies":true,"parent_id":"t1_n4btm3k","score":1,"author_fullname":"t2_at09kvrk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Either:   \\n1) you are fine-tuning to evade AI detectors?   \\nor  \\n2) you are asking if I'm evading AI detectors?   \\n  \\nIf it's 1) thanks, good, interesting area!   \\nIt it's 2) I dont get the question? My post sounds very AI'y? or what?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bvpdy","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Either:&lt;br/&gt;\\n1) you are fine-tuning to evade AI detectors?&lt;br/&gt;\\nor&lt;br/&gt;\\n2) you are asking if I&amp;#39;m evading AI detectors?   &lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s 1) thanks, good, interesting area!&lt;br/&gt;\\nIt it&amp;#39;s 2) I dont get the question? My post sounds very AI&amp;#39;y? or what?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gmfr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4bvpdy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100850,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4btm3k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rnosov","can_mod_post":false,"created_utc":1753100051,"send_replies":true,"parent_id":"t3_1m5gmfr","score":2,"author_fullname":"t2_18x6fa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Evading AI detectors?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4btm3k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Evading AI detectors?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4btm3k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100051,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cdj63","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1753106858,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_8lvrytgw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm interested in which models they are fine (base or instruct? Size?)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cdj63","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m interested in which models they are fine (base or instruct? Size?)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4cdj63/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106858,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dz9ia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GoodSamaritan333","can_mod_post":false,"created_utc":1753123237,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_5n4jepc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Amoral reasoning; Finding possible contraditions and corruption done to religious texts, like the Bible; Political reasoning; Roleplaying; Fictitious World Building.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dz9ia","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Amoral reasoning; Finding possible contraditions and corruption done to religious texts, like the Bible; Political reasoning; Roleplaying; Fictitious World Building.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4dz9ia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753123237,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dzruh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RRO-19","can_mod_post":false,"created_utc":1753123382,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_tpig9c37k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"user researcher here üëã what sorts of tools are you all using for fine-tuning? / what pain points are you hitting with fine tuning?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dzruh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;user researcher here üëã what sorts of tools are you all using for fine-tuning? / what pain points are you hitting with fine tuning?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4dzruh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753123382,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ermm1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"created_utc":1753131317,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most of the time you do not need to fine tune, if you do you will likely know.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ermm1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most of the time you do not need to fine tune, if you do you will likely know.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4ermm1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753131317,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ful54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fun-Wolf-2007","can_mod_post":false,"created_utc":1753143852,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_lsixf36sr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For privacy and confidential data, and domain based knowledge \\n\\nBy giving the local LLM models the business knowledge, RCA, CAR, and historical manufacturing data you can use the model to improve your operations and data analytics","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ful54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For privacy and confidential data, and domain based knowledge &lt;/p&gt;\\n\\n&lt;p&gt;By giving the local LLM models the business knowledge, RCA, CAR, and historical manufacturing data you can use the model to improve your operations and data analytics&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4ful54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753143852,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gqv1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"abaris243","can_mod_post":false,"created_utc":1753155601,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_e49kxbgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just see how human and casual I can get mine to sound with hand typed fine tuning datasets","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gqv1y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just see how human and casual I can get mine to sound with hand typed fine tuning datasets&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4gqv1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753155601,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4h70hq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CantaloupeDismal1195","can_mod_post":false,"created_utc":1753163021,"send_replies":true,"parent_id":"t3_1m5gmfr","score":1,"author_fullname":"t2_1ld1b995hk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Embedding models seem to have quite a difference in performance when fine-tuned in specific areas(Korean...), but for models with tens of billions of llm, the difference in performance is often minimal or even worse.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4h70hq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Embedding models seem to have quite a difference in performance when fine-tuned in specific areas(Korean...), but for models with tens of billions of llm, the difference in performance is often minimal or even worse.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4h70hq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753163021,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4h5cis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Scam_Altman","can_mod_post":false,"created_utc":1753162159,"send_replies":true,"parent_id":"t3_1m5gmfr","score":0,"author_fullname":"t2_1a0oiggi8d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hardcore pornography and other socially unacceptable activity","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4h5cis","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hardcore pornography and other socially unacceptable activity&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gmfr/what_are_people_finetuning_their_models_for/n4h5cis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753162159,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gmfr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
