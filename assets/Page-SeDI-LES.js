import{j as e}from"./index-CNyNkRpk.js";import{R as t}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Just like that, out of nowhere, we have an open-source Claude 4 Sonnet, or better yet, and this is no joke. I have been using the Kimi model for some time, and it truly feels the rightful successor to Claude 3.6 Sonnet. What Deepseek is to OpenAI, Kimi is to Anthropic.\\n\\nK2 isn't truly a different model; it uses Deepseek v3 architecture. You can find that in the model config, but there are some subtle yet key improvements that resulted in such drastic improvements.\\n\\n# Kimi K2 vs. DsV3 architecture\\n\\nThis is from Liu Shaowei's Zhihu post.\\n\\n1. **Number of experts = 384 vs. 256**: 1.5x more experts for improving overall model ability, and helps lower the train/val loss, yielding better quality at the same *activated-parameter* cost and inference FLOPs. But also a 50% spike in memory footprint.\\n2. **Number of attention heads = 64 vs 128**: They halve the attention-head count, shrinking the QKV projection weights from 10 GB to 5 GB per EP rank, which more than offsets the 50 % memory spike by yielding a net 2.5 GB saving while simultaneously halving pre-fill latency and leaving the KV-cache size unchanged.\\n3. **first\\\\_k\\\\_dense = 1 vs 3:** Kimi replaced the first layer with a dense layer after observing that the router in layer-1 consistently produced severe load imbalance.\\n4. **n\\\\_group = 1 vs. 8**: Dropping expert grouping frees every GPU to route to any of the 384 experts, letting EPLB handle load balancing while shrinking memory and widening the model‚Äôs effective capacity.\\n\\n# MuonCLIP\\n\\nOne of the key contributor of Kimi's success. Kimi went with Muon, more token efficient than AdamW. But it wasn't before tested for such a large model. To overcome they added a drop-in extension qk-clip. This helped to transplant Muon‚Äôs 2√ó token-efficiency into a 1-trillion-parameter regime without its historical Achilles‚Äô heel: qk-clip rescales the query and key projections after every Muon update.\\n\\n# How good in comparison to Claude 4 Sonnet?\\n\\nKimi k2's positioning directly challenged Claude 4 Sonnet, the current SOTA agentic model. The k2 was specifically RL'd for extensive tool-use scenarios. However, it's not just good at tool use, it is surprisingly creative at writing and coding.\\n\\nSome observations\\n\\n* The K2 feels most natural to talk to than any available models. Zero sycophancy, no assumption, it just sticks to the point. Though I still find Sonnet 4 to be more attentive to instructions.\\n* It has the simillar vibes of Claude 3.6 Sonnet, understands user intention better and more grounded response.\\n* K2 has a better taste.\\n* The coding is surprisingly good, though Sonnet will still be better at raw coding as for some task I found myself going back to it.\\n* The best part it is roughly 1/12th of Sonnet's cost. Crazy times indeed.\\n\\nYou can find the complete note here: [Notes on Kimi K2](https://composio.dev/blog/notes-on-kimi-k2)\\n\\nWould love to know your experience with the new Kimi K2 and how do you think it compares to Claude for agentic coding and other agentic tasks?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Notes on Kimi K2: A Deepseek derivative but the true Sonnet 3.6 Succesor","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m0rk8t","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.84,"author_flair_background_color":null,"subreddit_type":"public","ups":113,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_5cwsshv7","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":113,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752609298,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752608406,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Just like that, out of nowhere, we have an open-source Claude 4 Sonnet, or better yet, and this is no joke. I have been using the Kimi model for some time, and it truly feels the rightful successor to Claude 3.6 Sonnet. What Deepseek is to OpenAI, Kimi is to Anthropic.&lt;/p&gt;\\n\\n&lt;p&gt;K2 isn&amp;#39;t truly a different model; it uses Deepseek v3 architecture. You can find that in the model config, but there are some subtle yet key improvements that resulted in such drastic improvements.&lt;/p&gt;\\n\\n&lt;h1&gt;Kimi K2 vs. DsV3 architecture&lt;/h1&gt;\\n\\n&lt;p&gt;This is from Liu Shaowei&amp;#39;s Zhihu post.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Number of experts = 384 vs. 256&lt;/strong&gt;: 1.5x more experts for improving overall model ability, and helps lower the train/val loss, yielding better quality at the same &lt;em&gt;activated-parameter&lt;/em&gt; cost and inference FLOPs. But also a 50% spike in memory footprint.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Number of attention heads = 64 vs 128&lt;/strong&gt;: They halve the attention-head count, shrinking the QKV projection weights from 10 GB to 5 GB per EP rank, which more than offsets the 50 % memory spike by yielding a net 2.5 GB saving while simultaneously halving pre-fill latency and leaving the KV-cache size unchanged.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;first_k_dense = 1 vs 3:&lt;/strong&gt; Kimi replaced the first layer with a dense layer after observing that the router in layer-1 consistently produced severe load imbalance.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;n_group = 1 vs. 8&lt;/strong&gt;: Dropping expert grouping frees every GPU to route to any of the 384 experts, letting EPLB handle load balancing while shrinking memory and widening the model‚Äôs effective capacity.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;h1&gt;MuonCLIP&lt;/h1&gt;\\n\\n&lt;p&gt;One of the key contributor of Kimi&amp;#39;s success. Kimi went with Muon, more token efficient than AdamW. But it wasn&amp;#39;t before tested for such a large model. To overcome they added a drop-in extension qk-clip. This helped to transplant Muon‚Äôs 2√ó token-efficiency into a 1-trillion-parameter regime without its historical Achilles‚Äô heel: qk-clip rescales the query and key projections after every Muon update.&lt;/p&gt;\\n\\n&lt;h1&gt;How good in comparison to Claude 4 Sonnet?&lt;/h1&gt;\\n\\n&lt;p&gt;Kimi k2&amp;#39;s positioning directly challenged Claude 4 Sonnet, the current SOTA agentic model. The k2 was specifically RL&amp;#39;d for extensive tool-use scenarios. However, it&amp;#39;s not just good at tool use, it is surprisingly creative at writing and coding.&lt;/p&gt;\\n\\n&lt;p&gt;Some observations&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;The K2 feels most natural to talk to than any available models. Zero sycophancy, no assumption, it just sticks to the point. Though I still find Sonnet 4 to be more attentive to instructions.&lt;/li&gt;\\n&lt;li&gt;It has the simillar vibes of Claude 3.6 Sonnet, understands user intention better and more grounded response.&lt;/li&gt;\\n&lt;li&gt;K2 has a better taste.&lt;/li&gt;\\n&lt;li&gt;The coding is surprisingly good, though Sonnet will still be better at raw coding as for some task I found myself going back to it.&lt;/li&gt;\\n&lt;li&gt;The best part it is roughly 1/12th of Sonnet&amp;#39;s cost. Crazy times indeed.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;You can find the complete note here: &lt;a href=\\"https://composio.dev/blog/notes-on-kimi-k2\\"&gt;Notes on Kimi K2&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Would love to know your experience with the new Kimi K2 and how do you think it compares to Claude for agentic coding and other agentic tasks?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0.png?auto=webp&amp;s=be0f59a7d80ea9baf0f5765f28ae5ccb54405651","width":957,"height":638},"resolutions":[{"url":"https://external-preview.redd.it/zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b0a6766afd7ad39a4f200b56a12c3aac0dd8217","width":108,"height":72},{"url":"https://external-preview.redd.it/zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2938e3166381ec1896e700d2388d1776bb5dee0","width":216,"height":144},{"url":"https://external-preview.redd.it/zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9780dfd5ff0fb6bd81353eb93b97ab9ae7ad41b","width":320,"height":213},{"url":"https://external-preview.redd.it/zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5de23db11f854a0136a52e55d26a3b94d5b22c84","width":640,"height":426}],"variants":{},"id":"zGgQbeMFTo_lv7lUQOHfoNHDMmbj1qkSBZum0vd4aW0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m0rk8t","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"SunilKumarDash","discussion_type":null,"num_comments":31,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/","subreddit_subscribers":499773,"created_utc":1752608406,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3butv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752612074,"send_replies":true,"parent_id":"t1_n3bpjww","score":53,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's the semi-offical name of the new Claude 3.5 that was annouced in October 2024. Anthropic did not provide a name for it in the blog, they just called it the new Claude 3.5.\\n\\nTo avoid confusion a lot of the community started calling it Claude 3.6, and Anthropic essentially acknowledged this name when they released Claude 3.7 as the next update, since that name only makes sense if a 3.6 already exists.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3butv6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s the semi-offical name of the new Claude 3.5 that was annouced in October 2024. Anthropic did not provide a name for it in the blog, they just called it the new Claude 3.5.&lt;/p&gt;\\n\\n&lt;p&gt;To avoid confusion a lot of the community started calling it Claude 3.6, and Anthropic essentially acknowledged this name when they released Claude 3.7 as the next update, since that name only makes sense if a 3.6 already exists.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3butv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752612074,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3elely","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SunilKumarDash","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3crseq","score":1,"author_fullname":"t2_5cwsshv7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"3.6 was better than 3.7 for me","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3elely","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3.6 was better than 3.7 for me&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m0rk8t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3elely/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752649087,"author_flair_text":null,"treatment_tags":[],"created_utc":1752649087,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3crseq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Few-Yam9901","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3bssmx","score":1,"author_fullname":"t2_1rhlf3bcfk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So is OP saying it‚Äôs not as good as sonnet 3.7? I thought maybe it was better","edited":false,"author_flair_css_class":null,"name":"t1_n3crseq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So is OP saying it‚Äôs not as good as sonnet 3.7? I thought maybe it was better&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m0rk8t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3crseq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752622348,"author_flair_text":null,"collapsed":false,"created_utc":1752622348,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3bssmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fanboy190","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3brgys","score":4,"author_fullname":"t2_9sex8db9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ah ok, my apologies! After I saw it for the first time, I tried doing some online research, but I could never find out what it was. Thank you for letting me know!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bssmx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah ok, my apologies! After I saw it for the first time, I tried doing some online research, but I could never find out what it was. Thank you for letting me know!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3bssmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752611509,"author_flair_text":null,"treatment_tags":[],"created_utc":1752611509,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3brgys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ssjultrainstnict","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3bps5v","score":24,"author_fullname":"t2_8itp30y9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is claude sonnet 3.5 (new) which released in october 2024. It was a better model than the 3.5 sonnet they released in march 2024 but they never updated the name. People generally refer to it as 3.6 sonnet.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3brgys","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is claude sonnet 3.5 (new) which released in october 2024. It was a better model than the 3.5 sonnet they released in march 2024 but they never updated the name. People generally refer to it as 3.6 sonnet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3brgys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752611141,"author_flair_text":null,"treatment_tags":[],"created_utc":1752611141,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}}],"before":null}},"user_reports":[],"saved":false,"id":"n3bps5v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fanboy190","can_mod_post":false,"created_utc":1752610673,"send_replies":true,"parent_id":"t1_n3bpjww","score":5,"author_fullname":"t2_9sex8db9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I‚Äôve seen ‚Äú3.6‚Äù mentioned a lot on Reddit specifically and I am always very confused when I see it. Perhaps it‚Äôs just an indicator of hallucinated AI responses?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bps5v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I‚Äôve seen ‚Äú3.6‚Äù mentioned a lot on Reddit specifically and I am always very confused when I see it. Perhaps it‚Äôs just an indicator of hallucinated AI responses?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3bps5v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752610673,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ek2n5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-main","can_mod_post":false,"created_utc":1752648376,"send_replies":true,"parent_id":"t1_n3bpjww","score":1,"author_fullname":"t2_3dgjr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is \\"Claude Sonnet 3.5 (new)\\", from October last year. A totally distinct model from Sonnet 3.5 (June '24) and Sonnet 3.7 (Feb '25). Usually called 3.6, sometimes called 3.5.1, otherwise people refer to it by release time. Turns out when you mess up naming your products badly enough, your community does it for you but less coordinated. \\n\\nIf you think Anthropic's naming has been good compared to OpenAI and Google, well, this is where they got loudly reminded by their fans that they had really good thing going, if they could just refrain from *fucking it up*.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ek2n5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is &amp;quot;Claude Sonnet 3.5 (new)&amp;quot;, from October last year. A totally distinct model from Sonnet 3.5 (June &amp;#39;24) and Sonnet 3.7 (Feb &amp;#39;25). Usually called 3.6, sometimes called 3.5.1, otherwise people refer to it by release time. Turns out when you mess up naming your products badly enough, your community does it for you but less coordinated. &lt;/p&gt;\\n\\n&lt;p&gt;If you think Anthropic&amp;#39;s naming has been good compared to OpenAI and Google, well, this is where they got loudly reminded by their fans that they had really good thing going, if they could just refrain from &lt;em&gt;fucking it up&lt;/em&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3ek2n5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752648376,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3bpjww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Few-Yam9901","can_mod_post":false,"created_utc":1752610611,"send_replies":true,"parent_id":"t3_1m0rk8t","score":23,"author_fullname":"t2_1rhlf3bcfk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is sonnet 3.6? Isn‚Äôt it 3.7?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bpjww","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is sonnet 3.6? Isn‚Äôt it 3.7?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3bpjww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752610611,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3dzjui","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Briskfall","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3dyk54","score":1,"author_fullname":"t2_wmwp7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Claude's architecture is not publicly disclosed. I'd like to hear why you think so. As in, what characteristics of Claude models gives it off that way?\\n\\n[This](https://www.linkedin.com/pulse/under-hood-chatgptdense-transformers-vs-llamamixture-experts-joshi-owj0c) is not the most reliable source, but it stated that it's using a dense architecture. I also tried googling information that would corroborate that Claude is MoE, but wasn't able to find sources nor discussions that back it up.","edited":false,"author_flair_css_class":null,"name":"t1_n3dzjui","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude&amp;#39;s architecture is not publicly disclosed. I&amp;#39;d like to hear why you think so. As in, what characteristics of Claude models gives it off that way?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.linkedin.com/pulse/under-hood-chatgptdense-transformers-vs-llamamixture-experts-joshi-owj0c\\"&gt;This&lt;/a&gt; is not the most reliable source, but it stated that it&amp;#39;s using a dense architecture. I also tried googling information that would corroborate that Claude is MoE, but wasn&amp;#39;t able to find sources nor discussions that back it up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m0rk8t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3dzjui/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752638091,"author_flair_text":null,"collapsed":false,"created_utc":1752638091,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3dyk54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cheap_Meeting","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3dv141","score":4,"author_fullname":"t2_2ibsmh69","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not related. Claude is most likely an MoE model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3dyk54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not related. Claude is most likely an MoE model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3dyk54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752637697,"author_flair_text":null,"treatment_tags":[],"created_utc":1752637697,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ekci6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-main","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3dv141","score":2,"author_fullname":"t2_3dgjr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Before you infer anything from the name \\"mixture of experts\\" remember that the experts are routed per token per layer. It's a kind of sparse model. Nothing to do with invoking expertise.","edited":1752650224,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ekci6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Before you infer anything from the name &amp;quot;mixture of experts&amp;quot; remember that the experts are routed per token per layer. It&amp;#39;s a kind of sparse model. Nothing to do with invoking expertise.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3ekci6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752648523,"author_flair_text":null,"treatment_tags":[],"created_utc":1752648523,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3dv141","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Briskfall","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3duii9","score":-1,"author_fullname":"t2_wmwp7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Kimi-k2, when being called to act as an \\"expert\\" of a certain domain would also would swap its \\"voice\\" much evidently to a neutral one, whereas that is not so much the case for Claude models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3dv141","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kimi-k2, when being called to act as an &amp;quot;expert&amp;quot; of a certain domain would also would swap its &amp;quot;voice&amp;quot; much evidently to a neutral one, whereas that is not so much the case for Claude models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3dv141/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752636291,"author_flair_text":null,"treatment_tags":[],"created_utc":1752636291,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3duii9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1752636090,"send_replies":true,"parent_id":"t1_n3cd4zg","score":1,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;  I guess that's the downside of being a MoE model though\\n\\n\\nWhat do you mean by that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3duii9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I guess that&amp;#39;s the downside of being a MoE model though&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;What do you mean by that?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3duii9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752636090,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3cd4zg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Briskfall","can_mod_post":false,"created_utc":1752617475,"send_replies":true,"parent_id":"t3_1m0rk8t","score":10,"author_fullname":"t2_wmwp7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep! Agreed! The tone and the amount of sycophancy definitely feels lessened vs 4.0 Sonnet and 3.7 Sonnet when in a new convo, out of the box!\\n\\nThere's still a notable difference though... I would say that Sonnet-3-5-10-22's personality gets attuned better/faster to what I like though...\\n\\nKimi's base personality is still a bit too polite and distanced, haha! It also doesn't find the best energy to reflect my energy when we are doing \\"serious learning tasks\\" and starts to format like gpt-o3 ü´†... I guess that's the downside of being a MoE model though, sigh... üòó\\n\\nSo yeah - unfortunately not totally 3.6, and only sometimes. If I steered 4.0 and 3.7 away with longer context that's not out of the box, they can somehow reach a 3.5-10-22 like vibe and persona...","edited":1752619060,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cd4zg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep! Agreed! The tone and the amount of sycophancy definitely feels lessened vs 4.0 Sonnet and 3.7 Sonnet when in a new convo, out of the box!&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s still a notable difference though... I would say that Sonnet-3-5-10-22&amp;#39;s personality gets attuned better/faster to what I like though...&lt;/p&gt;\\n\\n&lt;p&gt;Kimi&amp;#39;s base personality is still a bit too polite and distanced, haha! It also doesn&amp;#39;t find the best energy to reflect my energy when we are doing &amp;quot;serious learning tasks&amp;quot; and starts to format like gpt-o3 ü´†... I guess that&amp;#39;s the downside of being a MoE model though, sigh... üòó&lt;/p&gt;\\n\\n&lt;p&gt;So yeah - unfortunately not totally 3.6, and only sometimes. If I steered 4.0 and 3.7 away with longer context that&amp;#39;s not out of the box, they can somehow reach a 3.5-10-22 like vibe and persona...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3cd4zg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752617475,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3cjke1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tat_tvam_asshole","can_mod_post":false,"created_utc":1752619652,"send_replies":true,"parent_id":"t3_1m0rk8t","score":8,"author_fullname":"t2_jxuvgdyj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'll say, it's the first model I've ever interacted with that doesn't just assume it knows why there's a code problem and first tries debugging before offering radical code refactors. \\n\\nalso, the ability to make 3d visualizations is pretty good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cjke1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll say, it&amp;#39;s the first model I&amp;#39;ve ever interacted with that doesn&amp;#39;t just assume it knows why there&amp;#39;s a code problem and first tries debugging before offering radical code refactors. &lt;/p&gt;\\n\\n&lt;p&gt;also, the ability to make 3d visualizations is pretty good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3cjke1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752619652,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3dp29q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nuclearbananana","can_mod_post":false,"created_utc":1752633997,"send_replies":true,"parent_id":"t3_1m0rk8t","score":3,"author_fullname":"t2_27hg4b53","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its prose is God-tier, way better than sonnet 3.6.\\n\\nIt can also actually write long when needed.\\n\\nConversely 3.6 had this curious sense of almost self awareness, that I'm not sure this one has. It was also really good at paying attention to the right parts of your message.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3dp29q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its prose is God-tier, way better than sonnet 3.6.&lt;/p&gt;\\n\\n&lt;p&gt;It can also actually write long when needed.&lt;/p&gt;\\n\\n&lt;p&gt;Conversely 3.6 had this curious sense of almost self awareness, that I&amp;#39;m not sure this one has. It was also really good at paying attention to the right parts of your message.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3dp29q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752633997,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3dvhkn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"createthiscom","can_mod_post":false,"created_utc":1752636471,"send_replies":true,"parent_id":"t3_1m0rk8t","score":2,"author_fullname":"t2_ozxxf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"k2 instruct Q4_K_XL is nice, but I‚Äôm still not convinced it‚Äôs really better than V3 0324. Maybe I just need more time on it. It seems to really dislike generating unified diffs for one thing, which kind of makes things awkward. It does have a very different personality though, which I find interesting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3dvhkn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;k2 instruct Q4_K_XL is nice, but I‚Äôm still not convinced it‚Äôs really better than V3 0324. Maybe I just need more time on it. It seems to really dislike generating unified diffs for one thing, which kind of makes things awkward. It does have a very different personality though, which I find interesting.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3dvhkn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752636471,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fe872","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3diomr","score":1,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The first phrase is weird, the whole post reads like an ad, and you can ask the AI to introduce grammar mistakes.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3fe872","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The first phrase is weird, the whole post reads like an ad, and you can ask the AI to introduce grammar mistakes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3fe872/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752664839,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1752664839,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3diomr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-LaughingMan-0D","can_mod_post":false,"created_utc":1752631669,"send_replies":true,"parent_id":"t1_n3bl63w","score":43,"author_fullname":"t2_f9b3qh4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There's a few grammar mistakes, and barely any slop. This is good old human written. It's just formatted well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3diomr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a few grammar mistakes, and barely any slop. This is good old human written. It&amp;#39;s just formatted well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3diomr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752631669,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":43}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3d5g1a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Robonglious","can_mod_post":false,"created_utc":1752627036,"send_replies":true,"parent_id":"t1_n3bl63w","score":23,"author_fullname":"t2_ckhhu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How can you tell? I mean, the formatting is too good for a Redditor but I didn't notice overt slop. Oh crap, maybe I'm getting de-sensitized...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3d5g1a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How can you tell? I mean, the formatting is too good for a Redditor but I didn&amp;#39;t notice overt slop. Oh crap, maybe I&amp;#39;m getting de-sensitized...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3d5g1a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752627036,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fdy2r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3epv22","score":0,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can ask the AI to introduce grammar errors or put them yourself. WTF start a post like \\"Just like that\\" and \\"and this is no joke\\" except a marketing agent or AI?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3fdy2r","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can ask the AI to introduce grammar errors or put them yourself. WTF start a post like &amp;quot;Just like that&amp;quot; and &amp;quot;and this is no joke&amp;quot; except a marketing agent or AI?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3fdy2r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752664715,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1752664715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n3epv22","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hambeggar","can_mod_post":false,"created_utc":1752651575,"send_replies":true,"parent_id":"t1_n3bl63w","score":8,"author_fullname":"t2_62gpc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bros are so AI-brained that they think every well-formatted post with grammar errors are now AI posts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3epv22","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bros are so AI-brained that they think every well-formatted post with grammar errors are now AI posts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3epv22/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752651575,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3bl63w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1752609385,"send_replies":true,"parent_id":"t3_1m0rk8t","score":14,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please stop posting text straight from AI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bl63w","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please stop posting text straight from AI&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3bl63w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752609385,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3en5vu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoseIndependent5370","can_mod_post":false,"created_utc":1752650052,"send_replies":true,"parent_id":"t1_n3e0wmg","score":2,"author_fullname":"t2_s3hzmyjs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OpenCode, Cline, Roo Code, Claude Code Router","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3en5vu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenCode, Cline, Roo Code, Claude Code Router&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3en5vu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752650052,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3e0wmg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather-Cod2129","can_mod_post":false,"created_utc":1752638648,"send_replies":true,"parent_id":"t3_1m0rk8t","score":1,"author_fullname":"t2_182pbi954w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How do you code with Kimi k2? With what tool?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3e0wmg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you code with Kimi k2? With what tool?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3e0wmg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752638648,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ft6ql","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Physical_Ad9040","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3en99s","score":1,"author_fullname":"t2_8h2i7wiei","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"so any llm provider that adjusts their api format to claude-style can be injected into claude code?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3ft6ql","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so any llm provider that adjusts their api format to claude-style can be injected into claude code?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3ft6ql/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752670600,"author_flair_text":null,"treatment_tags":[],"created_utc":1752670600,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3en99s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoseIndependent5370","can_mod_post":false,"created_utc":1752650103,"send_replies":true,"parent_id":"t1_n3e45yq","score":1,"author_fullname":"t2_s3hzmyjs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, their API is simply programmed to handle Anthropic-style API requests.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3en99s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, their API is simply programmed to handle Anthropic-style API requests.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0rk8t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3en99s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752650103,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3e45yq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Physical_Ad9040","can_mod_post":false,"created_utc":1752640067,"send_replies":true,"parent_id":"t3_1m0rk8t","score":1,"author_fullname":"t2_8h2i7wiei","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How could they make it Claude Code compatible?\\n\\n\\nAre they related to Anthropic?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3e45yq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How could they make it Claude Code compatible?&lt;/p&gt;\\n\\n&lt;p&gt;Are they related to Anthropic?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3e45yq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752640067,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3eb27v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InfiniteTrans69","can_mod_post":false,"created_utc":1752643620,"send_replies":true,"parent_id":"t3_1m0rk8t","score":1,"author_fullname":"t2_1j5dv6mrfz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;The K2 feels most natural to talk to than any available models. Zero sycophancy, no assumption, it just sticks to the point.\\n\\nThat's exactly my experience as well. For most stuff I search for on the web, I use K1.5 as it's fast and reliable, but when I really want to know something specific, I use K2 and I always really like the responses I get. They are to the point, not overly verbose, extremely well phrased, easy to understand, still conversational but not too casual and cringe, not sycophantic at all. Just right.\\n\\nI guess that's also the reason why Kimi K2 also reached the top in EQ-Bench.  \\n[https://eqbench.com/](https://eqbench.com/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3eb27v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The K2 feels most natural to talk to than any available models. Zero sycophancy, no assumption, it just sticks to the point.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s exactly my experience as well. For most stuff I search for on the web, I use K1.5 as it&amp;#39;s fast and reliable, but when I really want to know something specific, I use K2 and I always really like the responses I get. They are to the point, not overly verbose, extremely well phrased, easy to understand, still conversational but not too casual and cringe, not sycophantic at all. Just right.&lt;/p&gt;\\n\\n&lt;p&gt;I guess that&amp;#39;s also the reason why Kimi K2 also reached the top in EQ-Bench.&lt;br/&gt;\\n&lt;a href=\\"https://eqbench.com/\\"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3eb27v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752643620,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3bs6v3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"koushd","can_mod_post":false,"created_utc":1752611341,"send_replies":true,"parent_id":"t3_1m0rk8t","score":-10,"author_fullname":"t2_4yut6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Slop","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bs6v3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Slop&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0rk8t/notes_on_kimi_k2_a_deepseek_derivative_but_the/n3bs6v3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752611341,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0rk8t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-10}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
