import{j as e}from"./index-DACS7Nh6.js";import{R as l}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Meta’s New Superintelligence Lab Is Discussing Major A.I. Strategy Changes","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":73,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzv16g","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.92,"author_flair_background_color":null,"ups":105,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_hdcx5ggfg","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":105,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=684dded7ebf0cced3ec460c9dda8f551b9ecbd73","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752519240,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"nytimes.com","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?auto=webp&amp;s=211ff5c9d8860c633734a0f69515f881de8905e4","width":1050,"height":550},"resolutions":[{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f431ed3ef795de81f0d9be2452ed2466f4727f88","width":108,"height":56},{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c728fd0b47256c06b7e53063606348710b74999","width":216,"height":113},{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a1dc415541c74d1ee2dd3620b8e6997e56ad7f2","width":320,"height":167},{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a0ebffa84a0071645409fce2ba2a7d33bd6a731","width":640,"height":335},{"url":"https://external-preview.redd.it/62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=361e53f2aa166522931efd9533bd8c76685cfc5a","width":960,"height":502}],"variants":{},"id":"62QXtiCManuS6UimUaWcoUxH8gOETN8-9D6ljAVaZH0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lzv16g","is_robot_indexable":true,"num_duplicates":4,"report_reasons":null,"author":"showmeufos","discussion_type":null,"num_comments":53,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/","stickied":false,"url":"https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html","subreddit_subscribers":499295,"created_utc":1752519240,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n356eh1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Bandit-level-200","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nyuk","score":9,"author_fullname":"t2_2fabbmlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I love bench maxxed models trained on useless benchmarks","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n356eh1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love bench maxxed models trained on useless benchmarks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n356eh1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525954,"author_flair_text":null,"treatment_tags":[],"created_utc":1752525954,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n34nyuk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752520713,"send_replies":true,"parent_id":"t1_n34kjec","score":15,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So you're saying you *don't* want stem-maxxed llama 1b and 600b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34nyuk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So you&amp;#39;re saying you &lt;em&gt;don&amp;#39;t&lt;/em&gt; want stem-maxxed llama 1b and 600b?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34nyuk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752520713,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n34kjec","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Bandit-level-200","can_mod_post":false,"created_utc":1752519743,"send_replies":true,"parent_id":"t3_1lzv16g","score":69,"author_fullname":"t2_2fabbmlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"More censorship, more closed source, more safety.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34kjec","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More censorship, more closed source, more safety.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34kjec/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752519743,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37e4n3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Appropriate_Web8985","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34p529","score":5,"author_fullname":"t2_1sy8xh7u3b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it's like what the Kimi k2 post said - if you truly want AGI then you need to open source. otherwise you can use all kinds of tricks to juice your benchmarking and degrade the performance of your model over time while pretending it's as good as it was before like every other western lab","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37e4n3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s like what the Kimi k2 post said - if you truly want AGI then you need to open source. otherwise you can use all kinds of tricks to juice your benchmarking and degrade the performance of your model over time while pretending it&amp;#39;s as good as it was before like every other western lab&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n37e4n3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752553034,"author_flair_text":null,"treatment_tags":[],"created_utc":1752553034,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38g5kw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ToHallowMySleep","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34p529","score":0,"author_fullname":"t2_5c9lpcuj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To be fair it's not like that at all, it is more that they feel they are raising the level of models for everyone with their open source efforts, and that is something they want to shift away from, in order to preserve their lead.\\n\\nFrom a business perspective it makes sense, because they're throwing all this money at the new superintelligence team, so how are they going to make the money back?\\n\\nFrom a long term AI strategy perspective it could make sense as well, as they shared their progress early on to help catalyse the industry, but now they want to cement in a lead. They forced other players to show their hands, so it served its purpose.\\n\\nI hope they still contribute significantly to open source, but it has to be admitted it was a bit of a surprise when they released such excellent models completely open, over the past year or so. Meta is about money.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38g5kw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be fair it&amp;#39;s not like that at all, it is more that they feel they are raising the level of models for everyone with their open source efforts, and that is something they want to shift away from, in order to preserve their lead.&lt;/p&gt;\\n\\n&lt;p&gt;From a business perspective it makes sense, because they&amp;#39;re throwing all this money at the new superintelligence team, so how are they going to make the money back?&lt;/p&gt;\\n\\n&lt;p&gt;From a long term AI strategy perspective it could make sense as well, as they shared their progress early on to help catalyse the industry, but now they want to cement in a lead. They forced other players to show their hands, so it served its purpose.&lt;/p&gt;\\n\\n&lt;p&gt;I hope they still contribute significantly to open source, but it has to be admitted it was a bit of a surprise when they released such excellent models completely open, over the past year or so. Meta is about money.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38g5kw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752573545,"author_flair_text":null,"treatment_tags":[],"created_utc":1752573545,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n34p529","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BumbleSlob","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34k1sl","score":34,"author_fullname":"t2_1j7fhlcqkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What a strange internal discussion, if true. This is like saying you’re going to improve your grades by hiding your report card from your parents","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34p529","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What a strange internal discussion, if true. This is like saying you’re going to improve your grades by hiding your report card from your parents&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34p529/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521053,"author_flair_text":null,"treatment_tags":[],"created_utc":1752521053,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}}],"before":null}},"user_reports":[],"saved":false,"id":"n34k1sl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pip25hu","can_mod_post":false,"created_utc":1752519597,"send_replies":true,"parent_id":"t1_n34j2by","score":53,"author_fullname":"t2_9u8ghp9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not sure. For that to matter, they'll need to develop better models first. As long as they lag behind the competition, the most closing their models can accomplish is saving themselves from embarrassment.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34k1sl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure. For that to matter, they&amp;#39;ll need to develop better models first. As long as they lag behind the competition, the most closing their models can accomplish is saving themselves from embarrassment.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34k1sl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752519597,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3563ze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752525872,"send_replies":true,"parent_id":"t1_n34j2by","score":8,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not surprised at all and I expected this happening after Llama 4 flopped and they didn't release the weights for Llama 3.3 8B. It's essentially guaranteed they'll cease open weighting their models considering the new team is composed of people driven by greed and lacking in moral principles (in the sense that they're going to go harder with censorship).","edited":1752526085,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3563ze","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not surprised at all and I expected this happening after Llama 4 flopped and they didn&amp;#39;t release the weights for Llama 3.3 8B. It&amp;#39;s essentially guaranteed they&amp;#39;ll cease open weighting their models considering the new team is composed of people driven by greed and lacking in moral principles (in the sense that they&amp;#39;re going to go harder with censorship).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n3563ze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525872,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35m35v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Grimulkan","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34q3g0","score":7,"author_fullname":"t2_k6cdxg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Agree. I think Llama 3.1/3.3 models are fantastic bases for fine-tuning still, and are more stable due to the dense architecture. Personally, I still find 405B fine-tunes terrific for internal applications. Just not good at code, or with R1-style reasoning (out of the box).\\n\\nPersonally, I'm in the camp of \\"Llama 3 forever\\" as far as community fine-tunes go, kinda like \\"SDXL forever\\". I can see similar potential, and I think there is still good milleage left, especially for creative applications.\\n\\nUnfortunately, I think community involvement has not been great, perhaps because great and reasonable paid alternatives exist (Claude, Gemini), and because the community has been split between the GPU users and the CPU users who favor MoE, which is a bit more difficult to train (and the CPU users can't contribute to training).\\n\\nPity Meta never released other L3 sizes. I'd have loved a Mistral Large 2 sized model (Nemotron Ultra was great but has a very specific fine-tune philosophy), and a ~30B one (though as you mentioned, others have stepped in).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35m35v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree. I think Llama 3.1/3.3 models are fantastic bases for fine-tuning still, and are more stable due to the dense architecture. Personally, I still find 405B fine-tunes terrific for internal applications. Just not good at code, or with R1-style reasoning (out of the box).&lt;/p&gt;\\n\\n&lt;p&gt;Personally, I&amp;#39;m in the camp of &amp;quot;Llama 3 forever&amp;quot; as far as community fine-tunes go, kinda like &amp;quot;SDXL forever&amp;quot;. I can see similar potential, and I think there is still good milleage left, especially for creative applications.&lt;/p&gt;\\n\\n&lt;p&gt;Unfortunately, I think community involvement has not been great, perhaps because great and reasonable paid alternatives exist (Claude, Gemini), and because the community has been split between the GPU users and the CPU users who favor MoE, which is a bit more difficult to train (and the CPU users can&amp;#39;t contribute to training).&lt;/p&gt;\\n\\n&lt;p&gt;Pity Meta never released other L3 sizes. I&amp;#39;d have loved a Mistral Large 2 sized model (Nemotron Ultra was great but has a very specific fine-tune philosophy), and a ~30B one (though as you mentioned, others have stepped in).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35m35v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752530515,"author_flair_text":null,"treatment_tags":[],"created_utc":1752530515,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n356pj8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"giant3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34rd4y","score":3,"author_fullname":"t2_82esi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exaone has huge potential though some times it never converges on a solution despite spending 2000+ tokens on reasoning. I hope they fix it.","edited":false,"author_flair_css_class":null,"name":"t1_n356pj8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exaone has huge potential though some times it never converges on a solution despite spending 2000+ tokens on reasoning. I hope they fix it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzv16g","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n356pj8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526040,"author_flair_text":null,"collapsed":false,"created_utc":1752526040,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38g9ep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ToHallowMySleep","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34rd4y","score":1,"author_fullname":"t2_5c9lpcuj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I personally look forward to IBM's reveal that puts them 10 years behind everyone else, as they have consistently done since about the turn of the century.","edited":false,"author_flair_css_class":null,"name":"t1_n38g9ep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I personally look forward to IBM&amp;#39;s reveal that puts them 10 years behind everyone else, as they have consistently done since about the turn of the century.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzv16g","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38g9ep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752573604,"author_flair_text":null,"collapsed":false,"created_utc":1752573604,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34rd4y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34q3g0","score":8,"author_fullname":"t2_vqgbql9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please notice IBM is preparing Granite 4 and it's already supported in llama.cpp.\\nCurrently LG Exaone is working on support for their upcoming models.\\nAnd still there is nvidia with their surprises","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34rd4y","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please notice IBM is preparing Granite 4 and it&amp;#39;s already supported in llama.cpp.\\nCurrently LG Exaone is working on support for their upcoming models.\\nAnd still there is nvidia with their surprises&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34rd4y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521699,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752521699,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n34q3g0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":19,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's pretty much my take, too.  Also, we still have the Llama3 models to train further.  Tulu3-70B and Tulu3-405B show there's tons of potential there.\\n\\nI mostly regret that they didn't release a Llama3 in the 24B-32B range, but others have stepped in and filled that gap (Mistral small (24B), Gemma3-27B, Qwen3-32B).\\n\\nMy own plan for moving forward is to focus on continued pretraining of Phi-4-25B unfrozen layers.  It's MIT licensed, which is about as unburdensome as a license gets.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34q3g0","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s pretty much my take, too.  Also, we still have the Llama3 models to train further.  Tulu3-70B and Tulu3-405B show there&amp;#39;s tons of potential there.&lt;/p&gt;\\n\\n&lt;p&gt;I mostly regret that they didn&amp;#39;t release a Llama3 in the 24B-32B range, but others have stepped in and filled that gap (Mistral small (24B), Gemma3-27B, Qwen3-32B).&lt;/p&gt;\\n\\n&lt;p&gt;My own plan for moving forward is to focus on continued pretraining of Phi-4-25B unfrozen layers.  It&amp;#39;s MIT licensed, which is about as unburdensome as a license gets.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34q3g0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521328,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752521328,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3504k4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"One-Employment3759","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":12,"author_fullname":"t2_1f6wnmakwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's just how Alexandr Wang rolls. He is a very cringey guy from everything I've seen of him so far. He doesn't even understand AI he is just CEO bro.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3504k4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s just how Alexandr Wang rolls. He is a very cringey guy from everything I&amp;#39;ve seen of him so far. He doesn&amp;#39;t even understand AI he is just CEO bro.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n3504k4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752524204,"author_flair_text":null,"treatment_tags":[],"created_utc":1752524204,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35c5xj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":2,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why are you using quotes?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35c5xj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why are you using quotes?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35c5xj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752527587,"author_flair_text":null,"treatment_tags":[],"created_utc":1752527587,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n362dgf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":1,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Why?\\n\\nbecause all of these models were inspired by Meta's open-sourcing of llama just like OpenAI inspired others to close their research.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n362dgf","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Why?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;because all of these models were inspired by Meta&amp;#39;s open-sourcing of llama just like OpenAI inspired others to close their research.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n362dgf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752535721,"author_flair_text":"Llama 3.1","treatment_tags":[],"created_utc":1752535721,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n364qw1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rented4823","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":1,"author_fullname":"t2_1fnyacs6yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Always have been.\\n\\nhttps://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n364qw1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Always have been.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/\\"&gt;https://systemicjustice.org/article/facebook-and-genocide-how-facebook-contributed-to-genocide-in-myanmar-and-why-it-will-not-be-held-accountable/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n364qw1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752536494,"author_flair_text":null,"treatment_tags":[],"created_utc":1752536494,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36eylq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"srwaxalot","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34nvkr","score":1,"author_fullname":"t2_gc1n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meta has and will always be evil.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36eylq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta has and will always be evil.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n36eylq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752539973,"author_flair_text":null,"treatment_tags":[],"created_utc":1752539973,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34nvkr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1752520687,"send_replies":true,"parent_id":"t1_n34j2by","score":39,"author_fullname":"t2_vqgbql9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why?  \\nPeople here love models like Qwen, Mistral, Gemma, and many others. Llama has kind of been forgotten at this point.  \\nIt’s just disappointing, now both OpenAI and Meta will be \\"evil corporations\\" again.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34nvkr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why?&lt;br/&gt;\\nPeople here love models like Qwen, Mistral, Gemma, and many others. Llama has kind of been forgotten at this point.&lt;br/&gt;\\nIt’s just disappointing, now both OpenAI and Meta will be &amp;quot;evil corporations&amp;quot; again.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34nvkr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752520687,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34phqw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1752521154,"send_replies":true,"parent_id":"t1_n34j2by","score":4,"author_fullname":"t2_qhlcbiy3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"terrible\\" is a strong word. I think the local LLM community has done very well since the last good release of llama 3.3 70b \\\\~8 months ago (Llama 4 was pretty much ignored by most). We had a lot of good models such as GLM-4, Qwen3, dots.llm1, Mistral Small 3.0 - 3.2, Falcon H1, Command-A, etc.\\n\\nIt's sad if Meta gives up the llama series, yes, but we are still doing very fine without it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34phqw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;terrible&amp;quot; is a strong word. I think the local LLM community has done very well since the last good release of llama 3.3 70b ~8 months ago (Llama 4 was pretty much ignored by most). We had a lot of good models such as GLM-4, Qwen3, dots.llm1, Mistral Small 3.0 - 3.2, Falcon H1, Command-A, etc.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s sad if Meta gives up the llama series, yes, but we are still doing very fine without it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34phqw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521154,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35g84v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n351110","score":3,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sir, this is LocalLLaMA.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35g84v","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sir, this is LocalLLaMA.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35g84v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752528764,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752528764,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35gdxc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n351110","score":0,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;less ties to the NSA\\n\\n\\nLol, you get more because now you stand out. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35gdxc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;less ties to the NSA&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Lol, you get more because now you stand out. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35gdxc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752528811,"author_flair_text":null,"treatment_tags":[],"created_utc":1752528811,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n351110","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Extra-Whereas-9408","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34k8lh","score":13,"author_fullname":"t2_1n6r9xijnp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it's not, you can choose to run it on several Cloud providers, many which are more trustworthy and with less ties to the NSA than American closed AI companies.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n351110","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it&amp;#39;s not, you can choose to run it on several Cloud providers, many which are more trustworthy and with less ties to the NSA than American closed AI companies.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n351110/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752524453,"author_flair_text":null,"treatment_tags":[],"created_utc":1752524453,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n34k8lh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752519653,"send_replies":true,"parent_id":"t1_n34j2by","score":6,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If they produce a 2T model, it's closed source for me regardless if they release it. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34k8lh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If they produce a 2T model, it&amp;#39;s closed source for me regardless if they release it. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34k8lh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752519653,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n34j2by","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"showmeufos","can_mod_post":false,"created_utc":1752519300,"send_replies":true,"parent_id":"t3_1lzv16g","score":73,"author_fullname":"t2_hdcx5ggfg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Original link: [https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html](https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html)\\n\\nArchived copy (which also avoids paywall): [https://archive.is/CzXTF](https://archive.is/CzXTF)\\n\\n&gt;**Meta’s New Superintelligence Lab Is Discussing Major A.I. Strategy Changes**\\n\\n&gt;Members of the lab, including the new chief A.I. officer, Alexandr Wang, have talked about abandoning Meta’s most powerful open source A.I. model in favor of developing a closed one.\\n\\n&gt;Meta’s newly formed [superintelligence lab](https://archive.is/o/CzXTF/https://www.nytimes.com/2025/06/10/technology/meta-new-ai-lab-superintelligence.html) has discussed making a series of changes to the company’s artificial intelligence strategy, in what would amount to a major shake-up at the social media giant. Last week, a small group of top members of the lab, including Alexandr Wang, 28, Meta’s new chief A.I. officer, discussed abandoning the company’s most powerful open source A.I. model, called Behemoth, in favor of developing a closed model, two people with knowledge of the matter said.\\n\\nA shift to closed source would obviously be terrible for the r/LocalLLaMA community.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34j2by","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Original link: &lt;a href=\\"https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html\\"&gt;https://www.nytimes.com/2025/07/14/technology/meta-superintelligence-lab-ai.html&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Archived copy (which also avoids paywall): &lt;a href=\\"https://archive.is/CzXTF\\"&gt;https://archive.is/CzXTF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;&lt;strong&gt;Meta’s New Superintelligence Lab Is Discussing Major A.I. Strategy Changes&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Members of the lab, including the new chief A.I. officer, Alexandr Wang, have talked about abandoning Meta’s most powerful open source A.I. model in favor of developing a closed one.&lt;/p&gt;\\n\\n&lt;p&gt;Meta’s newly formed &lt;a href=\\"https://archive.is/o/CzXTF/https://www.nytimes.com/2025/06/10/technology/meta-new-ai-lab-superintelligence.html\\"&gt;superintelligence lab&lt;/a&gt; has discussed making a series of changes to the company’s artificial intelligence strategy, in what would amount to a major shake-up at the social media giant. Last week, a small group of top members of the lab, including Alexandr Wang, 28, Meta’s new chief A.I. officer, discussed abandoning the company’s most powerful open source A.I. model, called Behemoth, in favor of developing a closed model, two people with knowledge of the matter said.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;A shift to closed source would obviously be terrible for the &lt;a href=\\"/r/LocalLLaMA\\"&gt;r/LocalLLaMA&lt;/a&gt; community.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34j2by/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752519300,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":73}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37ivoy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rieux_n_Tarrou","can_mod_post":false,"created_utc":1752555195,"send_replies":true,"parent_id":"t1_n34r5yq","score":1,"author_fullname":"t2_19njxtbg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't worry, it just opens up the playing field for FOSS\\n\\nAlthough, by the looks of it FOSS will be outlaws now\\n\\nBring it on bitches. Thinking they can control the kraken haaaa","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37ivoy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t worry, it just opens up the playing field for FOSS&lt;/p&gt;\\n\\n&lt;p&gt;Although, by the looks of it FOSS will be outlaws now&lt;/p&gt;\\n\\n&lt;p&gt;Bring it on bitches. Thinking they can control the kraken haaaa&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n37ivoy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752555195,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34r5yq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"celsowm","can_mod_post":false,"created_utc":1752521641,"send_replies":true,"parent_id":"t3_1lzv16g","score":12,"author_fullname":"t2_dyvrh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sad","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34r5yq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sad&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34r5yq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521641,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34ss49","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34pbbe","score":14,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I completely agree, Llama-2's release had a huge effect, it pushed the entire industry to be more open.\\n\\nI feel like a lot of people that came to this later in the cycle might not realize just how novel and groundbreaking it was when Meta decided to officially release Llama-2. It was very much against the industry norm at the time. And I have absolutely no doubt that the only reason we have models like Gemma, Mistral, Qwen, etc today is because Meta kickstarted the open LLM movement.\\n\\nWhich is something we should be grateful for, despite the fact that they've faltered lately.  I still hope they'll end up taking another shot and releasing an actual good follow up to Llama-3, but even if they don't, they'll have made a permanent mark in the history of LLMs.","edited":1752523244,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34ss49","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I completely agree, Llama-2&amp;#39;s release had a huge effect, it pushed the entire industry to be more open.&lt;/p&gt;\\n\\n&lt;p&gt;I feel like a lot of people that came to this later in the cycle might not realize just how novel and groundbreaking it was when Meta decided to officially release Llama-2. It was very much against the industry norm at the time. And I have absolutely no doubt that the only reason we have models like Gemma, Mistral, Qwen, etc today is because Meta kickstarted the open LLM movement.&lt;/p&gt;\\n\\n&lt;p&gt;Which is something we should be grateful for, despite the fact that they&amp;#39;ve faltered lately.  I still hope they&amp;#39;ll end up taking another shot and releasing an actual good follow up to Llama-3, but even if they don&amp;#39;t, they&amp;#39;ll have made a permanent mark in the history of LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34ss49/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752522119,"author_flair_text":null,"treatment_tags":[],"created_utc":1752522119,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38l2mt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fish312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34pbbe","score":1,"author_fullname":"t2_mogjd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same for stable diffusion.\\n\\nEither die a hero or live long enough to become the villain","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n38l2mt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same for stable diffusion.&lt;/p&gt;\\n\\n&lt;p&gt;Either die a hero or live long enough to become the villain&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38l2mt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752576120,"author_flair_text":null,"treatment_tags":[],"created_utc":1752576120,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34pbbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loudmax","can_mod_post":false,"created_utc":1752521102,"send_replies":true,"parent_id":"t1_n34n88d","score":23,"author_fullname":"t2_61k60","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"From an investor's perspective, that money might be flushed down the toilet.\\n\\nThe leaked Llama models is what got me interested in running LLMs as a hobbyist.  That probably goes for a lot of us, or even most of us here.  As someone with no particular stake in Meta's financial success, I'll always be grateful to Meta's of making their model open-weights.  We probably wouldn't have all the open-weight models we do today if it weren't for Meta's example.  It may have been irresponsible for Meta's fiduciary situation, but it worked out well for the rest of us.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34pbbe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From an investor&amp;#39;s perspective, that money might be flushed down the toilet.&lt;/p&gt;\\n\\n&lt;p&gt;The leaked Llama models is what got me interested in running LLMs as a hobbyist.  That probably goes for a lot of us, or even most of us here.  As someone with no particular stake in Meta&amp;#39;s financial success, I&amp;#39;ll always be grateful to Meta&amp;#39;s of making their model open-weights.  We probably wouldn&amp;#39;t have all the open-weight models we do today if it weren&amp;#39;t for Meta&amp;#39;s example.  It may have been irresponsible for Meta&amp;#39;s fiduciary situation, but it worked out well for the rest of us.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34pbbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521102,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35bglv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"burner_sb","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35779y","score":3,"author_fullname":"t2_1ez41r3ib1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That would be a rational position for them to take (despite thinking it's generally bad, but hey it's not exactly like Meta is morally not-evil). That said, I'm pretty sure the 28 year old jackass who they made CEO doesn't really think that carefully about anything.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35bglv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would be a rational position for them to take (despite thinking it&amp;#39;s generally bad, but hey it&amp;#39;s not exactly like Meta is morally not-evil). That said, I&amp;#39;m pretty sure the 28 year old jackass who they made CEO doesn&amp;#39;t really think that carefully about anything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35bglv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752527383,"author_flair_text":null,"treatment_tags":[],"created_utc":1752527383,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n35779y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1752526178,"send_replies":true,"parent_id":"t1_n34n88d","score":4,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Supposedly Meta has been releasing weights for models to foment an open source LLM community which develops new technologies they will be able to use in-house, much as they are using other open source technologies in-house (like Linux, MySQL, PHP, Memcached, etc).\\n\\nPerhaps they believe that community is well established now, and they no longer need to release new model weights?  Technologies we develop for these other models should be readily applicable to their in-house models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35779y","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Supposedly Meta has been releasing weights for models to foment an open source LLM community which develops new technologies they will be able to use in-house, much as they are using other open source technologies in-house (like Linux, MySQL, PHP, Memcached, etc).&lt;/p&gt;\\n\\n&lt;p&gt;Perhaps they believe that community is well established now, and they no longer need to release new model weights?  Technologies we develop for these other models should be readily applicable to their in-house models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35779y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526178,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35imm2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"101m4n","can_mod_post":false,"created_utc":1752529468,"send_replies":true,"parent_id":"t1_n34n88d","score":2,"author_fullname":"t2_p7nc2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He still has the GPUs and the datasets. Those are most of the investment tbh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35imm2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He still has the GPUs and the datasets. Those are most of the investment tbh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35imm2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752529468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n34n88d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1752520501,"send_replies":true,"parent_id":"t3_1lzv16g","score":17,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So Mark invested so much money into Llama and now it will be flushed into the toilet?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34n88d","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So Mark invested so much money into Llama and now it will be flushed into the toilet?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34n88d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752520501,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-1,"removal_reason":null,"link_id":"t3_1lzv16g","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38qi1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kingwolf4","can_mod_post":false,"send_replies":true,"parent_id":"t1_n38l6xv","score":1,"author_fullname":"t2_15ciq93u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hahah lmfao","edited":false,"author_flair_css_class":null,"name":"t1_n38qi1w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hahah lmfao&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzv16g","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38qi1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752578604,"author_flair_text":null,"collapsed":false,"created_utc":1752578604,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n38l6xv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fish312","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35f37f","score":0,"author_fullname":"t2_mogjd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sure, the revolutionary new model known as GPT-2","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38l6xv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, the revolutionary new model known as GPT-2&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38l6xv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752576178,"author_flair_text":null,"treatment_tags":[],"created_utc":1752576178,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n35f37f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1752528431,"send_replies":true,"parent_id":"t1_n3565xq","score":-1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35f37f/","num_reports":null,"locked":false,"name":"t1_n35f37f","created":1752528431,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n3565xq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Limp_Classroom_2645","can_mod_post":false,"created_utc":1752525887,"send_replies":true,"parent_id":"t1_n34q7d3","score":18,"author_fullname":"t2_1lwf5vg68e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; OpenAI OS model.\\n\\nthis model is not coming, they would released it by now if they really had it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3565xq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;OpenAI OS model.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;this model is not coming, they would released it by now if they really had it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n3565xq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525887,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37x6aa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752562562,"send_replies":true,"parent_id":"t1_n34q7d3","score":2,"author_fullname":"t2_6lmlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It will not be competitive with any top OS models, especially their own. OAI doesn't want other people to eat their breakfast.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37x6aa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will not be competitive with any top OS models, especially their own. OAI doesn&amp;#39;t want other people to eat their breakfast.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n37x6aa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562562,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n34q7d3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Utoko","can_mod_post":false,"created_utc":1752521359,"send_replies":true,"parent_id":"t3_1lzv16g","score":30,"author_fullname":"t2_6a8ry","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do they want me to cheer for Chinas world dominance?\\n\\nA little bit of hope is still saved up for the OpenAI OS model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34q7d3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do they want me to cheer for Chinas world dominance?&lt;/p&gt;\\n\\n&lt;p&gt;A little bit of hope is still saved up for the OpenAI OS model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34q7d3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521359,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35envs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1752528306,"send_replies":true,"parent_id":"t1_n357qza","score":6,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes and no.\\n\\nIt is pretty well-established now that an LLM's skillset is determined by the comprehensiveness of those skills' representation in its training data, and its competence is determined by the quality of that training data and the model's parameter count.\\n\\nTrainers are thus able to pick and choose which skills a model exhibits, and each training organization has their own priorities (within limits; we know that general purpose models paradoxically make for better specialists, but not what the ideal trade-off is between generalization and skill-specific training).  IBM's Granite models, for example, have a fairly sparse skill set, and those skills are fairly specific to business applications.  The further implication is that as training datasets become increasingly exclusive of low-priority skills and subject matter, it will be up to the open source community to identify gaps in frontier models' skills and topics, amass training datasets which fill those gaps, and amend models with further training without causing catastrophic forgetting.\\n\\nHigh quality training data is still a tricky wicket.  Synthetic datasets help, and so does reward-model driven curation, but those are both very compute-intensive, and training data curation still requires the attention and labor of SMEs, who are in limited supply, in high demand, and expensive to employ.\\n\\nIt seems pretty clear that inference quality increases only logarithmically with parameter count, which hits the point of diminishing returns pretty quickly, but we are still learning new ways to make best use of a given parameter budget.  There was a recent paper, for example, demonstrating that as the ratio of training to parameters increases, parameters encoding memorized knowledge get cannibalized to encode more generalization capabilities.  That will have a profound effect on how we train and evaluate models, but I think it may take a while for the implications to seep outward to the largest players.\\n\\nThere is also still some low-hanging fruit to be plucked at the *other* end, at inference time, where we can utilize more resources to increase the effective skill sets and competence of existing models.  \\"Thinking\\" is one example of this (which does not require thinking models, but can be emulated with most models via multi-pass inference), but we can also improve inference quality by means of self-critique, self-mixing, RAG, and more sophisticated forms of Guided Generation.\\n\\nI think you are right, that there is a lot of optimization to do, too, but there is no shortage of other improvements to keep us busy.","edited":1752532569,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35envs","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and no.&lt;/p&gt;\\n\\n&lt;p&gt;It is pretty well-established now that an LLM&amp;#39;s skillset is determined by the comprehensiveness of those skills&amp;#39; representation in its training data, and its competence is determined by the quality of that training data and the model&amp;#39;s parameter count.&lt;/p&gt;\\n\\n&lt;p&gt;Trainers are thus able to pick and choose which skills a model exhibits, and each training organization has their own priorities (within limits; we know that general purpose models paradoxically make for better specialists, but not what the ideal trade-off is between generalization and skill-specific training).  IBM&amp;#39;s Granite models, for example, have a fairly sparse skill set, and those skills are fairly specific to business applications.  The further implication is that as training datasets become increasingly exclusive of low-priority skills and subject matter, it will be up to the open source community to identify gaps in frontier models&amp;#39; skills and topics, amass training datasets which fill those gaps, and amend models with further training without causing catastrophic forgetting.&lt;/p&gt;\\n\\n&lt;p&gt;High quality training data is still a tricky wicket.  Synthetic datasets help, and so does reward-model driven curation, but those are both very compute-intensive, and training data curation still requires the attention and labor of SMEs, who are in limited supply, in high demand, and expensive to employ.&lt;/p&gt;\\n\\n&lt;p&gt;It seems pretty clear that inference quality increases only logarithmically with parameter count, which hits the point of diminishing returns pretty quickly, but we are still learning new ways to make best use of a given parameter budget.  There was a recent paper, for example, demonstrating that as the ratio of training to parameters increases, parameters encoding memorized knowledge get cannibalized to encode more generalization capabilities.  That will have a profound effect on how we train and evaluate models, but I think it may take a while for the implications to seep outward to the largest players.&lt;/p&gt;\\n\\n&lt;p&gt;There is also still some low-hanging fruit to be plucked at the &lt;em&gt;other&lt;/em&gt; end, at inference time, where we can utilize more resources to increase the effective skill sets and competence of existing models.  &amp;quot;Thinking&amp;quot; is one example of this (which does not require thinking models, but can be emulated with most models via multi-pass inference), but we can also improve inference quality by means of self-critique, self-mixing, RAG, and more sophisticated forms of Guided Generation.&lt;/p&gt;\\n\\n&lt;p&gt;I think you are right, that there is a lot of optimization to do, too, but there is no shortage of other improvements to keep us busy.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35envs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752528306,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n357qza","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"evilbarron2","can_mod_post":false,"created_utc":1752526331,"send_replies":true,"parent_id":"t3_1lzv16g","score":9,"author_fullname":"t2_gr2fr79s1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anyone else get the feeling that LLM capabilities have peaked in terms of problems that can be solved by throwing more resources at them and now have to start optimizing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n357qza","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone else get the feeling that LLM capabilities have peaked in terms of problems that can be solved by throwing more resources at them and now have to start optimizing?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n357qza/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526331,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37f3kn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"randomqhacker","can_mod_post":false,"send_replies":true,"parent_id":"t1_n361rni","score":1,"author_fullname":"t2_4nw3v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, that was all ruled fair use, except they have to \\\\*buy\\\\* a lot of books!  Or \\"go to the library and read\\" in a country without copyright... ;-)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37f3kn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, that was all ruled fair use, except they have to *buy* a lot of books!  Or &amp;quot;go to the library and read&amp;quot; in a country without copyright... ;-)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n37f3kn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752553468,"author_flair_text":null,"treatment_tags":[],"created_utc":1752553468,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n361rni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"showmeufos","can_mod_post":false,"created_utc":1752535522,"send_replies":true,"parent_id":"t1_n35wud1","score":1,"author_fullname":"t2_hdcx5ggfg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You know about the trade secrets but it’s possible that this is in relation to their current inability to use copyrighted training data from lib gen etc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n361rni","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You know about the trade secrets but it’s possible that this is in relation to their current inability to use copyrighted training data from lib gen etc&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n361rni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752535522,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n35wud1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"randomqhacker","can_mod_post":false,"created_utc":1752533935,"send_replies":true,"parent_id":"t3_1lzv16g","score":3,"author_fullname":"t2_4nw3v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Of course they have to switch to closed models, how else can they use the stolen IP in the heads of their new hires?\\n\\nNah nah, I joke, OpenAI is a nonprofit, so it doesn't really matter, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35wud1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Of course they have to switch to closed models, how else can they use the stolen IP in the heads of their new hires?&lt;/p&gt;\\n\\n&lt;p&gt;Nah nah, I joke, OpenAI is a nonprofit, so it doesn&amp;#39;t really matter, right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35wud1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533935,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34pgsg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"custodiam99","can_mod_post":false,"created_utc":1752521146,"send_replies":true,"parent_id":"t3_1lzv16g","score":7,"author_fullname":"t2_nqnhgqqf5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To be honest I can only use Qwen, Gemma and rarely Phi models, so...whatever.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34pgsg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be honest I can only use Qwen, Gemma and rarely Phi models, so...whatever.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n34pgsg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521146,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35jjla","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"martinerous","can_mod_post":false,"created_utc":1752529741,"send_replies":true,"parent_id":"t3_1lzv16g","score":2,"author_fullname":"t2_5tp54ey","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If they create something great and closed, but still give us a glimpse of it in the shape of Llama 5 or whatever, then it's ok. Google's Gemini-closed / Gemma-open is a good example of how well it can actually work out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35jjla","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If they create something great and closed, but still give us a glimpse of it in the shape of Llama 5 or whatever, then it&amp;#39;s ok. Google&amp;#39;s Gemini-closed / Gemma-open is a good example of how well it can actually work out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35jjla/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752529741,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3776eu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35j09d","score":5,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Illegalize using or distributing them, or training a model on their outputs.\\n\\nMost of us won't care, and will continue using them at home on the down-low, but it would put a chilling effect on academic and commercial adoption.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3776eu","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Illegalize using or distributing them, or training a model on their outputs.&lt;/p&gt;\\n\\n&lt;p&gt;Most of us won&amp;#39;t care, and will continue using them at home on the down-low, but it would put a chilling effect on academic and commercial adoption.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n3776eu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550116,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752550116,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n35j09d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"outdoorsgeek","can_mod_post":false,"created_utc":1752529580,"send_replies":true,"parent_id":"t1_n352jtw","score":8,"author_fullname":"t2_4you5wn1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do you shut down a Chinese model?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35j09d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you shut down a Chinese model?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n35j09d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752529580,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n352jtw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Much-Contract-1397","can_mod_post":false,"created_utc":1752524874,"send_replies":true,"parent_id":"t3_1lzv16g","score":1,"author_fullname":"t2_1iqvb5w490","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The problem is as RL training compute scales up (Grok 4 suggests), there are very few labs that can keep up. I’d imagine scam Altman and closedAI will doing lots of lobbying to shut down Chinese models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n352jtw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The problem is as RL training compute scales up (Grok 4 suggests), there are very few labs that can keep up. I’d imagine scam Altman and closedAI will doing lots of lobbying to shut down Chinese models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n352jtw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752524874,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37wy3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752562439,"send_replies":true,"parent_id":"t3_1lzv16g","score":1,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I find it unlikely they'll go closed source as long as Zuck is in charge","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37wy3b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I find it unlikely they&amp;#39;ll go closed source as long as Zuck is in charge&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n37wy3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562439,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38qul3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kingwolf4","can_mod_post":false,"created_utc":1752578757,"send_replies":true,"parent_id":"t1_n381b6m","score":2,"author_fullname":"t2_15ciq93u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Their only sin was the cheating llama 4 fiasco. And maybe horrible internal management which sunk their AI ship but that's on them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38qul3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their only sin was the cheating llama 4 fiasco. And maybe horrible internal management which sunk their AI ship but that&amp;#39;s on them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzv16g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n38qul3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752578757,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n381b6m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"roselan","can_mod_post":false,"created_utc":1752564885,"send_replies":true,"parent_id":"t3_1lzv16g","score":0,"author_fullname":"t2_9akn4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mark, perhaps we treated you too harshly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n381b6m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mark, perhaps we treated you too harshly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzv16g/metas_new_superintelligence_lab_is_discussing/n381b6m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564885,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzv16g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
