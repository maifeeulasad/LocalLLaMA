import{j as e}from"./index-DOAmItP2.js";import{R as l}from"./RedditPostRenderer-KKgzpPpv.js";import"./index-YSfz60vQ.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"As title states I tried to find the way to use Jan AI with ollama available local models but I didn't found the working way.\\n\\nAfter lot of trial and error I found working way forwared and document in a blog post\\n\\n[Jan.AI with Ollama (working solution)](https://developers.knowivate.com/@kheersagar/jan-ai-with-ollama-working-solution)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Jan.AI with Ollama (working solution)","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lsoflk","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.56,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1b8utegv8t","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751762120,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;As title states I tried to find the way to use Jan AI with ollama available local models but I didn&amp;#39;t found the working way.&lt;/p&gt;\\n\\n&lt;p&gt;After lot of trial and error I found working way forwared and document in a blog post&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://developers.knowivate.com/@kheersagar/jan-ai-with-ollama-working-solution\\"&gt;Jan.AI with Ollama (working solution)&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/91QifmmkYXf4kont-M3pku_SgKmkEq-VLJGmQTJzr_I.png?auto=webp&amp;s=afb36909de3fdf0851321ac502e2cce712b98c60","width":500,"height":500},"resolutions":[{"url":"https://external-preview.redd.it/91QifmmkYXf4kont-M3pku_SgKmkEq-VLJGmQTJzr_I.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c478b3adde7eeada968ed24f96e70509dcbda47","width":108,"height":108},{"url":"https://external-preview.redd.it/91QifmmkYXf4kont-M3pku_SgKmkEq-VLJGmQTJzr_I.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=41118f6fe36315cf0dbd19388a1a22c9d4d07793","width":216,"height":216},{"url":"https://external-preview.redd.it/91QifmmkYXf4kont-M3pku_SgKmkEq-VLJGmQTJzr_I.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d6edb2be32708b5dd197c38934d1d63c949e3a9","width":320,"height":320}],"variants":{},"id":"91QifmmkYXf4kont-M3pku_SgKmkEq-VLJGmQTJzr_I"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lsoflk","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"InsideResolve4517","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/","subreddit_subscribers":494897,"created_utc":1751762120,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"fe89e94a-13f2-11f0-a9de-6262c74956cf","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"fe89e94a-13f2-11f0-a9de-6262c74956cf","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1katjb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Asleep-Ratio7535","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1k8zkx","score":2,"author_fullname":"t2_1lfyddwf0c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for explanation. I suddenly realize Jan is using gguf, while ollama's gguf isn't called gguf.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1katjb","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 4"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for explanation. I suddenly realize Jan is using gguf, while ollama&amp;#39;s gguf isn&amp;#39;t called gguf.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsoflk","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/n1katjb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751764629,"author_flair_text":"Llama 4","treatment_tags":[],"created_utc":1751764629,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#b0ae9b","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1k8zkx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Marksta","can_mod_post":false,"created_utc":1751763891,"send_replies":true,"parent_id":"t1_n1k6tyk","score":7,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The whole post is a low quality, self-promo for OP's blog. And I strongly wonder how literally the one and only correct way to do this, via the exposed OpenAI compatible API, was a trial-and-error, hard to accomplish feat for OP.\\n\\nBut all that aside, Jan.ai is its own can of worms that doesn't work like all other inference engines. You can't just point it to your $HF_HOME or whatever folder full of gguf files. They have their own format, and set folder on C-disk user %appdata%. So if someone has 1 TB of model files already downloaded and they desperately wanted to use Jan.ai as a front end, I would absolutely rather use an external inference engine than try to manually migrate model files or re-download them to get them all into Jan.ai folder structure format.\\n\\nAgain, it still begs the question of why to do literally any of this, with Ollama or Jan.ai at all.","edited":1751764072,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1k8zkx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The whole post is a low quality, self-promo for OP&amp;#39;s blog. And I strongly wonder how literally the one and only correct way to do this, via the exposed OpenAI compatible API, was a trial-and-error, hard to accomplish feat for OP.&lt;/p&gt;\\n\\n&lt;p&gt;But all that aside, Jan.ai is its own can of worms that doesn&amp;#39;t work like all other inference engines. You can&amp;#39;t just point it to your $HF_HOME or whatever folder full of gguf files. They have their own format, and set folder on C-disk user %appdata%. So if someone has 1 TB of model files already downloaded and they desperately wanted to use Jan.ai as a front end, I would absolutely rather use an external inference engine than try to manually migrate model files or re-download them to get them all into Jan.ai folder structure format.&lt;/p&gt;\\n\\n&lt;p&gt;Again, it still begs the question of why to do literally any of this, with Ollama or Jan.ai at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsoflk","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/n1k8zkx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751763891,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n1k6tyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Asleep-Ratio7535","can_mod_post":false,"created_utc":1751763020,"send_replies":true,"parent_id":"t3_1lsoflk","score":5,"author_fullname":"t2_1lfyddwf0c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why would you use another API server in an API server? That's redundant. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1k6tyk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 4"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would you use another API server in an API server? That&amp;#39;s redundant. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/n1k6tyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751763020,"author_flair_text":"Llama 4","treatment_tags":[],"link_id":"t3_1lsoflk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#b0ae9b","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1kej3o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"webitube","can_mod_post":false,"created_utc":1751766147,"send_replies":true,"parent_id":"t3_1lsoflk","score":2,"author_fullname":"t2_71eku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It looks interesting enough, but I think I'll wait till you get near the end of your current roadmap.  \\nThere isn't enough that is working yet to be really useful right now. (Maybe Q4 2025?)  \\nAlso, it would be nice to see an option to make it easy to backup and restore the databases.\\n\\nI'll stick with OpenWebUI for now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1kej3o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It looks interesting enough, but I think I&amp;#39;ll wait till you get near the end of your current roadmap.&lt;br/&gt;\\nThere isn&amp;#39;t enough that is working yet to be really useful right now. (Maybe Q4 2025?)&lt;br/&gt;\\nAlso, it would be nice to see an option to make it easy to backup and restore the databases.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll stick with OpenWebUI for now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/n1kej3o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751766147,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsoflk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1kkhjy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emprahsFury","can_mod_post":false,"created_utc":1751768586,"send_replies":false,"parent_id":"t3_1lsoflk","score":1,"author_fullname":"t2_177r8n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jan.ai consumes openai-compatible apis. Ollama has an openai-compatible api. What is the problem","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1kkhjy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan.ai consumes openai-compatible apis. Ollama has an openai-compatible api. What is the problem&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsoflk/janai_with_ollama_working_solution/n1kkhjy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751768586,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsoflk","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
