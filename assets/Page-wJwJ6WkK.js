import{j as e}from"./index-DKiEEeKK.js";import{R as l}from"./RedditPostRenderer-0BQU2Buj.js";import"./index-E74isNAL.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"So my doubt is very simple. I wish to buy a macbook and would like to locally build and train my VLM and LLM models (mini ones).  \\nWhat are my options of frameworks etc to learn and utilise to squeeze out the compute juice for this in macOS GPU cores. Any alternative to cuda? Does JAX work alright? What are my options?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"GPU Learning and Optimization on Macbook","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lnv75q","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1qhx2g5516","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751246904,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;So my doubt is very simple. I wish to buy a macbook and would like to locally build and train my VLM and LLM models (mini ones).&lt;br/&gt;\\nWhat are my options of frameworks etc to learn and utilise to squeeze out the compute juice for this in macOS GPU cores. Any alternative to cuda? Does JAX work alright? What are my options?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lnv75q","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Electronic-Guess-878","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lnv75q/gpu_learning_and_optimization_on_macbook/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lnv75q/gpu_learning_and_optimization_on_macbook/","subreddit_subscribers":492838,"created_utc":1751246904,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0i76ar","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ILoveMy2Balls","can_mod_post":false,"created_utc":1751247128,"send_replies":true,"parent_id":"t3_1lnv75q","score":2,"author_fullname":"t2_1nisx8ggay","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"mlx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0i76ar","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mlx&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnv75q/gpu_learning_and_optimization_on_macbook/n0i76ar/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751247128,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnv75q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0im0lk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Electronic-Guess-878","can_mod_post":false,"created_utc":1751252934,"send_replies":true,"parent_id":"t1_n0ii76g","score":1,"author_fullname":"t2_1qhx2g5516","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep thats the goal. to learn to write optimised kernels the way we can in cuda. does MLX offer the same flexibility?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0im0lk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep thats the goal. to learn to write optimised kernels the way we can in cuda. does MLX offer the same flexibility?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnv75q","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnv75q/gpu_learning_and_optimization_on_macbook/n0im0lk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751252934,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ii76g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"created_utc":1751251385,"send_replies":true,"parent_id":"t3_1lnv75q","score":2,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Even if you were using Nvidia GPUs, you don't need to touch CUDA for training your own models. If all you care about is building and training your models, all you need is PyTorch (or JAX if you prefer).  Quick Google searches lead to the relevant documentation pages for [PyTorch](https://developer.apple.com/metal/pytorch/) and [JAX](https://developer.apple.com/metal/jax/)).\\n\\nCreating good datasets and training models is already hard enough. Getting into writing your own compute kernels and optimizing them will make things 20x harder.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ii76g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even if you were using Nvidia GPUs, you don&amp;#39;t need to touch CUDA for training your own models. If all you care about is building and training your models, all you need is PyTorch (or JAX if you prefer).  Quick Google searches lead to the relevant documentation pages for &lt;a href=\\"https://developer.apple.com/metal/pytorch/\\"&gt;PyTorch&lt;/a&gt; and &lt;a href=\\"https://developer.apple.com/metal/jax/\\"&gt;JAX&lt;/a&gt;).&lt;/p&gt;\\n\\n&lt;p&gt;Creating good datasets and training models is already hard enough. Getting into writing your own compute kernels and optimizing them will make things 20x harder.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnv75q/gpu_learning_and_optimization_on_macbook/n0ii76g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751251385,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnv75q","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
