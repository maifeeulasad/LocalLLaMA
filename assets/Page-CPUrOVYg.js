import{j as e}from"./index-BpC9hjVs.js";import{R as l}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"OpenReasoning-Nemotron-32B is a large language model (LLM) which is a derivative of Qwen2.5-32B-Instruct (AKA the reference model). It is a reasoning model that is post-trained for reasoning about math, code and science solution generation. The model supports a context length of 64K tokens. The OpenReasoning model is available in the following sizes: 1.5B, 7B and 14B and 32B.  \\n\\n\\nThis model is ready for commercial/non-commercial research use.\\n\\n\\n\\n[https://huggingface.co/nvidia/OpenReasoning-Nemotron-32B](https://huggingface.co/nvidia/OpenReasoning-Nemotron-32B)\\n\\n[https://huggingface.co/nvidia/OpenReasoning-Nemotron-14B](https://huggingface.co/nvidia/OpenReasoning-Nemotron-14B)\\n\\n[https://huggingface.co/nvidia/OpenReasoning-Nemotron-7B](https://huggingface.co/nvidia/OpenReasoning-Nemotron-7B)\\n\\n[https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B](https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"new models from NVIDIA: OpenReasoning-Nemotron 32B/14B/7B/1.5B","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m394zh","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":"#bbbdbf","subreddit_type":"public","ups":195,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_vqgbql9w","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":195,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752861182,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenReasoning-Nemotron-32B is a large language model (LLM) which is a derivative of Qwen2.5-32B-Instruct (AKA the reference model). It is a reasoning model that is post-trained for reasoning about math, code and science solution generation. The model supports a context length of 64K tokens. The OpenReasoning model is available in the following sizes: 1.5B, 7B and 14B and 32B.  &lt;/p&gt;\\n\\n&lt;p&gt;This model is ready for commercial/non-commercial research use.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/OpenReasoning-Nemotron-32B\\"&gt;https://huggingface.co/nvidia/OpenReasoning-Nemotron-32B&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/OpenReasoning-Nemotron-14B\\"&gt;https://huggingface.co/nvidia/OpenReasoning-Nemotron-14B&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/OpenReasoning-Nemotron-7B\\"&gt;https://huggingface.co/nvidia/OpenReasoning-Nemotron-7B&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B\\"&gt;https://huggingface.co/nvidia/OpenReasoning-Nemotron-1.5B&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?auto=webp&amp;s=327b94853608fd599671fae5790b7a4511465a77","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=602376c40ecb4272ebb674f9b3e3b4d358685ba0","width":108,"height":58},{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3b803fe2d6467c44d640ddeb67a87feaabe3990","width":216,"height":116},{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d5ff7b3e45bd354ff9ce709276d44f8985f3a7e5","width":320,"height":172},{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b6f278e12de000e56d5e3cce8e3786a02ad9b607","width":640,"height":345},{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5f655ca2130e33e17e6f03eb7a79f0cbe7bffbd","width":960,"height":518},{"url":"https://external-preview.redd.it/xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=409ce4edaae946c421a769b3491851af64c77c0a","width":1080,"height":583}],"variants":{},"id":"xVaPHmDFX5vc4R__x4YuAzMSjDtirt1vFIt-J3MElOo"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1m394zh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"jacek2023","discussion_type":null,"num_comments":52,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/","subreddit_subscribers":502030,"created_utc":1752861182,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xhwzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zc5Gwu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xc09s","score":6,"author_fullname":"t2_67qrvlir","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IDK, it could be useful for some tasks where a responses can be verified easily (i.e. math, code with unit tests)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3xhwzh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IDK, it could be useful for some tasks where a responses can be verified easily (i.e. math, code with unit tests)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3xhwzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752892655,"author_flair_text":null,"treatment_tags":[],"created_utc":1752892655,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47bd0d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pedalnomica","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xc09s","score":2,"author_fullname":"t2_b0d7j6x9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's just like NVIDIA to design a niche mechanism that requires a ton of CUDA compute...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47bd0d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s just like NVIDIA to design a niche mechanism that requires a ton of CUDA compute...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n47bd0d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753034318,"author_flair_text":null,"treatment_tags":[],"created_utc":1753034318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xc09s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Midaychi","can_mod_post":false,"created_utc":1752890356,"send_replies":true,"parent_id":"t1_n3w51kx","score":4,"author_fullname":"t2_o3wnd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's just like Nvidia to design a niche mechanism that's sole purpose is to cherry pick benchmark scores","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xc09s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s just like Nvidia to design a niche mechanism that&amp;#39;s sole purpose is to cherry pick benchmark scores&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3xc09s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752890356,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3w51kx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResearchCrafty1804","can_mod_post":false,"created_utc":1752875140,"send_replies":true,"parent_id":"t3_1m394zh","score":22,"author_fullname":"t2_c705ri9b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OpenReasoning-Nemotron models can be used in a \\"heavy\\" mode by starting multiple parallel generations and combining them together via generative solution selection (GenSelect).\\n\\nWith this \\"heavy\\" GenSelect inference mode, **OpenReasoning-Nemotron-32B model surpasses O3 (High) on math and coding benchmarks.**\\n\\nhttps://preview.redd.it/xhigg7fqdpdf1.png?width=3192&amp;format=png&amp;auto=webp&amp;s=f006297c49d049e25f337b625e18479f1b5742f5","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w51kx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenReasoning-Nemotron models can be used in a &amp;quot;heavy&amp;quot; mode by starting multiple parallel generations and combining them together via generative solution selection (GenSelect).&lt;/p&gt;\\n\\n&lt;p&gt;With this &amp;quot;heavy&amp;quot; GenSelect inference mode, &lt;strong&gt;OpenReasoning-Nemotron-32B model surpasses O3 (High) on math and coding benchmarks.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/xhigg7fqdpdf1.png?width=3192&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f006297c49d049e25f337b625e18479f1b5742f5\\"&gt;https://preview.redd.it/xhigg7fqdpdf1.png?width=3192&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f006297c49d049e25f337b625e18479f1b5742f5&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3w51kx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752875140,"media_metadata":{"xhigg7fqdpdf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":52,"x":108,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4666f494931c10e3e65c80845792e9ba46d0aab4"},{"y":105,"x":216,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2cfa62787efbe6776130a609661efb35be2908"},{"y":156,"x":320,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4481056cdae3441664c882d542301afb3cdfe0b5"},{"y":313,"x":640,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8d6593a716b2d76d82664605f77e645b9028776"},{"y":470,"x":960,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9a779742e529fae87127fb4f65fa6db5dbef7749"},{"y":528,"x":1080,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2dff89fc8350ff84455401f89c319129290b9ae"}],"s":{"y":1563,"x":3192,"u":"https://preview.redd.it/xhigg7fqdpdf1.png?width=3192&amp;format=png&amp;auto=webp&amp;s=f006297c49d049e25f337b625e18479f1b5742f5"},"id":"xhigg7fqdpdf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vg59a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nivvis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vbmtm","score":1,"author_fullname":"t2_39blx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah it’s competing directly with qwen3 235b and even isn’t far off o3 in some cases (mostly @many but not always)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vg59a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it’s competing directly with qwen3 235b and even isn’t far off o3 in some cases (mostly @many but not always)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vg59a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867634,"author_flair_text":null,"treatment_tags":[],"created_utc":1752867634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3znq3c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3ykdok","score":1,"author_fullname":"t2_lpdsy","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not quite sure I understand the question.  Are you asking if there are models that distill one of OpenAI's?  Well, OpenAI certainly believes that Deekseek did for R1 :).  At the cost scales of training a huge model, using their normal API to get 10B tokens for &lt;$100k is reasonable enough.  But of course I don't think any solid evidence was presented either way.\\n\\nBeyond that, OpenAI says it's against their TOS to distill.  While that's likely unenforceable it does mean people aren't going to advertise distilling one of their models.  Nvidia could probably pay them enough to allow it, but again, R1 is free","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3znq3c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not quite sure I understand the question.  Are you asking if there are models that distill one of OpenAI&amp;#39;s?  Well, OpenAI certainly believes that Deekseek did for R1 :).  At the cost scales of training a huge model, using their normal API to get 10B tokens for &amp;lt;$100k is reasonable enough.  But of course I don&amp;#39;t think any solid evidence was presented either way.&lt;/p&gt;\\n\\n&lt;p&gt;Beyond that, OpenAI says it&amp;#39;s against their TOS to distill.  While that&amp;#39;s likely unenforceable it does mean people aren&amp;#39;t going to advertise distilling one of their models.  Nvidia could probably pay them enough to allow it, but again, R1 is free&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m394zh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3znq3c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752930538,"author_flair_text":null,"treatment_tags":[],"created_utc":1752930538,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ykdok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"logicalish","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vgzch","score":2,"author_fullname":"t2_c55rq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; pay to distill something form OpenAI\\n\\nI haven’t seen this yet - any example models you can share?","edited":false,"author_flair_css_class":null,"name":"t1_n3ykdok","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;pay to distill something form OpenAI&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I haven’t seen this yet - any example models you can share?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m394zh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3ykdok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911223,"author_flair_text":null,"collapsed":false,"created_utc":1752911223,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3yw962","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vgzch","score":1,"author_fullname":"t2_c2f558x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you source components yourself, the budget is $250 000–$300 000, heh!","edited":false,"author_flair_css_class":null,"name":"t1_n3yw962","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you source components yourself, the budget is $250 000–$300 000, heh!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m394zh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3yw962/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752917977,"author_flair_text":null,"collapsed":false,"created_utc":1752917977,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vgzch","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vct2a","score":8,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is nvidia: they have a lot of hardware, so open weights R1-0528 is awesome for them since they can just run it at scale and don't have to pay to distill something from OpenAI or whatever.  R1 is considerably better than Qwen3-235B so why would they distill that instead?\\n\\nAnd honestly?  Yeah, they're probably happy to provide some advertisement for Deepseek!  Deepseek R1 offered a massive leap in local LLM capabilities... if you bought the GPUs to run it.  What a huge win for nvidia (despite the initial bad takes): It was no longer \\"pay for tokens\\" vs \\"qwen coder on a 3090\\" it was now also \\"SOTA model on 8xH100\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vgzch","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is nvidia: they have a lot of hardware, so open weights R1-0528 is awesome for them since they can just run it at scale and don&amp;#39;t have to pay to distill something from OpenAI or whatever.  R1 is considerably better than Qwen3-235B so why would they distill that instead?&lt;/p&gt;\\n\\n&lt;p&gt;And honestly?  Yeah, they&amp;#39;re probably happy to provide some advertisement for Deepseek!  Deepseek R1 offered a massive leap in local LLM capabilities... if you bought the GPUs to run it.  What a huge win for nvidia (despite the initial bad takes): It was no longer &amp;quot;pay for tokens&amp;quot; vs &amp;quot;qwen coder on a 3090&amp;quot; it was now also &amp;quot;SOTA model on 8xH100&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vgzch/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867881,"author_flair_text":null,"treatment_tags":[],"created_utc":1752867881,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vct2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Stunning-Leather-898","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vbmtm","score":-5,"author_fullname":"t2_175dfmw94w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\--- and they do distill from DeepSeek-R1-0528, which is released after qwen3 series lol. All these things makes me really frustrated - are they just trying to advertise deepseek latest model? really?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vct2a","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;--- and they do distill from DeepSeek-R1-0528, which is released after qwen3 series lol. All these things makes me really frustrated - are they just trying to advertise deepseek latest model? really?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vct2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866634,"author_flair_text":null,"treatment_tags":[],"created_utc":1752866634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vbmtm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1752866282,"send_replies":true,"parent_id":"t1_n3uxs13","score":6,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would guess they compared to Qwen3 235B, which [is basically always better](https://qwenlm.github.io/blog/qwen3/) so sort of implies the comparison to 32B?  But that just kind of makes it even more strange...  Why show it with mixed results vs a larger model 235B when they could show it beating a equivalent one?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vbmtm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would guess they compared to Qwen3 235B, which &lt;a href=\\"https://qwenlm.github.io/blog/qwen3/\\"&gt;is basically always better&lt;/a&gt; so sort of implies the comparison to 32B?  But that just kind of makes it even more strange...  Why show it with mixed results vs a larger model 235B when they could show it beating a equivalent one?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vbmtm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866282,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47w54q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ExcitementNo5717","can_mod_post":false,"send_replies":true,"parent_id":"t1_n40pgf8","score":1,"author_fullname":"t2_h58pr95pr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I stopped downloading models : ) I'm going to use what I have for six months and then if continuous learning without Catastrophic forgetting isn't solved I'll just upgrade to the GOAT.","edited":false,"author_flair_css_class":null,"name":"t1_n47w54q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I stopped downloading models : ) I&amp;#39;m going to use what I have for six months and then if continuous learning without Catastrophic forgetting isn&amp;#39;t solved I&amp;#39;ll just upgrade to the GOAT.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m394zh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n47w54q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040763,"author_flair_text":null,"collapsed":false,"created_utc":1753040763,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n40pgf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3woltx","score":4,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; in the benchmarks\\n\\nI don't even open these anymore. If it's worth it, people will still be talking about it in a week.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n40pgf8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;in the benchmarks&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I don&amp;#39;t even open these anymore. If it&amp;#39;s worth it, people will still be talking about it in a week.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n40pgf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752942747,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752942747,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3woltx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Loighic","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vbcfg","score":27,"author_fullname":"t2_gem8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does beat Qwen 3 32b in the benchmarks, though. And by a lot.  \\nThe only one that it doesn't win by a lot is sci code, which it ties with qwen 3 32b.\\n\\nIt seems like they compared it with Qwen 3 235b because it is too far ahead of 32b.\\n\\nThe link for Qwen 3 32b scores:  \\n[https://artificialanalysis.ai/models/qwen3-32b-instruct#intelligence](https://artificialanalysis.ai/models/qwen3-32b-instruct#intelligence)\\n\\nY'all are jumping to conclusions so fast.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3woltx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does beat Qwen 3 32b in the benchmarks, though. And by a lot.&lt;br/&gt;\\nThe only one that it doesn&amp;#39;t win by a lot is sci code, which it ties with qwen 3 32b.&lt;/p&gt;\\n\\n&lt;p&gt;It seems like they compared it with Qwen 3 235b because it is too far ahead of 32b.&lt;/p&gt;\\n\\n&lt;p&gt;The link for Qwen 3 32b scores:&lt;br/&gt;\\n&lt;a href=\\"https://artificialanalysis.ai/models/qwen3-32b-instruct#intelligence\\"&gt;https://artificialanalysis.ai/models/qwen3-32b-instruct#intelligence&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Y&amp;#39;all are jumping to conclusions so fast.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3woltx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752881742,"author_flair_text":null,"treatment_tags":[],"created_utc":1752881742,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3veaju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vbcfg","score":10,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah i am getting that feeling too... if something is deliberately left out, then it's usually because it compares poorly.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3veaju","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah i am getting that feeling too... if something is deliberately left out, then it&amp;#39;s usually because it compares poorly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3veaju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867077,"author_flair_text":null,"treatment_tags":[],"created_utc":1752867077,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vr1b5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vgmtl","score":2,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good questions. What can we infer from the sizes they trained and the dataset?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vr1b5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good questions. What can we infer from the sizes they trained and the dataset?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vr1b5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752870844,"author_flair_text":null,"treatment_tags":[],"created_utc":1752870844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vgmtl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cryocari","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vbcfg","score":7,"author_fullname":"t2_c8xp0mh4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does nvidia really care about its models performance? This is just them doing research on what their hardware should do in the next iteration to make training easier, more efficient, etc.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vgmtl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does nvidia really care about its models performance? This is just them doing research on what their hardware should do in the next iteration to make training easier, more efficient, etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vgmtl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867780,"author_flair_text":null,"treatment_tags":[],"created_utc":1752867780,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vbcfg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreenHell","can_mod_post":false,"created_utc":1752866196,"send_replies":true,"parent_id":"t1_n3uxs13","score":47,"author_fullname":"t2_6518p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You know exactly why.\\n\\nIf it would beat qwen3, they would be shouting it from the rooftops.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vbcfg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You know exactly why.&lt;/p&gt;\\n\\n&lt;p&gt;If it would beat qwen3, they would be shouting it from the rooftops.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vbcfg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866196,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uxs13","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"created_utc":1752862209,"send_replies":true,"parent_id":"t3_1m394zh","score":66,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"they had the perfect chance to make an apples to apples comparsion with qwen 3 for the same size, but chose not to do it... just why? why make it harder to compare models like that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uxs13","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they had the perfect chance to make an apples to apples comparsion with qwen 3 for the same size, but chose not to do it... just why? why make it harder to compare models like that?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3uxs13/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862209,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":66}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3w4t9m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1752875066,"send_replies":true,"parent_id":"t3_1m394zh","score":13,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"GGUFs\\n\\n[https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-32B-GGUF](https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-32B-GGUF)\\n\\n[https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-14B-GGUF](https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-14B-GGUF)\\n\\n[https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-7B-GGUF](https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-7B-GGUF)\\n\\n[https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-1.5B-GGUF](https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-1.5B-GGUF)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w4t9m","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GGUFs&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-32B-GGUF\\"&gt;https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-32B-GGUF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-14B-GGUF\\"&gt;https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-14B-GGUF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-7B-GGUF\\"&gt;https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-7B-GGUF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-1.5B-GGUF\\"&gt;https://huggingface.co/gabriellarson/OpenReasoning-Nemotron-1.5B-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3w4t9m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752875066,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vjgkb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vevmw","score":8,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I didn't say anything about proving.  I said \\"testing out their hardware and software\\".  Of course this stuff works.  But if it works 10% slower than on AMD their market cap will drop by half overnight.  They need to say out on the bleeding edge and that means testing and optimizing and developing tools on real workloads and processes that their customers will experience.  Indeed, it's almost precisely _because_ these 1+1 models are boring that they're important.  This isn't some kind of research architecture that may or may not ever matter, it's what people are doing right now so it's what cuda, etc needs to be most performant for.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vjgkb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I didn&amp;#39;t say anything about proving.  I said &amp;quot;testing out their hardware and software&amp;quot;.  Of course this stuff works.  But if it works 10% slower than on AMD their market cap will drop by half overnight.  They need to say out on the bleeding edge and that means testing and optimizing and developing tools on real workloads and processes that their customers will experience.  Indeed, it&amp;#39;s almost precisely &lt;em&gt;because&lt;/em&gt; these 1+1 models are boring that they&amp;#39;re important.  This isn&amp;#39;t some kind of research architecture that may or may not ever matter, it&amp;#39;s what people are doing right now so it&amp;#39;s what cuda, etc needs to be most performant for.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vjgkb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868612,"author_flair_text":null,"treatment_tags":[],"created_utc":1752868612,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vevmw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Stunning-Leather-898","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vdivf","score":-1,"author_fullname":"t2_175dfmw94w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I really doubt that - nowadays frontier AI companies has proved their success on training large scale LLMs w/ NV devices (and yes a larger potion of them are open-source everything!) and there is no need to explain to their customers again by training these 1+1 models. Again, these 1+1 SFT has no magic inside: just start from a strong third-party base model and distill from another strong third party frontier model --- that's it. There have been so many downstream startups doing this for a long time.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vevmw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really doubt that - nowadays frontier AI companies has proved their success on training large scale LLMs w/ NV devices (and yes a larger potion of them are open-source everything!) and there is no need to explain to their customers again by training these 1+1 models. Again, these 1+1 SFT has no magic inside: just start from a strong third-party base model and distill from another strong third party frontier model --- that&amp;#39;s it. There have been so many downstream startups doing this for a long time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vevmw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867253,"author_flair_text":null,"treatment_tags":[],"created_utc":1752867253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vdivf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1752866848,"send_replies":true,"parent_id":"t1_n3v8npk","score":15,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm guessing that Nvidia is just dog-fooding.  They are testing out their hardware and software by training and evaluating models.  This sort of 1+1 is something I suspect a lot of their customers (by number, at least) care about since it's effectively a fine tuning process.  E.g. replace their R1 generated reasoning dataset with, say, a legal dataset or customer chat logs.\\n\\nUltimately, this is something they should be doing anyways to say on top of the developing technology.  The additional effort to actually release the resulting models is small compared to the advertising they get.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vdivf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m guessing that Nvidia is just dog-fooding.  They are testing out their hardware and software by training and evaluating models.  This sort of 1+1 is something I suspect a lot of their customers (by number, at least) care about since it&amp;#39;s effectively a fine tuning process.  E.g. replace their R1 generated reasoning dataset with, say, a legal dataset or customer chat logs.&lt;/p&gt;\\n\\n&lt;p&gt;Ultimately, this is something they should be doing anyways to say on top of the developing technology.  The additional effort to actually release the resulting models is small compared to the advertising they get.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vdivf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866848,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wtdwk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752883411,"send_replies":true,"parent_id":"t1_n3v8npk","score":5,"author_fullname":"t2_5oltmr5b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"imo they did a much better job with the previous iteration of nemotron (49B and 253B dense derived from llama 70B and 405B using NAS)\\n\\nwith those models they did an incredible work to develop much more advanced 'pruning' methods.\\n\\nI use nemotron ultra 253B a lot via API, I like how the model 'feel'... pretty smart, wide world knowledge and it give the feeling of a much 'lighter' alignment, while still keeping good instruction following capabilities (it doesn't give me the feedback of an 'overcooked' model). I suspect this is related to the fact that the model received just GRPO RL after SFT ~~without any DPO/PPO.~~ *edit: they did did a short run with RLOO for instruction tuning, and a final alignment \\"for helpfulness\\" but for that alignment they somehow used again GRPO for the 253B model instead of the RPO used on the smaller versions. so yes, technically they didn't use DPO/PPO but they did some alignment* \\n\\nI use it for some specific structured synthetic data generation, and it follow complex output formats without any 'json mode' or  generation constraints from the inference provider, just prompting.\\n\\nI started to use this model because a relevant percentage of those data are generated in Italian, and llama 3.1 405 was on of the best open weights model when it came to Italian, but it is a bit outdated now. still, much recent (and better) model like deepseek, llama 4 or qwen 3 feel much less natural when writing in Italian. llama 405 is still better on that aspect, but it is factually less smart.\\n\\nI mean... nvidia managed to cut down the parameters count by ~45%, \\"refresh\\" the model, add reasoning (optional), improve long context performance, and retain a capabilities (the fluency in Italian) that is something quite specific, and I initially thought that something like that would be one of the first things that would be lost with such aggressive parameters reduction, but I was happily surprised.\\n\\nstill, this is probably the bigger open model in terms of active parameters that was trained with reasoning.\\n\\n\\nthe 49B version is interesting but it didn't impress me so much, but still in many occasions while testing it I found its output better than llama4 models.\\n\\nthey also releasen an 8B version with just their post trading (not derived from a bigger model), but I have not tested it.\\n\\n\\nI have not tested those new 'openreasonin nemotron' models, I'll give them a try (even if I don't see so good opinions about it), even if they are not in the parameter range I target for my use case. \\n\\nbtw their paper about the neural architecture search and FFN fusion used on those model models is quite interesting Imo.\\nI suspect they did their 'magic' at this leven (+ the additional pretraining) rather than on the final post training\\n\\nedited an error... \\nhere the papers: https://arxiv.org/pdf/2505.00949 (models tech report) and https://arxiv.org/abs/2411.19146, (NAS) https://arxiv.org/abs/2503.18908 (FFN fusion)","edited":1752885704,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wtdwk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;imo they did a much better job with the previous iteration of nemotron (49B and 253B dense derived from llama 70B and 405B using NAS)&lt;/p&gt;\\n\\n&lt;p&gt;with those models they did an incredible work to develop much more advanced &amp;#39;pruning&amp;#39; methods.&lt;/p&gt;\\n\\n&lt;p&gt;I use nemotron ultra 253B a lot via API, I like how the model &amp;#39;feel&amp;#39;... pretty smart, wide world knowledge and it give the feeling of a much &amp;#39;lighter&amp;#39; alignment, while still keeping good instruction following capabilities (it doesn&amp;#39;t give me the feedback of an &amp;#39;overcooked&amp;#39; model). I suspect this is related to the fact that the model received just GRPO RL after SFT &lt;del&gt;without any DPO/PPO.&lt;/del&gt; &lt;em&gt;edit: they did did a short run with RLOO for instruction tuning, and a final alignment &amp;quot;for helpfulness&amp;quot; but for that alignment they somehow used again GRPO for the 253B model instead of the RPO used on the smaller versions. so yes, technically they didn&amp;#39;t use DPO/PPO but they did some alignment&lt;/em&gt; &lt;/p&gt;\\n\\n&lt;p&gt;I use it for some specific structured synthetic data generation, and it follow complex output formats without any &amp;#39;json mode&amp;#39; or  generation constraints from the inference provider, just prompting.&lt;/p&gt;\\n\\n&lt;p&gt;I started to use this model because a relevant percentage of those data are generated in Italian, and llama 3.1 405 was on of the best open weights model when it came to Italian, but it is a bit outdated now. still, much recent (and better) model like deepseek, llama 4 or qwen 3 feel much less natural when writing in Italian. llama 405 is still better on that aspect, but it is factually less smart.&lt;/p&gt;\\n\\n&lt;p&gt;I mean... nvidia managed to cut down the parameters count by ~45%, &amp;quot;refresh&amp;quot; the model, add reasoning (optional), improve long context performance, and retain a capabilities (the fluency in Italian) that is something quite specific, and I initially thought that something like that would be one of the first things that would be lost with such aggressive parameters reduction, but I was happily surprised.&lt;/p&gt;\\n\\n&lt;p&gt;still, this is probably the bigger open model in terms of active parameters that was trained with reasoning.&lt;/p&gt;\\n\\n&lt;p&gt;the 49B version is interesting but it didn&amp;#39;t impress me so much, but still in many occasions while testing it I found its output better than llama4 models.&lt;/p&gt;\\n\\n&lt;p&gt;they also releasen an 8B version with just their post trading (not derived from a bigger model), but I have not tested it.&lt;/p&gt;\\n\\n&lt;p&gt;I have not tested those new &amp;#39;openreasonin nemotron&amp;#39; models, I&amp;#39;ll give them a try (even if I don&amp;#39;t see so good opinions about it), even if they are not in the parameter range I target for my use case. &lt;/p&gt;\\n\\n&lt;p&gt;btw their paper about the neural architecture search and FFN fusion used on those model models is quite interesting Imo.\\nI suspect they did their &amp;#39;magic&amp;#39; at this leven (+ the additional pretraining) rather than on the final post training&lt;/p&gt;\\n\\n&lt;p&gt;edited an error... \\nhere the papers: &lt;a href=\\"https://arxiv.org/pdf/2505.00949\\"&gt;https://arxiv.org/pdf/2505.00949&lt;/a&gt; (models tech report) and &lt;a href=\\"https://arxiv.org/abs/2411.19146\\"&gt;https://arxiv.org/abs/2411.19146&lt;/a&gt;, (NAS) &lt;a href=\\"https://arxiv.org/abs/2503.18908\\"&gt;https://arxiv.org/abs/2503.18908&lt;/a&gt; (FFN fusion)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3wtdwk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752883411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v8npk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Stunning-Leather-898","can_mod_post":false,"created_utc":1752865393,"send_replies":true,"parent_id":"t3_1m394zh","score":10,"author_fullname":"t2_175dfmw94w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"tbh what's the point of releasing such 1+1 distill models by consuming soo much computation &amp; data scale cost? deepseek release their qwen distill model to show the superiority of their frontier models, and qwen release their distill model for advertising their brand.... I mean, why NV would like to do such 1+1 things where both \\"1\\" comes from other companies?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v8npk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;tbh what&amp;#39;s the point of releasing such 1+1 distill models by consuming soo much computation &amp;amp; data scale cost? deepseek release their qwen distill model to show the superiority of their frontier models, and qwen release their distill model for advertising their brand.... I mean, why NV would like to do such 1+1 things where both &amp;quot;1&amp;quot; comes from other companies?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3v8npk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865393,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n401crz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ResearchCrafty1804","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yk8hb","score":2,"author_fullname":"t2_c705ri9b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, they are, although, they are not performing as good as closed models like Sonnet 4 in agentic tools like cline, so there is still a lot of room for improvement","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n401crz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, they are, although, they are not performing as good as closed models like Sonnet 4 in agentic tools like cline, so there is still a lot of room for improvement&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n401crz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752935229,"author_flair_text":null,"treatment_tags":[],"created_utc":1752935229,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yk8hb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1752911142,"send_replies":true,"parent_id":"t1_n3vh0wj","score":2,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Isn't devstral small, DeepSWE-Preview, Kimi 72B Dev and Skywork 32B exactly that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yk8hb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t devstral small, DeepSWE-Preview, Kimi 72B Dev and Skywork 32B exactly that?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3yk8hb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911142,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vh0wj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResearchCrafty1804","can_mod_post":false,"created_utc":1752867894,"send_replies":true,"parent_id":"t3_1m394zh","score":6,"author_fullname":"t2_c705ri9b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We need small coding models trained for agentic use, perhaps distilled from Moonshot Kimi-K2. This is the gap, good small reasoners have been released already  (e.g. Qwen3-32b). \\n\\nSmall coding/agentinc focused models are missing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vh0wj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need small coding models trained for agentic use, perhaps distilled from Moonshot Kimi-K2. This is the gap, good small reasoners have been released already  (e.g. Qwen3-32b). &lt;/p&gt;\\n\\n&lt;p&gt;Small coding/agentinc focused models are missing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vh0wj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867894,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x7na9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bs6","can_mod_post":false,"created_utc":1752888700,"send_replies":true,"parent_id":"t3_1m394zh","score":4,"author_fullname":"t2_9mcdn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Damn somebody this morning on another thread was asking why we haven’t seen a nemotron update yet. Ask and ye shall inference locally","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x7na9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn somebody this morning on another thread was asking why we haven’t seen a nemotron update yet. Ask and ye shall inference locally&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3x7na9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888700,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48azn0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tango-Down766","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vd7ki","score":1,"author_fullname":"t2_1swzxdrzcr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"doesn't work","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n48azn0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;doesn&amp;#39;t work&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n48azn0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045351,"author_flair_text":null,"treatment_tags":[],"created_utc":1753045351,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vd7ki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"triynizzles1","can_mod_post":false,"created_utc":1752866755,"send_replies":true,"parent_id":"t1_n3uvhs8","score":5,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe build.nvida.com in a day or two.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vd7ki","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe build.nvida.com in a day or two.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vd7ki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866755,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uvhs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celsowm","can_mod_post":false,"created_utc":1752861548,"send_replies":true,"parent_id":"t3_1m394zh","score":3,"author_fullname":"t2_dyvrh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is there any place to test them online?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uvhs8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there any place to test them online?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3uvhs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752861548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x7bo3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nivvis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wjlt9","score":2,"author_fullname":"t2_39blx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1000x agreed. qwq was / is seriously amazing. I don’t get that sense .. the consistent convergence.. in any of the qwen3 series models. Though qwen3 14b has been decent.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3x7bo3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1000x agreed. qwq was / is seriously amazing. I don’t get that sense .. the consistent convergence.. in any of the qwen3 series models. Though qwen3 14b has been decent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3x7bo3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888577,"author_flair_text":null,"treatment_tags":[],"created_utc":1752888577,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wjlt9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iory1998","can_mod_post":false,"created_utc":1752880047,"send_replies":true,"parent_id":"t1_n3vgfd4","score":8,"author_fullname":"t2_byt5wa14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I said it before, and I say it now. If the QWQ-32B release didn't coincide with the release of R1, it would have been the biggest AI news for weeks. That model is a beast punching way above its weight.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wjlt9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I said it before, and I say it now. If the QWQ-32B release didn&amp;#39;t coincide with the release of R1, it would have been the biggest AI news for weeks. That model is a beast punching way above its weight.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3wjlt9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752880047,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vgfd4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nivvis","can_mod_post":false,"created_utc":1752867718,"send_replies":true,"parent_id":"t3_1m394zh","score":3,"author_fullname":"t2_39blx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With Nvidia sticking to Qwen 2.5 for these models, R2 not coming out imminently after Qwen3 .. and my own poor experience with Qwen3 .. starting to wonder if it’s not just me.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vgfd4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With Nvidia sticking to Qwen 2.5 for these models, R2 not coming out imminently after Qwen3 .. and my own poor experience with Qwen3 .. starting to wonder if it’s not just me.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vgfd4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867718,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3v6w3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gunkanreddit","can_mod_post":false,"created_utc":1752864877,"send_replies":true,"parent_id":"t1_n3uzet4","score":6,"author_fullname":"t2_e8pd0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think it's quite fair. You only need to give them atribution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v6w3d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it&amp;#39;s quite fair. You only need to give them atribution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3v6w3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752864877,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uzet4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArtisticHamster","can_mod_post":false,"created_utc":1752862688,"send_replies":true,"parent_id":"t3_1m394zh","score":2,"author_fullname":"t2_2t2xbyfm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why did they choose CC-BY-4.0?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uzet4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why did they choose CC-BY-4.0?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3uzet4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862688,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vm0by","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1752869368,"send_replies":true,"parent_id":"t3_1m394zh","score":2,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think this can be applied to qwen3, nemotron is basically a reasoning fine-tuning, yo can apply it to any model. That's why it's called \\"OpenReasoning\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vm0by","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this can be applied to qwen3, nemotron is basically a reasoning fine-tuning, yo can apply it to any model. That&amp;#39;s why it&amp;#39;s called &amp;quot;OpenReasoning&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vm0by/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752869368,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wj3du","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Iory1998","can_mod_post":false,"created_utc":1752879873,"send_replies":true,"parent_id":"t3_1m394zh","score":2,"author_fullname":"t2_byt5wa14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it weren't Nvidia fine-tuning the models, I wouldn't believe the benchmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wj3du","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it weren&amp;#39;t Nvidia fine-tuning the models, I wouldn&amp;#39;t believe the benchmarks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3wj3du/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752879873,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3yke0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1752911228,"send_replies":true,"parent_id":"t1_n3x8aiz","score":5,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3 32B and 235B base models were never released by Qwen team.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yke0x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 32B and 235B base models were never released by Qwen team.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3yke0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911228,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3x8aiz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Daemontatox","can_mod_post":false,"created_utc":1752888947,"send_replies":true,"parent_id":"t3_1m394zh","score":1,"author_fullname":"t2_1rm9syq1nb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why are most new finetunes of qwen2, not qwen3?\\n\\nDoes the selective thinking affect the training process to that extent?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x8aiz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why are most new finetunes of qwen2, not qwen3?&lt;/p&gt;\\n\\n&lt;p&gt;Does the selective thinking affect the training process to that extent?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3x8aiz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888947,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3y46rf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1752902487,"send_replies":true,"parent_id":"t3_1m394zh","score":1,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lame. Back to custom licenses that take away original license rights","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y46rf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lame. Back to custom licenses that take away original license rights&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3y46rf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752902487,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3y8av6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Guilty-History-9249","can_mod_post":false,"created_utc":1752904604,"send_replies":true,"parent_id":"t3_1m394zh","score":1,"author_fullname":"t2_rxk6hx4t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Perfect for the dual 5090, threadripper 7985WX with 256 GB's of ram that was just delivered to me today.  Really.  I'm ready to rock and roll!!!  After I copy all my stuff and models from my old single 4090 system sitting next to it.  Nothing like waiting for a recursive scp of several terabytes to finish.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y8av6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Perfect for the dual 5090, threadripper 7985WX with 256 GB&amp;#39;s of ram that was just delivered to me today.  Really.  I&amp;#39;m ready to rock and roll!!!  After I copy all my stuff and models from my old single 4090 system sitting next to it.  Nothing like waiting for a recursive scp of several terabytes to finish.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3y8av6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752904604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n471vla","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"slypheed","can_mod_post":false,"created_utc":1753031557,"send_replies":true,"parent_id":"t3_1m394zh","score":1,"author_fullname":"t2_1j3pi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really want to like this, but it's just absolute garbage in lm studio (chat) with mcp enabled and default model settings (mac m4).\\n\\nIt pretty much can't do anything and repeats itself with garbage output until it has to be hard-stopped.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n471vla","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really want to like this, but it&amp;#39;s just absolute garbage in lm studio (chat) with mcp enabled and default model settings (mac m4).&lt;/p&gt;\\n\\n&lt;p&gt;It pretty much can&amp;#39;t do anything and repeats itself with garbage output until it has to be hard-stopped.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n471vla/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n44ppni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3v0m7r","score":1,"author_fullname":"t2_vqgbql9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"this guy here is testing 7B with vllm (so unquantized)\\n\\n[https://youtu.be/D0PqUCa4KMQ?si=FyYbDN6\\\\_i6IifZ59](https://youtu.be/D0PqUCa4KMQ?si=FyYbDN6_i6IifZ59)\\n\\nat one point he said that model was thinking for 10 minutes but the answer was correct\\n\\nprobably he is u/Lopsided_Dot_4557","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n44ppni","is_submitter":true,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this guy here is testing 7B with vllm (so unquantized)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://youtu.be/D0PqUCa4KMQ?si=FyYbDN6_i6IifZ59\\"&gt;https://youtu.be/D0PqUCa4KMQ?si=FyYbDN6_i6IifZ59&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;at one point he said that model was thinking for 10 minutes but the answer was correct&lt;/p&gt;\\n\\n&lt;p&gt;probably he is &lt;a href=\\"/u/Lopsided_Dot_4557\\"&gt;u/Lopsided_Dot_4557&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n44ppni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752997069,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752997069,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vi8p0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Professional-Bear857","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3v4uh1","score":1,"author_fullname":"t2_yrl9ztfsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think its a template or jinja issue potentially, for some reason it just doesn't handle the think tag properly, and gets stuck in a thinking loop without answering.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vi8p0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think its a template or jinja issue potentially, for some reason it just doesn&amp;#39;t handle the think tag properly, and gets stuck in a thinking loop without answering.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3vi8p0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868252,"author_flair_text":null,"treatment_tags":[],"created_utc":1752868252,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v4uh1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3v0m7r","score":1,"author_fullname":"t2_vqgbql9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe it's a good idea to compare it with the unquantized version? It would be strange if both OpenCodeReasoning 1.1 and OpenReasoning had the same issue","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3v4uh1","is_submitter":true,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe it&amp;#39;s a good idea to compare it with the unquantized version? It would be strange if both OpenCodeReasoning 1.1 and OpenReasoning had the same issue&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3v4uh1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752864283,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752864283,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v0m7r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Professional-Bear857","can_mod_post":false,"created_utc":1752863042,"send_replies":true,"parent_id":"t1_n3uwua6","score":6,"author_fullname":"t2_yrl9ztfsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've tested it, its not a very good model, has the same issue as the 1.1 version did with the thinking tags not working properly. Acereason nemotron 14b is a better model I think.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v0m7r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tested it, its not a very good model, has the same issue as the 1.1 version did with the thinking tags not working properly. Acereason nemotron 14b is a better model I think.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3v0m7r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752863042,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uwua6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Professional-Bear857","can_mod_post":false,"created_utc":1752861937,"send_replies":true,"parent_id":"t3_1m394zh","score":1,"author_fullname":"t2_yrl9ztfsa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here is a quant of the 14b model:\\n\\n[https://huggingface.co/sm54/OpenReasoning-Nemotron-14B-Q6\\\\_K-GGUF](https://huggingface.co/sm54/OpenReasoning-Nemotron-14B-Q6_K-GGUF)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uwua6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here is a quant of the 14b model:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/sm54/OpenReasoning-Nemotron-14B-Q6_K-GGUF\\"&gt;https://huggingface.co/sm54/OpenReasoning-Nemotron-14B-Q6_K-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n3uwua6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752861937,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"body":"I just tested 32B Q8 on heavy reasoning task. And it performed magnificently. It is first nVidia model that passed my test, and the only 32B that did it with Q8. \\n\\nThe task was heavy reasoning one - evaluate vendor quality manual against 18 mandatory requirements. 34k ctx. Took over 1hr to complete the task, but the result is better than QwQ or Qwen3. Among few local models that successfully performed it.\\n\\nI will test it further, though I will probably wait for f16.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Win11 Pro, LM Studio - Open Reasoning Nemotron 32B Q8\\n\\n\\\\* ctx 27k\\n\\n\\\\* Input token count:17009 - Context is 76.5% full\\n\\n\\\\* 17min thinking\\n\\n\\\\* 2.15 tok/sec • 5536 tokens • 0.86s to first token • Stop reason: EOS Token Found\\n\\nWith speculative decoding:  \\n\\\\* 2.65 tok/sec • 8815 tokens • 164.57s to first token • Stop reason: EOS Token Found • Accepted 4163/8815 draft tokens (47.2%)  \\n  \\nI will switch later to Llamacpp on Linux","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46kob4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dodo13333","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45g9cv","score":1,"author_fullname":"t2_fxyo2uvcw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46kob4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Win11 Pro, LM Studio - Open Reasoning Nemotron 32B Q8&lt;/p&gt;\\n\\n&lt;p&gt;* ctx 27k&lt;/p&gt;\\n\\n&lt;p&gt;* Input token count:17009 - Context is 76.5% full&lt;/p&gt;\\n\\n&lt;p&gt;* 17min thinking&lt;/p&gt;\\n\\n&lt;p&gt;* 2.15 tok/sec • 5536 tokens • 0.86s to first token • Stop reason: EOS Token Found&lt;/p&gt;\\n\\n&lt;p&gt;With speculative decoding:&lt;br/&gt;\\n* 2.65 tok/sec • 8815 tokens • 164.57s to first token • Stop reason: EOS Token Found • Accepted 4163/8815 draft tokens (47.2%)  &lt;/p&gt;\\n\\n&lt;p&gt;I will switch later to Llamacpp on Linux&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n46kob4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753026383,"author_flair_text":null,"treatment_tags":[],"created_utc":1753026383,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n45g9cv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1753012006,"send_replies":true,"parent_id":"t1_n45dx1t","score":2,"author_fullname":"t2_vqgbql9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1 hour task for one prompt? Then what was the number of tokens?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45g9cv","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1 hour task for one prompt? Then what was the number of tokens?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m394zh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n45g9cv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753012006,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n45dx1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dodo13333","can_mod_post":false,"created_utc":1753010862,"send_replies":true,"parent_id":"t3_1m394zh","score":0,"author_fullname":"t2_fxyo2uvcw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45dx1t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just tested 32B Q8 on heavy reasoning task. And it performed magnificently. It is first nVidia model that passed my test, and the only 32B that did it with Q8. &lt;/p&gt;\\n\\n&lt;p&gt;The task was heavy reasoning one - evaluate vendor quality manual against 18 mandatory requirements. 34k ctx. Took over 1hr to complete the task, but the result is better than QwQ or Qwen3. Among few local models that successfully performed it.&lt;/p&gt;\\n\\n&lt;p&gt;I will test it further, though I will probably wait for f16.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m394zh/new_models_from_nvidia_openreasoningnemotron/n45dx1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753010862,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m394zh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
