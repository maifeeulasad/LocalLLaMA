import{j as e}from"./index-BxgxThME.js";import{R as l}from"./RedditPostRenderer-BL_SOtuv.js";import"./index--Az3yIKM.js";const t=[{kind:"Listing",data:{after:null,dist:1,modhash:"",geo_filter:"",children:[{kind:"t3",data:{approved_at_utc:null,subreddit:"LocalLLaMA",selftext:"Hey there all. I know benchmarks exist, but they're too clunky for screen readers (I'm blind). So is there some sort of active blog or website or mailing list that cuts through all that rainfall of models and actually tells us which ones are the best based on size and specialty? Thanks.",user_reports:[],saved:!1,mod_reason_title:null,gilded:0,clicked:!1,title:"Simple textual lists for llm rankings",link_flair_richtext:[{e:"text",t:"Question | Help"}],subreddit_name_prefixed:"r/LocalLLaMA",hidden:!1,pwls:6,link_flair_css_class:"",downs:0,thumbnail_height:null,top_awarded_type:null,hide_score:!1,name:"t3_1lntw6i",quarantine:!1,link_flair_text_color:"dark",upvote_ratio:.75,author_flair_background_color:null,subreddit_type:"public",ups:2,total_awards_received:0,media_embed:{},thumbnail_width:null,author_flair_template_id:null,is_original_content:!1,author_fullname:"t2_9xer9y5w",secure_media:null,is_reddit_media_domain:!1,is_meta:!1,category:null,secure_media_embed:{},link_flair_text:"Question | Help",can_mod_post:!1,score:2,approved_by:null,is_created_from_ads_ui:!1,author_premium:!1,thumbnail:"self",edited:!1,author_flair_css_class:null,author_flair_richtext:[],gildings:{},content_categories:null,is_self:!0,mod_note:null,created:1751242921,link_flair_type:"richtext",wls:6,removed_by_category:null,banned_by:null,author_flair_type:"text",domain:"self.LocalLLaMA",allow_live_comments:!1,selftext_html:`&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey there all. I know benchmarks exist, but they&amp;#39;re too clunky for screen readers (I&amp;#39;m blind). So is there some sort of active blog or website or mailing list that cuts through all that rainfall of models and actually tells us which ones are the best based on size and specialty? Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;`,likes:null,suggested_sort:null,banned_at_utc:null,view_count:null,archived:!1,no_follow:!1,is_crosspostable:!1,pinned:!1,over_18:!1,all_awardings:[],awarders:[],media_only:!1,link_flair_template_id:"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",can_gild:!1,spoiler:!1,locked:!1,author_flair_text:null,treatment_tags:[],visited:!1,removed_by:null,num_reports:null,distinguished:null,subreddit_id:"t5_81eyvm",author_is_blocked:!1,mod_reason_by:null,removal_reason:null,link_flair_background_color:"#5a74cc",id:"1lntw6i",is_robot_indexable:!0,num_duplicates:0,report_reasons:null,author:"Silver-Champion-4846",discussion_type:null,num_comments:1,send_replies:!0,media:null,contest_mode:!1,author_patreon_flair:!1,author_flair_text_color:null,permalink:"/r/LocalLLaMA/comments/1lntw6i/simple_textual_lists_for_llm_rankings/",stickied:!1,url:"https://www.reddit.com/r/LocalLLaMA/comments/1lntw6i/simple_textual_lists_for_llm_rankings/",subreddit_subscribers:493240,created_utc:1751242921,num_crossposts:0,mod_reports:[],is_video:!1}}],before:null}},{kind:"Listing",data:{after:null,dist:null,modhash:"",geo_filter:"",children:[{kind:"t1",data:{subreddit_id:"t5_81eyvm",approved_at_utc:null,author_is_blocked:!1,comment_type:null,awarders:[],mod_reason_by:null,banned_by:null,author_flair_type:"text",total_awards_received:0,subreddit:"LocalLLaMA",author_flair_template_id:null,likes:null,replies:"",user_reports:[],saved:!1,id:"n0j589n",banned_at_utc:null,mod_reason_title:null,gilded:0,archived:!1,collapsed_reason_code:null,no_follow:!0,author:"ArsNeph",can_mod_post:!1,created_utc:1751261945,send_replies:!0,parent_id:"t3_1lntw6i",score:3,author_fullname:"t2_vt0xkv60d",approved_by:null,mod_note:null,all_awardings:[],collapsed:!1,body:`I'm sorry to hear about your difficulty, I don't know of any easy website for that, as most data is displayed in graphs, and even when it's not, it's often in tables. I think a good idea to screenshot your entire screen, then use a frontier model like ChatGPT/Claude/Gemini to perform OCR, then use a screen reader on that text. Unfortunately, LLM benchmarks don't reflect reality perfectly well either, so real world testing for your use case is generally the best.

If you'd like, you can tell me the amount of VRAM you have and your use cases, and I can recommend the best models for each use case as of right now`,edited:!1,top_awarded_type:null,author_flair_css_class:null,name:"t1_n0j589n",is_submitter:!1,downs:0,author_flair_richtext:[],author_patreon_flair:!1,body_html:`&lt;div class="md"&gt;&lt;p&gt;I&amp;#39;m sorry to hear about your difficulty, I don&amp;#39;t know of any easy website for that, as most data is displayed in graphs, and even when it&amp;#39;s not, it&amp;#39;s often in tables. I think a good idea to screenshot your entire screen, then use a frontier model like ChatGPT/Claude/Gemini to perform OCR, then use a screen reader on that text. Unfortunately, LLM benchmarks don&amp;#39;t reflect reality perfectly well either, so real world testing for your use case is generally the best.&lt;/p&gt;

&lt;p&gt;If you&amp;#39;d like, you can tell me the amount of VRAM you have and your use cases, and I can recommend the best models for each use case as of right now&lt;/p&gt;
&lt;/div&gt;`,removal_reason:null,collapsed_reason:null,distinguished:null,associated_award:null,stickied:!1,author_premium:!1,can_gild:!1,gildings:{},unrepliable_reason:null,author_flair_text_color:null,score_hidden:!1,permalink:"/r/LocalLLaMA/comments/1lntw6i/simple_textual_lists_for_llm_rankings/n0j589n/",subreddit_type:"public",locked:!1,report_reasons:null,created:1751261945,author_flair_text:null,treatment_tags:[],link_id:"t3_1lntw6i",subreddit_name_prefixed:"r/LocalLLaMA",controversiality:0,depth:0,author_flair_background_color:null,collapsed_because_crowd_control:null,mod_reports:[],num_reports:null,ups:3}}],before:null}}],n=()=>e.jsx(l,{data:t});export{n as default};
