import{j as e}from"./index-Bu7qcPAU.js";import{R as t}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"&gt; **Framework overview:**\\n&gt; LLMs iteratively refine their own outputs—typically through a three‑phase cycle **draft → critique → revision**, repeat until convergence (all phases &amp; stop rules are configurable).\\n&gt; I started coding three weeks ago after an eight‑year break and zero professional dev experience.\\n\\n---\\n\\n**The classes work as Python callables with built in observability: instances are callable -**\\n\\n```Python,tabs=4\\nfrom recursive_companion.base import MarketingCompanion\\nagent  = MarketingCompanion()\\nanswer = agent(\\"question or problem…\\") # final refined output\\nprint(answer)\\nprint(agent.run_log)  # list[dict] of every draft, critique &amp; revision\\n```\\n\\n---\\n\\n**Why it stays clean &amp; modular**\\n\\n* Templates are plain text files (system prompts, user prompts, protocol).\\n  *Swap harsh critiques for creative ones by swapping files.*\\n* `build_templates()` lets you compose any combination.\\n* **Protocol injection** cleanly separates reasoning patterns from implementation.\\n* New agents in **3 lines**—just inherit from `BaseCompanion`.\\n* Convergence uses **embedding‑based cosine similarity** by default, but the metric is fully pluggable.\\n\\n---\\n\\n**How it came together**\\n\\nThe design emerged from recursive dialogues with multiple LLMs—the same iterative process the framework now automates.\\nNo legacy assumptions meant every piece became independent: swap models, add phases, change convergence logic—no rewiring required.\\n\\n---\\n\\n**Extras**\\n\\n* **Streamlit app** shows the thinking live as it happens.\\n* Demos cover raw orchestration *and* LangGraph integration (agents as graph nodes).\\n* Full architecture docs, comprehensive docstrings, commenting, and worked examples included.\\n\\n---\\n\\n**Repo (MIT)**\\n[https://github.com/hankbesser/recursive-companion](https://github.com/hankbesser/recursive-companion)\\n\\n---\\n\\n*Built by questioning everything. Learning by building, built for learning.*\\n\\n---\\n\\nThanks for reading and really looking for any feedback and open to contributors, no question or discussion is too big or small.\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"A Meta-Framework for Self-Improving LLMs with Transparent Reasoning","link_flair_richtext":[{"e":"text","t":"Generation"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1lokkpc","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.9,"author_flair_background_color":null,"ups":37,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1slbug571z","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Generation","can_mod_post":false,"score":37,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=33bbb1787e47e133d380d2b30df73bb6ae1c0556","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751320774,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;&lt;strong&gt;Framework overview:&lt;/strong&gt;\\nLLMs iteratively refine their own outputs—typically through a three‑phase cycle &lt;strong&gt;draft → critique → revision&lt;/strong&gt;, repeat until convergence (all phases &amp;amp; stop rules are configurable).\\nI started coding three weeks ago after an eight‑year break and zero professional dev experience.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;The classes work as Python callables with built in observability: instances are callable -&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;Python,tabs=4\\nfrom recursive_companion.base import MarketingCompanion\\nagent  = MarketingCompanion()\\nanswer = agent(&amp;quot;question or problem…&amp;quot;) # final refined output\\nprint(answer)\\nprint(agent.run_log)  # list[dict] of every draft, critique &amp;amp; revision\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Why it stays clean &amp;amp; modular&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Templates are plain text files (system prompts, user prompts, protocol).\\n&lt;em&gt;Swap harsh critiques for creative ones by swapping files.&lt;/em&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;code&gt;build_templates()&lt;/code&gt; lets you compose any combination.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Protocol injection&lt;/strong&gt; cleanly separates reasoning patterns from implementation.&lt;/li&gt;\\n&lt;li&gt;New agents in &lt;strong&gt;3 lines&lt;/strong&gt;—just inherit from &lt;code&gt;BaseCompanion&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Convergence uses &lt;strong&gt;embedding‑based cosine similarity&lt;/strong&gt; by default, but the metric is fully pluggable.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;How it came together&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The design emerged from recursive dialogues with multiple LLMs—the same iterative process the framework now automates.\\nNo legacy assumptions meant every piece became independent: swap models, add phases, change convergence logic—no rewiring required.&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Extras&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Streamlit app&lt;/strong&gt; shows the thinking live as it happens.&lt;/li&gt;\\n&lt;li&gt;Demos cover raw orchestration &lt;em&gt;and&lt;/em&gt; LangGraph integration (agents as graph nodes).&lt;/li&gt;\\n&lt;li&gt;Full architecture docs, comprehensive docstrings, commenting, and worked examples included.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Repo (MIT)&lt;/strong&gt;\\n&lt;a href=\\"https://github.com/hankbesser/recursive-companion\\"&gt;https://github.com/hankbesser/recursive-companion&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;em&gt;Built by questioning everything. Learning by building, built for learning.&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;Thanks for reading and really looking for any feedback and open to contributors, no question or discussion is too big or small.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/hankbesser/recursive-companion","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?auto=webp&amp;s=6d9fb848747823d616ada6934931a9ab13686405","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=52a2ae0c9fa3d46658f5ea203ca1a627fe7ed435","width":108,"height":54},{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0376f4d7b6a226eeda9b10786c7f32bbf9e40623","width":216,"height":108},{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8d5b1c1419d8eea70ba8d4899a12d2e9df4f36b","width":320,"height":160},{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31f4c15b33f9e40cd80aee5e1468225b045437e8","width":640,"height":320},{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=da522be8df3ab16530b6694571c74fae9016c804","width":960,"height":480},{"url":"https://external-preview.redd.it/GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32aea4dba2c99f5e33afa82803940e3ee4a9eb0e","width":1080,"height":540}],"variants":{},"id":"GF7LOLNV1EkT3j_WQj3wN6pKRBc62ktaNGoxeqmHjug"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"23bddba8-ff56-11ed-9688-1a11994b71f7","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#b5a3d0","id":"1lokkpc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"henryb213","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/","stickied":false,"url":"https://github.com/hankbesser/recursive-companion","subreddit_subscribers":493242,"created_utc":1751320774,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0nuk4t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henryb213","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nswlf","score":3,"author_fullname":"t2_1slbug571z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"there are example outputs in the notebooks in the demos folder. but you are right!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nuk4t","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;there are example outputs in the notebooks in the demos folder. but you are right!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nuk4t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751323877,"author_flair_text":null,"treatment_tags":[],"created_utc":1751323877,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nswlf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"1ncehost","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nqoqs","score":5,"author_fullname":"t2_lrannsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You should just put example outputs like you just mentioned in the readme so I don\'t need to run it to see if its worth running.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0nswlf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should just put example outputs like you just mentioned in the readme so I don&amp;#39;t need to run it to see if its worth running.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nswlf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751323323,"author_flair_text":null,"treatment_tags":[],"created_utc":1751323323,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nqoqs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henryb213","can_mod_post":false,"created_utc":1751322589,"send_replies":true,"parent_id":"t1_n0nmqiz","score":3,"author_fullname":"t2_1slbug571z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for responding, so there are notebook demos in the github repo and every class in [base.py](http://base.py) has examples you can run! you\'ll see the full reasoning and how the answer compares to your typical sophisticated LLM like o3 or opus. Very different answers when the LLM can critique its own revisions and has accesses to the system prompts , user prompts and overarching protocols tailored to the problem by a developer.","edited":1751325145,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nqoqs","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for responding, so there are notebook demos in the github repo and every class in &lt;a href=\\"http://base.py\\"&gt;base.py&lt;/a&gt; has examples you can run! you&amp;#39;ll see the full reasoning and how the answer compares to your typical sophisticated LLM like o3 or opus. Very different answers when the LLM can critique its own revisions and has accesses to the system prompts , user prompts and overarching protocols tailored to the problem by a developer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nqoqs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751322589,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0p131n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"brownman19","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nterx","score":1,"author_fullname":"t2_c6qwk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They did not - they are probably too busy gooning to their sketchy fake nudes and AI roleplay. We lost another one to the abyss. \\n\\nKeep making practical lightweight applications. I like the concept here. \\n\\nMain suggestion is reduce verbosity on the docs and readmes. Perhaps include user journeys that describe the practical examples and use cases.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0p131n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They did not - they are probably too busy gooning to their sketchy fake nudes and AI roleplay. We lost another one to the abyss. &lt;/p&gt;\\n\\n&lt;p&gt;Keep making practical lightweight applications. I like the concept here. &lt;/p&gt;\\n\\n&lt;p&gt;Main suggestion is reduce verbosity on the docs and readmes. Perhaps include user journeys that describe the practical examples and use cases.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0p131n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751338739,"author_flair_text":null,"treatment_tags":[],"created_utc":1751338739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nterx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"henryb213","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nnbkr","score":3,"author_fullname":"t2_1slbug571z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, thank you for the response, did you go the repo? I think by just a few moments after reading through the code and or documents you\'d realize this comment is not correct. but thanks! almost every company uses LangChain and LangGraph in some purpose, and in this framework, agents drop right into the graphs as nodes without the abstractions of LangChain that can take just a week to understand. Just one of the many purposes for this creating this repo. And you\'ll see the code couldn\'t possibly be generated by only LLMs themselves, their documentation everywhere, the modularity and separation of concerns, and how precise yet simple class hierarchy and template/prompts loading work...I\'d recommend maybe going to the architecture documents first.","edited":1751325291,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0nterx","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, thank you for the response, did you go the repo? I think by just a few moments after reading through the code and or documents you&amp;#39;d realize this comment is not correct. but thanks! almost every company uses LangChain and LangGraph in some purpose, and in this framework, agents drop right into the graphs as nodes without the abstractions of LangChain that can take just a week to understand. Just one of the many purposes for this creating this repo. And you&amp;#39;ll see the code couldn&amp;#39;t possibly be generated by only LLMs themselves, their documentation everywhere, the modularity and separation of concerns, and how precise yet simple class hierarchy and template/prompts loading work...I&amp;#39;d recommend maybe going to the architecture documents first.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nterx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751323493,"author_flair_text":null,"treatment_tags":[],"created_utc":1751323493,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nnbkr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thomthehound","can_mod_post":false,"created_utc":1751321497,"send_replies":true,"parent_id":"t1_n0nmqiz","score":4,"author_fullname":"t2_vxbs7cf4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The irony of being part of an AI discussion group is that you get posts written by AI about programs written by AI for some unexplained, fantasy AI purpose.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nnbkr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The irony of being part of an AI discussion group is that you get posts written by AI about programs written by AI for some unexplained, fantasy AI purpose.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nnbkr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751321497,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nmqiz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"1ncehost","can_mod_post":false,"created_utc":1751321309,"send_replies":true,"parent_id":"t3_1lokkpc","score":6,"author_fullname":"t2_lrannsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cool idea. Can you give some more practical examples of what it is used for?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nmqiz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool idea. Can you give some more practical examples of what it is used for?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0nmqiz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751321309,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lokkpc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pmt6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Valuable_Option7843","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0p6d90","score":1,"author_fullname":"t2_o8036kegb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think this is the right place for it since the big commercial providers already have similar tech on offer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pmt6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this is the right place for it since the big commercial providers already have similar tech on offer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0pmt6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751348335,"author_flair_text":null,"treatment_tags":[],"created_utc":1751348335,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0p6d90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henryb213","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0oyq52","score":2,"author_fullname":"t2_1slbug571z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank for the reply, the latter, definitely part of of the in context learning space, like a LangChain, LangGraph, autoGPT, etc. Think of it as it an easy way to get introduced the space using actual python, without abstractions, and full history of how an LLM agent reached its decisions in a single or multi agent workflow. And yes, clever way of prompt handling (simply changing the provided txt files or adding your own) but also pretty novel ideas of protocol injection throughout and easily changing how system and user prompts are handled per domain (which in itself is a simple as adding a 4 lines of code for a Class that inherits the BaseClass which has all the core logic for the project). That being said any model can be used so feel free to test it out with a model you trained yourself. I know posting in LocalLLLama might have not been the move haha.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0p6d90","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank for the reply, the latter, definitely part of of the in context learning space, like a LangChain, LangGraph, autoGPT, etc. Think of it as it an easy way to get introduced the space using actual python, without abstractions, and full history of how an LLM agent reached its decisions in a single or multi agent workflow. And yes, clever way of prompt handling (simply changing the provided txt files or adding your own) but also pretty novel ideas of protocol injection throughout and easily changing how system and user prompts are handled per domain (which in itself is a simple as adding a 4 lines of code for a Class that inherits the BaseClass which has all the core logic for the project). That being said any model can be used so feel free to test it out with a model you trained yourself. I know posting in LocalLLLama might have not been the move haha.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0p6d90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751340812,"author_flair_text":null,"treatment_tags":[],"created_utc":1751340812,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0oyq52","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1751337851,"send_replies":true,"parent_id":"t1_n0oln67","score":1,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Neat idea, I\'ll try to check it out. Perhaps I misunderstood though, do you train the model in anyway? Or is this more like intelligent system prompt handling with recursion (looping) to narrow in on a response?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0oyq52","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Neat idea, I&amp;#39;ll try to check it out. Perhaps I misunderstood though, do you train the model in anyway? Or is this more like intelligent system prompt handling with recursion (looping) to narrow in on a response?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lokkpc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0oyq52/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751337851,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0oln67","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henryb213","can_mod_post":false,"created_utc":1751333144,"send_replies":true,"parent_id":"t3_1lokkpc","score":2,"author_fullname":"t2_1slbug571z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey, I realized my title was too technical. Simply put: this makes AI give you thoughtful answers instead of lazy ones. It forces the AI to critique and improve its response multiple times before giving it to you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0oln67","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, I realized my title was too technical. Simply put: this makes AI give you thoughtful answers instead of lazy ones. It forces the AI to critique and improve its response multiple times before giving it to you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0oln67/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751333144,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lokkpc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pytxn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"created_utc":1751355073,"send_replies":true,"parent_id":"t3_1lokkpc","score":1,"author_fullname":"t2_3yvyd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you add an MCP server for this? Would be useful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pytxn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you add an MCP server for this? Would be useful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lokkpc/a_metaframework_for_selfimproving_llms_with/n0pytxn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751355073,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lokkpc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),o=()=>e.jsx(t,{data:l});export{o as default};
