const e=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I figured I'd post my final setup since many people asked about the P40 and assumed you couldn't do much with it (but you can!).\\n\\n    numactl --cpunodebind=0 -- ./ik_llama.cpp/build/bin/llama-cli \\\\\\n        --numa numactl  \\\\\\n        --model models/unsloth/DeepSeek-R1-0528-GGUF/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00001-of-00006.gguf \\\\\\n        --threads 40 \\\\\\n        --cache-type-k q8_0 \\\\\\n        --cache-type-v q8_0 \\\\\\n        --top-p 0.95 \\\\\\n        --temp 0.6 \\\\\\n        --ctx-size 32768 \\\\\\n        --seed 3407 \\\\\\n        --n-gpu-layers 62 \\\\\\n        -ot \\"exps=CPU\\" \\\\\\n        --mlock \\\\\\n        --no-mmap \\\\\\n        -mla 2 -fa -fmoe \\\\\\n        -ser 5,1 \\\\\\n        -amb 512 \\\\\\n        --prompt \\"&lt;｜User｜&gt;Create a Flappy Bird game in Python.&lt;｜Assistant｜&gt;\\"\\n\\nThe result at the end of the run is 6.5tk/s\\n\\nI'm open to ideas on how to improve it.\\n\\nHardware: \\n\\n* Fully populated Dell R740 (in performance profile)\\n* Nvidia Tesla P40 (24GB vram)\\n* Xeon Gold 6138\\n* 1.5TB of ram (all ram slots populated)\\n\\nFor other models, like Mistral or QwQ I get around 10tk/s\\n\\nThese are my QwQ settings (I use the regular llama.cpp for this one)\\n\\n    numactl --cpunodebind=0 -- ./llama.cpp/build/bin/llama-cli \\\\\\n        --numa numactl  \\\\\\n        --model models/unsloth/unsloth-QwQ-32B-GGUF/QwQ-32B-Q4_K_M.gguf \\\\\\n        --threads 40 \\\\\\n        --ctx-size 16384 \\\\\\n        --n-gpu-layers 99 \\\\\\n        --seed 3407 \\\\\\n        --temp 0.6 \\\\\\n        --repeat-penalty 1.1 \\\\\\n        --min-p 0.01 \\\\\\n        --top-k 40 \\\\\\n        --top-p 0.95 \\\\\\n        --dry-multiplier 0.5 \\\\\\n        --mlock \\\\\\n        --no-mmap \\\\\\n        --prio 3 \\\\\\n        -no-cnv \\\\\\n        -fa  \\\\\\n        --samplers \\"top_k;top_p;min_p;temperature;dry;typ_p;xtc\\" \\\\\\n        --prompt \\"&lt;|im_start|&gt;user\\\\nCreate a Flappy Bird game in Python. You must include these things:\\\\n1. You must use pygame.\\\\n2. The background color should be randomly chosen and is a light shade. Start with a light blue color.\\\\n3. Pressing SPACE multiple times will accelerate the bird.\\\\n4. The bird's shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.\\\\n5. Place on the bottom some land colored as dark brown or yellow chosen randomly.\\\\n6. Make a score shown on the top right side. Increment if you pass pipes and don't hit them.\\\\n7. Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.\\\\n8. When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.\\\\nThe final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section.&lt;|im_end|&gt;\\\\n&lt;|im_start|&gt;assistant\\\\n&lt;think&gt;\\\\n\\"\\n    # --prompt \\"&lt;｜User｜&gt;Create a Flappy Bird game in Python.&lt;｜Assistant｜&gt;\\"\\n\\n\\n\\nThe details on the selected quants are in the model path. Surprisingly, using ik\\\\_llama.cpp optimized models from *ubergarm* did not speed up Deepseek, but it slowed it down greatly.\\n\\n  \\nFeel free to suggest improvements. For models different than deepseek, ik\\\\_llama.cpp was giving me a lot of gibberish output if I enabled fast attention. And some models I couldn't even run on it, so that's why I still use the regular llama.cpp for some of them.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Deepseek R1 at 6,5 tk/s on an Nvidia Tesla P40","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":true,"name":"t3_1lp01c7","quarantine":false,"link_flair_text_color":"light","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dkwhd0p","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751371939,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I figured I&amp;#39;d post my final setup since many people asked about the P40 and assumed you couldn&amp;#39;t do much with it (but you can!).&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;numactl --cpunodebind=0 -- ./ik_llama.cpp/build/bin/llama-cli \\\\\\n    --numa numactl  \\\\\\n    --model models/unsloth/DeepSeek-R1-0528-GGUF/UD-Q2_K_XL/DeepSeek-R1-0528-UD-Q2_K_XL-00001-of-00006.gguf \\\\\\n    --threads 40 \\\\\\n    --cache-type-k q8_0 \\\\\\n    --cache-type-v q8_0 \\\\\\n    --top-p 0.95 \\\\\\n    --temp 0.6 \\\\\\n    --ctx-size 32768 \\\\\\n    --seed 3407 \\\\\\n    --n-gpu-layers 62 \\\\\\n    -ot &amp;quot;exps=CPU&amp;quot; \\\\\\n    --mlock \\\\\\n    --no-mmap \\\\\\n    -mla 2 -fa -fmoe \\\\\\n    -ser 5,1 \\\\\\n    -amb 512 \\\\\\n    --prompt &amp;quot;&amp;lt;｜User｜&amp;gt;Create a Flappy Bird game in Python.&amp;lt;｜Assistant｜&amp;gt;&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;The result at the end of the run is 6.5tk/s&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m open to ideas on how to improve it.&lt;/p&gt;\\n\\n&lt;p&gt;Hardware: &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Fully populated Dell R740 (in performance profile)&lt;/li&gt;\\n&lt;li&gt;Nvidia Tesla P40 (24GB vram)&lt;/li&gt;\\n&lt;li&gt;Xeon Gold 6138&lt;/li&gt;\\n&lt;li&gt;1.5TB of ram (all ram slots populated)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;For other models, like Mistral or QwQ I get around 10tk/s&lt;/p&gt;\\n\\n&lt;p&gt;These are my QwQ settings (I use the regular llama.cpp for this one)&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;numactl --cpunodebind=0 -- ./llama.cpp/build/bin/llama-cli \\\\\\n    --numa numactl  \\\\\\n    --model models/unsloth/unsloth-QwQ-32B-GGUF/QwQ-32B-Q4_K_M.gguf \\\\\\n    --threads 40 \\\\\\n    --ctx-size 16384 \\\\\\n    --n-gpu-layers 99 \\\\\\n    --seed 3407 \\\\\\n    --temp 0.6 \\\\\\n    --repeat-penalty 1.1 \\\\\\n    --min-p 0.01 \\\\\\n    --top-k 40 \\\\\\n    --top-p 0.95 \\\\\\n    --dry-multiplier 0.5 \\\\\\n    --mlock \\\\\\n    --no-mmap \\\\\\n    --prio 3 \\\\\\n    -no-cnv \\\\\\n    -fa  \\\\\\n    --samplers &amp;quot;top_k;top_p;min_p;temperature;dry;typ_p;xtc&amp;quot; \\\\\\n    --prompt &amp;quot;&amp;lt;|im_start|&amp;gt;user\\\\nCreate a Flappy Bird game in Python. You must include these things:\\\\n1. You must use pygame.\\\\n2. The background color should be randomly chosen and is a light shade. Start with a light blue color.\\\\n3. Pressing SPACE multiple times will accelerate the bird.\\\\n4. The bird&amp;#39;s shape should be randomly chosen as a square, circle or triangle. The color should be randomly chosen as a dark color.\\\\n5. Place on the bottom some land colored as dark brown or yellow chosen randomly.\\\\n6. Make a score shown on the top right side. Increment if you pass pipes and don&amp;#39;t hit them.\\\\n7. Make randomly spaced pipes with enough space. Color them randomly as dark green or light brown or a dark gray shade.\\\\n8. When you lose, show the best score. Make the text inside the screen. Pressing q or Esc will quit the game. Restarting is pressing SPACE again.\\\\nThe final game should be inside a markdown section in Python. Check your code for errors and fix them before the final markdown section.&amp;lt;|im_end|&amp;gt;\\\\n&amp;lt;|im_start|&amp;gt;assistant\\\\n&amp;lt;think&amp;gt;\\\\n&amp;quot;\\n# --prompt &amp;quot;&amp;lt;｜User｜&amp;gt;Create a Flappy Bird game in Python.&amp;lt;｜Assistant｜&amp;gt;&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;The details on the selected quants are in the model path. Surprisingly, using ik_llama.cpp optimized models from &lt;em&gt;ubergarm&lt;/em&gt; did not speed up Deepseek, but it slowed it down greatly.&lt;/p&gt;\\n\\n&lt;p&gt;Feel free to suggest improvements. For models different than deepseek, ik_llama.cpp was giving me a lot of gibberish output if I enabled fast attention. And some models I couldn&amp;#39;t even run on it, so that&amp;#39;s why I still use the regular llama.cpp for some of them.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lp01c7","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"dc740","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lp01c7/deepseek_r1_at_65_tks_on_an_nvidia_tesla_p40/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lp01c7/deepseek_r1_at_65_tks_on_an_nvidia_tesla_p40/","subreddit_subscribers":493242,"created_utc":1751371939,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qvpto","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1751372408,"send_replies":true,"parent_id":"t3_1lp01c7","score":1,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"could you explan how this is different than 3090? I mean is there anything P40-specific?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qvpto","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;could you explan how this is different than 3090? I mean is there anything P40-specific?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp01c7/deepseek_r1_at_65_tks_on_an_nvidia_tesla_p40/n0qvpto/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372408,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lp01c7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qvx7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MengerianMango","can_mod_post":false,"created_utc":1751372487,"send_replies":true,"parent_id":"t1_n0qvrgg","score":1,"author_fullname":"t2_mcvyi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ask ur mom","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qvx7d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ask ur mom&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp01c7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp01c7/deepseek_r1_at_65_tks_on_an_nvidia_tesla_p40/n0qvx7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372487,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qvrgg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751372426,"send_replies":true,"parent_id":"t3_1lp01c7","score":1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how big is PP?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qvrgg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how big is PP?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp01c7/deepseek_r1_at_65_tks_on_an_nvidia_tesla_p40/n0qvrgg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372426,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp01c7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`);export{e as default};
