import{j as e}from"./index-Bu7qcPAU.js";import{R as l}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello!\\nI've been looking for a new model to default to(for chatting, coding, side projects and so on) so I've also been looking at many Benchmark results and it seems like Gemini 2.5 Flash is beating all the open model(except for the new R1) and even Claude 4 Opus.\\nWhile I don't have the resources to test all the models in a more professional manner I have to say in my small vibe tests 2.5 just feels worse than or at most on par with models like Qwen3 235B, Sonnet 4 or the original R1.\\nWhat is your experience with 2.5 Flash and is it really as good as the Benchmarks suggest?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Flash 2.5 vs Open weights","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m3is87","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.87,"author_flair_background_color":null,"subreddit_type":"public","ups":11,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_7v7emhil","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":11,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752885487,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello!\\nI&amp;#39;ve been looking for a new model to default to(for chatting, coding, side projects and so on) so I&amp;#39;ve also been looking at many Benchmark results and it seems like Gemini 2.5 Flash is beating all the open model(except for the new R1) and even Claude 4 Opus.\\nWhile I don&amp;#39;t have the resources to test all the models in a more professional manner I have to say in my small vibe tests 2.5 just feels worse than or at most on par with models like Qwen3 235B, Sonnet 4 or the original R1.\\nWhat is your experience with 2.5 Flash and is it really as good as the Benchmarks suggest?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m3is87","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Jakelolipopp","discussion_type":null,"num_comments":9,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/","subreddit_subscribers":501753,"created_utc":1752885487,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x5zcq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Efficiency_1144","can_mod_post":false,"created_utc":1752888073,"send_replies":true,"parent_id":"t1_n3x0i29","score":1,"author_fullname":"t2_1nkj9l14b0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I would not rate 2.5 Flash highly for code. Math is where it is very strong.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x5zcq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I would not rate 2.5 Flash highly for code. Math is where it is very strong.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3is87","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3x5zcq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888073,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3x0i29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1752886020,"send_replies":true,"parent_id":"t3_1m3is87","score":2,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"2.5 Flash is pretty high up there on LM Arena, but on this [ranking for UI and frontend,](https://www.designarena.ai/) it's fairly low and a lot lower than many of the open weights. \\n\\nThat said, in terms of anecdotal evidence, I haven't found Flash to be all that good and I definitely wouldn't call it comparable to Opus or Sonnet or R1-0528. \\n\\nYou can also try out different models for coding [frontends specifically here](https://www.designarena.ai/play).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x0i29","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2.5 Flash is pretty high up there on LM Arena, but on this &lt;a href=\\"https://www.designarena.ai/\\"&gt;ranking for UI and frontend,&lt;/a&gt; it&amp;#39;s fairly low and a lot lower than many of the open weights. &lt;/p&gt;\\n\\n&lt;p&gt;That said, in terms of anecdotal evidence, I haven&amp;#39;t found Flash to be all that good and I definitely wouldn&amp;#39;t call it comparable to Opus or Sonnet or R1-0528. &lt;/p&gt;\\n\\n&lt;p&gt;You can also try out different models for coding &lt;a href=\\"https://www.designarena.ai/play\\"&gt;frontends specifically here&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3x0i29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752886020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x0lzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Efficiency_1144","can_mod_post":false,"created_utc":1752886061,"send_replies":true,"parent_id":"t3_1m3is87","score":4,"author_fullname":"t2_1nkj9l14b0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemini 2.5 Pro feels way stronger than 2.5 Flash out of the box but once you add even a basic setup like a tailored system message, RAG, CoT and Few-Shot the gap closes for most problems. 2.5 Pro stays ahead for the hardest problems, mostly math.\\n\\n\\nThere is also Gemini 2.5 Flash Lite as an alternative. I did not know it had released until I saw it in AI Studio. To me Gemini 2.5 Flash Lite feels noticeably worse than 2.5 Flash.\\n\\n\\nFor open, Kimi K2, Minimax M1, Nvidia Nemotron models, Qwen models, Llama 4 models and Gemma are worth trying","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x0lzh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemini 2.5 Pro feels way stronger than 2.5 Flash out of the box but once you add even a basic setup like a tailored system message, RAG, CoT and Few-Shot the gap closes for most problems. 2.5 Pro stays ahead for the hardest problems, mostly math.&lt;/p&gt;\\n\\n&lt;p&gt;There is also Gemini 2.5 Flash Lite as an alternative. I did not know it had released until I saw it in AI Studio. To me Gemini 2.5 Flash Lite feels noticeably worse than 2.5 Flash.&lt;/p&gt;\\n\\n&lt;p&gt;For open, Kimi K2, Minimax M1, Nvidia Nemotron models, Qwen models, Llama 4 models and Gemma are worth trying&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3x0lzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752886061,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x58km","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"offlinesir","can_mod_post":false,"created_utc":1752887795,"send_replies":true,"parent_id":"t3_1m3is87","score":3,"author_fullname":"t2_jn5ft2le","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I believe flash is beaten in coding when compared to open models as Google didn't optimize flash for coding. Gemini 2.5 Pro is the coding model that Google always shows off and gives benchmarks, while flash seems more pointed towards chat and turn by turn conversations at a low API cost (when compared to OpenAI).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x58km","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I believe flash is beaten in coding when compared to open models as Google didn&amp;#39;t optimize flash for coding. Gemini 2.5 Pro is the coding model that Google always shows off and gives benchmarks, while flash seems more pointed towards chat and turn by turn conversations at a low API cost (when compared to OpenAI).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3x58km/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752887795,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"fe89e94a-13f2-11f0-a9de-6262c74956cf","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x69t3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Asleep-Ratio7535","can_mod_post":false,"created_utc":1752888182,"send_replies":true,"parent_id":"t3_1m3is87","score":1,"author_fullname":"t2_1lfyddwf0c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For what? For coding, no. R1 is better. But you can use pro.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x69t3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 4"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For what? For coding, no. R1 is better. But you can use pro.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3x69t3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888182,"author_flair_text":"Llama 4","treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#b0ae9b","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xslvz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vesuraychev","can_mod_post":false,"created_utc":1752897128,"send_replies":true,"parent_id":"t3_1m3is87","score":1,"author_fullname":"t2_6dv5x7st","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My experience with flash 2.5 is that it has to be given automatic thinking budget. Otherwise performance degrades really rapidly. \\n\\nWith automatic thinking budget though, it is quite expensive. We find it ends up costing about as much as OpenAI o3, and o3 is in a different league. \\n\\nThis is for coding. I want to like Gemini models, but my experience was not that good unfortunately. Now, Gemini flash 2.0 was quite good and hard to beat on price. 2.5 with no thinking budget of 1k tokens ends up worse than 2.0.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xslvz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My experience with flash 2.5 is that it has to be given automatic thinking budget. Otherwise performance degrades really rapidly. &lt;/p&gt;\\n\\n&lt;p&gt;With automatic thinking budget though, it is quite expensive. We find it ends up costing about as much as OpenAI o3, and o3 is in a different league. &lt;/p&gt;\\n\\n&lt;p&gt;This is for coding. I want to like Gemini models, but my experience was not that good unfortunately. Now, Gemini flash 2.0 was quite good and hard to beat on price. 2.5 with no thinking budget of 1k tokens ends up worse than 2.0.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3xslvz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752897128,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ylkcq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1752911880,"send_replies":true,"parent_id":"t3_1m3is87","score":1,"author_fullname":"t2_askwa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the benchmarks rarely reflect real life. 2.5 flash was actually worse than 2.0 in real world writing for example, but it’s rarely reported","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ylkcq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the benchmarks rarely reflect real life. 2.5 flash was actually worse than 2.0 in real world writing for example, but it’s rarely reported&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3ylkcq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911880,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3z103s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lostnuclues","can_mod_post":false,"created_utc":1752920610,"send_replies":true,"parent_id":"t3_1m3is87","score":1,"author_fullname":"t2_7spksnox","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"2.5 flash is fast and good for tool calling, For coding I won't use it as it makes lots of mistake which 2.5 pro or R1 does not .","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z103s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2.5 flash is fast and good for tool calling, For coding I won&amp;#39;t use it as it makes lots of mistake which 2.5 pro or R1 does not .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3z103s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752920610,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3z8zps","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-LaughingMan-0D","can_mod_post":false,"created_utc":1752924558,"send_replies":true,"parent_id":"t3_1m3is87","score":1,"author_fullname":"t2_f9b3qh4c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I use Flash the most for code fill and quick code completion in VsC. It's very fast and capable enough. For anything more complex, I'd go with Claude, O3, or R1.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z8zps","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use Flash the most for code fill and quick code completion in VsC. It&amp;#39;s very fast and capable enough. For anything more complex, I&amp;#39;d go with Claude, O3, or R1.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3is87/flash_25_vs_open_weights/n3z8zps/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752924558,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3is87","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
