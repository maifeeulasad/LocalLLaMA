import{j as t}from"./index-CWmJdUH_.js";import{R as e}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"# ðŸš€ Just Dropped: Eloquent â€“ A Local LLM Powerhouse\\n\\nHey LocalLLaMA! Just dropped **Eloquent** after 4 months of \\"just one more feature\\" syndrome.\\n\\nStarted as a basic chat interface... ended up as a full-stack, dual-GPU, memory-retaining AI companion.  \\nBuilt entirely for local model users â€” by someone who actually uses local models.\\n\\n# ðŸ§  Key Features\\n\\n* Dual-GPU architecture with memory offloading\\n* Persistent memory system that learns who you are over time\\n* Model ELO testing (head-to-head tournaments + scoring)\\n* Auto-character creator (talk to an AI â†’ get a JSON persona)\\n* Built-in SD support (EloDiffusion + ADetailer)\\n* 60+ TTS voices, fast voice-to-text\\n* RAG support for PDFs, DOCX, and more\\n* Focus &amp; Call modes (clean UI &amp; voice-only UX)\\n\\nâ€¦and probably a dozen other things I forgot I built.\\n\\n# ðŸ› ï¸ Install &amp; Run\\n\\nQuick setup (Windows):\\n\\n    git clone https://github.com/boneylizard/Eloquent.git\\n    cd Eloquent\\n    install.bat\\n    run.bat\\n\\nWorks with any GGUF model. Supports single GPU, but flies with two.\\n\\n# ðŸ§¬ Why?\\n\\n* I wanted real memory, so it remembers your background, style, vibe.\\n* I wanted model comparisons that arenâ€™t just vibes-based.\\n* I wanted persona creation without filling out forms.\\n* I wanted it modular, so anyone can build on top of it.\\n* I wanted it local, private, and fast.\\n\\n# ðŸ”“ Open Source &amp; Yours to Break\\n\\n* 100% local â€” nothing phones home\\n* AGPL-3.0 licensed\\n* Everything's in backend/app or frontend/src\\n* The rest is just dependencies â€” over 300 of them\\n\\nPlease, try it out. Break it. Fork it. Adapt it.  \\nI genuinely think people will build cool stuff on top of this.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"GitHub - boneylizard/Eloquent: A local front-end for open-weight LLMs with memory, RAG, TTS/STT, Elo ratings, and dynamic research tools. Built with React and FastAPI.","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m18nke","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.92,"author_flair_background_color":null,"subreddit_type":"public","ups":10,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_43prq","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":10,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"default","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"mod_note":null,"created":1752660245,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;h1&gt;ðŸš€ Just Dropped: Eloquent â€“ A Local LLM Powerhouse&lt;/h1&gt;\\n\\n&lt;p&gt;Hey LocalLLaMA! Just dropped &lt;strong&gt;Eloquent&lt;/strong&gt; after 4 months of &amp;quot;just one more feature&amp;quot; syndrome.&lt;/p&gt;\\n\\n&lt;p&gt;Started as a basic chat interface... ended up as a full-stack, dual-GPU, memory-retaining AI companion.&lt;br/&gt;\\nBuilt entirely for local model users â€” by someone who actually uses local models.&lt;/p&gt;\\n\\n&lt;h1&gt;ðŸ§  Key Features&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Dual-GPU architecture with memory offloading&lt;/li&gt;\\n&lt;li&gt;Persistent memory system that learns who you are over time&lt;/li&gt;\\n&lt;li&gt;Model ELO testing (head-to-head tournaments + scoring)&lt;/li&gt;\\n&lt;li&gt;Auto-character creator (talk to an AI â†’ get a JSON persona)&lt;/li&gt;\\n&lt;li&gt;Built-in SD support (EloDiffusion + ADetailer)&lt;/li&gt;\\n&lt;li&gt;60+ TTS voices, fast voice-to-text&lt;/li&gt;\\n&lt;li&gt;RAG support for PDFs, DOCX, and more&lt;/li&gt;\\n&lt;li&gt;Focus &amp;amp; Call modes (clean UI &amp;amp; voice-only UX)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;â€¦and probably a dozen other things I forgot I built.&lt;/p&gt;\\n\\n&lt;h1&gt;ðŸ› ï¸ Install &amp;amp; Run&lt;/h1&gt;\\n\\n&lt;p&gt;Quick setup (Windows):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;git clone https://github.com/boneylizard/Eloquent.git\\ncd Eloquent\\ninstall.bat\\nrun.bat\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Works with any GGUF model. Supports single GPU, but flies with two.&lt;/p&gt;\\n\\n&lt;h1&gt;ðŸ§¬ Why?&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;I wanted real memory, so it remembers your background, style, vibe.&lt;/li&gt;\\n&lt;li&gt;I wanted model comparisons that arenâ€™t just vibes-based.&lt;/li&gt;\\n&lt;li&gt;I wanted persona creation without filling out forms.&lt;/li&gt;\\n&lt;li&gt;I wanted it modular, so anyone can build on top of it.&lt;/li&gt;\\n&lt;li&gt;I wanted it local, private, and fast.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;ðŸ”“ Open Source &amp;amp; Yours to Break&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;100% local â€” nothing phones home&lt;/li&gt;\\n&lt;li&gt;AGPL-3.0 licensed&lt;/li&gt;\\n&lt;li&gt;Everything&amp;#39;s in backend/app or frontend/src&lt;/li&gt;\\n&lt;li&gt;The rest is just dependencies â€” over 300 of them&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Please, try it out. Break it. Fork it. Adapt it.&lt;br/&gt;\\nI genuinely think people will build cool stuff on top of this.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/boneylizard/Eloquent","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m18nke","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Gerdel","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m18nke/github_boneylizardeloquent_a_local_frontend_for/","stickied":false,"url":"https://github.com/boneylizard/Eloquent","subreddit_subscribers":499773,"created_utc":1752660245,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fhsg7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3fchk4","score":1,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"is that why nemo isn't as common as Pytorch?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3fhsg7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;is that why nemo isn&amp;#39;t as common as Pytorch?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m18nke","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m18nke/github_boneylizardeloquent_a_local_frontend_for/n3fhsg7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752666364,"author_flair_text":null,"treatment_tags":[],"created_utc":1752666364,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3fchk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gerdel","can_mod_post":false,"created_utc":1752664059,"send_replies":true,"parent_id":"t1_n3fatse","score":1,"author_fullname":"t2_43prq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes that's become a persistent headache. I did manage to get it going with the instructions followed in the github on my secondary test PC before launch, and its worth it in the end, if you can get it going. Whisper 3 Turbo is an okay fallback, but its not as good as Parakeet.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fchk4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes that&amp;#39;s become a persistent headache. I did manage to get it going with the instructions followed in the github on my secondary test PC before launch, and its worth it in the end, if you can get it going. Whisper 3 Turbo is an okay fallback, but its not as good as Parakeet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m18nke","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m18nke/github_boneylizardeloquent_a_local_frontend_for/n3fchk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752664059,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3fatse","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"R_Duncan","can_mod_post":false,"created_utc":1752663293,"send_replies":true,"parent_id":"t3_1m18nke","score":2,"author_fullname":"t2_3xd4mwvn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good luck to everyone trying to install the nemo toolkit. I'm at sixth retry.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fatse","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good luck to everyone trying to install the nemo toolkit. I&amp;#39;m at sixth retry.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m18nke/github_boneylizardeloquent_a_local_frontend_for/n3fatse/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752663293,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m18nke","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fcdbc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vasileer","can_mod_post":false,"created_utc":1752664005,"send_replies":true,"parent_id":"t3_1m18nke","score":4,"author_fullname":"t2_730bgdulm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\- AGPL: not a good license to want to hack it or contribute\\n\\n\\\\- RAG: fixed size chunks (=500 words?), there are better ways to do it, try chonkie\\n\\n\\\\- llama-cpp-python: v0.2.11 from 2023? which means no modern llms (e.g. gemma3n) can be used\\n\\nhttps://preview.redd.it/tltzjc6xx7df1.png?width=501&amp;format=png&amp;auto=webp&amp;s=e1e8050637c35b018a48b9a3fa384e6192704587","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fcdbc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;- AGPL: not a good license to want to hack it or contribute&lt;/p&gt;\\n\\n&lt;p&gt;- RAG: fixed size chunks (=500 words?), there are better ways to do it, try chonkie&lt;/p&gt;\\n\\n&lt;p&gt;- llama-cpp-python: v0.2.11 from 2023? which means no modern llms (e.g. gemma3n) can be used&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/tltzjc6xx7df1.png?width=501&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1e8050637c35b018a48b9a3fa384e6192704587\\"&gt;https://preview.redd.it/tltzjc6xx7df1.png?width=501&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1e8050637c35b018a48b9a3fa384e6192704587&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m18nke/github_boneylizardeloquent_a_local_frontend_for/n3fcdbc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752664005,"media_metadata":{"tltzjc6xx7df1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":68,"x":108,"u":"https://preview.redd.it/tltzjc6xx7df1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=432ddee3ef4f39a9ab03b5277f06eaedc26d2dfd"},{"y":137,"x":216,"u":"https://preview.redd.it/tltzjc6xx7df1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e083c4e408ad80879b148ac7e7d4c3994693af7"},{"y":203,"x":320,"u":"https://preview.redd.it/tltzjc6xx7df1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9c5e668ff58cb56769b6c5f3f3e3ff3697535d1"}],"s":{"y":318,"x":501,"u":"https://preview.redd.it/tltzjc6xx7df1.png?width=501&amp;format=png&amp;auto=webp&amp;s=e1e8050637c35b018a48b9a3fa384e6192704587"},"id":"tltzjc6xx7df1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m18nke","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}}]`),r=()=>t.jsx(e,{data:l});export{r as default};
