import{j as e}from"./index-BOnf-UhU.js";import{R as l}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"What options do we have for Qwen3 Coder, either local or cloud services?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What is the cheapest option for hosting llama cpp with Qwen Coder at Q8?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6nvhs","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.77,"author_flair_background_color":null,"subreddit_type":"public","ups":7,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_mxdkomgg","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":7,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1753213772,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753213111,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;What options do we have for Qwen3 Coder, either local or cloud services?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m6nvhs","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Available_Driver6406","discussion_type":null,"num_comments":15,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/","subreddit_subscribers":503254,"created_utc":1753213111,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4oavt1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leflakk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lnqmi","score":1,"author_fullname":"t2_udr659irv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Could you please give some detail about your setup? On my side, was more thinking about the unsloth UD 4 K XL (around 280Gb) with the 4x3090 and a « good » DDR4 config but I understand from your answer even Q4 will be slow as not enough offloading?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oavt1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you please give some detail about your setup? On my side, was more thinking about the unsloth UD 4 K XL (around 280Gb) with the 4x3090 and a « good » DDR4 config but I understand from your answer even Q4 will be slow as not enough offloading?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4oavt1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753256778,"author_flair_text":null,"treatment_tags":[],"created_utc":1753256778,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lnqmi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lhln3","score":2,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, the model is 480B and Q8_0 is 8.5bpw so it would be 510GB.  This wouldn't fit without the GPUs, and might not even still when you consider context.  (AFAIK there is no fp8 CPU inference engine so you need Q8_0 instead of fp8.)\\n\\n8ch DDR4-3200 is ~205GBps.  It has 35 active parameters or 37GB @ Q8_0 of which ~15% will be on GPU.  So in theory you could get 6.5t/s but in practice I've found MoE runs a lot worse, so let's say 4t/s.  Note the speed is mostly defined by the slowest part, but the GPUs at least offer additional RAM.  Even Q4 isn't going to be able to offload a large enough fraction to move the needle by a lot, I'd expect.\\n\\nThat isn't too arbitrary - Qwen3-235B-A22B @ Q8 gives 14t/s on my machine - a DDR5 Epyc with 500GBps theoretical memory bandwidth.  The same math says it should run at 21t/s.  I think there's in inefficiency in the Qwen3-235B-A22B routing or something and one would presume that Coder will be the same though who knows.  But if we take my 14t/s and math \`14 * 205/500 * 22/37\` we get 3.5t/s.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lnqmi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, the model is 480B and Q8_0 is 8.5bpw so it would be 510GB.  This wouldn&amp;#39;t fit without the GPUs, and might not even still when you consider context.  (AFAIK there is no fp8 CPU inference engine so you need Q8_0 instead of fp8.)&lt;/p&gt;\\n\\n&lt;p&gt;8ch DDR4-3200 is ~205GBps.  It has 35 active parameters or 37GB @ Q8_0 of which ~15% will be on GPU.  So in theory you could get 6.5t/s but in practice I&amp;#39;ve found MoE runs a lot worse, so let&amp;#39;s say 4t/s.  Note the speed is mostly defined by the slowest part, but the GPUs at least offer additional RAM.  Even Q4 isn&amp;#39;t going to be able to offload a large enough fraction to move the needle by a lot, I&amp;#39;d expect.&lt;/p&gt;\\n\\n&lt;p&gt;That isn&amp;#39;t too arbitrary - Qwen3-235B-A22B @ Q8 gives 14t/s on my machine - a DDR5 Epyc with 500GBps theoretical memory bandwidth.  The same math says it should run at 21t/s.  I think there&amp;#39;s in inefficiency in the Qwen3-235B-A22B routing or something and one would presume that Coder will be the same though who knows.  But if we take my 14t/s and math &lt;code&gt;14 * 205/500 * 22/37&lt;/code&gt; we get 3.5t/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4lnqmi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219857,"author_flair_text":null,"treatment_tags":[],"created_utc":1753219857,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4mey4k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lhln3","score":2,"author_fullname":"t2_wjjtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It will be slow","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4mey4k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will be slow&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4mey4k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753228463,"author_flair_text":null,"treatment_tags":[],"created_utc":1753228463,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ln5o3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lhln3","score":1,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good = 8+ channels fast DDR4","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ln5o3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good = 8+ channels fast DDR4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4ln5o3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219682,"author_flair_text":null,"treatment_tags":[],"created_utc":1753219682,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lhln3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leflakk","can_mod_post":false,"created_utc":1753218060,"send_replies":true,"parent_id":"t1_n4l0ja4","score":1,"author_fullname":"t2_udr659irv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have 4\\\\*3090, do you think that even with a \\"good\\" DDR4 system it will still be slow? Not sure what good means (EPYC + fastest RAM possible?).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lhln3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have 4*3090, do you think that even with a &amp;quot;good&amp;quot; DDR4 system it will still be slow? Not sure what good means (EPYC + fastest RAM possible?).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4lhln3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753218060,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4l3oy2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mysterious_Finish543","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4l1efy","score":3,"author_fullname":"t2_gbx2bcdvl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Given the demonstrated performance so far, I think we'll see many providers host this model –– just look at [Kimi-K2 on OpenRouter](https://openrouter.ai/moonshotai/kimi-k2). \\n\\nThat being said, the model hasn't even been officially released yet (we've been testing it via Qwen Chat and Hyperbolic), so we might need to wait 1-2 weeks for providers to get inference running smoothly.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4l3oy2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Given the demonstrated performance so far, I think we&amp;#39;ll see many providers host this model –– just look at &lt;a href=\\"https://openrouter.ai/moonshotai/kimi-k2\\"&gt;Kimi-K2 on OpenRouter&lt;/a&gt;. &lt;/p&gt;\\n\\n&lt;p&gt;That being said, the model hasn&amp;#39;t even been officially released yet (we&amp;#39;ve been testing it via Qwen Chat and Hyperbolic), so we might need to wait 1-2 weeks for providers to get inference running smoothly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4l3oy2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753214219,"author_flair_text":null,"treatment_tags":[],"created_utc":1753214219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l1efy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Available_Driver6406","can_mod_post":false,"created_utc":1753213581,"send_replies":true,"parent_id":"t1_n4l0ja4","score":1,"author_fullname":"t2_mxdkomgg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, Qwen3 Coder. \\n\\nAnd what options in cloud services?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l1efy","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, Qwen3 Coder. &lt;/p&gt;\\n\\n&lt;p&gt;And what options in cloud services?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4l1efy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753213581,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l0ja4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tomz17","can_mod_post":false,"created_utc":1753213332,"send_replies":true,"parent_id":"t3_1m6nvhs","score":14,"author_fullname":"t2_1mhx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm assuming you mean Qwen3 Coder?\\n\\nCheapest?   DDR4 system with a ton of RAM  (you'll need 512GB For FP8 w/ a small context).   It'll be cheap, but it certainly won't be fast.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l0ja4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m assuming you mean Qwen3 Coder?&lt;/p&gt;\\n\\n&lt;p&gt;Cheapest?   DDR4 system with a ton of RAM  (you&amp;#39;ll need 512GB For FP8 w/ a small context).   It&amp;#39;ll be cheap, but it certainly won&amp;#39;t be fast.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4l0ja4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753213332,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6nvhs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4m9zai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"candreacchio","can_mod_post":false,"created_utc":1753226863,"send_replies":true,"parent_id":"t1_n4lintv","score":1,"author_fullname":"t2_3awu1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Weights are here? https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct/tree/main","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4m9zai","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Weights are here? &lt;a href=\\"https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct/tree/main\\"&gt;https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct/tree/main&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4m9zai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753226863,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lintv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PermanentLiminality","can_mod_post":false,"created_utc":1753218364,"send_replies":true,"parent_id":"t3_1m6nvhs","score":2,"author_fullname":"t2_19zqycaf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Way too much VRAM required.  I'll be running it as soon as it appears on OpenRouter.  It usually gets there within 24 hours of official release.\\n\\nIt's on [qwen.ai](http://qwen.ai) for free\\n\\nHope that doesn't mean that they will not be releasing weights.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lintv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Way too much VRAM required.  I&amp;#39;ll be running it as soon as it appears on OpenRouter.  It usually gets there within 24 hours of official release.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s on &lt;a href=\\"http://qwen.ai\\"&gt;qwen.ai&lt;/a&gt; for free&lt;/p&gt;\\n\\n&lt;p&gt;Hope that doesn&amp;#39;t mean that they will not be releasing weights.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4lintv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753218364,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6nvhs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4oggwb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kaisurniwurer","can_mod_post":false,"created_utc":1753260000,"send_replies":true,"parent_id":"t3_1m6nvhs","score":1,"author_fullname":"t2_qafso","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The cheapest is by using MMAP with a refurbished used office PC.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4oggwb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The cheapest is by using MMAP with a refurbished used office PC.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4oggwb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753260000,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6nvhs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lh1za","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leflakk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lb5uh","score":1,"author_fullname":"t2_udr659irv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agree! People (like me) not enough familiar with deep understanding of servers CPU/RAM characteristics would need that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lh1za","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree! People (like me) not enough familiar with deep understanding of servers CPU/RAM characteristics would need that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4lh1za/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217907,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217907,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ln6ny","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Danmoreng","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lb5uh","score":1,"author_fullname":"t2_7z26p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well you got a point there…thing is: asking on Reddit with this little effort is disrespectful and should be downvoted to oblivion in my opinion.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ln6ny","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well you got a point there…thing is: asking on Reddit with this little effort is disrespectful and should be downvoted to oblivion in my opinion.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4ln6ny/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219690,"author_flair_text":null,"treatment_tags":[],"created_utc":1753219690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lb5uh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1753216290,"send_replies":true,"parent_id":"t1_n4l69lg","score":4,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Considering the people that come here with bad-to-awful build ideas from ChatGPT I would actually strongly recommend against that :).\\n\\nI do feel like we should have a \\"what can I build to run a big MoE\\" wiki or pin thread, though...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lb5uh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Considering the people that come here with bad-to-awful build ideas from ChatGPT I would actually strongly recommend against that :).&lt;/p&gt;\\n\\n&lt;p&gt;I do feel like we should have a &amp;quot;what can I build to run a big MoE&amp;quot; wiki or pin thread, though...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6nvhs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4lb5uh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753216290,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4l69lg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Danmoreng","can_mod_post":false,"created_utc":1753214929,"send_replies":true,"parent_id":"t3_1m6nvhs","score":0,"author_fullname":"t2_7z26p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ask any AI for a detailed analysis and suggestions…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l69lg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ask any AI for a detailed analysis and suggestions…&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6nvhs/what_is_the_cheapest_option_for_hosting_llama_cpp/n4l69lg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753214929,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6nvhs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
