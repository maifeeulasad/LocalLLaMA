import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi I'm a college student from India.\\n\\nSo i'm looking for a language model for code generation to run locally. I only have 16 GB of ram and iris xe gpu, so looking for some good opensource SLMs which can be decent enough. I could use something like llama.cpp given performance and latency would be decent(currently using a gguf version of mistral 7B-instruct and it's working fine) . Can also consider using raspberry pi if it'll be of any use","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Best opensource SLM/ lightweight llm for code generation","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6dvhi","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.78,"author_flair_background_color":null,"subreddit_type":"public","ups":5,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_7q8gvaa19","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":5,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753190318,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi I&amp;#39;m a college student from India.&lt;/p&gt;\\n\\n&lt;p&gt;So i&amp;#39;m looking for a language model for code generation to run locally. I only have 16 GB of ram and iris xe gpu, so looking for some good opensource SLMs which can be decent enough. I could use something like llama.cpp given performance and latency would be decent(currently using a gguf version of mistral 7B-instruct and it&amp;#39;s working fine) . Can also consider using raspberry pi if it&amp;#39;ll be of any use&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m6dvhi","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"RustinChole11","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/","subreddit_subscribers":503254,"created_utc":1753190318,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lhgax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wooden-guy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lgvvh","score":1,"author_fullname":"t2_16to413y2o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are right, and your advice applies to people who don't understand that devices can reach a 100 percent load and that you should test your device based on that and apply your work accordingly.\\n\\nBut if we take the claim as it is then yeah it's really not true.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lhgax","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are right, and your advice applies to people who don&amp;#39;t understand that devices can reach a 100 percent load and that you should test your device based on that and apply your work accordingly.&lt;/p&gt;\\n\\n&lt;p&gt;But if we take the claim as it is then yeah it&amp;#39;s really not true.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4lhgax/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753218018,"author_flair_text":null,"treatment_tags":[],"created_utc":1753218018,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lgvvh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"winter-m00n","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lffvr","score":1,"author_fullname":"t2_scey28yts","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When gpt4all  was generating text it used resources heavily, at least in my case fans started spinning really loud and the back of the laptop often got so hot that I had to use a laptop stand.\\n\\nMaybe you are right, but still no harm in keeping little precautions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lgvvh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When gpt4all  was generating text it used resources heavily, at least in my case fans started spinning really loud and the back of the laptop often got so hot that I had to use a laptop stand.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe you are right, but still no harm in keeping little precautions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4lgvvh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217859,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217859,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lffvr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wooden-guy","can_mod_post":false,"created_utc":1753217465,"send_replies":true,"parent_id":"t1_n4j1tu3","score":2,"author_fullname":"t2_16to413y2o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is some of the worst advice on the internet lol, there is no device getting fried because of this specific use case\\n\\nInstead it's if the device is under load, be it gaming development or any other shit, and it gets fried or hits high temps, then there's a problem.\\n\\nAny software that isn't a virus or alike will never harm your system, IF your system won't get fried under 100% CPU/GPU load","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lffvr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is some of the worst advice on the internet lol, there is no device getting fried because of this specific use case&lt;/p&gt;\\n\\n&lt;p&gt;Instead it&amp;#39;s if the device is under load, be it gaming development or any other shit, and it gets fried or hits high temps, then there&amp;#39;s a problem.&lt;/p&gt;\\n\\n&lt;p&gt;Any software that isn&amp;#39;t a virus or alike will never harm your system, IF your system won&amp;#39;t get fried under 100% CPU/GPU load&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4lffvr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217465,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j92ve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RustinChole11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4j8fv5","score":1,"author_fullname":"t2_7q8gvaa19","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Right, I'll keep that in mind","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j92ve","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right, I&amp;#39;ll keep that in mind&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4j92ve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195707,"author_flair_text":null,"treatment_tags":[],"created_utc":1753195707,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j8fv5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"winter-m00n","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4j7n6r","score":3,"author_fullname":"t2_scey28yts","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am not too sure, maybe motherboard itself was faulty but my laptop often ran hot while using gpt4all. But I thought it's still under control.\\n\\n\\nI was using Lenovo IdeaPad gaming laptop and it was new. 8gb Ram and 4gb vram and i5 processor. Don't remember exact spec though.\\n\\nI am not saying this would happen with you but happened with me so just commented.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4j8fv5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am not too sure, maybe motherboard itself was faulty but my laptop often ran hot while using gpt4all. But I thought it&amp;#39;s still under control.&lt;/p&gt;\\n\\n&lt;p&gt;I was using Lenovo IdeaPad gaming laptop and it was new. 8gb Ram and 4gb vram and i5 processor. Don&amp;#39;t remember exact spec though.&lt;/p&gt;\\n\\n&lt;p&gt;I am not saying this would happen with you but happened with me so just commented.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4j8fv5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195530,"author_flair_text":null,"treatment_tags":[],"created_utc":1753195530,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j7n6r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RustinChole11","can_mod_post":false,"created_utc":1753195306,"send_replies":true,"parent_id":"t1_n4j1tu3","score":1,"author_fullname":"t2_7q8gvaa19","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow . So you suggest not to go for any llms, not even quantized versions? \\nAlso, just curious what were your laptop specs and model you ran in this case.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j7n6r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow . So you suggest not to go for any llms, not even quantized versions? \\nAlso, just curious what were your laptop specs and model you ran in this case.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4j7n6r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195306,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j1tu3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"winter-m00n","can_mod_post":false,"created_utc":1753193639,"send_replies":true,"parent_id":"t3_1m6dvhi","score":2,"author_fullname":"t2_scey28yts","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"be careful if you are running llm on laptop, specially if it increase the heat while running. my motherboard got fried, probably because of it and needed to be replaced.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j1tu3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;be careful if you are running llm on laptop, specially if it increase the heat while running. my motherboard got fried, probably because of it and needed to be replaced.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4j1tu3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753193639,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6dvhi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ny9e2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RustinChole11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4nskfq","score":1,"author_fullname":"t2_7q8gvaa19","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sure, thanks mate.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ny9e2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, thanks mate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4ny9e2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753249889,"author_flair_text":null,"treatment_tags":[],"created_utc":1753249889,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nskfq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mkengine","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4mv6jl","score":2,"author_fullname":"t2_9p2xe","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you can wait a bit longer, they are releasing Qwen3-Coder, a finetune specifically for Coding in different sizes.\\n\\nThey are starting with the biggest one but smaller ones will follow soon:\\n\\nhttps://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct\\n\\nJust have an eye in their hugginface spaces.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4nskfq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you can wait a bit longer, they are releasing Qwen3-Coder, a finetune specifically for Coding in different sizes.&lt;/p&gt;\\n\\n&lt;p&gt;They are starting with the biggest one but smaller ones will follow soon:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct\\"&gt;https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Just have an eye in their hugginface spaces.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4nskfq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753247059,"author_flair_text":null,"treatment_tags":[],"created_utc":1753247059,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mv6jl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RustinChole11","can_mod_post":false,"created_utc":1753234012,"send_replies":true,"parent_id":"t1_n4lcwl5","score":1,"author_fullname":"t2_7q8gvaa19","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not yet, but will do now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mv6jl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not yet, but will do now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dvhi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4mv6jl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753234012,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lcwl5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mkengine","can_mod_post":false,"created_utc":1753216769,"send_replies":true,"parent_id":"t3_1m6dvhi","score":2,"author_fullname":"t2_9p2xe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried Qwen3-8B?\\n\\nhttps://huggingface.co/Qwen/Qwen3-8B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lcwl5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried Qwen3-8B?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/Qwen/Qwen3-8B\\"&gt;https://huggingface.co/Qwen/Qwen3-8B&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dvhi/best_opensource_slm_lightweight_llm_for_code/n4lcwl5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753216769,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6dvhi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
