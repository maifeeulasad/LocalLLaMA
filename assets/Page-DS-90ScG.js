import{j as e}from"./index-DQXiEb7D.js";import{R as l}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Can somebody test the performance of Gemma3 12B / 27B q4 on different modes ONNX, llamacpp, GPU, CPU, NPU ?\\n\\n https://www.youtube.com/watch?v=mcf7dDybUco","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Official Local LLM support by AMD released. Lemonade","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m16o6r","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.91,"author_flair_background_color":null,"subreddit_type":"public","ups":25,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_37dhn","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":25,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752652402,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Can somebody test the performance of Gemma3 12B / 27B q4 on different modes ONNX, llamacpp, GPU, CPU, NPU ?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.youtube.com/watch?v=mcf7dDybUco\\"&gt;https://www.youtube.com/watch?v=mcf7dDybUco&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/C7vLvyc2VR5SHdy5lbc2lopLTghrszZiODshvSAbsCw.jpeg?auto=webp&amp;s=86b7d1570b1b3ae885466d0ef7e471d7d281e739","width":480,"height":360},"resolutions":[{"url":"https://external-preview.redd.it/C7vLvyc2VR5SHdy5lbc2lopLTghrszZiODshvSAbsCw.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=20307eaee47e8d81001356a8a35bd8a5a6dbe244","width":108,"height":81},{"url":"https://external-preview.redd.it/C7vLvyc2VR5SHdy5lbc2lopLTghrszZiODshvSAbsCw.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=281f5c27d3f995ba74f6d241a3a205faec614f91","width":216,"height":162},{"url":"https://external-preview.redd.it/C7vLvyc2VR5SHdy5lbc2lopLTghrszZiODshvSAbsCw.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c3e53e6a5f79e14d65cf8154eb43a3687a3dcc8","width":320,"height":240}],"variants":{},"id":"C7vLvyc2VR5SHdy5lbc2lopLTghrszZiODshvSAbsCw"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m16o6r","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"grigio","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/","subreddit_subscribers":499773,"created_utc":1752652402,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3f2dj9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grigio","can_mod_post":false,"created_utc":1752658861,"send_replies":true,"parent_id":"t1_n3f14cu","score":3,"author_fullname":"t2_37dhn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it seems so. Currently there is a bug open on Github about that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3f2dj9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it seems so. Currently there is a bug open on Github about that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m16o6r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3f2dj9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752658861,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3f14cu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wooden_Yam1924","can_mod_post":false,"created_utc":1752658134,"send_replies":true,"parent_id":"t3_1m16o6r","score":7,"author_fullname":"t2_4fyr3i20","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"do I understand it correctly, hybrid inference with NPU works only on Windows?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3f14cu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do I understand it correctly, hybrid inference with NPU works only on Windows?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3f14cu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752658134,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16o6r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3faicr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"advertisementeconomy","can_mod_post":false,"created_utc":1752663144,"send_replies":true,"parent_id":"t3_1m16o6r","score":7,"author_fullname":"t2_db56ilco","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From the Readme:\\n\\n&gt; Lemonade makes it easy to run Large Language Models (LLMs) on your PC. Our focus is using the best tools, such as neural processing units (NPUs) and Vulkan GPU acceleration, to maximize LLM speed and responsiveness.\\n\\n...\\n\\n&gt; Model Library\\n\\n&gt; Lemonade supports both GGUF and ONNX models as detailed in the Supported Configuration section. A list of all built-in models is available here.\\n\\n&gt; You can also import custom GGUF and ONNX models from Hugging Face by using our Model Manager (requires server to be running).\\n\\n...\\n\\n&gt; Maintainers\\n\\n&gt; This project is sponsored by AMD. It is maintained by @danielholanda @jeremyfowers @ramkrishna @vgodsoe in equal measure. You can reach us by filing an issue, email lemonade@amd.com, or join our Discord.\\n\\n...\\n\\n&gt; License\\n\\n&gt; This project is licensed under the Apache 2.0 License. Portions of the project are licensed as described in NOTICE.md.\\n\\n\\n\\nhttps://github.com/lemonade-sdk/lemonade?tab=readme-ov-file","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3faicr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From the Readme:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Lemonade makes it easy to run Large Language Models (LLMs) on your PC. Our focus is using the best tools, such as neural processing units (NPUs) and Vulkan GPU acceleration, to maximize LLM speed and responsiveness.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;...&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Model Library&lt;/p&gt;\\n\\n&lt;p&gt;Lemonade supports both GGUF and ONNX models as detailed in the Supported Configuration section. A list of all built-in models is available here.&lt;/p&gt;\\n\\n&lt;p&gt;You can also import custom GGUF and ONNX models from Hugging Face by using our Model Manager (requires server to be running).&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;...&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Maintainers&lt;/p&gt;\\n\\n&lt;p&gt;This project is sponsored by AMD. It is maintained by @danielholanda @jeremyfowers @ramkrishna @vgodsoe in equal measure. You can reach us by filing an issue, email &lt;a href=\\"mailto:lemonade@amd.com\\"&gt;lemonade@amd.com&lt;/a&gt;, or join our Discord.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;...&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;License&lt;/p&gt;\\n\\n&lt;p&gt;This project is licensed under the Apache 2.0 License. Portions of the project are licensed as described in NOTICE.md.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lemonade-sdk/lemonade?tab=readme-ov-file\\"&gt;https://github.com/lemonade-sdk/lemonade?tab=readme-ov-file&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3faicr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752663144,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16o6r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3f9pgj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grigio","can_mod_post":false,"created_utc":1752662760,"send_replies":true,"parent_id":"t1_n3f72al","score":3,"author_fullname":"t2_37dhn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think this is only for amd ryzen ai 3xx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3f9pgj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this is only for amd ryzen ai 3xx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m16o6r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3f9pgj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752662760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3f72al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mxforest","can_mod_post":false,"created_utc":1752661403,"send_replies":true,"parent_id":"t3_1m16o6r","score":1,"author_fullname":"t2_kenmq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Will it help something like 8700G in anyway?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3f72al","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will it help something like 8700G in anyway?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3f72al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752661403,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16o6r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fpv7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"created_utc":1752669447,"send_replies":true,"parent_id":"t3_1m16o6r","score":1,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This post title is misleading.\\n\\nIts \\"lemonade-server\\".\\n\\nWhile it does offer a GUI (windows only) and a webui, they dont expose any settings there at all. You cant even set temperature.\\n\\nThis is made to offer an API, so I am not sure where the benefits over llama.cpp's llama-server are.\\n\\nMaybe its early days, but currently there really is little reason to use it for most people.\\n\\nUnless you want to run onnx models on your \\"AI 300\\" series NPU on windows.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fpv7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This post title is misleading.&lt;/p&gt;\\n\\n&lt;p&gt;Its &amp;quot;lemonade-server&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;While it does offer a GUI (windows only) and a webui, they dont expose any settings there at all. You cant even set temperature.&lt;/p&gt;\\n\\n&lt;p&gt;This is made to offer an API, so I am not sure where the benefits over llama.cpp&amp;#39;s llama-server are.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe its early days, but currently there really is little reason to use it for most people.&lt;/p&gt;\\n\\n&lt;p&gt;Unless you want to run onnx models on your &amp;quot;AI 300&amp;quot; series NPU on windows.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16o6r/official_local_llm_support_by_amd_released/n3fpv7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752669447,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16o6r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
