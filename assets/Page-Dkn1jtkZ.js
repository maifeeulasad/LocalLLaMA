import{j as e}from"./index-Bu7qcPAU.js";import{R as l}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi so I am a student and I can't afford a cloud gpu to train my model so I thought to use kaggle. since kaggle has a limited storage in input and output (20gb in output) to save checkpoints I thought to split my whole dataset which is 400gb into subsets. I did it into 16gb subsets each. I just want to ask will it affect by any chance the model accuracy rather than running the epoch on full dataset I would primarily do it in each dataset and thus select the checkpoint. Please give genuine advices","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"[D] Any limitations if you try to split your dataset and run full epochs","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxljco","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":6,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1pa7gw9ibk","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":6,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752276111,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi so I am a student and I can&amp;#39;t afford a cloud gpu to train my model so I thought to use kaggle. since kaggle has a limited storage in input and output (20gb in output) to save checkpoints I thought to split my whole dataset which is 400gb into subsets. I did it into 16gb subsets each. I just want to ask will it affect by any chance the model accuracy rather than running the epoch on full dataset I would primarily do it in each dataset and thus select the checkpoint. Please give genuine advices&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lxljco","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Empty-Investment-827","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/","subreddit_subscribers":498115,"created_utc":1752276111,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2odilb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Empty-Investment-827","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2o55ny","score":1,"author_fullname":"t2_1pa7gw9ibk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You sure 1 epoch will be enough? Btw it's a speech dataset. Does gcp provide GPUs on free credits?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2odilb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You sure 1 epoch will be enough? Btw it&amp;#39;s a speech dataset. Does gcp provide GPUs on free credits?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxljco","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/n2odilb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752294823,"author_flair_text":null,"treatment_tags":[],"created_utc":1752294823,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2o55ny","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"laser_man6","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2nsxxd","score":1,"author_fullname":"t2_xx06z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Idk about kaggle I use torch. But anyway it's actually perfectly fine for the model to only get a subset each epoch. It will eventually see everything, possibly multiple times depending how you sample, and epochs aren't like, an actual 'thing'. They're just groups of batches you can do stuff between, like evaluate or save the model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2o55ny","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Idk about kaggle I use torch. But anyway it&amp;#39;s actually perfectly fine for the model to only get a subset each epoch. It will eventually see everything, possibly multiple times depending how you sample, and epochs aren&amp;#39;t like, an actual &amp;#39;thing&amp;#39;. They&amp;#39;re just groups of batches you can do stuff between, like evaluate or save the model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxljco","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/n2o55ny/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752291233,"author_flair_text":null,"treatment_tags":[],"created_utc":1752291233,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2nsxxd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Empty-Investment-827","can_mod_post":false,"created_utc":1752286442,"send_replies":true,"parent_id":"t1_n2n5na7","score":1,"author_fullname":"t2_1pa7gw9ibk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ig kaggle kernels don't allow steaming the dataset. Have u done that? And i don't want to use subsets per epoch as it won't be good for the model to go for each subset only once with limited context","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nsxxd","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ig kaggle kernels don&amp;#39;t allow steaming the dataset. Have u done that? And i don&amp;#39;t want to use subsets per epoch as it won&amp;#39;t be good for the model to go for each subset only once with limited context&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxljco","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/n2nsxxd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752286442,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2n5na7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"laser_man6","can_mod_post":false,"created_utc":1752277953,"send_replies":true,"parent_id":"t3_1lxljco","score":5,"author_fullname":"t2_xx06z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just stream the dataset. But if you do want to use subsets per epoch and cycle between sets between epochs you can do that, it's fine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2n5na7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just stream the dataset. But if you do want to use subsets per epoch and cycle between sets between epochs you can do that, it&amp;#39;s fine.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/n2n5na7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752277953,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxljco","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2q8q5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1752328672,"send_replies":true,"parent_id":"t3_1lxljco","score":1,"author_fullname":"t2_9so78ol2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can get pretty small if you turn your file into parquet files beforehand","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2q8q5h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can get pretty small if you turn your file into parquet files beforehand&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxljco/d_any_limitations_if_you_try_to_split_your/n2q8q5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752328672,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxljco","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
