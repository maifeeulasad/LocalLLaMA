import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Anyone else feel like things have gone quieter in the open-source Llama scene lately?  \\nEarlier this year, there were constant updates, fine-tunes, and people sharing their custom Llama workflows. But these past weeks, I‚Äôve seen less buzz‚Äîeven though projects like DeepSeek and Gemma keep getting mentioned in broader AI circles.\\n\\n* **Is development still going strong behind the scenes?**\\n* Are people switching to closed models, or just not posting as much here?\\n* What are the most exciting recent breakthroughs or fine-tunes in the local Llama space that might have flown under the radar?\\n\\nI found [this article](https://maktoobai.com/open-source-ai/) that discusses the sudden ‚Äúsilence‚Äù around open-source AI and how it could impact the future of local models like Llama.  \\nWould love to hear from anyone who‚Äôs still actively using or training Llama‚Äîwhat‚Äôs working, what‚Äôs stalling, and any tips for keeping the momentum going!\\n\\nLet‚Äôs swap updates and see what‚Äôs brewing locally! üëá","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Has Local Llama Development Slowed Down, or Am I Missing Something? ü§î","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lx6g3p","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.35,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_tcapu8ix","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752239254,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone else feel like things have gone quieter in the open-source Llama scene lately?&lt;br/&gt;\\nEarlier this year, there were constant updates, fine-tunes, and people sharing their custom Llama workflows. But these past weeks, I‚Äôve seen less buzz‚Äîeven though projects like DeepSeek and Gemma keep getting mentioned in broader AI circles.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Is development still going strong behind the scenes?&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;Are people switching to closed models, or just not posting as much here?&lt;/li&gt;\\n&lt;li&gt;What are the most exciting recent breakthroughs or fine-tunes in the local Llama space that might have flown under the radar?&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I found &lt;a href=\\"https://maktoobai.com/open-source-ai/\\"&gt;this article&lt;/a&gt; that discusses the sudden ‚Äúsilence‚Äù around open-source AI and how it could impact the future of local models like Llama.&lt;br/&gt;\\nWould love to hear from anyone who‚Äôs still actively using or training Llama‚Äîwhat‚Äôs working, what‚Äôs stalling, and any tips for keeping the momentum going!&lt;/p&gt;\\n\\n&lt;p&gt;Let‚Äôs swap updates and see what‚Äôs brewing locally! üëá&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lx6g3p","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"shaker-ameen","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/","subreddit_subscribers":497825,"created_utc":1752239254,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jx8rw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mikael110","can_mod_post":false,"created_utc":1752243218,"send_replies":true,"parent_id":"t3_1lx6g3p","score":19,"author_fullname":"t2_4amlo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;I found¬†[this article](https://maktoobai.com/open-source-ai/)¬†that discusses the sudden ‚Äúsilence‚Äù around open-source AI and how it could impact the future of local models like Llama.\\n\\nSure you did, which is why you've posted links to it in 4 different places just in the last few hours... It's definitively not your own article that you are trying to promote...\\n\\nAlso the premise of the post isn't even true. Just this month we've had new models from Baidu, Tencent and a number of other smaller companies. It's actually been quite busy lately.","edited":1752245597,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jx8rw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I found¬†&lt;a href=\\"https://maktoobai.com/open-source-ai/\\"&gt;this article&lt;/a&gt;¬†that discusses the sudden ‚Äúsilence‚Äù around open-source AI and how it could impact the future of local models like Llama.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Sure you did, which is why you&amp;#39;ve posted links to it in 4 different places just in the last few hours... It&amp;#39;s definitively not your own article that you are trying to promote...&lt;/p&gt;\\n\\n&lt;p&gt;Also the premise of the post isn&amp;#39;t even true. Just this month we&amp;#39;ve had new models from Baidu, Tencent and a number of other smaller companies. It&amp;#39;s actually been quite busy lately.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2jx8rw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752243218,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jlp99","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fizzy1242","can_mod_post":false,"created_utc":1752239623,"send_replies":true,"parent_id":"t3_1lx6g3p","score":5,"author_fullname":"t2_16zcsx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"definitely feels like things have narrowed down to few key players that release new models, compared to 2023-2024","edited":1752239850,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jlp99","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;definitely feels like things have narrowed down to few key players that release new models, compared to 2023-2024&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2jlp99/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752239623,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jtgza","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AdamDhahabi","can_mod_post":false,"created_utc":1752242080,"send_replies":true,"parent_id":"t3_1lx6g3p","score":4,"author_fullname":"t2_x5lnbc2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Waiting for Qwen3 32b coder.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jtgza","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Waiting for Qwen3 32b coder.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2jtgza/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752242080,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kdx2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rorykoehler","can_mod_post":false,"created_utc":1752247962,"send_replies":true,"parent_id":"t3_1lx6g3p","score":5,"author_fullname":"t2_ku4i0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Literally just came here from a new SOTA 1T param open weight model announcement post.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kdx2q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Literally just came here from a new SOTA 1T param open weight model announcement post.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2kdx2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752247962,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kbay8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1752247235,"send_replies":true,"parent_id":"t3_1lx6g3p","score":3,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What are you talking about? This week was pure üî•üî•üî•","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kbay8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are you talking about? This week was pure üî•üî•üî•&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2kbay8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752247235,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jlvhc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dentuam","can_mod_post":false,"created_utc":1752239680,"send_replies":true,"parent_id":"t3_1lx6g3p","score":1,"author_fullname":"t2_znctr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"maybe because of summer idk.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jlvhc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;maybe because of summer idk.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2jlvhc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752239680,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2jqdnr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"offlinesir","can_mod_post":false,"created_utc":1752241132,"send_replies":true,"parent_id":"t3_1lx6g3p","score":2,"author_fullname":"t2_jn5ft2le","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We are in summer, so there's def people taking off around this time of year. It could mean more releases get pushed to early fall.\\n\\nSecondly, we are missing Meta's Llama 4! Well, we aren't missing it, but there's no large fine tunes because the model doesn't win when compared to Qwen or updated deepseek. That's also likely why there's less \\"development\\" in the whole AI space. If you remember, llama 3 had many fine tunes when it released because it was actually GOOD.\\n\\nLastly, I think the hype train has kinda halted for local AI (not that it can't start again). Everyone saw AI as on their phones in an app, in the cloud, and Deepseek really opened it up further to on deviece (even though they were not the first). We may have gotten to the point where there used to be a ton of local LLM followers which were interested before but now only find the trade offs, eg, I can't run large models, and the tokens per second can suck. Less attention is = less models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2jqdnr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We are in summer, so there&amp;#39;s def people taking off around this time of year. It could mean more releases get pushed to early fall.&lt;/p&gt;\\n\\n&lt;p&gt;Secondly, we are missing Meta&amp;#39;s Llama 4! Well, we aren&amp;#39;t missing it, but there&amp;#39;s no large fine tunes because the model doesn&amp;#39;t win when compared to Qwen or updated deepseek. That&amp;#39;s also likely why there&amp;#39;s less &amp;quot;development&amp;quot; in the whole AI space. If you remember, llama 3 had many fine tunes when it released because it was actually GOOD.&lt;/p&gt;\\n\\n&lt;p&gt;Lastly, I think the hype train has kinda halted for local AI (not that it can&amp;#39;t start again). Everyone saw AI as on their phones in an app, in the cloud, and Deepseek really opened it up further to on deviece (even though they were not the first). We may have gotten to the point where there used to be a ton of local LLM followers which were interested before but now only find the trade offs, eg, I can&amp;#39;t run large models, and the tokens per second can suck. Less attention is = less models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2jqdnr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752241132,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kjk3i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1752249532,"send_replies":true,"parent_id":"t1_n2khye7","score":1,"author_fullname":"t2_131eezppgs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"100% the models are better initially now\\n\\n\\nSame for images for example SD 1.5 base versus Flux Dev base.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kjk3i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;100% the models are better initially now&lt;/p&gt;\\n\\n&lt;p&gt;Same for images for example SD 1.5 base versus Flux Dev base.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lx6g3p","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2kjk3i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752249532,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2khye7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1752249080,"send_replies":true,"parent_id":"t3_1lx6g3p","score":2,"author_fullname":"t2_1by73qs5e5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see two reasons for it to. First, the good open source models getting released are larger than they were before and 2nd, there are diminishing returns on fine tuning newer smaller models because more work is being put into trying to eek every bit of performance out of them initially.¬†","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2khye7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see two reasons for it to. First, the good open source models getting released are larger than they were before and 2nd, there are diminishing returns on fine tuning newer smaller models because more work is being put into trying to eek every bit of performance out of them initially.¬†&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2khye7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752249080,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kje38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1752249484,"send_replies":true,"parent_id":"t3_1lx6g3p","score":2,"author_fullname":"t2_131eezppgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Everyone who wanted frontier perf kinda just went Deepseek aside from today when a new 1T model dropped","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kje38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everyone who wanted frontier perf kinda just went Deepseek aside from today when a new 1T model dropped&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2kje38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752249484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lhx3i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752259213,"send_replies":true,"parent_id":"t3_1lx6g3p","score":1,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mistral has released new models almost weekly for the last month and a half.\\n\\nLooks like there‚Äôs a lot happening in the AI space still. Grok4 yesterday, open AI is going to open source something next Thursday, qwen3 coder is on its way, Granite4 pull request for llamacpp means the lunch of their full Granite 4 model is imminent. Meta still has to release behemoth and their thinking model.\\n\\nPotentially all of this happening in the next few weeks.\\n\\nI see no slow down","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lhx3i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral has released new models almost weekly for the last month and a half.&lt;/p&gt;\\n\\n&lt;p&gt;Looks like there‚Äôs a lot happening in the AI space still. Grok4 yesterday, open AI is going to open source something next Thursday, qwen3 coder is on its way, Granite4 pull request for llamacpp means the lunch of their full Granite 4 model is imminent. Meta still has to release behemoth and their thinking model.&lt;/p&gt;\\n\\n&lt;p&gt;Potentially all of this happening in the next few weeks.&lt;/p&gt;\\n\\n&lt;p&gt;I see no slow down&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx6g3p/has_local_llama_development_slowed_down_or_am_i/n2lhx3i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752259213,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx6g3p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:a});export{r as default};
