import{j as e}from"./index-CWmJdUH_.js";import{R as t}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Jeremy from the AMD Lemonade team here. We just released Lemonade v8.0.4, which adds some often-requested formatting to the LLM Chat part of our web ui (see video).\\n\\nA discussion we keep having on the team is: how far does it make sense to develop our own web ui, if the primary purpose of Lemonade is to be a local server that connects to other apps?\\n\\nMy take is that people should just use the web ui to try things out for the first time, then connect to a more capable end-user app like Open WebUI or Continue.dev. There's another take that we should just make the web ui as nice as possible, since it is the first thing our users see after they install.\\n\\n* Some things we should almost certainly add: image input, buttons to load and unload models.\\n* Something we're on the fence about is a sidebar with a chat history.\\n\\nI'm curious to get the community's feedback to help settle the debate!\\n\\nPS. details of the video:\\n\\n* GitHub: [lemonade-sdk/lemonade: Local LLM Server with GPU and NPU Acceleration](https://github.com/lemonade-sdk/lemonade)\\n* Quick Start: [Lemonade Server](https://lemonade-server.ai/)\\n* Model: Qwen3 MOE (30B total / 3B active)\\n* Hardware: Strix Halo (Ryzen AI Max 395+ with 128 GB RAM)\\n* Inference engine: llama.cpp with Vulkan","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Help settle a debate on the Lemonade team: how much web UI is too much for a local server?","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":116,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvpp0e","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.65,"author_flair_background_color":null,"ups":5,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1m2ckixcqh","secure_media":{"reddit_video":{"bitrate_kbps":2400,"fallback_url":"https://v.redd.it/lqvyapxe0wbf1/DASH_720.mp4?source=fallback","has_audio":true,"height":720,"width":866,"scrubber_media_url":"https://v.redd.it/lqvyapxe0wbf1/DASH_96.mp4","dash_url":"https://v.redd.it/lqvyapxe0wbf1/DASHPlaylist.mpd?a=1754740780%2CMWNiMjE5ZDllOGU2YmY4ODQ1ZGQ1Y2IwZjliMWQ0MDdhNzc1ZTYwNGEwYjA0YzlmMTU5YWVmOTFmNTE1OTM0MA%3D%3D&amp;v=1&amp;f=sd","duration":40,"hls_url":"https://v.redd.it/lqvyapxe0wbf1/HLSPlaylist.m3u8?a=1754740780%2CMWQxZjY3YTk3MmNiNGVhM2Q1Yzk0ODQwNTcxYzI1YjdhMDYwNTI0ZjAyNDA1OWUyYWVlZTAyZDExYjY4YmY4MQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":5,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?width=140&amp;height=116&amp;crop=140:116,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=76fdecfdc8e1ddc3b28425e12bd356cd8770dc6c","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752084185,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Jeremy from the AMD Lemonade team here. We just released Lemonade v8.0.4, which adds some often-requested formatting to the LLM Chat part of our web ui (see video).&lt;/p&gt;\\n\\n&lt;p&gt;A discussion we keep having on the team is: how far does it make sense to develop our own web ui, if the primary purpose of Lemonade is to be a local server that connects to other apps?&lt;/p&gt;\\n\\n&lt;p&gt;My take is that people should just use the web ui to try things out for the first time, then connect to a more capable end-user app like Open WebUI or Continue.dev. There&amp;#39;s another take that we should just make the web ui as nice as possible, since it is the first thing our users see after they install.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Some things we should almost certainly add: image input, buttons to load and unload models.&lt;/li&gt;\\n&lt;li&gt;Something we&amp;#39;re on the fence about is a sidebar with a chat history.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I&amp;#39;m curious to get the community&amp;#39;s feedback to help settle the debate!&lt;/p&gt;\\n\\n&lt;p&gt;PS. details of the video:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;GitHub: &lt;a href=\\"https://github.com/lemonade-sdk/lemonade\\"&gt;lemonade-sdk/lemonade: Local LLM Server with GPU and NPU Acceleration&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Quick Start: &lt;a href=\\"https://lemonade-server.ai/\\"&gt;Lemonade Server&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Model: Qwen3 MOE (30B total / 3B active)&lt;/li&gt;\\n&lt;li&gt;Hardware: Strix Halo (Ryzen AI Max 395+ with 128 GB RAM)&lt;/li&gt;\\n&lt;li&gt;Inference engine: llama.cpp with Vulkan&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/lqvyapxe0wbf1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?format=pjpg&amp;auto=webp&amp;s=e90d2cb9e85227c2a2cf4f9ebbafe151533195ef","width":940,"height":782},"resolutions":[{"url":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c3a78f080464fc0acc7b5e3a568c5abd197e471e","width":108,"height":89},{"url":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c9da4e01f762030840750023843898467dc661ac","width":216,"height":179},{"url":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b126fe44194bd9d1a88356fef3e82c233e6bb6eb","width":320,"height":266},{"url":"https://external-preview.redd.it/a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a8977a13ad96b1c9139787f28b421850156500db","width":640,"height":532}],"variants":{},"id":"a3NlMzVteGUwd2JmMbld0vN-YDqXepEZ7jk7fsVH50PMdq02YFgXtbKrMRDk"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lvpp0e","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"jfowers_amd","discussion_type":null,"num_comments":10,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":2400,"fallback_url":"https://v.redd.it/lqvyapxe0wbf1/DASH_720.mp4?source=fallback","has_audio":true,"height":720,"width":866,"scrubber_media_url":"https://v.redd.it/lqvyapxe0wbf1/DASH_96.mp4","dash_url":"https://v.redd.it/lqvyapxe0wbf1/DASHPlaylist.mpd?a=1754740780%2CMWNiMjE5ZDllOGU2YmY4ODQ1ZGQ1Y2IwZjliMWQ0MDdhNzc1ZTYwNGEwYjA0YzlmMTU5YWVmOTFmNTE1OTM0MA%3D%3D&amp;v=1&amp;f=sd","duration":40,"hls_url":"https://v.redd.it/lqvyapxe0wbf1/HLSPlaylist.m3u8?a=1754740780%2CMWQxZjY3YTk3MmNiNGVhM2Q1Yzk0ODQwNTcxYzI1YjdhMDYwNTI0ZjAyNDA1OWUyYWVlZTAyZDExYjY4YmY4MQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/","stickied":false,"url":"https://v.redd.it/lqvyapxe0wbf1","subreddit_subscribers":497024,"created_utc":1752084185,"num_crossposts":0,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n287fki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jfowers_amd","can_mod_post":false,"created_utc":1752087714,"send_replies":true,"parent_id":"t1_n2802y7","score":2,"author_fullname":"t2_1m2ckixcqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt; Is lemonade going to be AMD’s interference server or an all-in-one?\\n\\nInference server\\n\\n\\\\&gt; In my opinion having an easy to run AMD hardware optimized inference server that provides an OpenAI API would be a killer product. If you have AMD hardware it should be a no-brainer to just use lemonade.\\n\\nThis is Lemonade's core mission!\\n\\n\\\\&gt; The frontend should be enough to use the latest server features. I don’t think it needs to be competing with the feature sets of the heavier weight webui’s.\\n\\nThanks for the feedback :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n287fki","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Is lemonade going to be AMD’s interference server or an all-in-one?&lt;/p&gt;\\n\\n&lt;p&gt;Inference server&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; In my opinion having an easy to run AMD hardware optimized inference server that provides an OpenAI API would be a killer product. If you have AMD hardware it should be a no-brainer to just use lemonade.&lt;/p&gt;\\n\\n&lt;p&gt;This is Lemonade&amp;#39;s core mission!&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; The frontend should be enough to use the latest server features. I don’t think it needs to be competing with the feature sets of the heavier weight webui’s.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for the feedback :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvpp0e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n287fki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752087714,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2802y7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Statement-0001","can_mod_post":false,"created_utc":1752085674,"send_replies":true,"parent_id":"t3_1lvpp0e","score":5,"author_fullname":"t2_11gh93nhos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is lemonade going to be AMD’s interference server or an all-in-one? \\n\\nIn my opinion having an easy to run AMD hardware optimized inference server that provides an OpenAI API would be a killer product. If you have AMD hardware it should be a no-brainer to just use lemonade. \\n\\nThe frontend should be enough to use the latest server features. I don’t think it needs to be competing with the feature sets of the heavier weight webui’s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2802y7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is lemonade going to be AMD’s interference server or an all-in-one? &lt;/p&gt;\\n\\n&lt;p&gt;In my opinion having an easy to run AMD hardware optimized inference server that provides an OpenAI API would be a killer product. If you have AMD hardware it should be a no-brainer to just use lemonade. &lt;/p&gt;\\n\\n&lt;p&gt;The frontend should be enough to use the latest server features. I don’t think it needs to be competing with the feature sets of the heavier weight webui’s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n2802y7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085674,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lvpp0e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n289b96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jfowers_amd","can_mod_post":false,"created_utc":1752088239,"send_replies":true,"parent_id":"t1_n286qai","score":2,"author_fullname":"t2_1m2ckixcqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the feedback! I hadn't considered editing or reloading the context, that is definitely interesting. Opened a couple issues on the repo\\n\\n[https://github.com/lemonade-sdk/lemonade/issues/66](https://github.com/lemonade-sdk/lemonade/issues/66)\\n\\n[https://github.com/lemonade-sdk/lemonade/issues/67](https://github.com/lemonade-sdk/lemonade/issues/67)\\n\\n\\\\&gt; use the llama.cpp server front-end since you're already using it as the engine\\n\\nThis came up in an internal discussion, but we also need to support ONNX as an inference engine. I figured that the llamacpp web ui might not support our ONNX stuff as well, and we'd need to substantially fork it.\\n\\n\\\\&gt; make the dream of using the NPU on Linux come true\\n\\nAbsolutely, this is much more central to our mission! That's why I'm trying to figure out what the MVP is for the web ui and go no further.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n289b96","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the feedback! I hadn&amp;#39;t considered editing or reloading the context, that is definitely interesting. Opened a couple issues on the repo&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lemonade-sdk/lemonade/issues/66\\"&gt;https://github.com/lemonade-sdk/lemonade/issues/66&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lemonade-sdk/lemonade/issues/67\\"&gt;https://github.com/lemonade-sdk/lemonade/issues/67&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; use the llama.cpp server front-end since you&amp;#39;re already using it as the engine&lt;/p&gt;\\n\\n&lt;p&gt;This came up in an internal discussion, but we also need to support ONNX as an inference engine. I figured that the llamacpp web ui might not support our ONNX stuff as well, and we&amp;#39;d need to substantially fork it.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; make the dream of using the NPU on Linux come true&lt;/p&gt;\\n\\n&lt;p&gt;Absolutely, this is much more central to our mission! That&amp;#39;s why I&amp;#39;m trying to figure out what the MVP is for the web ui and go no further.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvpp0e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n289b96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752088239,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n286qai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MDT-49","can_mod_post":false,"created_utc":1752087520,"send_replies":true,"parent_id":"t3_1lvpp0e","score":3,"author_fullname":"t2_h8yrica5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'd say playground-like features would be the best middle ground. So maybe some settings (LLM, temp, sys-prompt, etc.) and an ephemeral chat where you can preferably edit the context by editing/deleting messages. No need for chat history, but maybe an option to export and import a conversation manually. I think this should cover 90% of the use cases, while you can still keep everything really simple. \\n\\nOr settle the debate by doing nothing, use the llama.cpp server front-end since you're already using it as the engine, and make the dream of using the NPU on Linux come true!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n286qai","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d say playground-like features would be the best middle ground. So maybe some settings (LLM, temp, sys-prompt, etc.) and an ephemeral chat where you can preferably edit the context by editing/deleting messages. No need for chat history, but maybe an option to export and import a conversation manually. I think this should cover 90% of the use cases, while you can still keep everything really simple. &lt;/p&gt;\\n\\n&lt;p&gt;Or settle the debate by doing nothing, use the llama.cpp server front-end since you&amp;#39;re already using it as the engine, and make the dream of using the NPU on Linux come true!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n286qai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752087520,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvpp0e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2873uo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jfowers_amd","can_mod_post":false,"created_utc":1752087624,"send_replies":true,"parent_id":"t1_n285w0r","score":2,"author_fullname":"t2_1m2ckixcqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the feedback! This project is relatively new, so we are still discovering who the userbase is and what they're looking for. Some are developers who never use the web UI and just use the APIs, and some users are asking for increasingly advanced capabilities in the web UI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2873uo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the feedback! This project is relatively new, so we are still discovering who the userbase is and what they&amp;#39;re looking for. Some are developers who never use the web UI and just use the APIs, and some users are asking for increasingly advanced capabilities in the web UI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvpp0e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n2873uo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752087624,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n285w0r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ekaj","can_mod_post":false,"created_utc":1752087288,"send_replies":true,"parent_id":"t3_1lvpp0e","score":2,"author_fullname":"t2_3cajs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think it would depend on what your user profile looks like.\\n\\nSidebar with chat history seems like a extremely small item to add, like adding a full blown RAG system might be a bit much, but chat history seems like a standard.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n285w0r","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it would depend on what your user profile looks like.&lt;/p&gt;\\n\\n&lt;p&gt;Sidebar with chat history seems like a extremely small item to add, like adding a full blown RAG system might be a bit much, but chat history seems like a standard.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n285w0r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752087288,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lvpp0e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28oehp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jfowers_amd","can_mod_post":false,"created_utc":1752092411,"send_replies":true,"parent_id":"t1_n28kmng","score":1,"author_fullname":"t2_1m2ckixcqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Makes sense, thanks for the feedback!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28oehp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Makes sense, thanks for the feedback!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvpp0e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n28oehp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752092411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n28kmng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"trtm","can_mod_post":false,"created_utc":1752091368,"send_replies":true,"parent_id":"t3_1lvpp0e","score":2,"author_fullname":"t2_ih2d1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great job! Please focus on the inference server. Let others do the chat UIs like https://assistant.sh/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28kmng","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great job! Please focus on the inference server. Let others do the chat UIs like &lt;a href=\\"https://assistant.sh/\\"&gt;https://assistant.sh/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n28kmng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752091368,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvpp0e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29cwd9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"National_Meeting_749","can_mod_post":false,"created_utc":1752099424,"send_replies":true,"parent_id":"t3_1lvpp0e","score":2,"author_fullname":"t2_drm5tg5d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think there's no such thing as too much UI. \\n\\nI think your goal should be to make lemonade the easiest, while being very capable, way to run LLM's especially on AMD hardware. Which is how I see you hitting the bigger goal of being the most used localllm platform and I don't think you get there without a lot of UI. \\n\\nAs someone with an all red build, finding a platform that is feature rich and runs well on your hardware was definitely a challenge, this is the first time I'm hearing of lemonade. \\n\\nIt just being a bare bones server with minimal UI will only appeal to people who even understand what an API is. And that's definitely not 90% of the people who use LLMs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29cwd9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think there&amp;#39;s no such thing as too much UI. &lt;/p&gt;\\n\\n&lt;p&gt;I think your goal should be to make lemonade the easiest, while being very capable, way to run LLM&amp;#39;s especially on AMD hardware. Which is how I see you hitting the bigger goal of being the most used localllm platform and I don&amp;#39;t think you get there without a lot of UI. &lt;/p&gt;\\n\\n&lt;p&gt;As someone with an all red build, finding a platform that is feature rich and runs well on your hardware was definitely a challenge, this is the first time I&amp;#39;m hearing of lemonade. &lt;/p&gt;\\n\\n&lt;p&gt;It just being a bare bones server with minimal UI will only appeal to people who even understand what an API is. And that&amp;#39;s definitely not 90% of the people who use LLMs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvpp0e/help_settle_a_debate_on_the_lemonade_team_how/n29cwd9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099424,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvpp0e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
