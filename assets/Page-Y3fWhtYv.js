import{j as e}from"./index-C9o7w-KS.js";import{R as l}from"./RedditPostRenderer-C4RcPiw4.js";import"./index-CvnyzE1l.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"All feedback is welcome! I am learning how to do better everyday.\\n\\nI went down the LLM rabbit hole trying to find the **best local model** that runs *well* on a humble MacBook Air M1 with just 8GB RAM.\\n\\nMy goal? **Compare 10 models** across question generation, answering, and self-evaluation.\\n\\nTL;DR: Some models were brilliant, others… not so much. One even took **8 minutes** to write a question.\\n\\nHere's the breakdown \\n\\n**Models Tested**\\n\\n* Mistral 7B\\n* DeepSeek-R1 1.5B\\n* Gemma3:1b\\n* Gemma3:latest\\n* Qwen3 1.7B\\n* Qwen2.5-VL 3B\\n* Qwen3 4B\\n* LLaMA 3.2 1B\\n* LLaMA 3.2 3B\\n* LLaMA 3.1 8B\\n\\n(All models run with quantized versions, via: os.environ\\\\[\\"OLLAMA\\\\_CONTEXT\\\\_LENGTH\\"\\\\] = \\"4096\\" and os.environ\\\\[\\"OLLAMA\\\\_KV\\\\_CACHE\\\\_TYPE\\"\\\\] = \\"q4\\\\_0\\")\\n\\n **Methodology**\\n\\nEach model:\\n\\n1. Generated 1 question on 5 topics: *Math, Writing, Coding, Psychology, History*\\n2. Answered all 50 questions (5 x 10)\\n3. Evaluated every answer (including their own)\\n\\nSo in total:\\n\\n* 50 questions\\n* 500 answers\\n* 4830 evaluations (Should be 5000; I evaluated less answers with qwen3:1.7b and qwen3:4b as they do not generate scores and take a lot of time\\\\*\\\\*)\\\\*\\\\*\\n\\nAnd I tracked:\\n\\n* token generation speed (tokens/sec)\\n* tokens created\\n* time taken\\n* scored all answers for quality\\n\\n**Key Results**\\n\\n**Question Generation**\\n\\n* Fastest: **LLaMA 3.2 1B**, **Gemma3:1b**, **Qwen3 1.7B** (LLaMA 3.2 1B hit 82 tokens/sec, avg is \\\\~40 tokens/sec (for english topic question it reached **146 tokens/sec)**\\n* Slowest: **LLaMA 3.1 8B**, **Qwen3 4B**, **Mistral 7B** Qwen3 4B took **486s** (8+ mins) to generate a single Math question!\\n* Fun fact: deepseek-r1:1.5b, qwen3:4b and Qwen3:1.7B  output &lt;think&gt; tags in questions\\n\\n**Answer Generation**\\n\\n* Fastest: **Gemma3:1b**, **LLaMA 3.2 1B** and **DeepSeek-R1 1.5B**\\n* DeepSeek got faster answering *its own* questions (80 tokens/s vs. avg 40 tokens/s)\\n* Qwen3 4B generates **2–3x more tokens** per answer\\n* Slowest: llama3.1:8b, qwen3:4b and mistral:7b\\n\\n **Evaluation**\\n\\n* Best scorer: Gemma3:latest – consistent, numerical, no bias\\n* Worst scorer: **DeepSeek-R1 1.5B** – often skipped scores entirely\\n* Bias detected: Many models **rate their own answers higher**\\n* DeepSeek even evaluated some answers **in Chinese**\\n* I did think of creating a control set of answers. I could tell the mdoel this is the perfect answer basis this rate others. But I did not because it would need support from a lot of people- creating perfect answer, which still can have a bias. I read a few answers and found most of them decent except math. So I tried to find which model's evaluation scores were closest to the average to determine a decent model for evaluation tasks(check last image)\\n\\n**Fun Observations**\\n\\n* Some models create &lt;think&gt; tags for questions, answers and even while evaluation as output\\n* Score inflation is real: Mistral, Qwen3, and LLaMA 3.1 8B overrate themselves\\n* Score formats vary wildly (text explanations vs. plain numbers)\\n* Speed isn’t everything – some slower models gave much higher quality answers\\n\\nBest Performers (My Picks)\\n\\n|Task|Best Model|Why|\\n|:-|:-|:-|\\n||\\n|Question Gen|LLaMA 3.2 1B|Fast &amp; relevant|\\n|Answer Gen|Gemma3:1b|Fast, accurate|\\n|Evaluation|LLaMA 3.2 3B|Generates numerical scores and evaluations closest to model average|\\n\\n# Worst Surprises\\n\\n|Task|Model|Problem|\\n|:-|:-|:-|\\n||\\n|Question Gen|Qwen3 4B|Took 486s to generate 1 question|\\n|Answer Gen|LLaMA 3.1 8B|Slow|\\n|Evaluation|DeepSeek-R1 1.5B|Inconsistent, skipped scores|\\n\\n  \\n\\n\\n**Screenshots Galore**\\n\\nI’m adding screenshots of:\\n\\n* Questions generation\\n* Answer comparisons\\n* Evaluation outputs\\n* Token/sec charts\\n\\n**Takeaways**\\n\\n* You **can** run decent LLMs locally on M1 Air (8GB) – if you pick the right ones\\n* Model size ≠ performance. Bigger isn't always better.\\n* 5 Models have a self bais, they rate their own answers higher than average scores. attaching screen shot of a table. Diagonal is their own evaluation, last column is average.\\n* Models' evaluation has high variance! Every model has a unique distribution of the scores it gave.\\n\\n\\n\\nPost questions if you have any, I will try to answer.\\n\\nHappy to share more data if you need.\\n\\nOpen to collaborate on interesting projects!  \\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"is_gallery":true,"title":"I tested 10 LLMs locally on my MacBook Air M1 (8GB RAM!) – Here's what actually works-","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":112,"top_awarded_type":null,"name":"t3_1lmfiu9","media_metadata":{"w4f8xli4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":29,"x":108,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b96b9d71e7f5cc19270d3e6757274fac5fe9e559"},{"y":59,"x":216,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf125b59a5d0fbb0104681091d2cd72710d9438c"},{"y":87,"x":320,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f239944c53abb16cd6f10f737c0d3e9c05029fc3"},{"y":175,"x":640,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d69126eba42bde7f077facec0a350d57c56256"},{"y":262,"x":960,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=714909e3b8b9add5188e1cf71f01d0ede670096b"},{"y":295,"x":1080,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1edde5fe76b20b90da3d4bac9cb308f007f9b2a1"}],"s":{"y":608,"x":2222,"u":"https://preview.redd.it/w4f8xli4wl9f1.png?width=2222&amp;format=png&amp;auto=webp&amp;s=ad9ae202236ff1cd2a5d1cf75d70eb52b16391f6"},"id":"w4f8xli4wl9f1"},"7ow61zr5yl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":34,"x":108,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d71ac73034ce77fb319f3e990af9dfcb44e24ae"},{"y":69,"x":216,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2d6854bb1262cfb00057e00b4b4e6194c543add"},{"y":102,"x":320,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d942c0c3a8bcd5cd2ec47ed9eec14908266197b"},{"y":205,"x":640,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3db8e0da43940b98ce87c2231621edf4865bd8d3"},{"y":308,"x":960,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd04e93a170d7594a1cb1e71bdde008140e19fc4"},{"y":347,"x":1080,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa807713456f50b628c2dbbb7f9bd31cb36af2c3"}],"s":{"y":578,"x":1798,"u":"https://preview.redd.it/7ow61zr5yl9f1.png?width=1798&amp;format=png&amp;auto=webp&amp;s=4e017761dc8a2a68934ac7aa89b630b9ed2b8c35"},"id":"7ow61zr5yl9f1"},"egnnlsi2wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":86,"x":108,"u":"https://preview.redd.it/egnnlsi2wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9448c36d381645725739286c81c00c47042504a"},{"y":173,"x":216,"u":"https://preview.redd.it/egnnlsi2wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=90beda29783d07c6f8fdcbe4dc9571577513c239"},{"y":256,"x":320,"u":"https://preview.redd.it/egnnlsi2wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b81341be72a56d8b0ea6bf950c56f7262fe5f095"}],"s":{"y":462,"x":576,"u":"https://preview.redd.it/egnnlsi2wl9f1.png?width=576&amp;format=png&amp;auto=webp&amp;s=74c468152e1b07a9477cb9f585813b049d8fe26a"},"id":"egnnlsi2wl9f1"},"3a2up8h4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":55,"x":108,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b160363637899ad144ebf490c61dc85337660b4e"},{"y":111,"x":216,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c2516aaf407375f16ad9e0056be5294332c94e7"},{"y":165,"x":320,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a2b191dda64d1e00eb4adc7349872c23ea50618"},{"y":331,"x":640,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=79a9835abf82b64f59e6451b9a4983d31832c526"},{"y":497,"x":960,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3321e89c17c380a374228afd5f94fa21aaa45a0f"},{"y":559,"x":1080,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bfad51ac4fdb43c37a6bfefc824617849188b0ce"}],"s":{"y":612,"x":1182,"u":"https://preview.redd.it/3a2up8h4wl9f1.png?width=1182&amp;format=png&amp;auto=webp&amp;s=748edef3784d64cc28c4d60c3e50571ddcaad313"},"id":"3a2up8h4wl9f1"},"liu63zk4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":37,"x":108,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e50689d45b956d6a4b2c5f7590a12f95ac267972"},{"y":74,"x":216,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a68615664589ed852faaaf98f6779a17e22563"},{"y":109,"x":320,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=20bca0e7073ae1d89178fe678c7f460bd00fc6e0"},{"y":219,"x":640,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ddcc8fb4ef36dac5f1ca0f95fc62a3e37486e2a"},{"y":329,"x":960,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=021bf74293f3c00eaac63703a8d127e3fb4f63be"},{"y":370,"x":1080,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a39b2959311f50782f311f9745422c8e4ee378c"}],"s":{"y":622,"x":1812,"u":"https://preview.redd.it/liu63zk4wl9f1.png?width=1812&amp;format=png&amp;auto=webp&amp;s=546b5bd3a523c15dc10ff4dde46352f729e79c6a"},"id":"liu63zk4wl9f1"},"d8xub4g4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":55,"x":108,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dd67cbc493ea896c4e423238cae173000db0548"},{"y":111,"x":216,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d55bc9d396022cce49b2c94bac0437c04d689f10"},{"y":165,"x":320,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=61aaf12e41251c658b2b4f868b3781eb04ab55d1"},{"y":331,"x":640,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e308e90fe91bbbc89a40ddb9b9096dae15730cf"},{"y":497,"x":960,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=175ecbe1ba43ce3239bc45eac8b0da69a27f2b86"},{"y":559,"x":1080,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc210e0d4f4388c78242014ab57cf0e07e63ee76"}],"s":{"y":612,"x":1182,"u":"https://preview.redd.it/d8xub4g4wl9f1.png?width=1182&amp;format=png&amp;auto=webp&amp;s=a4bb86c652cec9b038e938fe04a714dc0736c538"},"id":"d8xub4g4wl9f1"},"40gg0ih4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":51,"x":108,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=843dd3262374605f266f4c27d5e9f1d89dbaa2b2"},{"y":102,"x":216,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=56f75b650d38e914049b6fd64a26e2fc3c016b5d"},{"y":152,"x":320,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=95f9ce0398be85d3a2b624b01002420346b3ad0c"},{"y":304,"x":640,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcfc3c93a167ba16a262a2da7e5a418386d5ea24"},{"y":456,"x":960,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b6fd6795c6cf705e757ca019f69fb8a5d85dc083"},{"y":513,"x":1080,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1675b1bd8c2c958cbf831b82c33e80db9ff880c2"}],"s":{"y":638,"x":1342,"u":"https://preview.redd.it/40gg0ih4wl9f1.png?width=1342&amp;format=png&amp;auto=webp&amp;s=42cd465376a98a0e2334441ad593bbc235416c5d"},"id":"40gg0ih4wl9f1"},"pvm051l4wl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":36,"x":108,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7db0df0d613449adf472a0d58e9ce7adce1ae72"},{"y":73,"x":216,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cfabb69b61246b25865db0c730e257755a797c8"},{"y":108,"x":320,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc741039d34362412cd2b230ea2ee1e48e35f194"},{"y":216,"x":640,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d93dc81a7c1dd207d9c6fe7d69347616516cf7c"},{"y":324,"x":960,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ddabbd002a9e5e456a17c6870bb97674fb1719a"},{"y":365,"x":1080,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c7e81f875f564219b86016f4279dc98de4ca000"}],"s":{"y":616,"x":1820,"u":"https://preview.redd.it/pvm051l4wl9f1.png?width=1820&amp;format=png&amp;auto=webp&amp;s=a174b16eed66f061fe3ae72b957c5603f6a1a8d8"},"id":"pvm051l4wl9f1"}},"hide_score":false,"quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.94,"author_flair_background_color":null,"ups":373,"domain":"reddit.com","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_l5xlcgf2j","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"gallery_data":{"items":[{"media_id":"egnnlsi2wl9f1","id":694183376},{"media_id":"pvm051l4wl9f1","id":694183377},{"media_id":"liu63zk4wl9f1","id":694183378},{"media_id":"d8xub4g4wl9f1","id":694183379},{"media_id":"3a2up8h4wl9f1","id":694183380},{"media_id":"40gg0ih4wl9f1","id":694183381},{"media_id":"w4f8xli4wl9f1","id":694183382},{"media_id":"7ow61zr5yl9f1","id":694183383}]},"link_flair_text":"Discussion","can_mod_post":false,"score":373,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=140&amp;height=112&amp;crop=140:112,smart&amp;auto=webp&amp;s=dc5f7c42f0d761e20ad7ac19bcfae402a94d6091","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"gallery","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751090266,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;All feedback is welcome! I am learning how to do better everyday.&lt;/p&gt;\\n\\n&lt;p&gt;I went down the LLM rabbit hole trying to find the &lt;strong&gt;best local model&lt;/strong&gt; that runs &lt;em&gt;well&lt;/em&gt; on a humble MacBook Air M1 with just 8GB RAM.&lt;/p&gt;\\n\\n&lt;p&gt;My goal? &lt;strong&gt;Compare 10 models&lt;/strong&gt; across question generation, answering, and self-evaluation.&lt;/p&gt;\\n\\n&lt;p&gt;TL;DR: Some models were brilliant, others… not so much. One even took &lt;strong&gt;8 minutes&lt;/strong&gt; to write a question.&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s the breakdown &lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Models Tested&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Mistral 7B&lt;/li&gt;\\n&lt;li&gt;DeepSeek-R1 1.5B&lt;/li&gt;\\n&lt;li&gt;Gemma3:1b&lt;/li&gt;\\n&lt;li&gt;Gemma3:latest&lt;/li&gt;\\n&lt;li&gt;Qwen3 1.7B&lt;/li&gt;\\n&lt;li&gt;Qwen2.5-VL 3B&lt;/li&gt;\\n&lt;li&gt;Qwen3 4B&lt;/li&gt;\\n&lt;li&gt;LLaMA 3.2 1B&lt;/li&gt;\\n&lt;li&gt;LLaMA 3.2 3B&lt;/li&gt;\\n&lt;li&gt;LLaMA 3.1 8B&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;(All models run with quantized versions, via: os.environ[&amp;quot;OLLAMA_CONTEXT_LENGTH&amp;quot;] = &amp;quot;4096&amp;quot; and os.environ[&amp;quot;OLLAMA_KV_CACHE_TYPE&amp;quot;] = &amp;quot;q4_0&amp;quot;)&lt;/p&gt;\\n\\n&lt;p&gt; &lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Each model:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Generated 1 question on 5 topics: &lt;em&gt;Math, Writing, Coding, Psychology, History&lt;/em&gt;&lt;/li&gt;\\n&lt;li&gt;Answered all 50 questions (5 x 10)&lt;/li&gt;\\n&lt;li&gt;Evaluated every answer (including their own)&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;So in total:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;50 questions&lt;/li&gt;\\n&lt;li&gt;500 answers&lt;/li&gt;\\n&lt;li&gt;4830 evaluations (Should be 5000; I evaluated less answers with qwen3:1.7b and qwen3:4b as they do not generate scores and take a lot of time**)**&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;And I tracked:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;token generation speed (tokens/sec)&lt;/li&gt;\\n&lt;li&gt;tokens created&lt;/li&gt;\\n&lt;li&gt;time taken&lt;/li&gt;\\n&lt;li&gt;scored all answers for quality&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Key Results&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Question Generation&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Fastest: &lt;strong&gt;LLaMA 3.2 1B&lt;/strong&gt;, &lt;strong&gt;Gemma3:1b&lt;/strong&gt;, &lt;strong&gt;Qwen3 1.7B&lt;/strong&gt; (LLaMA 3.2 1B hit 82 tokens/sec, avg is ~40 tokens/sec (for english topic question it reached &lt;strong&gt;146 tokens/sec)&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;Slowest: &lt;strong&gt;LLaMA 3.1 8B&lt;/strong&gt;, &lt;strong&gt;Qwen3 4B&lt;/strong&gt;, &lt;strong&gt;Mistral 7B&lt;/strong&gt; Qwen3 4B took &lt;strong&gt;486s&lt;/strong&gt; (8+ mins) to generate a single Math question!&lt;/li&gt;\\n&lt;li&gt;Fun fact: deepseek-r1:1.5b, qwen3:4b and Qwen3:1.7B  output &amp;lt;think&amp;gt; tags in questions&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Answer Generation&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Fastest: &lt;strong&gt;Gemma3:1b&lt;/strong&gt;, &lt;strong&gt;LLaMA 3.2 1B&lt;/strong&gt; and &lt;strong&gt;DeepSeek-R1 1.5B&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;DeepSeek got faster answering &lt;em&gt;its own&lt;/em&gt; questions (80 tokens/s vs. avg 40 tokens/s)&lt;/li&gt;\\n&lt;li&gt;Qwen3 4B generates &lt;strong&gt;2–3x more tokens&lt;/strong&gt; per answer&lt;/li&gt;\\n&lt;li&gt;Slowest: llama3.1:8b, qwen3:4b and mistral:7b&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt; &lt;strong&gt;Evaluation&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Best scorer: Gemma3:latest – consistent, numerical, no bias&lt;/li&gt;\\n&lt;li&gt;Worst scorer: &lt;strong&gt;DeepSeek-R1 1.5B&lt;/strong&gt; – often skipped scores entirely&lt;/li&gt;\\n&lt;li&gt;Bias detected: Many models &lt;strong&gt;rate their own answers higher&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;DeepSeek even evaluated some answers &lt;strong&gt;in Chinese&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;I did think of creating a control set of answers. I could tell the mdoel this is the perfect answer basis this rate others. But I did not because it would need support from a lot of people- creating perfect answer, which still can have a bias. I read a few answers and found most of them decent except math. So I tried to find which model&amp;#39;s evaluation scores were closest to the average to determine a decent model for evaluation tasks(check last image)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Fun Observations&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Some models create &amp;lt;think&amp;gt; tags for questions, answers and even while evaluation as output&lt;/li&gt;\\n&lt;li&gt;Score inflation is real: Mistral, Qwen3, and LLaMA 3.1 8B overrate themselves&lt;/li&gt;\\n&lt;li&gt;Score formats vary wildly (text explanations vs. plain numbers)&lt;/li&gt;\\n&lt;li&gt;Speed isn’t everything – some slower models gave much higher quality answers&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Best Performers (My Picks)&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Task&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Best Model&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Why&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;/td&gt;\\n&lt;td colspan=\\"2\\"  align=\\"left\\"&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Question Gen&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;LLaMA 3.2 1B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Fast &amp;amp; relevant&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Answer Gen&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Gemma3:1b&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Fast, accurate&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Evaluation&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;LLaMA 3.2 3B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Generates numerical scores and evaluations closest to model average&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;h1&gt;Worst Surprises&lt;/h1&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Task&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Model&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Problem&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;/td&gt;\\n&lt;td colspan=\\"2\\"  align=\\"left\\"&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Question Gen&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Qwen3 4B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Took 486s to generate 1 question&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Answer Gen&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;LLaMA 3.1 8B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Slow&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Evaluation&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;DeepSeek-R1 1.5B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Inconsistent, skipped scores&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Screenshots Galore&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I’m adding screenshots of:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Questions generation&lt;/li&gt;\\n&lt;li&gt;Answer comparisons&lt;/li&gt;\\n&lt;li&gt;Evaluation outputs&lt;/li&gt;\\n&lt;li&gt;Token/sec charts&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Takeaways&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;You &lt;strong&gt;can&lt;/strong&gt; run decent LLMs locally on M1 Air (8GB) – if you pick the right ones&lt;/li&gt;\\n&lt;li&gt;Model size ≠ performance. Bigger isn&amp;#39;t always better.&lt;/li&gt;\\n&lt;li&gt;5 Models have a self bais, they rate their own answers higher than average scores. attaching screen shot of a table. Diagonal is their own evaluation, last column is average.&lt;/li&gt;\\n&lt;li&gt;Models&amp;#39; evaluation has high variance! Every model has a unique distribution of the scores it gave.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Post questions if you have any, I will try to answer.&lt;/p&gt;\\n\\n&lt;p&gt;Happy to share more data if you need.&lt;/p&gt;\\n\\n&lt;p&gt;Open to collaborate on interesting projects!  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.reddit.com/gallery/1lmfiu9","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?auto=webp&amp;s=a10cedac67e9fa4bc062f13cc4ef20dafb782493","width":576,"height":462},"resolutions":[{"url":"https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0ba456f772896d13d26a433eb814c01465159c5","width":108,"height":86},{"url":"https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4cd893d5d514dea0401f679947934b06ac7b1f8","width":216,"height":173},{"url":"https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d68c4413ac33077ccb1f955a9767daec572c1df8","width":320,"height":256}],"variants":{},"id":"lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lmfiu9","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"irodov4030","discussion_type":null,"num_comments":104,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/","stickied":false,"url":"https://www.reddit.com/gallery/1lmfiu9","subreddit_subscribers":492929,"created_utc":1751090266,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07dnpn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"irodov4030","can_mod_post":false,"created_utc":1751095077,"send_replies":true,"parent_id":"t1_n07cde5","score":6,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you for the feedback!\\n\\nSo I did this in 3 steps, 1 for generaiting questions, 2nd for answering and the 3rd for evaluating  \\nFor every step, code was a nested loop on all models and topics.  \\nFor all steps my laptop was plugged in with no background apps and no internet.\\n\\n  \\nI agree on running 2 large models to test all results. I will try to do the evaluation again","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07dnpn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you for the feedback!&lt;/p&gt;\\n\\n&lt;p&gt;So I did this in 3 steps, 1 for generaiting questions, 2nd for answering and the 3rd for evaluating&lt;br/&gt;\\nFor every step, code was a nested loop on all models and topics.&lt;br/&gt;\\nFor all steps my laptop was plugged in with no background apps and no internet.&lt;/p&gt;\\n\\n&lt;p&gt;I agree on running 2 large models to test all results. I will try to do the evaluation again&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07dnpn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751095077,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n07cde5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1751094361,"send_replies":true,"parent_id":"t3_1lmfiu9","score":24,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for these details. Looking at these it seems to be that there's a flaw in the time measurement somewhere, and the scoring is potentially also not as good as it looks.\\n\\n&gt;DeepSeek got faster answering *its own* questions (80 tokens/s vs. avg 40 tokens/s)\\n\\nYou didn't specify using a speculative decoding model (probably wouldn't have fit the 8GB in addition to the model anyway). The LLM answer generation speed is somewhat constant - at least at your 4k context length. If it suddenly generated tokens at twice the speed then there must be an oversight in execution (swapping to system RAM, background tasks, incorrect timing, measuring prompt processing time together with inference time, wrong model, etc).\\n\\n&gt;Qwen3 4B took 8+ mins to generate a single Math question!\\n\\nAt 6 tokens per second that's too slow compared to the other models. You might not have run an apples to apples comparison here. Maybe not all models were quantized in the same format?\\n\\nSpeaking of quantization, this hurts the output quality quite a bit:\\n\\n&gt;os.environ\\\\[\\"OLLAMA\\\\_KV\\\\_CACHE\\\\_TYPE\\"\\\\] = \\"q4\\\\_0\\"\\n\\nIt's OKish to set the V cache to Q4, but the K cache [should stay at least on Q8](https://www.reddit.com/r/LocalLLaMA/comments/1iuw1kx/comment/me15i32/?context=3).\\n\\n&gt;Each model ... Evaluated every answer (including their own)\\n\\nIt would've been helpful for assessing the scoring to let two large, high quality models generate a few sets of questions and also perform a few evaluation runs over the output of the small models. By running multiple sets with the smaller models you could also measure the variance in generation quality - what if a model in your single run randomly performed pretty well, while another randomly generated low quality output?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07cde5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for these details. Looking at these it seems to be that there&amp;#39;s a flaw in the time measurement somewhere, and the scoring is potentially also not as good as it looks.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;DeepSeek got faster answering &lt;em&gt;its own&lt;/em&gt; questions (80 tokens/s vs. avg 40 tokens/s)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;You didn&amp;#39;t specify using a speculative decoding model (probably wouldn&amp;#39;t have fit the 8GB in addition to the model anyway). The LLM answer generation speed is somewhat constant - at least at your 4k context length. If it suddenly generated tokens at twice the speed then there must be an oversight in execution (swapping to system RAM, background tasks, incorrect timing, measuring prompt processing time together with inference time, wrong model, etc).&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Qwen3 4B took 8+ mins to generate a single Math question!&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;At 6 tokens per second that&amp;#39;s too slow compared to the other models. You might not have run an apples to apples comparison here. Maybe not all models were quantized in the same format?&lt;/p&gt;\\n\\n&lt;p&gt;Speaking of quantization, this hurts the output quality quite a bit:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;os.environ[&amp;quot;OLLAMA_KV_CACHE_TYPE&amp;quot;] = &amp;quot;q4_0&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s OKish to set the V cache to Q4, but the K cache &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1iuw1kx/comment/me15i32/?context=3\\"&gt;should stay at least on Q8&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Each model ... Evaluated every answer (including their own)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It would&amp;#39;ve been helpful for assessing the scoring to let two large, high quality models generate a few sets of questions and also perform a few evaluation runs over the output of the small models. By running multiple sets with the smaller models you could also measure the variance in generation quality - what if a model in your single run randomly performed pretty well, while another randomly generated low quality output?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07cde5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094361,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08tg3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"irodov4030","can_mod_post":false,"created_utc":1751120285,"send_replies":true,"parent_id":"t1_n07zml5","score":8,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will include it in the next.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08tg3g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will include it in the next.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08tg3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751120285,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n07zml5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ultimatepritam","can_mod_post":false,"created_utc":1751107903,"send_replies":true,"parent_id":"t3_1lmfiu9","score":19,"author_fullname":"t2_h0p8bff","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please do humanity another favour and include Gemma 3N results as well 🥹","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07zml5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please do humanity another favour and include Gemma 3N results as well 🥹&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07zml5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751107903,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f7d90d62-c910-11ed-b26b-aa0bc6a7ec55","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0egye5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0cier1","score":1,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unfortunately yes.\\n\\nIt helps get higher benchmark results if you don't mind waiting for those results and also running the risk of the model getting stuck in a reasoning loop. I feel it's a hack that we might do away with soon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0egye5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately yes.&lt;/p&gt;\\n\\n&lt;p&gt;It helps get higher benchmark results if you don&amp;#39;t mind waiting for those results and also running the risk of the model getting stuck in a reasoning loop. I feel it&amp;#39;s a hack that we might do away with soon.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0egye5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751202286,"author_flair_text":null,"treatment_tags":[],"created_utc":1751202286,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cier1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"balder1993","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07dio9","score":1,"author_fullname":"t2_cibet99ap","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don’t know if it’s just my impression, but this “thinking” thing seems kinda useless for most answers.","edited":1751208953,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0cier1","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 13B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t know if it’s just my impression, but this “thinking” thing seems kinda useless for most answers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0cier1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751165579,"author_flair_text":"Llama 13B","treatment_tags":[],"created_utc":1751165579,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07dio9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1751094998,"send_replies":true,"parent_id":"t1_n077onj","score":25,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma 3 4B is one heck of a model with excellent multilingual understanding given the size.\\n\\nThe Qwen 3 models have become a disappointment for me. They spend too many tokens ruminating until it's not worth waiting for a better answer when Gemma gives something good enough in a quarter of the time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07dio9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3 4B is one heck of a model with excellent multilingual understanding given the size.&lt;/p&gt;\\n\\n&lt;p&gt;The Qwen 3 models have become a disappointment for me. They spend too many tokens ruminating until it&amp;#39;s not worth waiting for a better answer when Gemma gives something good enough in a quarter of the time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07dio9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094998,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07aoq0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751093438,"send_replies":true,"parent_id":"t1_n077onj","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yup","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07aoq0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yup&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07aoq0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093438,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n077onj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"horse_tinder","can_mod_post":false,"created_utc":1751091820,"send_replies":true,"parent_id":"t3_1lmfiu9","score":31,"author_fullname":"t2_1aqzktph67","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma is good around all the tasks in general","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n077onj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma is good around all the tasks in general&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n077onj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751091820,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08tbk8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751120243,"send_replies":true,"parent_id":"t1_n07mjv9","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks! I will check out 8k for other tasks.\\n\\nBut I believe it will still generates a lot of &lt;think&gt; text","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08tbk8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks! I will check out 8k for other tasks.&lt;/p&gt;\\n\\n&lt;p&gt;But I believe it will still generates a lot of &amp;lt;think&amp;gt; text&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08tbk8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751120243,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07mjv9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mysterious_Finish543","can_mod_post":false,"created_utc":1751100300,"send_replies":true,"parent_id":"t3_1lmfiu9","score":7,"author_fullname":"t2_gbx2bcdvl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think the reason the reasoning models like DeepSeek-R1-Distill-Qwen-1.5B is doing poorly is the short context length.\\n\\nReasoning models will often need 8K to perform reliability without being cut off / entering a loop.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07mjv9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the reason the reasoning models like DeepSeek-R1-Distill-Qwen-1.5B is doing poorly is the short context length.&lt;/p&gt;\\n\\n&lt;p&gt;Reasoning models will often need 8K to perform reliability without being cut off / entering a loop.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07mjv9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751100300,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08tddt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751120260,"send_replies":true,"parent_id":"t1_n07eeb2","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yup! 😅","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08tddt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yup! 😅&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08tddt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751120260,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n07eeb2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chub79","can_mod_post":false,"created_utc":1751095492,"send_replies":true,"parent_id":"t3_1lmfiu9","score":6,"author_fullname":"t2_36n3l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Qwen3 4B generates 2–3x more tokens per answer\\n\\nIt's such a bloody chatty one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07eeb2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Qwen3 4B generates 2–3x more tokens per answer&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s such a bloody chatty one.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07eeb2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751095492,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cf04p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0c1hpd","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"interesting. thanks! I will check it out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cf04p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;interesting. thanks! I will check it out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0cf04p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751164183,"author_flair_text":null,"treatment_tags":[],"created_utc":1751164183,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0c1hpd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"scipi0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0bah20","score":3,"author_fullname":"t2_4adp1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"From the announcement (https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/):\\n\\n&gt;While the Gemma 3n E2B and E4B models have a total parameter count of 5B and 8B respectively, PLE allows a significant portion of these parameters (the embeddings associated with each layer) to be loaded and computed efficiently on the CPU. This means only the core transformer weights (approximately 2B for E2B and 4B for E4B) need to sit in the typically more constrained accelerator memory (VRAM).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0c1hpd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From the announcement (&lt;a href=\\"https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/):\\"&gt;https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/):&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;While the Gemma 3n E2B and E4B models have a total parameter count of 5B and 8B respectively, PLE allows a significant portion of these parameters (the embeddings associated with each layer) to be loaded and computed efficiently on the CPU. This means only the core transformer weights (approximately 2B for E2B and 4B for E4B) need to sit in the typically more constrained accelerator memory (VRAM).&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0c1hpd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751158790,"author_flair_text":null,"treatment_tags":[],"created_utc":1751158790,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0eyrbw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dkaow","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It will work on 16GB RAM","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0eyrbw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will work on 16GB RAM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0eyrbw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751208535,"author_flair_text":null,"treatment_tags":[],"created_utc":1751208535,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dkaow","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Randommaggy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0bah20","score":1,"author_fullname":"t2_t8a2k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can run it and check the actual memory consumption on my 16GB M1 Air.   \\nI just have to dig it out of my pile of laptops.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0dkaow","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can run it and check the actual memory consumption on my 16GB M1 Air.&lt;br/&gt;\\nI just have to dig it out of my pile of laptops.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0dkaow/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184915,"author_flair_text":null,"treatment_tags":[],"created_utc":1751184915,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0bah20","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751148846,"send_replies":true,"parent_id":"t1_n087zu8","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/v1itq1wisq9f1.png?width=1678&amp;format=png&amp;auto=webp&amp;s=254ebd85604af3895a8decf0c3d1500317c05008\\n\\nit looks almost impossible for 8GB RAM.\\n\\nAll models I tested are under 5GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bah20","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/v1itq1wisq9f1.png?width=1678&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=254ebd85604af3895a8decf0c3d1500317c05008\\"&gt;https://preview.redd.it/v1itq1wisq9f1.png?width=1678&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=254ebd85604af3895a8decf0c3d1500317c05008&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;it looks almost impossible for 8GB RAM.&lt;/p&gt;\\n\\n&lt;p&gt;All models I tested are under 5GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0bah20/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148846,"media_metadata":{"v1itq1wisq9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":91,"x":108,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=26cee1a0cd68a341e72026b694171b2aefb65afa"},{"y":183,"x":216,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a2849537a3f4f3151c075689c0980f0034f53e3"},{"y":272,"x":320,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cef1e0addee008f42763156437f768c5fcad67d6"},{"y":544,"x":640,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=296948129dc1fe429aec067a8a02fd8a9d8ec3cf"},{"y":816,"x":960,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f58f240c5e522bf73c60531f42bfeea219e89b76"},{"y":919,"x":1080,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=635b2c52071e84a4d80e7219cc2ae8b77eb69504"}],"s":{"y":1428,"x":1678,"u":"https://preview.redd.it/v1itq1wisq9f1.png?width=1678&amp;format=png&amp;auto=webp&amp;s=254ebd85604af3895a8decf0c3d1500317c05008"},"id":"v1itq1wisq9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n087zu8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Randommaggy","can_mod_post":false,"created_utc":1751111986,"send_replies":true,"parent_id":"t3_1lmfiu9","score":3,"author_fullname":"t2_t8a2k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried Gemma 3n?\\nDamn capable for it's size in my personal testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n087zu8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried Gemma 3n?\\nDamn capable for it&amp;#39;s size in my personal testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n087zu8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751111986,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07e67o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllanSundry2020","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07b784","score":3,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma3n also now on thiis hardware type","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07e67o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma3n also now on thiis hardware type&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07e67o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751095365,"author_flair_text":null,"treatment_tags":[],"created_utc":1751095365,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n07b784","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nonomomomo2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07azh8","score":4,"author_fullname":"t2_8k6kwn2y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s great, thanks for sharing your test results and experience!\\n\\nEdit: why TF would someone downvote me for thanking OP for answering my question?","edited":1751100618,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n07b784","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s great, thanks for sharing your test results and experience!&lt;/p&gt;\\n\\n&lt;p&gt;Edit: why TF would someone downvote me for thanking OP for answering my question?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07b784/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093716,"author_flair_text":null,"treatment_tags":[],"created_utc":1751093716,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bq3g3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thatisverytrue54321","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09jqzf","score":1,"author_fullname":"t2_behl6etu","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you give an example?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0bq3g3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you give an example?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmfiu9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0bq3g3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751154496,"author_flair_text":null,"treatment_tags":[],"created_utc":1751154496,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09jqzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09g7kr","score":1,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, other than the vision, I really dont like gemma, if it hasnt been asked before, gemma will do very poorly.","edited":false,"author_flair_css_class":null,"name":"t1_n09jqzf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, other than the vision, I really dont like gemma, if it hasnt been asked before, gemma will do very poorly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmfiu9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09jqzf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751128685,"author_flair_text":null,"collapsed":false,"created_utc":1751128685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09g7kr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n08gxts","score":3,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Let me try hallucination tests.\\n\\n  \\nGemma is weird though. It has a bias for its own answers\\n\\nAnother interesting case- \\n\\nThis is the question: In a right triangle, side lengths in centimeters satisfy a, b, and c (where a² + b² = c²). If the circumference of the circumcircle is 8π cm, find the ratio of side length 'a' to the hypotenuse 'c'. Express your final answer as a simplified fraction.\\n\\nDeepseek answered to a math problem that answer can not be determined(this is incorrect), it got 0 score by qwen3:1.7b, mistral:7b and qwen2.5vl:3b while gemma3:1b gave it 10 😅","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09g7kr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let me try hallucination tests.&lt;/p&gt;\\n\\n&lt;p&gt;Gemma is weird though. It has a bias for its own answers&lt;/p&gt;\\n\\n&lt;p&gt;Another interesting case- &lt;/p&gt;\\n\\n&lt;p&gt;This is the question: In a right triangle, side lengths in centimeters satisfy a, b, and c (where a² + b² = c²). If the circumference of the circumcircle is 8π cm, find the ratio of side length &amp;#39;a&amp;#39; to the hypotenuse &amp;#39;c&amp;#39;. Express your final answer as a simplified fraction.&lt;/p&gt;\\n\\n&lt;p&gt;Deepseek answered to a math problem that answer can not be determined(this is incorrect), it got 0 score by qwen3:1.7b, mistral:7b and qwen2.5vl:3b while gemma3:1b gave it 10 😅&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09g7kr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751127544,"author_flair_text":null,"treatment_tags":[],"created_utc":1751127544,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n08gxts","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07azh8","score":1,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do a hallucination test, or out of distribution questions with Gemma, it breaks down very fast.\\n\\nGemma is extremely overfit imo.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n08gxts","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do a hallucination test, or out of distribution questions with Gemma, it breaks down very fast.&lt;/p&gt;\\n\\n&lt;p&gt;Gemma is extremely overfit imo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08gxts/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751115728,"author_flair_text":null,"treatment_tags":[],"created_utc":1751115728,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07azh8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751093601,"send_replies":true,"parent_id":"t1_n078iwq","score":3,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would pick gemma or llama 3B\\n\\nAnd I still would want to test qven 7b with tighter prompts again. I want to reinforce controls and see if it performs better.\\n\\nFor this test I did do it but I mean reinforcing multiple times for the next test","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07azh8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would pick gemma or llama 3B&lt;/p&gt;\\n\\n&lt;p&gt;And I still would want to test qven 7b with tighter prompts again. I want to reinforce controls and see if it performs better.&lt;/p&gt;\\n\\n&lt;p&gt;For this test I did do it but I mean reinforcing multiple times for the next test&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07azh8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093601,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09dha4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vibjelo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n08kmaf","score":1,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; In reality, you get as good as you can at one, passable at one or two more, and try to do everything you can in the language you’re best at. \\n\\nWell, I guess we just have two very different perspectives then, because I'd say that's fine for a junior developer perhaps but if you want to be proficient in programming then your knowledge should be diverse enough to be able to jump to new languages without breaking much sweat beyond reading up on the specific interfaces when you need them. Most mainstream languages are more similar than they're different today, broadly speaking. \\n\\n&gt; The same is true for applying local models in the wild. Multiple models are ideal. In reality, ain’t nobody got time for that.\\n\\nIn reality, the people who take care to achieve accuracy and correctness usually get their value back. Trying out a new local model for me involves adding it to the list of currently \\"under test\\" models and start the benchmark run, later read through the results. Only because I spent the time to setup my own testing benchmarks for the stuff I use LLMs for, so I can actually see if new model is better or not.\\n\\nIf you're relying on local models for anything of importance, then you also need to have testing infrastructure around the use cases you care about. Otherwise you'll be stuck in a loop of asking in random places \\"What is the best all arounder?\\" forever, because it changes, quickly, and is very subjective ultimately, depending on prompting, data, and so much more. If you spend some time setting this up today, you'll save yourself many hours of manual testing in the future.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09dha4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;In reality, you get as good as you can at one, passable at one or two more, and try to do everything you can in the language you’re best at. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Well, I guess we just have two very different perspectives then, because I&amp;#39;d say that&amp;#39;s fine for a junior developer perhaps but if you want to be proficient in programming then your knowledge should be diverse enough to be able to jump to new languages without breaking much sweat beyond reading up on the specific interfaces when you need them. Most mainstream languages are more similar than they&amp;#39;re different today, broadly speaking. &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The same is true for applying local models in the wild. Multiple models are ideal. In reality, ain’t nobody got time for that.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;In reality, the people who take care to achieve accuracy and correctness usually get their value back. Trying out a new local model for me involves adding it to the list of currently &amp;quot;under test&amp;quot; models and start the benchmark run, later read through the results. Only because I spent the time to setup my own testing benchmarks for the stuff I use LLMs for, so I can actually see if new model is better or not.&lt;/p&gt;\\n\\n&lt;p&gt;If you&amp;#39;re relying on local models for anything of importance, then you also need to have testing infrastructure around the use cases you care about. Otherwise you&amp;#39;ll be stuck in a loop of asking in random places &amp;quot;What is the best all arounder?&amp;quot; forever, because it changes, quickly, and is very subjective ultimately, depending on prompting, data, and so much more. If you spend some time setting this up today, you&amp;#39;ll save yourself many hours of manual testing in the future.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09dha4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126672,"author_flair_text":null,"treatment_tags":[],"created_utc":1751126672,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08kmaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nonomomomo2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07r7dr","score":2,"author_fullname":"t2_8k6kwn2y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The value of my question is that many of us in the field have neither the time nor inclination to install and use multiple local models in our workflow. \\n\\nYes, in an ideal world I’d learn every programming language and use the best one for the task at hand. \\n\\nIn reality, you get as good as you can at one, passable at one or two more, and try to do everything you can in the language you’re best at. \\n\\nThe same is true for applying local models in the wild. Multiple models are ideal. In reality, ain’t nobody got time for that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n08kmaf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The value of my question is that many of us in the field have neither the time nor inclination to install and use multiple local models in our workflow. &lt;/p&gt;\\n\\n&lt;p&gt;Yes, in an ideal world I’d learn every programming language and use the best one for the task at hand. &lt;/p&gt;\\n\\n&lt;p&gt;In reality, you get as good as you can at one, passable at one or two more, and try to do everything you can in the language you’re best at. &lt;/p&gt;\\n\\n&lt;p&gt;The same is true for applying local models in the wild. Multiple models are ideal. In reality, ain’t nobody got time for that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08kmaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751117140,"author_flair_text":null,"treatment_tags":[],"created_utc":1751117140,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n07r7dr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vibjelo","can_mod_post":false,"created_utc":1751103096,"send_replies":true,"parent_id":"t1_n078iwq","score":1,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Still, which would you pick as your preferred all arounder?\\n\\nIt's a bit like \\"all arounder\\" programming languages, sure, they'll all work for everything, and people have their personal preference and subjective opinions about it, but is that really important to know? Yes, Norvig's favorite programming language is Python, but why that matters? Isn't it more important to be able to evaluate which language is right for a problem?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07r7dr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Still, which would you pick as your preferred all arounder?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s a bit like &amp;quot;all arounder&amp;quot; programming languages, sure, they&amp;#39;ll all work for everything, and people have their personal preference and subjective opinions about it, but is that really important to know? Yes, Norvig&amp;#39;s favorite programming language is Python, but why that matters? Isn&amp;#39;t it more important to be able to evaluate which language is right for a problem?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07r7dr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751103096,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n078iwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nonomomomo2","can_mod_post":false,"created_utc":1751092268,"send_replies":true,"parent_id":"t3_1lmfiu9","score":3,"author_fullname":"t2_8k6kwn2y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So if you had to pick just one to run, which would it be?\\n\\nYada yada “task dependence” etc, we all get it. \\n\\nStill, which would you pick as your preferred all arounder?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n078iwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So if you had to pick just one to run, which would it be?&lt;/p&gt;\\n\\n&lt;p&gt;Yada yada “task dependence” etc, we all get it. &lt;/p&gt;\\n\\n&lt;p&gt;Still, which would you pick as your preferred all arounder?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n078iwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092268,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bajan","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751148868,"send_replies":true,"parent_id":"t1_n08asnf","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will try it. thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bajan","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will try it. thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0bajan/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148868,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n08asnf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Source-9920","can_mod_post":false,"created_utc":1751113221,"send_replies":true,"parent_id":"t3_1lmfiu9","score":4,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no phi4 is a heresy, imo the best out of all of these","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08asnf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no phi4 is a heresy, imo the best out of all of these&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08asnf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751113221,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09duqz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751126790,"send_replies":true,"parent_id":"t1_n08zz96","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So I asked all models to create questions, every model answered every question. and every answer was evaluated by every model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09duqz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I asked all models to create questions, every model answered every question. and every answer was evaluated by every model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09duqz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126790,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09e559","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751126883,"send_replies":true,"parent_id":"t1_n08zz96","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=2228&amp;format=png&amp;auto=webp&amp;s=3bf5a32b91cddbefc99b592ddf224598c99a4c38\\n\\nThe diagonal has score for self evaluations and last column has average scores \\n\\nGreen has no bias. orange has bias for own answers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09e559","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/zyt8vmt2zo9f1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3bf5a32b91cddbefc99b592ddf224598c99a4c38\\"&gt;https://preview.redd.it/zyt8vmt2zo9f1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3bf5a32b91cddbefc99b592ddf224598c99a4c38&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The diagonal has score for self evaluations and last column has average scores &lt;/p&gt;\\n\\n&lt;p&gt;Green has no bias. orange has bias for own answers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09e559/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126883,"media_metadata":{"zyt8vmt2zo9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":29,"x":108,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=57578df739d7596ebd6df086975cff3fa89b1906"},{"y":58,"x":216,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1edc11c45b7f928102d6f6c47c05ac4f657b3a87"},{"y":86,"x":320,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e370717dbb7c3cb296486b0b97d1fbed87024ed"},{"y":172,"x":640,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4569e61f56cc79bf75f9d3b217755a557b90f714"},{"y":259,"x":960,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4e6d8dc40f7663a8ab96cab63fde9823f9940da"},{"y":291,"x":1080,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68fc89fb7327e0708b0a735def6ccde69f96bbbc"}],"s":{"y":602,"x":2228,"u":"https://preview.redd.it/zyt8vmt2zo9f1.png?width=2228&amp;format=png&amp;auto=webp&amp;s=3bf5a32b91cddbefc99b592ddf224598c99a4c38"},"id":"zyt8vmt2zo9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08zz96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Bid-1264","can_mod_post":false,"created_utc":1751122408,"send_replies":true,"parent_id":"t3_1lmfiu9","score":2,"author_fullname":"t2_1sfunm5n8s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow, this is seriously impressive, especially on just 8GB RAM! I’ve struggled to run anything over 3B smoothly on my own M1.\\n\\nThanks for the detailed breakdown. The self-evaluation part is really interesting, especially the bias detection and score inflation. I’m curious if you tried mixing models, like generating questions with one and evaluating with another.\\n\\nAlso, if you ever publish the full dataset or want help building a benchmark UI around it, I’d be happy to contribute!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08zz96","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, this is seriously impressive, especially on just 8GB RAM! I’ve struggled to run anything over 3B smoothly on my own M1.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for the detailed breakdown. The self-evaluation part is really interesting, especially the bias detection and score inflation. I’m curious if you tried mixing models, like generating questions with one and evaluating with another.&lt;/p&gt;\\n\\n&lt;p&gt;Also, if you ever publish the full dataset or want help building a benchmark UI around it, I’d be happy to contribute!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08zz96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122408,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08zud9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751122364,"send_replies":true,"parent_id":"t1_n07ei35","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/y2e7i8idlo9f1.png?width=2904&amp;format=png&amp;auto=webp&amp;s=f2ba190f757ecc5c4b6d5dca413e259e4cdafd05\\n\\nThese were the questions generated. \\n\\nllama 3.2 1B was quicker than  llama 3.1 8B in generating questions. I am not rating the quality of the questions specifically but they look similar","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08zud9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/y2e7i8idlo9f1.png?width=2904&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2ba190f757ecc5c4b6d5dca413e259e4cdafd05\\"&gt;https://preview.redd.it/y2e7i8idlo9f1.png?width=2904&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2ba190f757ecc5c4b6d5dca413e259e4cdafd05&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;These were the questions generated. &lt;/p&gt;\\n\\n&lt;p&gt;llama 3.2 1B was quicker than  llama 3.1 8B in generating questions. I am not rating the quality of the questions specifically but they look similar&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08zud9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122364,"media_metadata":{"y2e7i8idlo9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":28,"x":108,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53bfb4ccaa5d2b375e25970563cec2def1549a52"},{"y":57,"x":216,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cc68850a633aa01591395b411f9785da91bdae5"},{"y":85,"x":320,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b09076d2d7a8120c9e39d8970871d447ad9156f"},{"y":171,"x":640,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f715ab38bc4caba952747e4021650759a6f3b98f"},{"y":257,"x":960,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=77ae5f3f78090d5a203139ab88e984892ae1180c"},{"y":289,"x":1080,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf20dd561699521e6e69d3266f233f0c408ff7c7"}],"s":{"y":778,"x":2904,"u":"https://preview.redd.it/y2e7i8idlo9f1.png?width=2904&amp;format=png&amp;auto=webp&amp;s=f2ba190f757ecc5c4b6d5dca413e259e4cdafd05"},"id":"y2e7i8idlo9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n090auh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751122512,"send_replies":true,"parent_id":"t1_n07ei35","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=d21585a24fd6f92c343d22be455b257c68c9d0e0\\n\\non LLMs evaluating text numerically\\n\\nllama3.1:8b, llama3.2:3b and qwen2.5vl:3b do a decent job! some models fail miserably\\n\\nThe prompt to evaluate the answers was same. I was running a nested loop for model and topics to evaluate all answers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n090auh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5n5v2ahxlo9f1.png?width=2406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d21585a24fd6f92c343d22be455b257c68c9d0e0\\"&gt;https://preview.redd.it/5n5v2ahxlo9f1.png?width=2406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d21585a24fd6f92c343d22be455b257c68c9d0e0&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;on LLMs evaluating text numerically&lt;/p&gt;\\n\\n&lt;p&gt;llama3.1:8b, llama3.2:3b and qwen2.5vl:3b do a decent job! some models fail miserably&lt;/p&gt;\\n\\n&lt;p&gt;The prompt to evaluate the answers was same. I was running a nested loop for model and topics to evaluate all answers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n090auh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122512,"media_metadata":{"5n5v2ahxlo9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":61,"x":108,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0a6c4578417aa97a77e0c6259ed648946819aa2"},{"y":122,"x":216,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=64fcca9a3199c25a628de72bd14e72745a34e74a"},{"y":181,"x":320,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ee37bc7492c218d301a0678f3910f60a8d132584"},{"y":362,"x":640,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=35b51e23c44da283a9e1abf402dd456ecbe6afd8"},{"y":543,"x":960,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=40f97f4d30ffe1630024eaa8bc84d72a8d182b6a"},{"y":611,"x":1080,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01b01c55fb9875782f1b157dce569734cd8e0fbf"}],"s":{"y":1362,"x":2406,"u":"https://preview.redd.it/5n5v2ahxlo9f1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=d21585a24fd6f92c343d22be455b257c68c9d0e0"},"id":"5n5v2ahxlo9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07ei35","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LevianMcBirdo","can_mod_post":false,"created_utc":1751095553,"send_replies":true,"parent_id":"t3_1lmfiu9","score":2,"author_fullname":"t2_cw9f6o0r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I somehow really doubt that llama 3.2 1B beats 3.1 8B, except asking knowledge about very current stuff. Now, I don't know your benchmark questions and maybe it's the best for your usecase, but the relax small models being this good doesn't really track with my usage experience. They are great for their size though.   \\nMaybe this just answers us the question if llms should numerically evaluate texts","edited":1751095733,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ei35","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I somehow really doubt that llama 3.2 1B beats 3.1 8B, except asking knowledge about very current stuff. Now, I don&amp;#39;t know your benchmark questions and maybe it&amp;#39;s the best for your usecase, but the relax small models being this good doesn&amp;#39;t really track with my usage experience. They are great for their size though.&lt;br/&gt;\\nMaybe this just answers us the question if llms should numerically evaluate texts&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ei35/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751095553,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0916e5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751122793,"send_replies":true,"parent_id":"t1_n07ld93","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I did not specifically check swap. GPU% in activity monitor was 85+%","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0916e5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did not specifically check swap. GPU% in activity monitor was 85+%&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0916e5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122793,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0hlq77","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tipop","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0gpflm","score":1,"author_fullname":"t2_6562x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe channel some of the energy away from being snarky and into using the right terms for things so you don’t confuse other people, yeah? HDs and SSDs are two different things. I was thinking “Why is he talking about hard drives? I don’t think many people even use those anymore.”","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0hlq77","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe channel some of the energy away from being snarky and into using the right terms for things so you don’t confuse other people, yeah? HDs and SSDs are two different things. I was thinking “Why is he talking about hard drives? I don’t think many people even use those anymore.”&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0hlq77/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751239174,"author_flair_text":null,"treatment_tags":[],"created_utc":1751239174,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0gpflm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-Dog6141","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07pijm","score":1,"author_fullname":"t2_4uyy18ifx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ssd of course this is 2025 not 2015 right","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0gpflm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ssd of course this is 2025 not 2015 right&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0gpflm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751228356,"author_flair_text":null,"treatment_tags":[],"created_utc":1751228356,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07pijm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tipop","can_mod_post":false,"created_utc":1751102074,"send_replies":true,"parent_id":"t1_n07ld93","score":1,"author_fullname":"t2_6562x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"By “HD” do you mean SSD? Or are you specifically referring to spinning hard drives?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07pijm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By “HD” do you mean SSD? Or are you specifically referring to spinning hard drives?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07pijm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751102074,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07ld93","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-Dog6141","can_mod_post":false,"created_utc":1751099599,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_4uyy18ifx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"nice test thanks for sharing, have you been able to determine how much you used your HD swap memory when loading the 7b/8b models, do note that using swap for LLM is not recommended because you will rapidly deteriorate the HD","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ld93","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nice test thanks for sharing, have you been able to determine how much you used your HD swap memory when loading the 7b/8b models, do note that using swap for LLM is not recommended because you will rapidly deteriorate the HD&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ld93/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751099599,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0917iy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751122802,"send_replies":true,"parent_id":"t1_n07nfnu","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0917iy","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0917iy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122802,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07nfnu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"created_utc":1751100826,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_c2f558x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I like your plot, and I don't even own a Mac. Congrats, and thanks for the insight!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07nfnu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like your plot, and I don&amp;#39;t even own a Mac. Congrats, and thanks for the insight!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07nfnu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751100826,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08t1pn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"send_replies":true,"parent_id":"t1_n08omcf","score":2,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure. Try the Prompt Maker\\nhttps://github.com/adamjen/Prompt_Maker\\n\\nLet me know what you think.","edited":false,"author_flair_css_class":null,"name":"t1_n08t1pn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure. Try the Prompt Maker\\n&lt;a href=\\"https://github.com/adamjen/Prompt_Maker\\"&gt;https://github.com/adamjen/Prompt_Maker&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Let me know what you think.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmfiu9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08t1pn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751120152,"author_flair_text":null,"collapsed":false,"created_utc":1751120152,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n08omcf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmttyji","can_mod_post":false,"send_replies":true,"parent_id":"t1_n089rnk","score":1,"author_fullname":"t2_1deiadfhb1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Prompt enchaner\\n\\nHi, could you please provide more info on this? My prompts are still trash. Looking for offline solution to improve my prompts. Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08omcf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Prompt enchaner&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Hi, could you please provide more info on this? My prompts are still trash. Looking for offline solution to improve my prompts. Thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08omcf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751118622,"author_flair_text":null,"treatment_tags":[],"created_utc":1751118622,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n089rnk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0861t1","score":2,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's what I used 8b for. Prompt enchaner! Perfect!. Have a little chat. Excellent...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n089rnk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s what I used 8b for. Prompt enchaner! Perfect!. Have a little chat. Excellent...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n089rnk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751112773,"author_flair_text":null,"treatment_tags":[],"created_utc":1751112773,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0861t1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1751111101,"send_replies":true,"parent_id":"t1_n07ozqu","score":0,"author_fullname":"t2_79slapln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"this, as m1 8gb enjoyer myself i found these 'mobile' models are still in their proof of concept phase  \\nif qwen3:235B online struggle for 5+ minutes with my questions, why even bother with local 8B\\n\\n  \\nthey are fine for \\"take this part of the text and put it here\\" tasks, you can build stuff with them","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0861t1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this, as m1 8gb enjoyer myself i found these &amp;#39;mobile&amp;#39; models are still in their proof of concept phase&lt;br/&gt;\\nif qwen3:235B online struggle for 5+ minutes with my questions, why even bother with local 8B&lt;/p&gt;\\n\\n&lt;p&gt;they are fine for &amp;quot;take this part of the text and put it here&amp;quot; tasks, you can build stuff with them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0861t1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751111101,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n07ozqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1751101756,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah qwen3 8b is a beast. But it wouldn't be my choice for complex debugging that a 400b+ model struggles with","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ozqu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah qwen3 8b is a beast. But it wouldn&amp;#39;t be my choice for complex debugging that a 400b+ model struggles with&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ozqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751101756,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08npwm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n08ngmm","score":1,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah wasted opportunity, but their philosophy is that they open-source the models that they themselves use because they're not an LLM company, so they don't really care about being in the race beyond how they can use it for their primary ad business.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n08npwm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah wasted opportunity, but their philosophy is that they open-source the models that they themselves use because they&amp;#39;re not an LLM company, so they don&amp;#39;t really care about being in the race beyond how they can use it for their primary ad business.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08npwm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751118293,"author_flair_text":null,"treatment_tags":[],"created_utc":1751118293,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08ngmm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmttyji","can_mod_post":false,"created_utc":1751118200,"send_replies":true,"parent_id":"t1_n07ywct","score":2,"author_fullname":"t2_1deiadfhb1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I see Llama-3.1-8B still holding strong.\\n\\nMeta should've released upgraded model of this one during Llama-4 release. But they didn't release any tiny/small models at that time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08ngmm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I see Llama-3.1-8B still holding strong.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Meta should&amp;#39;ve released upgraded model of this one during Llama-4 release. But they didn&amp;#39;t release any tiny/small models at that time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08ngmm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751118200,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09bgsj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n093k7j","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09bgsj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09bgsj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126032,"author_flair_text":null,"treatment_tags":[],"created_utc":1751126032,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n093k7j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09293v","score":1,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you are right I missed the specs\\n\\nI love this kind of benchmarking by the way","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n093k7j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you are right I missed the specs&lt;/p&gt;\\n\\n&lt;p&gt;I love this kind of benchmarking by the way&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n093k7j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751123549,"author_flair_text":null,"treatment_tags":[],"created_utc":1751123549,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09293v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751123133,"send_replies":true,"parent_id":"t1_n07ywct","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"qwen3:8b is 5.2 GB. I did not expect it to run 8GB RAM.\\n\\nBut i will try","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09293v","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen3:8b is 5.2 GB. I did not expect it to run 8GB RAM.&lt;/p&gt;\\n\\n&lt;p&gt;But i will try&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09293v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751123133,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07ywct","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"created_utc":1751107515,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see Llama-3.1-8B still holding strong. Did you try Qwen3-8B without thinking?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ywct","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see Llama-3.1-8B still holding strong. Did you try Qwen3-8B without thinking?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ywct/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751107515,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n094w7c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751123964,"send_replies":true,"parent_id":"t1_n08bq4f","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/5neou74jqo9f1.png?width=2472&amp;format=png&amp;auto=webp&amp;s=42af548e1981e439846d4e7a672e037d7e5936f2\\n\\nIt creates decent questions. &lt;think&gt; tag is added","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n094w7c","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5neou74jqo9f1.png?width=2472&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=42af548e1981e439846d4e7a672e037d7e5936f2\\"&gt;https://preview.redd.it/5neou74jqo9f1.png?width=2472&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=42af548e1981e439846d4e7a672e037d7e5936f2&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It creates decent questions. &amp;lt;think&amp;gt; tag is added&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n094w7c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751123964,"media_metadata":{"5neou74jqo9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":53,"x":108,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=739afebc126bbf0e93a4e1175f8b9be67150f039"},{"y":106,"x":216,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=35a6cfefbce81cf2952be940e4634805143e2f1c"},{"y":158,"x":320,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=66ff30d39b17fab0cbe323e9182be2a79071799b"},{"y":316,"x":640,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a75fa5231895c65c71194cf1a12a2aa2bac3f1b9"},{"y":474,"x":960,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=82f24d10a1f62758089930f291b7bf2cffa4caed"},{"y":533,"x":1080,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b5b53daebe839e929f299ce07d166f0242d739eb"}],"s":{"y":1222,"x":2472,"u":"https://preview.redd.it/5neou74jqo9f1.png?width=2472&amp;format=png&amp;auto=webp&amp;s=42af548e1981e439846d4e7a672e037d7e5936f2"},"id":"5neou74jqo9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n099hqw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751125410,"send_replies":true,"parent_id":"t1_n08bq4f","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"answeres generated are a bit long. but I can post here if you want","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n099hqw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;answeres generated are a bit long. but I can post here if you want&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n099hqw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125410,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08bq4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FormalAd7367","can_mod_post":false,"created_utc":1751113620,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_e3wdiuasg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i ran Qwen 1.7b for a short time and thought it was too stupid for any use? what was your experience ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08bq4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i ran Qwen 1.7b for a short time and thought it was too stupid for any use? what was your experience ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08bq4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751113620,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09a1c5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751125581,"send_replies":true,"parent_id":"t1_n08c2do","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For tokens per sec, I just divided tokens created by time taken\\n\\n                start_time = time.time()\\n                response = ollama.chat.completions.create(model=model_name, messages=messages)\\n                end_time = time.time()\\n                \\n                question = response.choices[0].message.content.strip()\\n                duration = end_time - start_time\\n                token_usage = response.usage.total_tokens if hasattr(response, \\"usage\\") else None","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09a1c5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For tokens per sec, I just divided tokens created by time taken&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;            start_time = time.time()\\n            response = ollama.chat.completions.create(model=model_name, messages=messages)\\n            end_time = time.time()\\n\\n            question = response.choices[0].message.content.strip()\\n            duration = end_time - start_time\\n            token_usage = response.usage.total_tokens if hasattr(response, &amp;quot;usage&amp;quot;) else None\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09a1c5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125581,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09afj5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751125704,"send_replies":true,"parent_id":"t1_n08c2do","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I had all models evaluate each other's answers. The model which gave scores closer to the average seems like a better model. Check the last image on the main post.\\n\\n  \\nPlease elaborate your question if I missed anything","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09afj5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had all models evaluate each other&amp;#39;s answers. The model which gave scores closer to the average seems like a better model. Check the last image on the main post.&lt;/p&gt;\\n\\n&lt;p&gt;Please elaborate your question if I missed anything&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09afj5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125704,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08c2do","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious_Wish_887","can_mod_post":false,"created_utc":1751113762,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_842uhrr1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you explain how you measured average token/sec and the prompts for evaluation. Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08c2do","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you explain how you measured average token/sec and the prompts for evaluation. Thanks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08c2do/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751113762,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09b13x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751125893,"send_replies":true,"parent_id":"t1_n08hp1d","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would keep the context same but use q8 quantization and include more models.\\n\\nI believe mistral 7b will perform a lot better. without math, its scores are still in top 3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09b13x","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would keep the context same but use q8 quantization and include more models.&lt;/p&gt;\\n\\n&lt;p&gt;I believe mistral 7b will perform a lot better. without math, its scores are still in top 3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09b13x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125893,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08hp1d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jinnyjuice","can_mod_post":false,"created_utc":1751116022,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_4hrx8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very interesting results!\\n\\nWhat would you do if you had 16 or 32GB of RAM instead?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08hp1d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very interesting results!&lt;/p&gt;\\n\\n&lt;p&gt;What would you do if you had 16 or 32GB of RAM instead?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08hp1d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751116022,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09fd4l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmttyji","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09b8h0","score":1,"author_fullname":"t2_1deiadfhb1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Great.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n09fd4l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09fd4l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751127272,"author_flair_text":null,"treatment_tags":[],"created_utc":1751127272,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09b8h0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751125958,"send_replies":true,"parent_id":"t1_n08msmh","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Now that I have learned new things and perspectives, I will definitely try to do this again!\\n\\nI will try to include these\\n\\nthanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09b8h0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now that I have learned new things and perspectives, I will definitely try to do this again!&lt;/p&gt;\\n\\n&lt;p&gt;I will try to include these&lt;/p&gt;\\n\\n&lt;p&gt;thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09b8h0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125958,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cwqeb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmployeeLogical5051","can_mod_post":false,"created_utc":1751171969,"send_replies":true,"parent_id":"t1_n08msmh","score":1,"author_fullname":"t2_1ey2xkybge","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Jan is basically qwen 3 4b.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cwqeb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan is basically qwen 3 4b.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0cwqeb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751171969,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08msmh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmttyji","can_mod_post":false,"created_utc":1751117951,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_1deiadfhb1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for sharing this. Wish you tested bunch more models on this. Please try if you get a chance. Thanks again.\\n\\nFor example:\\n\\n1. Gemma3-4B (since Llama3.2-3B &amp; Qwen3-4B in your list)\\n2. Qwen3-0.6B (since Llama3.2-1B &amp; Gemma3-1B in your list)\\n3. Phi-4-mini-instruct (since Llama3.1-8B &amp; Mistral-7B in your list)\\n4. Jan-nano\\n5. Granite3.3-2B\\n6. MiniCPM4-0.5B (Optional)\\n7. BitCPM4-1B (Optional)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08msmh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for sharing this. Wish you tested bunch more models on this. Please try if you get a chance. Thanks again.&lt;/p&gt;\\n\\n&lt;p&gt;For example:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Gemma3-4B (since Llama3.2-3B &amp;amp; Qwen3-4B in your list)&lt;/li&gt;\\n&lt;li&gt;Qwen3-0.6B (since Llama3.2-1B &amp;amp; Gemma3-1B in your list)&lt;/li&gt;\\n&lt;li&gt;Phi-4-mini-instruct (since Llama3.1-8B &amp;amp; Mistral-7B in your list)&lt;/li&gt;\\n&lt;li&gt;Jan-nano&lt;/li&gt;\\n&lt;li&gt;Granite3.3-2B&lt;/li&gt;\\n&lt;li&gt;MiniCPM4-0.5B (Optional)&lt;/li&gt;\\n&lt;li&gt;BitCPM4-1B (Optional)&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08msmh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751117951,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f2j7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Over-Independent4414","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09d8mz","score":1,"author_fullname":"t2_1bhfwergwb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! One way I've found to do this is to use ancient textbooks that could not possibly have been digitized because they are long gone. It helps if you attended college in the 70s :-)\\n\\nBut Ebay could possibly be a source, I never looked, but maybe. The older the better and it helps, obviously, if the book itself has the answer key (many did, but not all). I have fed LLMs problems from my old textbooks with known answers fro the answer key.\\n\\nIt's not perfect because we do know, for example, that anthropic bought millions of old books and chopped them up to scan them into Claude. But the smaller models are unlikely to have that data directly baked into them.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0f2j7d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! One way I&amp;#39;ve found to do this is to use ancient textbooks that could not possibly have been digitized because they are long gone. It helps if you attended college in the 70s :-)&lt;/p&gt;\\n\\n&lt;p&gt;But Ebay could possibly be a source, I never looked, but maybe. The older the better and it helps, obviously, if the book itself has the answer key (many did, but not all). I have fed LLMs problems from my old textbooks with known answers fro the answer key.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s not perfect because we do know, for example, that anthropic bought millions of old books and chopped them up to scan them into Claude. But the smaller models are unlikely to have that data directly baked into them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0f2j7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751209738,"author_flair_text":null,"treatment_tags":[],"created_utc":1751209738,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09d8mz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751126596,"send_replies":true,"parent_id":"t1_n08xbjz","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If I do another experiment, I will include set of questions with know answers as well.\\n\\nthanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09d8mz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I do another experiment, I will include set of questions with know answers as well.&lt;/p&gt;\\n\\n&lt;p&gt;thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09d8mz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126596,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n08xbjz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Over-Independent4414","can_mod_post":false,"created_utc":1751121555,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_1bhfwergwb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If i understand right you are asking the models to evaluate the answers of the other models, and themselves. I think a really helpful upgrade would be to have a set of questions that have known answers and then have a model evaluate the answers against known correct answers.\\n\\nThere's a decent chance you'd have to do that yourself because a lot of benchmarks out there are overtrained in the models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08xbjz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If i understand right you are asking the models to evaluate the answers of the other models, and themselves. I think a really helpful upgrade would be to have a set of questions that have known answers and then have a model evaluate the answers against known correct answers.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s a decent chance you&amp;#39;d have to do that yourself because a lot of benchmarks out there are overtrained in the models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08xbjz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751121555,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09dj0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751126688,"send_replies":true,"parent_id":"t1_n08zszq","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I ran simple code like below in nested loop of model and topic to generate questions\\n\\nI used similar prompts for answer and evaluations.\\n\\n    prompt = (\\n                    f\\"Please create a challenging and nuanced question which high school students can answer \\"\\n                    f\\"in the field of {topic} that can be used to evaluate the intelligence of a language model. \\"\\n                    \\"Give only the question without any explanation or reasoning process.\\"\\n                )\\n                messages = [{\\"role\\": \\"user\\", \\"content\\": prompt}]","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09dj0s","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I ran simple code like below in nested loop of model and topic to generate questions&lt;/p&gt;\\n\\n&lt;p&gt;I used similar prompts for answer and evaluations.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt = (\\n                f&amp;quot;Please create a challenging and nuanced question which high school students can answer &amp;quot;\\n                f&amp;quot;in the field of {topic} that can be used to evaluate the intelligence of a language model. &amp;quot;\\n                &amp;quot;Give only the question without any explanation or reasoning process.&amp;quot;\\n            )\\n            messages = [{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt}]\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09dj0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126688,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n08zszq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BinaryHelix","can_mod_post":false,"created_utc":1751122352,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_5xh5x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you have the source available? Would like to test on my M1 Macbook air.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08zszq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have the source available? Would like to test on my M1 Macbook air.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n08zszq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122352,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09gii8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09g2ji","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thank you!\\n\\nI will use this from now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09gii8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you!&lt;/p&gt;\\n\\n&lt;p&gt;I will use this from now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09gii8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751127641,"author_flair_text":null,"treatment_tags":[],"created_utc":1751127641,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n09g2ji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glxblt76","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09efs8","score":1,"author_fullname":"t2_acpx1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Here's the way I do it when I want speed more than reasoning. It's recognized by the model as a special parameter. the &lt;think&gt; tags will still be there but they'll be empty, so it will stop using output tokens for reasoning.\\n\\n    prompt = (\\n                    f\\"/nothink Please create a challenging and nuanced question which high school students can answer \\"\\n                    f\\"in the field of {topic} that can be used to evaluate the intelligence of a language model. \\"\\n                    \\"Give only the question without any explanation or reasoning process.\\"\\n                )\\n                messages = [{\\"role\\": \\"user\\", \\"content\\": prompt}]","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n09g2ji","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here&amp;#39;s the way I do it when I want speed more than reasoning. It&amp;#39;s recognized by the model as a special parameter. the &amp;lt;think&amp;gt; tags will still be there but they&amp;#39;ll be empty, so it will stop using output tokens for reasoning.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt = (\\n                f&amp;quot;/nothink Please create a challenging and nuanced question which high school students can answer &amp;quot;\\n                f&amp;quot;in the field of {topic} that can be used to evaluate the intelligence of a language model. &amp;quot;\\n                &amp;quot;Give only the question without any explanation or reasoning process.&amp;quot;\\n            )\\n            messages = [{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt}]\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09g2ji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751127499,"author_flair_text":null,"treatment_tags":[],"created_utc":1751127499,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09efs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751126977,"send_replies":true,"parent_id":"t1_n097jbl","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"While I did specify it not to, I agree it needs to be reinforced. I will try to use /nothink.  \\nBelow is the prompt that I used\\n\\n    prompt = (\\n                    f\\"Please create a challenging and nuanced question which high school students can answer \\"\\n                    f\\"in the field of {topic} that can be used to evaluate the intelligence of a language model. \\"\\n                    \\"Give only the question without any explanation or reasoning process.\\"\\n                )\\n                messages = [{\\"role\\": \\"user\\", \\"content\\": prompt}]","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09efs8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While I did specify it not to, I agree it needs to be reinforced. I will try to use /nothink.&lt;br/&gt;\\nBelow is the prompt that I used&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt = (\\n                f&amp;quot;Please create a challenging and nuanced question which high school students can answer &amp;quot;\\n                f&amp;quot;in the field of {topic} that can be used to evaluate the intelligence of a language model. &amp;quot;\\n                &amp;quot;Give only the question without any explanation or reasoning process.&amp;quot;\\n            )\\n            messages = [{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt}]\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09efs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751126977,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n097jbl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glxblt76","can_mod_post":false,"created_utc":1751124794,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_acpx1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can use /nothink to prevent Qwen models from consuming reasoning tokens. Their behavior becomes more comparable to typical small models like that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n097jbl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can use /nothink to prevent Qwen models from consuming reasoning tokens. Their behavior becomes more comparable to typical small models like that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n097jbl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751124794,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b9sc7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0a4r9e","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thanks! I will definitely test it out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b9sc7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks! I will definitely test it out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0b9sc7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148604,"author_flair_text":null,"treatment_tags":[],"created_utc":1751148604,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0a4r9e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"My_Unbiased_Opinion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n09evfk","score":1,"author_fullname":"t2_esiyl0yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"According to the unsloth team, UD Q2KXL is the most efficient out of all quants in terms of size and performance on benchmarks. So I would try to find the best model in Q2KXL that you can fit in your situation. You might be able to use Phi 4 or Phi 4 reasoning in UD Q2KXL. Just be sure to use the unsloth dynamic quants. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0a4r9e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;According to the unsloth team, UD Q2KXL is the most efficient out of all quants in terms of size and performance on benchmarks. So I would try to find the best model in Q2KXL that you can fit in your situation. You might be able to use Phi 4 or Phi 4 reasoning in UD Q2KXL. Just be sure to use the unsloth dynamic quants. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0a4r9e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751135151,"author_flair_text":null,"treatment_tags":[],"created_utc":1751135151,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n09evfk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751127115,"send_replies":true,"parent_id":"t1_n098wnt","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gemma 3 12b is 8.1GB  \\nMistral Nemo 12B is 7.1 GB\\n\\nI wanted to test  under 5GB size.  \\nI can try UD Q3KXL next time.\\n\\nthanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09evfk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma 3 12b is 8.1GB&lt;br/&gt;\\nMistral Nemo 12B is 7.1 GB&lt;/p&gt;\\n\\n&lt;p&gt;I wanted to test  under 5GB size.&lt;br/&gt;\\nI can try UD Q3KXL next time.&lt;/p&gt;\\n\\n&lt;p&gt;thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n09evfk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751127115,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n098wnt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1751125224,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How about Mistral Nemo 12B at UD Q2KXL or UD Q3KXL? Should fit in ram with a good amount of Context especially with the more quantized model. Or even Gemma 3 12B. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n098wnt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How about Mistral Nemo 12B at UD Q2KXL or UD Q3KXL? Should fit in ram with a good amount of Context especially with the more quantized model. Or even Gemma 3 12B. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n098wnt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751125224,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bks0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clduab11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ba78f","score":1,"author_fullname":"t2_uobka","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ahhh gotcha. I was wondering how that E2B and E4B had handled its claims about memory management.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0bks0o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ahhh gotcha. I was wondering how that E2B and E4B had handled its claims about memory management.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0bks0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751152585,"author_flair_text":null,"treatment_tags":[],"created_utc":1751152585,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ba78f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751148748,"send_replies":true,"parent_id":"t1_n0a1kn4","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=1742&amp;format=png&amp;auto=webp&amp;s=361d6657f98b7afda0e401f3dfcfa0d0e72f7fc4\\n\\nit looks almost impossible for 8GB RAM.\\n\\nAll models I tested are under 5GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ba78f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/0xd7gtw1sq9f1.png?width=1742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=361d6657f98b7afda0e401f3dfcfa0d0e72f7fc4\\"&gt;https://preview.redd.it/0xd7gtw1sq9f1.png?width=1742&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=361d6657f98b7afda0e401f3dfcfa0d0e72f7fc4&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;it looks almost impossible for 8GB RAM.&lt;/p&gt;\\n\\n&lt;p&gt;All models I tested are under 5GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0ba78f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148748,"media_metadata":{"0xd7gtw1sq9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":114,"x":108,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=96053b3d08766be640cbfe92692b929f11eed77a"},{"y":229,"x":216,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5c75738848fb768714e2b1092a8fe44a0ed299c"},{"y":340,"x":320,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ea36f86dcb96bd41522999c202efe1cf703d7d7"},{"y":680,"x":640,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e7f316615b254b8c626cd82aebfaca9754abdbb3"},{"y":1020,"x":960,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7562614983015eedd747af337fde4371afefafba"},{"y":1148,"x":1080,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5996d61bff7a486849b5c660f03471b739eac0ab"}],"s":{"y":1852,"x":1742,"u":"https://preview.redd.it/0xd7gtw1sq9f1.png?width=1742&amp;format=png&amp;auto=webp&amp;s=361d6657f98b7afda0e401f3dfcfa0d0e72f7fc4"},"id":"0xd7gtw1sq9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0a1kn4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clduab11","can_mod_post":false,"created_utc":1751134147,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_uobka","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not sure if this was mentioned, but is it possible to compare with Gemma3n just yet?\\n\\nI'm interested to see how it benchmarks next to OG Gemma3.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0a1kn4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure if this was mentioned, but is it possible to compare with Gemma3n just yet?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m interested to see how it benchmarks next to OG Gemma3.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0a1kn4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751134147,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f1amz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751209344,"send_replies":true,"parent_id":"t1_n0bwuh9","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gemma3:latest performs the best for coding.\\n\\ncheck the third last image","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f1amz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma3:latest performs the best for coding.&lt;/p&gt;\\n\\n&lt;p&gt;check the third last image&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0f1amz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751209344,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0bwuh9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nareshdamera","can_mod_post":false,"created_utc":1751157006,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_1scubm4zyg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Which one is best for coding?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bwuh9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which one is best for coding?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0bwuh9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751157006,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f1yo0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RandiyOrtonu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ezr9p","score":1,"author_fullname":"t2_l7dkiy2q6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"fair enough ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0f1yo0","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;fair enough &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0f1yo0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751209557,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1751209557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ezr9p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751208853,"send_replies":true,"parent_id":"t1_n0cmace","score":2,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"models over 5GB on 8GB RAM are very slow. I was testing everything under 5GB\\n\\nI did include deepseek-r1:7b but there was some issue. it was not giving response via ollama. I removed and pulled it again but still no response.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ezr9p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;models over 5GB on 8GB RAM are very slow. I was testing everything under 5GB&lt;/p&gt;\\n\\n&lt;p&gt;I did include deepseek-r1:7b but there was some issue. it was not giving response via ollama. I removed and pulled it again but still no response.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0ezr9p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751208853,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cmace","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RandiyOrtonu","can_mod_post":false,"created_utc":1751167251,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_l7dkiy2q6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"why didn't u tested the new deepseek r1 qwen3 model ?  \\nthis one -&gt; [https://ollama.com/library/deepseek-r1:8b](https://ollama.com/library/deepseek-r1:8b)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cmace","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;why didn&amp;#39;t u tested the new deepseek r1 qwen3 model ?&lt;br/&gt;\\nthis one -&amp;gt; &lt;a href=\\"https://ollama.com/library/deepseek-r1:8b\\"&gt;https://ollama.com/library/deepseek-r1:8b&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0cmace/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751167251,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0hip0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CoolstaConnor","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ez10h","score":1,"author_fullname":"t2_48u2k6w6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's okay, thanks a lot!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0hip0a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s okay, thanks a lot!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0hip0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751238088,"author_flair_text":null,"treatment_tags":[],"created_utc":1751238088,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ez10h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751208620,"send_replies":true,"parent_id":"t1_n0cpux0","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will post here.\\n\\nBut it will take me some time to run this again. I am currently working on a different project","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ez10h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will post here.&lt;/p&gt;\\n\\n&lt;p&gt;But it will take me some time to run this again. I am currently working on a different project&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0ez10h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751208620,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cpux0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CoolstaConnor","can_mod_post":false,"created_utc":1751168827,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_48u2k6w6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for this because I run at the exact same same setup and this is valuable! Please write a comment here when you do your further evaluation so I can come back to it and look at it again.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cpux0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this because I run at the exact same same setup and this is valuable! Please write a comment here when you do your further evaluation so I can come back to it and look at it again.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0cpux0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751168827,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fnu9v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751216494,"send_replies":true,"parent_id":"t1_n0fixcn","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/sjohpou7dw9f1.png?width=1944&amp;format=png&amp;auto=webp&amp;s=9724ea6822d21c3a151936cb186e19df5d7ec34c\\n\\ngemma 3n e2b is over 5 GB. It will be very slow for 8GB RAM. I am testing everyhting under 5GB.\\n\\nBut someone sent me some post. So I am reading about it more","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fnu9v","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/sjohpou7dw9f1.png?width=1944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9724ea6822d21c3a151936cb186e19df5d7ec34c\\"&gt;https://preview.redd.it/sjohpou7dw9f1.png?width=1944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9724ea6822d21c3a151936cb186e19df5d7ec34c&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;gemma 3n e2b is over 5 GB. It will be very slow for 8GB RAM. I am testing everyhting under 5GB.&lt;/p&gt;\\n\\n&lt;p&gt;But someone sent me some post. So I am reading about it more&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0fnu9v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751216494,"media_metadata":{"sjohpou7dw9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":66,"x":108,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a492e86a9cd81b5332315c5fe70c613afef1d3ce"},{"y":133,"x":216,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2247fec747348b0a536f5a552e6c8975689d9c3b"},{"y":197,"x":320,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=347da175f2666801ae9d00caa920e60b627690f6"},{"y":394,"x":640,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=71f5120d4560459f7c3fd5cbe5be083015afcf92"},{"y":591,"x":960,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=69c9c6a44bfec900c69df8f3c5c37be6266c37a6"},{"y":665,"x":1080,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bcca664d4b54fb55834241bbdc621325c878dfc0"}],"s":{"y":1198,"x":1944,"u":"https://preview.redd.it/sjohpou7dw9f1.png?width=1944&amp;format=png&amp;auto=webp&amp;s=9724ea6822d21c3a151936cb186e19df5d7ec34c"},"id":"sjohpou7dw9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fixcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnduriII","can_mod_post":false,"created_utc":1751214953,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_ethybpf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for this amazing work  \\ncan you also include gemma3n:e2b in the next test?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fixcn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this amazing work&lt;br/&gt;\\ncan you also include gemma3n:e2b in the next test?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0fixcn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751214953,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n090jit","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"irodov4030","can_mod_post":false,"created_utc":1751122589,"send_replies":true,"parent_id":"t1_n085a5i","score":1,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you! I will try these out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n090jit","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you! I will try these out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n090jit/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751122589,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n085a5i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1751110739,"send_replies":true,"parent_id":"t3_1lmfiu9","score":1,"author_fullname":"t2_79slapln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you can run qwen3:8b, qwen2.5-vl:7b and deepseek-qwen3:8b via MLX with 10-13 token/s, you'll need 6-7gb of free ssd space or it will freeze\\n\\nalso try whisper, parakeet, kokoro, chatterbox and facefusion\\n\\nm1 8gb is still strong and gives you an ability to check out new stuff, build and test workflows, you can scale when you get that m4 512gb mac mini. if someone considers m1 8gb and reads this - yeah it's not ideal, but it will enable you to start your local journey for a very low price","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n085a5i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can run qwen3:8b, qwen2.5-vl:7b and deepseek-qwen3:8b via MLX with 10-13 token/s, you&amp;#39;ll need 6-7gb of free ssd space or it will freeze&lt;/p&gt;\\n\\n&lt;p&gt;also try whisper, parakeet, kokoro, chatterbox and facefusion&lt;/p&gt;\\n\\n&lt;p&gt;m1 8gb is still strong and gives you an ability to check out new stuff, build and test workflows, you can scale when you get that m4 512gb mac mini. if someone considers m1 8gb and reads this - yeah it&amp;#39;s not ideal, but it will enable you to start your local journey for a very low price&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n085a5i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751110739,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmfiu9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-8,"removal_reason":null,"link_id":"t3_1lmfiu9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07ecs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Comfortable-Tap-9991","can_mod_post":false,"created_utc":1751095468,"send_replies":true,"parent_id":"t1_n0795fi","score":9,"author_fullname":"t2_1fcbojgfd8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it's the cheapest macboook from 2020, chill","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ecs8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s the cheapest macboook from 2020, chill&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ecs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751095468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2ff18162-05ce-11ee-aa52-6a828e39b56c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07q7it","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RelicDerelict","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07anga","score":3,"author_fullname":"t2_c9l5cm1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much. I love tests and perspectives from the hardware poorer side of enthusiasts like us.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n07q7it","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Orca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much. I love tests and perspectives from the hardware poorer side of enthusiasts like us.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07q7it/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751102495,"author_flair_text":"Orca","treatment_tags":[],"created_utc":1751102495,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n07anga","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"irodov4030","can_mod_post":false,"created_utc":1751093418,"send_replies":true,"parent_id":"t1_n0795fi","score":6,"author_fullname":"t2_l5xlcgf2j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"results are decent if you just want to chat. Avg. reading speed would be around 5-10 tokens per sec.\\n\\nSO it is ok for personal use and average tasks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07anga","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;results are decent if you just want to chat. Avg. reading speed would be around 5-10 tokens per sec.&lt;/p&gt;\\n\\n&lt;p&gt;SO it is ok for personal use and average tasks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07anga/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093418,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07u6fm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"techno156","can_mod_post":false,"created_utc":1751104857,"send_replies":true,"parent_id":"t1_n0795fi","score":2,"author_fullname":"t2_b3s88","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; 8GB ram not even Vram, the specs are too low.\\n\\nM-Series Macs complicate that a bit, since RAM and VRAM are shared, up to 1/3rd of the total RAM capacity or thereabouts. So OP would still have 2 - 3 GB of VRAM to work with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07u6fm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;8GB ram not even Vram, the specs are too low.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;M-Series Macs complicate that a bit, since RAM and VRAM are shared, up to 1/3rd of the total RAM capacity or thereabouts. So OP would still have 2 - 3 GB of VRAM to work with.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmfiu9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07u6fm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751104857,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0795fi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1lmfiu9","score":-8,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0795fi/","num_reports":null,"locked":false,"name":"t1_n0795fi","created":1751092607,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751092607,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
