import{j as e}from"./index-CWmJdUH_.js";import{R as t}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I have been using Langgraph and chrome vector DB for RAG pipeline. In last one month's time I have got out of the loop. I still use Deepseek r1 on the chat.deepseek.com on daily basis for development purposes. It increases my daiy development product by multifold as it understands any library and code requirements really well. \\n\\nRecently I started wishing that there should be some agentic setup that should be able to read the entire code repo and be able to write or read and answer questions from any files in the repo. \\n\\nI found two majore projects\\n1. AgenticSeek\\n2. MetaGPT\\n\\nI couldn't get AgenticSeek setup and run on my local macbook pro (m3-pro 36GBRAM).\\n\\nI have heard about MetaGPT for more than 1 year now but couldn't try it actively.\\n\\nI sometimes might want to use such to create entire backend and frontend and overall planning like feature wise (which I think MetaGPT provides).\\n\\nI have not tried Cursor IDE. I know it is a shame on my part, wishing to work and not having it tried yet so.\\n\\nPlease suggest any such setup or IDE or project that works the best!!!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Which project/program or IDE to use attached with LLM online/local for free use for entire code-repos?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1luvt31","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_s5ork","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751998198,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been using Langgraph and chrome vector DB for RAG pipeline. In last one month&amp;#39;s time I have got out of the loop. I still use Deepseek r1 on the chat.deepseek.com on daily basis for development purposes. It increases my daiy development product by multifold as it understands any library and code requirements really well. &lt;/p&gt;\\n\\n&lt;p&gt;Recently I started wishing that there should be some agentic setup that should be able to read the entire code repo and be able to write or read and answer questions from any files in the repo. &lt;/p&gt;\\n\\n&lt;p&gt;I found two majore projects\\n1. AgenticSeek\\n2. MetaGPT&lt;/p&gt;\\n\\n&lt;p&gt;I couldn&amp;#39;t get AgenticSeek setup and run on my local macbook pro (m3-pro 36GBRAM).&lt;/p&gt;\\n\\n&lt;p&gt;I have heard about MetaGPT for more than 1 year now but couldn&amp;#39;t try it actively.&lt;/p&gt;\\n\\n&lt;p&gt;I sometimes might want to use such to create entire backend and frontend and overall planning like feature wise (which I think MetaGPT provides).&lt;/p&gt;\\n\\n&lt;p&gt;I have not tried Cursor IDE. I know it is a shame on my part, wishing to work and not having it tried yet so.&lt;/p&gt;\\n\\n&lt;p&gt;Please suggest any such setup or IDE or project that works the best!!!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1luvt31","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"tapu_buoy","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1luvt31/which_projectprogram_or_ide_to_use_attached_with/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1luvt31/which_projectprogram_or_ide_to_use_attached_with/","subreddit_subscribers":496592,"created_utc":1751998198,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n21givi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tapu_buoy","can_mod_post":false,"created_utc":1752002525,"send_replies":true,"parent_id":"t1_n21aypq","score":1,"author_fullname":"t2_s5ork","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh okay! what is QWQ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21givi","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh okay! what is QWQ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1luvt31","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luvt31/which_projectprogram_or_ide_to_use_attached_with/n21givi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752002525,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n21aypq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dc740","can_mod_post":false,"created_utc":1752000997,"send_replies":true,"parent_id":"t3_1luvt31","score":1,"author_fullname":"t2_dkwhd0p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Aider connected to a local llama using openai works fine for unlimited coding. I'm currently trying qwq","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n21aypq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Aider connected to a local llama using openai works fine for unlimited coding. I&amp;#39;m currently trying qwq&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luvt31/which_projectprogram_or_ide_to_use_attached_with/n21aypq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752000997,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luvt31","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
