import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Is anyone maintaining a \\"fits in a MacBook Pro\\" kind of leaderboard for open models? It's by far the form factor for open models I've seen colleagues interested in.\\n\\nI know you can just see the number of parameters, active parameters in MoEs, etc., but a nice leaderboard with some tokens/sec average would be useful for many.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"MacBook model rank","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7lp0z","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_e9yxn","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753305825,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Is anyone maintaining a &amp;quot;fits in a MacBook Pro&amp;quot; kind of leaderboard for open models? It&amp;#39;s by far the form factor for open models I&amp;#39;ve seen colleagues interested in.&lt;/p&gt;\\n\\n&lt;p&gt;I know you can just see the number of parameters, active parameters in MoEs, etc., but a nice leaderboard with some tokens/sec average would be useful for many.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m7lp0z","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"JCx64","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/","subreddit_subscribers":503759,"created_utc":1753305825,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vcmx1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sfe95","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you have a Mac you should definitely use MLX models instead of GGUF. I'm following a GitHub thread on Ollama repository about MLX support, but it's been opened since 2024 (but still active)\\n\\nIn the meantime I use LMStudio (you can use it headless, like Ollama) but I heard about an Ollama contender called Swama. I didn't try it yet though.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4vcmx1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you have a Mac you should definitely use MLX models instead of GGUF. I&amp;#39;m following a GitHub thread on Ollama repository about MLX support, but it&amp;#39;s been opened since 2024 (but still active)&lt;/p&gt;\\n\\n&lt;p&gt;In the meantime I use LMStudio (you can use it headless, like Ollama) but I heard about an Ollama contender called Swama. I didn&amp;#39;t try it yet though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7lp0z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4vcmx1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753349685,"author_flair_text":null,"treatment_tags":[],"created_utc":1753349685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sfe95","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JCx64","can_mod_post":false,"created_utc":1753306359,"send_replies":true,"parent_id":"t1_n4sefo2","score":1,"author_fullname":"t2_e9yxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is for me, although it gets dangerously close to my reading speed. Maybe I should switch away from Ollama","edited":1753306861,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sfe95","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is for me, although it gets dangerously close to my reading speed. Maybe I should switch away from Ollama&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7lp0z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4sfe95/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753306359,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sefo2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-dysangel-","can_mod_post":false,"created_utc":1753306071,"send_replies":true,"parent_id":"t3_1m7lp0z","score":2,"author_fullname":"t2_12ggykute6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'd assume Qwen 3 32B is at the lead of that board","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sefo2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d assume Qwen 3 32B is at the lead of that board&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4sefo2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753306071,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m7lp0z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vd0oj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"created_utc":1753349901,"send_replies":true,"parent_id":"t1_n4soc34","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait, you can run Qwen3 big MoEs on less than 512GB of memory?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vd0oj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait, you can run Qwen3 big MoEs on less than 512GB of memory?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7lp0z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4vd0oj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753349901,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4soc34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VegetaTheGrump","can_mod_post":false,"created_utc":1753309099,"send_replies":true,"parent_id":"t3_1m7lp0z","score":1,"author_fullname":"t2_taorh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not just MacBook but Mac in general. I feel like the 512Gb model gets targeted and then Nvidia cards for PCs. I'd like to see 256GB 128GB 96GB 64GB and 32GB macs all get addressed. \\n\\nHowever, that's a lot to ask of anyone, so I just download models and very unscientifically try them out until I see what seems to be working best for me. \\n\\nSo far it's been Qwen3 235B due to speed/quality tradeoff. The new Qwen3 480B seems to be just as fast, though I wish I had a sense for the Qwen3 235B Q6 quality vs Qwen3 480B Q3\\\\_K\\\\_XL quality. It was easier back when QWQ32 just seemed to smash everything.\\n\\nAnother thing people on Mac should know is that LMStudio is very conservative about size estimates.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4soc34","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not just MacBook but Mac in general. I feel like the 512Gb model gets targeted and then Nvidia cards for PCs. I&amp;#39;d like to see 256GB 128GB 96GB 64GB and 32GB macs all get addressed. &lt;/p&gt;\\n\\n&lt;p&gt;However, that&amp;#39;s a lot to ask of anyone, so I just download models and very unscientifically try them out until I see what seems to be working best for me. &lt;/p&gt;\\n\\n&lt;p&gt;So far it&amp;#39;s been Qwen3 235B due to speed/quality tradeoff. The new Qwen3 480B seems to be just as fast, though I wish I had a sense for the Qwen3 235B Q6 quality vs Qwen3 480B Q3_K_XL quality. It was easier back when QWQ32 just seemed to smash everything.&lt;/p&gt;\\n\\n&lt;p&gt;Another thing people on Mac should know is that LMStudio is very conservative about size estimates.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4soc34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753309099,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7lp0z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vb07f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JCx64","can_mod_post":false,"created_utc":1753348758,"send_replies":true,"parent_id":"t1_n4tqtlk","score":1,"author_fullname":"t2_e9yxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, I mentioned the MoE topic as well. The value on having this is saving this calculations and reporting something at an intuitive level","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vb07f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, I mentioned the MoE topic as well. The value on having this is saving this calculations and reporting something at an intuitive level&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7lp0z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4vb07f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753348758,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4tqtlk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"droptableadventures","can_mod_post":false,"created_utc":1753322085,"send_replies":true,"parent_id":"t3_1m7lp0z","score":1,"author_fullname":"t2_52zg0eoq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In terms of a leaderboard for \\"fastest model\\" - this would be a bit pointless:\\n\\nTokens/sec is pretty much (memory bandwidth) / (size of model) - there won't be major differences between models of the same size.\\n\\nThe reason why it seems like there are wild differences in model speed are because some models are MoE and don't run the whole model every time - in that case you look at the \\"active parameters\\", not the \\"total parameters\\" and the equation above still holds true.","edited":1753324914,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4tqtlk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In terms of a leaderboard for &amp;quot;fastest model&amp;quot; - this would be a bit pointless:&lt;/p&gt;\\n\\n&lt;p&gt;Tokens/sec is pretty much (memory bandwidth) / (size of model) - there won&amp;#39;t be major differences between models of the same size.&lt;/p&gt;\\n\\n&lt;p&gt;The reason why it seems like there are wild differences in model speed are because some models are MoE and don&amp;#39;t run the whole model every time - in that case you look at the &amp;quot;active parameters&amp;quot;, not the &amp;quot;total parameters&amp;quot; and the equation above still holds true.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7lp0z/macbook_model_rank/n4tqtlk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753322085,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7lp0z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
