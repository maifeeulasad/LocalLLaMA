import{j as e}from"./index-CeRg6Q3f.js";import{R as l}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm looking for something I can run locally that's actually close to gpt-4o or claude in terms of quality.\\n\\nKinda tight on money right now so I can't afford gpt plus or claude pro :/  \\n  \\nI have to write a bunch of posts throughout the day, and the free gpt-4o hits its limit way too fast.\\n\\nIs there anything similar out there that gives quality output like gpt-4o or claude and can run locally?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Any Actual alternative to gpt-4o or claude?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzb7fh","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.58,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vbdiiix7","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752461154,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m looking for something I can run locally that&amp;#39;s actually close to gpt-4o or claude in terms of quality.&lt;/p&gt;\\n\\n&lt;p&gt;Kinda tight on money right now so I can&amp;#39;t afford gpt plus or claude pro :/  &lt;/p&gt;\\n\\n&lt;p&gt;I have to write a bunch of posts throughout the day, and the free gpt-4o hits its limit way too fast.&lt;/p&gt;\\n\\n&lt;p&gt;Is there anything similar out there that gives quality output like gpt-4o or claude and can run locally?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lzb7fh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Dragonacious","discussion_type":null,"num_comments":47,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/","subreddit_subscribers":499297,"created_utc":1752461154,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31wzk0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1752489393,"send_replies":true,"parent_id":"t1_n30gic3","score":0,"author_fullname":"t2_1k4sjdwzk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Money aside, it's probably kimi k2","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31wzk0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Money aside, it&amp;#39;s probably kimi k2&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31wzk0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752489393,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n30gic3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ninjasaid13","can_mod_post":false,"created_utc":1752462148,"send_replies":true,"parent_id":"t3_1lzb7fh","score":70,"author_fullname":"t2_qjpsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Kinda tight on money right now so I can't afford gpt plus or claude pro :/\\n\\nIf you're tight on money then you can't afford the hardware that can run models close to gpt4o or claude.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30gic3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Kinda tight on money right now so I can&amp;#39;t afford gpt plus or claude pro :/&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;If you&amp;#39;re tight on money then you can&amp;#39;t afford the hardware that can run models close to gpt4o or claude.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30gic3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462148,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":70}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n318g34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"skipfish","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30oj9c","score":5,"author_fullname":"t2_5jbk4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Both of those far away in terms of quality comparing to Claude or gpt-4, unfortunately.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n318g34","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Both of those far away in terms of quality comparing to Claude or gpt-4, unfortunately.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n318g34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475337,"author_flair_text":null,"treatment_tags":[],"created_utc":1752475337,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n30oj9c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30m714","score":4,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How fast do you need it?  \\nYou can run Qwen3 32b very slowly  \\nor Qwen3 14b at better speeds.[](https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q4_K_XL.gguf?download=true)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30oj9c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How fast do you need it?&lt;br/&gt;\\nYou can run Qwen3 32b very slowly&lt;br/&gt;\\nor Qwen3 14b at better speeds.&lt;a href=\\"https://huggingface.co/unsloth/Qwen3-32B-GGUF/resolve/main/Qwen3-32B-UD-Q4_K_XL.gguf?download=true\\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30oj9c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465486,"author_flair_text":null,"treatment_tags":[],"created_utc":1752465486,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n30m714","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dragonacious","can_mod_post":false,"created_utc":1752464492,"send_replies":true,"parent_id":"t1_n30e4hc","score":2,"author_fullname":"t2_vbdiiix7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5. Sorry I dont have high specs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30m714","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt; I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5. Sorry I dont have high specs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30m714/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464492,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30e4hc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1752461216,"send_replies":true,"parent_id":"t3_1lzb7fh","score":9,"author_fullname":"t2_9hl4ymvj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"On what hardware?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30e4hc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On what hardware?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30e4hc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461216,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30okxm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sciencewarrior","can_mod_post":false,"created_utc":1752465508,"send_replies":true,"parent_id":"t3_1lzb7fh","score":7,"author_fullname":"t2_4feaa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unless you have a beefy GPU or a Mac, you may be better off sticking with online providers. Deepseek is a solid option, and Gemini 2.5 Pro is available for free via Google's AI Studio.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30okxm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless you have a beefy GPU or a Mac, you may be better off sticking with online providers. Deepseek is a solid option, and Gemini 2.5 Pro is available for free via Google&amp;#39;s AI Studio.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30okxm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465508,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3181b2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Annual_Cable_7865","can_mod_post":false,"created_utc":1752475109,"send_replies":true,"parent_id":"t3_1lzb7fh","score":4,"author_fullname":"t2_ccjayp09","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"use gemini 2.5pro for free [http://ai.studio/](http://ai.studio/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3181b2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;use gemini 2.5pro for free &lt;a href=\\"http://ai.studio/\\"&gt;http://ai.studio/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n3181b2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30mfdo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vegatx40","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30kqis","score":3,"author_fullname":"t2_18dhiarv40","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It might not be super fast, but I am guessing you could squeeze in maybe a 15 billion parameter model.\\n\\nDeepseek-r1:14b\\n\\nGemma3:12b\\n\\nQwen3:14b\\n\\nLlama3.1:8b","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30mfdo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It might not be super fast, but I am guessing you could squeeze in maybe a 15 billion parameter model.&lt;/p&gt;\\n\\n&lt;p&gt;Deepseek-r1:14b&lt;/p&gt;\\n\\n&lt;p&gt;Gemma3:12b&lt;/p&gt;\\n\\n&lt;p&gt;Qwen3:14b&lt;/p&gt;\\n\\n&lt;p&gt;Llama3.1:8b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30mfdo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464590,"author_flair_text":null,"treatment_tags":[],"created_utc":1752464590,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n30kqis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dragonacious","can_mod_post":false,"created_utc":1752463876,"send_replies":true,"parent_id":"t1_n30jcb6","score":2,"author_fullname":"t2_vbdiiix7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I got rtx 12 gb nvidia 3060, 16 gb ram and an i5","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kqis","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I got rtx 12 gb nvidia 3060, 16 gb ram and an i5&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30kqis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463876,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30jcb6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vegatx40","can_mod_post":false,"created_utc":1752463292,"send_replies":true,"parent_id":"t3_1lzb7fh","score":3,"author_fullname":"t2_18dhiarv40","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does your laptop have a graphics card? \\n\\nA lot of low end consumer RTX cards have between four and eight gig of VRAM. With that you could run one of the smaller Gemma3 models, for actually Gemma2 because you don't need multimodal. And of course there's the workhorse llama 3.1-8b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30jcb6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does your laptop have a graphics card? &lt;/p&gt;\\n\\n&lt;p&gt;A lot of low end consumer RTX cards have between four and eight gig of VRAM. With that you could run one of the smaller Gemma3 models, for actually Gemma2 because you don&amp;#39;t need multimodal. And of course there&amp;#39;s the workhorse llama 3.1-8b&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30jcb6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463292,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30kzhe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1752463981,"send_replies":true,"parent_id":"t3_1lzb7fh","score":3,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"At least for coding, there's DeepSeek, Mistral, Kimi (though that's heavy). On this benchmark for models developing UI, GPT comes behind a lot of open source models. \\n\\nhttps://preview.redd.it/d35o0ch2frcf1.png?width=1962&amp;format=png&amp;auto=webp&amp;s=f521e8608196d36cf31c6977c2fe69fb9e8dbece","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kzhe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At least for coding, there&amp;#39;s DeepSeek, Mistral, Kimi (though that&amp;#39;s heavy). On this benchmark for models developing UI, GPT comes behind a lot of open source models. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/d35o0ch2frcf1.png?width=1962&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f521e8608196d36cf31c6977c2fe69fb9e8dbece\\"&gt;https://preview.redd.it/d35o0ch2frcf1.png?width=1962&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f521e8608196d36cf31c6977c2fe69fb9e8dbece&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30kzhe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463981,"media_metadata":{"d35o0ch2frcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":88,"x":108,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=381079fdbafb028962c135fd7197c4552fb15dd5"},{"y":177,"x":216,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=85e768d8c05bcfb6a20e5687cb5b20e5bb7c71d1"},{"y":262,"x":320,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8a1425de8254fffea8449fb855da5f60a1a95e7"},{"y":525,"x":640,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e087ea26d765567f3ab78e554a6e904bf7435f79"},{"y":788,"x":960,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e77f16c5528b9f0550d2a2ce0993182f8cd6347"},{"y":887,"x":1080,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f83c1aeb59521069bd430a7b337d43382d003db"}],"s":{"y":1612,"x":1962,"u":"https://preview.redd.it/d35o0ch2frcf1.png?width=1962&amp;format=png&amp;auto=webp&amp;s=f521e8608196d36cf31c6977c2fe69fb9e8dbece"},"id":"d35o0ch2frcf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310ayv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tempetemplar","can_mod_post":false,"created_utc":1752471000,"send_replies":true,"parent_id":"t3_1lzb7fh","score":3,"author_fullname":"t2_atvw2aj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Welcome to DeepSeek!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310ayv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Welcome to DeepSeek!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n310ayv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471000,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30wg2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"simracerman","can_mod_post":false,"created_utc":1752469090,"send_replies":true,"parent_id":"t1_n30hnus","score":6,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mistral Small 3.2 -24B is amazing! Even if some of the Q4 spills into system memory, OP will still have a nice experience.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30wg2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral Small 3.2 -24B is amazing! Even if some of the Q4 spills into system memory, OP will still have a nice experience.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30wg2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469090,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n315z9e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jkh911208","can_mod_post":false,"send_replies":true,"parent_id":"t1_n315axc","score":2,"author_fullname":"t2_eq49q5k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"M1 max with 64gb ram getting about 13token/s with lmstudio","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n315z9e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;M1 max with 64gb ram getting about 13token/s with lmstudio&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n315z9e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473974,"author_flair_text":null,"treatment_tags":[],"created_utc":1752473974,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n315axc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"burner-throw_away","can_mod_post":false,"created_utc":1752473602,"send_replies":true,"parent_id":"t1_n30hnus","score":1,"author_fullname":"t2_lelpp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What model &amp; specs, if I may ask? \\nThank you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n315axc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What model &amp;amp; specs, if I may ask? \\nThank you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n315axc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473602,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30hnus","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jkh911208","can_mod_post":false,"created_utc":1752462604,"send_replies":true,"parent_id":"t3_1lzb7fh","score":4,"author_fullname":"t2_eq49q5k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i tried [https://lmstudio.ai/models/mistralai/devstral-small-2507](https://lmstudio.ai/models/mistralai/devstral-small-2507) for few days now and it is very reliable \\n\\ni am using 8 bit version but if you are downgrade to 4bit it will need 14GB of VRAM\\n\\ni am running it on Mac","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30hnus","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i tried &lt;a href=\\"https://lmstudio.ai/models/mistralai/devstral-small-2507\\"&gt;https://lmstudio.ai/models/mistralai/devstral-small-2507&lt;/a&gt; for few days now and it is very reliable &lt;/p&gt;\\n\\n&lt;p&gt;i am using 8 bit version but if you are downgrade to 4bit it will need 14GB of VRAM&lt;/p&gt;\\n\\n&lt;p&gt;i am running it on Mac&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30hnus/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31pzue","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30yrpw","score":1,"author_fullname":"t2_5oltmr5b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, also as I said in another comment, if you are not going to share sensitice/private data you have 1k request/day for ':free: models on openrouter (deepseek R1 is currently avaible as free version). you just have to add 10$ one time to increase the limit for free models to 1k.\\n\\nwhen you are going to share something you don't want to be logged, just swith to the non free version (check specific provider policy / ToS) , and 5-6$ / month will give you many tokens","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31pzue","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, also as I said in another comment, if you are not going to share sensitice/private data you have 1k request/day for &amp;#39;:free: models on openrouter (deepseek R1 is currently avaible as free version). you just have to add 10$ one time to increase the limit for free models to 1k.&lt;/p&gt;\\n\\n&lt;p&gt;when you are going to share something you don&amp;#39;t want to be logged, just swith to the non free version (check specific provider policy / ToS) , and 5-6$ / month will give you many tokens&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31pzue/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752485531,"author_flair_text":null,"treatment_tags":[],"created_utc":1752485531,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30yrpw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"d4rk31337","can_mod_post":false,"created_utc":1752470227,"send_replies":true,"parent_id":"t1_n30m2gh","score":4,"author_fullname":"t2_33dob5fs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can get plenty of tokens for that budget on openrouter.ai and use different models for different purposes. There are even free models occasionally. That combined with https://openwebui.com/ should be more than enough for your requirements","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30yrpw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can get plenty of tokens for that budget on openrouter.ai and use different models for different purposes. There are even free models occasionally. That combined with &lt;a href=\\"https://openwebui.com/\\"&gt;https://openwebui.com/&lt;/a&gt; should be more than enough for your requirements&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30yrpw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470227,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30zd19","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"botornobotcrawler","can_mod_post":false,"created_utc":1752470525,"send_replies":true,"parent_id":"t1_n30m2gh","score":2,"author_fullname":"t2_qmk7876e9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Take your budget to openrouter, if you cannot run the models locally. There you can basically buy every llm via one api as you need! \\n5-6 dollars are month will be enough for most smaller models. When you use roo or cline to do the calls you have a nice ui and keep track of your spending.\\n\\nThere you can run deepseek r1 for quite cheap or even for free.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30zd19","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Take your budget to openrouter, if you cannot run the models locally. There you can basically buy every llm via one api as you need! \\n5-6 dollars are month will be enough for most smaller models. When you use roo or cline to do the calls you have a nice ui and keep track of your spending.&lt;/p&gt;\\n\\n&lt;p&gt;There you can run deepseek r1 for quite cheap or even for free.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30zd19/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470525,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30pub3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dark_Fire_12","can_mod_post":false,"created_utc":1752466057,"send_replies":true,"parent_id":"t1_n30m2gh","score":2,"author_fullname":"t2_kwl47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not affiliated but you can use t3 chat, it fits your budget, it's $8.\\n\\nTheo gives lots of $1 discounts regularly for the first month.\\n\\nMost Indies who built their own stop working on it but he managed to get enough success I think he and his team won't stop.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30pub3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not affiliated but you can use t3 chat, it fits your budget, it&amp;#39;s $8.&lt;/p&gt;\\n\\n&lt;p&gt;Theo gives lots of $1 discounts regularly for the first month.&lt;/p&gt;\\n\\n&lt;p&gt;Most Indies who built their own stop working on it but he managed to get enough success I think he and his team won&amp;#39;t stop.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30pub3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752466057,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30m2gh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dragonacious","can_mod_post":false,"created_utc":1752464438,"send_replies":true,"parent_id":"t3_1lzb7fh","score":2,"author_fullname":"t2_vbdiiix7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My specs are not that high. I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5.\\n\\nI can spend like around $5-$6 a month for an LLM that gives gpt-4o or claude quality response.\\n\\nI came across a site called galaxy .ai and which claims to provides all AI tools like claude, gpt-4o, veo 3 for $15 a month. The price seems too be good to be true, and seems like a scam too so didn't bother.  \\n  \\nCan I use gpt-4o api? I've heard APIs are cheaper but not sure if they give the \\"actual\\" same quality response as gpt-4o via gpt plus subscription.  \\n  \\nWhat are my options?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30m2gh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My specs are not that high. I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5.&lt;/p&gt;\\n\\n&lt;p&gt;I can spend like around $5-$6 a month for an LLM that gives gpt-4o or claude quality response.&lt;/p&gt;\\n\\n&lt;p&gt;I came across a site called galaxy .ai and which claims to provides all AI tools like claude, gpt-4o, veo 3 for $15 a month. The price seems too be good to be true, and seems like a scam too so didn&amp;#39;t bother.  &lt;/p&gt;\\n\\n&lt;p&gt;Can I use gpt-4o api? I&amp;#39;ve heard APIs are cheaper but not sure if they give the &amp;quot;actual&amp;quot; same quality response as gpt-4o via gpt plus subscription.  &lt;/p&gt;\\n\\n&lt;p&gt;What are my options?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30m2gh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464438,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30z6cp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Ad8465","can_mod_post":false,"created_utc":1752470431,"send_replies":true,"parent_id":"t3_1lzb7fh","score":2,"author_fullname":"t2_66ye1sqb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma or Qwen do well with this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30z6cp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma or Qwen do well with this&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30z6cp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470431,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310ps7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1752471211,"send_replies":true,"parent_id":"t3_1lzb7fh","score":2,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Uh...It really depends on what you use it for specifically.\\n\\nDepending on exactly what you do, QwQ 32B, one of the Mistral Small variants (or finetunes) might do it. You could potentially push for Jamba Mini 1.7.\\n\\nIt'll be slow on your hardware but in principle it's possible, at least.\\n\\nAgain, I'm not really sure what you're doing (\\"write a bunch of posts\\" is extremely vague. Technical articles? Lifestyle posts?), so it's really hard to say. From your description anything from Gemma 3 4B to Kimi 1T might be necessary and it's really not clear where you are on that spectrum.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310ps7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Uh...It really depends on what you use it for specifically.&lt;/p&gt;\\n\\n&lt;p&gt;Depending on exactly what you do, QwQ 32B, one of the Mistral Small variants (or finetunes) might do it. You could potentially push for Jamba Mini 1.7.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;ll be slow on your hardware but in principle it&amp;#39;s possible, at least.&lt;/p&gt;\\n\\n&lt;p&gt;Again, I&amp;#39;m not really sure what you&amp;#39;re doing (&amp;quot;write a bunch of posts&amp;quot; is extremely vague. Technical articles? Lifestyle posts?), so it&amp;#39;s really hard to say. From your description anything from Gemma 3 4B to Kimi 1T might be necessary and it&amp;#39;s really not clear where you are on that spectrum.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n310ps7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471211,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31888y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1752475216,"send_replies":true,"parent_id":"t3_1lzb7fh","score":2,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think local LLMs are not what you expect","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31888y","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think local LLMs are not what you expect&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31888y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475216,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n311vka","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Chris__Kyle","can_mod_post":false,"created_utc":1752471807,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_80ld4nyt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you won't end up being able to run locally, then why no use:\\n1. chat.qwen.ai\\n2. aistudio.google.com\\n3. gemini.google.com\\n4. kimi.com\\nThere is a YouTuber called Theo. Many times he gives a promo codes in his videos so you can buy a subscription for t3.chat for $1. But you can still subscribe to $8 if you don't have.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n311vka","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you won&amp;#39;t end up being able to run locally, then why no use:\\n1. chat.qwen.ai\\n2. aistudio.google.com\\n3. gemini.google.com\\n4. kimi.com\\nThere is a YouTuber called Theo. Many times he gives a promo codes in his videos so you can buy a subscription for t3.chat for $1. But you can still subscribe to $8 if you don&amp;#39;t have.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n311vka/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471807,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31fb91","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CommunityTough1","can_mod_post":false,"created_utc":1752479252,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_1iuzpxw7eg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not local, but Google is giving away $300 in AI credits to everyone for free for Gemini 2.5. Also, if you use something like OpenWebUI where you can bring your own key for API-based inference, there are a lot of really good models for free through OpenRouter, such as DeepSeek V3 and R1, as well as Kimi K2.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31fb91","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not local, but Google is giving away $300 in AI credits to everyone for free for Gemini 2.5. Also, if you use something like OpenWebUI where you can bring your own key for API-based inference, there are a lot of really good models for free through OpenRouter, such as DeepSeek V3 and R1, as well as Kimi K2.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31fb91/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752479252,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31hpog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iheartmuffinz","can_mod_post":false,"created_utc":1752480642,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_11hdm8l45p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Using large models via OpenRouter (or any API) might be for you. Instead of paying monthly, you deposit money and then pay per token generated. It is almost always cheaper than the subscriptions and by a substantial amount.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31hpog","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using large models via OpenRouter (or any API) might be for you. Instead of paying monthly, you deposit money and then pay per token generated. It is almost always cheaper than the subscriptions and by a substantial amount.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31hpog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752480642,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33980v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31zv0f","score":1,"author_fullname":"t2_5oltmr5b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I didn't know that... thanks for the info!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n33980v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I didn&amp;#39;t know that... thanks for the info!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n33980v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752506513,"author_flair_text":null,"treatment_tags":[],"created_utc":1752506513,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n31zv0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752490800,"send_replies":true,"parent_id":"t1_n31owev","score":2,"author_fullname":"t2_6lmlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you sign up directly with what they route to e.g. chutes you can get even better usage limits","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31zv0f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you sign up directly with what they route to e.g. chutes you can get even better usage limits&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31zv0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752490800,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n31owev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752484891,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you can make 1k/day requests for free on openrouter, search for 'free' models. (you just have to add 10$ of credit one time to increase the limit for free models from 50 to 1k per day) currently they offer even deepseek R1 for free.\\n(obviously, don't expect much privacy...free models are usually hosted from providers that store your data)\\n\\nyou can chat with those models on the openrouter chat UI or use the API key on another UI (ie openwebUI)\\n\\nif you value privacy, use non 'free' model on openrouter (look at the providers for every model, everyone has different politics about logging ad data retention).\\nmany models are really cheap and cost arount 1$ per million token.\\n\\nhttps://openrouter.ai/models?order=pricing-low-to-high\\n\\nabout rate limits:\\n&gt; Free usage limits: If you’re using a free model variant (with an ID ending in :free), you can make up to 20 requests per minute. The following per-day limits apply:\\n&gt;\\n&gt;If you have purchased less than 10 credits, you’re limited to 50 :free model requests per day.\\n&gt;\\n&gt;If you purchase at least 10 credits, your daily limit is increased to 1000 :free model requests per day.\\n\\n\\n(all of that assuming that 'money' is the only reason for that you want to go local)","edited":1752485239,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31owev","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can make 1k/day requests for free on openrouter, search for &amp;#39;free&amp;#39; models. (you just have to add 10$ of credit one time to increase the limit for free models from 50 to 1k per day) currently they offer even deepseek R1 for free.\\n(obviously, don&amp;#39;t expect much privacy...free models are usually hosted from providers that store your data)&lt;/p&gt;\\n\\n&lt;p&gt;you can chat with those models on the openrouter chat UI or use the API key on another UI (ie openwebUI)&lt;/p&gt;\\n\\n&lt;p&gt;if you value privacy, use non &amp;#39;free&amp;#39; model on openrouter (look at the providers for every model, everyone has different politics about logging ad data retention).\\nmany models are really cheap and cost arount 1$ per million token.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://openrouter.ai/models?order=pricing-low-to-high\\"&gt;https://openrouter.ai/models?order=pricing-low-to-high&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;about rate limits:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Free usage limits: If you’re using a free model variant (with an ID ending in :free), you can make up to 20 requests per minute. The following per-day limits apply:&lt;/p&gt;\\n\\n&lt;p&gt;If you have purchased less than 10 credits, you’re limited to 50 :free model requests per day.&lt;/p&gt;\\n\\n&lt;p&gt;If you purchase at least 10 credits, your daily limit is increased to 1000 :free model requests per day.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;(all of that assuming that &amp;#39;money&amp;#39; is the only reason for that you want to go local)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31owev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752484891,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31znwh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Logical_Divide_3595","can_mod_post":false,"created_utc":1752490708,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_18riberpl8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can buy a gemini pro account with student subscribed with $20, which is valid till Aug, 2026","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31znwh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can buy a gemini pro account with student subscribed with $20, which is valid till Aug, 2026&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31znwh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752490708,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31zpqe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752490731,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can use DeepSeek for free on the web, or through API","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31zpqe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can use DeepSeek for free on the web, or through API&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n31zpqe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752490731,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3248rv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dragonacious","can_mod_post":false,"created_utc":1752492799,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_vbdiiix7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Saw a video on using Open AI API for using gpt-4o.   \\n  \\nVideo says cost will be far less compared to GPT Plus subscription. Really?\\n\\nIf I use gpt-4o via API, will it be same quality response compared to when using gpt-4o via GPT Plus subscription?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3248rv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Saw a video on using Open AI API for using gpt-4o.   &lt;/p&gt;\\n\\n&lt;p&gt;Video says cost will be far less compared to GPT Plus subscription. Really?&lt;/p&gt;\\n\\n&lt;p&gt;If I use gpt-4o via API, will it be same quality response compared to when using gpt-4o via GPT Plus subscription?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n3248rv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752492799,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n325r2x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pokemonplayer2001","can_mod_post":false,"created_utc":1752493452,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_11qjf3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Is there anything similar out there that gives quality output like gpt-4o or claude and can run locally?\\"\\n\\nNo. And,\\n\\n\\"I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5. Sorry I dont have high specs.\\"\\n\\nNothing you can run will be close to the quality.\\n\\nUse free models with openrouter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n325r2x","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Is there anything similar out there that gives quality output like gpt-4o or claude and can run locally?&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;No. And,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;I got RTX 12 GB Nvidia 3060, 16 gb ram and an i5. Sorry I dont have high specs.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Nothing you can run will be close to the quality.&lt;/p&gt;\\n\\n&lt;p&gt;Use free models with openrouter.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n325r2x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752493452,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32rje9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jakegh","can_mod_post":false,"created_utc":1752501303,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_6vt1n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Use gemini 2.5 pro in google's AI studio for free (for now, anyway).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32rje9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use gemini 2.5 pro in google&amp;#39;s AI studio for free (for now, anyway).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n32rje9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752501303,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33rzv1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752511823,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1. If you have a relative who is a student, you can have them use to their student email to sign-up for Gemini Pro for free. GitHub Education will also offer free Copilot Pro\\n\\n2. You can use AIStudio or its API for free (with generous rate limits) with the knowledge that Google will store and train on your data.\\n\\n3. If you have historically placed $10 of credit on OpenRouter, you can use models with free endpoints up to 1000 requests a day. Note that oftentimes these providers will train on your data.\\n\\n4. OpenAI offers daily complementary tokens on their API (https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h\\\\_4b00a02e1f) if you spend at least $5 in credits. They will train on your data if you enable the option, however, and you have to be careful to have more than $0 balance to use these free tokens.","edited":1752512145,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33rzv1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;If you have a relative who is a student, you can have them use to their student email to sign-up for Gemini Pro for free. GitHub Education will also offer free Copilot Pro&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;You can use AIStudio or its API for free (with generous rate limits) with the knowledge that Google will store and train on your data.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;If you have historically placed $10 of credit on OpenRouter, you can use models with free endpoints up to 1000 requests a day. Note that oftentimes these providers will train on your data.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;OpenAI offers daily complementary tokens on their API (&lt;a href=\\"https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h%5C_4b00a02e1f\\"&gt;https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h\\\\_4b00a02e1f&lt;/a&gt;) if you spend at least $5 in credits. They will train on your data if you enable the option, however, and you have to be careful to have more than $0 balance to use these free tokens.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n33rzv1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752511823,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n343c34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Corporate_Drone31","can_mod_post":false,"created_utc":1752514899,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_32o8hu91","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Save your money for the hardware in the future. Instead, try Kimi K2 from the API. At least on my provider, it's extremely inexpensive, and even a single dollar of query credit will take you far.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n343c34","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Save your money for the hardware in the future. Instead, try Kimi K2 from the API. At least on my provider, it&amp;#39;s extremely inexpensive, and even a single dollar of query credit will take you far.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n343c34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752514899,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35vi4h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1752533503,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_askwa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"just use gemini via the web or deepseek/mistral/etc free via api or kimi for cheap via api","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35vi4h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just use gemini via the web or deepseek/mistral/etc free via api or kimi for cheap via api&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n35vi4h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533503,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36scc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable_Strawberry38","can_mod_post":false,"created_utc":1752544626,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_1r5sypm40v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The core issue you're facing is that local models powerful enough to rival GPT-4o or Claude require very expensive hardware, which contradicts being on a tight budget. For high-quality, reliable output without the hardware investment, you might consider a platform like Jenova. It's a research intelligence platform that routes tasks to the best-suited model, including those from OpenAI and Anthropic, which can provide that top-tier quality you're looking for more consistently than hitting free usage limits.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36scc4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The core issue you&amp;#39;re facing is that local models powerful enough to rival GPT-4o or Claude require very expensive hardware, which contradicts being on a tight budget. For high-quality, reliable output without the hardware investment, you might consider a platform like Jenova. It&amp;#39;s a research intelligence platform that routes tasks to the best-suited model, including those from OpenAI and Anthropic, which can provide that top-tier quality you&amp;#39;re looking for more consistently than hitting free usage limits.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n36scc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544626,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36vlfj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Beginning-Dealer-937","can_mod_post":false,"created_utc":1752545768,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_1tjby93qlu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"that is a classic trade-off: models that rival GPT-4o or Claude in quality require significant hardware, which contradicts being on a tight budget or you can try jenova for a lower price","edited":1752564567,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36vlfj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that is a classic trade-off: models that rival GPT-4o or Claude in quality require significant hardware, which contradicts being on a tight budget or you can try jenova for a lower price&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n36vlfj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752545768,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30h5dq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kevin_1994","can_mod_post":false,"created_utc":1752462398,"send_replies":true,"parent_id":"t3_1lzb7fh","score":1,"author_fullname":"t2_o015g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I actually dont think qwen3 32b is much worse than 4o. If you want o3 or claude, there is only deepseek, and there's no realistic way for you to run it, considering you use the free tier of chatgpt lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30h5dq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually dont think qwen3 32b is much worse than 4o. If you want o3 or claude, there is only deepseek, and there&amp;#39;s no realistic way for you to run it, considering you use the free tier of chatgpt lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30h5dq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462398,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n315dql","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CommunityTough1","can_mod_post":false,"created_utc":1752473644,"send_replies":true,"parent_id":"t1_n30fu4y","score":3,"author_fullname":"t2_1iuzpxw7eg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nah. RTX Pro 6000 Blackwell 96GB is $8k and can easily handle 70B models at 4-bit quants. You wouldn't need to spend $12k for the rest of the setup. You could do a whole Ryzen 9 16-core/32 thread setup with 128GB DDR5 and 1200W 80 Plus Platinum PSU on top of that for another $1,500. That's only $9-10k total. For less than $20k you could have two of those A6000s in that rig and be running models as large as Qwen 3 235B fully on GPU.","edited":1752474068,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n315dql","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nah. RTX Pro 6000 Blackwell 96GB is $8k and can easily handle 70B models at 4-bit quants. You wouldn&amp;#39;t need to spend $12k for the rest of the setup. You could do a whole Ryzen 9 16-core/32 thread setup with 128GB DDR5 and 1200W 80 Plus Platinum PSU on top of that for another $1,500. That&amp;#39;s only $9-10k total. For less than $20k you could have two of those A6000s in that rig and be running models as large as Qwen 3 235B fully on GPU.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzb7fh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n315dql/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473644,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n30fu4y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Square-Onion-1825","can_mod_post":false,"created_utc":1752461881,"send_replies":true,"parent_id":"t3_1lzb7fh","score":0,"author_fullname":"t2_1mkh7x2yxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you need h/w to support 70B+ parameter models. that h/w will cost you over $20k.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30fu4y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you need h/w to support 70B+ parameter models. that h/w will cost you over $20k.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n30fu4y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461881,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n314u59","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wivaca2","can_mod_post":false,"created_utc":1752473353,"send_replies":true,"parent_id":"t3_1lzb7fh","score":0,"author_fullname":"t2_1mwz0wzz62","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gpt4o is probably using the same electricity per user as your monthly home electric bill. Nothing is going to match these that isn't consuming a half a city block of racks in a datacenter and reading the entire internet for training material.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n314u59","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gpt4o is probably using the same electricity per user as your monthly home electric bill. Nothing is going to match these that isn&amp;#39;t consuming a half a city block of racks in a datacenter and reading the entire internet for training material.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzb7fh/any_actual_alternative_to_gpt4o_or_claude/n314u59/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473353,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzb7fh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
