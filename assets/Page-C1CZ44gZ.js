import{j as e}from"./index-BgwOAK4-.js";import{R as t}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I know that most platforms fine-tune their models and use a good system prompt, but I've tried Qwen3 32B locally and on [qwen.com](http://qwen.com) and the difference is so huge.\\n\\nAre there publicly available ready fine-tunes and system prompts I can use to improve the models locally?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Why are base non-finetuned models so bad?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5th6s","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_48vjfixh","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753128457,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I know that most platforms fine-tune their models and use a good system prompt, but I&amp;#39;ve tried Qwen3 32B locally and on &lt;a href=\\"http://qwen.com\\"&gt;qwen.com&lt;/a&gt; and the difference is so huge.&lt;/p&gt;\\n\\n&lt;p&gt;Are there publicly available ready fine-tunes and system prompts I can use to improve the models locally?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m5th6s","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ThatIsNotIllegal","discussion_type":null,"num_comments":17,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/","subreddit_subscribers":502515,"created_utc":1753128457,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ellhm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1753129602,"send_replies":true,"parent_id":"t1_n4eju0n","score":3,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is why I think Mistral should release their larger models, but only in base format as opposed to not at all. We get the use of their base models to fine tune them… and they get to advertise the strength of their instruction models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ellhm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is why I think Mistral should release their larger models, but only in base format as opposed to not at all. We get the use of their base models to fine tune them… and they get to advertise the strength of their instruction models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4ellhm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753129602,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4eym3u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThatIsNotIllegal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4eunkg","score":0,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the sentiment analysis was just an example I still don't have a clear use case this is why I'm trying to figure out what I should be doing next","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eym3u","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the sentiment analysis was just an example I still don&amp;#39;t have a clear use case this is why I&amp;#39;m trying to figure out what I should be doing next&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4eym3u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753133394,"author_flair_text":null,"treatment_tags":[],"created_utc":1753133394,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eunkg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"youcef0w0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4eofpa","score":2,"author_fullname":"t2_49fdoure","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"sentiment analysis is a well explored problem in NLP, plenty of specialized models for that specific use case that run much much faster than a general purpose LLM.\\n\\ntry this one for example:  \\n[https://huggingface.co/tabularisai/multilingual-sentiment-analysis](https://huggingface.co/tabularisai/multilingual-sentiment-analysis)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4eunkg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;sentiment analysis is a well explored problem in NLP, plenty of specialized models for that specific use case that run much much faster than a general purpose LLM.&lt;/p&gt;\\n\\n&lt;p&gt;try this one for example:&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/tabularisai/multilingual-sentiment-analysis\\"&gt;https://huggingface.co/tabularisai/multilingual-sentiment-analysis&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4eunkg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753132198,"author_flair_text":null,"treatment_tags":[],"created_utc":1753132198,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fa27c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WaveCut","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4eofpa","score":1,"author_fullname":"t2_9sufu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a really good question that, to be honest, cannot be answered without experimentation. It would also make a good subject for a research paper.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4fa27c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a really good question that, to be honest, cannot be answered without experimentation. It would also make a good subject for a research paper.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4fa27c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753137025,"author_flair_text":null,"treatment_tags":[],"created_utc":1753137025,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eofpa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThatIsNotIllegal","can_mod_post":false,"created_utc":1753130411,"send_replies":true,"parent_id":"t1_n4eju0n","score":-1,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If I have a specific need like detecting the sentiment in a text for example, is it better to just fine-tune the base model on a few hundred examples of sentiment detection or should i try distilling a general fine-tune from better instruct models?\\n\\n  \\nAre there any open source datasets or fine-tunes I can use to skip this process and just train on the available training set?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eofpa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I have a specific need like detecting the sentiment in a text for example, is it better to just fine-tune the base model on a few hundred examples of sentiment detection or should i try distilling a general fine-tune from better instruct models?&lt;/p&gt;\\n\\n&lt;p&gt;Are there any open source datasets or fine-tunes I can use to skip this process and just train on the available training set?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4eofpa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753130411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eju0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WaveCut","can_mod_post":false,"created_utc":1753129088,"send_replies":true,"parent_id":"t3_1m5th6s","score":14,"author_fullname":"t2_9sufu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Base models are meant for text completion only, not instruction chat.\\n\\nLike, f.e. you input \\"Once upon a time in a faraway galaxy there was a man, named El\\" and get a result like \\"on Musk, who loves to build rockets,\\" etc.\\n\\nIt may entirely ignore your \\"instruction\\", or even expand it because it has no clue of this format; it just completes the text it is fed.\\n\\n\\\\---\\n\\nThus said, they're not bad; they're a universal, in a way, endless repository of human text. With careful steering using fine-tuning they became instruction models as we know it, but they may be fine-tuned in a completely different way and there are examples of weird models based on transformer LLMs that used in med and bio-tech and chemistry, producing not only text but any desired output they are tuned to. Instruct models are just hitting the spotlight because of their versatility as a human replacer.","edited":1753129376,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eju0n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Base models are meant for text completion only, not instruction chat.&lt;/p&gt;\\n\\n&lt;p&gt;Like, f.e. you input &amp;quot;Once upon a time in a faraway galaxy there was a man, named El&amp;quot; and get a result like &amp;quot;on Musk, who loves to build rockets,&amp;quot; etc.&lt;/p&gt;\\n\\n&lt;p&gt;It may entirely ignore your &amp;quot;instruction&amp;quot;, or even expand it because it has no clue of this format; it just completes the text it is fed.&lt;/p&gt;\\n\\n&lt;p&gt;---&lt;/p&gt;\\n\\n&lt;p&gt;Thus said, they&amp;#39;re not bad; they&amp;#39;re a universal, in a way, endless repository of human text. With careful steering using fine-tuning they became instruction models as we know it, but they may be fine-tuned in a completely different way and there are examples of weird models based on transformer LLMs that used in med and bio-tech and chemistry, producing not only text but any desired output they are tuned to. Instruct models are just hitting the spotlight because of their versatility as a human replacer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4eju0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753129088,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fa5ix","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Usual-Corgi-552","can_mod_post":false,"created_utc":1753137055,"send_replies":true,"parent_id":"t1_n4eia35","score":2,"author_fullname":"t2_kjrzem6g1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks that was a helpful way to phrase it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fa5ix","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks that was a helpful way to phrase it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4fa5ix/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753137055,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4f7ab3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4f6f2b","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"with base models? it works somewhat at best. they are not meant for use.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4f7ab3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;with base models? it works somewhat at best. they are not meant for use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4f7ab3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753136118,"author_flair_text":null,"treatment_tags":[],"created_utc":1753136118,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4f6f2b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"apodicity","can_mod_post":false,"created_utc":1753135837,"send_replies":true,"parent_id":"t1_n4eia35","score":1,"author_fullname":"t2_r0x1k85","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They sort of understand all sorts of formats.  You can just make one up, and if you put it in the right place in the context, it just works.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f6f2b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They sort of understand all sorts of formats.  You can just make one up, and if you put it in the right place in the context, it just works.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4f6f2b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135837,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eia35","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"created_utc":1753128650,"send_replies":true,"parent_id":"t3_1m5th6s","score":6,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"base models have not been trained to respond in a chat context. they also don't understand instruct formats (well aside from some basic ones like \\"User:\\" and \\"AI:\\". The purpose of these models is that you can do instruct tuning on them to align them with what you want from the model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eia35","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;base models have not been trained to respond in a chat context. they also don&amp;#39;t understand instruct formats (well aside from some basic ones like &amp;quot;User:&amp;quot; and &amp;quot;AI:&amp;quot;. The purpose of these models is that you can do instruct tuning on them to align them with what you want from the model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4eia35/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753128650,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4f6ron","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThatIsNotIllegal","can_mod_post":false,"created_utc":1753135952,"send_replies":true,"parent_id":"t1_n4f5ypu","score":1,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So basically I have to look into few-shot prompting and give it examples on what it should and shouldn't do? \\n\\nwould it make sense to also include my reasoning so that they are not just picking up random patterns but only the ones I specify?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f6ron","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So basically I have to look into few-shot prompting and give it examples on what it should and shouldn&amp;#39;t do? &lt;/p&gt;\\n\\n&lt;p&gt;would it make sense to also include my reasoning so that they are not just picking up random patterns but only the ones I specify?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4f6ron/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135952,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4f5ypu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"apodicity","can_mod_post":false,"created_utc":1753135689,"send_replies":true,"parent_id":"t3_1m5th6s","score":3,"author_fullname":"t2_r0x1k85","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Base models can be WAY better for long-form writing.  Night and day.  To give them \\"out-of-band\\" information, just make up your own format for the data and throw it in the context somewhere.  These things love patterns.  It'll pick up on it.  CFG can also be helpful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f5ypu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Base models can be WAY better for long-form writing.  Night and day.  To give them &amp;quot;out-of-band&amp;quot; information, just make up your own format for the data and throw it in the context somewhere.  These things love patterns.  It&amp;#39;ll pick up on it.  CFG can also be helpful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4f5ypu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135689,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fpwjt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1753142225,"send_replies":true,"parent_id":"t3_1m5th6s","score":2,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe the model running on their website as a unique system, prompt and other software support like tool calling. The model running on their website is likely not quantized. All these things combined could lead to variations of quality.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fpwjt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe the model running on their website as a unique system, prompt and other software support like tool calling. The model running on their website is likely not quantized. All these things combined could lead to variations of quality.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4fpwjt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753142225,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fuz26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4f6htp","score":1,"author_fullname":"t2_5oltmr5b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well, for example, if you sent a base model a long text followed by \\"\\\\n\\\\n, TLDR:\\" it will generate a quite good summary\\n\\nthey are autocomplete models. that add the most probable token that complete and follow the input text (instruct tuned models work the same obviously, but they know the concept of \\"turns\\" and they \\"know\\" that the environment / context is structured as a chat/conversation. base models doesn't have those concept printed in their weights from SFT/RL). \\n\\nlook at how the autoregressive pretraining work and you will have pretty clear what those models can do.\\n\\nAlso, answering to other messages you wrote here... Just open huggingface and search, there are a lot of datasets for any kind if task. also, probably a model fine tuned for your task already exist, so look at how they trained it (if you are lucky the author will explain the process, or at least which dataset they used, in the model card)","edited":1753144431,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4fuz26","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well, for example, if you sent a base model a long text followed by &amp;quot;\\\\n\\\\n, TLDR:&amp;quot; it will generate a quite good summary&lt;/p&gt;\\n\\n&lt;p&gt;they are autocomplete models. that add the most probable token that complete and follow the input text (instruct tuned models work the same obviously, but they know the concept of &amp;quot;turns&amp;quot; and they &amp;quot;know&amp;quot; that the environment / context is structured as a chat/conversation. base models doesn&amp;#39;t have those concept printed in their weights from SFT/RL). &lt;/p&gt;\\n\\n&lt;p&gt;look at how the autoregressive pretraining work and you will have pretty clear what those models can do.&lt;/p&gt;\\n\\n&lt;p&gt;Also, answering to other messages you wrote here... Just open huggingface and search, there are a lot of datasets for any kind if task. also, probably a model fine tuned for your task already exist, so look at how they trained it (if you are lucky the author will explain the process, or at least which dataset they used, in the model card)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4fuz26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753143988,"author_flair_text":null,"treatment_tags":[],"created_utc":1753143988,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4f6htp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThatIsNotIllegal","can_mod_post":false,"created_utc":1753135862,"send_replies":true,"parent_id":"t1_n4evuqf","score":2,"author_fullname":"t2_48vjfixh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that's actually brilliant, I'll do some more research on few shot prompting it might just be what i need","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f6htp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that&amp;#39;s actually brilliant, I&amp;#39;ll do some more research on few shot prompting it might just be what i need&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5th6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4f6htp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753135862,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4evuqf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"phree_radical","can_mod_post":false,"created_utc":1753132558,"send_replies":true,"parent_id":"t3_1m5th6s","score":3,"author_fullname":"t2_44nkp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you want to understand the power of base models, use few-shot prompts, like the examples in [this thread](https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/)\\n\\nInstruct/chat fine-tuning erodes knowledge and capabilities, installs censorship, and exacerbates the danger of prompt injection, while keeping developers in the dark about how language models can be used.  Don't make posts about them being \\"bad\\" without having some knowledge of how to use them.  \\n If the corpos get their way, we'd never see base models again","edited":1753133138,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4evuqf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you want to understand the power of base models, use few-shot prompts, like the examples in &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/\\"&gt;this thread&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Instruct/chat fine-tuning erodes knowledge and capabilities, installs censorship, and exacerbates the danger of prompt injection, while keeping developers in the dark about how language models can be used.  Don&amp;#39;t make posts about them being &amp;quot;bad&amp;quot; without having some knowledge of how to use them.&lt;br/&gt;\\n If the corpos get their way, we&amp;#39;d never see base models again&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4evuqf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753132558,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fcqgz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Needleworker_5247","can_mod_post":false,"created_utc":1753137903,"send_replies":true,"parent_id":"t3_1m5th6s","score":1,"author_fullname":"t2_1gmprv51a1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you're looking to enhance your local model, exploring open-source datasets from platforms like Hugging Face can be super helpful. They have various fine-tuned models and resources that could serve as a starting point. Crafting a custom fine-tuning on top of a base model could also be worth it if you have a specific task in mind. Check out their community discussions for insights and shared experiences from other devs tackling similar challenges.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fcqgz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re looking to enhance your local model, exploring open-source datasets from platforms like Hugging Face can be super helpful. They have various fine-tuned models and resources that could serve as a starting point. Crafting a custom fine-tuning on top of a base model could also be worth it if you have a specific task in mind. Check out their community discussions for insights and shared experiences from other devs tackling similar challenges.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5th6s/why_are_base_nonfinetuned_models_so_bad/n4fcqgz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753137903,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5th6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(t,{data:l});export{s as default};
