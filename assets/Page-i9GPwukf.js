import{j as e}from"./index-CNyNkRpk.js";import{R as t}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi everyone!\\n\\nWanted to ask a question that's been on my mind recently.\\n\\nI've done LLM research in academia in various forms, each time I thought of a way to improve a certain aspect of LLMs for different tasks, and when asked to prove that my alteration actually improved upon something I almost always had a benchmark to test myself.\\n\\nBut how is LLM evaluation done in real life (i.e. in industry)? If I'm a company that wants to offer a strong coding-assistant, research-assistant or any other type of LLM product - How do I make sure that it's doing a good job?\\n\\nIs it only product related metrics like customer satisfaction and existing benchmarks like in the industry? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"LLM evaluation in real life?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lyq1yh","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.71,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_owqzu42m8","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752404393,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\\n\\n&lt;p&gt;Wanted to ask a question that&amp;#39;s been on my mind recently.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve done LLM research in academia in various forms, each time I thought of a way to improve a certain aspect of LLMs for different tasks, and when asked to prove that my alteration actually improved upon something I almost always had a benchmark to test myself.&lt;/p&gt;\\n\\n&lt;p&gt;But how is LLM evaluation done in real life (i.e. in industry)? If I&amp;#39;m a company that wants to offer a strong coding-assistant, research-assistant or any other type of LLM product - How do I make sure that it&amp;#39;s doing a good job?&lt;/p&gt;\\n\\n&lt;p&gt;Is it only product related metrics like customer satisfaction and existing benchmarks like in the industry? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lyq1yh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Plastic-Bus-7003","discussion_type":null,"num_comments":10,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/","subreddit_subscribers":498343,"created_utc":1752404393,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vrvs7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vp7ta","score":1,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;And also, how do you release a product to the public before you've checked it?\\n\\nI myself ask that about a lot of model releases.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2vrvs7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;And also, how do you release a product to the public before you&amp;#39;ve checked it?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I myself ask that about a lot of model releases.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyq1yh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2vrvs7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752406613,"author_flair_text":null,"treatment_tags":[],"created_utc":1752406613,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wmtkp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nore_se_kra","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vp7ta","score":1,"author_fullname":"t2_1bpvzzmckh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Users can be internal as well.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2wmtkp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Users can be internal as well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyq1yh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2wmtkp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752418197,"author_flair_text":null,"treatment_tags":[],"created_utc":1752418197,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vp7ta","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Plastic-Bus-7003","can_mod_post":false,"created_utc":1752405278,"send_replies":true,"parent_id":"t1_n2vnwzb","score":2,"author_fullname":"t2_owqzu42m8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But that also isn't very reliable no?  \\nAnd also, how do you release a product to the public before you've checked it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vp7ta","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But that also isn&amp;#39;t very reliable no?&lt;br/&gt;\\nAnd also, how do you release a product to the public before you&amp;#39;ve checked it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyq1yh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2vp7ta/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752405278,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vnwzb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752404600,"send_replies":true,"parent_id":"t3_1lyq1yh","score":7,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Users use it and then complain.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vnwzb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Users use it and then complain.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2vnwzb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404600,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vpf99","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1752405380,"send_replies":true,"parent_id":"t3_1lyq1yh","score":3,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looking at it from another angle, getting $company to use $LLM is the same as with most other SaaS products.\\n\\n* Prepare some compact executive level website / slides that praise the product\\n   * Optionally include a few cherry-picked benchmark results - doesn't matter if irrelevant\\n* Find out who at $company is responsible for approving your area of SaaS product\\n* Schedule a biz call with a bit of presentation and offer a special discount, \\"just for $company\\" of course\\n* $company now pays for your SaaS product, no matter whether they actually need it or it's the best solution for them\\n\\nEvaluation usually happens like [a\\\\_beautiful\\\\_rhind](https://www.reddit.com/r/LocalLLaMA/comments/1lyq1yh/comment/n2vnwzb/) said it nicely. Sometimes the solution is just not integrated correctly, people think it's a bad solution and it eventually fades into irrelevance. Very few take the time to do proper evaluation, especially ahead of using it - as doing so takes quite some time and effort. It'd be less time spent (and cost) than introducing it at the company and letting the users deal with it, but that's where companies are often not that efficient. If the product impacts a core area of the company it's a different story though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vpf99","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking at it from another angle, getting $company to use $LLM is the same as with most other SaaS products.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Prepare some compact executive level website / slides that praise the product\\n\\n&lt;ul&gt;\\n&lt;li&gt;Optionally include a few cherry-picked benchmark results - doesn&amp;#39;t matter if irrelevant&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;Find out who at $company is responsible for approving your area of SaaS product&lt;/li&gt;\\n&lt;li&gt;Schedule a biz call with a bit of presentation and offer a special discount, &amp;quot;just for $company&amp;quot; of course&lt;/li&gt;\\n&lt;li&gt;$company now pays for your SaaS product, no matter whether they actually need it or it&amp;#39;s the best solution for them&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Evaluation usually happens like &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lyq1yh/comment/n2vnwzb/\\"&gt;a_beautiful_rhind&lt;/a&gt; said it nicely. Sometimes the solution is just not integrated correctly, people think it&amp;#39;s a bad solution and it eventually fades into irrelevance. Very few take the time to do proper evaluation, especially ahead of using it - as doing so takes quite some time and effort. It&amp;#39;d be less time spent (and cost) than introducing it at the company and letting the users deal with it, but that&amp;#39;s where companies are often not that efficient. If the product impacts a core area of the company it&amp;#39;s a different story though.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2vpf99/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752405380,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vv0tz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShinyAnkleBalls","can_mod_post":false,"created_utc":1752408073,"send_replies":true,"parent_id":"t3_1lyq1yh","score":1,"author_fullname":"t2_2m3au2xb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Usability and use experience evaluations with actual users.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vv0tz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Usability and use experience evaluations with actual users.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2vv0tz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752408073,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2w5w3x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SirSoggybotom","can_mod_post":false,"created_utc":1752412502,"send_replies":true,"parent_id":"t3_1lyq1yh","score":1,"author_fullname":"t2_1t5c2yvwni","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In industry, LLM eval often combines product metrics with real-world testing. Companies frequently conduct A/B testing, where users interact with different versions to see which performs better. User feedback plays a big role, but it's crucial to involve focused usability testing with specific user groups to get actionable insights. Check [this article](https://linktoanexample.com) on industry practices for more details. This helps tailor the models more closely to actual use cases.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2w5w3x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In industry, LLM eval often combines product metrics with real-world testing. Companies frequently conduct A/B testing, where users interact with different versions to see which performs better. User feedback plays a big role, but it&amp;#39;s crucial to involve focused usability testing with specific user groups to get actionable insights. Check &lt;a href=\\"https://linktoanexample.com\\"&gt;this article&lt;/a&gt; on industry practices for more details. This helps tailor the models more closely to actual use cases.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2w5w3x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752412502,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wmd6i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nore_se_kra","can_mod_post":false,"created_utc":1752418056,"send_replies":true,"parent_id":"t3_1lyq1yh","score":1,"author_fullname":"t2_1bpvzzmckh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Doing some internal hype, repeating claims none really can check anyway (20% efficiency gain) and give managers the feeling they have to do something now or they will miss out. Shortly later they will have high level articles about ai strategy and probably press releases. At least in the beginning - now you just have to use the momentum to have a cool solution that actually works for the stakeholder use cases. Hopefully before the initial hype budget runs out. \\n\\nPerhaps you in a different kind of company though?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2wmd6i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doing some internal hype, repeating claims none really can check anyway (20% efficiency gain) and give managers the feeling they have to do something now or they will miss out. Shortly later they will have high level articles about ai strategy and probably press releases. At least in the beginning - now you just have to use the momentum to have a cool solution that actually works for the stakeholder use cases. Hopefully before the initial hype budget runs out. &lt;/p&gt;\\n\\n&lt;p&gt;Perhaps you in a different kind of company though?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2wmd6i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752418056,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wmrlq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"potatolicious","can_mod_post":false,"created_utc":1752418180,"send_replies":true,"parent_id":"t3_1lyq1yh","score":1,"author_fullname":"t2_3936u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Depends on company and whether or not you’re interested in making products that work, or if you’re a hype engine designed to raise VC$. \\n\\nThere’s a whole range:\\n\\n- You don’t do any rigorous evals. All just vibes and whether or not your users *think* the thing works. \\n\\n- You do “evals” but they don’t directly measure LLM outputs (e.g., user satisfaction scores)\\n\\n- You do evals on LLM output directly. You have evaluation data sets you’ve constructed for this task that combine usually some mixture of human raters and algorithmic gates. You put resources into ensuring your evaluation data sets reflect some underlying reality. \\n\\nThe latter group are the only ones serious about the LLM. The vast majority of companies fit into the first two categories.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2wmrlq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends on company and whether or not you’re interested in making products that work, or if you’re a hype engine designed to raise VC$. &lt;/p&gt;\\n\\n&lt;p&gt;There’s a whole range:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;You don’t do any rigorous evals. All just vibes and whether or not your users &lt;em&gt;think&lt;/em&gt; the thing works. &lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;You do “evals” but they don’t directly measure LLM outputs (e.g., user satisfaction scores)&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;You do evals on LLM output directly. You have evaluation data sets you’ve constructed for this task that combine usually some mixture of human raters and algorithmic gates. You put resources into ensuring your evaluation data sets reflect some underlying reality. &lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The latter group are the only ones serious about the LLM. The vast majority of companies fit into the first two categories.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyq1yh/llm_evaluation_in_real_life/n2wmrlq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752418180,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyq1yh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
