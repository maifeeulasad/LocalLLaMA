import{j as e}from"./index-CeRg6Q3f.js";import{R as l}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I was browsing the llama.cpp PRs and saw that Am17an has added diffusion model support in llama.cpp. It works. It's very cool to watch it do it's thing. Make sure to use the --diffusion-visual flag. It's still a PR but has been approved so it should be merged soon.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Diffusion model support in llama.cpp.","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1lze1r3","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.99,"author_flair_background_color":null,"ups":137,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_o65i6kx","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":137,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=77e8aaca890b1dc8486701afa4da4f4e06d486be","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752470404,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I was browsing the llama.cpp PRs and saw that Am17an has added diffusion model support in llama.cpp. It works. It&amp;#39;s very cool to watch it do it&amp;#39;s thing. Make sure to use the --diffusion-visual flag. It&amp;#39;s still a PR but has been approved so it should be merged soon.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/ggml-org/llama.cpp/pull/14644","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?auto=webp&amp;s=e183ff7e541a319425a36dcaf9b80b74c4ff9243","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f661fc69800730ffa673f5aa97b47d5b9e191899","width":108,"height":54},{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4c5410f2c6927b2130b0b8edfce13fc0ce8cd59","width":216,"height":108},{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=aab06d8dbc7317d7ae49105599d33bc04e0c66cf","width":320,"height":160},{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c75c6786f093153f6a5dc5065d5f9e2b741b5086","width":640,"height":320},{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a1002549b1b328880a986274b59212fd91c0e1f","width":960,"height":480},{"url":"https://external-preview.redd.it/X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01b756f299543d2fda31db392dfcbc407ad0faa7","width":1080,"height":540}],"variants":{},"id":"X6RZ_QwBHXWQcBNsgWEp_Ow5ef9fjjqJddTY6M9a0cA"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lze1r3","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"fallingdowndizzyvr","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/","stickied":false,"url":"https://github.com/ggml-org/llama.cpp/pull/14644","subreddit_subscribers":499297,"created_utc":1752470404,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32jhvt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Capable-Ad-7494","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32hyad","score":9,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s why i said it would be on the user client to interpret it properly.\\n\\nThere isn’t an established way to stream models like these yet, as far as i know. You can technically bundle positional info in the streaming api response, but that would also be on the user client to interpret that properly as well.\\n\\nJust thinking of it as a frame of text and handling it like that is probably the easiest way to deal with it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32jhvt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s why i said it would be on the user client to interpret it properly.&lt;/p&gt;\\n\\n&lt;p&gt;There isn’t an established way to stream models like these yet, as far as i know. You can technically bundle positional info in the streaming api response, but that would also be on the user client to interpret that properly as well.&lt;/p&gt;\\n\\n&lt;p&gt;Just thinking of it as a frame of text and handling it like that is probably the easiest way to deal with it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n32jhvt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752498651,"author_flair_text":null,"treatment_tags":[],"created_utc":1752498651,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n32hyad","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harrro","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31kjvd","score":3,"author_fullname":"t2_4axt7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think this would work with the way the streaming (openai-compatible) API works -- there's usually a delta text in the streaming API response and most clients just append that output to the previously-received output (clients don't replace the entire text on every streamed piece).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n32hyad","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think this would work with the way the streaming (openai-compatible) API works -- there&amp;#39;s usually a delta text in the streaming API response and most clients just append that output to the previously-received output (clients don&amp;#39;t replace the entire text on every streamed piece).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n32hyad/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752498118,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1752498118,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n31kjvd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1752482331,"send_replies":true,"parent_id":"t1_n315glj","score":11,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i imagine making this streamable in a rudimentary manner would be just sending the entire output of denoised tokens every time a new one gets denoised.\\n\\nThen it would be in the user client to handle interpreting the stream properly","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31kjvd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i imagine making this streamable in a rudimentary manner would be just sending the entire output of denoised tokens every time a new one gets denoised.&lt;/p&gt;\\n\\n&lt;p&gt;Then it would be in the user client to handle interpreting the stream properly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n31kjvd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482331,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n315glj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"muxxington","can_mod_post":false,"created_utc":1752473688,"send_replies":true,"parent_id":"t3_1lze1r3","score":23,"author_fullname":"t2_1ktdmsvo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice. But how will this be implemented in llama-server? Will streaming still be possible with this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n315glj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice. But how will this be implemented in llama-server? Will streaming still be possible with this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n315glj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473688,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lze1r3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n388qul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"paryska99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3551gz","score":1,"author_fullname":"t2_10v86q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exactly my thoughts, makes you wonder if that would be the better direction to take with all the reasoning LLMs instead of making the LLMs spit out  a thousand tokens first.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n388qul","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly my thoughts, makes you wonder if that would be the better direction to take with all the reasoning LLMs instead of making the LLMs spit out  a thousand tokens first.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n388qul/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752569277,"author_flair_text":null,"treatment_tags":[],"created_utc":1752569277,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3551gz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Semi_Tech","can_mod_post":false,"created_utc":1752525569,"send_replies":true,"parent_id":"t1_n33tmn3","score":3,"author_fullname":"t2_kbar9qn28","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Whenever i see this I wonder what would happen to benchmark results at 10/100/1000/10k steps\\n\\nIt would take ALOT to run but it could be something that van be left overnight just to see what comes out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3551gz","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Whenever i see this I wonder what would happen to benchmark results at 10/100/1000/10k steps&lt;/p&gt;\\n\\n&lt;p&gt;It would take ALOT to run but it could be something that van be left overnight just to see what comes out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n3551gz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525569,"author_flair_text":"Ollama","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n33tmn3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"paryska99","can_mod_post":false,"created_utc":1752512263,"send_replies":true,"parent_id":"t3_1lze1r3","score":3,"author_fullname":"t2_10v86q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I love seeing new directions people take LLMs. Diffusion sure seems like a good one to explore, considering it can refine output with chosen number of steps.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33tmn3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love seeing new directions people take LLMs. Diffusion sure seems like a good one to explore, considering it can refine output with chosen number of steps.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n33tmn3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752512263,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lze1r3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33wkpn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zc5Gwu","can_mod_post":false,"created_utc":1752513079,"send_replies":true,"parent_id":"t3_1lze1r3","score":3,"author_fullname":"t2_67qrvlir","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope eventually there is an FIM model. Imagine crazy fast and accurate code completion. No http calls means you could complete large chunks of code in less than a couple hundred milliseconds.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33wkpn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope eventually there is an FIM model. Imagine crazy fast and accurate code completion. No http calls means you could complete large chunks of code in less than a couple hundred milliseconds.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n33wkpn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752513079,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lze1r3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34ediq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wh33t","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31l4pk","score":1,"author_fullname":"t2_b74xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh excellent!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34ediq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh excellent!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n34ediq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517950,"author_flair_text":null,"treatment_tags":[],"created_utc":1752517950,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n31l4pk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"created_utc":1752482676,"send_replies":true,"parent_id":"t1_n31jjgn","score":15,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If I understand correctly it's diffusion based text generation, not image.\\n\\nSee e.g. https://huggingface.co/apple/DiffuCoder-7B-cpGRPO\\n\\nAnd there's a cool animated GIF in the PR showing the progress of the diffusion:\\n\\nhttps://github.com/ggml-org/llama.cpp/pull/14644","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31l4pk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I understand correctly it&amp;#39;s diffusion based text generation, not image.&lt;/p&gt;\\n\\n&lt;p&gt;See e.g. &lt;a href=\\"https://huggingface.co/apple/DiffuCoder-7B-cpGRPO\\"&gt;https://huggingface.co/apple/DiffuCoder-7B-cpGRPO&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;And there&amp;#39;s a cool animated GIF in the PR showing the progress of the diffusion:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/14644\\"&gt;https://github.com/ggml-org/llama.cpp/pull/14644&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n31l4pk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482676,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31ofg1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1752484614,"send_replies":true,"parent_id":"t1_n31jjgn","score":5,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No\\n\\nThere has been work to make diffusion text generation possible as well, same concept as image generation, but instead of pixels, it's text.\\n\\nIn theory you could make more optimised models this was as well, and bigger, while using less space. In theory","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31ofg1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No&lt;/p&gt;\\n\\n&lt;p&gt;There has been work to make diffusion text generation possible as well, same concept as image generation, but instead of pixels, it&amp;#39;s text.&lt;/p&gt;\\n\\n&lt;p&gt;In theory you could make more optimised models this was as well, and bigger, while using less space. In theory&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n31ofg1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752484614,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34dr0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shroddy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32zfzd","score":1,"author_fullname":"t2_10idu2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or svg","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n34dr0j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or svg&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n34dr0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517770,"author_flair_text":null,"treatment_tags":[],"created_utc":1752517770,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n32zfzd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xignaceh","can_mod_post":false,"created_utc":1752503691,"send_replies":true,"parent_id":"t1_n31jjgn","score":1,"author_fullname":"t2_7ec9wuz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Kinda, if you ask it to make ASCII-art ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32zfzd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kinda, if you ask it to make ASCII-art ;)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lze1r3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n32zfzd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752503691,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n31jjgn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"wh33t","can_mod_post":false,"created_utc":1752481723,"send_replies":true,"parent_id":"t3_1lze1r3","score":-5,"author_fullname":"t2_b74xb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"So you can generate images directly in llama.cpp now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31jjgn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So you can generate images directly in llama.cpp now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lze1r3/diffusion_model_support_in_llamacpp/n31jjgn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752481723,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lze1r3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
