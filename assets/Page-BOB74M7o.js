import{j as e}from"./index-cvG704yx.js";import{R as l}from"./RedditPostRenderer-CBthLTAH.js";import"./index-D-GavSZU.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Based on the this [benchmark for coding and UI/UX](https://www.designarena.ai/leaderboard), the Llama models are absolutely horrendous when it comes to build websites, apps, and other kinds of user interfaces. \\n\\nHow is Llama this bad and Meta so behind on AI compared to everyone else? No wonder they're trying to poach every top AI researcher out there. \\n\\n[Llama Examples](https://www.designarena.ai/models/llama-4-scout)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"is_gallery":true,"title":"How and why is Llama so behind the other models at coding and UI/UX? Who is even using it?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":74,"top_awarded_type":null,"name":"t3_1lrvlsx","media_metadata":{"uh0dpa2rsxaf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":62,"x":108,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eebaebedefb7e6d4e8ff5df1affbd89ae578bf8a"},{"y":125,"x":216,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=66951caca8dfec2a4ca9db0ac6c26d344c4cbabf"},{"y":186,"x":320,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba2f50c343073de41862a2096f915bfd3fb6563c"},{"y":372,"x":640,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1fe85bccfa08dd07358d039a3aa1a45726b94800"},{"y":558,"x":960,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a15f7ace8eb7191fcf63f515802cee1d796c8d8f"},{"y":627,"x":1080,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=24609a96b4ac923e07198a1c59f740532d7c73b8"}],"s":{"y":1480,"x":2546,"u":"https://preview.redd.it/uh0dpa2rsxaf1.png?width=2546&amp;format=png&amp;auto=webp&amp;s=e3cb26cf0342dafcd6eeb977bd85a8593aa31eb6"},"id":"uh0dpa2rsxaf1"},"ds1hszgcsxaf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":57,"x":108,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cb9c84690474a26bbf87a9bfb1bd998b8970eca"},{"y":114,"x":216,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=28e294c8871af2545ca0260bb16bd2ff24e49b0f"},{"y":170,"x":320,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e9139ca024158104ada0bc31ba3a8a76e068556"},{"y":340,"x":640,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=22ef93d523e44b3613360f466e305ef60cc4482c"},{"y":510,"x":960,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9dd93ea41aed35e1e594fc7d97a90744a229e8d8"},{"y":574,"x":1080,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=86aa10a177a70ed19f43406337ecaf7bc483a8c9"}],"s":{"y":1396,"x":2626,"u":"https://preview.redd.it/ds1hszgcsxaf1.png?width=2626&amp;format=png&amp;auto=webp&amp;s=641ae6f2f1ad5b242d23fef71ccef731b86d8dd5"},"id":"ds1hszgcsxaf1"}},"hide_score":false,"quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.71,"author_flair_background_color":null,"ups":26,"domain":"reddit.com","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_15wmlp183l","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"gallery_data":{"items":[{"media_id":"ds1hszgcsxaf1","id":698864361},{"media_id":"uh0dpa2rsxaf1","id":698864362}]},"link_flair_text":"Discussion","can_mod_post":false,"score":26,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/ky0nsIz_RJXchcUklbRQzW-JFzxABDUvpQ9m5bMNp2o.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"subreddit_type":"public","created":1751669552,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Based on the this &lt;a href=\\"https://www.designarena.ai/leaderboard\\"&gt;benchmark for coding and UI/UX&lt;/a&gt;, the Llama models are absolutely horrendous when it comes to build websites, apps, and other kinds of user interfaces. &lt;/p&gt;\\n\\n&lt;p&gt;How is Llama this bad and Meta so behind on AI compared to everyone else? No wonder they&amp;#39;re trying to poach every top AI researcher out there. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.designarena.ai/models/llama-4-scout\\"&gt;Llama Examples&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.reddit.com/gallery/1lrvlsx","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lrvlsx","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"idwiw_wiw","discussion_type":null,"num_comments":31,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/","stickied":false,"url":"https://www.reddit.com/gallery/1lrvlsx","subreddit_subscribers":494987,"created_utc":1751669552,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1egizd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"created_utc":1751678213,"send_replies":true,"parent_id":"t1_n1e15g5","score":18,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is a perfect summary.\\n\\nUse the right tool for the right job.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1egizd","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a perfect summary.&lt;/p&gt;\\n\\n&lt;p&gt;Use the right tool for the right job.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1egizd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751678213,"author_flair_text":":X:","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1e6fi1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1751673972,"send_replies":true,"parent_id":"t1_n1e15g5","score":11,"author_fullname":"t2_askwa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama is #1 for support agents lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1e6fi1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama is #1 for support agents lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1e6fi1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751673972,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1fi4li","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hidden_kid","can_mod_post":false,"created_utc":1751696242,"send_replies":true,"parent_id":"t1_n1e15g5","score":2,"author_fullname":"t2_3jo1n877","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wasn't aware that tt has a structured output, but yes, not all models need to be good at coding as there are more things out there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1fi4li","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wasn&amp;#39;t aware that tt has a structured output, but yes, not all models need to be good at coding as there are more things out there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1fi4li/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751696242,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1gpq4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1goiok","score":-29,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"So many words, so much derision, so little information to actually help inform us.\\n\\nTell us, oh informed one, what was…. Oh I don’t care.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1gpq4e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So many words, so much derision, so little information to actually help inform us.&lt;/p&gt;\\n\\n&lt;p&gt;Tell us, oh informed one, what was…. Oh I don’t care.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1gpq4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751720515,"author_flair_text":null,"treatment_tags":[],"created_utc":1751720515,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-29}}],"before":null}},"user_reports":[],"saved":false,"id":"n1goiok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1g7249","score":15,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you know what the largest training data source for Llama is? Hint: It's not Facebook comments.\\n\\nDo you know what the largest training data source for Gemini is? Hint: It's not Google searches.\\n\\nDo you know what the largest training data source for Grok is? Hint: It's not tweets.\\n\\nDo you know what the largest training data source for Qwen is? Hint: It's not Alibaba product descriptions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1goiok","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know what the largest training data source for Llama is? Hint: It&amp;#39;s not Facebook comments.&lt;/p&gt;\\n\\n&lt;p&gt;Do you know what the largest training data source for Gemini is? Hint: It&amp;#39;s not Google searches.&lt;/p&gt;\\n\\n&lt;p&gt;Do you know what the largest training data source for Grok is? Hint: It&amp;#39;s not tweets.&lt;/p&gt;\\n\\n&lt;p&gt;Do you know what the largest training data source for Qwen is? Hint: It&amp;#39;s not Alibaba product descriptions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1goiok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751720018,"author_flair_text":":X:","treatment_tags":[],"created_utc":1751720018,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n1g7249","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nay-byde","can_mod_post":false,"created_utc":1751711344,"send_replies":true,"parent_id":"t1_n1e15g5","score":2,"author_fullname":"t2_rjqnggzlt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Who would've thought Facebook comments make shit data for training LLM","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1g7249","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Who would&amp;#39;ve thought Facebook comments make shit data for training LLM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1g7249/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751711344,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1e15g5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nullmove","can_mod_post":false,"created_utc":1751671915,"send_replies":true,"parent_id":"t3_1lrvlsx","score":66,"author_fullname":"t2_aq4j0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Who is even using it?\\n\\nFor this cycle Meta almost exclusively cared about needs of (certain) enterprise clients, not single users like your. It's good for large scale text processing where dumb but fast, cheap at scale, and reliable structured output and function calling matters more.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1e15g5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Who is even using it?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;For this cycle Meta almost exclusively cared about needs of (certain) enterprise clients, not single users like your. It&amp;#39;s good for large scale text processing where dumb but fast, cheap at scale, and reliable structured output and function calling matters more.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1e15g5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751671915,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":66}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1gc93y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"maturelearner4846","can_mod_post":false,"created_utc":1751714240,"send_replies":true,"parent_id":"t1_n1egnz6","score":8,"author_fullname":"t2_e4yu0f7u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"AI engineers post chatgpt era","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1gc93y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI engineers post chatgpt era&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1gc93y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751714240,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1egnz6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"created_utc":1751678272,"send_replies":true,"parent_id":"t3_1lrvlsx","score":34,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Meta so behind on AI\\n\\ndo you know what Pytorch is?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1egnz6","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Meta so behind on AI&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;do you know what Pytorch is?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1egnz6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751678272,"author_flair_text":":X:","treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1f5358","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1751689284,"send_replies":true,"parent_id":"t1_n1ew91k","score":7,"author_fullname":"t2_1k4sjdwzk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama4 was trained to be good at chatting and does it well. People have fun with it on whatsapp group chats","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1f5358","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama4 was trained to be good at chatting and does it well. People have fun with it on whatsapp group chats&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1f5358/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751689284,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1m4wn1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Inevitable_Host_1446","can_mod_post":false,"created_utc":1751798640,"send_replies":true,"parent_id":"t1_n1ew91k","score":1,"author_fullname":"t2_cw4nm3sx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tried it recently for story writing and it seemed really lackluster. Extremely sterile sounding and had no creativity. I have 12b models that are far better for that purpose, like far far better - though this is mostly down to prose quality and not intellect.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m4wn1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried it recently for story writing and it seemed really lackluster. Extremely sterile sounding and had no creativity. I have 12b models that are far better for that purpose, like far far better - though this is mostly down to prose quality and not intellect.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1m4wn1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751798640,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ew91k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1751685133,"send_replies":true,"parent_id":"t3_1lrvlsx","score":11,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Meta screwed the pooch with Llama4.  It's not just bad at codegen; it's bad at everything else, too.\\n\\nZuck is pissed and has assumed personal charge over a new R&amp;D team, which he is spending $29billion to fill out with top talent.\\n\\nTime will tell if that works out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ew91k","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta screwed the pooch with Llama4.  It&amp;#39;s not just bad at codegen; it&amp;#39;s bad at everything else, too.&lt;/p&gt;\\n\\n&lt;p&gt;Zuck is pissed and has assumed personal charge over a new R&amp;amp;D team, which he is spending $29billion to fill out with top talent.&lt;/p&gt;\\n\\n&lt;p&gt;Time will tell if that works out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1ew91k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751685133,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1dvp4v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NNN_Throwaway2","can_mod_post":false,"created_utc":1751669857,"send_replies":true,"parent_id":"t3_1lrvlsx","score":12,"author_fullname":"t2_8rrihts9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably because scout and maverick are smaller than almost every other model on the list.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1dvp4v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably because scout and maverick are smaller than almost every other model on the list.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1dvp4v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751669857,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1eht1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"synn89","can_mod_post":false,"created_utc":1751678764,"send_replies":true,"parent_id":"t3_1lrvlsx","score":7,"author_fullname":"t2_3jm4t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It feels like with Llama 4 they chased a new architecture type and had some learning pains. Hopefully we get a better releases from them next time. It's not great to be dependent on China for good open weight models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1eht1h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It feels like with Llama 4 they chased a new architecture type and had some learning pains. Hopefully we get a better releases from them next time. It&amp;#39;s not great to be dependent on China for good open weight models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1eht1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751678764,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1hqq9a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"this-just_in","can_mod_post":false,"created_utc":1751733109,"send_replies":true,"parent_id":"t3_1lrvlsx","score":2,"author_fullname":"t2_kdmu4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Everyone seems to forget about Llama4 fine tunes that were all the rave here, topping LMArena charts under their anonymous names.  I don’t think Maverick and Scout are bad, but we didn’t get the best versions of them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1hqq9a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everyone seems to forget about Llama4 fine tunes that were all the rave here, topping LMArena charts under their anonymous names.  I don’t think Maverick and Scout are bad, but we didn’t get the best versions of them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1hqq9a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751733109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1m569e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Inevitable_Host_1446","can_mod_post":false,"created_utc":1751798790,"send_replies":true,"parent_id":"t1_n1fqnno","score":1,"author_fullname":"t2_cw4nm3sx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I suppose Maverick/Scout would both run vastly faster than Qwen 235b, since it's a dense model as opposed to MoE. However I recently tried both of these and Qwen was vastly better, at least for writing. Same with Deepseek.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m569e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I suppose Maverick/Scout would both run vastly faster than Qwen 235b, since it&amp;#39;s a dense model as opposed to MoE. However I recently tried both of these and Qwen was vastly better, at least for writing. Same with Deepseek.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1m569e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751798790,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1h28a6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rorowhat","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1g935y","score":1,"author_fullname":"t2_yq51a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you mean by virtual understanding and what variant are you running?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1h28a6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you mean by virtual understanding and what variant are you running?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1h28a6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751725230,"author_flair_text":null,"treatment_tags":[],"created_utc":1751725230,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1g935y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xanduonc","can_mod_post":false,"created_utc":1751712510,"send_replies":true,"parent_id":"t1_n1fqnno","score":1,"author_fullname":"t2_10n3b6gg97","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is good enough at visual understanding for me to use it mostly on cpu","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1g935y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is good enough at visual understanding for me to use it mostly on cpu&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1g935y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751712510,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1fqnno","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mitchins-au","can_mod_post":false,"created_utc":1751701231,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_4hjtgq5u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are people on this Reddit even using Llama 4?\\nLlama 3 has some good fine tunes of the 70B model from both distills and creative writing, but why bother with Llama 4? If you can run maverick or scout you can probably run Qwen3-235B and if not there’s Qwen3-30B which scout should have been.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1fqnno","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are people on this Reddit even using Llama 4?\\nLlama 3 has some good fine tunes of the 70B model from both distills and creative writing, but why bother with Llama 4? If you can run maverick or scout you can probably run Qwen3-235B and if not there’s Qwen3-30B which scout should have been.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1fqnno/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751701231,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1gxdzq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slow_Release_6144","can_mod_post":false,"created_utc":1751723495,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_15cm47epmz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was looking at it last night…so embarrassing the target audience they made it for which you can see from the promo pics and videos","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1gxdzq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was looking at it last night…so embarrassing the target audience they made it for which you can see from the promo pics and videos&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1gxdzq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751723495,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1h3okq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BidWestern1056","can_mod_post":false,"created_utc":1751725721,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_uzxql7po","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i still use llama3.2 for some things but nothing newer can really work locally so 😕","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1h3okq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i still use llama3.2 for some things but nothing newer can really work locally so 😕&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1h3okq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751725721,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1hlejo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"createthiscom","can_mod_post":false,"created_utc":1751731353,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_ozxxf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Meta is using it in their own platforms, I imagine. They probably care more about convincing catfish style conversations and advertising style headlines than anything else. Their goal is to sell advertising space, so the longer they can keep you engaged with their dumb-ass bot the more money they make.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1hlejo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta is using it in their own platforms, I imagine. They probably care more about convincing catfish style conversations and advertising style headlines than anything else. Their goal is to sell advertising space, so the longer they can keep you engaged with their dumb-ass bot the more money they make.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1hlejo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751731353,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"609bf7d4-01f3-11f0-9760-5611c8333bee","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1iitas","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Anthonyg5005","can_mod_post":false,"created_utc":1751741939,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_3us4bz8y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Because it's basically just llama 3 as moes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1iitas","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"exllama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because it&amp;#39;s basically just llama 3 as moes&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1iitas/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751741939,"author_flair_text":"exllama","treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1j4r4v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Popular-Direction984","can_mod_post":false,"created_utc":1751749196,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_fugduoos","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nobody. Llama has never been useful. At first, it was eclipsed by Mistral, then Qwen took the lead.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1j4r4v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nobody. Llama has never been useful. At first, it was eclipsed by Mistral, then Qwen took the lead.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1j4r4v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751749196,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1fk2jd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"az226","can_mod_post":false,"created_utc":1751697354,"send_replies":true,"parent_id":"t3_1lrvlsx","score":1,"author_fullname":"t2_yamxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s why they poached top AI researchers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1fk2jd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s why they poached top AI researchers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1fk2jd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751697354,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1g811w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AdIllustrious436","can_mod_post":false,"created_utc":1751711912,"send_replies":true,"parent_id":"t1_n1e5ba8","score":7,"author_fullname":"t2_562xjcrr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"3 months is not \\"super old\\" ... 😑","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1g811w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3 months is not &amp;quot;super old&amp;quot; ... 😑&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1g811w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751711912,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n1e5ba8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Betadoggo_","can_mod_post":false,"created_utc":1751673522,"send_replies":true,"parent_id":"t3_1lrvlsx","score":-6,"author_fullname":"t2_a177eog2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"llama 4 is super old now and likely has fewer active parameters than every other model listed (other than qwen). The llama 4 that was released was seemingly rushed together from scratch after deepseek r1 came out. They likely had limited time to run ablations. Their plan to distill from the larger Behemoth variant was also a failure, because the Behemoth variant wasn't finished yet, and also underperformed, likely due to poor data mix or training practices.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1e5ba8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama 4 is super old now and likely has fewer active parameters than every other model listed (other than qwen). The llama 4 that was released was seemingly rushed together from scratch after deepseek r1 came out. They likely had limited time to run ablations. Their plan to distill from the larger Behemoth variant was also a failure, because the Behemoth variant wasn&amp;#39;t finished yet, and also underperformed, likely due to poor data mix or training practices.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1e5ba8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751673522,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ipt6x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grabber4321","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1h2rjr","score":1,"author_fullname":"t2_1180s0gl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes if you specify prebuilt UI/UX framework like Bootstrap.\\n\\nBut if its plain CSS, there's 0 chance it can do what I do when I receive a design for a website.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1ipt6x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes if you specify prebuilt UI/UX framework like Bootstrap.&lt;/p&gt;\\n\\n&lt;p&gt;But if its plain CSS, there&amp;#39;s 0 chance it can do what I do when I receive a design for a website.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1ipt6x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751744278,"author_flair_text":null,"treatment_tags":[],"created_utc":1751744278,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1h2rjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"my_name_isnt_clever","can_mod_post":false,"created_utc":1751725413,"send_replies":true,"parent_id":"t1_n1g027e","score":2,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Vision in general is way, way behind compared to text understanding. If you describe what you want in words lots of models can build UIs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1h2rjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Vision in general is way, way behind compared to text understanding. If you describe what you want in words lots of models can build UIs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrvlsx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1h2rjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751725413,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1g027e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grabber4321","can_mod_post":false,"created_utc":1751707012,"send_replies":true,"parent_id":"t3_1lrvlsx","score":-1,"author_fullname":"t2_1180s0gl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All of them suck at UI/UX. I havent found a model that can take an image and create a website yet. \\n\\nClosest was Cursor actually. But result was very weak and barely working.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1g027e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All of them suck at UI/UX. I havent found a model that can take an image and create a website yet. &lt;/p&gt;\\n\\n&lt;p&gt;Closest was Cursor actually. But result was very weak and barely working.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrvlsx/how_and_why_is_llama_so_behind_the_other_models/n1g027e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751707012,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lrvlsx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
