import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Alright so basically - I want to run qwen3 235b MoE. I dont wanna pay 235b MoE money tho. So far I've been eyeing grabbing an old dell xeon workstation, slapping in lots of RAM &amp; two mi50 cards &amp; calling it a day. Would that work? probably i guess, hell you'd even get good performance out of that running 32b models which do the job for most cases. but i want real crackhead technology. completely out of the box shit. the funnier in its sheer absurdity/cheaper/faster the better. let's hear what you guys can think of ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What's the most crackhead garbage local LLM setup you can think of?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m4u7j6","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.87,"author_flair_background_color":null,"subreddit_type":"public","ups":58,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_9y0b4xlc","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":58,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753031293,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Alright so basically - I want to run qwen3 235b MoE. I dont wanna pay 235b MoE money tho. So far I&amp;#39;ve been eyeing grabbing an old dell xeon workstation, slapping in lots of RAM &amp;amp; two mi50 cards &amp;amp; calling it a day. Would that work? probably i guess, hell you&amp;#39;d even get good performance out of that running 32b models which do the job for most cases. but i want real crackhead technology. completely out of the box shit. the funnier in its sheer absurdity/cheaper/faster the better. let&amp;#39;s hear what you guys can think of &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m4u7j6","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"caraccidentGAMING","discussion_type":null,"num_comments":61,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/","subreddit_subscribers":502722,"created_utc":1753031293,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4amvv1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4a20dv","score":-1,"author_fullname":"t2_13jvln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, I understand computers buddy. I've been writing C professionally for years.\\n\\nNone of that changes the fact that the whole point of this was building a ridiculous raid 0 array and skimping on everything else.\\n\\nNo matter what, when parameters are needed that aren't already closer to the cpu there will be something that causes it to be loaded. \\n\\nPre-loading the next layer with read() might help a bit since there will be many many page faults.  but you can't do anything smart with moe because you don't know what expert layers are needed until *right* before you need them, it's literally the last calculation done before the params are needed.\\n\\nAlso, this would be a cold, random access pattern, see benchmarks here \\n\\nhttps://sasha-f.medium.com/why-mmap-is-faster-than-system-calls-24718e75ab37","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4amvv1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I understand computers buddy. I&amp;#39;ve been writing C professionally for years.&lt;/p&gt;\\n\\n&lt;p&gt;None of that changes the fact that the whole point of this was building a ridiculous raid 0 array and skimping on everything else.&lt;/p&gt;\\n\\n&lt;p&gt;No matter what, when parameters are needed that aren&amp;#39;t already closer to the cpu there will be something that causes it to be loaded. &lt;/p&gt;\\n\\n&lt;p&gt;Pre-loading the next layer with read() might help a bit since there will be many many page faults.  but you can&amp;#39;t do anything smart with moe because you don&amp;#39;t know what expert layers are needed until &lt;em&gt;right&lt;/em&gt; before you need them, it&amp;#39;s literally the last calculation done before the params are needed.&lt;/p&gt;\\n\\n&lt;p&gt;Also, this would be a cold, random access pattern, see benchmarks here &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://sasha-f.medium.com/why-mmap-is-faster-than-system-calls-24718e75ab37\\"&gt;https://sasha-f.medium.com/why-mmap-is-faster-than-system-calls-24718e75ab37&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4amvv1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753077600,"author_flair_text":null,"treatment_tags":[],"created_utc":1753077600,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4a20dv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49x9rd","score":6,"author_fullname":"t2_lpdsy","approved_by":null,"mod_note":null,"all_awardings":[],"body":"That is a misunderstanding of how computers work... as I alluded to in my original post, the processor can't do anything with data from a disk until it's been DMAed into main memory.  So you can't \\"run it from disk\\".  Recent technologies do aim to change this:\\n\\n- SDCI/DDIO: This _still_ puts the data into main memory _technically_, but it actually puts it into L3 cache first.  So if you're clever you can overwrite the cache before the memory controller flushes it back to main memory.\\n- NVME-oC: This basically just exposes the NVMe's memory buffer as CXL memory.  With this (which AFAIK doesn't exist yet) the data won't actually have an address in main memory so would be like running \\"from disk\\".\\n\\nIn either scenario, however, you would still want to move away from mmap.  Less because of the page faults and more because getting benefits out of these techs would require careful coordination with the storage to make sure it's reading what you need before you need it.  Like NVME-oC is nice because it means you don't need a hard fault and kswapd to manage accesses anymore, but it really just moves the blocking I/O to the hardware.  You'll get a lot better performance if you, say, pre-load the next layer or required experts because the CPU actually needs them for calculations.  mmap simply isn't smart enough to do that (especially with MoE)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4a20dv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That is a misunderstanding of how computers work... as I alluded to in my original post, the processor can&amp;#39;t do anything with data from a disk until it&amp;#39;s been DMAed into main memory.  So you can&amp;#39;t &amp;quot;run it from disk&amp;quot;.  Recent technologies do aim to change this:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;SDCI/DDIO: This &lt;em&gt;still&lt;/em&gt; puts the data into main memory &lt;em&gt;technically&lt;/em&gt;, but it actually puts it into L3 cache first.  So if you&amp;#39;re clever you can overwrite the cache before the memory controller flushes it back to main memory.&lt;/li&gt;\\n&lt;li&gt;NVME-oC: This basically just exposes the NVMe&amp;#39;s memory buffer as CXL memory.  With this (which AFAIK doesn&amp;#39;t exist yet) the data won&amp;#39;t actually have an address in main memory so would be like running &amp;quot;from disk&amp;quot;.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;In either scenario, however, you would still want to move away from mmap.  Less because of the page faults and more because getting benefits out of these techs would require careful coordination with the storage to make sure it&amp;#39;s reading what you need before you need it.  Like NVME-oC is nice because it means you don&amp;#39;t need a hard fault and kswapd to manage accesses anymore, but it really just moves the blocking I/O to the hardware.  You&amp;#39;ll get a lot better performance if you, say, pre-load the next layer or required experts because the CPU actually needs them for calculations.  mmap simply isn&amp;#39;t smart enough to do that (especially with MoE)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4a20dv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753067907,"author_flair_text":null,"treatment_tags":[],"created_utc":1753067907,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n49x9rd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49wu0o","score":-2,"author_fullname":"t2_13jvln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The scenario isn't loading an entire model to ram. It's running one *from disk*.\\n\\nYou have the context switch no matter what.","edited":false,"author_flair_css_class":null,"name":"t1_n49x9rd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The scenario isn&amp;#39;t loading an entire model to ram. It&amp;#39;s running one &lt;em&gt;from disk&lt;/em&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;You have the context switch no matter what.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49x9rd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066020,"author_flair_text":null,"collapsed":false,"created_utc":1753066020,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n49wu0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49twev","score":9,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you know how mmap works?  [Here's a source I found in like 10 seconds of searching](https://huonw.github.io/blog/2024/08/async-hazard-mmap/).  IDK how relevant it is because if you have experience with high performance computing the problem is obvious.\\n\\nmmap is fine for what it is, but what it is is a bad tool for this job.  Any access to a missing page hard faults, **stopping execution of the thread** until an I/O operation can be scheduled to fill the missing data.  On top of that, swapping in data means the system also needs to swap out data, marking those pages as a new performance hazard.  That task is handled by the single threaded kswapd and can easily pin a core at 100% with all that.\\n\\nI also reported my benchmark numbers.  You are welcome to run them yourself, it's quite simple to do.  I can get 12GBps from my storage (via fio).  I get 7-8GBps initially loading a model (mmap before I run out of RAM) then it drops to about 3-5GBps (mmap still loading but now swapping out older pages).  During inference I get 2GBps (mmap with page faults).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49wu0o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know how mmap works?  &lt;a href=\\"https://huonw.github.io/blog/2024/08/async-hazard-mmap/\\"&gt;Here&amp;#39;s a source I found in like 10 seconds of searching&lt;/a&gt;.  IDK how relevant it is because if you have experience with high performance computing the problem is obvious.&lt;/p&gt;\\n\\n&lt;p&gt;mmap is fine for what it is, but what it is is a bad tool for this job.  Any access to a missing page hard faults, &lt;strong&gt;stopping execution of the thread&lt;/strong&gt; until an I/O operation can be scheduled to fill the missing data.  On top of that, swapping in data means the system also needs to swap out data, marking those pages as a new performance hazard.  That task is handled by the single threaded kswapd and can easily pin a core at 100% with all that.&lt;/p&gt;\\n\\n&lt;p&gt;I also reported my benchmark numbers.  You are welcome to run them yourself, it&amp;#39;s quite simple to do.  I can get 12GBps from my storage (via fio).  I get 7-8GBps initially loading a model (mmap before I run out of RAM) then it drops to about 3-5GBps (mmap still loading but now swapping out older pages).  During inference I get 2GBps (mmap with page faults).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49wu0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753065849,"author_flair_text":null,"treatment_tags":[],"created_utc":1753065849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n49twev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49nxeh","score":-6,"author_fullname":"t2_13jvln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"mmap inefficient eh?\\n\\nSource? As something of a unix person myself, I suspect you don't have one. *ESPECIALLY* one that would match the use case here.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n49twev","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mmap inefficient eh?&lt;/p&gt;\\n\\n&lt;p&gt;Source? As something of a unix person myself, I suspect you don&amp;#39;t have one. &lt;em&gt;ESPECIALLY&lt;/em&gt; one that would match the use case here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49twev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753064728,"author_flair_text":null,"treatment_tags":[],"created_utc":1753064728,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"n49nxeh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"created_utc":1753062502,"send_replies":true,"parent_id":"t1_n47f3if","score":10,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've actually wanted to try this, but sadly the software isn't really there.  Right now llama.cpp relies on mmap to read storage which is super inefficient (my system caps at ~2GBps, well under what storage can offer).\\n\\nMaybe adding a way to pin tensors to \\"storage\\" (e.g. --override-tensor with DISK instead of CPU or CUDA#) would allow for proper threaded and anticipatory I/O.  The problem is that it still needs to write through main memory anyways so you couldn't really use the extra bandwidth - just capacity.  (I guess these days we do have SDCI / DDIO... hrm...)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49nxeh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve actually wanted to try this, but sadly the software isn&amp;#39;t really there.  Right now llama.cpp relies on mmap to read storage which is super inefficient (my system caps at ~2GBps, well under what storage can offer).&lt;/p&gt;\\n\\n&lt;p&gt;Maybe adding a way to pin tensors to &amp;quot;storage&amp;quot; (e.g. --override-tensor with DISK instead of CPU or CUDA#) would allow for proper threaded and anticipatory I/O.  The problem is that it still needs to write through main memory anyways so you couldn&amp;#39;t really use the extra bandwidth - just capacity.  (I guess these days we do have SDCI / DDIO... hrm...)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49nxeh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062502,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49ysmj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"droptableadventures","can_mod_post":false,"created_utc":1753066619,"send_replies":true,"parent_id":"t1_n47f3if","score":7,"author_fullname":"t2_52zg0eoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think for optimal insanity, all of the SSDs should be those 16GB Optane NVMe drives which you can buy for about $2 each. \\n\\nSomething like this: https://www.reddit.com/r/truenas/comments/1k0dlbt/i_made_18_nvme_truenas_scale_using_asus_mining/\\n\\nAs the top comment says: \\n\\n&gt; Wow that sounds like a terrible idea. Please keep me up to date I'm interested!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49ysmj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think for optimal insanity, all of the SSDs should be those 16GB Optane NVMe drives which you can buy for about $2 each. &lt;/p&gt;\\n\\n&lt;p&gt;Something like this: &lt;a href=\\"https://www.reddit.com/r/truenas/comments/1k0dlbt/i_made_18_nvme_truenas_scale_using_asus_mining/\\"&gt;https://www.reddit.com/r/truenas/comments/1k0dlbt/i_made_18_nvme_truenas_scale_using_asus_mining/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;As the top comment says: &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Wow that sounds like a terrible idea. Please keep me up to date I&amp;#39;m interested!&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49ysmj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066619,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48b2nk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KontoOficjalneMR","can_mod_post":false,"created_utc":1753045377,"send_replies":true,"parent_id":"t1_n47f3if","score":11,"author_fullname":"t2_16x2kodiqz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This wins a thread IMO","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48b2nk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This wins a thread IMO&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48b2nk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045377,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48vk0w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"1ncehost","can_mod_post":false,"created_utc":1753052183,"send_replies":true,"parent_id":"t1_n47f3if","score":3,"author_fullname":"t2_lrannsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is wonderful","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48vk0w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is wonderful&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48vk0w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753052183,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n499vd4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n498vzp","score":5,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There would be no wait time to load the model into memory XD\\n\\nI Would definitely love to see someone try this out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n499vd4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There would be no wait time to load the model into memory XD&lt;/p&gt;\\n\\n&lt;p&gt;I Would definitely love to see someone try this out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n499vd4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753057253,"author_flair_text":null,"treatment_tags":[],"created_utc":1753057253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49s8j0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n498vzp","score":4,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Current software only uses storage via \`mmap\` so the I/O performance is garbage (think single PCIe3 NVMe).  Even if you fixed that, most CPUs need to do NVMe-&gt;RAM-&gt;CPU so you're still RAM-limited but now with a bunch of writes destroying bandwidth.  Latest gen server chips have a feature to directly read into cache, which would make it work, but tuning that would be pretty tricky.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n49s8j0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Current software only uses storage via &lt;code&gt;mmap&lt;/code&gt; so the I/O performance is garbage (think single PCIe3 NVMe).  Even if you fixed that, most CPUs need to do NVMe-&amp;gt;RAM-&amp;gt;CPU so you&amp;#39;re still RAM-limited but now with a bunch of writes destroying bandwidth.  Latest gen server chips have a feature to directly read into cache, which would make it work, but tuning that would be pretty tricky.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49s8j0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753064096,"author_flair_text":null,"treatment_tags":[],"created_utc":1753064096,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n498vzp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheSilverSmith47","can_mod_post":false,"created_utc":1753056887,"send_replies":true,"parent_id":"t1_n47f3if","score":1,"author_fullname":"t2_29au5bw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you know if anyone has tried this? How does it compare to a CPU + RAM setup in performance and cost effectiveness?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n498vzp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know if anyone has tried this? How does it compare to a CPU + RAM setup in performance and cost effectiveness?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n498vzp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753056887,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bzz4m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BalorNG","can_mod_post":false,"created_utc":1753102398,"send_replies":true,"parent_id":"t1_n47f3if","score":1,"author_fullname":"t2_b6gw9q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's not garbage, x16 raid board for x4 SSD is 1000$, and this board is not that cheap either, neither are high-speed ssds.\\n\\nA used server with tons of ram and something like Epyc is pretty affordable tho and much, much easier to setup.\\n\\nI follow a local listing for a mobo with 32core epyc and 256gb ram for like 1500$ - ddr4 tho, but it has 12 channels afaik.\\n\\nToo bad I'm ass-broke and have other priorities :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bzz4m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s not garbage, x16 raid board for x4 SSD is 1000$, and this board is not that cheap either, neither are high-speed ssds.&lt;/p&gt;\\n\\n&lt;p&gt;A used server with tons of ram and something like Epyc is pretty affordable tho and much, much easier to setup.&lt;/p&gt;\\n\\n&lt;p&gt;I follow a local listing for a mobo with 32core epyc and 256gb ram for like 1500$ - ddr4 tho, but it has 12 channels afaik.&lt;/p&gt;\\n\\n&lt;p&gt;Too bad I&amp;#39;m ass-broke and have other priorities :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4bzz4m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102398,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dh7am","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c6yky","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that would be a downside for sure. It would also depend on how many drives are in the raid to determine how many gigabytes are read per token.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dh7am","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that would be a downside for sure. It would also depend on how many drives are in the raid to determine how many gigabytes are read per token.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4dh7am/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118253,"author_flair_text":null,"treatment_tags":[],"created_utc":1753118253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4hokqi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"droptableadventures","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c6yky","score":2,"author_fullname":"t2_52zg0eoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Reads don't wear out the drive like writes do.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4hokqi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Reads don&amp;#39;t wear out the drive like writes do.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4hokqi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753172737,"author_flair_text":null,"treatment_tags":[],"created_utc":1753172737,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c6yky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HerrGronbar","can_mod_post":false,"created_utc":1753104778,"send_replies":true,"parent_id":"t1_n47f3if","score":1,"author_fullname":"t2_39owmlq7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Those NVME drives wouldn't die fast?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c6yky","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Those NVME drives wouldn&amp;#39;t die fast?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4c6yky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104778,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47f3if","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"triynizzles1","can_mod_post":false,"created_utc":1753035445,"send_replies":true,"parent_id":"t3_1m4u7j6","score":60,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The most garbage llm set up I can think of would be an inexpensive server board or thread ripper with 128 PCI gen 5 lanes. Populate every lane with an NVME drive and then put it in a raid zero. You’ll get like 500 GB per second read speed from your storage. Then you can inference off storage instead of RAM or a GPU.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47f3if","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The most garbage llm set up I can think of would be an inexpensive server board or thread ripper with 128 PCI gen 5 lanes. Populate every lane with an NVME drive and then put it in a raid zero. You’ll get like 500 GB per second read speed from your storage. Then you can inference off storage instead of RAM or a GPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47f3if/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035445,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":60}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47q98w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n472fuu","score":24,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Much worse -- a cluster. Sooo much more complex. It's gloriously stupid.\\n\\nAlso, even if you pay out the nose for RPi 5s you'd still spend like double/triple that on the networking gear unless you got lucky buying used.\\n\\nAssuming u/sebgggg meant putting a 10G PCIe NIC on each RPi and then connecting them to a switch with at least 30 10G ports.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47q98w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Much worse -- a cluster. Sooo much more complex. It&amp;#39;s gloriously stupid.&lt;/p&gt;\\n\\n&lt;p&gt;Also, even if you pay out the nose for RPi 5s you&amp;#39;d still spend like double/triple that on the networking gear unless you got lucky buying used.&lt;/p&gt;\\n\\n&lt;p&gt;Assuming &lt;a href=\\"/u/sebgggg\\"&gt;u/sebgggg&lt;/a&gt; meant putting a 10G PCIe NIC on each RPi and then connecting them to a switch with at least 30 10G ports.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47q98w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753038898,"author_flair_text":null,"treatment_tags":[],"created_utc":1753038898,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}}],"before":null}},"user_reports":[],"saved":false,"id":"n472fuu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"caraccidentGAMING","can_mod_post":false,"created_utc":1753031723,"send_replies":true,"parent_id":"t1_n471rq1","score":9,"author_fullname":"t2_9y0b4xlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"isn't this just building a bigger gpu out of a lot of small cpus\\nIm down for this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n472fuu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;isn&amp;#39;t this just building a bigger gpu out of a lot of small cpus\\nIm down for this&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n472fuu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031723,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n471rq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sebgggg","can_mod_post":false,"created_utc":1753031527,"send_replies":true,"parent_id":"t3_1m4u7j6","score":88,"author_fullname":"t2_zsujj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A cluster of 30 raspberry pis with 10gb ethernet because it gotta go fast","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n471rq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A cluster of 30 raspberry pis with 10gb ethernet because it gotta go fast&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n471rq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031527,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":88}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47qmov","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DorphinPack","can_mod_post":false,"created_utc":1753039014,"send_replies":true,"parent_id":"t1_n471r19","score":9,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Put it in a Lack Rack!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47qmov","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Put it in a Lack Rack!!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47qmov/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039014,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n471r19","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DorphinPack","can_mod_post":false,"created_utc":1753031521,"send_replies":true,"parent_id":"t3_1m4u7j6","score":36,"author_fullname":"t2_zebuyjw9s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I always feel that signature mix of admiration and horror when I see someone doing parallel PSUs with paperclip bridges so they can power an ungodly number of cheap GPUs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n471r19","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I always feel that signature mix of admiration and horror when I see someone doing parallel PSUs with paperclip bridges so they can power an ungodly number of cheap GPUs&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n471r19/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031521,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47zr7l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_xulion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47vbu9","score":7,"author_fullname":"t2_a1dvxm4d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"512 G. Trying to get 1T","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n47zr7l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;512 G. Trying to get 1T&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47zr7l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753041895,"author_flair_text":null,"treatment_tags":[],"created_utc":1753041895,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n47vbu9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Soggy-Camera1270","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47r7dq","score":1,"author_fullname":"t2_6kmvfbdk","approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much ram do you have?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n47vbu9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much ram do you have?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47vbu9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040509,"author_flair_text":null,"treatment_tags":[],"created_utc":1753040509,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47r7dq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_xulion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47qdh2","score":2,"author_fullname":"t2_a1dvxm4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Correct. The reason I use 8b is because of not having enough memory for full weight. \\n\\nI did some llama bench before (actually posted questions about why no speed improvement by quant the model) and the speed pretty much the same. I’m trying to get more ram now so I can run full weight.","edited":false,"author_flair_css_class":null,"name":"t1_n47r7dq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Correct. The reason I use 8b is because of not having enough memory for full weight. &lt;/p&gt;\\n\\n&lt;p&gt;I did some llama bench before (actually posted questions about why no speed improvement by quant the model) and the speed pretty much the same. I’m trying to get more ram now so I can run full weight.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4u7j6","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47r7dq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039193,"author_flair_text":null,"collapsed":false,"created_utc":1753039193,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n47qdh2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47lr0s","score":2,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Should help for total memory usage though, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47qdh2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should help for total memory usage though, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47qdh2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753038935,"author_flair_text":null,"treatment_tags":[],"created_utc":1753038935,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n47lr0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_xulion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47g755","score":9,"author_fullname":"t2_a1dvxm4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"8b. But it doesn’t matter. CPU will covert it to double anyway as there is no hardware support for 4b or 8b.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47lr0s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;8b. But it doesn’t matter. CPU will covert it to double anyway as there is no hardware support for 4b or 8b.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47lr0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037502,"author_flair_text":null,"treatment_tags":[],"created_utc":1753037502,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n47g755","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Own-Potential-2308","can_mod_post":false,"created_utc":1753035782,"send_replies":true,"parent_id":"t1_n474joq","score":4,"author_fullname":"t2_18di024ua3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Quant?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47g755","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Quant?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47g755/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035782,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47zoqg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_xulion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47p354","score":5,"author_fullname":"t2_a1dvxm4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"GPU may consume more power unless it has enough VRAM. Currently my setup consumes just 300W more compared to idle during inference.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47zoqg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GPU may consume more power unless it has enough VRAM. Currently my setup consumes just 300W more compared to idle during inference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47zoqg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753041873,"author_flair_text":null,"treatment_tags":[],"created_utc":1753041873,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n47p354","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1753038535,"send_replies":true,"parent_id":"t1_n474joq","score":1,"author_fullname":"t2_qz1qjc86","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This doesn't sound too bad. Maybe if you added a GPU, wouldn't even have to be super expensive one, just a standard gaming GPU would do, you could give that inference a good boost, but those Intel CPUs are rather hungry, I don't want to see those bills for electric power to run that lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47p354","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This doesn&amp;#39;t sound too bad. Maybe if you added a GPU, wouldn&amp;#39;t even have to be super expensive one, just a standard gaming GPU would do, you could give that inference a good boost, but those Intel CPUs are rather hungry, I don&amp;#39;t want to see those bills for electric power to run that lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47p354/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753038535,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4adkjy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_xulion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4a9osb","score":2,"author_fullname":"t2_a1dvxm4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"server console output (from my dual gold 5120 running 235B-A22B-Q4, my 6140 is running the Deepseek now):\\n\\n    prompt eval time = 6555.45 ms / 90 tokens ( 72.84 ms per token, 13.73 tokens per second)\\n    eval time = 181958.99 ms / 589 tokens ( 308.93 ms per token, 3.24 tokens per second)\\n    total time = 188514.44 ms / 679 tokens\\n\\nfull command line:\\n\\n\`llama-server -m ./Qwen3-235B-A22B-GGUF/Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00001-of-00005.gguf --temp 0.2 --numa distribute --host\` [\`0.0.0.0\`](http://0.0.0.0) \`--port 8000 -c 0 --mlock -t 46\`","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4adkjy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;server console output (from my dual gold 5120 running 235B-A22B-Q4, my 6140 is running the Deepseek now):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt eval time = 6555.45 ms / 90 tokens ( 72.84 ms per token, 13.73 tokens per second)\\neval time = 181958.99 ms / 589 tokens ( 308.93 ms per token, 3.24 tokens per second)\\ntotal time = 188514.44 ms / 679 tokens\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;full command line:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;llama-server -m ./Qwen3-235B-A22B-GGUF/Q4_K_M/Qwen3-235B-A22B-Q4_K_M-00001-of-00005.gguf --temp 0.2 --numa distribute --host&lt;/code&gt; &lt;a href=\\"http://0.0.0.0\\"&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/a&gt; &lt;code&gt;--port 8000 -c 0 --mlock -t 46&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4adkjy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753072934,"author_flair_text":null,"treatment_tags":[],"created_utc":1753072934,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4a9osb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Such-East7382","can_mod_post":false,"created_utc":1753071163,"send_replies":true,"parent_id":"t1_n474joq","score":1,"author_fullname":"t2_1c0w7x5whd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have the same setup, what’s your ppt/s? Mine is ass for some reason, barely 7t/s for qwen","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a9osb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have the same setup, what’s your ppt/s? Mine is ass for some reason, barely 7t/s for qwen&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4a9osb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753071163,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n474joq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_xulion","can_mod_post":false,"created_utc":1753032339,"send_replies":true,"parent_id":"t3_1m4u7j6","score":17,"author_fullname":"t2_a1dvxm4d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My dual Xeon (gold 6140) run this 235B-A22B at around 3-4 t/s, without GPU.  It also can run Deepseek R1 528 at about 1.5t/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n474joq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My dual Xeon (gold 6140) run this 235B-A22B at around 3-4 t/s, without GPU.  It also can run Deepseek R1 528 at about 1.5t/s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n474joq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753032339,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47mwrx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tengo_harambe","can_mod_post":false,"created_utc":1753037860,"send_replies":true,"parent_id":"t3_1m4u7j6","score":8,"author_fullname":"t2_sgx7w7mb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"BC 250 mining rig. 192GB of GDDR6 VRAM in the form of 12x PS5 APUs for a grand total of only $1K.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47mwrx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;BC 250 mining rig. 192GB of GDDR6 VRAM in the form of 12x PS5 APUs for a grand total of only $1K.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47mwrx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037860,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47xe5w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kholejones8888","can_mod_post":false,"created_utc":1753041157,"send_replies":true,"parent_id":"t3_1m4u7j6","score":9,"author_fullname":"t2_1jp9h6pxqa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"GPT4FREE is the most busted setup you can have.\\n\\nhttps://github.com/xtekky/gpt4free\\n\\nHuggingSpace has qwen3 235B MoE on tap.\\n\\nYou can plug it directly into KiloCode, it’s fine","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47xe5w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GPT4FREE is the most busted setup you can have.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/xtekky/gpt4free\\"&gt;https://github.com/xtekky/gpt4free&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;HuggingSpace has qwen3 235B MoE on tap.&lt;/p&gt;\\n\\n&lt;p&gt;You can plug it directly into KiloCode, it’s fine&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47xe5w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753041157,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47vxq3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Weary-Wing-6806","can_mod_post":false,"created_utc":1753040699,"send_replies":true,"parent_id":"t3_1m4u7j6","score":8,"author_fullname":"t2_1t2xvghrcr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Run the MoE off a Raspberry Pi cluster duct-taped to an e-bike, solar-powered, inference streamed over LoRa. Model sharded across four SD cards. Cold start requires pedaling for 12 minutes. Only outputs tokens when the wind is blowing east. Winner winner chicken dinner.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47vxq3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Run the MoE off a Raspberry Pi cluster duct-taped to an e-bike, solar-powered, inference streamed over LoRa. Model sharded across four SD cards. Cold start requires pedaling for 12 minutes. Only outputs tokens when the wind is blowing east. Winner winner chicken dinner.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47vxq3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040699,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47hnfb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MDT-49","can_mod_post":false,"created_utc":1753036227,"send_replies":true,"parent_id":"t3_1m4u7j6","score":3,"author_fullname":"t2_h8yrica5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Raspberry Pi 5 (16GB) with the M.2 HAT+ and 256GB NVMe SSD, using mmap to dynamically load the parameters from the drive. The only problem with this brilliant idea is that you'd probably die of old age before seeing the results.\\n\\nI think another unconventional but more sensible idea is using a (secondhand) previous generation AMD APU (e.g. AMD Ryzen 7 8700G) with a decent iGPU (Radeon 780M). Upgrade to the highest RAM capacity and supported speed. \\n\\nRun the LLM using the iGPU for faster prompt ingestion (compared to CPU), although the text generation is probably still limited by the relatively slow RAM bandwidth.\\n\\nAnother trick is to use the IQ1 quant, set the \`qwen3moe.expert_used_count\` to 1, and use LSD so you still feel like you're talking to AGI.","edited":1753036658,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47hnfb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Raspberry Pi 5 (16GB) with the M.2 HAT+ and 256GB NVMe SSD, using mmap to dynamically load the parameters from the drive. The only problem with this brilliant idea is that you&amp;#39;d probably die of old age before seeing the results.&lt;/p&gt;\\n\\n&lt;p&gt;I think another unconventional but more sensible idea is using a (secondhand) previous generation AMD APU (e.g. AMD Ryzen 7 8700G) with a decent iGPU (Radeon 780M). Upgrade to the highest RAM capacity and supported speed. &lt;/p&gt;\\n\\n&lt;p&gt;Run the LLM using the iGPU for faster prompt ingestion (compared to CPU), although the text generation is probably still limited by the relatively slow RAM bandwidth.&lt;/p&gt;\\n\\n&lt;p&gt;Another trick is to use the IQ1 quant, set the &lt;code&gt;qwen3moe.expert_used_count&lt;/code&gt; to 1, and use LSD so you still feel like you&amp;#39;re talking to AGI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47hnfb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036227,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n472ego","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Frosty-Cap-4282","can_mod_post":false,"created_utc":1753031712,"send_replies":true,"parent_id":"t3_1m4u7j6","score":3,"author_fullname":"t2_18z668t0lo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"tinyllama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n472ego","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;tinyllama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n472ego/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031712,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47mopi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1753037790,"send_replies":true,"parent_id":"t3_1m4u7j6","score":3,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Crackhead setup? A bunch of SFF PCs that used to do digital signage. Implication being you get them for free and then use RPC to split the model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47mopi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Crackhead setup? A bunch of SFF PCs that used to do digital signage. Implication being you get them for free and then use RPC to split the model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47mopi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037790,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4843mc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"absolooot1","can_mod_post":false,"created_utc":1753043233,"send_replies":true,"parent_id":"t3_1m4u7j6","score":3,"author_fullname":"t2_1pr7hwh6t5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Silent mini PC with an Intel N100 4 core CPU and 16 GB RAM. You can run the qwen at 4 bit quantization and a small context, with memory mapping. So only the active parameters will be in RAM, the rest served from SSD. It won't be fast, but you can leave it running overnight. Get up in the morning and your code is ready.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4843mc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Silent mini PC with an Intel N100 4 core CPU and 16 GB RAM. You can run the qwen at 4 bit quantization and a small context, with memory mapping. So only the active parameters will be in RAM, the rest served from SSD. It won&amp;#39;t be fast, but you can leave it running overnight. Get up in the morning and your code is ready.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4843mc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043233,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47c2mn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1753034527,"send_replies":true,"parent_id":"t3_1m4u7j6","score":2,"author_fullname":"t2_8fu8sqhz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Old decommissioned mining rig with P102-100s each flashed to 10gb\\n\\n\\nEquivalent of an electric kettle for each 100gb of vram... But usually very cheap to get hold of","edited":1753034734,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47c2mn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Old decommissioned mining rig with P102-100s each flashed to 10gb&lt;/p&gt;\\n\\n&lt;p&gt;Equivalent of an electric kettle for each 100gb of vram... But usually very cheap to get hold of&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47c2mn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753034527,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48rdg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"outtokill7","can_mod_post":false,"created_utc":1753050729,"send_replies":true,"parent_id":"t3_1m4u7j6","score":2,"author_fullname":"t2_7ikfz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a 11th Gen i5 Framework 13 mainboard in a 3D printed case with a thunderbolt GPU enclosure and a 3060 12gb inside.\\n\\nThere are going to be more jank setups than mine but I like to think it's jank enough to mention","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48rdg6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a 11th Gen i5 Framework 13 mainboard in a 3D printed case with a thunderbolt GPU enclosure and a 3060 12gb inside.&lt;/p&gt;\\n\\n&lt;p&gt;There are going to be more jank setups than mine but I like to think it&amp;#39;s jank enough to mention&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48rdg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753050729,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47fjeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SnooEagles1027","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47f1kc","score":3,"author_fullname":"t2_3slgxl3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"👌 if it works! P40's still are pretty good for their age - I have one and still impressed with what they can do.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47fjeg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;👌 if it works! P40&amp;#39;s still are pretty good for their age - I have one and still impressed with what they can do.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47fjeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035580,"author_flair_text":null,"treatment_tags":[],"created_utc":1753035580,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n47f1kc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FunnyAsparagus1253","can_mod_post":false,"created_utc":1753035429,"send_replies":true,"parent_id":"t1_n473vpf","score":10,"author_fullname":"t2_i6c8tay3w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wooden frame: ✅ Drilling holes myself: ✅ Duct tape: ✅ Non-standard sized mobo: ✅ Weird fan: ✅ Dremeled airflow/cable slots: ✅ Ikea cabinet for a case 😅 P40 club: ✅ Sucks so much power it’s more expensive than runpod: ✅ ✅ ✅ Fun though!\\n\\nhttps://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47f1kc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wooden frame: ✅ Drilling holes myself: ✅ Duct tape: ✅ Non-standard sized mobo: ✅ Weird fan: ✅ Dremeled airflow/cable slots: ✅ Ikea cabinet for a case 😅 P40 club: ✅ Sucks so much power it’s more expensive than runpod: ✅ ✅ ✅ Fun though!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c\\"&gt;https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47f1kc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035429,"media_metadata":{"86mq9bzcm2ef1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":144,"x":108,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1274b10bf39b29ee717b9ad2ecd864ac28fb0e93"},{"y":288,"x":216,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df2b0e0e1b4d2dfd93cfeedf65f197e1b8948f1a"},{"y":426,"x":320,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=784f89e5e78291c3a3be26b0a9f07a4ccb9269a1"},{"y":853,"x":640,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74e39ba58ceda620dfb20665578171e274012b0c"},{"y":1280,"x":960,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d27832b0741d6c140956c5a4e0ffe12409d3a69f"},{"y":1440,"x":1080,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=550ad072363a237876974dca9d437c24d2f69f56"}],"s":{"y":4032,"x":3024,"u":"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c"},"id":"86mq9bzcm2ef1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4744u3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SnooEagles1027","can_mod_post":false,"created_utc":1753032220,"send_replies":true,"parent_id":"t1_n473vpf","score":3,"author_fullname":"t2_3slgxl3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or you could go with a 4u supermicro case with a ton of pcie slots and throw a bunch of consumer cards in it... but hey :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4744u3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or you could go with a 4u supermicro case with a ton of pcie slots and throw a bunch of consumer cards in it... but hey :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4744u3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753032220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47jyyg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n474ino","score":5,"author_fullname":"t2_8jqx3m14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can get 8x v100 32GB in a server for about 6k now.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47jyyg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can get 8x v100 32GB in a server for about 6k now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47jyyg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036946,"author_flair_text":null,"treatment_tags":[],"created_utc":1753036946,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n474ino","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SnooEagles1027","can_mod_post":false,"created_utc":1753032331,"send_replies":true,"parent_id":"t1_n473vpf","score":3,"author_fullname":"t2_3slgxl3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh, and the v100 16gb are cheap but the carrier boards about 300ish a piece","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n474ino","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh, and the v100 16gb are cheap but the carrier boards about 300ish a piece&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n474ino/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753032331,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47n2gl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1753037909,"send_replies":true,"parent_id":"t1_n473vpf","score":3,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I stand off my GPUs on a shelf I made from pallet wood. The kind sprayed with methyl bromide too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47n2gl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I stand off my GPUs on a shelf I made from pallet wood. The kind sprayed with methyl bromide too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u7j6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47n2gl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037909,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n473vpf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SnooEagles1027","can_mod_post":false,"created_utc":1753032145,"send_replies":true,"parent_id":"t3_1m4u7j6","score":2,"author_fullname":"t2_3slgxl3h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You gotta build a wooden frame to mount a mobo and  gpus it holds but no, not regulart off the shelf mobos, server mobos, if you really want to get janky use the dell ones so you have to use their proprietary power supply too. Then use a crap ton of v100 16gb on dgx boards but you find yourself having to run standard power supplies because your other power supplies won't handle it.\\n\\nScratch that - use standard mobos with these dgx Frankenstein setups oh and there needs to be duct tape somewhere.\\n\\nAnd ChatGPT version:\\n1. Frame (Wood, Obviously)\\n\\n2x4s and plywood. No pre-fab racks here.\\n\\nDrill holes and mount standoffs yourself.\\n\\nEnsure airflow gaps (front-to-back or bottom-to-top).\\n\\nBonus points: Burn the wood with a torch to \\"harden\\" it (or at least make it look cyberpunk-apocalyptic).\\n\\n\\n2. Motherboards\\n\\nYou’re flip-flopping between:\\n\\nServer boards (Dell, etc.) — a pain because of:\\n\\nProprietary power connectors.\\n\\nNon-standard dimensions.\\n\\nPotential lack of accessible BIOS tuning.\\n\\nStandard consumer/workstation boards (more sane):\\n\\nEasier power, ATX mounting.\\n\\nBut you may run out of PCIe lanes depending on how greedy you get with the GPUs.\\n\\nPick one. For jank’s sake, go standard. You’ll thank yourself when something fails at 2 AM.\\n\\n\\n3. GPUs: V100 16GB (On DGX carrier boards)\\n\\nThese DGX boards usually carry 4x V100s each.\\n\\nPCIe slot edge connector. Power-hungry monsters.\\n\\nProblem: DGX boards aren’t made to be run outside of their cozy, $150K servers.\\n\\nPower: You must run standard ATX PSUs unless you’ve got server-grade 12V rails (or want to solder your own cables and live on the edge).\\n\\nMultiple 1200W Platinum-rated PSUs (server pulls or mining leftovers).\\n\\nJump pins on 24-pin connectors to power on without motherboard.\\n\\nCustom cable routing to GPU edge connectors. Make sure the wire gauge is legit (12 AWG ideally).\\n\\n\\n4. Mounting the DGX Boards\\n\\nCustom risers or standoff rail system.\\n\\nSpacers under the board, vent holes underneath.\\n\\nThink vertical sandwich or slotted wooden backplate.\\n\\n\\n5. Cooling\\n\\n120mm or 140mm high-static pressure fans.\\n\\nBox fan in the corner blowing on your duct-taped rig.\\n\\nBonus: Bathroom exhaust fan and some dryer ducting.\\n\\n\\n6. The Duct Tape (Non-Negotiable)\\n\\nHold PSUs to the frame? Duct tape.\\n\\nSecure a janky riser that keeps popping loose? Duct tape.\\n\\nLabel dead GPUs? Duct tape + Sharpie.\\n\\nFan that won’t stay where you want it? Duct tape.\\n\\nIt’s not real unless there’s duct tape.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n473vpf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You gotta build a wooden frame to mount a mobo and  gpus it holds but no, not regulart off the shelf mobos, server mobos, if you really want to get janky use the dell ones so you have to use their proprietary power supply too. Then use a crap ton of v100 16gb on dgx boards but you find yourself having to run standard power supplies because your other power supplies won&amp;#39;t handle it.&lt;/p&gt;\\n\\n&lt;p&gt;Scratch that - use standard mobos with these dgx Frankenstein setups oh and there needs to be duct tape somewhere.&lt;/p&gt;\\n\\n&lt;p&gt;And ChatGPT version:\\n1. Frame (Wood, Obviously)&lt;/p&gt;\\n\\n&lt;p&gt;2x4s and plywood. No pre-fab racks here.&lt;/p&gt;\\n\\n&lt;p&gt;Drill holes and mount standoffs yourself.&lt;/p&gt;\\n\\n&lt;p&gt;Ensure airflow gaps (front-to-back or bottom-to-top).&lt;/p&gt;\\n\\n&lt;p&gt;Bonus points: Burn the wood with a torch to &amp;quot;harden&amp;quot; it (or at least make it look cyberpunk-apocalyptic).&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Motherboards&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;You’re flip-flopping between:&lt;/p&gt;\\n\\n&lt;p&gt;Server boards (Dell, etc.) — a pain because of:&lt;/p&gt;\\n\\n&lt;p&gt;Proprietary power connectors.&lt;/p&gt;\\n\\n&lt;p&gt;Non-standard dimensions.&lt;/p&gt;\\n\\n&lt;p&gt;Potential lack of accessible BIOS tuning.&lt;/p&gt;\\n\\n&lt;p&gt;Standard consumer/workstation boards (more sane):&lt;/p&gt;\\n\\n&lt;p&gt;Easier power, ATX mounting.&lt;/p&gt;\\n\\n&lt;p&gt;But you may run out of PCIe lanes depending on how greedy you get with the GPUs.&lt;/p&gt;\\n\\n&lt;p&gt;Pick one. For jank’s sake, go standard. You’ll thank yourself when something fails at 2 AM.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;GPUs: V100 16GB (On DGX carrier boards)&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;These DGX boards usually carry 4x V100s each.&lt;/p&gt;\\n\\n&lt;p&gt;PCIe slot edge connector. Power-hungry monsters.&lt;/p&gt;\\n\\n&lt;p&gt;Problem: DGX boards aren’t made to be run outside of their cozy, $150K servers.&lt;/p&gt;\\n\\n&lt;p&gt;Power: You must run standard ATX PSUs unless you’ve got server-grade 12V rails (or want to solder your own cables and live on the edge).&lt;/p&gt;\\n\\n&lt;p&gt;Multiple 1200W Platinum-rated PSUs (server pulls or mining leftovers).&lt;/p&gt;\\n\\n&lt;p&gt;Jump pins on 24-pin connectors to power on without motherboard.&lt;/p&gt;\\n\\n&lt;p&gt;Custom cable routing to GPU edge connectors. Make sure the wire gauge is legit (12 AWG ideally).&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Mounting the DGX Boards&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Custom risers or standoff rail system.&lt;/p&gt;\\n\\n&lt;p&gt;Spacers under the board, vent holes underneath.&lt;/p&gt;\\n\\n&lt;p&gt;Think vertical sandwich or slotted wooden backplate.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Cooling&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;120mm or 140mm high-static pressure fans.&lt;/p&gt;\\n\\n&lt;p&gt;Box fan in the corner blowing on your duct-taped rig.&lt;/p&gt;\\n\\n&lt;p&gt;Bonus: Bathroom exhaust fan and some dryer ducting.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;The Duct Tape (Non-Negotiable)&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Hold PSUs to the frame? Duct tape.&lt;/p&gt;\\n\\n&lt;p&gt;Secure a janky riser that keeps popping loose? Duct tape.&lt;/p&gt;\\n\\n&lt;p&gt;Label dead GPUs? Duct tape + Sharpie.&lt;/p&gt;\\n\\n&lt;p&gt;Fan that won’t stay where you want it? Duct tape.&lt;/p&gt;\\n\\n&lt;p&gt;It’s not real unless there’s duct tape.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n473vpf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753032145,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n478zyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1753033629,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With a consumer CPU (Ryzen 9950X), and a 20GB GPU (kind of overkill for this due to the nature of 235B's MoE structure not having a shared expert), I get around 3 T/s.\\n\\nThis is decidedly not super optimal, but the main limitation here is the CPU. Generally I do a tensor override to keep the experts on CPU and everything else on GPU, which IMO is the cheapest way to run models like this.\\n\\nAs an aside, if they'd done a shared expert in Qwen 235B I'd expect closer to Llama 4 speeds; I get 10 T/s on Maverick, surprisingly.\\n\\nAnyway, the limiting factor there is in fact not the GPU, but the CPU.\\n\\nIf I'd gone with a Threadripper I'd expect around 6 T/s, and around 9-12 T/s with Threadripper Pro. I'm guessing there's a limit or diminishing returns somewhere, but with an Epyc 9124 I'd guess somewhere around 10-20T/s should be possible with the same ish setup.\\n\\nNow, you could throw more of the model on VRAM to ease the burden on the CPU, and that's definitely one way to make it easier (only offloading the experts of some of the layers to CPU), but I generally tend to think that the best strat is just to get a bigger CPU.\\n\\nUsed Xeons are okay (typically I think models with around 200GB/s of bandwidth are pretty common at reasonable prices. You'd expect on the upper end around 10 T/s being possible with a modest GPU to pair it with).\\n\\nIn terms of GPU, if you do tensor overrides etc, you'd expect not to need that much GPU power. I think at low ish context (32k) I use around 3-6GB for the KV cache and Attention at q8 in LlamaCPP.\\n\\nIn that light, even quite affordable 12-16GB GPUs are suitable if you're not throwing experts onto the GPUs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n478zyr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With a consumer CPU (Ryzen 9950X), and a 20GB GPU (kind of overkill for this due to the nature of 235B&amp;#39;s MoE structure not having a shared expert), I get around 3 T/s.&lt;/p&gt;\\n\\n&lt;p&gt;This is decidedly not super optimal, but the main limitation here is the CPU. Generally I do a tensor override to keep the experts on CPU and everything else on GPU, which IMO is the cheapest way to run models like this.&lt;/p&gt;\\n\\n&lt;p&gt;As an aside, if they&amp;#39;d done a shared expert in Qwen 235B I&amp;#39;d expect closer to Llama 4 speeds; I get 10 T/s on Maverick, surprisingly.&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, the limiting factor there is in fact not the GPU, but the CPU.&lt;/p&gt;\\n\\n&lt;p&gt;If I&amp;#39;d gone with a Threadripper I&amp;#39;d expect around 6 T/s, and around 9-12 T/s with Threadripper Pro. I&amp;#39;m guessing there&amp;#39;s a limit or diminishing returns somewhere, but with an Epyc 9124 I&amp;#39;d guess somewhere around 10-20T/s should be possible with the same ish setup.&lt;/p&gt;\\n\\n&lt;p&gt;Now, you could throw more of the model on VRAM to ease the burden on the CPU, and that&amp;#39;s definitely one way to make it easier (only offloading the experts of some of the layers to CPU), but I generally tend to think that the best strat is just to get a bigger CPU.&lt;/p&gt;\\n\\n&lt;p&gt;Used Xeons are okay (typically I think models with around 200GB/s of bandwidth are pretty common at reasonable prices. You&amp;#39;d expect on the upper end around 10 T/s being possible with a modest GPU to pair it with).&lt;/p&gt;\\n\\n&lt;p&gt;In terms of GPU, if you do tensor overrides etc, you&amp;#39;d expect not to need that much GPU power. I think at low ish context (32k) I use around 3-6GB for the KV cache and Attention at q8 in LlamaCPP.&lt;/p&gt;\\n\\n&lt;p&gt;In that light, even quite affordable 12-16GB GPUs are suitable if you&amp;#39;re not throwing experts onto the GPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n478zyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033629,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47jv0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hawk_7979","can_mod_post":false,"created_utc":1753036913,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_85eeoiqtd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have single MI50 with 64gb RAM and i am getting 4 t/s on Q2_K_L\\n\\nI’ve seen people getting 20t/s with 3 mi50’s.\\n\\nGo for pcie gen 5/4 MOBO and bifurcate pcie x16.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47jv0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have single MI50 with 64gb RAM and i am getting 4 t/s on Q2_K_L&lt;/p&gt;\\n\\n&lt;p&gt;I’ve seen people getting 20t/s with 3 mi50’s.&lt;/p&gt;\\n\\n&lt;p&gt;Go for pcie gen 5/4 MOBO and bifurcate pcie x16.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47jv0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036913,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n482ia0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ConnectBodybuilder36","can_mod_post":false,"created_utc":1753042747,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_1nq5dpbfmd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What comes to mind for me is just a bunch of M60 gpus","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n482ia0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What comes to mind for me is just a bunch of M60 gpus&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n482ia0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753042747,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n485bsm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Stepfunction","can_mod_post":false,"created_utc":1753043608,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_sxigq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With an MoE model like that, you can load it fully in RAM and get interactive speeds. No absolute need for a GPU even as long as you have a decent CPU setup.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n485bsm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With an MoE model like that, you can load it fully in RAM and get interactive speeds. No absolute need for a GPU even as long as you have a decent CPU setup.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n485bsm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043608,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48cpy9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"swagonflyyyy","can_mod_post":false,"created_utc":1753045896,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_iev1qh7k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Using a CD player as a grenade and Deepseek-R1-671b-FP16 as the detonator by loading it in and attempting to generate \`Hello, World!\`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48cpy9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using a CD player as a grenade and Deepseek-R1-671b-FP16 as the detonator by loading it in and attempting to generate &lt;code&gt;Hello, World!&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48cpy9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045896,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48v6r2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1753052058,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_i5os0v0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What's your budget?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48v6r2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s your budget?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48v6r2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753052058,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49ecgt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kevin_1994","can_mod_post":false,"created_utc":1753058925,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_o015g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had this idea one time:\\n\\nGet as many cheap npu accelerated android devices as you can. You can probably get them virtually for free with cracked screens, unable to use battery, etc. \\n\\nHave some server as many usb hubs you can find. \\n\\nWrite some software where each phone is a node running llm inference. \\n\\nThe idea is the cheapest performance per Watt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49ecgt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had this idea one time:&lt;/p&gt;\\n\\n&lt;p&gt;Get as many cheap npu accelerated android devices as you can. You can probably get them virtually for free with cracked screens, unable to use battery, etc. &lt;/p&gt;\\n\\n&lt;p&gt;Have some server as many usb hubs you can find. &lt;/p&gt;\\n\\n&lt;p&gt;Write some software where each phone is a node running llm inference. &lt;/p&gt;\\n\\n&lt;p&gt;The idea is the cheapest performance per Watt&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49ecgt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753058925,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49eqj6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1753059072,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"3090, 3080ti, 3060, P40, V100, MI50, mix it across 3 machines, I'm running Kimi k2 at 30,000 tokens at 1.5tk/sec","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49eqj6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3090, 3080ti, 3060, P40, V100, MI50, mix it across 3 machines, I&amp;#39;m running Kimi k2 at 30,000 tokens at 1.5tk/sec&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49eqj6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753059072,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49mdwj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1753061927,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An old quad Xeon (4 cpus not cores) server filled with 768gb of ddr3 with the lid taken off and GPU'S plugged into the PCIE risers with PCIE extention cables. GPU'S attached to a homemade or 3d printed GPU stand and all powered with an external PSU. Can probably do that for around ~$1500, doesn't mean it will be that fast tho. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49mdwj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An old quad Xeon (4 cpus not cores) server filled with 768gb of ddr3 with the lid taken off and GPU&amp;#39;S plugged into the PCIE risers with PCIE extention cables. GPU&amp;#39;S attached to a homemade or 3d printed GPU stand and all powered with an external PSU. Can probably do that for around ~$1500, doesn&amp;#39;t mean it will be that fast tho. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49mdwj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753061927,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4afunx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"quarteryudo","can_mod_post":false,"created_utc":1753074017,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_1sj4v0evea","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have Devstral 2507 running on an AMD 680m GPU. Entirely rootless. I used Podman to install brand-new Vulkan support to llama.cpp running within a container on an external SSD. I had 4gb of VRAM and by GOD I was determined to use it.\\n\\nMy whole setup is a minipc.\\n\\nThink it, dream it, do it.\\n\\nLink to my github, it's really quite simple: [https://github.com/michaelsoftmd/ai-pet-project](https://github.com/michaelsoftmd/ai-pet-project)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4afunx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have Devstral 2507 running on an AMD 680m GPU. Entirely rootless. I used Podman to install brand-new Vulkan support to llama.cpp running within a container on an external SSD. I had 4gb of VRAM and by GOD I was determined to use it.&lt;/p&gt;\\n\\n&lt;p&gt;My whole setup is a minipc.&lt;/p&gt;\\n\\n&lt;p&gt;Think it, dream it, do it.&lt;/p&gt;\\n\\n&lt;p&gt;Link to my github, it&amp;#39;s really quite simple: &lt;a href=\\"https://github.com/michaelsoftmd/ai-pet-project\\"&gt;https://github.com/michaelsoftmd/ai-pet-project&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4afunx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753074017,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4are1x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1753080042,"send_replies":true,"parent_id":"t3_1m4u7j6","score":1,"author_fullname":"t2_3f9vjjno","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm in the same situation as you, the best I've seen is throwing 5x MI50 gpus together. Someone got 19 tok/s doing that. With a super strict budget the whole system should be under 1k.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4are1x","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m in the same situation as you, the best I&amp;#39;ve seen is throwing 5x MI50 gpus together. Someone got 19 tok/s doing that. With a super strict budget the whole system should be under 1k.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4are1x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753080042,"author_flair_text":"Llama 70B","treatment_tags":[],"link_id":"t3_1m4u7j6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
