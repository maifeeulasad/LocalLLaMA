import{j as e}from"./index-CqAPCjw5.js";import{R as l}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Qwen3 Embedding has great retrieval results on [MTEB](https://huggingface.co/spaces/mteb/leaderboard).\\n\\nHowever, I tried it in [llama.cpp](https://huggingface.co/Qwen/Qwen3-Embedding-8B-GGUF). The results were much worse than competitors. I have an FAQ benchmark that looks a bit like this:\\n\\n| Model  | Score    |\\n|---------|----------|\\n| Qwen3 8B | 18.70% |\\n| Mistral | 53.12% |\\n| OpenAI (text-embedding-3-large) | 55.87% |\\n| Google (text-embedding-004) | 57.99% |\\n| Cohere (embed-v4.0) | 58.50% |\\n| Voyage AI | 60.54% |\\n\\nQwen3 is the only one that I am not using an API for, but I would assume that the F16 GGUF shouldn't have that big of an impact on performance compared to the raw model, say using TEI or vLLM.\\n\\nDoes anybody have a similar experience?\\n\\nEdit:\\nThe official TEI command does get 35.63%.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Are Qwen3 Embedding GGUF faulty?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lt18hg","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.91,"author_flair_background_color":null,"subreddit_type":"public","ups":35,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_5nceo","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":35,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751959701,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751808440,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 Embedding has great retrieval results on &lt;a href=\\"https://huggingface.co/spaces/mteb/leaderboard\\"&gt;MTEB&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;However, I tried it in &lt;a href=\\"https://huggingface.co/Qwen/Qwen3-Embedding-8B-GGUF\\"&gt;llama.cpp&lt;/a&gt;. The results were much worse than competitors. I have an FAQ benchmark that looks a bit like this:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Model&lt;/th&gt;\\n&lt;th&gt;Score&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Qwen3 8B&lt;/td&gt;\\n&lt;td&gt;18.70%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Mistral&lt;/td&gt;\\n&lt;td&gt;53.12%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;OpenAI (text-embedding-3-large)&lt;/td&gt;\\n&lt;td&gt;55.87%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Google (text-embedding-004)&lt;/td&gt;\\n&lt;td&gt;57.99%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Cohere (embed-v4.0)&lt;/td&gt;\\n&lt;td&gt;58.50%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Voyage AI&lt;/td&gt;\\n&lt;td&gt;60.54%&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;Qwen3 is the only one that I am not using an API for, but I would assume that the F16 GGUF shouldn&amp;#39;t have that big of an impact on performance compared to the raw model, say using TEI or vLLM.&lt;/p&gt;\\n\\n&lt;p&gt;Does anybody have a similar experience?&lt;/p&gt;\\n\\n&lt;p&gt;Edit:\\nThe official TEI command does get 35.63%.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?auto=webp&amp;s=2c5b27b819fcf9d302ea9223ff63779967c158ee","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bca5092323f107110de703666d0987ca51bedba1","width":108,"height":58},{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=358d7917ee14c30039ae1797ffd0ca1d9fe68d82","width":216,"height":116},{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c373fac417435224291450b1bfdd231978005f7","width":320,"height":172},{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c4fb1a0d407644b871f4c6fd852f1d65ac7b457","width":640,"height":345},{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=09ef247e453733c039205a9236d582047820cf4c","width":960,"height":518},{"url":"https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb5439e321758db220736b4ddd80f3cdab962692","width":1080,"height":583}],"variants":{},"id":"hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lt18hg","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"espadrine","discussion_type":null,"num_comments":20,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/","subreddit_subscribers":496033,"created_utc":1751808440,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1oq2ff","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"terminoid_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1nqkpy","score":2,"author_fullname":"t2_1iu07dnz2i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"hey, my issue! that issue should be resolved, but i haven't re-tested.\\n\\ni get weird results with the GGUF too, but before when i compared model output it didn't look obviously wrong. it's still slightly lower retrieval scores than ONNX model. (which honestly doesn't have the best retrieval performance either)\\n\\nanother thing to mention, besides confirming that EOS token is being appended, is: don't use the official GGUFs. i don't think they ever got a fixed tokenizer, you need to make your own GGUF from the safetensors model.\\n\\nedit: that was the case for the .6B, haven't looked at the 8B","edited":1751830919,"author_flair_css_class":null,"name":"t1_n1oq2ff","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hey, my issue! that issue should be resolved, but i haven&amp;#39;t re-tested.&lt;/p&gt;\\n\\n&lt;p&gt;i get weird results with the GGUF too, but before when i compared model output it didn&amp;#39;t look obviously wrong. it&amp;#39;s still slightly lower retrieval scores than ONNX model. (which honestly doesn&amp;#39;t have the best retrieval performance either)&lt;/p&gt;\\n\\n&lt;p&gt;another thing to mention, besides confirming that EOS token is being appended, is: don&amp;#39;t use the official GGUFs. i don&amp;#39;t think they ever got a fixed tokenizer, you need to make your own GGUF from the safetensors model.&lt;/p&gt;\\n\\n&lt;p&gt;edit: that was the case for the .6B, haven&amp;#39;t looked at the 8B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lt18hg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1oq2ff/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751830695,"author_flair_text":null,"collapsed":false,"created_utc":1751830695,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1nqkpy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Flashy_Management962","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1nmpkt","score":2,"author_fullname":"t2_n9dnke1h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You have to add the EOS Token manually \\"&lt;|endoftext|&gt;\\" as of here: [https://github.com/ggml-org/llama.cpp/issues/14234](https://github.com/ggml-org/llama.cpp/issues/14234)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1nqkpy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You have to add the EOS Token manually &amp;quot;&amp;lt;|endoftext|&amp;gt;&amp;quot; as of here: &lt;a href=\\"https://github.com/ggml-org/llama.cpp/issues/14234\\"&gt;https://github.com/ggml-org/llama.cpp/issues/14234&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1nqkpy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751819878,"author_flair_text":null,"treatment_tags":[],"created_utc":1751819878,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1nmpkt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"espadrine","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1mvcn6","score":1,"author_fullname":"t2_5nceo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am indexing this way:\\n\\n    requests.post(\\n        \\"http://127.0.0.1:8114/v1/embeddings\\",\\n        headers={\\"Content-Type\\": \\"application/json\\"},\\n        data=json.dumps({\\n            \\"input\\": texts,\\n            \\"model\\": \\"Qwen3-Embedding-8B-f16\\"\\n        })\\n    )\\n\\nand querying this way:\\n\\n    instruct = \\"Instruct: Given a customer FAQ search query, retrieve relevant passages that answer the query\\\\nQuery: \\"\\n    instructed_texts = [instruct + text for text in texts]\\n    response = requests.post(\\n        \\"http://127.0.0.1:8114/v1/embeddings\\",\\n        headers={\\"Content-Type\\": \\"application/json\\"},\\n        data=json.dumps({\\n            \\"input\\": instructed_texts,\\n            \\"model\\": \\"Qwen3-Embedding-8B-f16\\"\\n        })","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1nmpkt","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am indexing this way:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;requests.post(\\n    &amp;quot;http://127.0.0.1:8114/v1/embeddings&amp;quot;,\\n    headers={&amp;quot;Content-Type&amp;quot;: &amp;quot;application/json&amp;quot;},\\n    data=json.dumps({\\n        &amp;quot;input&amp;quot;: texts,\\n        &amp;quot;model&amp;quot;: &amp;quot;Qwen3-Embedding-8B-f16&amp;quot;\\n    })\\n)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;and querying this way:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;instruct = &amp;quot;Instruct: Given a customer FAQ search query, retrieve relevant passages that answer the query\\\\nQuery: &amp;quot;\\ninstructed_texts = [instruct + text for text in texts]\\nresponse = requests.post(\\n    &amp;quot;http://127.0.0.1:8114/v1/embeddings&amp;quot;,\\n    headers={&amp;quot;Content-Type&amp;quot;: &amp;quot;application/json&amp;quot;},\\n    data=json.dumps({\\n        &amp;quot;input&amp;quot;: instructed_texts,\\n        &amp;quot;model&amp;quot;: &amp;quot;Qwen3-Embedding-8B-f16&amp;quot;\\n    })\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1nmpkt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751818693,"author_flair_text":null,"treatment_tags":[],"created_utc":1751818693,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1mvcn6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1751810163,"send_replies":true,"parent_id":"t1_n1msm51","score":9,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, and the [exact CLI settings](https://www.reddit.com/r/LocalLLaMA/comments/1l3vt95/comment/mw4k324/) also need to be followed, or the results get extremely bad.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1mvcn6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, and the &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1l3vt95/comment/mw4k324/\\"&gt;exact CLI settings&lt;/a&gt; also need to be followed, or the results get extremely bad.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1mvcn6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751810163,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1nmkb4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"espadrine","can_mod_post":false,"created_utc":1751818648,"send_replies":true,"parent_id":"t1_n1msm51","score":1,"author_fullname":"t2_5nceo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am doing:\\n\\ndocker run --gpus all -v /data/ml/models/gguf:/models -p 8114:8080 ghcr.io/ggml-org/llama.cpp:full-cuda -s --host 0.0.0.0 -m /models/Qwen3-Embedding-8B-f16.gguf --embedding --pooling last -c 32768 -ub 8192 --verbose-prompt --n-gpu-layers 999\\n\\nSo maybe this doesn't include the right patch indeed!\\n\\nI have some compilation issues with my gcc version, but I'll try this branch, after checking vLLM to see if there is a difference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1nmkb4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am doing:&lt;/p&gt;\\n\\n&lt;p&gt;docker run --gpus all -v /data/ml/models/gguf:/models -p 8114:8080 ghcr.io/ggml-org/llama.cpp:full-cuda -s --host 0.0.0.0 -m /models/Qwen3-Embedding-8B-f16.gguf --embedding --pooling last -c 32768 -ub 8192 --verbose-prompt --n-gpu-layers 999&lt;/p&gt;\\n\\n&lt;p&gt;So maybe this doesn&amp;#39;t include the right patch indeed!&lt;/p&gt;\\n\\n&lt;p&gt;I have some compilation issues with my gcc version, but I&amp;#39;ll try this branch, after checking vLLM to see if there is a difference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1nmkb4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751818648,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1msm51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"foldl-li","can_mod_post":false,"created_utc":1751809185,"send_replies":true,"parent_id":"t3_1lt18hg","score":12,"author_fullname":"t2_g644e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are you using this https://github.com/ggml-org/llama.cpp/pull/14029?\\n\\nBesides this, query and document are encoded differently.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1msm51","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you using this &lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/14029\\"&gt;https://github.com/ggml-org/llama.cpp/pull/14029&lt;/a&gt;?&lt;/p&gt;\\n\\n&lt;p&gt;Besides this, query and document are encoded differently.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1msm51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751809185,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1npijc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"DinoAmino","can_mod_post":false,"created_utc":1751819550,"send_replies":true,"parent_id":"t1_n1nf548","score":-5,"author_fullname":"t2_j1v7f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"It has great benchmarks, but... \\" - The Story of Qwen.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1npijc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;It has great benchmarks, but... &amp;quot; - The Story of Qwen.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1npijc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751819550,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1nf548","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1751816443,"send_replies":true,"parent_id":"t3_1lt18hg","score":7,"author_fullname":"t2_s6sfw4yy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried the 0.6b full model but it is doing worse than 150m piccolo-base-zh","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1nf548","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried the 0.6b full model but it is doing worse than 150m piccolo-base-zh&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1nf548/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751816443,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1slzc9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uber-linny","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1p22wo","score":1,"author_fullname":"t2_14166b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i wonder when this goes GGUF how it stacks up to Qwen0.6 Embedding \\n\\n  \\nRemindMe! -7 day","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1slzc9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i wonder when this goes GGUF how it stacks up to Qwen0.6 Embedding &lt;/p&gt;\\n\\n&lt;p&gt;RemindMe! -7 day&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1slzc9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751890099,"author_flair_text":null,"treatment_tags":[],"created_utc":1751890099,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1y29wb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"espadrine","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1p22wo","score":1,"author_fullname":"t2_5nceo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does work much better, getting 48.11% on the same benchmark.\\n\\nThe official JINA API is very slow though. Half a minute for a batch of 32.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1y29wb","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does work much better, getting 48.11% on the same benchmark.&lt;/p&gt;\\n\\n&lt;p&gt;The official JINA API is very slow though. Half a minute for a batch of 32.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1y29wb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751958369,"author_flair_text":null,"treatment_tags":[],"created_utc":1751958369,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1p22wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"masc98","can_mod_post":false,"created_utc":1751834445,"send_replies":true,"parent_id":"t1_n1orkni","score":6,"author_fullname":"t2_12nt66","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"v4 is out btw: https://huggingface.co/jinaai/jina-embeddings-v4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1p22wo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;v4 is out btw: &lt;a href=\\"https://huggingface.co/jinaai/jina-embeddings-v4\\"&gt;https://huggingface.co/jinaai/jina-embeddings-v4&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1p22wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751834445,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rmgwh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prudence-0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1p8610","score":1,"author_fullname":"t2_51bbppl4b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I made my own server with FastAPI.\\n\\nOtherwise, maybe vLLM helps expose","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1rmgwh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I made my own server with FastAPI.&lt;/p&gt;\\n\\n&lt;p&gt;Otherwise, maybe vLLM helps expose&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1rmgwh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751870714,"author_flair_text":null,"treatment_tags":[],"created_utc":1751870714,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1p8610","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dinerburgeryum","can_mod_post":false,"created_utc":1751836314,"send_replies":true,"parent_id":"t1_n1orkni","score":1,"author_fullname":"t2_1j53p3yv3e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What’s the best way to expose Jina v3 via an OpenAI-compatible API?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1p8610","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What’s the best way to expose Jina v3 via an OpenAI-compatible API?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1p8610/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751836314,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1tbb0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1751898912,"send_replies":true,"parent_id":"t1_n1orkni","score":0,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But isn't jina v3 requires remote code execution?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1tbb0h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But isn&amp;#39;t jina v3 requires remote code execution?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1tbb0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751898912,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n1orkni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prudence-0","can_mod_post":false,"created_utc":1751831168,"send_replies":true,"parent_id":"t3_1lt18hg","score":3,"author_fullname":"t2_51bbppl4b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In multilingual, I was very disappointed with qwen3 embedding compared to jinaai/jina-embeddings-v3 which remains my favorite for the moment","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1orkni","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In multilingual, I was very disappointed with qwen3 embedding compared to jinaai/jina-embeddings-v3 which remains my favorite for the moment&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1orkni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751831168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1r30o2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1751860802,"send_replies":true,"parent_id":"t1_n1r2uu2","score":1,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I also tried truncating because its supposed to be a matryoshka embedding on qwen, and using a linear weighting, no dice.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r30o2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I also tried truncating because its supposed to be a matryoshka embedding on qwen, and using a linear weighting, no dice.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1r30o2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751860802,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1r2uu2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1751860730,"send_replies":true,"parent_id":"t3_1lt18hg","score":2,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would you believe I was just trying it out today and it was all messed up.  Swapped from Q3 4B and 0.6B to granite 278m and all my problems went away.  \\n\\nI even pasted the lyrics from Bull on Parade and it scored better than a near duplicate of a VLM caption for a final fantasy video game screenshot in similarity, though everything was scoring way too high.\\n\\nUsing LM studio (via openai api) for testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r2uu2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would you believe I was just trying it out today and it was all messed up.  Swapped from Q3 4B and 0.6B to granite 278m and all my problems went away.  &lt;/p&gt;\\n\\n&lt;p&gt;I even pasted the lyrics from Bull on Parade and it scored better than a near duplicate of a VLM caption for a final fantasy video game screenshot in similarity, though everything was scoring way too high.&lt;/p&gt;\\n\\n&lt;p&gt;Using LM studio (via openai api) for testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1r2uu2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751860730,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rvgxt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FrostAutomaton","can_mod_post":false,"created_utc":1751875990,"send_replies":true,"parent_id":"t3_1lt18hg","score":2,"author_fullname":"t2_1e9th1d970","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, though if I tried generating the embeddings through the SentenceTransformers module instead, I got the state-of-the-art results I was hoping for on my benchmark. A code snippet for how to do so is listed on their HF page.\\n\\nI'm unsure of what the cause is, likely an outdated version of llamacpp or some setting I'm not aware of.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rvgxt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, though if I tried generating the embeddings through the SentenceTransformers module instead, I got the state-of-the-art results I was hoping for on my benchmark. A code snippet for how to do so is listed on their HF page.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m unsure of what the cause is, likely an outdated version of llamacpp or some setting I&amp;#39;m not aware of.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1rvgxt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751875990,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1y2ee2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"espadrine","can_mod_post":false,"created_utc":1751958441,"send_replies":true,"parent_id":"t1_n1tbny8","score":1,"author_fullname":"t2_5nceo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Using the Huggingface model with TEI does give a slightly better result of 35.63%, which is much better than the GGUF. It is still a far cry from the other models I tested.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1y2ee2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using the Huggingface model with TEI does give a slightly better result of 35.63%, which is much better than the GGUF. It is still a far cry from the other models I tested.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lt18hg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1y2ee2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751958441,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tbny8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1751899019,"send_replies":true,"parent_id":"t3_1lt18hg","score":2,"author_fullname":"t2_s6sfw4yy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think you should test the original model first before you try the gguf. My experience with the original Qwen Embedding has been disappointing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1tbny8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you should test the original model first before you try the gguf. My experience with the original Qwen Embedding has been disappointing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/n1tbny8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751899019,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lt18hg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
