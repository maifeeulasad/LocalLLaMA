import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I need help finding an uncensored AI LLM model fhat has absolutely no restrictions. \\n\\nBackground: I'm writing a story that involves violence, gore, and explicit cuss words spoken by the characters.\\n\\nChatGPT 4o can occassionally (and under rare circumstances) curse and say \\"fuck\\" \\"bitch\\" and \\"ass\\" (albeit with a ton of asterisks). However, I need an LLM that can curse far more harsh and crudely. \\n\\nAnd at the moment, I dont have any money on my hands due to financial problems. So I'd appreciate it if you could link a free LLM that doesnt require credit top ups or anything.\\n\\nPlus my laptop specs are 8GB RAM, GTX 1650 and i5 10th gen CPU, if thats relevant, which seems far too small. So I'd also appreciate it if you could link a model that I can deploy to Gradio.\\n\\nI'm a rookie in these things, so I apologise in advance if you see any ignorance in my post.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Free uncensored LLM model that I can deploy to Gradio.","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m82w07","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.33,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1skctar8q4","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753359629,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I need help finding an uncensored AI LLM model fhat has absolutely no restrictions. &lt;/p&gt;\\n\\n&lt;p&gt;Background: I&amp;#39;m writing a story that involves violence, gore, and explicit cuss words spoken by the characters.&lt;/p&gt;\\n\\n&lt;p&gt;ChatGPT 4o can occassionally (and under rare circumstances) curse and say &amp;quot;fuck&amp;quot; &amp;quot;bitch&amp;quot; and &amp;quot;ass&amp;quot; (albeit with a ton of asterisks). However, I need an LLM that can curse far more harsh and crudely. &lt;/p&gt;\\n\\n&lt;p&gt;And at the moment, I dont have any money on my hands due to financial problems. So I&amp;#39;d appreciate it if you could link a free LLM that doesnt require credit top ups or anything.&lt;/p&gt;\\n\\n&lt;p&gt;Plus my laptop specs are 8GB RAM, GTX 1650 and i5 10th gen CPU, if thats relevant, which seems far too small. So I&amp;#39;d also appreciate it if you could link a model that I can deploy to Gradio.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m a rookie in these things, so I apologise in advance if you see any ignorance in my post.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m82w07","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"NeutronSchool","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/","subreddit_subscribers":504023,"created_utc":1753359629,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4w0fxj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NeutronSchool","can_mod_post":false,"created_utc":1753360328,"send_replies":true,"parent_id":"t1_n4w00o2","score":1,"author_fullname":"t2_1skctar8q4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm dirt poor, not even a single dollar in my pocket/paypal/bankðŸ’€\\n\\nThanks for informing me tho..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w0fxj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m dirt poor, not even a single dollar in my pocket/paypal/bankðŸ’€&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for informing me tho..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m82w07","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w0fxj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753360328,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4w00o2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Anduin1357","can_mod_post":false,"created_utc":1753360175,"send_replies":true,"parent_id":"t3_1m82w07","score":2,"author_fullname":"t2_lpy03","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Your specifications are unfortunately too low for any kind of coherent roleplay model we might recommend. For AI workloads, a 1440p-capable GPU and at least 32 GB of RAM is a must.\\n\\nAt the very least, upgrade your RAM so that you can fit decently sized models. If you're too poor for even that, try SillyTavern through the 'AI Horde' API and use the community hosted models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w00o2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your specifications are unfortunately too low for any kind of coherent roleplay model we might recommend. For AI workloads, a 1440p-capable GPU and at least 32 GB of RAM is a must.&lt;/p&gt;\\n\\n&lt;p&gt;At the very least, upgrade your RAM so that you can fit decently sized models. If you&amp;#39;re too poor for even that, try SillyTavern through the &amp;#39;AI Horde&amp;#39; API and use the community hosted models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w00o2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753360175,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m82w07","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4w104v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Obvious-Ad-2454","can_mod_post":false,"created_utc":1753360529,"send_replies":true,"parent_id":"t3_1m82w07","score":0,"author_fullname":"t2_favmw9ob","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"50 free requests per day from open router, 1000 per day if you put 10 dollars in.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w104v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;50 free requests per day from open router, 1000 per day if you put 10 dollars in.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w104v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753360529,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m82w07","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4w1o2f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ready_Necessary97","can_mod_post":false,"created_utc":1753360759,"send_replies":true,"parent_id":"t3_1m82w07","score":1,"author_fullname":"t2_15ud15xy5d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Regardless of the specs, what's a good local model for this use case?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w1o2f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Regardless of the specs, what&amp;#39;s a good local model for this use case?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w1o2f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753360759,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m82w07","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4w4df7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Herr_Drosselmeyer","can_mod_post":false,"created_utc":1753361671,"send_replies":true,"parent_id":"t3_1m82w07","score":3,"author_fullname":"t2_1zr9gwsn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You could run [https://huggingface.co/bartowski/NemoMix-Unleashed-12B-GGUF](https://huggingface.co/bartowski/NemoMix-Unleashed-12B-GGUF) at Q4 on that rig, but it'd be slow. Smaller models are just not good enough imho. \\n\\nI can vouch for the fact that the model itself has no issues with refusals for your use case if prompted to roleplay. Give it a go, doesn't cost you anything other than time to set it up. ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w4df7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could run &lt;a href=\\"https://huggingface.co/bartowski/NemoMix-Unleashed-12B-GGUF\\"&gt;https://huggingface.co/bartowski/NemoMix-Unleashed-12B-GGUF&lt;/a&gt; at Q4 on that rig, but it&amp;#39;d be slow. Smaller models are just not good enough imho. &lt;/p&gt;\\n\\n&lt;p&gt;I can vouch for the fact that the model itself has no issues with refusals for your use case if prompted to roleplay. Give it a go, doesn&amp;#39;t cost you anything other than time to set it up. ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w4df7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753361671,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m82w07","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4w7j0d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Toooooool","can_mod_post":false,"created_utc":1753362702,"send_replies":true,"parent_id":"t3_1m82w07","score":3,"author_fullname":"t2_8llornh4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ReadyArt has some good models for this.  \\nForgotten Safeword was actively trained for smut and gore, it's as unhinged as it gets. (8B to 70B)  \\nGaslight and Omega-Darker-Gaslight will also do some, they're 30% Forgotten Safeword (24B)  \\nBroken-TuTu is 20% are 20% of each of these models so it'll also do NSFL content (24B)  \\nForgotten Abomination is a mix of Safeword and Nevoria (8B to 70B)\\n\\nWith just 4GB of VRAM even a Q4\\\\_K\\\\_XS model is too big so you'd really need to outsource it.  \\nI've seen Broken-TuTu hosted on AI Horde a lot so that could be a free alternative.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4w7j0d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ReadyArt has some good models for this.&lt;br/&gt;\\nForgotten Safeword was actively trained for smut and gore, it&amp;#39;s as unhinged as it gets. (8B to 70B)&lt;br/&gt;\\nGaslight and Omega-Darker-Gaslight will also do some, they&amp;#39;re 30% Forgotten Safeword (24B)&lt;br/&gt;\\nBroken-TuTu is 20% are 20% of each of these models so it&amp;#39;ll also do NSFL content (24B)&lt;br/&gt;\\nForgotten Abomination is a mix of Safeword and Nevoria (8B to 70B)&lt;/p&gt;\\n\\n&lt;p&gt;With just 4GB of VRAM even a Q4_K_XS model is too big so you&amp;#39;d really need to outsource it.&lt;br/&gt;\\nI&amp;#39;ve seen Broken-TuTu hosted on AI Horde a lot so that could be a free alternative.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m82w07/free_uncensored_llm_model_that_i_can_deploy_to/n4w7j0d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753362702,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m82w07","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
