import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I can‚Äôt code/program (at least not yet). \\n\\nIs anyone building tools/abilities to use a FOSS LLM like Llama to integrate with the family tree software GRAMPS? \\n\\nI‚Äôm thinking you could talk to Llama (ie 3.1 or 3.3) in plain English information about family members, relationships, events, locations, etc and Llama automatically inputs the data into GRAMPS? \\n\\nThanks üôè \\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Llama &amp; GRAMPS","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lsqr9n","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_z1u2be88b","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751769743,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I can‚Äôt code/program (at least not yet). &lt;/p&gt;\\n\\n&lt;p&gt;Is anyone building tools/abilities to use a FOSS LLM like Llama to integrate with the family tree software GRAMPS? &lt;/p&gt;\\n\\n&lt;p&gt;I‚Äôm thinking you could talk to Llama (ie 3.1 or 3.3) in plain English information about family members, relationships, events, locations, etc and Llama automatically inputs the data into GRAMPS? &lt;/p&gt;\\n\\n&lt;p&gt;Thanks üôè &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lsqr9n","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"AdCompetitive6193","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lsqr9n/llama_gramps/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lsqr9n/llama_gramps/","subreddit_subscribers":495396,"created_utc":1751769743,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1mhw5w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AdCompetitive6193","can_mod_post":false,"created_utc":1751804972,"send_replies":true,"parent_id":"t1_n1ktiao","score":1,"author_fullname":"t2_z1u2be88b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good point! I might try!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1mhw5w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good point! I might try!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsqr9n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsqr9n/llama_gramps/n1mhw5w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751804972,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ktiao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FORLLM","can_mod_post":false,"created_utc":1751772445,"send_replies":true,"parent_id":"t3_1lsqr9n","score":2,"author_fullname":"t2_1rav5zv0dv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Now's a good time to take up vibe-coding. Lots of free inference floating around while companies try to steal marketshare.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ktiao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now&amp;#39;s a good time to take up vibe-coding. Lots of free inference floating around while companies try to steal marketshare.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsqr9n/llama_gramps/n1ktiao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751772445,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsqr9n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1o2omn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pbm2505","can_mod_post":false,"created_utc":1751823537,"send_replies":true,"parent_id":"t3_1lsqr9n","score":2,"author_fullname":"t2_dtl018hz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"TL;DR - I used OCR + LLMs to translate textual family history into Gramps, with a lot of manual work and verification - not silver bullet for me, but helped.\\n\\nI used OCR + LLMs to parse a textual family history into a GEDCOM file, for import into Gramps.  The family was about 40 pages, containing about 850 names.  I didn't have access to the original document files, which compounded the matter.\\n\\nMy result was mixed, but probably helped me get a fair amount done.  I used Tesseract for OCR, which did an OK job, but had some trouble with superscripts and subscripts in the document, sometimes creating unicode that didn't match the intent.  I spent several hours fixing up the text output with various sed scripts and a few manually typed edits.\\n\\nText to GEDCOM was also hit and miss.  At the time, I didn't have a good local LLM that both 1.) had a decent context window, and 2.) created any or even reasonable GEDCOM, despite several attempts at providing examples.  In the end, I had to cut my OCR-ed and massaged text files into pieces and got some usable GEDCOM output.   Alas, I had approximately 30 hours of fix up in Gramps to add missing information, restore many family records, and verify.  Much of the missing information not in the resulting GEDCOM file were dates, birth/death places, and marriages.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1o2omn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;TL;DR - I used OCR + LLMs to translate textual family history into Gramps, with a lot of manual work and verification - not silver bullet for me, but helped.&lt;/p&gt;\\n\\n&lt;p&gt;I used OCR + LLMs to parse a textual family history into a GEDCOM file, for import into Gramps.  The family was about 40 pages, containing about 850 names.  I didn&amp;#39;t have access to the original document files, which compounded the matter.&lt;/p&gt;\\n\\n&lt;p&gt;My result was mixed, but probably helped me get a fair amount done.  I used Tesseract for OCR, which did an OK job, but had some trouble with superscripts and subscripts in the document, sometimes creating unicode that didn&amp;#39;t match the intent.  I spent several hours fixing up the text output with various sed scripts and a few manually typed edits.&lt;/p&gt;\\n\\n&lt;p&gt;Text to GEDCOM was also hit and miss.  At the time, I didn&amp;#39;t have a good local LLM that both 1.) had a decent context window, and 2.) created any or even reasonable GEDCOM, despite several attempts at providing examples.  In the end, I had to cut my OCR-ed and massaged text files into pieces and got some usable GEDCOM output.   Alas, I had approximately 30 hours of fix up in Gramps to add missing information, restore many family records, and verify.  Much of the missing information not in the resulting GEDCOM file were dates, birth/death places, and marriages.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsqr9n/llama_gramps/n1o2omn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751823537,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsqr9n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
