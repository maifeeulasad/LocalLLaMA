import{j as e}from"./index-CqAPCjw5.js";import{R as t}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Choosing the right on-device LLM is a major challenge 🤔. How do you balance speed, size, and true intelligence? To find a definitive answer, we created the BastionRank Benchmark.We put 10 of the most promising models through a rigorous gauntlet of tests designed to simulate real-world developer and user needs 🥊. Our evaluation covered three critical areas:\\n\\n⚡️ Raw Performance: We measured Time-To-First-Token (responsiveness) and Tokens/Second (generation speed) to find the true speed kings.\\n\\n🧠 Qualitative Intelligence: Can a model understand the nuance of literary prose (Moby Dick) and the precision of a technical paper? We tested both.\\n\\n🤖 Structured Reasoning: The ultimate test for building local AI agents. We assessed each model's ability to extract clean, structured data from a business memo.The results were fascinating, revealing a clear hierarchy of performance and some surprising nuances in model behavior.\\n\\nFind out which models made the top of our tiered rankings 🏆 and see our full analysis in the complete blog post. Read the full report on our official blog or on Medium:\\n\\n👉 Medium: [https://medium.com/@freddyayala/the-bastionrank-showdown-crowning-the-best-on-device-ai-models-of-2025-95a3c058401e](https://medium.com/@freddyayala/the-bastionrank-showdown-crowning-the-best-on-device-ai-models-of-2025-95a3c058401e)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"The BastionRank Showdown: Crowning the Best On-Device AI Models of 2025","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxaz08","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.63,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_2cmiiytn","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752250316,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Choosing the right on-device LLM is a major challenge 🤔. How do you balance speed, size, and true intelligence? To find a definitive answer, we created the BastionRank Benchmark.We put 10 of the most promising models through a rigorous gauntlet of tests designed to simulate real-world developer and user needs 🥊. Our evaluation covered three critical areas:&lt;/p&gt;\\n\\n&lt;p&gt;⚡️ Raw Performance: We measured Time-To-First-Token (responsiveness) and Tokens/Second (generation speed) to find the true speed kings.&lt;/p&gt;\\n\\n&lt;p&gt;🧠 Qualitative Intelligence: Can a model understand the nuance of literary prose (Moby Dick) and the precision of a technical paper? We tested both.&lt;/p&gt;\\n\\n&lt;p&gt;🤖 Structured Reasoning: The ultimate test for building local AI agents. We assessed each model&amp;#39;s ability to extract clean, structured data from a business memo.The results were fascinating, revealing a clear hierarchy of performance and some surprising nuances in model behavior.&lt;/p&gt;\\n\\n&lt;p&gt;Find out which models made the top of our tiered rankings 🏆 and see our full analysis in the complete blog post. Read the full report on our official blog or on Medium:&lt;/p&gt;\\n\\n&lt;p&gt;👉 Medium: &lt;a href=\\"https://medium.com/@freddyayala/the-bastionrank-showdown-crowning-the-best-on-device-ai-models-of-2025-95a3c058401e\\"&gt;https://medium.com/@freddyayala/the-bastionrank-showdown-crowning-the-best-on-device-ai-models-of-2025-95a3c058401e&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/fI5k02DR1sOEKQLbuJoh-Ag2mqh9Q28OHsSdk9zyjQE.png?auto=webp&amp;s=d40ea71c2aabd9bac682acf02c6bfa2699dbe704","width":410,"height":410},"resolutions":[{"url":"https://external-preview.redd.it/fI5k02DR1sOEKQLbuJoh-Ag2mqh9Q28OHsSdk9zyjQE.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd8c820178ab5cc2c4f33f2be0e9c5ff6994dd37","width":108,"height":108},{"url":"https://external-preview.redd.it/fI5k02DR1sOEKQLbuJoh-Ag2mqh9Q28OHsSdk9zyjQE.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5ed78eac1b9e41d0b0219518d102b626658a3f2","width":216,"height":216},{"url":"https://external-preview.redd.it/fI5k02DR1sOEKQLbuJoh-Ag2mqh9Q28OHsSdk9zyjQE.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c30d8f95d348fc8617d81b15858638bf86f8bde2","width":320,"height":320}],"variants":{},"id":"fI5k02DR1sOEKQLbuJoh-Ag2mqh9Q28OHsSdk9zyjQE"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lxaz08","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"frayala87","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxaz08/the_bastionrank_showdown_crowning_the_best/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxaz08/the_bastionrank_showdown_crowning_the_best/","subreddit_subscribers":497825,"created_utc":1752250316,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lg2bg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"this-just_in","can_mod_post":false,"created_utc":1752258674,"send_replies":true,"parent_id":"t1_n2kwqkx","score":3,"author_fullname":"t2_kdmu4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Even top tier models will add additional explanations or descriptions, extra formatting like markdown code fences, or requests for follow-up without prompting that away, and even then you parse responses defensively assuming it ignored your instruction anyhow.  And you might have better results sending the JSON schema response format along in a tool or for structured output.  But this is certainly not a problem unique smaller models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lg2bg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even top tier models will add additional explanations or descriptions, extra formatting like markdown code fences, or requests for follow-up without prompting that away, and even then you parse responses defensively assuming it ignored your instruction anyhow.  And you might have better results sending the JSON schema response format along in a tool or for structured output.  But this is certainly not a problem unique smaller models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxaz08","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxaz08/the_bastionrank_showdown_crowning_the_best/n2lg2bg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752258674,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2kwqkx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teleolurian","can_mod_post":false,"created_utc":1752253263,"send_replies":true,"parent_id":"t3_1lxaz08","score":3,"author_fullname":"t2_5jl5q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the json test seems kinda unfair - some output behaviors are baked into the model, is it really so hard to s/\\\\^\\\\[\\\\^\\\\\\\\{\\\\]\\\\*(\\\\\\\\{.\\\\*\\\\\\\\})\\\\[\\\\^\\\\\\\\}\\\\]\\\\*$/\\\\\\\\1/m or whatever\\n\\n  \\nedit: missed closing paren - don't regex and phone","edited":1752290604,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kwqkx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the json test seems kinda unfair - some output behaviors are baked into the model, is it really so hard to s/^[^\\\\{]*(\\\\{.*\\\\})[^\\\\}]*$/\\\\1/m or whatever&lt;/p&gt;\\n\\n&lt;p&gt;edit: missed closing paren - don&amp;#39;t regex and phone&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxaz08/the_bastionrank_showdown_crowning_the_best/n2kwqkx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752253263,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxaz08","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
