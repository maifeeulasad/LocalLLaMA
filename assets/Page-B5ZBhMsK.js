import{j as e}from"./index-BlGsFJYy.js";import{R as l}from"./RedditPostRenderer-B6uvq_Zl.js";import"./index-DDvVtNwD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi community,\\n\\nWe wrote our own inference engine based on Rust for Apple Silicon. It's open sourced under MIT license.\\n\\nWhy we do this:\\n\\n* should be easy to integrate\\n* believe that app UX will completely change in a recent years\\n* it faster than llama.cpp in most of the cases\\n* sometimes it is even faster than MLX from Apple\\n\\nSpeculative decoding right now tightened with platform (trymirai). Feel free to try it out.\\n\\nWould really appreciate your feedback. Some benchmarks are in readme of the repo. More and more things we will publish later (more benchmarks, support of VLM &amp; TTS/STT is coming soon).","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Alternative to llama.cpp for Apple Silicon","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1m0twqa","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.88,"author_flair_background_color":null,"ups":142,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_am0r9","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":142,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=15ae5a47c095593ebf881ab5e62b6758fc25d283","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752613783,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi community,&lt;/p&gt;\\n\\n&lt;p&gt;We wrote our own inference engine based on Rust for Apple Silicon. It&amp;#39;s open sourced under MIT license.&lt;/p&gt;\\n\\n&lt;p&gt;Why we do this:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;should be easy to integrate&lt;/li&gt;\\n&lt;li&gt;believe that app UX will completely change in a recent years&lt;/li&gt;\\n&lt;li&gt;it faster than llama.cpp in most of the cases&lt;/li&gt;\\n&lt;li&gt;sometimes it is even faster than MLX from Apple&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Speculative decoding right now tightened with platform (trymirai). Feel free to try it out.&lt;/p&gt;\\n\\n&lt;p&gt;Would really appreciate your feedback. Some benchmarks are in readme of the repo. More and more things we will publish later (more benchmarks, support of VLM &amp;amp; TTS/STT is coming soon).&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/trymirai/uzu","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?auto=webp&amp;s=700e55ffe3c14785262eed92cf4ac4e6b00d2777","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=674ea07b479810a47c822bb9fc729d905a23be2c","width":108,"height":54},{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=19f95b4986c06cda340818a9b2680efdb53caa34","width":216,"height":108},{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a02420be8031c27c485fda923223394476f11692","width":320,"height":160},{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3332c993dd26519a4ef1b63d265d7a6c44d33516","width":640,"height":320},{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=879f81b0282d8f538bd6df1590c7b63dbb274596","width":960,"height":480},{"url":"https://external-preview.redd.it/hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c80c046d782e15f10e0e630289a0b96a095332f7","width":1080,"height":540}],"variants":{},"id":"hgPKgy_3Vizk0MqLpC77xRGYB-9mpWo_rx5vN9M9zVU"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m0twqa","is_robot_indexable":true,"num_duplicates":5,"report_reasons":null,"author":"darkolorin","discussion_type":null,"num_comments":19,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/","stickied":false,"url":"https://github.com/trymirai/uzu","subreddit_subscribers":499773,"created_utc":1752613783,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ccmtu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darkolorin","can_mod_post":false,"created_utc":1752617316,"send_replies":true,"parent_id":"t1_n3cc4eh","score":21,"author_fullname":"t2_am0r9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"will see! challenge accepted!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ccmtu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;will see! challenge accepted!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3ccmtu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752617316,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3e0txw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ardalok","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3cwory","score":4,"author_fullname":"t2_vgnewja","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"...that will be in 6 months.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3e0txw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...that will be in 6 months.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3e0txw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752638617,"author_flair_text":null,"treatment_tags":[],"created_utc":1752638617,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3cwory","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1752623989,"send_replies":true,"parent_id":"t1_n3cc4eh","score":5,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But also, why not just backport some of these optimizations into llama.cpp?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cwory","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But also, why not just backport some of these optimizations into llama.cpp?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cwory/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752623989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3cc4eh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"created_utc":1752617152,"send_replies":true,"parent_id":"t3_1m0twqa","score":27,"author_fullname":"t2_t6glzswk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's easy to write an inference engine faster than llama.cpp. It's hard to write an inference engine that's faster than llama.cpp 6 months later.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cc4eh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s easy to write an inference engine faster than llama.cpp. It&amp;#39;s hard to write an inference engine that&amp;#39;s faster than llama.cpp 6 months later.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cc4eh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752617152,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3cg7pk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"norpadon","can_mod_post":false,"created_utc":1752618557,"send_replies":true,"parent_id":"t1_n3c7rfe","score":11,"author_fullname":"t2_12kvb8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Lead dev here. We support quantised models, for example Qwen3. Quantization is the main priority in our roadmap and big improvements (both in terms of performance and quality) are coming soon. Currently we use AWQ with some hacks, but we are working on a fully custom end2end quantization pipeline using the latest PTQ methods","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cg7pk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lead dev here. We support quantised models, for example Qwen3. Quantization is the main priority in our roadmap and big improvements (both in terms of performance and quality) are coming soon. Currently we use AWQ with some hacks, but we are working on a fully custom end2end quantization pipeline using the latest PTQ methods&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cg7pk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752618557,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3c862f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darkolorin","can_mod_post":false,"created_utc":1752615927,"send_replies":true,"parent_id":"t1_n3c7rfe","score":10,"author_fullname":"t2_am0r9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Right now we support AWQ quantization, models we support are ona website.\\n\\nIn some use cases it faster on mac than MLX. We will publish more soon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3c862f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right now we support AWQ quantization, models we support are ona website.&lt;/p&gt;\\n\\n&lt;p&gt;In some use cases it faster on mac than MLX. We will publish more soon.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3c862f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752615927,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n3c7rfe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1752615805,"send_replies":true,"parent_id":"t3_1m0twqa","score":10,"author_fullname":"t2_p45er6oo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pretty cool work! But I’m wondering does it only run bf16/f16?\\n\\n\\nAnd how is it faster than mlx? I couldn’t find examples","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3c7rfe","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty cool work! But I’m wondering does it only run bf16/f16?&lt;/p&gt;\\n\\n&lt;p&gt;And how is it faster than mlx? I couldn’t find examples&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3c7rfe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752615805,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3cntiw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darkolorin","can_mod_post":false,"created_utc":1752621047,"send_replies":true,"parent_id":"t1_n3clxcu","score":7,"author_fullname":"t2_am0r9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ye, we did some ads on Reddit. We’re testing. Idk was it effective or not. First time used it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cntiw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ye, we did some ads on Reddit. We’re testing. Idk was it effective or not. First time used it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cntiw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752621047,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n3clxcu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752620423,"send_replies":true,"parent_id":"t3_1m0twqa","score":5,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dude, I clicked on your ad just today. It was one of those \\"promoted\\" ads amongst the posts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3clxcu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dude, I clicked on your ad just today. It was one of those &amp;quot;promoted&amp;quot; ads amongst the posts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3clxcu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752620423,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3cz4pl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"darkolorin","can_mod_post":false,"created_utc":1752624835,"send_replies":true,"parent_id":"t1_n3cyzq0","score":2,"author_fullname":"t2_am0r9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Will do!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cz4pl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will do!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cz4pl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752624835,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3cyzq0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"created_utc":1752624789,"send_replies":true,"parent_id":"t3_1m0twqa","score":3,"author_fullname":"t2_e9jh97s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome, let me know when it supports all the models that MLX supports including tts and vision-language models. Then I'll switch. :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cyzq0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome, let me know when it supports all the models that MLX supports including tts and vision-language models. Then I&amp;#39;ll switch. :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cyzq0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752624789,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fpqk6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"darkolorin","can_mod_post":false,"created_utc":1752669401,"send_replies":true,"parent_id":"t1_n3ezxgj","score":1,"author_fullname":"t2_am0r9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are several things to consider:\\n1/ MLX is doing some additional quantization over the models you run. So to be honest we don’t know how much quality we loose. We are planning to release research on this. \\n2/ Speculative decoding and other pipelines within inference are quite hard to implement. We do it out of the box. \\n3/ Cross platform. We design our engine to be universal. And we do not focus on training and other things right now. Only inference part. \\n4/ we would prioritize community needs over company strategy (because we are startup huh) and can move faster with new architectures and pipelines (text diffusion, ssm etc)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fpqk6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are several things to consider:\\n1/ MLX is doing some additional quantization over the models you run. So to be honest we don’t know how much quality we loose. We are planning to release research on this. \\n2/ Speculative decoding and other pipelines within inference are quite hard to implement. We do it out of the box. \\n3/ Cross platform. We design our engine to be universal. And we do not focus on training and other things right now. Only inference part. \\n4/ we would prioritize community needs over company strategy (because we are startup huh) and can move faster with new architectures and pipelines (text diffusion, ssm etc)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0twqa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3fpqk6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752669401,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ezxgj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fdg_avid","can_mod_post":false,"created_utc":1752657441,"send_replies":true,"parent_id":"t3_1m0twqa","score":1,"author_fullname":"t2_7vr0myfd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is cool work, congratulations. The thing I don’t really understand is when/why I would use this over MLX?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ezxgj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is cool work, congratulations. The thing I don’t really understand is when/why I would use this over MLX?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3ezxgj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752657441,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fqbdv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Away_Expression_3713","can_mod_post":false,"created_utc":1752669606,"send_replies":true,"parent_id":"t3_1m0twqa","score":1,"author_fullname":"t2_mmtl1muh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"will keep up","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fqbdv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;will keep up&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3fqbdv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752669606,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3dm6ri","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HealthCorrect","can_mod_post":false,"created_utc":1752632934,"send_replies":true,"parent_id":"t3_1m0twqa","score":1,"author_fullname":"t2_7w7ujxhh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Speed is one thing. But the breadth of compatibility and features set llama.cpp apart.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3dm6ri","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Speed is one thing. But the breadth of compatibility and features set llama.cpp apart.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3dm6ri/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752632934,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"41af45de-fdc0-11ee-a05e-8227e0534943","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3dzarc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bwjxjelsbd","can_mod_post":false,"created_utc":1752637993,"send_replies":true,"parent_id":"t3_1m0twqa","score":1,"author_fullname":"t2_lurv0xw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Faster than MLX? Damn!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3dzarc","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 8B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Faster than MLX? Damn!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3dzarc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752637993,"author_flair_text":"Llama 8B","treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3e954c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robberviet","can_mod_post":false,"created_utc":1752642654,"send_replies":true,"parent_id":"t3_1m0twqa","score":1,"author_fullname":"t2_jxc5a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice, another option. Will see in 3 months.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3e954c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice, another option. Will see in 3 months.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3e954c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752642654,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3cictn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"MrDevGuyMcCoder","can_mod_post":false,"created_utc":1752619259,"send_replies":true,"parent_id":"t3_1m0twqa","score":-8,"author_fullname":"t2_mc46ls73","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"I like to propose an alternative to the apple silicon instead, gets more traction","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3cictn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like to propose an alternative to the apple silicon instead, gets more traction&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0twqa/alternative_to_llamacpp_for_apple_silicon/n3cictn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752619259,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0twqa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
