import{j as e}from"./index-BlGsFJYy.js";import{R as t}from"./RedditPostRenderer-B6uvq_Zl.js";import"./index-DDvVtNwD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I've noticed that if you begin a chat with a reasoning model like Qwen 3 and then in subsequent messages switch to a different non-reasoning model (such as Gemma 3 12b or Devstral 2507) the non-reasoning model will sometimes also generate reasoning tokens and respond with a final answer afterwards like it was trained to perform reasoning. This is also without any system prompt.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Non-reasoning models adopting reasoning behavior from previous messages","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m06nhe","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.86,"author_flair_background_color":null,"subreddit_type":"public","ups":16,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_i305y","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":16,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752548299,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve noticed that if you begin a chat with a reasoning model like Qwen 3 and then in subsequent messages switch to a different non-reasoning model (such as Gemma 3 12b or Devstral 2507) the non-reasoning model will sometimes also generate reasoning tokens and respond with a final answer afterwards like it was trained to perform reasoning. This is also without any system prompt.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m06nhe","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Thedudely1","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/","subreddit_subscribers":499294,"created_utc":1752548299,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37bix9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thick-Protection-458","can_mod_post":false,"created_utc":1752551909,"send_replies":true,"parent_id":"t1_n37aitm","score":4,"author_fullname":"t2_abr7phdd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; about the days when you had to provide a few examples\\n\\n\\nNah, these days pretty much never gone.\\n\\n\\nAt least unless you are using llms to do some repeating data transformation pipeline and transformation is complicated enough so even with instructions you need to show some generic and cirner cases examples","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37bix9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;about the days when you had to provide a few examples&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Nah, these days pretty much never gone.&lt;/p&gt;\\n\\n&lt;p&gt;At least unless you are using llms to do some repeating data transformation pipeline and transformation is complicated enough so even with instructions you need to show some generic and cirner cases examples&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37bix9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752551909,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n37aitm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"randomqhacker","can_mod_post":false,"created_utc":1752551491,"send_replies":true,"parent_id":"t3_1m06nhe","score":22,"author_fullname":"t2_4nw3v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep, in-context learning FTW!  Models have gotten so advanced people forget about the days when you had to provide a few examples of what you wanted with your prompt!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37aitm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, in-context learning FTW!  Models have gotten so advanced people forget about the days when you had to provide a few examples of what you wanted with your prompt!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37aitm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752551491,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m06nhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37co2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37bsk5","score":3,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, you have put it succinctly and well.\\n\\n\\"Thinking\\" models are just streamlining the process, and making it intrinsic model behavior.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37co2p","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, you have put it succinctly and well.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Thinking&amp;quot; models are just streamlining the process, and making it intrinsic model behavior.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37co2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752552398,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752552398,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37mrkg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37kn5h","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yea sloppy language on my part.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37mrkg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea sloppy language on my part.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37mrkg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752557074,"author_flair_text":null,"treatment_tags":[],"created_utc":1752557074,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37un6n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hust921","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37kn5h","score":2,"author_fullname":"t2_6nadg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; nothing is \\"fed back into\\" ...\\n\\nMy understanding was that the context is iteratively \\"fed back\\" to predict the next token (word) ?  \\nAnd that's why this, system prompts and context in general works.\\n\\nOr what am I missing?\\n\\nI presume \\"real\\" reasoning models primarily reason because of training data. Or is reasoning something entirely different?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37un6n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; nothing is &amp;quot;fed back into&amp;quot; ...&lt;/p&gt;\\n\\n&lt;p&gt;My understanding was that the context is iteratively &amp;quot;fed back&amp;quot; to predict the next token (word) ?&lt;br/&gt;\\nAnd that&amp;#39;s why this, system prompts and context in general works.&lt;/p&gt;\\n\\n&lt;p&gt;Or what am I missing?&lt;/p&gt;\\n\\n&lt;p&gt;I presume &amp;quot;real&amp;quot; reasoning models primarily reason because of training data. Or is reasoning something entirely different?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37un6n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752561193,"author_flair_text":null,"treatment_tags":[],"created_utc":1752561193,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n37kn5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llmentry","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37bsk5","score":2,"author_fullname":"t2_1lufy6yx6z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I mean isn't that what reasoning / chain of thought is all about? All a reasoning model is doing is first generating a response for a reasoning task when its \\"thinking\\", and then that response is fed back into the input to do whatever the initial task was.\\n\\nNot quite -- nothing is \\"fed back into\\" the input explicitly.  But the model has generated context which it is using for generating new text, and models seem to quite good at naturally reinforcing a solution once they've worked it out, so it just works anyway.\\n\\n&gt;The baseline model theoretically should be able to follow basic instructions and have some minimal reasoning capabilities, so you should be able to replicate \\"reasoning\\" for a non-reasoning model through prompting.\\n\\nYes, you can very easily replicate CoT reasoning with a system prompt in non-reasoning models.  It works very well for when you need reasoning behaviour.  I do this whenever I need deeper reasoning; it's generally cheaper than using a fine-tuned reasoning model, and the results are almost indistinguishable.\\n\\n(One thing I have noticed, though, is that some reasoning models perform far worse than non-reasoning models if you \\\\*prevent\\\\* them from thinking.)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37kn5h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I mean isn&amp;#39;t that what reasoning / chain of thought is all about? All a reasoning model is doing is first generating a response for a reasoning task when its &amp;quot;thinking&amp;quot;, and then that response is fed back into the input to do whatever the initial task was.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Not quite -- nothing is &amp;quot;fed back into&amp;quot; the input explicitly.  But the model has generated context which it is using for generating new text, and models seem to quite good at naturally reinforcing a solution once they&amp;#39;ve worked it out, so it just works anyway.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The baseline model theoretically should be able to follow basic instructions and have some minimal reasoning capabilities, so you should be able to replicate &amp;quot;reasoning&amp;quot; for a non-reasoning model through prompting.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yes, you can very easily replicate CoT reasoning with a system prompt in non-reasoning models.  It works very well for when you need reasoning behaviour.  I do this whenever I need deeper reasoning; it&amp;#39;s generally cheaper than using a fine-tuned reasoning model, and the results are almost indistinguishable.&lt;/p&gt;\\n\\n&lt;p&gt;(One thing I have noticed, though, is that some reasoning models perform far worse than non-reasoning models if you *prevent* them from thinking.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37kn5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752556036,"author_flair_text":null,"treatment_tags":[],"created_utc":1752556036,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n37bsk5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1752552023,"send_replies":true,"parent_id":"t1_n373zb7","score":6,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean isn't that what reasoning / chain of thought is all about? All a reasoning model is doing is first generating a response for a reasoning task when its \\"thinking\\", and then that response is fed back into the input to do whatever the initial task was.\\n\\nThe baseline model theoretically should be able to follow basic instructions and have some minimal reasoning capabilities, so you should be able to replicate \\"reasoning\\" for a non-reasoning model through prompting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37bsk5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean isn&amp;#39;t that what reasoning / chain of thought is all about? All a reasoning model is doing is first generating a response for a reasoning task when its &amp;quot;thinking&amp;quot;, and then that response is fed back into the input to do whatever the initial task was.&lt;/p&gt;\\n\\n&lt;p&gt;The baseline model theoretically should be able to follow basic instructions and have some minimal reasoning capabilities, so you should be able to replicate &amp;quot;reasoning&amp;quot; for a non-reasoning model through prompting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37bsk5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752552023,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n375nph","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thedudely1","can_mod_post":false,"created_utc":1752549507,"send_replies":true,"parent_id":"t1_n373zb7","score":3,"author_fullname":"t2_i305y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes that's true. I thought it was interesting that they would specifically adopt the reasoning tags for LMStudio to interpret as the distinct reasoning section, versus just doing chain of thought prompting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n375nph","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes that&amp;#39;s true. I thought it was interesting that they would specifically adopt the reasoning tags for LMStudio to interpret as the distinct reasoning section, versus just doing chain of thought prompting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m06nhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n375nph/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549507,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n373zb7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1752548848,"send_replies":true,"parent_id":"t3_1m06nhe","score":6,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep.  You can use the same iterative approach to make any model act like a \\"reasoning\\" model, too, without switching models.\\n\\nIf you ask a model to list twenty true things relevant to the prompt, and then ask it to make a step-by-step plan for coming up with the best answer, and then tell it to follow the plan to answer the prompt, it's going to use all of that inferred content now in its context to come up with an answer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n373zb7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep.  You can use the same iterative approach to make any model act like a &amp;quot;reasoning&amp;quot; model, too, without switching models.&lt;/p&gt;\\n\\n&lt;p&gt;If you ask a model to list twenty true things relevant to the prompt, and then ask it to make a step-by-step plan for coming up with the best answer, and then tell it to follow the plan to answer the prompt, it&amp;#39;s going to use all of that inferred content now in its context to come up with an answer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n373zb7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548848,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m06nhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zz6e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Some-Cauliflower4902","can_mod_post":false,"created_utc":1752564127,"send_replies":true,"parent_id":"t3_1m06nhe","score":3,"author_fullname":"t2_1e2tnqudlj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had Mistral “thinking“ like Qwen after same session model switch. I think it just thought it produced the response and continued the conversation in the same format. Same as models acting dumb after tinyllama went before them — they would even apologize for being dumb ..\\n\\nAfter I added model name tags to each message I get less of those. More “Qwens idea was great, here’s what I think…” in its own format.","edited":1752564347,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zz6e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had Mistral “thinking“ like Qwen after same session model switch. I think it just thought it produced the response and continued the conversation in the same format. Same as models acting dumb after tinyllama went before them — they would even apologize for being dumb ..&lt;/p&gt;\\n\\n&lt;p&gt;After I added model name tags to each message I get less of those. More “Qwens idea was great, here’s what I think…” in its own format.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n37zz6e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564127,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m06nhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n382oag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Snoo_28140","can_mod_post":false,"created_utc":1752565662,"send_replies":true,"parent_id":"t3_1m06nhe","score":3,"author_fullname":"t2_6ms1kza7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wait, you're feeding the thoughts back into the model? I always strip that.","edited":1752566958,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n382oag","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait, you&amp;#39;re feeding the thoughts back into the model? I always strip that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m06nhe/nonreasoning_models_adopting_reasoning_behavior/n382oag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752565662,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m06nhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
