import{j as e}from"./index-BxgxThME.js";import{R as l}from"./RedditPostRenderer-BL_SOtuv.js";import"./index--Az3yIKM.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey guys,\\n\\nI’m diving into running models locally with Ollama or LMStudio, and there are so many options that I don’t even know where to start, especially before I lock in on a specific project. I want to develop a clear process for figuring out which model might suit me, even if I don’t yet have a narrow use case.\\n\\nCould you walk me through your thought process? \\nFor example:\\n\\t•\\tHow do you survey the landscape of available models and group them into “creative,” “factual,” or “code-focused” categories?\\n\\t•\\tWhat are the first metrics or specs you check (size, quantization, RAM/VRAM needs, inference speed, training data)?\\n\\t•\\tHow do you run quick, side-by-side tests in Ollama/LMStudio to compare responses on a handful of prompts?\\n\\t•\\tWhat mental shortcuts or analogies do you use to decide “this one feels like the right fit” before committing?\\n\\t•\\tAny go-to scripts, benchmarks, or community resources that help you narrow down from a dozen candidates to your top one or two?\\n\\nI’m not a developer or engineer, I’m coming at this entirely as an end-user who just wants a consumer-friendly way to experiment with local AI. I don’t have deep technical skills or coding experience, so I’m looking for recommendations and processes explained in plain English rather than programming tutorials.\\n\\nHope someone can help and thanks in advance!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How do you pick the right local LLM for your needs?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lq2wn6","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.83,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_8lee8rfc","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751479612,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\\n\\n&lt;p&gt;I’m diving into running models locally with Ollama or LMStudio, and there are so many options that I don’t even know where to start, especially before I lock in on a specific project. I want to develop a clear process for figuring out which model might suit me, even if I don’t yet have a narrow use case.&lt;/p&gt;\\n\\n&lt;p&gt;Could you walk me through your thought process? \\nFor example:\\n    • How do you survey the landscape of available models and group them into “creative,” “factual,” or “code-focused” categories?\\n    • What are the first metrics or specs you check (size, quantization, RAM/VRAM needs, inference speed, training data)?\\n    • How do you run quick, side-by-side tests in Ollama/LMStudio to compare responses on a handful of prompts?\\n    • What mental shortcuts or analogies do you use to decide “this one feels like the right fit” before committing?\\n    • Any go-to scripts, benchmarks, or community resources that help you narrow down from a dozen candidates to your top one or two?&lt;/p&gt;\\n\\n&lt;p&gt;I’m not a developer or engineer, I’m coming at this entirely as an end-user who just wants a consumer-friendly way to experiment with local AI. I don’t have deep technical skills or coding experience, so I’m looking for recommendations and processes explained in plain English rather than programming tutorials.&lt;/p&gt;\\n\\n&lt;p&gt;Hope someone can help and thanks in advance!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lq2wn6","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ExtiqX","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/","subreddit_subscribers":494198,"created_utc":1751479612,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zuxr9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1751484017,"send_replies":true,"parent_id":"t3_1lq2wn6","score":7,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's only a few major models.  Everything else is basically a finetune of those models.  I guess it's similar to how there's only a few real linux distros and a billion derivatives.  Try out the major models like llama, qwen, mistral, and just see what works best.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zuxr9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s only a few major models.  Everything else is basically a finetune of those models.  I guess it&amp;#39;s similar to how there&amp;#39;s only a few real linux distros and a billion derivatives.  Try out the major models like llama, qwen, mistral, and just see what works best.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zuxr9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751484017,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq2wn6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1007nh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ExtiqX","can_mod_post":false,"created_utc":1751485626,"send_replies":true,"parent_id":"t1_n0zjan0","score":2,"author_fullname":"t2_8lee8rfc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, I will try that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1007nh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I will try that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n1007nh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751485626,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zjan0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751480538,"send_replies":true,"parent_id":"t3_1lq2wn6","score":3,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Any go-to scripts, benchmarks, or community resources that help you narrow down from a dozen candidates to your top one or two?\\n\\n[Eqbench.com](http://Eqbench.com)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zjan0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Any go-to scripts, benchmarks, or community resources that help you narrow down from a dozen candidates to your top one or two?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"http://Eqbench.com\\"&gt;Eqbench.com&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zjan0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751480538,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq2wn6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n123ync","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uber-linny","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11alaw","score":1,"author_fullname":"t2_14166b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looking at the mteb leaderboard. The qwen models are at the top . \\n\\nI have specific docs that I pull data from...  I'm looking for the specific answer and the reference so that I double check it , when I have to .","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n123ync","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking at the mteb leaderboard. The qwen models are at the top . &lt;/p&gt;\\n\\n&lt;p&gt;I have specific docs that I pull data from...  I&amp;#39;m looking for the specific answer and the reference so that I double check it , when I have to .&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n123ync/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751509670,"author_flair_text":null,"treatment_tags":[],"created_utc":1751509670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n11alaw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GrungeWerX","can_mod_post":false,"created_utc":1751499965,"send_replies":true,"parent_id":"t1_n10hgli","score":1,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What are the embeddings for? I’m assuming a vector database but how specifically are you using them?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11alaw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are the embeddings for? I’m assuming a vector database but how specifically are you using them?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n11alaw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751499965,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n10hgli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uber-linny","can_mod_post":false,"created_utc":1751490637,"send_replies":true,"parent_id":"t3_1lq2wn6","score":1,"author_fullname":"t2_14166b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As a non software guy that needed rag on a 6700xt, I've tried to squeeze as much as I could. I really need to stop touching it until I get new hardware but I just use :\\n\\nQwen 3 4_k_m with flash attention and the two experimental tags changed to q8\\n\\nPreset to recommend /think settings like temp etc \\n\\nQwen3 0.6 embedding set to 1024 tokens .\\n\\n1024 chunks with 25 overlap \\n\\nAnythingLLM embedding set to qwene 0.6 and with vectoring set to high. \\n\\nGet around 20 tokens /s, and it gives the most informative and accurate answers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10hgli","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a non software guy that needed rag on a 6700xt, I&amp;#39;ve tried to squeeze as much as I could. I really need to stop touching it until I get new hardware but I just use :&lt;/p&gt;\\n\\n&lt;p&gt;Qwen 3 4_k_m with flash attention and the two experimental tags changed to q8&lt;/p&gt;\\n\\n&lt;p&gt;Preset to recommend /think settings like temp etc &lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 0.6 embedding set to 1024 tokens .&lt;/p&gt;\\n\\n&lt;p&gt;1024 chunks with 25 overlap &lt;/p&gt;\\n\\n&lt;p&gt;AnythingLLM embedding set to qwene 0.6 and with vectoring set to high. &lt;/p&gt;\\n\\n&lt;p&gt;Get around 20 tokens /s, and it gives the most informative and accurate answers&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n10hgli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751490637,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq2wn6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zu3j9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahmetegesel","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0zqls7","score":1,"author_fullname":"t2_69skhb61","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pretty close to times where all content is generated by LLM and consumed by only LLM. I’ll go find a farm now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zu3j9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty close to times where all content is generated by LLM and consumed by only LLM. I’ll go find a farm now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zu3j9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751483764,"author_flair_text":null,"treatment_tags":[],"created_utc":1751483764,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zqls7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RonHarrods","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0zpa0o","score":1,"author_fullname":"t2_a4486q5q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Half the internet is LLM generated. Then another 40% is pre-LLM autogenerated.\\n\\n\\nEdit: damn that post isn't even properly formatted. I didn't even glance at it, but there was no oerson involved in even pressing the post button I reckon","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0zqls7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Half the internet is LLM generated. Then another 40% is pre-LLM autogenerated.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: damn that post isn&amp;#39;t even properly formatted. I didn&amp;#39;t even glance at it, but there was no oerson involved in even pressing the post button I reckon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zqls7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751482710,"author_flair_text":null,"treatment_tags":[],"created_utc":1751482710,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zpa0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cergorach","can_mod_post":false,"created_utc":1751482320,"send_replies":true,"parent_id":"t1_n0zmpnq","score":1,"author_fullname":"t2_cs4w88d2l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And apparently they already know how to use an LLM, as most of that post is LLM generated...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zpa0o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And apparently they already know how to use an LLM, as most of that post is LLM generated...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq2wn6","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zpa0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751482320,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zmpnq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RonHarrods","can_mod_post":false,"created_utc":1751481557,"send_replies":true,"parent_id":"t3_1lq2wn6","score":1,"author_fullname":"t2_a4486q5q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is such a great question to ask an LLM. Claude is always cery helpful for me with these types of questions","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zmpnq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is such a great question to ask an LLM. Claude is always cery helpful for me with these types of questions&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq2wn6/how_do_you_pick_the_right_local_llm_for_your_needs/n0zmpnq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751481557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq2wn6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
