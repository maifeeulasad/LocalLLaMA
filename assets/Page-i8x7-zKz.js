import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Did any of you guys try to augment text data uaing an LLM? For example augmenting medical symptoms using MedGemma, by telling the LLM to generate 3 different phrases similar to the original phrase and then repeating this for every row until all the dataset is augmented.\\n\\nWhat do you think about this approach, and would it be better than using a bert model or other augmentation techniques like synonyms replacement, translation....","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Has anyone here tried to augment text data using local domain specific LLMs ?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltyc9k","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.63,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_2zj2xaar","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751904856,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Did any of you guys try to augment text data uaing an LLM? For example augmenting medical symptoms using MedGemma, by telling the LLM to generate 3 different phrases similar to the original phrase and then repeating this for every row until all the dataset is augmented.&lt;/p&gt;\\n\\n&lt;p&gt;What do you think about this approach, and would it be better than using a bert model or other augmentation techniques like synonyms replacement, translation....&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1ltyc9k","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"skillmaker","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ltyc9k/has_anyone_here_tried_to_augment_text_data_using/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ltyc9k/has_anyone_here_tried_to_augment_text_data_using/","subreddit_subscribers":496034,"created_utc":1751904856,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1w5e2l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1751930779,"send_replies":true,"parent_id":"t1_n1ulupw","score":2,"author_fullname":"t2_8lvrytgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which BERT like model would you recommend specifically?\\nThx!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1w5e2l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which BERT like model would you recommend specifically?\\nThx!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltyc9k","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltyc9k/has_anyone_here_tried_to_augment_text_data_using/n1w5e2l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751930779,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ulupw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Former-Ad-5757","can_mod_post":false,"created_utc":1751912577,"send_replies":true,"parent_id":"t3_1ltyc9k","score":2,"author_fullname":"t2_ihsdiwk6k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What do you synthetic data is? \\n\\nBert-models are just much and much cheaper to create data than an llm.\\nIf you want 3 different phrases then I would use an llm.\\nBut if for example you wanted 20 different phrases I would say use an llm for 5 variations and then use Bert to create another 3 variations for every llm generation. You get 20 generations, while only 5 will be “expensive”","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ulupw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you synthetic data is? &lt;/p&gt;\\n\\n&lt;p&gt;Bert-models are just much and much cheaper to create data than an llm.\\nIf you want 3 different phrases then I would use an llm.\\nBut if for example you wanted 20 different phrases I would say use an llm for 5 variations and then use Bert to create another 3 variations for every llm generation. You get 20 generations, while only 5 will be “expensive”&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltyc9k/has_anyone_here_tried_to_augment_text_data_using/n1ulupw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751912577,"author_flair_text":"Llama 3","treatment_tags":[],"link_id":"t3_1ltyc9k","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xiz9o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1751948610,"send_replies":true,"parent_id":"t3_1ltyc9k","score":1,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes!  The method is called self-critique, though the critique need not be of the model's output.\\n\\nHelixNet pioneered the technique:  https://huggingface.co/migtissera/HelixNet\\n\\nI usually find best results using Phi-4 for critique, and Gemma3-27B to rewrite the text, though sometimes for STEM subject matter I use Tulu3-70B for the rewrite.\\n\\nMy prompt for the critique:\\n\\n&gt; Given the following prompt and reply, critique the answer and suggest ways it might be improved.  Do not rewrite the answer; only provide suggestions for its improvement.\\n\\n&gt; **Prompt:** {PROMPT}\\n\\n&gt; **Reply:** {REPLY}\\n\\n.. and then for the rewrite step:\\n\\n&gt; Given the following prompt, reply, and critique, rewrite the answer, incorporating the suggested improvements.\\n\\n&gt; **Prompt:** {PROMPT}\\n\\n&gt; **Reply:** {REPLY}\\n\\n&gt; **Critique:** {CRITIQUE}\\n\\nThe rewrite step is particularly effective when used in conjunction with RAG, if you have a RAG database with relevant content.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xiz9o","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes!  The method is called self-critique, though the critique need not be of the model&amp;#39;s output.&lt;/p&gt;\\n\\n&lt;p&gt;HelixNet pioneered the technique:  &lt;a href=\\"https://huggingface.co/migtissera/HelixNet\\"&gt;https://huggingface.co/migtissera/HelixNet&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I usually find best results using Phi-4 for critique, and Gemma3-27B to rewrite the text, though sometimes for STEM subject matter I use Tulu3-70B for the rewrite.&lt;/p&gt;\\n\\n&lt;p&gt;My prompt for the critique:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Given the following prompt and reply, critique the answer and suggest ways it might be improved.  Do not rewrite the answer; only provide suggestions for its improvement.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; {PROMPT}&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Reply:&lt;/strong&gt; {REPLY}&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;.. and then for the rewrite step:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Given the following prompt, reply, and critique, rewrite the answer, incorporating the suggested improvements.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; {PROMPT}&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Reply:&lt;/strong&gt; {REPLY}&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Critique:&lt;/strong&gt; {CRITIQUE}&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The rewrite step is particularly effective when used in conjunction with RAG, if you have a RAG database with relevant content.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltyc9k/has_anyone_here_tried_to_augment_text_data_using/n1xiz9o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751948610,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1ltyc9k","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
