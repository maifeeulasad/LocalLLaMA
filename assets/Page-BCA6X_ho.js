import{j as e}from"./index-BgwOAK4-.js";import{R as l}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Need advice. I'm ordering a new mac for work and was thinking about M4 Max 128GB to run the models locally for coding tasks. I'm going to run mlx llms with LM Studio. Which model would you recommend? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Which model can I run comfortably on M4 Max 128GB with a long context window?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m0apct","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.6,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_3eyym7wo","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752561851,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Need advice. I&amp;#39;m ordering a new mac for work and was thinking about M4 Max 128GB to run the models locally for coding tasks. I&amp;#39;m going to run mlx llms with LM Studio. Which model would you recommend? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m0apct","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"pppreddit","discussion_type":null,"num_comments":9,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/","subreddit_subscribers":499295,"created_utc":1752561851,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zcdq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ill_Occasion_1537","can_mod_post":false,"created_utc":1752563770,"send_replies":true,"parent_id":"t3_1m0apct","score":3,"author_fullname":"t2_9qhdfp2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A lot. I have few models that I’m running locally on my Mac. I use ollama tho Deepseek and others","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zcdq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A lot. I have few models that I’m running locally on my Mac. I use ollama tho Deepseek and others&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n37zcdq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752563770,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zftm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bobby-chan","can_mod_post":false,"created_utc":1752563824,"send_replies":true,"parent_id":"t3_1m0apct","score":2,"author_fullname":"t2_frmtv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If all you want is context, maybe you can try [https://huggingface.co/mlx-community/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct-bf16](https://huggingface.co/mlx-community/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct-bf16) (nvidia also made 2M and 4M context variants) or [https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-8bit](https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-8bit)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zftm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If all you want is context, maybe you can try &lt;a href=\\"https://huggingface.co/mlx-community/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct-bf16\\"&gt;https://huggingface.co/mlx-community/Llama-3.1-Nemotron-8B-UltraLong-1M-Instruct-bf16&lt;/a&gt; (nvidia also made 2M and 4M context variants) or &lt;a href=\\"https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-8bit\\"&gt;https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-1M-8bit&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n37zftm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752563824,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zr6u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SandboChang","can_mod_post":false,"created_utc":1752564004,"send_replies":true,"parent_id":"t3_1m0apct","score":2,"author_fullname":"t2_10icmj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3 32B work relatively well with 10-20 tps depending on context length, but problem with long context is the long prompt processing. \\n\\nYou might want to try Qwen3 30B-A3B to see if it is good enough for you to begin with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zr6u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 32B work relatively well with 10-20 tps depending on context length, but problem with long context is the long prompt processing. &lt;/p&gt;\\n\\n&lt;p&gt;You might want to try Qwen3 30B-A3B to see if it is good enough for you to begin with.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n37zr6u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564004,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38f2px","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1752572956,"send_replies":true,"parent_id":"t3_1m0apct","score":2,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The new devstral small model will be relatively fast on that depending on what you are using as an interface. Cline is prompt heavy and will overwhelm devstral small.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38f2px","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The new devstral small model will be relatively fast on that depending on what you are using as an interface. Cline is prompt heavy and will overwhelm devstral small.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n38f2px/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752572956,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37ypgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ill_Occasion_1537","can_mod_post":false,"created_utc":1752563410,"send_replies":true,"parent_id":"t3_1m0apct","score":1,"author_fullname":"t2_9qhdfp2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I downloaded all versions of kimi k2 and they never worked. I have the same Mac as you. It needs nvdia GPU.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37ypgd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I downloaded all versions of kimi k2 and they never worked. I have the same Mac as you. It needs nvdia GPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n37ypgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752563410,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n385o41","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Efficiency_1144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n384ix9","score":1,"author_fullname":"t2_1nkj9l14b0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/nswulf0lyzcf1.png?width=3131&amp;format=png&amp;auto=webp&amp;s=88f99bb85e1268aae2950450a493c909623504cb\\n\\nYeah picking one of the ones on the left is the way to go","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n385o41","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/nswulf0lyzcf1.png?width=3131&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=88f99bb85e1268aae2950450a493c909623504cb\\"&gt;https://preview.redd.it/nswulf0lyzcf1.png?width=3131&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=88f99bb85e1268aae2950450a493c909623504cb&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Yeah picking one of the ones on the left is the way to go&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0apct","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n385o41/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752567388,"media_metadata":{"nswulf0lyzcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":75,"x":108,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c945f8cddd28e81a8d4cf0acdb3af49124da74f"},{"y":151,"x":216,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e40438646d3e32fed129d7a8d9f07b98dbc4b30"},{"y":224,"x":320,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=41b5f57f1d75443faf1600ba8d6f5f0967895e69"},{"y":448,"x":640,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e835347b32efbfae3bacc4cfa31e63f5dad881d"},{"y":672,"x":960,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3aadb9fa22daf4c76d9641d8d0becde1be4f9185"},{"y":756,"x":1080,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c66cc6dab1b690b172a811f18ea6ffbf424c8397"}],"s":{"y":2194,"x":3131,"u":"https://preview.redd.it/nswulf0lyzcf1.png?width=3131&amp;format=png&amp;auto=webp&amp;s=88f99bb85e1268aae2950450a493c909623504cb"},"id":"nswulf0lyzcf1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1752567388,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n384ix9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"profcuck","can_mod_post":false,"created_utc":1752566720,"send_replies":true,"parent_id":"t1_n37xru6","score":1,"author_fullname":"t2_qc2xc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is just deeply uninformed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n384ix9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is just deeply uninformed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m0apct","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n384ix9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752566720,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n37xru6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"BigMagnut","can_mod_post":false,"created_utc":1752562893,"send_replies":true,"parent_id":"t3_1m0apct","score":-11,"author_fullname":"t2_kmbhlwmn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"None. You need a new computer. Coding models require twice that much ram, more like 256 to 500 gigs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37xru6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;None. You need a new computer. Coding models require twice that much ram, more like 256 to 500 gigs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n37xru6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562893,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38w7qv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rakhmat3","can_mod_post":false,"created_utc":1752580942,"send_replies":true,"parent_id":"t3_1m0apct","score":1,"author_fullname":"t2_m2ujq54i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Every 30-40B model at Q8. Qwen3 30B-A3B is extremely fast.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38w7qv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Every 30-40B model at Q8. Qwen3 30B-A3B is extremely fast.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0apct/which_model_can_i_run_comfortably_on_m4_max_128gb/n38w7qv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752580942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0apct","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
