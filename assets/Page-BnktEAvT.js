import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I’m looking to set up a homelab. I’ve got 2 NVIDIA Quadro RTX 6000’s laying around that I was given a few years back. I don’t have any server equipment yet, but I’m gonna buy a rack, PSU, server motherboard, Processor, RAM, and storage enclaves to set up my first homelab. \\n\\nI want to build an AI to help me with my job in Cybersecurity, I’d like to train it on big data sets like Stack Overflow and CVE.\\n\\nMy question is, are my GPU’s good enough for this task? What kind of CPU/S do I need to keep up? Ram capacity/speed recommendations?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I own a few Quadro’s, can I build an AI with these?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6v9yq","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.25,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1cam2liip6","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753231391,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m looking to set up a homelab. I’ve got 2 NVIDIA Quadro RTX 6000’s laying around that I was given a few years back. I don’t have any server equipment yet, but I’m gonna buy a rack, PSU, server motherboard, Processor, RAM, and storage enclaves to set up my first homelab. &lt;/p&gt;\\n\\n&lt;p&gt;I want to build an AI to help me with my job in Cybersecurity, I’d like to train it on big data sets like Stack Overflow and CVE.&lt;/p&gt;\\n\\n&lt;p&gt;My question is, are my GPU’s good enough for this task? What kind of CPU/S do I need to keep up? Ram capacity/speed recommendations?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m6v9yq","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"NetTechMan","discussion_type":null,"num_comments":13,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/","subreddit_subscribers":503519,"created_utc":1753231391,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ntn7r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Efficiency_1144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4mz390","score":2,"author_fullname":"t2_1nkj9l14b0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Berts are small LLMs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ntn7r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Berts are small LLMs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4ntn7r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753247574,"author_flair_text":null,"treatment_tags":[],"created_utc":1753247574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mz390","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NetTechMan","can_mod_post":false,"created_utc":1753235368,"send_replies":true,"parent_id":"t1_n4mtbob","score":1,"author_fullname":"t2_1cam2liip6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mz390","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;??&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4mz390/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753235368,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4mtbob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fp4guru","can_mod_post":false,"created_utc":1753233363,"send_replies":true,"parent_id":"t3_1m6v9yq","score":2,"author_fullname":"t2_1tp8zldw5g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Bert yes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mtbob","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bert yes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4mtbob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753233363,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6v9yq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4nmu2f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NetTechMan","can_mod_post":false,"created_utc":1753244464,"send_replies":true,"parent_id":"t1_n4nkney","score":1,"author_fullname":"t2_1cam2liip6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So 2 of my Quadro’s will be sufficient to run an LLM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nmu2f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So 2 of my Quadro’s will be sufficient to run an LLM?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4nmu2f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753244464,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nkney","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeepWisdomGuy","can_mod_post":false,"created_utc":1753243526,"send_replies":true,"parent_id":"t3_1m6v9yq","score":1,"author_fullname":"t2_lznk2wv8h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had a similar setup with P40s: [https://www.reddit.com/r/LocalLLaMA/comments/1djd6ll/behemoth\\\\_build/](https://www.reddit.com/r/LocalLLaMA/comments/1djd6ll/behemoth_build/) They are on par in terms of cuda cores and VRAM, but the P40s allegedly have better performance with machine learning. I found them underwhelming and ended up replacing them with 3090s. They tripled in price after I bought them, though. :-)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nkney","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had a similar setup with P40s: &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1djd6ll/behemoth_build/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1djd6ll/behemoth_build/&lt;/a&gt; They are on par in terms of cuda cores and VRAM, but the P40s allegedly have better performance with machine learning. I found them underwhelming and ended up replacing them with 3090s. They tripled in price after I bought them, though. :-)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4nkney/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753243526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6v9yq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4pfvqb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NetTechMan","can_mod_post":false,"created_utc":1753275974,"send_replies":true,"parent_id":"t1_n4nzrt2","score":1,"author_fullname":"t2_1cam2liip6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Turing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pfvqb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Turing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4pfvqb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753275974,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4nzrt2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1753250669,"send_replies":true,"parent_id":"t3_1m6v9yq","score":1,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Turing rtx 6000 or ampere/ Ada rtx6000?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nzrt2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Turing rtx 6000 or ampere/ Ada rtx6000?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4nzrt2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753250669,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6v9yq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4pnlfb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fizzy1242","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pn77f","score":1,"author_fullname":"t2_16zcsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it depends on the size of model you want to tune. [unsloth docs](https://docs.unsloth.ai/get-started/beginner-start-here/unsloth-requirements) are pretty helpful.\\n\\nthat said, you probably don't want to finetune unless you have +10k rows of data. Atleast try if a non-finetuned model works for your use case before breaking the bank","edited":false,"author_flair_css_class":null,"name":"t1_n4pnlfb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it depends on the size of model you want to tune. &lt;a href=\\"https://docs.unsloth.ai/get-started/beginner-start-here/unsloth-requirements\\"&gt;unsloth docs&lt;/a&gt; are pretty helpful.&lt;/p&gt;\\n\\n&lt;p&gt;that said, you probably don&amp;#39;t want to finetune unless you have +10k rows of data. Atleast try if a non-finetuned model works for your use case before breaking the bank&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6v9yq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4pnlfb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753278425,"author_flair_text":null,"collapsed":false,"created_utc":1753278425,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pn77f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NetTechMan","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pkyh8","score":1,"author_fullname":"t2_1cam2liip6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What do I need to train? Any spec lists?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pn77f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do I need to train? Any spec lists?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4pn77f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753278303,"author_flair_text":null,"treatment_tags":[],"created_utc":1753278303,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pkyh8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fizzy1242","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4pfjqy","score":1,"author_fullname":"t2_16zcsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It means actually using the given AI model (talking to it, etc...), NOT training it.\\n\\nTraining needs much more memory","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4pkyh8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It means actually using the given AI model (talking to it, etc...), NOT training it.&lt;/p&gt;\\n\\n&lt;p&gt;Training needs much more memory&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4pkyh8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753277597,"author_flair_text":null,"treatment_tags":[],"created_utc":1753277597,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4pfjqy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NetTechMan","can_mod_post":false,"created_utc":1753275864,"send_replies":true,"parent_id":"t1_n4ob1qe","score":1,"author_fullname":"t2_1cam2liip6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What’s inferencing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4pfjqy","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What’s inferencing?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6v9yq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4pfjqy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753275864,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ob1qe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fizzy1242","can_mod_post":false,"created_utc":1753256871,"send_replies":true,"parent_id":"t3_1m6v9yq","score":1,"author_fullname":"t2_16zcsx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Your gpus are fine. cpu isn't \\"as\\" important, but a good one is always nice with plenty ram. 48 vram lets you tune some smaller models, but whether it's worth it is up to you.\\n\\ninferencing bigger models however might fit your use case \\"well enough\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ob1qe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your gpus are fine. cpu isn&amp;#39;t &amp;quot;as&amp;quot; important, but a good one is always nice with plenty ram. 48 vram lets you tune some smaller models, but whether it&amp;#39;s worth it is up to you.&lt;/p&gt;\\n\\n&lt;p&gt;inferencing bigger models however might fit your use case &amp;quot;well enough&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6v9yq/i_own_a_few_quadros_can_i_build_an_ai_with_these/n4ob1qe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753256871,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6v9yq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),_=()=>e.jsx(l,{data:a});export{_ as default};
