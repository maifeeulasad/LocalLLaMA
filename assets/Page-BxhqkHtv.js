import{j as e}from"./index-BOnf-UhU.js";import{R as l}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Google DeepMind's new paper explore a new advanced Transformers architecture for LLMs called Mixture-of-Recursions which uses recursive Transformers with dynamic recursion per token. Check visual explanation details : https://youtu.be/GWqXCgd7Hnc?si=M6xxbtczSf_TEEYR","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Google DeepMind release Mixture-of-Recursions","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7fwhl","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"subreddit_type":"public","ups":210,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_th2ct5t8g","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":210,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1753292638,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Google DeepMind&amp;#39;s new paper explore a new advanced Transformers architecture for LLMs called Mixture-of-Recursions which uses recursive Transformers with dynamic recursion per token. Check visual explanation details : &lt;a href=\\"https://youtu.be/GWqXCgd7Hnc?si=M6xxbtczSf_TEEYR\\"&gt;https://youtu.be/GWqXCgd7Hnc?si=M6xxbtczSf_TEEYR&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/QmbZwjHL_nSls3hlAww-zDS-HWSbRw7J2Tj08JUnDak.jpeg?auto=webp&amp;s=5d63020d7a90f3dd9933e344b8670cb78b0b5165","width":480,"height":360},"resolutions":[{"url":"https://external-preview.redd.it/QmbZwjHL_nSls3hlAww-zDS-HWSbRw7J2Tj08JUnDak.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46cf0a3ba4ca4557db533db7facf3345d193ff14","width":108,"height":81},{"url":"https://external-preview.redd.it/QmbZwjHL_nSls3hlAww-zDS-HWSbRw7J2Tj08JUnDak.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3bcb7fc50ee4b735515cf0df1fa150704579262","width":216,"height":162},{"url":"https://external-preview.redd.it/QmbZwjHL_nSls3hlAww-zDS-HWSbRw7J2Tj08JUnDak.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc83119edf707dba6c55fc32d3a9910075ea589d","width":320,"height":240}],"variants":{},"id":"QmbZwjHL_nSls3hlAww-zDS-HWSbRw7J2Tj08JUnDak"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m7fwhl","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"Technical-Love-8479","discussion_type":null,"num_comments":29,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/","subreddit_subscribers":503518,"created_utc":1753292638,"num_crossposts":3,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rwprv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BalorNG","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rvdyp","score":5,"author_fullname":"t2_b6gw9q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I know, I should have added \\"by us\\" :)\\nDynamic layer sharing is even better, cause you can have dynamic model depth per token, saving both ram *and* compute.\\nNow, with recent \\"hierarchical reasoning model\\" paper we have even more potential for \\"dynamic depth\\" but that will have to wait a while to be practical I suppose... Next month at the very least, heh - the progress is *glacial*, I'm telling ye","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rwprv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know, I should have added &amp;quot;by us&amp;quot; :)\\nDynamic layer sharing is even better, cause you can have dynamic model depth per token, saving both ram &lt;em&gt;and&lt;/em&gt; compute.\\nNow, with recent &amp;quot;hierarchical reasoning model&amp;quot; paper we have even more potential for &amp;quot;dynamic depth&amp;quot; but that will have to wait a while to be practical I suppose... Next month at the very least, heh - the progress is &lt;em&gt;glacial&lt;/em&gt;, I&amp;#39;m telling ye&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rwprv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753301058,"author_flair_text":null,"treatment_tags":[],"created_utc":1753301058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4t0knq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sygm8","score":3,"author_fullname":"t2_vbzgnic","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see the point behind you idea now. I think you should keep pursuing it since MoR is potentially chasing performance mainly while your work is focused on improving quality.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4t0knq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see the point behind you idea now. I think you should keep pursuing it since MoR is potentially chasing performance mainly while your work is focused on improving quality.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m7fwhl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4t0knq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753313041,"author_flair_text":null,"treatment_tags":[],"created_utc":1753313041,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sygm8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4s9gq0","score":2,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For Deepmind's MoR, I don't know.  I'm still learning about this along with everyone else.\\n\\nFor self-mixing, I typically see inference speed **decrease** by about 30% (since it is inferring with all layers, but inferring with some layers twice), with the benefit of higher inference **competence** for some tasks, while holding memory requirements more or less constant (slight increase from extra KV cache).  Basically, whatever the model normally does poorly, it will still do poorly because self-mixing doesn't give it any new skills, but whatever the model normally does well, it frequently does much better once I've figured out which layers to repeat to benefit competence the most.","edited":false,"author_flair_css_class":null,"name":"t1_n4sygm8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For Deepmind&amp;#39;s MoR, I don&amp;#39;t know.  I&amp;#39;m still learning about this along with everyone else.&lt;/p&gt;\\n\\n&lt;p&gt;For self-mixing, I typically see inference speed &lt;strong&gt;decrease&lt;/strong&gt; by about 30% (since it is inferring with all layers, but inferring with some layers twice), with the benefit of higher inference &lt;strong&gt;competence&lt;/strong&gt; for some tasks, while holding memory requirements more or less constant (slight increase from extra KV cache).  Basically, whatever the model normally does poorly, it will still do poorly because self-mixing doesn&amp;#39;t give it any new skills, but whatever the model normally does well, it frequently does much better once I&amp;#39;ve figured out which layers to repeat to benefit competence the most.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m7fwhl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4sygm8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753312349,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1753312349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4s9gq0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rvdyp","score":2,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Theoretically, where and how much performance we potentially can gain?\\n\\nSay PP for a certain model is 300 t/s, and tg is 25 t/s. What's the theoretical boost here?\\n\\nGiven that it's context dependent the tg will be highly variable, but an average of even 20% is amazing at this point.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4s9gq0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Theoretically, where and how much performance we potentially can gain?&lt;/p&gt;\\n\\n&lt;p&gt;Say PP for a certain model is 300 t/s, and tg is 25 t/s. What&amp;#39;s the theoretical boost here?&lt;/p&gt;\\n\\n&lt;p&gt;Given that it&amp;#39;s context dependent the tg will be highly variable, but an average of even 20% is amazing at this point.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4s9gq0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753304621,"author_flair_text":null,"treatment_tags":[],"created_utc":1753304621,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rvdyp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ru0w3","score":6,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yup, I was in that discussion :-) been working on self-mixing in llama.cpp for about two years, now.\\n\\nIt's definitely more of a win for us GPU-poors than the GPU-rich, if only because it makes much more effective use of limited VRAM.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4rvdyp","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yup, I was in that discussion :-) been working on self-mixing in llama.cpp for about two years, now.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s definitely more of a win for us GPU-poors than the GPU-rich, if only because it makes much more effective use of limited VRAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rvdyp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753300687,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753300687,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ru0w3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BalorNG","can_mod_post":false,"created_utc":1753300306,"send_replies":true,"parent_id":"t1_n4rcoya","score":14,"author_fullname":"t2_b6gw9q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea, this was discussed here months ago, and frankly is a fairly old idea (layer sharing was suggested way before Gpt3)\\nhttps://www.reddit.com/r/LocalLLaMA/s/nOrqOh25al\\nNow add conventional MoE and we should have the most bang for a computational and RAM buck.\\n\\nI guess it was not that interesting for \\"large players\\" because this is more of an efficiency upgrade than \\"numbers go up on benchmarks\\" type of research, but with field getting ever more competitive \\"stack more layers, duh\\" paradigm is reaching its limits.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ru0w3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, this was discussed here months ago, and frankly is a fairly old idea (layer sharing was suggested way before Gpt3)\\n&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/s/nOrqOh25al\\"&gt;https://www.reddit.com/r/LocalLLaMA/s/nOrqOh25al&lt;/a&gt;\\nNow add conventional MoE and we should have the most bang for a computational and RAM buck.&lt;/p&gt;\\n\\n&lt;p&gt;I guess it was not that interesting for &amp;quot;large players&amp;quot; because this is more of an efficiency upgrade than &amp;quot;numbers go up on benchmarks&amp;quot; type of research, but with field getting ever more competitive &amp;quot;stack more layers, duh&amp;quot; paradigm is reaching its limits.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4ru0w3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753300306,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rcoya","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1753295412,"send_replies":true,"parent_id":"t3_1m7fwhl","score":43,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Excellent.  This looks like self-mixing with conventional transformers (using some layers multiple times, like an in-situ passthrough self-merge), but more scalable and with less potential for brain damage.  Hopefully this kicks my self-mixing work into the trashbin.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rcoya","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Excellent.  This looks like self-mixing with conventional transformers (using some layers multiple times, like an in-situ passthrough self-merge), but more scalable and with less potential for brain damage.  Hopefully this kicks my self-mixing work into the trashbin.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rcoya/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753295412,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":43}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4r5gmh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Technical-Love-8479","can_mod_post":false,"created_utc":1753293403,"send_replies":true,"parent_id":"t3_1m7fwhl","score":19,"author_fullname":"t2_th2ct5t8g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Blog : https://medium.com/data-science-in-your-pocket/googles-mixture-of-recursions-end-of-transformers-b8de0fe9c83b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4r5gmh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Blog : &lt;a href=\\"https://medium.com/data-science-in-your-pocket/googles-mixture-of-recursions-end-of-transformers-b8de0fe9c83b\\"&gt;https://medium.com/data-science-in-your-pocket/googles-mixture-of-recursions-end-of-transformers-b8de0fe9c83b&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4r5gmh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753293403,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4r5hfn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DinoAmino","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4r5dpg","score":10,"author_fullname":"t2_j1v7f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks 👍","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4r5hfn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks 👍&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4r5hfn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753293409,"author_flair_text":null,"treatment_tags":[],"created_utc":1753293409,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n4r5dpg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Technical-Love-8479","can_mod_post":false,"created_utc":1753293381,"send_replies":true,"parent_id":"t1_n4r4fdw","score":44,"author_fullname":"t2_th2ct5t8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://arxiv.org/abs/2507.10524","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4r5dpg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2507.10524\\"&gt;https://arxiv.org/abs/2507.10524&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4r5dpg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753293381,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":44}}],"before":null}},"user_reports":[],"saved":false,"id":"n4r4fdw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DinoAmino","can_mod_post":false,"created_utc":1753293121,"send_replies":true,"parent_id":"t3_1m7fwhl","score":44,"author_fullname":"t2_j1v7f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Screw YouTube. Link to paper?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4r4fdw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Screw YouTube. Link to paper?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4r4fdw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753293121,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":44}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4shws9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pedalnomica","can_mod_post":false,"created_utc":1753307105,"send_replies":true,"parent_id":"t3_1m7fwhl","score":3,"author_fullname":"t2_b0d7j6x9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cue Gemini getting much faster in 6 weeks and a bunch of posts wondering how they pull it off and lamenting that Deepmind doesn't share their research anymore.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4shws9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cue Gemini getting much faster in 6 weeks and a bunch of posts wondering how they pull it off and lamenting that Deepmind doesn&amp;#39;t share their research anymore.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4shws9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753307105,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rno2l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rgobm","score":2,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ASIC. Bam. Rockchip has had 50t/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rno2l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ASIC. Bam. Rockchip has had 50t/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rno2l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753298481,"author_flair_text":null,"treatment_tags":[],"created_utc":1753298481,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rgobm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_slay_nub","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4reg68","score":3,"author_fullname":"t2_u8o4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I get like 6 tokens/second for a 7B model on my S25, that might be good enough for r/localllama but not for the average user. I'm not sure on-device models will ever really take off. For high-end phones, the limitation is the compute, not the memory IMO.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4rgobm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I get like 6 tokens/second for a 7B model on my S25, that might be good enough for &lt;a href=\\"/r/localllama\\"&gt;r/localllama&lt;/a&gt; but not for the average user. I&amp;#39;m not sure on-device models will ever really take off. For high-end phones, the limitation is the compute, not the memory IMO.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rgobm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753296517,"author_flair_text":null,"treatment_tags":[],"created_utc":1753296517,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4reg68","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mnt_brain","can_mod_post":false,"created_utc":1753295899,"send_replies":true,"parent_id":"t1_n4ra80a","score":17,"author_fullname":"t2_1mtt9dytfn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"to be fair though- mobile is the ultimate frontier for these models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4reg68","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;to be fair though- mobile is the ultimate frontier for these models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4reg68/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753295899,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4sxnm5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sea-Rope-31","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sqkg3","score":1,"author_fullname":"t2_1sdssbj1gj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, my first reaction was \\"wait, didn't KAIST release something similar sounding recently?\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4sxnm5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, my first reaction was &amp;quot;wait, didn&amp;#39;t KAIST release something similar sounding recently?&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4sxnm5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753312088,"author_flair_text":null,"treatment_tags":[],"created_utc":1753312088,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sqkg3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cryocari","can_mod_post":false,"created_utc":1753309808,"send_replies":true,"parent_id":"t1_n4ra80a","score":2,"author_fullname":"t2_c8xp0mh4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Smaller models translate to cheaper inference.\\n\\nAnd also, this is from KAIST not deepmind but google has some co-authors on it, which means they likely did not come up with it but are interested.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sqkg3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Smaller models translate to cheaper inference.&lt;/p&gt;\\n\\n&lt;p&gt;And also, this is from KAIST not deepmind but google has some co-authors on it, which means they likely did not come up with it but are interested.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4sqkg3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753309808,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ra80a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_slay_nub","can_mod_post":false,"created_utc":1753294723,"send_replies":true,"parent_id":"t3_1m7fwhl","score":7,"author_fullname":"t2_u8o4d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It seems like it would be about the same performance for the same compute. Potentially good for local but not for the large companies","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ra80a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems like it would be about the same performance for the same compute. Potentially good for local but not for the large companies&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4ra80a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753294723,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ro147","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LetterRip","can_mod_post":false,"created_utc":1753298584,"send_replies":true,"parent_id":"t3_1m7fwhl","score":4,"author_fullname":"t2_3zb81","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This was only used for toy models, the biggest was 1.7B.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ro147","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was only used for toy models, the biggest was 1.7B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4ro147/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753298584,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4siv9u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeProgrammer99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4s0mje","score":2,"author_fullname":"t2_w4j8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And now there's ATLAS. [https://arxiv.org/abs/2505.23735](https://arxiv.org/abs/2505.23735)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4siv9u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And now there&amp;#39;s ATLAS. &lt;a href=\\"https://arxiv.org/abs/2505.23735\\"&gt;https://arxiv.org/abs/2505.23735&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4siv9u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753307398,"author_flair_text":null,"treatment_tags":[],"created_utc":1753307398,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4s0mje","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dapper_Extent_7474","can_mod_post":false,"created_utc":1753302149,"send_replies":true,"parent_id":"t1_n4rr9uf","score":2,"author_fullname":"t2_1pxvlldm8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lucidrains made it into an actual library but I'm not sure anyone has actually trained it yet.\\n\\n[https://github.com/lucidrains/titans-pytorch](https://github.com/lucidrains/titans-pytorch)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4s0mje","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lucidrains made it into an actual library but I&amp;#39;m not sure anyone has actually trained it yet.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/lucidrains/titans-pytorch\\"&gt;https://github.com/lucidrains/titans-pytorch&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4s0mje/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753302149,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rr9uf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sudden-Lingonberry-8","can_mod_post":false,"created_utc":1753299517,"send_replies":true,"parent_id":"t3_1m7fwhl","score":3,"author_fullname":"t2_7j2k5hlp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"whatever happened to the titans architecture google released... nothing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rr9uf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;whatever happened to the titans architecture google released... nothing?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rr9uf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299517,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4sjn3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"twnznz","can_mod_post":false,"created_utc":1753307637,"send_replies":true,"parent_id":"t3_1m7fwhl","score":1,"author_fullname":"t2_z2ziv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Help me understand this, is this like thinking but without having to traverse all the way out to the output layer and back in via the tokeniser?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sjn3z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Help me understand this, is this like thinking but without having to traverse all the way out to the output layer and back in via the tokeniser?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4sjn3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753307637,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4srqji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"strangescript","can_mod_post":false,"created_utc":1753310188,"send_replies":true,"parent_id":"t3_1m7fwhl","score":1,"author_fullname":"t2_z1qi0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Torch doesn't support true token dropout which means you are either writing a ton of custom code or you aren't getting the performance gains","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4srqji","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Torch doesn&amp;#39;t support true token dropout which means you are either writing a ton of custom code or you aren&amp;#39;t getting the performance gains&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4srqji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753310188,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4s1zky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Efficiency_1144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rvx45","score":1,"author_fullname":"t2_1nkj9l14b0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Okay yeah I was just noticing a pattern","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4s1zky","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay yeah I was just noticing a pattern&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4s1zky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753302525,"author_flair_text":null,"treatment_tags":[],"created_utc":1753302525,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rvx45","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hapliniste","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rtpz1","score":2,"author_fullname":"t2_fc7rd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not saying it's my idea, but that I had a similar one.\\n\\nAlso I read part of it and I don't think it's like what I had in mind after all.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4rvx45","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not saying it&amp;#39;s my idea, but that I had a similar one.&lt;/p&gt;\\n\\n&lt;p&gt;Also I read part of it and I don&amp;#39;t think it&amp;#39;s like what I had in mind after all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rvx45/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753300836,"author_flair_text":null,"treatment_tags":[],"created_utc":1753300836,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rtpz1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Efficiency_1144","can_mod_post":false,"created_utc":1753300222,"send_replies":true,"parent_id":"t1_n4r9tz0","score":2,"author_fullname":"t2_1nkj9l14b0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This happened yesterday with the hierarchical RNN paper, someone said it was their idea.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rtpz1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This happened yesterday with the hierarchical RNN paper, someone said it was their idea.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7fwhl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rtpz1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753300222,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4r9tz0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"hapliniste","can_mod_post":false,"created_utc":1753294613,"send_replies":true,"parent_id":"t3_1m7fwhl","score":-7,"author_fullname":"t2_fc7rd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Damn I did not read it yet but it looks like my pool of expert idea.\\n\\nI've been convinced this is the holy grail for years now. Maybe we're already in the end game.\\n\\n4B ASI when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4r9tz0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn I did not read it yet but it looks like my pool of expert idea.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been convinced this is the holy grail for years now. Maybe we&amp;#39;re already in the end game.&lt;/p&gt;\\n\\n&lt;p&gt;4B ASI when?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4r9tz0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753294613,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rdx0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"created_utc":1753295753,"send_replies":true,"parent_id":"t3_1m7fwhl","score":0,"author_fullname":"t2_qjpsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"is there a research paper link?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rdx0z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;is there a research paper link?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7fwhl/google_deepmind_release_mixtureofrecursions/n4rdx0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753295753,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7fwhl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
