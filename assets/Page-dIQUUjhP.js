import{j as l}from"./index-BQFNqx_J.js";import{R as e}from"./RedditPostRenderer-BkLorFru.js";import"./index-BGD6HmIH.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello, I am looking for &lt;= 4B coding models. I realize that none of these will be practical for now just looking for some to do experiments.\\n\\nHere is what i found so far:\\n\\r- Menlo / Jan-nano — 4.02 B (Not really coding but I expect it to be better than others)\\r\\n- Gemma — 4 B / 2 B\\r\\n- Qwen 3 — 4 B / 0.6 B\\r- Phi-4 Mini — 3.8 B\\r- Phi-3.5 Mini — 3.5 B\\r- Llama-3.2 — 3.2 B\\r- Starcoder — 3 B / 1 B\\r- Starcoder 2 — 3 B\\r- Stable-Code — 3 B\\r- Granite — 3 B / 2.53 B\\r- Cogito — 3 B\\r- DeepSeek Coder — 2.6 B / 1.3 B\\r- DeepSeek R1 Distill (Qwen-tuned) — 1.78 B\\r- Qwen 2.5 — 1.5 B / 0.5 B\\r- Yi-Coder — 1.5 B\\r- Deepscaler — 1.5 B\\r- Deepcoder — 1.5 B\\r- CodeGen2 — 1 B\\r- BitNet-B1.58 — 0.85 B\\r- ERNIE-4.5 — 0.36 B\\n\\nHas anyone tried any of these or compared &lt;= 4B models on coding tasks? \\n\\n\\r\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What is the current best local coding model with &lt;= 4B parameters?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lo5vnf","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.78,"author_flair_background_color":null,"subreddit_type":"public","ups":32,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1g2h9wsp6m","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":32,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751285432,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello, I am looking for &amp;lt;= 4B coding models. I realize that none of these will be practical for now just looking for some to do experiments.&lt;/p&gt;\\n\\n&lt;p&gt;Here is what i found so far:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Menlo / Jan-nano — 4.02 B (Not really coding but I expect it to be better than others)&lt;/li&gt;\\n&lt;li&gt;Gemma — 4 B / 2 B&lt;/li&gt;\\n&lt;li&gt;Qwen 3 — 4 B / 0.6 B&lt;/li&gt;\\n&lt;li&gt;Phi-4 Mini — 3.8 B&lt;/li&gt;\\n&lt;li&gt;Phi-3.5 Mini — 3.5 B&lt;/li&gt;\\n&lt;li&gt;Llama-3.2 — 3.2 B&lt;/li&gt;\\n&lt;li&gt;Starcoder — 3 B / 1 B&lt;/li&gt;\\n&lt;li&gt;Starcoder 2 — 3 B&lt;/li&gt;\\n&lt;li&gt;Stable-Code — 3 B&lt;/li&gt;\\n&lt;li&gt;Granite — 3 B / 2.53 B&lt;/li&gt;\\n&lt;li&gt;Cogito — 3 B&lt;/li&gt;\\n&lt;li&gt;DeepSeek Coder — 2.6 B / 1.3 B&lt;/li&gt;\\n&lt;li&gt;DeepSeek R1 Distill (Qwen-tuned) — 1.78 B&lt;/li&gt;\\n&lt;li&gt;Qwen 2.5 — 1.5 B / 0.5 B&lt;/li&gt;\\n&lt;li&gt;Yi-Coder — 1.5 B&lt;/li&gt;\\n&lt;li&gt;Deepscaler — 1.5 B&lt;/li&gt;\\n&lt;li&gt;Deepcoder — 1.5 B&lt;/li&gt;\\n&lt;li&gt;CodeGen2 — 1 B&lt;/li&gt;\\n&lt;li&gt;BitNet-B1.58 — 0.85 B&lt;/li&gt;\\n&lt;li&gt;ERNIE-4.5 — 0.36 B&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Has anyone tried any of these or compared &amp;lt;= 4B models on coding tasks? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lo5vnf","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Wooden-Key751","discussion_type":null,"num_comments":54,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/","subreddit_subscribers":493243,"created_utc":1751285432,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kheo8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fdg_avid","can_mod_post":false,"created_utc":1751287655,"send_replies":true,"parent_id":"t3_1lo5vnf","score":62,"author_fullname":"t2_7vr0myfd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen2.5-Coder-3B-Instruct","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kheo8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen2.5-Coder-3B-Instruct&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kheo8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751287655,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":62}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0plzri","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nyghtbynger","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0n3bm5","score":2,"author_fullname":"t2_p3x56ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm okay as long as the differentiator is model size vs open/closed source","edited":false,"author_flair_css_class":null,"name":"t1_n0plzri","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m okay as long as the differentiator is model size vs open/closed source&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lo5vnf","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0plzri/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347916,"author_flair_text":null,"collapsed":false,"created_utc":1751347916,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0n3bm5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IrisColt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l7ewp","score":5,"author_fullname":"t2_c2f558x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;I've stopped using local models for coding some time ago.\\n\\n\\nSad but true. :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0n3bm5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I&amp;#39;ve stopped using local models for coding some time ago.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Sad but true. :(&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0n3bm5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751315488,"author_flair_text":null,"treatment_tags":[],"created_utc":1751315488,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n0l7ewp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MokoshHydro","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":22,"author_fullname":"t2_vtgj4az4a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You should test personally. That depends on your expectations. I've stopped using local models for coding some time ago.\\n\\nBut I won’t even consider anything smaller than 14B.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0l7ewp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should test personally. That depends on your expectations. I&amp;#39;ve stopped using local models for coding some time ago.&lt;/p&gt;\\n\\n&lt;p&gt;But I won’t even consider anything smaller than 14B.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l7ewp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296016,"author_flair_text":null,"treatment_tags":[],"created_utc":1751296016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lst91","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"giantsparklerobot","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":5,"author_fullname":"t2_47gyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The number of parameters is a sort of rough approximation of a model's \\"knowledge\\". Embeddings are sort of magical but not *that* magical about encoding the training set. A dense model with fewer than 4B parameters isn't likely to \\"know\\" enough to be really helpful for coding. It might be able to spit code that sometimes works but it often won't have the breadth to actually be universally usable. I've personally only found the &gt;10B models to be stable/reliable for coding questions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0lst91","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The number of parameters is a sort of rough approximation of a model&amp;#39;s &amp;quot;knowledge&amp;quot;. Embeddings are sort of magical but not &lt;em&gt;that&lt;/em&gt; magical about encoding the training set. A dense model with fewer than 4B parameters isn&amp;#39;t likely to &amp;quot;know&amp;quot; enough to be really helpful for coding. It might be able to spit code that sometimes works but it often won&amp;#39;t have the breadth to actually be universally usable. I&amp;#39;ve personally only found the &amp;gt;10B models to be stable/reliable for coding questions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lst91/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751302207,"author_flair_text":null,"treatment_tags":[],"created_utc":1751302207,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m8648","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Orolol","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":2,"author_fullname":"t2_fbzx9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It all depends on your use case. With coding, there seems to exist no shortcuts, the bigger the model, the better the results. As it's my job, I use Claude 4 Opus. Anything smaller doesn't make sense to.me, as I just want the best of the best. \\n\\nTo chat, I can use smaller models, because I don't chase absolute performance.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0m8648","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It all depends on your use case. With coding, there seems to exist no shortcuts, the bigger the model, the better the results. As it&amp;#39;s my job, I use Claude 4 Opus. Anything smaller doesn&amp;#39;t make sense to.me, as I just want the best of the best. &lt;/p&gt;\\n\\n&lt;p&gt;To chat, I can use smaller models, because I don&amp;#39;t chase absolute performance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0m8648/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306415,"author_flair_text":null,"treatment_tags":[],"created_utc":1751306415,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lrzon","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"im_not_here_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0lgri7","score":5,"author_fullname":"t2_9l428","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It depends what you want from it. I ask and do occasional small bits of asking questions on code here and there. But I am not making full vibe coding, or otherwise, projects or anything remotely like that with them.\\n\\nIt's been correct probably more like at least 85% of the time for that use case maybe a bit more, using more along the lines of 14b. \\n\\nCurrently got some ok results from those questions from 30b qwen 3, which I have in RAM as I don't have a usable gpu (6bg free doesn't get you much), but I haven't used it much yet to really know.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lrzon","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It depends what you want from it. I ask and do occasional small bits of asking questions on code here and there. But I am not making full vibe coding, or otherwise, projects or anything remotely like that with them.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s been correct probably more like at least 85% of the time for that use case maybe a bit more, using more along the lines of 14b. &lt;/p&gt;\\n\\n&lt;p&gt;Currently got some ok results from those questions from 30b qwen 3, which I have in RAM as I don&amp;#39;t have a usable gpu (6bg free doesn&amp;#39;t get you much), but I haven&amp;#39;t used it much yet to really know.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lrzon/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751301971,"author_flair_text":null,"treatment_tags":[],"created_utc":1751301971,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n0lgri7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"krileon","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":2,"author_fullname":"t2_7eurf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nothing you can run without spending $100,000+ on hardware, lol. Lets be real for coding the local modals don't come even close to cloud. If you like it being maybe right 20-30% of the time then go for it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0lgri7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nothing you can run without spending $100,000+ on hardware, lol. Lets be real for coding the local modals don&amp;#39;t come even close to cloud. If you like it being maybe right 20-30% of the time then go for it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lgri7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751298735,"author_flair_text":null,"treatment_tags":[],"created_utc":1751298735,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pcolh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Foreign-Beginning-49","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0mvzyv","score":1,"author_fullname":"t2_83u2l6o4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I will second devstral, just started using it with kilo code and agentic coding has blown my mind.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pcolh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will second devstral, just started using it with kilo code and agentic coding has blown my mind.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0pcolh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751343451,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751343451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0mvzyv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MrPrivateObservation","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":1,"author_fullname":"t2_42wlymjd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"32b is good enough for most my usecases and has good varity of models (codestral, devstral, qwen2.5coder, GLM)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0mvzyv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;32b is good enough for most my usecases and has good varity of models (codestral, devstral, qwen2.5coder, GLM)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0mvzyv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751313344,"author_flair_text":null,"treatment_tags":[],"created_utc":1751313344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m6swk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l34qj","score":-1,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It doesn't really work like that...  They get better as they get bigger but that manifests as the scope of problems they can solve and how frequently they do so adequately.  A 4B model is kind of like a monkey banging on a keyboard - it might eventually get it right with enough tries, but do want to deal with that?  Maybe!\\n\\nIMHO even the frontier cloud models are pretty meh on raw development so like... No size? ;)  But I find the Qwen ~30B models (QwQ, Qwen3 32B, Qwen3 30A3, Qwen2.5 coder, etc) to be adequate for refactors, review, small tasks, tests, etc.  They run fast on a 24GB GPU so definitely provide solid bang-for-buck.  I do offload some stuff on DS V3 / R1 sometimes but those are slow so somewhat situational.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0m6swk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t really work like that...  They get better as they get bigger but that manifests as the scope of problems they can solve and how frequently they do so adequately.  A 4B model is kind of like a monkey banging on a keyboard - it might eventually get it right with enough tries, but do want to deal with that?  Maybe!&lt;/p&gt;\\n\\n&lt;p&gt;IMHO even the frontier cloud models are pretty meh on raw development so like... No size? ;)  But I find the Qwen ~30B models (QwQ, Qwen3 32B, Qwen3 30A3, Qwen2.5 coder, etc) to be adequate for refactors, review, small tasks, tests, etc.  They run fast on a 24GB GPU so definitely provide solid bang-for-buck.  I do offload some stuff on DS V3 / R1 sometimes but those are slow so somewhat situational.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0m6swk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306040,"author_flair_text":null,"treatment_tags":[],"created_utc":1751306040,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0l34qj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AuspiciousApple","can_mod_post":false,"created_utc":1751294760,"send_replies":true,"parent_id":"t1_n0kg35b","score":2,"author_fullname":"t2_bndbg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's the minimum viable size?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0l34qj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s the minimum viable size?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l34qj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751294760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0q81be","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"manu_ovg","can_mod_post":false,"created_utc":1751360676,"send_replies":true,"parent_id":"t1_n0kg35b","score":1,"author_fullname":"t2_swjxu7bje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For autocompletion it'll work great","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0q81be","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For autocompletion it&amp;#39;ll work great&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0q81be/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751360676,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0l391l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AuspiciousApple","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kxe8m","score":3,"author_fullname":"t2_bndbg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, the post title is very clearly asking for optimality.","edited":false,"author_flair_css_class":null,"name":"t1_n0l391l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, the post title is very clearly asking for optimality.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lo5vnf","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l391l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751294797,"author_flair_text":null,"collapsed":false,"created_utc":1751294797,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kxe8m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Gregory-Wolf","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kudhf","score":19,"author_fullname":"t2_gethr3mh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"literally says \\"best\\", not \\"good\\". so technically nobody asked for a \\"good coding model\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kxe8m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;literally says &amp;quot;best&amp;quot;, not &amp;quot;good&amp;quot;. so technically nobody asked for a &amp;quot;good coding model&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kxe8m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751293025,"author_flair_text":null,"treatment_tags":[],"created_utc":1751293025,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lpwd7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EffervescentFacade","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0lim2s","score":1,"author_fullname":"t2_3f0wcqwt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ya know,  I hate my autism until I read such sound principles as this.","edited":false,"author_flair_css_class":null,"name":"t1_n0lpwd7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ya know,  I hate my autism until I read such sound principles as this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lo5vnf","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lpwd7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751301365,"author_flair_text":null,"collapsed":false,"created_utc":1751301365,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0lim2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Available_Load_5334","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kudhf","score":0,"author_fullname":"t2_oxguhk8bl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yes, look again. he's asking for the best model within specific parameters, not a good model. imo there is no good mcdonalds burger but if i ate all, one would emerge as the best, still bad but the best mcd has to offer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lim2s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, look again. he&amp;#39;s asking for the best model within specific parameters, not a good model. imo there is no good mcdonalds burger but if i ate all, one would emerge as the best, still bad but the best mcd has to offer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lim2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751299260,"author_flair_text":null,"treatment_tags":[],"created_utc":1751299260,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kudhf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"busylivin_322","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kpbds","score":15,"author_fullname":"t2_7dke2mrk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&lt;looks at post title&gt;","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0kudhf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;lt;looks at post title&amp;gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kudhf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751292076,"author_flair_text":null,"treatment_tags":[],"created_utc":1751292076,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kpbds","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Available_Load_5334","can_mod_post":false,"created_utc":1751290450,"send_replies":true,"parent_id":"t1_n0kg35b","score":-13,"author_fullname":"t2_oxguhk8bl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nobody asked for a good coding model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kpbds","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nobody asked for a good coding model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kpbds/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751290450,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-13}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kg35b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MokoshHydro","can_mod_post":false,"created_utc":1751287156,"send_replies":true,"parent_id":"t3_1lo5vnf","score":68,"author_fullname":"t2_vtgj4az4a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There is no good \\"coding model\\" at this size.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kg35b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is no good &amp;quot;coding model&amp;quot; at this size.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kg35b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751287156,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":68}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lan62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Key751","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kv7uz","score":2,"author_fullname":"t2_1g2h9wsp6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Right, for people who are also looking the interesting ones i found are Tiny StarCoder Python, Qwen2.5 Coder, Replit Code v1.5 3B and InCoder 1B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lan62","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right, for people who are also looking the interesting ones i found are Tiny StarCoder Python, Qwen2.5 Coder, Replit Code v1.5 3B and InCoder 1B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lan62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296958,"author_flair_text":null,"treatment_tags":[],"created_utc":1751296958,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kv7uz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Gregory-Wolf","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0krvx9","score":9,"author_fullname":"t2_gethr3mh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"then you can safely ignore suggestions about tool calling capabilities.  \\nmost models are somewhat coding-capable. but for good autocompletion you need a model with FIM training, not just coding. I guess Qwen2.5-coder (as already suggested) is the best bet. though in my experience it kind of sucks in chat (I had repetition problems even with 7B model, so smaller model will be even less stable).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0kv7uz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;then you can safely ignore suggestions about tool calling capabilities.&lt;br/&gt;\\nmost models are somewhat coding-capable. but for good autocompletion you need a model with FIM training, not just coding. I guess Qwen2.5-coder (as already suggested) is the best bet. though in my experience it kind of sucks in chat (I had repetition problems even with 7B model, so smaller model will be even less stable).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kv7uz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751292343,"author_flair_text":null,"treatment_tags":[],"created_utc":1751292343,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n0krvx9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Key751","can_mod_post":false,"created_utc":1751291298,"send_replies":true,"parent_id":"t1_n0krg26","score":2,"author_fullname":"t2_1g2h9wsp6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was thinking of something where code is provided in context with the prompt and a task is given so it’s less agentic and more something in between autocomplete and chat","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0krvx9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was thinking of something where code is provided in context with the prompt and a task is given so it’s less agentic and more something in between autocomplete and chat&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0krvx9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751291298,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0krg26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Gregory-Wolf","can_mod_post":false,"created_utc":1751291158,"send_replies":true,"parent_id":"t3_1lo5vnf","score":9,"author_fullname":"t2_gethr3mh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"coding as in autocomplete? agentic? or just \\"code me a bubble sort function\\" in chat?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0krg26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;coding as in autocomplete? agentic? or just &amp;quot;code me a bubble sort function&amp;quot; in chat?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0krg26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751291158,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0l878y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0khxk4","score":2,"author_fullname":"t2_86dk0gye","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cant wait to use it!! yay","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0l878y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cant wait to use it!! yay&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l878y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296247,"author_flair_text":null,"treatment_tags":[],"created_utc":1751296247,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0khxk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loyalekoinu88","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kgzaq","score":6,"author_fullname":"t2_1x5p0ubz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Alibaba is gonna drop qwen3 coder soon. I’m gonna guess that’ll be the best for a while since their existing coder is still largely used by folks.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0khxk4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Alibaba is gonna drop qwen3 coder soon. I’m gonna guess that’ll be the best for a while since their existing coder is still largely used by folks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0khxk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751287850,"author_flair_text":null,"treatment_tags":[],"created_utc":1751287850,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kgzaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Voxandr","can_mod_post":false,"created_utc":1751287494,"send_replies":true,"parent_id":"t1_n0kcsjj","score":7,"author_fullname":"t2_86dk0gye","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tried with Cline , its really bad at coding - and it just does wrong tool calls and cannot use edits well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kgzaq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried with Cline , its really bad at coding - and it just does wrong tool calls and cannot use edits well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kgzaq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751287494,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kcsjj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loyalekoinu88","can_mod_post":false,"created_utc":1751285868,"send_replies":true,"parent_id":"t3_1lo5vnf","score":13,"author_fullname":"t2_1x5p0ubz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jan-Nano is just a specialty QWEN3 4B model.\\n\\nMy best guess would be to use ones specifically trained on coding since that isn’t a lot of parameters for general models. I’d also imagine coding models that have good tool use would be best since you can pull in more coding context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kcsjj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan-Nano is just a specialty QWEN3 4B model.&lt;/p&gt;\\n\\n&lt;p&gt;My best guess would be to use ones specifically trained on coding since that isn’t a lot of parameters for general models. I’d also imagine coding models that have good tool use would be best since you can pull in more coding context.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kcsjj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751285868,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0l5bfw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Key751","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l2o3c","score":3,"author_fullname":"t2_1g2h9wsp6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Had a similar experience performed poorer both in terms of speed and quality than qwen3","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0l5bfw","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Had a similar experience performed poorer both in terms of speed and quality than qwen3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l5bfw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751295404,"author_flair_text":null,"treatment_tags":[],"created_utc":1751295404,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0l2o3c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jedisct1","can_mod_post":false,"created_utc":1751294623,"send_replies":true,"parent_id":"t1_n0ksibi","score":3,"author_fullname":"t2_7p6tw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tried it; it's terrible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0l2o3c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried it; it&amp;#39;s terrible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0l2o3c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751294623,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ktw2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Key751","can_mod_post":false,"created_utc":1751291925,"send_replies":true,"parent_id":"t1_n0ksibi","score":2,"author_fullname":"t2_1g2h9wsp6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I did some basic tests with gemma3n. I wasn’t sure on including it in the list because i don’t think it classifies as a 4b model even though it technically is with it’s partial execution. It was failing/crashing on my setup even though qwen:4b was running fine","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ktw2t","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did some basic tests with gemma3n. I wasn’t sure on including it in the list because i don’t think it classifies as a 4b model even though it technically is with it’s partial execution. It was failing/crashing on my setup even though qwen:4b was running fine&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0ktw2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751291925,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ksibi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"1ncehost","can_mod_post":false,"created_utc":1751291496,"send_replies":true,"parent_id":"t3_1lo5vnf","score":3,"author_fullname":"t2_lrannsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3n seems fairly coherent. I'd give it a shot in your testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ksibi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3n seems fairly coherent. I&amp;#39;d give it a shot in your testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0ksibi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751291496,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m9e0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emprahsFury","can_mod_post":false,"created_utc":1751306759,"send_replies":false,"parent_id":"t3_1lo5vnf","score":2,"author_fullname":"t2_177r8n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jetbrains just released mellum on Hf, it's a 4b fim coding llm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m9e0j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jetbrains just released mellum on Hf, it&amp;#39;s a 4b fim coding llm.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0m9e0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306759,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":4,"removal_reason":null,"link_id":"t3_1lo5vnf","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lfr84","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slowhill369","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0la6oa","score":2,"author_fullname":"t2_96zelxcg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have nothing against it, but it is what it is: an MCP validator. And the creator needs to market it as such rather than pretending like it’s the next Siri. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0lfr84","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have nothing against it, but it is what it is: an MCP validator. And the creator needs to market it as such rather than pretending like it’s the next Siri. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lfr84/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751298447,"author_flair_text":null,"treatment_tags":[],"created_utc":1751298447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0la6oa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"created_utc":1751296826,"send_replies":true,"parent_id":"t1_n0kp5cc","score":2,"author_fullname":"t2_86dk0gye","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"and it is failing hard at multi-turn agent-to-agent ochestrations based tool callings. Really bad results.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0la6oa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;and it is failing hard at multi-turn agent-to-agent ochestrations based tool callings. Really bad results.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0la6oa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296826,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lab32","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kvtc4","score":2,"author_fullname":"t2_86dk0gye","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"if you had tested you would see it doesn't do anything they claim to do.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0lab32","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if you had tested you would see it doesn&amp;#39;t do anything they claim to do.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lab32/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296861,"author_flair_text":null,"treatment_tags":[],"created_utc":1751296861,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kx00m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Final_Wheel_7486","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kwlir","score":2,"author_fullname":"t2_cyrs5dhp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah okay I get what you mean. Fair","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kx00m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah okay I get what you mean. Fair&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kx00m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751292903,"author_flair_text":null,"treatment_tags":[],"created_utc":1751292903,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kwlir","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slowhill369","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0kvtc4","score":2,"author_fullname":"t2_96zelxcg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen is good at tool calling. Jan is good at focusing that ability. I’m just saying… it’s a feature, not a true standalone model like the rest. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0kwlir","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen is good at tool calling. Jan is good at focusing that ability. I’m just saying… it’s a feature, not a true standalone model like the rest. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kwlir/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751292779,"author_flair_text":null,"treatment_tags":[],"created_utc":1751292779,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kvtc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Final_Wheel_7486","can_mod_post":false,"created_utc":1751292532,"send_replies":true,"parent_id":"t1_n0kp5cc","score":3,"author_fullname":"t2_cyrs5dhp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's specifically good at tool calling, what's so wrong about listing it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kvtc4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s specifically good at tool calling, what&amp;#39;s so wrong about listing it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kvtc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751292532,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ldtes","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"created_utc":1751297884,"send_replies":true,"parent_id":"t1_n0kp5cc","score":1,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is jan nano free and local?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ldtes","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is jan nano free and local?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0ldtes/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751297884,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qt32u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slowhill369","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qa7f1","score":1,"author_fullname":"t2_96zelxcg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I respect you for saying something. My apologies for stepping on your work. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qt32u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I respect you for saying something. My apologies for stepping on your work. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0qt32u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751371359,"author_flair_text":null,"treatment_tags":[],"created_utc":1751371359,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qa7f1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eck72","can_mod_post":false,"created_utc":1751361984,"send_replies":true,"parent_id":"t1_n0kp5cc","score":1,"author_fullname":"t2_g6cmmsdd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, Emre here from the Jan (Menlo) team.\\n\\nJust to clarify up front, this post wasn't made by us. If and when we post, we always identify ourselves clearly. We don't do astroturfing, stealth marketing, or anything like that, and we've already made sure the whole team understands that after last week's confusion.\\n\\nAs for Jan-nano, it's definitely not a coding model. It's trained for search, especially retrieval and long-context question answering. Tool use and agentic behavior are still in progress. \\n\\nTo be honest, we probably over-emphasized MCP too early in our last post, that's on us.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qa7f1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, Emre here from the Jan (Menlo) team.&lt;/p&gt;\\n\\n&lt;p&gt;Just to clarify up front, this post wasn&amp;#39;t made by us. If and when we post, we always identify ourselves clearly. We don&amp;#39;t do astroturfing, stealth marketing, or anything like that, and we&amp;#39;ve already made sure the whole team understands that after last week&amp;#39;s confusion.&lt;/p&gt;\\n\\n&lt;p&gt;As for Jan-nano, it&amp;#39;s definitely not a coding model. It&amp;#39;s trained for search, especially retrieval and long-context question answering. Tool use and agentic behavior are still in progress. &lt;/p&gt;\\n\\n&lt;p&gt;To be honest, we probably over-emphasized MCP too early in our last post, that&amp;#39;s on us.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0qa7f1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751361984,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qgt3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Key751","can_mod_post":false,"created_utc":1751365703,"send_replies":true,"parent_id":"t1_n0kp5cc","score":1,"author_fullname":"t2_1g2h9wsp6m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can assure you i am not a part of Big Jan-Nano","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qgt3g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can assure you i am not a part of Big Jan-Nano&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0qgt3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751365703,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kp5cc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1lo5vnf","score":4,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kp5cc/","num_reports":null,"locked":false,"name":"t1_n0kp5cc","created":1751290391,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751290391,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lu187","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ilintar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0lagf8","score":1,"author_fullname":"t2_cctud","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"More chatty and much stronger.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0lu187","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More chatty and much stronger.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lu187/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751302553,"author_flair_text":null,"treatment_tags":[],"created_utc":1751302553,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0lagf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"created_utc":1751296904,"send_replies":true,"parent_id":"t1_n0kp4va","score":1,"author_fullname":"t2_86dk0gye","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what it does? any good points vs qwen ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lagf8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what it does? any good points vs qwen ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lagf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751296904,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0n28n1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ilintar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0mqqu4","score":1,"author_fullname":"t2_cctud","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Talking from personal experience, I plugged it in Roo Code and it actually worked (a 4B model). It's really great. Make sure to heed generation settings tho, they're pretty unconventional 😀","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0n28n1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Talking from personal experience, I plugged it in Roo Code and it actually worked (a 4B model). It&amp;#39;s really great. Make sure to heed generation settings tho, they&amp;#39;re pretty unconventional 😀&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0n28n1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751315176,"author_flair_text":null,"treatment_tags":[],"created_utc":1751315176,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0mqqu4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751311775,"send_replies":true,"parent_id":"t1_n0kp4va","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Did you try it? It seems to be purely Math model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0mqqu4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did you try it? It seems to be purely Math model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo5vnf","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0mqqu4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751311775,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0kp4va","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ilintar","can_mod_post":false,"created_utc":1751290387,"send_replies":true,"parent_id":"t3_1lo5vnf","score":1,"author_fullname":"t2_cctud","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Definitely Polaris 4B.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kp4va","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely Polaris 4B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kp4va/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751290387,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kzwam","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poita66","can_mod_post":false,"created_utc":1751293791,"send_replies":true,"parent_id":"t3_1lo5vnf","score":1,"author_fullname":"t2_hbp5l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’ve been playing with Qwen 2.5 coder 3b (base) for autocomplete with llama.vscode (as it’s one of their suggested models). It works ok. For actual coding you really need something like Devstral (but that’s 24b) or bigger. Qwen 3 30b a3b might work for you as it’s only 3b active with the rest MoE (if I understand correctly)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kzwam","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve been playing with Qwen 2.5 coder 3b (base) for autocomplete with llama.vscode (as it’s one of their suggested models). It works ok. For actual coding you really need something like Devstral (but that’s 24b) or bigger. Qwen 3 30b a3b might work for you as it’s only 3b active with the rest MoE (if I understand correctly)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0kzwam/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751293791,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lw1bx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Strong_Hurry6781","can_mod_post":false,"created_utc":1751303109,"send_replies":true,"parent_id":"t3_1lo5vnf","score":1,"author_fullname":"t2_1lgaixr0nm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone explain to me please what is he asking and what are all of these parameters? I m just starting out and I would like to know more about this field","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lw1bx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone explain to me please what is he asking and what are all of these parameters? I m just starting out and I would like to know more about this field&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0lw1bx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751303109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0oslpp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dangerous_Fix_5526","can_mod_post":false,"created_utc":1751335608,"send_replies":true,"parent_id":"t3_1lo5vnf","score":1,"author_fullname":"t2_uhummsau","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The issue with these smaller models: Instruction following, then knowledge.   \\n  \\nTry clarifying your instructions and /or breaking the problem down more (single block of code per \\"prompt\\") then see how that goes. \\n\\nModels this size will not get some more nuanced requirements either - again, clarify it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0oslpp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The issue with these smaller models: Instruction following, then knowledge.   &lt;/p&gt;\\n\\n&lt;p&gt;Try clarifying your instructions and /or breaking the problem down more (single block of code per &amp;quot;prompt&amp;quot;) then see how that goes. &lt;/p&gt;\\n\\n&lt;p&gt;Models this size will not get some more nuanced requirements either - again, clarify it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0oslpp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751335608,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ke9bs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ProfessionalAd8199","can_mod_post":false,"created_utc":1751286451,"send_replies":true,"parent_id":"t3_1lo5vnf","score":0,"author_fullname":"t2_7v1k34wy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Either of what you choose it should support tool calling. starcoder and deepseek coder were the ones i liked the most.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ke9bs","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Either of what you choose it should support tool calling. starcoder and deepseek coder were the ones i liked the most.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/n0ke9bs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751286451,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1lo5vnf","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>l.jsx(e,{data:t});export{n as default};
