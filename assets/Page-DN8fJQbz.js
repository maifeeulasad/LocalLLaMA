import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"EXAONE 4.0 32B","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1m04a20","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"ups":249,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1fc9cbovwe","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":249,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=8a97b0e14968bf021760fe24b232086843a6916d","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752541575,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"huggingface.co","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?auto=webp&amp;s=21346c43501458b33bb875a62eb15906b79b28b2","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=01c7ab98318dec8e4dfb9ad444e48cb42d1afee0","width":108,"height":58},{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3ab4d919ac27b9f67137eb710ebbcd8ffae7191","width":216,"height":116},{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e17ff014e394f7eaa73049e5608695028dc583e","width":320,"height":172},{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=18202842c69b787ccdb604277c8c0ce21247e4d3","width":640,"height":345},{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3d99f4430cca13dd301692b895103c848c110e72","width":960,"height":518},{"url":"https://external-preview.redd.it/8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=92fd7f637d351ce6963b08dd9b62b92904ecbc6d","width":1080,"height":583}],"variants":{},"id":"8nr2BOfjyJy107kRprOzRDlPGzQeiMZ1zJzNkF1pk6I"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1m04a20","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"minpeter2","discussion_type":null,"num_comments":81,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/","stickied":false,"url":"https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B","subreddit_subscribers":499294,"created_utc":1752541575,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36th54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"panchovix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ruzt","score":30,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\+1 to this. Supposedly Ernie 300B, or Qwen 235B are both supposedly better than R1 0528 and V3 0324.\\n\\nIn reality I still prefer V3 0324 above those 2 (testing all of the models of course, Q8 235B, Q5\\\\_K 300B and IQ4\\\\_XS 685B of DeepSeek).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36th54","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;+1 to this. Supposedly Ernie 300B, or Qwen 235B are both supposedly better than R1 0528 and V3 0324.&lt;/p&gt;\\n\\n&lt;p&gt;In reality I still prefer V3 0324 above those 2 (testing all of the models of course, Q8 235B, Q5_K 300B and IQ4_XS 685B of DeepSeek).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36th54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752545022,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1752545022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38gwm1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MINIMAN10001","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ruzt","score":1,"author_fullname":"t2_15mrcb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The answer is never and the older a benchmark is the less reliable it seems to become. \\n\\n\\nHowever for people not running the models and creating there judgement or otherwise posting to Reddit their experiences most people have nothing else to go on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38gwm1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The answer is never and the older a benchmark is the less reliable it seems to become. &lt;/p&gt;\\n\\n&lt;p&gt;However for people not running the models and creating there judgement or otherwise posting to Reddit their experiences most people have nothing else to go on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38gwm1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752573953,"author_flair_text":null,"treatment_tags":[],"created_utc":1752573953,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38t31z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hksbindra","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ruzt","score":1,"author_fullname":"t2_5dvq05mr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Benchmarks are based on f16, quantized versions specially Q4 and below don't perform as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38t31z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Benchmarks are based on f16, quantized versions specially Q4 and below don&amp;#39;t perform as well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38t31z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752579700,"author_flair_text":null,"treatment_tags":[],"created_utc":1752579700,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n391b96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37xhrk","score":1,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You would do yourself better by slamming your head against concrete than believe *\\"surely THIS is the small model that beats Deepseek!\\"* because of the nth jpeg to lie to you this month","edited":false,"author_flair_css_class":null,"name":"t1_n391b96","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You would do yourself better by slamming your head against concrete than believe &lt;em&gt;&amp;quot;surely THIS is the small model that beats Deepseek!&amp;quot;&lt;/em&gt; because of the nth jpeg to lie to you this month&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n391b96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752582864,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1752582864,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n37xhrk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Perfect_Twist713","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ruzt","score":-5,"author_fullname":"t2_i2wfev1l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Yes, that would be so much better, just endless arguments over what model is better (or worse) because nothing is allowed to be measured in any way. Such an incredibly good take.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37xhrk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, that would be so much better, just endless arguments over what model is better (or worse) because nothing is allowed to be measured in any way. Such an incredibly good take.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37xhrk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562737,"author_flair_text":null,"treatment_tags":[],"created_utc":1752562737,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n36ruzt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36lo5n","score":74,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Every model released in the last several months and claimed this but I haven't seen a single one worth its measure. When do we stop looking at benchmark jpegs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36ruzt","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Every model released in the last several months and claimed this but I haven&amp;#39;t seen a single one worth its measure. When do we stop looking at benchmark jpegs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36ruzt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544459,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752544459,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":74}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37n66n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Serprotease","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36lo5n","score":10,"author_fullname":"t2_odh3w8c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Instruction following benchmarks are almost “solved” problems with any Llm above 27b. If you look at the GitHub with the benchmark you will see that it’s only fairly simple tests. \\n\\nIn real life test, there is still a noticeable gap. \\nBut this gap is not visible if you ask things like “Rewrite this in json/mrkdwn” + check if the format is correct.   \\nIt’s only visible for things like “Return True if the user comment is positive, else False - user comment : Great product! Only broke after 2 days!”  \\n\\nLastly, this benchmarks paper are NOT peer-reviewed documents. They are promotional documents (Else you will see things like confidence intervals, statistical differences and an explanation of the choice of comparison.)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37n66n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Instruction following benchmarks are almost “solved” problems with any Llm above 27b. If you look at the GitHub with the benchmark you will see that it’s only fairly simple tests. &lt;/p&gt;\\n\\n&lt;p&gt;In real life test, there is still a noticeable gap. \\nBut this gap is not visible if you ask things like “Rewrite this in json/mrkdwn” + check if the format is correct.&lt;br/&gt;\\nIt’s only visible for things like “Return True if the user comment is positive, else False - user comment : Great product! Only broke after 2 days!”  &lt;/p&gt;\\n\\n&lt;p&gt;Lastly, this benchmarks paper are NOT peer-reviewed documents. They are promotional documents (Else you will see things like confidence intervals, statistical differences and an explanation of the choice of comparison.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37n66n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752557277,"author_flair_text":null,"treatment_tags":[],"created_utc":1752557277,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n36lo5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"secopsml","can_mod_post":false,"created_utc":1752542292,"send_replies":true,"parent_id":"t1_n36kya0","score":37,"author_fullname":"t2_pmniwf57y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"beating DeepSeek R1 and Qwen 235B on instruction following","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36lo5n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;beating DeepSeek R1 and Qwen 235B on instruction following&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36lo5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542292,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36v8di","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36tpa9","score":19,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hmm. Maybe I misunderstood?\\n\\n\\\\&gt; **Hybrid Attention**: For the 32B model, we adopt hybrid attention scheme, which combines *Local attention (sliding window attention)* with *Global attention (full attention)* in a 3:1 ratio. We do not use RoPE (Rotary Positional Embedding) for global attention for better global context understanding.","edited":1752548360,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36v8di","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmm. Maybe I misunderstood?&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; &lt;strong&gt;Hybrid Attention&lt;/strong&gt;: For the 32B model, we adopt hybrid attention scheme, which combines &lt;em&gt;Local attention (sliding window attention)&lt;/em&gt; with &lt;em&gt;Global attention (full attention)&lt;/em&gt; in a 3:1 ratio. We do not use RoPE (Rotary Positional Embedding) for global attention for better global context understanding.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36v8di/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752545637,"author_flair_text":null,"treatment_tags":[],"created_utc":1752545637,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38cvsb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Educational_Judge852","can_mod_post":false,"send_replies":true,"parent_id":"t1_n385vb1","score":1,"author_fullname":"t2_c37kclt8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I guess not..","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n38cvsb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I guess not..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38cvsb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752571709,"author_flair_text":null,"treatment_tags":[],"created_utc":1752571709,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38n4sz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752577090,"send_replies":true,"parent_id":"t1_n38m802","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;that is *beyond quadratic*\\n\\nso something like 'lightning attention' used in minimax-01 / minimax-M1?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n38n4sz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;that is &lt;em&gt;beyond quadratic&lt;/em&gt;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;so something like &amp;#39;lightning attention&amp;#39; used in minimax-01 / minimax-M1?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38n4sz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752577090,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n38m802","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BalorNG","can_mod_post":false,"send_replies":true,"parent_id":"t1_n38jip5","score":1,"author_fullname":"t2_b6gw9q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I *REALLY* like the idea of a tiered attention system. Maybe 4k tokens of a sliding window is a bit too much... Er, as in - little, but I'd love a system that automatically creates and updates some sort of internal knowlege graph (think - wiki) with key concepts from the conversation and their relations and use it along with sliding window and more \\"diffuse\\" global attention, maybe self-rag, too, to pull relevant chunks of text from the long convo into working memory.\\n\\nYou can have it as a part of neurosymbolic framework (like OAI memory feature), true, but ideally it should be built into the model itself...\\n\\nAn other feature that is missing is an attention/sampling alternative that is *beyond quadratic*, but frankly I have no idea it can possibly work :)\\nMaybe something like this:\\n\\nhttps://arxiv.org/abs/2405.00099","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n38m802","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I &lt;em&gt;REALLY&lt;/em&gt; like the idea of a tiered attention system. Maybe 4k tokens of a sliding window is a bit too much... Er, as in - little, but I&amp;#39;d love a system that automatically creates and updates some sort of internal knowlege graph (think - wiki) with key concepts from the conversation and their relations and use it along with sliding window and more &amp;quot;diffuse&amp;quot; global attention, maybe self-rag, too, to pull relevant chunks of text from the long convo into working memory.&lt;/p&gt;\\n\\n&lt;p&gt;You can have it as a part of neurosymbolic framework (like OAI memory feature), true, but ideally it should be built into the model itself...&lt;/p&gt;\\n\\n&lt;p&gt;An other feature that is missing is an attention/sampling alternative that is &lt;em&gt;beyond quadratic&lt;/em&gt;, but frankly I have no idea it can possibly work :)\\nMaybe something like this:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2405.00099\\"&gt;https://arxiv.org/abs/2405.00099&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38m802/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752576662,"author_flair_text":null,"treatment_tags":[],"created_utc":1752576662,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n38jip5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_n385vb1","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"body":"if that's like llama 4 or cohere r7b, the 'global attention' is probably a conventional softmax attention without positional encoding","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n38jip5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if that&amp;#39;s like llama 4 or cohere r7b, the &amp;#39;global attention&amp;#39; is probably a conventional softmax attention without positional encoding&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38jip5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752575334,"author_flair_text":null,"treatment_tags":[],"created_utc":1752575334,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n385vb1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BalorNG","can_mod_post":false,"send_replies":true,"parent_id":"t1_n383ygp","score":1,"author_fullname":"t2_b6gw9q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's used for global attention, some sort of SSM?","edited":false,"author_flair_css_class":null,"name":"t1_n385vb1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s used for global attention, some sort of SSM?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m04a20","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n385vb1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752567507,"author_flair_text":null,"collapsed":false,"created_utc":1752567507,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n383ygp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Educational_Judge852","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36tpa9","score":4,"author_fullname":"t2_c37kclt8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As far as I know, it seems they used Rope for local attention, and didn't use Rope for global attention.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n383ygp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As far as I know, it seems they used Rope for local attention, and didn&amp;#39;t use Rope for global attention.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n383ygp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752566388,"author_flair_text":null,"treatment_tags":[],"created_utc":1752566388,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n36tpa9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"plankalkul-z1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36oxac","score":11,"author_fullname":"t2_w73n3yrsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; they say they don't use Rope\\n\\nDo they?..\\n\\nWhat I see in their \`config.json\` is a regular \`\\"rope_scaling\\"\` block with \`\\"original_max_position_embeddings\\": 8192\`","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36tpa9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;they say they don&amp;#39;t use Rope&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Do they?..&lt;/p&gt;\\n\\n&lt;p&gt;What I see in their &lt;code&gt;config.json&lt;/code&gt; is a regular &lt;code&gt;&amp;quot;rope_scaling&amp;quot;&lt;/code&gt; block with &lt;code&gt;&amp;quot;original_max_position_embeddings&amp;quot;: 8192&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36tpa9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752545101,"author_flair_text":null,"treatment_tags":[],"created_utc":1752545101,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n36oxac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752543431,"send_replies":true,"parent_id":"t1_n36kya0","score":10,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Long context might be interesting since they say they don't use Rope","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36oxac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Long context might be interesting since they say they don&amp;#39;t use Rope&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36oxac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752543431,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36qboo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeProgrammer99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36puy6","score":5,"author_fullname":"t2_w4j8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh, yes. They have long-context benchmarks in the non-reasoning table. Beats Qwen3-32B on all three of those.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36qboo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh, yes. They have long-context benchmarks in the non-reasoning table. Beats Qwen3-32B on all three of those.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36qboo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752543922,"author_flair_text":null,"treatment_tags":[],"created_utc":1752543922,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n36puy6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Recoil42","can_mod_post":false,"created_utc":1752543759,"send_replies":true,"parent_id":"t1_n36kya0","score":5,"author_fullname":"t2_2kndo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also no RoPE. I'm curious how this does with long context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36puy6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also no RoPE. I&amp;#39;m curious how this does with long context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36puy6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752543759,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38ur0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeProgrammer99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n38b08v","score":1,"author_fullname":"t2_w4j8t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, I meant the license only permits noncommercial use. It says you can't even use the outputs to indirectly make money.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n38ur0z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, I meant the license only permits noncommercial use. It says you can&amp;#39;t even use the outputs to indirectly make money.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38ur0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752580371,"author_flair_text":null,"treatment_tags":[],"created_utc":1752580371,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n38b08v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Green-Ad-3964","can_mod_post":false,"created_utc":1752570614,"send_replies":true,"parent_id":"t1_n36kya0","score":1,"author_fullname":"t2_sfb08i7a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So this can be freely used in commercial projects?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38b08v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So this can be freely used in commercial projects?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38b08v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752570614,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n381w4n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BFGsuno","can_mod_post":false,"created_utc":1752565216,"send_replies":true,"parent_id":"t1_n36kya0","score":1,"author_fullname":"t2_1pu42hfw1u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Dude by the benchmarks it is very close to R1-0528.\\n\\nI need to do some private testing because those are fucking big claims.\\n\\nAlso for context it doesn't use rope at all.\\n\\nedit:\\n\\nseems like it has own architecture, isn't compatibile right now with lm studio.","edited":1752565712,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n381w4n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dude by the benchmarks it is very close to R1-0528.&lt;/p&gt;\\n\\n&lt;p&gt;I need to do some private testing because those are fucking big claims.&lt;/p&gt;\\n\\n&lt;p&gt;Also for context it doesn&amp;#39;t use rope at all.&lt;/p&gt;\\n\\n&lt;p&gt;edit:&lt;/p&gt;\\n\\n&lt;p&gt;seems like it has own architecture, isn&amp;#39;t compatibile right now with lm studio.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n381w4n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752565216,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n36kya0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeProgrammer99","can_mod_post":false,"created_utc":1752542042,"send_replies":true,"parent_id":"t3_1m04a20","score":119,"author_fullname":"t2_w4j8t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Key points, in my mind: beating Qwen 3 32B in MOST benchmarks (including LiveCodeBench), toggleable reasoning), noncommercial license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36kya0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Key points, in my mind: beating Qwen 3 32B in MOST benchmarks (including LiveCodeBench), toggleable reasoning), noncommercial license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36kya0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542042,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":119}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n385dup","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fiery_prometheus","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37w7ts","score":8,"author_fullname":"t2_celhj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I'm pretty sure that just as authors can't sue them for using their material, neither can you be sued for using the output of models.\\n\\n\\nIf that would be the case, it would lend credibility to the first case, and corporate would not like that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n385dup","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I&amp;#39;m pretty sure that just as authors can&amp;#39;t sue them for using their material, neither can you be sued for using the output of models.&lt;/p&gt;\\n\\n&lt;p&gt;If that would be the case, it would lend credibility to the first case, and corporate would not like that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n385dup/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752567219,"author_flair_text":null,"treatment_tags":[],"created_utc":1752567219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38ds2o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Severin_Suveren","can_mod_post":false,"send_replies":true,"parent_id":"t1_n38bzay","score":3,"author_fullname":"t2_vfpsd1c8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's only true in America","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38ds2o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s only true in America&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38ds2o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752572229,"author_flair_text":null,"treatment_tags":[],"created_utc":1752572229,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n38bzay","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jazir5","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37w7ts","score":3,"author_fullname":"t2_8u27g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You don't even need a license, AI produced materials are not copyrightable at all, they are instantly public domain.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n38bzay","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don&amp;#39;t even need a license, AI produced materials are not copyrightable at all, they are instantly public domain.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38bzay/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752571187,"author_flair_text":null,"treatment_tags":[],"created_utc":1752571187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n37w7ts","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Severin_Suveren","can_mod_post":false,"created_utc":1752562047,"send_replies":true,"parent_id":"t1_n36rz8u","score":15,"author_fullname":"t2_vfpsd1c8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Kind of insane it also includes outputs from the model. Usually it's just deployments of the model itself or derivatives of it that's not allowed","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37w7ts","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kind of insane it also includes outputs from the model. Usually it&amp;#39;s just deployments of the model itself or derivatives of it that&amp;#39;s not allowed&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37w7ts/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562047,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38ezqs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnomalyNexus","can_mod_post":false,"created_utc":1752572910,"send_replies":true,"parent_id":"t1_n36rz8u","score":3,"author_fullname":"t2_3q8dd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow that’s a rubbish license","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38ezqs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow that’s a rubbish license&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38ezqs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752572910,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n36rz8u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BogaSchwifty","can_mod_post":false,"created_utc":1752544500,"send_replies":true,"parent_id":"t3_1m04a20","score":45,"author_fullname":"t2_5b3a0s4d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From their license, looks like I can’t ship it to my 7 users:\\n“””\\nCommercial Use: The Licensee is expressly prohibited from using the Model, Derivatives, or Output for\\n    any commercial purposes, including but not limited to, developing or deploying products, services, or\\n    applications that generate revenue, whether directly or indirectly. Any commercial exploitation of the\\n    Model or its derivatives requires a separate commercial license agreement with the Licensor. Furthermore,\\n    the Licensee shall not use the Model, Derivatives or Output to develop or improve any models that compete\\n    with the Licensor’s models.\\n“””","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36rz8u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From their license, looks like I can’t ship it to my 7 users:\\n“””\\nCommercial Use: The Licensee is expressly prohibited from using the Model, Derivatives, or Output for\\n    any commercial purposes, including but not limited to, developing or deploying products, services, or\\n    applications that generate revenue, whether directly or indirectly. Any commercial exploitation of the\\n    Model or its derivatives requires a separate commercial license agreement with the Licensor. Furthermore,\\n    the Licensee shall not use the Model, Derivatives or Output to develop or improve any models that compete\\n    with the Licensor’s models.\\n“””&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36rz8u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544500,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":45}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3746b8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"foldl-li","can_mod_post":false,"created_utc":1752548924,"send_replies":true,"parent_id":"t3_1m04a20","score":19,"author_fullname":"t2_g644e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Haha.\\n\\n\`config.json\`:\\n\\n\`\`\`json\\n{\\n  \\"sliding_window_pattern\\": \\"LLLG\\",\\n}\\n\`\`\`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3746b8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haha.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;config.json&lt;/code&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;json\\n{\\n  &amp;quot;sliding_window_pattern&amp;quot;: &amp;quot;LLLG&amp;quot;,\\n}\\n&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n3746b8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548924,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n388wi2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dhlu","can_mod_post":false,"created_utc":1752569369,"send_replies":true,"parent_id":"t1_n37697h","score":4,"author_fullname":"t2_3bcperq1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Curiously lot of my test with those kind of prompts fall short on any LLM\\n\\nSome are so small, so concentrated, that if you don't talk them about code problem they just explode\\n\\nBut nevermind, I'll download a psychology help LLM the day I would want to, right now I want a coding one","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n388wi2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Curiously lot of my test with those kind of prompts fall short on any LLM&lt;/p&gt;\\n\\n&lt;p&gt;Some are so small, so concentrated, that if you don&amp;#39;t talk them about code problem they just explode&lt;/p&gt;\\n\\n&lt;p&gt;But nevermind, I&amp;#39;ll download a psychology help LLM the day I would want to, right now I want a coding one&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n388wi2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752569369,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37q7v1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37l6ij","score":3,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nothing special:\\n\\nCloned their build and  \\ncmake -B build -DGGML\\\\_CUDA=ON -DLLAMA\\\\_CURL=ON  \\ncmake --build build --config Release -j$(nproc)  \\n./llama-server -m \\\\~/models/EXAONE-4.0-32B-Q8\\\\_0.gguf --ctx-size 80000 -ngl 99 -fa --host [0.0.0.0](http://0.0.0.0) \\\\--port 8000 --temp 0.0 --top-k 1\\n\\n  \\nThat said, it's worse than Qwen3 32b from my testing.","edited":1752559255,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37q7v1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nothing special:&lt;/p&gt;\\n\\n&lt;p&gt;Cloned their build and&lt;br/&gt;\\ncmake -B build -DGGML_CUDA=ON -DLLAMA_CURL=ON&lt;br/&gt;\\ncmake --build build --config Release -j$(nproc)&lt;br/&gt;\\n./llama-server -m ~/models/EXAONE-4.0-32B-Q8_0.gguf --ctx-size 80000 -ngl 99 -fa --host &lt;a href=\\"http://0.0.0.0\\"&gt;0.0.0.0&lt;/a&gt; --port 8000 --temp 0.0 --top-k 1&lt;/p&gt;\\n\\n&lt;p&gt;That said, it&amp;#39;s worse than Qwen3 32b from my testing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37q7v1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752558843,"author_flair_text":null,"treatment_tags":[],"created_utc":1752558843,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n37l6ij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InfernalDread","can_mod_post":false,"created_utc":1752556294,"send_replies":true,"parent_id":"t1_n37697h","score":1,"author_fullname":"t2_6tebyfr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I built the custom fork/branch that they provided and downloaded their gguf file, but I am getting a jinja error when running llama server. How did you get around this issue?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37l6ij","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I built the custom fork/branch that they provided and downloaded their gguf file, but I am getting a jinja error when running llama server. How did you get around this issue?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37l6ij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752556294,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n37697h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1752549745,"send_replies":true,"parent_id":"t3_1m04a20","score":9,"author_fullname":"t2_9hl4ymvj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It goes completely insane if you say:  \\nHi how are you?\\n\\nThought it was a bad gguf of something, but if you ask it a real question it seems fine.  \\nTesting now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37697h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It goes completely insane if you say:&lt;br/&gt;\\nHi how are you?&lt;/p&gt;\\n\\n&lt;p&gt;Thought it was a bad gguf of something, but if you ask it a real question it seems fine.&lt;br/&gt;\\nTesting now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37697h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549745,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38zhkt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xrailgun","can_mod_post":false,"send_replies":true,"parent_id":"t1_n372zaf","score":1,"author_fullname":"t2_kggm5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And mainly because EXAONE is from LG, a Korean company.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38zhkt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And mainly because EXAONE is from LG, a Korean company.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38zhkt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752582182,"author_flair_text":null,"treatment_tags":[],"created_utc":1752582182,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n372zaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jinnyjuice","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36rxhe","score":13,"author_fullname":"t2_4hrx8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very efficient indeed, because Koreans also have the densest + fastest adoption rate of LLMs for the population","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n372zaf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very efficient indeed, because Koreans also have the densest + fastest adoption rate of LLMs for the population&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n372zaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548461,"author_flair_text":null,"treatment_tags":[],"created_utc":1752548461,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n36rxhe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emprahsFury","can_mod_post":false,"created_utc":1752544483,"send_replies":false,"parent_id":"t1_n36lz9n","score":27,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"8 billion people in the world, 2+ billion speak one of those three languages. Pretty efficient spread","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36rxhe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;8 billion people in the world, 2+ billion speak one of those three languages. Pretty efficient spread&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36rxhe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544483,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}}],"before":null}},"user_reports":[],"saved":false,"id":"n36lz9n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1752542399,"send_replies":true,"parent_id":"t3_1m04a20","score":27,"author_fullname":"t2_4gc7hf3m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; its multilingual capabilities are extended to support Spanish in addition to English and Korean.\\n\\n\\nOnly 3 languages? ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36lz9n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;its multilingual capabilities are extended to support Spanish in addition to English and Korean.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Only 3 languages? &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36lz9n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542399,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37cy2r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Accomplished_Mode170","can_mod_post":false,"created_utc":1752552518,"send_replies":true,"parent_id":"t1_n3747rf","score":27,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"License still stinks; testing now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37cy2r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;License still stinks; testing now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37cy2r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752552518,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}}],"before":null}},"user_reports":[],"saved":false,"id":"n3747rf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kastmada","can_mod_post":false,"created_utc":1752548940,"send_replies":true,"parent_id":"t3_1m04a20","score":23,"author_fullname":"t2_10yyuu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"EXAONE models were really good starting from their first version. I feel like they were not getting attention they deserved. I'm excited to try this one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3747rf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;EXAONE models were really good starting from their first version. I feel like they were not getting attention they deserved. I&amp;#39;m excited to try this one.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n3747rf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548940,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36n4al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"this-just_in","can_mod_post":false,"created_utc":1752542793,"send_replies":true,"parent_id":"t3_1m04a20","score":12,"author_fullname":"t2_kdmu4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Some truly impressive reasoning and non-reasoning benchmarks, if they hold.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36n4al","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some truly impressive reasoning and non-reasoning benchmarks, if they hold.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36n4al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542793,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37gs1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheActualStudy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n375m6u","score":5,"author_fullname":"t2_7b7fm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The model card provides instructions on how to clone from their repo that the open pull request for llama.cpp support comes from. You can use their GGUFs with that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37gs1t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The model card provides instructions on how to clone from their repo that the open pull request for llama.cpp support comes from. You can use their GGUFs with that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37gs1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752554227,"author_flair_text":null,"treatment_tags":[],"created_utc":1752554227,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n375m6u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"giant3","can_mod_post":false,"created_utc":1752549490,"send_replies":true,"parent_id":"t1_n374bk7","score":3,"author_fullname":"t2_82esi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looks like it is only for the converter Python program? \\n\\n\\nAlso, if support isn't merged why are they providing GGUF?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n375m6u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like it is only for the converter Python program? &lt;/p&gt;\\n\\n&lt;p&gt;Also, if support isn&amp;#39;t merged why are they providing GGUF?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n375m6u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549490,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n374bk7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreenPastures2845","can_mod_post":false,"created_utc":1752548981,"send_replies":true,"parent_id":"t3_1m04a20","score":12,"author_fullname":"t2_1eec9087px","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llamacpp support still in the works: https://github.com/ggml-org/llama.cpp/issues/14474","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n374bk7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llamacpp support still in the works: &lt;a href=\\"https://github.com/ggml-org/llama.cpp/issues/14474\\"&gt;https://github.com/ggml-org/llama.cpp/issues/14474&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n374bk7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548981,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n380z6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bobby-chan","can_mod_post":false,"created_utc":1752564696,"send_replies":true,"parent_id":"t1_n3724uu","score":4,"author_fullname":"t2_frmtv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They already started, you're just not the intended audience\\n\\n[https://www.tomshardware.com/networking/your-washing-machine-could-be-sending-37-gb-of-data-a-day](https://www.tomshardware.com/networking/your-washing-machine-could-be-sending-37-gb-of-data-a-day)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n380z6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They already started, you&amp;#39;re just not the intended audience&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.tomshardware.com/networking/your-washing-machine-could-be-sending-37-gb-of-data-a-day\\"&gt;https://www.tomshardware.com/networking/your-washing-machine-could-be-sending-37-gb-of-data-a-day&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n380z6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564696,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3724uu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"created_utc":1752548140,"send_replies":true,"parent_id":"t3_1m04a20","score":11,"author_fullname":"t2_eerln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I can’t wait for my washer and dryer to start a Korean drama. My freezer and fridge must be cool heads","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3724uu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can’t wait for my washer and dryer to start a Korean drama. My freezer and fridge must be cool heads&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n3724uu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n371id8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RedditDiedLongAgo","can_mod_post":false,"created_utc":1752547911,"send_replies":true,"parent_id":"t1_n36lwm8","score":3,"author_fullname":"t2_42tdujpc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Le Fridge","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n371id8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Le Fridge&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n371id8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547911,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38agom","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mochila-Mochila","can_mod_post":false,"created_utc":1752570297,"send_replies":true,"parent_id":"t1_n36lwm8","score":0,"author_fullname":"t2_10otgvvrn1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; French door fridges\\n\\nUh, first time I read this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38agom","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;French door fridges&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Uh, first time I read this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38agom/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752570297,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n36lwm8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sourceholder","can_mod_post":false,"created_utc":1752542374,"send_replies":true,"parent_id":"t3_1m04a20","score":21,"author_fullname":"t2_35jjv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are LG models compatible with French door fridges or limited to classic single door design?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36lwm8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are LG models compatible with French door fridges or limited to classic single door design?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36lwm8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542374,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37wj5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37az4z","score":2,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\^\\\\^\\\\^\\\\^\\n\\nSupport hasn't been merged yet, maybe it's possible to build that branch and test...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37wj5x","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;^^^^&lt;/p&gt;\\n\\n&lt;p&gt;Support hasn&amp;#39;t been merged yet, maybe it&amp;#39;s possible to build that branch and test...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37wj5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562217,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752562217,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n37az4z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sammcj","can_mod_post":false,"created_utc":1752551679,"send_replies":true,"parent_id":"t1_n370tjp","score":6,"author_fullname":"t2_3mf7o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"- https://github.com/ggml-org/llama.cpp/issues/14474\\n- https://github.com/ggml-org/llama.cpp/pull/14630","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37az4z","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ul&gt;\\n&lt;li&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/issues/14474\\"&gt;https://github.com/ggml-org/llama.cpp/issues/14474&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/14630\\"&gt;https://github.com/ggml-org/llama.cpp/pull/14630&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37az4z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752551679,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n370tjp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1752547655,"send_replies":true,"parent_id":"t3_1m04a20","score":6,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh nice, they offer GGUFs too:\\n\\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF\\n\\nWonder if I'll have to rebuild llama.cpp to evaluate it.  Guess I'll find out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n370tjp","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh nice, they offer GGUFs too:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF\\"&gt;https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B-GGUF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Wonder if I&amp;#39;ll have to rebuild llama.cpp to evaluate it.  Guess I&amp;#39;ll find out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n370tjp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547655,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37et6x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36s42n","score":5,"author_fullname":"t2_ielo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"v20 owner checking in","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37et6x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;v20 owner checking in&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37et6x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752553340,"author_flair_text":null,"treatment_tags":[],"created_utc":1752553340,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38gxqm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36s42n","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The G3 was pretty good back in the day, used that one for years till the gnss chip failed.\\n\\nI think LG invented the tap-the-screen-twice-to-wake which is now ubiquitous, though I could be misremembering.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38gxqm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The G3 was pretty good back in the day, used that one for years till the gnss chip failed.&lt;/p&gt;\\n\\n&lt;p&gt;I think LG invented the tap-the-screen-twice-to-wake which is now ubiquitous, though I could be misremembering.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38gxqm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752573970,"author_flair_text":null,"treatment_tags":[],"created_utc":1752573970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38jyx7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36s42n","score":1,"author_fullname":"t2_5oltmr5b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've used only LG smartphone till their last one...\\n\\nthe g6 was an amazing phone","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38jyx7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve used only LG smartphone till their last one...&lt;/p&gt;\\n\\n&lt;p&gt;the g6 was an amazing phone&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38jyx7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752575566,"author_flair_text":null,"treatment_tags":[],"created_utc":1752575566,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n36s42n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36rd5p","score":13,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Their defunct smartphone business for one.\\n\\nThey made phones that forced Samsung to behave for several years.\\n\\nSamsung dropping features largely started after LG called it quits. LG made some damn good phones.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36s42n","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their defunct smartphone business for one.&lt;/p&gt;\\n\\n&lt;p&gt;They made phones that forced Samsung to behave for several years.&lt;/p&gt;\\n\\n&lt;p&gt;Samsung dropping features largely started after LG called it quits. LG made some damn good phones.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36s42n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544547,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752544547,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n36rd5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yungfishstick","can_mod_post":false,"created_utc":1752544286,"send_replies":true,"parent_id":"t1_n36ovu7","score":34,"author_fullname":"t2_3bzzdk93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Like Samsung, LG is a way bigger company than many think it is.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36rd5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Like Samsung, LG is a way bigger company than many think it is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36rd5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752544286,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n388eis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37ws3p","score":2,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, the pure ai research labs have nothing else going for them but the models. While the conglomerates can give out their models because it is just a side project for them.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n388eis","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, the pure ai research labs have nothing else going for them but the models. While the conglomerates can give out their models because it is just a side project for them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n388eis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752569075,"author_flair_text":null,"treatment_tags":[],"created_utc":1752569075,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n37ws3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"indicava","can_mod_post":false,"created_utc":1752562350,"send_replies":true,"parent_id":"t1_n36ovu7","score":6,"author_fullname":"t2_4dvff","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And yet all these huge conglomerates are giving us open weights models (Alibaba, LG, IBM, Meta…) while the “pure” AI research labs are giving us jack shit.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37ws3p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And yet all these huge conglomerates are giving us open weights models (Alibaba, LG, IBM, Meta…) while the “pure” AI research labs are giving us jack shit.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37ws3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752562350,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n36ovu7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ninjasaid13","can_mod_post":false,"created_utc":1752543416,"send_replies":true,"parent_id":"t3_1m04a20","score":11,"author_fullname":"t2_qjpsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"are they making LLMs for fridges? \\n\\nEvery company and their mom has an AI research division.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36ovu7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are they making LLMs for fridges? &lt;/p&gt;\\n\\n&lt;p&gt;Every company and their mom has an AI research division.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36ovu7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752543416,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37a95j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Active-Picture-5681","can_mod_post":false,"created_utc":1752551380,"send_replies":true,"parent_id":"t3_1m04a20","score":3,"author_fullname":"t2_8z7n5g7p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anyone run aider polyglot yet?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37a95j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone run aider polyglot yet?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37a95j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752551380,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36zat4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ysk1","score":6,"author_fullname":"t2_3c2a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same. mmlu-redux in this case (noted in notes).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36zat4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same. mmlu-redux in this case (noted in notes).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36zat4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547102,"author_flair_text":null,"treatment_tags":[],"created_utc":1752547102,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38hki8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_n36ysk1","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah doesn't the MMLU have like 5% wrong answers in it? That's basically nearly the theoretical maximum.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n38hki8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah doesn&amp;#39;t the MMLU have like 5% wrong answers in it? That&amp;#39;s basically nearly the theoretical maximum.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38hki8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752574312,"author_flair_text":null,"treatment_tags":[],"created_utc":1752574312,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n36ysk1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"djm07231","can_mod_post":false,"created_utc":1752546918,"send_replies":true,"parent_id":"t1_n36x4up","score":24,"author_fullname":"t2_zuxto","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"MMLU of 92.3 makes me suspicious of a lot of benchmark-maxing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36ysk1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MMLU of 92.3 makes me suspicious of a lot of benchmark-maxing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36ysk1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752546918,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3753ud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lucas03crok","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37426h","score":6,"author_fullname":"t2_zdltg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Non reasoning is 89.8, 77.6 and 63.7","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3753ud","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Non reasoning is 89.8, 77.6 and 63.7&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n3753ud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549290,"author_flair_text":null,"treatment_tags":[],"created_utc":1752549290,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n37426h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lucas03crok","can_mod_post":false,"created_utc":1752548879,"send_replies":true,"parent_id":"t1_n36x4up","score":1,"author_fullname":"t2_zdltg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's reasoning vs non reasoning","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37426h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s reasoning vs non reasoning&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37426h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548879,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n36x4up","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adt","can_mod_post":false,"created_utc":1752546322,"send_replies":true,"parent_id":"t3_1m04a20","score":9,"author_fullname":"t2_3c2a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"32B outperforms Kimi K2 1T:\\n\\n[https://lifearchitect.ai/models-table/](https://lifearchitect.ai/models-table/)\\n\\nhttps://preview.redd.it/bg4ejz6z7ycf1.png?width=1988&amp;format=png&amp;auto=webp&amp;s=f428077030f761f6b6c8d02e0ff1ff7eab62964e","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36x4up","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;32B outperforms Kimi K2 1T:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://lifearchitect.ai/models-table/\\"&gt;https://lifearchitect.ai/models-table/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/bg4ejz6z7ycf1.png?width=1988&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f428077030f761f6b6c8d02e0ff1ff7eab62964e\\"&gt;https://preview.redd.it/bg4ejz6z7ycf1.png?width=1988&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f428077030f761f6b6c8d02e0ff1ff7eab62964e&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36x4up/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752546322,"media_metadata":{"bg4ejz6z7ycf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":15,"x":108,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1c550a6781a8c2623ca24cc6661e247a20c6f9b1"},{"y":30,"x":216,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=49cb6ebbb19b12866b86f5ca58f3090700a59d15"},{"y":45,"x":320,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=868b6d146fd0180a411800666b709d1448a721f8"},{"y":90,"x":640,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ed4553103ff50ac9588afdf03a345c52fef92e8"},{"y":135,"x":960,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=93177754ceb8b7ba72b3abf742be4af4e85e8e46"},{"y":152,"x":1080,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ed7ce65c63f0d6eb6a7e6517daeafde12ac3e549"}],"s":{"y":280,"x":1988,"u":"https://preview.redd.it/bg4ejz6z7ycf1.png?width=1988&amp;format=png&amp;auto=webp&amp;s=f428077030f761f6b6c8d02e0ff1ff7eab62964e"},"id":"bg4ejz6z7ycf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36q2bx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RedditUsr2","can_mod_post":false,"created_utc":1752543831,"send_replies":true,"parent_id":"t3_1m04a20","score":6,"author_fullname":"t2_16stt5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Previous one was above average for RAG. I can't wait to test it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36q2bx","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Previous one was above average for RAG. I can&amp;#39;t wait to test it!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36q2bx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752543831,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38fzsq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"created_utc":1752573458,"send_replies":true,"parent_id":"t3_1m04a20","score":2,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"EXAFOUR","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38fzsq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;EXAFOUR&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38fzsq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752573458,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37nhqr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brahh85","can_mod_post":false,"created_utc":1752557442,"send_replies":true,"parent_id":"t3_1m04a20","score":5,"author_fullname":"t2_n9d13wu1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They create an useful model and  they  force you to use it for useless things.\\n\\nThe Licensee is expressly prohibited from using the Model, Derivatives, or Output for any commercial purposes, including but not limited to, developing or deploying products, services, or applications that generate revenue, whether directly or indirectly.\\n\\nI cant even use it for creative writing , or coding. I cant even help a friend with it, if what my friend asks me  is related to his work. \\n\\nIts the epitome of stupidity. LG stands for License Garbage.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37nhqr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They create an useful model and  they  force you to use it for useless things.&lt;/p&gt;\\n\\n&lt;p&gt;The Licensee is expressly prohibited from using the Model, Derivatives, or Output for any commercial purposes, including but not limited to, developing or deploying products, services, or applications that generate revenue, whether directly or indirectly.&lt;/p&gt;\\n\\n&lt;p&gt;I cant even use it for creative writing , or coding. I cant even help a friend with it, if what my friend asks me  is related to his work. &lt;/p&gt;\\n\\n&lt;p&gt;Its the epitome of stupidity. LG stands for License Garbage.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37nhqr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752557442,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37hhbw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Balance-","can_mod_post":false,"created_utc":1752554548,"send_replies":true,"parent_id":"t3_1m04a20","score":4,"author_fullname":"t2_14okit","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great model, terrible license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37hhbw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great model, terrible license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37hhbw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752554548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37zydu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Cow1976","can_mod_post":false,"created_utc":1752564114,"send_replies":true,"parent_id":"t1_n37sad4","score":3,"author_fullname":"t2_3pwbsmdr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My experience too","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37zydu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My experience too&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37zydu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564114,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n37sad4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mitchins-au","can_mod_post":false,"created_utc":1752559913,"send_replies":true,"parent_id":"t3_1m04a20","score":2,"author_fullname":"t2_4hjtgq5u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried the last one and it sucked.\\nIt was slow (if it even finished at all as it tended to get sticks in loops).\\nEven Reka-Flash-21B was better","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n37sad4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried the last one and it sucked.\\nIt was slow (if it even finished at all as it tended to get sticks in loops).\\nEven Reka-Flash-21B was better&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n37sad4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752559913,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n380pvy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1752564548,"send_replies":true,"parent_id":"t3_1m04a20","score":1,"author_fullname":"t2_ogjj6ebj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So that model is very improved version of qwen 32b ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n380pvy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So that model is very improved version of qwen 32b ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n380pvy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752564548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38817l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"created_utc":1752568855,"send_replies":true,"parent_id":"t3_1m04a20","score":1,"author_fullname":"t2_63vtw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am actually more interested in the 1.2B model.\\n\\nI am resisting the urge to try and train or full fine tune (not LORA) one of these and I wonder if it is worth doing it, if any can have basic reasoning skills, even in monolingual mode.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38817l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am actually more interested in the 1.2B model.&lt;/p&gt;\\n\\n&lt;p&gt;I am resisting the urge to try and train or full fine tune (not LORA) one of these and I wonder if it is worth doing it, if any can have basic reasoning skills, even in monolingual mode.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38817l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752568855,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38nsbj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adrgrondin","can_mod_post":false,"created_utc":1752577390,"send_replies":true,"parent_id":"t3_1m04a20","score":1,"author_fullname":"t2_1jgkfm9u25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Still have a non-commercial license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38nsbj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still have a non-commercial license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38nsbj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752577390,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38yqu4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NoobMLDude","can_mod_post":false,"created_utc":1752581906,"send_replies":true,"parent_id":"t3_1m04a20","score":1,"author_fullname":"t2_t0syffr8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is there a paper or technical report atleast?📝","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38yqu4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there a paper or technical report atleast?📝&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n38yqu4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752581906,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3781c5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752550469,"send_replies":true,"parent_id":"t3_1m04a20","score":1,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"### 1. High-Level Summary\\nEXAONE 4.0 is a series of large language models developed by LG AI Research, designed to unify strong instruction-following capabilities with advanced reasoning. It introduces a dual-mode system (**NON-REASONING** and **REASONING**) within a single model, extends multilingual support to Spanish alongside English and Korean, and incorporates agentic tool-use functionalities. The series includes a high-performance **32B** model and an on-device oriented **1.2B** model, both publicly available for research.\\n\\n---\\n\\n### 2. Model Architecture and Configuration\\nEXAONE 4.0 builds upon its predecessors but introduces significant architectural modifications focused on long-context efficiency and performance.\\n\\n#### **2.1. Hybrid Attention Mechanism (32B Model)**\\nUnlike previous versions that used global attention in every layer, the 32B model employs a hybrid attention mechanism to manage the computational cost of its 128K context length.\\n*   **Structure:** It combines local attention (sliding window) and global attention in a **3:1 ratio** across its layers. One out of every four layers uses global attention, while the other three use local attention.\\n*   **Local Attention:** A sliding window attention with a **4K token window size** is used. This specific type of sparse attention was chosen for its theoretical stability and wide support in open-source frameworks.\\n*   **Global Attention:** The layers with global attention do not use Rotary Position Embedding (RoPE) to prevent the model from developing length-based biases and to maintain a true global view of the context.\\n\\n#### **2.2. Layer Normalization (LayerNorm)**\\nThe model architecture has been updated from a standard Pre-LN Transformer to a **QK-Reorder-LN** configuration.\\n*   **Mechanism:** LayerNorm (specifically RMSNorm) is applied to the queries (Q) and keys (K) *before* the attention calculation, and then again to the attention output.\\n*   **Justification:** This method, while computationally more intensive, is cited to yield significantly better performance on downstream tasks compared to the conventional Pre-LN approach. The standard RMSNorm from previous versions is retained.\\n\\n#### **2.3. Model Hyperparameters**\\nKey configurations for the two model sizes are detailed below:\\n\\n| Parameter | EXAONE 4.0 32B | EXAONE 4.0 1.2B |\\n| :--- | :--- | :--- |\\n| **Model Size** | 32.0B | 1.2B |\\n| **\`d_model\`** | 5,120 | 2,048 |\\n| **Num. Layers** | 64 | 30 |\\n| **Attention Type** | **Hybrid** (3:1 Local:Global) | **Global** |\\n| **Head Type** | Grouped-Query Attention (GQA) | Grouped-Query Attention (GQA) |\\n| **Num. Heads (KV)** | 40 (8) | 32 (8) |\\n| **Max Context** | **128K** (131,072) | **64K** (65,536) |\\n| **Normalization** | **QK-Reorder-LN** (RMSNorm) | **QK-Reorder-LN** (RMSNorm) |\\n| **Non-linearity** | SwiGLU | SwiGLU |\\n| **Tokenizer** | BBPE (102,400 vocab size) | BBPE (102,400 vocab size) |\\n| **Knowledge Cut-off**| Nov. 2024 | Nov. 2024 |\\n\\n---\\n\\n### 3. Training Pipeline\\n\\n#### **3.1. Pre-training**\\n*   **Data Scale:** The 32B model was pre-trained on **14 trillion tokens**, a twofold increase from its predecessor (EXAONE 3.5). This was specifically aimed at enhancing world knowledge and reasoning.\\n*   **Data Curation:** Rigorous data curation was performed, focusing on documents exhibiting \\"cognitive behavior\\" and specialized STEM data to improve reasoning performance.\\n\\n#### **3.2. Context Length Extension**\\nA two-stage, validated process was used to extend the context window.\\n1.  **Stage 1:** The model pre-trained with a 4K context was extended to **32K**.\\n2.  **Stage 2:** The 32K model was further extended to **128K** (for the 32B model) and **64K** (for the 1.2B model).\\n*   **Validation:** The **Needle In A Haystack (NIAH)** test was used iteratively at each stage to ensure performance was not compromised during the extension.\\n\\n#### **3.3. Post-training and Alignment**\\nThe post-training pipeline (Figure 3) is a multi-stage process designed to create the unified dual-mode model.\\n\\n1.  **Large-Scale Supervised Fine-Tuning (SFT):**\\n    *   **Unified Mode Training:** The model is trained on a combined dataset for both NON-REASONING (diverse general tasks) and REASONING (Math, Code, Logic) modes.\\n    *   **Data Ratio:** An ablation-tested token ratio of **1.5 (Reasoning) : 1 (Non-Reasoning)** is used to balance the modes and prevent the model from defaulting to reasoning-style generation.\\n    *   **Domain-Specific SFT:** A second SFT round is performed on high-quality Code and Tool Use data to address domain imbalance.\\n\\n2.  **Reasoning Reinforcement Learning (RL):**\\n    A novel algorithm, **AGAPO (Asymmetric Sampling and Global Advantage Policy Optimization)**, was developed to enhance reasoning. It improves upon GRPO with several key features:\\n    *   **Removed Clipped Objective:** Replaces PPO's clipped loss with a standard policy gradient loss to allow for more substantial updates from low-probability \\"exploratory\\" tokens crucial for reasoning paths.\\n    *   **Asymmetric Sampling:** Unlike methods that discard samples where all generated responses are incorrect, AGAPO retains them, using them as negative feedback to guide the model away from erroneous paths.\\n    *   **Group &amp; Global Advantages:** A two-stage advantage calculation. First, a Leave-One-Out (LOO) advantage is computed within a group of responses. This is then normalized across the entire batch (global) to provide a more robust final advantage score.\\n    *   **Sequence-Level Cumulative KL:** A KL penalty is applied at the sequence level to maintain the capabilities learned during SFT while optimizing for the RL objective.\\n\\n3.  **Preference Learning with Hybrid Reward:**\\n    To refine the model and align it with human preferences, a two-stage preference learning phase using the \`SimPER\` framework is conducted.\\n    *   **Stage 1 (Efficiency):** A hybrid reward combining **verifiable reward (correctness) and a conciseness reward** is used. This encourages the model to select the shortest correct answer, improving token efficiency.\\n    *   **Stage 2 (Alignment):** A hybrid reward combining **preference reward and language consistency reward** is used for human alignment.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3781c5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;h3&gt;1. High-Level Summary&lt;/h3&gt;\\n\\n&lt;p&gt;EXAONE 4.0 is a series of large language models developed by LG AI Research, designed to unify strong instruction-following capabilities with advanced reasoning. It introduces a dual-mode system (&lt;strong&gt;NON-REASONING&lt;/strong&gt; and &lt;strong&gt;REASONING&lt;/strong&gt;) within a single model, extends multilingual support to Spanish alongside English and Korean, and incorporates agentic tool-use functionalities. The series includes a high-performance &lt;strong&gt;32B&lt;/strong&gt; model and an on-device oriented &lt;strong&gt;1.2B&lt;/strong&gt; model, both publicly available for research.&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;h3&gt;2. Model Architecture and Configuration&lt;/h3&gt;\\n\\n&lt;p&gt;EXAONE 4.0 builds upon its predecessors but introduces significant architectural modifications focused on long-context efficiency and performance.&lt;/p&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;2.1. Hybrid Attention Mechanism (32B Model)&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;p&gt;Unlike previous versions that used global attention in every layer, the 32B model employs a hybrid attention mechanism to manage the computational cost of its 128K context length.\\n*   &lt;strong&gt;Structure:&lt;/strong&gt; It combines local attention (sliding window) and global attention in a &lt;strong&gt;3:1 ratio&lt;/strong&gt; across its layers. One out of every four layers uses global attention, while the other three use local attention.\\n*   &lt;strong&gt;Local Attention:&lt;/strong&gt; A sliding window attention with a &lt;strong&gt;4K token window size&lt;/strong&gt; is used. This specific type of sparse attention was chosen for its theoretical stability and wide support in open-source frameworks.\\n*   &lt;strong&gt;Global Attention:&lt;/strong&gt; The layers with global attention do not use Rotary Position Embedding (RoPE) to prevent the model from developing length-based biases and to maintain a true global view of the context.&lt;/p&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;2.2. Layer Normalization (LayerNorm)&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;p&gt;The model architecture has been updated from a standard Pre-LN Transformer to a &lt;strong&gt;QK-Reorder-LN&lt;/strong&gt; configuration.\\n*   &lt;strong&gt;Mechanism:&lt;/strong&gt; LayerNorm (specifically RMSNorm) is applied to the queries (Q) and keys (K) &lt;em&gt;before&lt;/em&gt; the attention calculation, and then again to the attention output.\\n*   &lt;strong&gt;Justification:&lt;/strong&gt; This method, while computationally more intensive, is cited to yield significantly better performance on downstream tasks compared to the conventional Pre-LN approach. The standard RMSNorm from previous versions is retained.&lt;/p&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;2.3. Model Hyperparameters&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;p&gt;Key configurations for the two model sizes are detailed below:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Parameter&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;EXAONE 4.0 32B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;EXAONE 4.0 1.2B&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Model Size&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;32.0B&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1.2B&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;&lt;code&gt;d_model&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;5,120&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2,048&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Num. Layers&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;64&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;30&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Attention Type&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Hybrid&lt;/strong&gt; (3:1 Local:Global)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Global&lt;/strong&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Head Type&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Grouped-Query Attention (GQA)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Grouped-Query Attention (GQA)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Num. Heads (KV)&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;40 (8)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;32 (8)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Max Context&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;128K&lt;/strong&gt; (131,072)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;64K&lt;/strong&gt; (65,536)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Normalization&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;QK-Reorder-LN&lt;/strong&gt; (RMSNorm)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;QK-Reorder-LN&lt;/strong&gt; (RMSNorm)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Non-linearity&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;SwiGLU&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;SwiGLU&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Tokenizer&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;BBPE (102,400 vocab size)&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;BBPE (102,400 vocab size)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;Knowledge Cut-off&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Nov. 2024&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Nov. 2024&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;h3&gt;3. Training Pipeline&lt;/h3&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;3.1. Pre-training&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;  &lt;strong&gt;Data Scale:&lt;/strong&gt; The 32B model was pre-trained on &lt;strong&gt;14 trillion tokens&lt;/strong&gt;, a twofold increase from its predecessor (EXAONE 3.5). This was specifically aimed at enhancing world knowledge and reasoning.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Data Curation:&lt;/strong&gt; Rigorous data curation was performed, focusing on documents exhibiting &amp;quot;cognitive behavior&amp;quot; and specialized STEM data to improve reasoning performance.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;3.2. Context Length Extension&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;p&gt;A two-stage, validated process was used to extend the context window.\\n1.  &lt;strong&gt;Stage 1:&lt;/strong&gt; The model pre-trained with a 4K context was extended to &lt;strong&gt;32K&lt;/strong&gt;.\\n2.  &lt;strong&gt;Stage 2:&lt;/strong&gt; The 32K model was further extended to &lt;strong&gt;128K&lt;/strong&gt; (for the 32B model) and &lt;strong&gt;64K&lt;/strong&gt; (for the 1.2B model).\\n*   &lt;strong&gt;Validation:&lt;/strong&gt; The &lt;strong&gt;Needle In A Haystack (NIAH)&lt;/strong&gt; test was used iteratively at each stage to ensure performance was not compromised during the extension.&lt;/p&gt;\\n\\n&lt;h4&gt;&lt;strong&gt;3.3. Post-training and Alignment&lt;/strong&gt;&lt;/h4&gt;\\n\\n&lt;p&gt;The post-training pipeline (Figure 3) is a multi-stage process designed to create the unified dual-mode model.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Large-Scale Supervised Fine-Tuning (SFT):&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;  &lt;strong&gt;Unified Mode Training:&lt;/strong&gt; The model is trained on a combined dataset for both NON-REASONING (diverse general tasks) and REASONING (Math, Code, Logic) modes.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Data Ratio:&lt;/strong&gt; An ablation-tested token ratio of &lt;strong&gt;1.5 (Reasoning) : 1 (Non-Reasoning)&lt;/strong&gt; is used to balance the modes and prevent the model from defaulting to reasoning-style generation.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Domain-Specific SFT:&lt;/strong&gt; A second SFT round is performed on high-quality Code and Tool Use data to address domain imbalance.&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reasoning Reinforcement Learning (RL):&lt;/strong&gt;\\nA novel algorithm, &lt;strong&gt;AGAPO (Asymmetric Sampling and Global Advantage Policy Optimization)&lt;/strong&gt;, was developed to enhance reasoning. It improves upon GRPO with several key features:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;  &lt;strong&gt;Removed Clipped Objective:&lt;/strong&gt; Replaces PPO&amp;#39;s clipped loss with a standard policy gradient loss to allow for more substantial updates from low-probability &amp;quot;exploratory&amp;quot; tokens crucial for reasoning paths.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Asymmetric Sampling:&lt;/strong&gt; Unlike methods that discard samples where all generated responses are incorrect, AGAPO retains them, using them as negative feedback to guide the model away from erroneous paths.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Group &amp;amp; Global Advantages:&lt;/strong&gt; A two-stage advantage calculation. First, a Leave-One-Out (LOO) advantage is computed within a group of responses. This is then normalized across the entire batch (global) to provide a more robust final advantage score.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Sequence-Level Cumulative KL:&lt;/strong&gt; A KL penalty is applied at the sequence level to maintain the capabilities learned during SFT while optimizing for the RL objective.&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Preference Learning with Hybrid Reward:&lt;/strong&gt;\\nTo refine the model and align it with human preferences, a two-stage preference learning phase using the &lt;code&gt;SimPER&lt;/code&gt; framework is conducted.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;  &lt;strong&gt;Stage 1 (Efficiency):&lt;/strong&gt; A hybrid reward combining &lt;strong&gt;verifiable reward (correctness) and a conciseness reward&lt;/strong&gt; is used. This encourages the model to select the shortest correct answer, improving token efficiency.&lt;/li&gt;\\n&lt;li&gt;  &lt;strong&gt;Stage 2 (Alignment):&lt;/strong&gt; A hybrid reward combining &lt;strong&gt;preference reward and language consistency reward&lt;/strong&gt; is used for human alignment.&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n3781c5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550469,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n372hbm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752548269,"send_replies":true,"parent_id":"t1_n36zk7n","score":12,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a 32B model, I'd sure hope R1 and Kimi-K2 is better...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n372hbm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a 32B model, I&amp;#39;d sure hope R1 and Kimi-K2 is better...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n372hbm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548269,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n370c8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1752547480,"send_replies":true,"parent_id":"t1_n36zk7n","score":5,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What kind of GPU do you have that have enough VRAM to accommodate those models?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n370c8t","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What kind of GPU do you have that have enough VRAM to accommodate those models?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m04a20","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n370c8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547480,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n36zk7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"balianone","can_mod_post":false,"created_utc":1752547196,"send_replies":true,"parent_id":"t3_1m04a20","score":-10,"author_fullname":"t2_8pgou3uq9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"not good. kimi 2 &amp; deepseek r1 is better","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36zk7n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;not good. kimi 2 &amp;amp; deepseek r1 is better&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m04a20/exaone_40_32b/n36zk7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752547196,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m04a20","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-10}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
