import{j as e}from"./index-CNyNkRpk.js";import{R as l}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey guys, I am trying to use the new OpenAI Responses API with ollama. However, I get a \\n\\n\`raise self._make_status_error_from_response(err.response) from None\`\\n\\n\`openai.NotFoundError: 404 page not found\`\\n\\n\\n\\nMy code is basically this:\\n\\n    from openai import OpenAI\\n    \\n    client = OpenAI(api_key=\\"Hello\\",\\n                    base_url=\\"http://localhost:11434/v1\\")\\n    \\n    \\n    response = client.responses.create(\\n        model=\\"llama3.2\\",\\n        input=\\"Talk me about apples\\")\\n    \\n    print(response.output)\\n\\nThe ollama server is successfully running at [http://localhost:11434/](http://localhost:11434/)\\n\\nDoes the responses API work with Ollama?\\n\\n**Edit**: Added /v1 to the URL (but still the same error).","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Does the OpenAI Responses API work with Ollama?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lwb5py","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.33,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1k0rn65e6g","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752150092,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752149623,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey guys, I am trying to use the new OpenAI Responses API with ollama. However, I get a &lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;raise self._make_status_error_from_response(err.response) from None&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;openai.NotFoundError: 404 page not found&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;My code is basically this:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;from openai import OpenAI\\n\\nclient = OpenAI(api_key=&amp;quot;Hello&amp;quot;,\\n                base_url=&amp;quot;http://localhost:11434/v1&amp;quot;)\\n\\n\\nresponse = client.responses.create(\\n    model=&amp;quot;llama3.2&amp;quot;,\\n    input=&amp;quot;Talk me about apples&amp;quot;)\\n\\nprint(response.output)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;The ollama server is successfully running at &lt;a href=\\"http://localhost:11434/\\"&gt;http://localhost:11434/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Does the responses API work with Ollama?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt;: Added /v1 to the URL (but still the same error).&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lwb5py","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"These-South-8284","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/","subreddit_subscribers":497354,"created_utc":1752149623,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cnynl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-South-8284","can_mod_post":false,"created_utc":1752150186,"send_replies":true,"parent_id":"t1_n2cnctf","score":1,"author_fullname":"t2_1k0rn65e6g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, but I already tried that too and I get the same error.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cnynl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, but I already tried that too and I get the same error.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cnynl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150186,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cnctf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Somms1978","can_mod_post":false,"created_utc":1752149962,"send_replies":true,"parent_id":"t3_1lwb5py","score":1,"author_fullname":"t2_2pbcnc12","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try using this base\\\\_url:\\n\\n    http://localhost:11434/v1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cnctf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try using this base_url:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;http://localhost:11434/v1\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cnctf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752149962,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwb5py","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cqbn2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GortKlaatu_","can_mod_post":false,"created_utc":1752151052,"send_replies":true,"parent_id":"t3_1lwb5py","score":2,"author_fullname":"t2_ixeagk4w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unless I missed something, I don't believe the responses API is supported in Ollama or llama.cpp.\\n\\n  \\n[https://github.com/ollama/ollama/issues/10309](https://github.com/ollama/ollama/issues/10309)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cqbn2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless I missed something, I don&amp;#39;t believe the responses API is supported in Ollama or llama.cpp.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ollama/ollama/issues/10309\\"&gt;https://github.com/ollama/ollama/issues/10309&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cqbn2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151052,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwb5py","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cvum3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Altruistic_Heat_9531","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2csee2","score":1,"author_fullname":"t2_9sh0mgya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ouhhhhh yeah..... ollama might not support it yet. for a mean time just use completion","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cvum3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ouhhhhh yeah..... ollama might not support it yet. for a mean time just use completion&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cvum3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752152959,"author_flair_text":null,"treatment_tags":[],"created_utc":1752152959,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2csee2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-South-8284","can_mod_post":false,"created_utc":1752151790,"send_replies":true,"parent_id":"t1_n2cqkde","score":1,"author_fullname":"t2_1k0rn65e6g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am using the responses API though, not the completions API.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2csee2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am using the responses API though, not the completions API.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2csee2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151790,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cqkde","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Altruistic_Heat_9531","can_mod_post":false,"created_utc":1752151139,"send_replies":true,"parent_id":"t3_1lwb5py","score":1,"author_fullname":"t2_9sh0mgya","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"model name, some ollama model has \\"latest\\" sting attached to it so  \\n\\"llama3.2:latest\\" . I dont have it since i custom import GGUF not from Ollama repo\\n\\n  \\ncurl [http://localhost:11434/v1/models](http://localhost:11434/v1/models)\\n\\n{\\"object\\":\\"list\\",\\"data\\":\\n\\n\\\\[{\\"id\\":\\"**LLama-3.1-indonesia:latest**\\",\\"object\\":\\"model\\",\\"created\\":1749884017,\\"owned\\\\_by\\":\\"library\\"},\\n\\n{\\"id\\":\\"qwen2.5:7b\\",\\"object\\":\\"model\\",\\"created\\":1747140802,\\"owned\\\\_by\\":\\"library\\"},{\\"id\\":\\"qwen3:30b-a3b\\",\\"object\\":\\"model\\",\\"created\\":1745938742,\\"owned\\\\_by\\":\\"library\\"},\\n\\n{\\"id\\":\\"qwen3:8b\\",\\"object\\":\\"model\\",\\"created\\":1745931065,\\"owned\\\\_by\\":\\"library\\"},\\n\\n{\\"id\\":\\"qwen3:14b\\",\\"object\\":\\"model\\",\\"created\\":1745905295,\\"owned\\\\_by\\":\\"library\\"},{\\"id\\":\\"mistral-small3.1:24b\\",\\"object\\":\\"model\\",\\"created\\":1745760416,\\"owned\\\\_by\\":\\"library\\"}\\\\]}\\n\\n\\n\\n  \\n\\n\\n    C:\\\\Windows\\\\System32&gt;curl -X POST http://localhost:11434/v1/chat/completions -H \\"Content-Type: application/json\\" -d \\"{ \\\\\\"model\\\\\\": \\\\\\"LLama-3.1-indonesia:latest\\\\\\", \\\\\\"messages\\\\\\": [ { \\\\\\"role\\\\\\": \\\\\\"user\\\\\\", \\\\\\"content\\\\\\": \\\\\\"Say hello\\\\\\" } ] }\\"\\n    {\\"id\\":\\"chatcmpl-886\\",\\"object\\":\\"chat.completion\\",\\"created\\":1752151053,\\"model\\":\\"qwen2.5:7b\\",\\"system_fingerprint\\":\\"fp_ollama\\",\\"choices\\":[{\\"index\\":0,\\"message\\":{\\"role\\":\\"assistant\\",\\"content\\":\\"Hello! Nice to meet you. How can I assist you today?\\"},\\"finish_reason\\":\\"stop\\"}],\\"usage\\":{\\"prompt_tokens\\":31,\\"completion_tokens\\":15,\\"total_tokens\\":46}}","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cqkde","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;model name, some ollama model has &amp;quot;latest&amp;quot; sting attached to it so&lt;br/&gt;\\n&amp;quot;llama3.2:latest&amp;quot; . I dont have it since i custom import GGUF not from Ollama repo&lt;/p&gt;\\n\\n&lt;p&gt;curl &lt;a href=\\"http://localhost:11434/v1/models\\"&gt;http://localhost:11434/v1/models&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;{&amp;quot;object&amp;quot;:&amp;quot;list&amp;quot;,&amp;quot;data&amp;quot;:&lt;/p&gt;\\n\\n&lt;p&gt;[{&amp;quot;id&amp;quot;:&amp;quot;&lt;strong&gt;LLama-3.1-indonesia:latest&lt;/strong&gt;&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1749884017,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;},&lt;/p&gt;\\n\\n&lt;p&gt;{&amp;quot;id&amp;quot;:&amp;quot;qwen2.5:7b&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1747140802,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;},{&amp;quot;id&amp;quot;:&amp;quot;qwen3:30b-a3b&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1745938742,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;},&lt;/p&gt;\\n\\n&lt;p&gt;{&amp;quot;id&amp;quot;:&amp;quot;qwen3:8b&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1745931065,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;},&lt;/p&gt;\\n\\n&lt;p&gt;{&amp;quot;id&amp;quot;:&amp;quot;qwen3:14b&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1745905295,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;},{&amp;quot;id&amp;quot;:&amp;quot;mistral-small3.1:24b&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;model&amp;quot;,&amp;quot;created&amp;quot;:1745760416,&amp;quot;owned_by&amp;quot;:&amp;quot;library&amp;quot;}]}&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;C:\\\\Windows\\\\System32&amp;gt;curl -X POST http://localhost:11434/v1/chat/completions -H &amp;quot;Content-Type: application/json&amp;quot; -d &amp;quot;{ \\\\&amp;quot;model\\\\&amp;quot;: \\\\&amp;quot;LLama-3.1-indonesia:latest\\\\&amp;quot;, \\\\&amp;quot;messages\\\\&amp;quot;: [ { \\\\&amp;quot;role\\\\&amp;quot;: \\\\&amp;quot;user\\\\&amp;quot;, \\\\&amp;quot;content\\\\&amp;quot;: \\\\&amp;quot;Say hello\\\\&amp;quot; } ] }&amp;quot;\\n{&amp;quot;id&amp;quot;:&amp;quot;chatcmpl-886&amp;quot;,&amp;quot;object&amp;quot;:&amp;quot;chat.completion&amp;quot;,&amp;quot;created&amp;quot;:1752151053,&amp;quot;model&amp;quot;:&amp;quot;qwen2.5:7b&amp;quot;,&amp;quot;system_fingerprint&amp;quot;:&amp;quot;fp_ollama&amp;quot;,&amp;quot;choices&amp;quot;:[{&amp;quot;index&amp;quot;:0,&amp;quot;message&amp;quot;:{&amp;quot;role&amp;quot;:&amp;quot;assistant&amp;quot;,&amp;quot;content&amp;quot;:&amp;quot;Hello! Nice to meet you. How can I assist you today?&amp;quot;},&amp;quot;finish_reason&amp;quot;:&amp;quot;stop&amp;quot;}],&amp;quot;usage&amp;quot;:{&amp;quot;prompt_tokens&amp;quot;:31,&amp;quot;completion_tokens&amp;quot;:15,&amp;quot;total_tokens&amp;quot;:46}}\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cqkde/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151139,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwb5py","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cooeq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-South-8284","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2co8mm","score":1,"author_fullname":"t2_1k0rn65e6g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Doesn't the response API support llama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cooeq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doesn&amp;#39;t the response API support llama?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cooeq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150451,"author_flair_text":null,"treatment_tags":[],"created_utc":1752150451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2co8mm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cnlec","score":1,"author_fullname":"t2_e9jh97s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah, you're using new response OpenAI api. You have to use chat.completion api.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2co8mm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah, you&amp;#39;re using new response OpenAI api. You have to use chat.completion api.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2co8mm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150288,"author_flair_text":null,"treatment_tags":[],"created_utc":1752150288,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cotmh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cnlec","score":1,"author_fullname":"t2_e9jh97s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're using the new response API: client.responses.create. You have to use client.chat.completions.create.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cotmh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re using the new response API: client.responses.create. You have to use client.chat.completions.create.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cotmh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150505,"author_flair_text":null,"treatment_tags":[],"created_utc":1752150505,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cnlec","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"These-South-8284","can_mod_post":false,"created_utc":1752150050,"send_replies":true,"parent_id":"t1_n2cn9d5","score":1,"author_fullname":"t2_1k0rn65e6g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I had tried that too. It's the same error.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cnlec","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had tried that too. It&amp;#39;s the same error.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwb5py","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cnlec/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752150050,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cn9d5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"created_utc":1752149925,"send_replies":true,"parent_id":"t3_1lwb5py","score":0,"author_fullname":"t2_e9jh97s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you forgot /v1 at the end.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cn9d5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you forgot /v1 at the end.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwb5py/does_the_openai_responses_api_work_with_ollama/n2cn9d5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752149925,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwb5py","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
