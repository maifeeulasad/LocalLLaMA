import{j as e}from"./index-Bu7qcPAU.js";import{R as t}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Down a deep rabbit hole of prompt eng, fine tuning w Unsloth, but not getting any great results.\\n\\nMy use case: Creating social content which sounds like me, not AI slop.\\n\\nWhat's the best way to do this nowadays? Would appreciate any direction\\n\\nEdit for more context: Right now I'm generating content with a powerful model, then I'm aiming to do the 'styling' in a final call.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Best way to get an LLM to sound like me? Prompt eng or Finetune?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lqmmv2","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.83,"author_flair_background_color":null,"subreddit_type":"public","ups":12,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_165nf2mrsb","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":12,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751543339,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751540252,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Down a deep rabbit hole of prompt eng, fine tuning w Unsloth, but not getting any great results.&lt;/p&gt;\\n\\n&lt;p&gt;My use case: Creating social content which sounds like me, not AI slop.&lt;/p&gt;\\n\\n&lt;p&gt;What&amp;#39;s the best way to do this nowadays? Would appreciate any direction&lt;/p&gt;\\n\\n&lt;p&gt;Edit for more context: Right now I&amp;#39;m generating content with a powerful model, then I&amp;#39;m aiming to do the &amp;#39;styling&amp;#39; in a final call.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lqmmv2","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"RelevantPractice2074","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/","subreddit_subscribers":494198,"created_utc":1751540252,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n140bwx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RelevantPractice2074","can_mod_post":false,"created_utc":1751543414,"send_replies":true,"parent_id":"t1_n13tnfe","score":2,"author_fullname":"t2_165nf2mrsb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks. Any best practices for fine-tuning? Tried a 5-10 times and the model always ends up changing the meaning of the tweet or post I'm giving it rather than just making it sound 'like me' \\n\\nProbably down to bad synthetic training data, idk","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n140bwx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks. Any best practices for fine-tuning? Tried a 5-10 times and the model always ends up changing the meaning of the tweet or post I&amp;#39;m giving it rather than just making it sound &amp;#39;like me&amp;#39; &lt;/p&gt;\\n\\n&lt;p&gt;Probably down to bad synthetic training data, idk&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqmmv2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n140bwx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751543414,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n13tnfe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teleolurian","can_mod_post":false,"created_utc":1751540464,"send_replies":true,"parent_id":"t3_1lqmmv2","score":5,"author_fullname":"t2_5jl5q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For style, both - train a LoRA on the small model which performs best and then give additional direction in the system prompt. Models like Dobby Unhinged are quite good at their roles","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13tnfe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For style, both - train a LoRA on the small model which performs best and then give additional direction in the system prompt. Models like Dobby Unhinged are quite good at their roles&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n13tnfe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751540464,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqmmv2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n146rox","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dbuildofficial","can_mod_post":false,"send_replies":true,"parent_id":"t1_n140hua","score":1,"author_fullname":"t2_5k8ox0g9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeeeah... I usually end up fixing a few stuff anyway so I stop when I see a path to completion and finish by hand :/","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n146rox","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeeeah... I usually end up fixing a few stuff anyway so I stop when I see a path to completion and finish by hand :/&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqmmv2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n146rox/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751545930,"author_flair_text":null,"treatment_tags":[],"created_utc":1751545930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n140hua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RelevantPractice2074","can_mod_post":false,"created_utc":1751543479,"send_replies":true,"parent_id":"t1_n13ufbi","score":2,"author_fullname":"t2_165nf2mrsb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I've also been calling models with a dump of my content. It kinda works, but kinda isn't good enough\\n\\nMy best success atm is using a reasoning model to iterate on a single piece of content until it's 9/10 in sounding like me.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n140hua","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I&amp;#39;ve also been calling models with a dump of my content. It kinda works, but kinda isn&amp;#39;t good enough&lt;/p&gt;\\n\\n&lt;p&gt;My best success atm is using a reasoning model to iterate on a single piece of content until it&amp;#39;s 9/10 in sounding like me.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqmmv2","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n140hua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751543479,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n13ufbi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dbuildofficial","can_mod_post":false,"created_utc":1751540829,"send_replies":true,"parent_id":"t3_1lqmmv2","score":3,"author_fullname":"t2_5k8ox0g9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would not mind the advice too.  \\nI tried with local models but I just don't have enough vram to feed context therefore results are.... mediocre at best\\n\\nwhat i do right now is I use a local model to search and layout ideas, give it a quick check/fix and then feed all that to gemini 2.0 flash with a relevant dump of MY content (no AI there)\\n\\nIt is not perfect and in progress but I hope to \\"automate\\" the social media churn for [https://litechat.dev/](https://litechat.dev/) (i am a inge-near, not a influensite )","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13ufbi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would not mind the advice too.&lt;br/&gt;\\nI tried with local models but I just don&amp;#39;t have enough vram to feed context therefore results are.... mediocre at best&lt;/p&gt;\\n\\n&lt;p&gt;what i do right now is I use a local model to search and layout ideas, give it a quick check/fix and then feed all that to gemini 2.0 flash with a relevant dump of MY content (no AI there)&lt;/p&gt;\\n\\n&lt;p&gt;It is not perfect and in progress but I hope to &amp;quot;automate&amp;quot; the social media churn for &lt;a href=\\"https://litechat.dev/\\"&gt;https://litechat.dev/&lt;/a&gt; (i am a inge-near, not a influensite )&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n13ufbi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751540829,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqmmv2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n148fr8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1751546542,"send_replies":true,"parent_id":"t3_1lqmmv2","score":3,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Start by giving it examples and see where you end up. I usually make them sound like *other people*. 1k of example messages tends to be enough. Training a lora seems like overkill. Make sure you instruct it to reply like the examples.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n148fr8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Start by giving it examples and see where you end up. I usually make them sound like &lt;em&gt;other people&lt;/em&gt;. 1k of example messages tends to be enough. Training a lora seems like overkill. Make sure you instruct it to reply like the examples.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n148fr8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751546542,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqmmv2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14ifjo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1751549943,"send_replies":true,"parent_id":"t3_1lqmmv2","score":3,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried simply giving examples (writing samples) in context before tasking?\\n\\nOr try workshopping a few chat interactions back and forth in a simple LLM UI, maybe also pasting in some writing samples.  Task it, then give it editor's remarks to correct it and ask it again. Once you have a chat interaction that works, just reuse it as context for future individual tasks.\\n\\nI'd start with, \\n\\n    Here are a number of writing samples: [paste in a few dozen samples]\\n    I want you to write a social media post about [xyz]\\"\\n\\nllm responds...\\n\\n    I think [this or that] is not the proper style. Try to correct.\\n\\nor\\n\\n    Here's what I actually would like for this task: [write it]\\n    Here's a new task, try to mimic my writing style:  Write a [post about ABC]\\n\\nAnother technique would be to write prompts for things you already wrote, and you can paste in your real samples as if it was the LLM responding.  Ex. LM Studio simply allows you to edit the LLM output blocks, or you can use API and literally paste in your own data in the assistant response fields and use that as prefilled history.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14ifjo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried simply giving examples (writing samples) in context before tasking?&lt;/p&gt;\\n\\n&lt;p&gt;Or try workshopping a few chat interactions back and forth in a simple LLM UI, maybe also pasting in some writing samples.  Task it, then give it editor&amp;#39;s remarks to correct it and ask it again. Once you have a chat interaction that works, just reuse it as context for future individual tasks.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d start with, &lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Here are a number of writing samples: [paste in a few dozen samples]\\nI want you to write a social media post about [xyz]&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;llm responds...&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;I think [this or that] is not the proper style. Try to correct.\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;or&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Here&amp;#39;s what I actually would like for this task: [write it]\\nHere&amp;#39;s a new task, try to mimic my writing style:  Write a [post about ABC]\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Another technique would be to write prompts for things you already wrote, and you can paste in your real samples as if it was the LLM responding.  Ex. LM Studio simply allows you to edit the LLM output blocks, or you can use API and literally paste in your own data in the assistant response fields and use that as prefilled history.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqmmv2/best_way_to_get_an_llm_to_sound_like_me_prompt/n14ifjo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751549943,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqmmv2","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
