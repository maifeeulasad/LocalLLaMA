import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I want to test this on something brutal. You give me your hardest technical challenge, I’ll build a specialized AI for it this weekend and release it here for everyone.\\n\\nWhat I’m looking for:\\n\\n - Extremely niche technical problems\\n - Challenges where current LLMs completely fail\\n - Tasks that normally require 10+ years of expertise\\n - The more “impossible” the better \\n\\nExamples of the difficulty level I want:\\n\\n - AI that optimizes CUDA kernels for specific GPU architectures\\n - AI that diagnoses and fixes race conditions in concurrent code\\n - AI that ports assembly between different architectures\\n - AI that generates efficient Vulkan/Metal shaders from descriptions\\n\\nWhat happens:\\n\\n - Most upvoted challenge by Friday 6PM EST wins\\n - I build it over the weekend\\n - I come back Monday with the working system\\n - You all get to stress-test it with your edge cases\\n - If it works, everyone gets access to use it\\n\\nNot selling anything. Just want to see if this handles your worst problems.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I’ll build an expert AI for your impossible challenge and give it away free - looking for the hardest technical problem you’ve got","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2ml3n","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.65,"author_flair_background_color":null,"subreddit_type":"public","ups":29,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1khzsxj24m","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":29,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752794398,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to test this on something brutal. You give me your hardest technical challenge, I’ll build a specialized AI for it this weekend and release it here for everyone.&lt;/p&gt;\\n\\n&lt;p&gt;What I’m looking for:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Extremely niche technical problems&lt;/li&gt;\\n&lt;li&gt;Challenges where current LLMs completely fail&lt;/li&gt;\\n&lt;li&gt;Tasks that normally require 10+ years of expertise&lt;/li&gt;\\n&lt;li&gt;The more “impossible” the better &lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Examples of the difficulty level I want:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;AI that optimizes CUDA kernels for specific GPU architectures&lt;/li&gt;\\n&lt;li&gt;AI that diagnoses and fixes race conditions in concurrent code&lt;/li&gt;\\n&lt;li&gt;AI that ports assembly between different architectures&lt;/li&gt;\\n&lt;li&gt;AI that generates efficient Vulkan/Metal shaders from descriptions&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;What happens:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Most upvoted challenge by Friday 6PM EST wins&lt;/li&gt;\\n&lt;li&gt;I build it over the weekend&lt;/li&gt;\\n&lt;li&gt;I come back Monday with the working system&lt;/li&gt;\\n&lt;li&gt;You all get to stress-test it with your edge cases&lt;/li&gt;\\n&lt;li&gt;If it works, everyone gets access to use it&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Not selling anything. Just want to see if this handles your worst problems.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m2ml3n","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Prestigious-Fan118","discussion_type":null,"num_comments":135,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/","subreddit_subscribers":500896,"created_utc":1752794398,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uq4fs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-dysangel-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q9a72","score":1,"author_fullname":"t2_12ggykute6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"doesn't sound very impossible tbh, it's a perfect use case for LLMs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3uq4fs","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;doesn&amp;#39;t sound very impossible tbh, it&amp;#39;s a perfect use case for LLMs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3uq4fs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752860053,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752860053,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q9a72","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1752797295,"send_replies":true,"parent_id":"t1_n3q4xjh","score":40,"author_fullname":"t2_8fu8sqhz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I second this: niche, technical, impossible, yet rather easy to understand and to test","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q9a72","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I second this: niche, technical, impossible, yet rather easy to understand and to test&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q9a72/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797295,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qbv4w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dinerburgeryum","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qan3v","score":17,"author_fullname":"t2_1j53p3yv3e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea, OP, I feel like this is a winner.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qbv4w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, OP, I feel like this is a winner.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qbv4w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752798208,"author_flair_text":null,"treatment_tags":[],"created_utc":1752798208,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tmgpi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Brainlag","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qan3v","score":3,"author_fullname":"t2_4oasu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes I was assuming it would use available disassemblers and reverse engineering tools.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3tmgpi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes I was assuming it would use available disassemblers and reverse engineering tools.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tmgpi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752848896,"author_flair_text":null,"treatment_tags":[],"created_utc":1752848896,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qr9dw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qan3v","score":-2,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP won't do the decompiler, the transformer will learn it","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qr9dw","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP won&amp;#39;t do the decompiler, the transformer will learn it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qr9dw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803739,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752803739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qan3v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1752797773,"send_replies":true,"parent_id":"t1_n3q4xjh","score":58,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What about a middleground?\\n\\nAn LLM that can read the current decompiled machine jumble and rewrite it as fully-commented code that labels what everything does or is for?\\n\\nProbably nearly as monumental a task - but at least OP wouldn't be tasked with doing the decompiler part","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qan3v","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about a middleground?&lt;/p&gt;\\n\\n&lt;p&gt;An LLM that can read the current decompiled machine jumble and rewrite it as fully-commented code that labels what everything does or is for?&lt;/p&gt;\\n\\n&lt;p&gt;Probably nearly as monumental a task - but at least OP wouldn&amp;#39;t be tasked with doing the decompiler part&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qan3v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797773,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":58}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rtfqb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clockish","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qezmr","score":3,"author_fullname":"t2_cohd9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not an assessment of those specific tools, but I can confirm that the capabilities shown in their demo videos (assigning reasonable &amp; helpful default names within decompiled code, and semi-automatically solving VERY in-distribution crackmes) are in fact totally realistic.\\n\\n...I'd give a better source than \\"trust me bro\\" if I could but the only one I recall right now is [OpenAI including words about o1's limited success with cybersecurity challenges](https://cdn.openai.com/o1-system-card.pdf#page=14), which would have included crackmes like the one in the current suidpit/ghidra-mcp demo video.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rtfqb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not an assessment of those specific tools, but I can confirm that the capabilities shown in their demo videos (assigning reasonable &amp;amp; helpful default names within decompiled code, and semi-automatically solving VERY in-distribution crackmes) are in fact totally realistic.&lt;/p&gt;\\n\\n&lt;p&gt;...I&amp;#39;d give a better source than &amp;quot;trust me bro&amp;quot; if I could but the only one I recall right now is &lt;a href=\\"https://cdn.openai.com/o1-system-card.pdf#page=14\\"&gt;OpenAI including words about o1&amp;#39;s limited success with cybersecurity challenges&lt;/a&gt;, which would have included crackmes like the one in the current suidpit/ghidra-mcp demo video.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rtfqb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820353,"author_flair_text":null,"treatment_tags":[],"created_utc":1752820353,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tc07r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amazing_Trace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3t35y5","score":1,"author_fullname":"t2_cltk5172","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I meant OP would be the first to build an LLM for it.\\n\\nOfcourse REs have been working on this a long time! I also work in this space hello fellow researcher!","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3tc07r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I meant OP would be the first to build an LLM for it.&lt;/p&gt;\\n\\n&lt;p&gt;Ofcourse REs have been working on this a long time! I also work in this space hello fellow researcher!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tc07r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752845757,"author_flair_text":null,"treatment_tags":[],"created_utc":1752845757,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3t35y5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rhlqf","score":1,"author_fullname":"t2_13jvln","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Op would not be the first if we are thinking of the same thing.  I *sponsored* this research at government funded university affiliated research labs. It's pretty much solved now. It was nearly solved before LLMs.\\n\\nEdit: this isn't to say that op wouldn't build a useful thing with this goal. Software is never finished and I'm sure they (or the LLM they're using as a stand in for expertise) could come up with genuine improvements in usability.","edited":1752843249,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3t35y5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Op would not be the first if we are thinking of the same thing.  I &lt;em&gt;sponsored&lt;/em&gt; this research at government funded university affiliated research labs. It&amp;#39;s pretty much solved now. It was nearly solved before LLMs.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: this isn&amp;#39;t to say that op wouldn&amp;#39;t build a useful thing with this goal. Software is never finished and I&amp;#39;m sure they (or the LLM they&amp;#39;re using as a stand in for expertise) could come up with genuine improvements in usability.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3t35y5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752842885,"author_flair_text":null,"treatment_tags":[],"created_utc":1752842885,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rhlqf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Amazing_Trace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qxh3s","score":3,"author_fullname":"t2_cltk5172","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP would be the first one to do it, I know several research labs at schools like OSU AND UCI that are working on this problem \\n\\nBut there is not really a simplistic model for reverse engineering instruction to code, specially as obfuscation exists in most closed-source binaries so you basically have to assemble a dataset with open source binaries only and then the translation layer between code and instructional language is still very dependent on factors like systems,  os version, and devices it was built/compiled for.\\n\\nWindow's dumbass way of centralizing configs using registry and dll sure doesn't help.","edited":false,"author_flair_css_class":null,"name":"t1_n3rhlqf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP would be the first one to do it, I know several research labs at schools like OSU AND UCI that are working on this problem &lt;/p&gt;\\n\\n&lt;p&gt;But there is not really a simplistic model for reverse engineering instruction to code, specially as obfuscation exists in most closed-source binaries so you basically have to assemble a dataset with open source binaries only and then the translation layer between code and instructional language is still very dependent on factors like systems,  os version, and devices it was built/compiled for.&lt;/p&gt;\\n\\n&lt;p&gt;Window&amp;#39;s dumbass way of centralizing configs using registry and dll sure doesn&amp;#39;t help.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rhlqf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752814401,"author_flair_text":null,"collapsed":false,"created_utc":1752814401,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qxh3s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"newtopost","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qrms1","score":1,"author_fullname":"t2_1k20wdbpxk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ah, that makes sense. Instructions that could help OP's model write the code for you, though!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qxh3s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah, that makes sense. Instructions that could help OP&amp;#39;s model write the code for you, though!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qxh3s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806027,"author_flair_text":null,"treatment_tags":[],"created_utc":1752806027,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tf3ac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qrms1","score":1,"author_fullname":"t2_13jvln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"?\\nGhidras decompiler lifts to C from ghidras p-code, a SSA IR that it uses which is arch agnostic.\\n\\nInstruction decoding is a separate, partially unsolved (even for x86) problem. Which is fascinating in its own right, that there are a bunch of libraries that decode instructions, and they don't all agree.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tf3ac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;?\\nGhidras decompiler lifts to C from ghidras p-code, a SSA IR that it uses which is arch agnostic.&lt;/p&gt;\\n\\n&lt;p&gt;Instruction decoding is a separate, partially unsolved (even for x86) problem. Which is fascinating in its own right, that there are a bunch of libraries that decode instructions, and they don&amp;#39;t all agree.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tf3ac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752846713,"author_flair_text":null,"treatment_tags":[],"created_utc":1752846713,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qrms1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amazing_Trace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qezmr","score":3,"author_fullname":"t2_cltk5172","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ghidra decompiles to instructions not code","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qrms1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ghidra decompiles to instructions not code&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qrms1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803873,"author_flair_text":null,"treatment_tags":[],"created_utc":1752803873,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qezmr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"newtopost","can_mod_post":false,"created_utc":1752799324,"send_replies":true,"parent_id":"t1_n3q4xjh","score":7,"author_fullname":"t2_1k20wdbpxk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is neat. I don't know anything about decomp but I've seen some videos where they talk about Ghidra. \\n\\nIt looks like people have already made some Ghidra Model Context Protocol servers:\\n\\n[github.com/LaurieWired/GhidraMCP LaurieWired/GhidraMCP](https://github.com/LaurieWired/GhidraMCP)\\n\\n[github.com/suidpit/ghidra-mcpsuidpit/ghidra-mcp](https://github.com/suidpit/ghidra-mcp)\\n\\nI'd be curious to hear a real Ghidra user's assessment of those tools","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qezmr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is neat. I don&amp;#39;t know anything about decomp but I&amp;#39;ve seen some videos where they talk about Ghidra. &lt;/p&gt;\\n\\n&lt;p&gt;It looks like people have already made some Ghidra Model Context Protocol servers:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/LaurieWired/GhidraMCP\\"&gt;github.com/LaurieWired/GhidraMCP LaurieWired/GhidraMCP&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/suidpit/ghidra-mcp\\"&gt;github.com/suidpit/ghidra-mcpsuidpit/ghidra-mcp&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d be curious to hear a real Ghidra user&amp;#39;s assessment of those tools&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qezmr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799324,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qrg7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Amazing_Trace","can_mod_post":false,"created_utc":1752803807,"send_replies":true,"parent_id":"t1_n3q4xjh","score":4,"author_fullname":"t2_cltk5172","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes, do Reverse engineering + deobfuscation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qrg7n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, do Reverse engineering + deobfuscation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qrg7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803807,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q4xjh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Brainlag","can_mod_post":false,"created_utc":1752795781,"send_replies":true,"parent_id":"t3_1m2ml3n","score":174,"author_fullname":"t2_4oasu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that decompiles binaries into human readable code. And I mean the code should look like the real, human written code. Not like this abstract code current decompiler tools generate.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q4xjh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that decompiles binaries into human readable code. And I mean the code should look like the real, human written code. Not like this abstract code current decompiler tools generate.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q4xjh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795781,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":174}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s97p1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Revolutionary-Bat310","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s7xzx","score":1,"author_fullname":"t2_bkmd5muq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can, we have multiple PDFs that we process through AWS Textract, but we display them in our own UI. The challenge is to capture the original format and be able to edit in real time.\\n\\nsend me the link where i can drop it","edited":false,"author_flair_css_class":null,"name":"t1_n3s97p1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can, we have multiple PDFs that we process through AWS Textract, but we display them in our own UI. The challenge is to capture the original format and be able to edit in real time.&lt;/p&gt;\\n\\n&lt;p&gt;send me the link where i can drop it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s97p1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752829151,"author_flair_text":null,"collapsed":false,"created_utc":1752829151,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s7xzx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jazzlike_Use6242","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rscia","score":1,"author_fullname":"t2_uao4xuo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Send me ur pdf that u don’t think can be done","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s7xzx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Send me ur pdf that u don’t think can be done&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s7xzx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828425,"author_flair_text":null,"treatment_tags":[],"created_utc":1752828425,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sdg9b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hazed-and-dazed","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rscia","score":1,"author_fullname":"t2_ckgdw3y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LlamaParse and then run the md on LLM powered guardrail to catch anything g unexpected","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sdg9b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LlamaParse and then run the md on LLM powered guardrail to catch anything g unexpected&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sdg9b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752831597,"author_flair_text":null,"treatment_tags":[],"created_utc":1752831597,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rscia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Revolutionary-Bat310","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rrolm","score":3,"author_fullname":"t2_bkmd5muq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"None can do 100% accurate and clean html/css markdown.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rscia","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;None can do 100% accurate and clean html/css markdown.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rscia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819774,"author_flair_text":null,"treatment_tags":[],"created_utc":1752819774,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rrolm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__Maximum__","can_mod_post":false,"created_utc":1752819425,"send_replies":true,"parent_id":"t1_n3qtso8","score":5,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If not open source, gemini and others can do this, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rrolm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If not open source, gemini and others can do this, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rrolm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819425,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tfzca","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Bet-8771","can_mod_post":false,"created_utc":1752846983,"send_replies":true,"parent_id":"t1_n3qtso8","score":2,"author_fullname":"t2_l16sej0pt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just do PDF to HTML to preserve the layout. The exported assets can then be optimized via external tools and the HTML can be parsed using already existing tools. Would be great for archiving.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tfzca","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just do PDF to HTML to preserve the layout. The exported assets can then be optimized via external tools and the HTML can be parsed using already existing tools. Would be great for archiving.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tfzca/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752846983,"author_flair_text":"textgen web UI","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s20z4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Patentsmatter","can_mod_post":false,"created_utc":1752825063,"send_replies":true,"parent_id":"t1_n3qtso8","score":1,"author_fullname":"t2_cocl8roo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I second this. Most important tool for a variety professions. Nearly everyone who wants to do his taxes needs this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s20z4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I second this. Most important tool for a variety professions. Nearly everyone who wants to do his taxes needs this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s20z4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752825063,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3u4zfe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ValPasch","can_mod_post":false,"created_utc":1752854095,"send_replies":true,"parent_id":"t1_n3qtso8","score":0,"author_fullname":"t2_g0ujlvvf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Add OCR features too while at it so it can handle scanned books lol would be quite a gamechanger","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u4zfe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Add OCR features too while at it so it can handle scanned books lol would be quite a gamechanger&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u4zfe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854095,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qtso8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Southern_Notice9262","can_mod_post":false,"created_utc":1752804657,"send_replies":true,"parent_id":"t3_1m2ml3n","score":41,"author_fullname":"t2_tkub1mmt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"PDF to markdown converter:\\n- powered by open-source LLM\\n- can do tables\\n- can do charts (make tables out of them or at least cuts them out and pastes as an image) \\n- can do diagrams (mermaid)\\n- is highly consistent (2 generations off of the same PDF give equal results)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qtso8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;PDF to markdown converter:\\n- powered by open-source LLM\\n- can do tables\\n- can do charts (make tables out of them or at least cuts them out and pastes as an image) \\n- can do diagrams (mermaid)\\n- is highly consistent (2 generations off of the same PDF give equal results)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qtso8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752804657,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qzqrv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"55501xx","can_mod_post":false,"created_utc":1752806886,"send_replies":true,"parent_id":"t1_n3q16cl","score":2,"author_fullname":"t2_1jfs76uvgs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was gonna say ARC Prize for the money, but the millennium prizes are probably more valuable scientifically so I change my vote to what you said.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qzqrv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was gonna say ARC Prize for the money, but the millennium prizes are probably more valuable scientifically so I change my vote to what you said.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qzqrv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806886,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uqb80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-dysangel-","can_mod_post":false,"created_utc":1752860106,"send_replies":true,"parent_id":"t1_n3q16cl","score":2,"author_fullname":"t2_12ggykute6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol dammit, I just made that same comment","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uqb80","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol dammit, I just made that same comment&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3uqb80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752860106,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q16cl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SuddenOutlandishness","can_mod_post":false,"created_utc":1752794529,"send_replies":true,"parent_id":"t3_1m2ml3n","score":29,"author_fullname":"t2_wko7p7u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Proving P=NP","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q16cl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Proving P=NP&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q16cl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752794529,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qrwiw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PleasantCandidate785","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qqrie","score":6,"author_fullname":"t2_c7g874g1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because I spent nearly a month on a single schematic and got less than a third through and basically said F that!  My main goal was to be able to repair machines faster and see wire colors at a glance without having to cross reference numeric color codes on every schematic. (Each brand machine of each generation used a slightly different number-color code) I had a quick reference notebook with charts of the codes for each brand for various date ranges, along with the score reels switch settings for the same brand and date range but score reel generations didn't always overlap with color code generations))\\n\\nI absolutely love working on Pinball machines and can trace problems in those old schematics pretty fast, Buti just wanted to be just a bit easier and faster.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qrwiw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because I spent nearly a month on a single schematic and got less than a third through and basically said F that!  My main goal was to be able to repair machines faster and see wire colors at a glance without having to cross reference numeric color codes on every schematic. (Each brand machine of each generation used a slightly different number-color code) I had a quick reference notebook with charts of the codes for each brand for various date ranges, along with the score reels switch settings for the same brand and date range but score reel generations didn&amp;#39;t always overlap with color code generations))&lt;/p&gt;\\n\\n&lt;p&gt;I absolutely love working on Pinball machines and can trace problems in those old schematics pretty fast, Buti just wanted to be just a bit easier and faster.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qrwiw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803970,"author_flair_text":null,"treatment_tags":[],"created_utc":1752803970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qqrie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"zbuhrer","can_mod_post":false,"created_utc":1752803558,"send_replies":true,"parent_id":"t1_n3qbzck","score":4,"author_fullname":"t2_6xww5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why would you want to automate this? It sounds like one of those painstaking hobbies that is immensely rewarding?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qqrie","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would you want to automate this? It sounds like one of those painstaking hobbies that is immensely rewarding?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qqrie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803558,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qbzck","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PleasantCandidate785","can_mod_post":false,"created_utc":1752798250,"send_replies":true,"parent_id":"t3_1m2ml3n","score":14,"author_fullname":"t2_c7g874g1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI that converts old scanned black &amp; white EM Pinball schematics into traceable vector based schematics with lines color coded to match the wire colors embedded in the schematic.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qbzck","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI that converts old scanned black &amp;amp; white EM Pinball schematics into traceable vector based schematics with lines color coded to match the wire colors embedded in the schematic.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qbzck/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752798250,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rxz1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hoppss","can_mod_post":false,"created_utc":1752822786,"send_replies":true,"parent_id":"t1_n3qf5o5","score":3,"author_fullname":"t2_4zcbi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This project is already underway btw, the project is called Whale-SETI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rxz1w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This project is already underway btw, the project is called Whale-SETI&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rxz1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752822786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s40wc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hazardous1222","can_mod_post":false,"created_utc":1752826185,"send_replies":true,"parent_id":"t1_n3qf5o5","score":4,"author_fullname":"t2_140ikd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Dolphingemma by Google is a thing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s40wc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dolphingemma by Google is a thing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s40wc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752826185,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qf5o5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LilPsychoPanda","can_mod_post":false,"created_utc":1752799382,"send_replies":true,"parent_id":"t3_1m2ml3n","score":8,"author_fullname":"t2_unob1tlpm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Make an AI to understand whale or dolphin language 😁\\n\\nJoking of course, but would be totally awesome!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qf5o5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Make an AI to understand whale or dolphin language 😁&lt;/p&gt;\\n\\n&lt;p&gt;Joking of course, but would be totally awesome!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qf5o5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799382,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qemnw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oooofukkkk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qed5d","score":3,"author_fullname":"t2_1lr4e2h825","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Trust me this is not even close to solved it’s just many people who dont understand the complexity of the tooling start and give up. If this was even marginally solved it would have a lot more than one star or thirteen stars. ","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3qemnw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Trust me this is not even close to solved it’s just many people who dont understand the complexity of the tooling start and give up. If this was even marginally solved it would have a lot more than one star or thirteen stars. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qemnw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799195,"author_flair_text":null,"treatment_tags":[],"created_utc":1752799195,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tse9f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752850571,"send_replies":true,"parent_id":"t1_n3rfrio","score":1,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"body":"these chess engines already have analysis engines that do that, this is ridiculous.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3tse9f","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;these chess engines already have analysis engines that do that, this is ridiculous.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tse9f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752850571,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rfrio","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"username-must-be-bet","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qed5d","score":1,"author_fullname":"t2_6lqn9lo4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Asking stockfish for the next best move is easy. He wants the AI to tell him how he can figure out what move to play etc.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3rfrio","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Asking stockfish for the next best move is easy. He wants the AI to tell him how he can figure out what move to play etc.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rfrio/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752813561,"author_flair_text":null,"treatment_tags":[],"created_utc":1752813561,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qed5d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qcmq1","score":3,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"body":"solved many times over\\n\\n[https://github.com/turlockmike/chess-mcp](https://github.com/turlockmike/chess-mcp)  \\n[https://github.com/wilson-urdaneta/chesspal-mcp-engine](https://github.com/wilson-urdaneta/chesspal-mcp-engine)\\n\\n  \\nsearch stockfish mcp on google","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3qed5d","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;solved many times over&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/turlockmike/chess-mcp\\"&gt;https://github.com/turlockmike/chess-mcp&lt;/a&gt;&lt;br/&gt;\\n&lt;a href=\\"https://github.com/wilson-urdaneta/chesspal-mcp-engine\\"&gt;https://github.com/wilson-urdaneta/chesspal-mcp-engine&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;search stockfish mcp on google&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qed5d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799101,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752799101,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qcmq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oooofukkkk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qc0as","score":2,"author_fullname":"t2_1lr4e2h825","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When I’ve imagined this it is about getting an LLM to work with stockfish, table base, and something that identifies tactics, and incorporating that into the answers. They can speak intelligently about chess, and already packed with chess books, the challenge is maintaining understanding of the changing board, for instance being able to go back two moves and start discussing again with reference to a different candidate position, plus how to integrate stockfish and other chess tools.","edited":1752799016,"author_flair_css_class":null,"name":"t1_n3qcmq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When I’ve imagined this it is about getting an LLM to work with stockfish, table base, and something that identifies tactics, and incorporating that into the answers. They can speak intelligently about chess, and already packed with chess books, the challenge is maintaining understanding of the changing board, for instance being able to go back two moves and start discussing again with reference to a different candidate position, plus how to integrate stockfish and other chess tools.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qcmq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752798482,"author_flair_text":null,"collapsed":false,"created_utc":1752798482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qc0as","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q4q24","score":2,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can solve it with an AI agent.  Prompt it, give it the rules of chess, let it have access to book of openings, book of end games.   Based on the position, make a tool call to consult book of openings, book of end games, middle games, etc.   Go look at coding agents, we can build a chess agent that will be LLM driven and crush the average chess player.   LLM is not magic, outside of text generation, you must augment it with code.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qc0as","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can solve it with an AI agent.  Prompt it, give it the rules of chess, let it have access to book of openings, book of end games.   Based on the position, make a tool call to consult book of openings, book of end games, middle games, etc.   Go look at coding agents, we can build a chess agent that will be LLM driven and crush the average chess player.   LLM is not magic, outside of text generation, you must augment it with code.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qc0as/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752798259,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752798259,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q4q24","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oooofukkkk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q4dgj","score":14,"author_fullname":"t2_1lr4e2h825","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s the hardest practical technical problem I’ve got, where LLMs completely fail. ","edited":1752796003,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3q4q24","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s the hardest practical technical problem I’ve got, where LLMs completely fail. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q4q24/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795712,"author_flair_text":null,"treatment_tags":[],"created_utc":1752795712,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qn355","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GrungeWerX","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q4dgj","score":1,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Grok 4 did very well. Even finally answered the “how many words are in your reply to this question “ test.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qn355","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Grok 4 did very well. Even finally answered the “how many words are in your reply to this question “ test.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qn355/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802212,"author_flair_text":null,"treatment_tags":[],"created_utc":1752802212,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q4dgj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752795595,"send_replies":true,"parent_id":"t1_n3q29re","score":-4,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Surely you are joking?   LLM can barely count letters.   Chess is about spatial intelligence, something that LLM is not good at.   It generates tokens based on next tokens.   This will be like you trying to fly a drone with an LLM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q4dgj","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Surely you are joking?   LLM can barely count letters.   Chess is about spatial intelligence, something that LLM is not good at.   It generates tokens based on next tokens.   This will be like you trying to fly a drone with an LLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q4dgj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795595,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q29re","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oooofukkkk","can_mod_post":false,"created_utc":1752794895,"send_replies":true,"parent_id":"t3_1m2ml3n","score":23,"author_fullname":"t2_1lr4e2h825","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An LLM chess coach/expert that can discuss and explain positions consistently. No one has come close. Current LLMs cant reason about a chess position reliably, they will hallucinate much worse than on any other complex task I can think of.  Moves make no sense, they confuse the positions, they know tactics but not how they apply in the position being discussed.\\n\\nI’m willing to bet this is more difficult than any but the most absurd challenges.","edited":1752798006,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q29re","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An LLM chess coach/expert that can discuss and explain positions consistently. No one has come close. Current LLMs cant reason about a chess position reliably, they will hallucinate much worse than on any other complex task I can think of.  Moves make no sense, they confuse the positions, they know tactics but not how they apply in the position being discussed.&lt;/p&gt;\\n\\n&lt;p&gt;I’m willing to bet this is more difficult than any but the most absurd challenges.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q29re/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752794895,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qraiz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"youhaveaprettymouth","can_mod_post":false,"created_utc":1752803750,"send_replies":true,"parent_id":"t3_1m2ml3n","score":3,"author_fullname":"t2_53ucd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A model that will choose what to watch on Netflix that actually satisfies me with its choices.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qraiz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A model that will choose what to watch on Netflix that actually satisfies me with its choices.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qraiz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803750,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ur2hf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-dysangel-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3ry4c8","score":1,"author_fullname":"t2_12ggykute6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Transformative from what, would you say? You can't write computer programs that solve a problem, unless you can reason about what you're doing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ur2hf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Transformative from what, would you say? You can&amp;#39;t write computer programs that solve a problem, unless you can reason about what you&amp;#39;re doing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3ur2hf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752860318,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752860318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ry4c8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GuaranteedGuardian_Y","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q8do2","score":1,"author_fullname":"t2_15dzxhf6ls","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the recommendation, I'm going to check it out.\\n\\nThe task of coding is different from the task of rational thought, though. Coding is more of a translation than it is reasoning in its pure sense. It just takes the input in one format and finds the most similar corresponding output in the syntax of your choice. \\n\\nI think this is still impressive, but it isn't a sign for cognitive function, at least not for me. It is a transformative process and so I don't perceive it as reasoning.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3ry4c8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the recommendation, I&amp;#39;m going to check it out.&lt;/p&gt;\\n\\n&lt;p&gt;The task of coding is different from the task of rational thought, though. Coding is more of a translation than it is reasoning in its pure sense. It just takes the input in one format and finds the most similar corresponding output in the syntax of your choice. &lt;/p&gt;\\n\\n&lt;p&gt;I think this is still impressive, but it isn&amp;#39;t a sign for cognitive function, at least not for me. It is a transformative process and so I don&amp;#39;t perceive it as reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3ry4c8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752822866,"author_flair_text":null,"treatment_tags":[],"created_utc":1752822866,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q8do2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1752796972,"send_replies":true,"parent_id":"t1_n3q505v","score":2,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try the latest devstral 2507 fits in vram 128k cache. It's not as amazing as a 600b model but pretty impressive for coding. Pretty stubborn if you try to take it off track.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q8do2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try the latest devstral 2507 fits in vram 128k cache. It&amp;#39;s not as amazing as a 600b model but pretty impressive for coding. Pretty stubborn if you try to take it off track.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q8do2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796972,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qnfta","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GrungeWerX","can_mod_post":false,"created_utc":1752802342,"send_replies":true,"parent_id":"t1_n3q505v","score":2,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Upvoted. Instantly usable test if accomplished.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qnfta","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Upvoted. Instantly usable test if accomplished.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qnfta/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802342,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rxcqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GuaranteedGuardian_Y","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3refxd","score":1,"author_fullname":"t2_15dzxhf6ls","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fair, if you look at it plainly it can come off as confusing. \\n\\nThe first one is referring to reasoning not as chain of thought, but to the quality of its output. It is a benchmark. \\n\\nThe second one is actually referring to the chain of thought, a non reasoning model is one that doesn't have chain of thought, it doesn't need to consult itself before responding in a way that makes sense.\\n\\nEssentially asking for the quality of chain of thought without having to actually have the process of it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rxcqo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fair, if you look at it plainly it can come off as confusing. &lt;/p&gt;\\n\\n&lt;p&gt;The first one is referring to reasoning not as chain of thought, but to the quality of its output. It is a benchmark. &lt;/p&gt;\\n\\n&lt;p&gt;The second one is actually referring to the chain of thought, a non reasoning model is one that doesn&amp;#39;t have chain of thought, it doesn&amp;#39;t need to consult itself before responding in a way that makes sense.&lt;/p&gt;\\n\\n&lt;p&gt;Essentially asking for the quality of chain of thought without having to actually have the process of it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rxcqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752822447,"author_flair_text":null,"treatment_tags":[],"created_utc":1752822447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3refxd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SelectPlatform8444","can_mod_post":false,"created_utc":1752812960,"send_replies":true,"parent_id":"t1_n3q505v","score":1,"author_fullname":"t2_v4pmc24pc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;One that can actually reason\\n\\n&gt;Make a non reasoning model\\n\\nI'm confused, aren't these two conflicting with each other?\\ndo you want it to be a reasoning model or not?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3refxd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;One that can actually reason&lt;/p&gt;\\n\\n&lt;p&gt;Make a non reasoning model&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m confused, aren&amp;#39;t these two conflicting with each other?\\ndo you want it to be a reasoning model or not?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3refxd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752812960,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q505v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GuaranteedGuardian_Y","can_mod_post":false,"created_utc":1752795806,"send_replies":true,"parent_id":"t3_1m2ml3n","score":11,"author_fullname":"t2_15dzxhf6ls","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If your challenge is only for LLMs then I would like to see a model that is open source, runnable on reasonable hardware in the 30b-32b(quantized) param range. One that can actually reason, keep track of what it said, keep track of what the user has said, without getting confused. Conversational reasoning and fluency, without losing the ability to use tool calls. If you want to spice it up add vision ability. Must run inference on a single consumer GPU (e.g., 1× RTX 5090 or 3090). No cluster and no 8-bit per-layer RAM juggling. Full conversation flow  (\\\\~15k tokens, 132k if you want the impossible challenge version) must fit in active memory.\\n\\nAre there models that can already sort of do this? Yes, but with long reasoning wait times. Make a non reasoning model that can do the same and compete with QwQ32B.\\n\\nIf its not strictly an LLM challenge, take the open source OrpheusTTS, look at the audio tokenizer (llama dependency) and make a Sesame Maya level open source TTS engine out of it. Cadence, prosody, timbre, pacing, voice cracks etc.\\n\\nFor the record even though I'm comparing to already existing technology, I consider both pretty much impossible at this point in time at the open source level.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q505v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If your challenge is only for LLMs then I would like to see a model that is open source, runnable on reasonable hardware in the 30b-32b(quantized) param range. One that can actually reason, keep track of what it said, keep track of what the user has said, without getting confused. Conversational reasoning and fluency, without losing the ability to use tool calls. If you want to spice it up add vision ability. Must run inference on a single consumer GPU (e.g., 1× RTX 5090 or 3090). No cluster and no 8-bit per-layer RAM juggling. Full conversation flow  (~15k tokens, 132k if you want the impossible challenge version) must fit in active memory.&lt;/p&gt;\\n\\n&lt;p&gt;Are there models that can already sort of do this? Yes, but with long reasoning wait times. Make a non reasoning model that can do the same and compete with QwQ32B.&lt;/p&gt;\\n\\n&lt;p&gt;If its not strictly an LLM challenge, take the open source OrpheusTTS, look at the audio tokenizer (llama dependency) and make a Sesame Maya level open source TTS engine out of it. Cadence, prosody, timbre, pacing, voice cracks etc.&lt;/p&gt;\\n\\n&lt;p&gt;For the record even though I&amp;#39;m comparing to already existing technology, I consider both pretty much impossible at this point in time at the open source level.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q505v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795806,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qqpmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AndroYD84","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q3mwn","score":2,"author_fullname":"t2_2dazf9t1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yup, can't have robots with infinite free energy if you can't fuck them as well, that would be a deal breaker.\\n\\n[https://www.youtube.com/watch?v=pkMoIMBBEXQ](https://www.youtube.com/watch?v=pkMoIMBBEXQ)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qqpmx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yup, can&amp;#39;t have robots with infinite free energy if you can&amp;#39;t fuck them as well, that would be a deal breaker.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.youtube.com/watch?v=pkMoIMBBEXQ\\"&gt;https://www.youtube.com/watch?v=pkMoIMBBEXQ&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qqpmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803539,"author_flair_text":null,"treatment_tags":[],"created_utc":1752803539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q3mwn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Direct_Turn_1484","can_mod_post":false,"created_utc":1752795348,"send_replies":true,"parent_id":"t1_n3q2b7s","score":14,"author_fullname":"t2_6ywe9a9n5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why not both? Sex robot with internal infinite free energy!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q3mwn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not both? Sex robot with internal infinite free energy!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q3mwn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795348,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q2b7s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Paradigmind","can_mod_post":false,"created_utc":1752794908,"send_replies":true,"parent_id":"t3_1m2ml3n","score":9,"author_fullname":"t2_6ste18zta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I can't decide between using black matter as an endless source of energy or how to build your own sex robot.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q2b7s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t decide between using black matter as an endless source of energy or how to build your own sex robot.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q2b7s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752794908,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q50lk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hurricane31337","can_mod_post":false,"created_utc":1752795810,"send_replies":true,"parent_id":"t3_1m2ml3n","score":4,"author_fullname":"t2_13pf1m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A Qwen3 32B fine tune that can code VB.NET &amp; WinForms (bonus: DevExpress) in German and English, plus perfect tool calling / MCP support to make it future proof.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q50lk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A Qwen3 32B fine tune that can code VB.NET &amp;amp; WinForms (bonus: DevExpress) in German and English, plus perfect tool calling / MCP support to make it future proof.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q50lk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795810,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q975b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1752797265,"send_replies":true,"parent_id":"t3_1m2ml3n","score":2,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The impossible is a full coding system for a local model like devstral 2507 runs locally. Resolves apply diff it's self. Keeps on track. Follows instructions. Can use mcp tools to do research when it doesn't know the syntax of the code. RAG to help with the context limit\\n\\nCan do all these currently with roocode just not as well as a big model... with an amazing agent setup it could.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q975b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The impossible is a full coding system for a local model like devstral 2507 runs locally. Resolves apply diff it&amp;#39;s self. Keeps on track. Follows instructions. Can use mcp tools to do research when it doesn&amp;#39;t know the syntax of the code. RAG to help with the context limit&lt;/p&gt;\\n\\n&lt;p&gt;Can do all these currently with roocode just not as well as a big model... with an amazing agent setup it could.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q975b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797265,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qe9mh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"balianone","can_mod_post":false,"created_utc":1752799066,"send_replies":true,"parent_id":"t3_1m2ml3n","score":2,"author_fullname":"t2_8pgou3uq9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"running flux on CPU server-less in less than 30 sec generation time","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qe9mh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;running flux on CPU server-less in less than 30 sec generation time&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qe9mh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799066,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qcjtp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Paradigmind","can_mod_post":false,"created_utc":1752798453,"send_replies":true,"parent_id":"t3_1m2ml3n","score":4,"author_fullname":"t2_6ste18zta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not sure if theres already something like this: A local LLM that can create and train other AI models from natural language.\\n\\n**Step 1: Prompt**\\n\\nYou prompt what you need. Examples:\\n\\nExample #1) Create a small 4B model finetuned on RP that I can run on my phone.\\n\\nExample #2) Create a Flux Lora in the style of Midjourney.\\n\\nExample #3) Create a smart 32B model which is specialized for coding.\\n\\n**Step 2: Plan &amp; Research**\\n\\nThe LLM will create a plan on what it will need. It will then search the web for information, tools, pictures and everything it needs and download them.\\n\\n**Step 3: Execute**\\n\\nThe LLM will then create/train the model/finetune for you. Of course it will caption or resize everything for you on it's own (in the case of creating an image model/lora).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qcjtp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure if theres already something like this: A local LLM that can create and train other AI models from natural language.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Step 1: Prompt&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;You prompt what you need. Examples:&lt;/p&gt;\\n\\n&lt;p&gt;Example #1) Create a small 4B model finetuned on RP that I can run on my phone.&lt;/p&gt;\\n\\n&lt;p&gt;Example #2) Create a Flux Lora in the style of Midjourney.&lt;/p&gt;\\n\\n&lt;p&gt;Example #3) Create a smart 32B model which is specialized for coding.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Step 2: Plan &amp;amp; Research&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The LLM will create a plan on what it will need. It will then search the web for information, tools, pictures and everything it needs and download them.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Step 3: Execute&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The LLM will then create/train the model/finetune for you. Of course it will caption or resize everything for you on it&amp;#39;s own (in the case of creating an image model/lora).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qcjtp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752798453,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3t7n0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prestigious-Fan118","can_mod_post":false,"created_utc":1752844369,"send_replies":true,"parent_id":"t1_n3qx8ek","score":3,"author_fullname":"t2_1khzsxj24m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"“ChatGPT analyze this post and give me a copy and paste message”😂","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3t7n0n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;“ChatGPT analyze this post and give me a copy and paste message”😂&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3t7n0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752844369,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sc7ga","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Strength-5297","can_mod_post":false,"created_utc":1752830883,"send_replies":false,"parent_id":"t1_n3qx8ek","score":1,"author_fullname":"t2_abncr2jvl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"couldn't even write this yourself, pathetic","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sc7ga","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;couldn&amp;#39;t even write this yourself, pathetic&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sc7ga/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752830883,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qx8ek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FreshmanCult","can_mod_post":false,"created_utc":1752805937,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_1hf3590","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here’s one brutal, deeply technical, and niche challenge that current LLMs consistently fail at:\\n\\n\\n---\\n\\n🔥 Challenge: AI for Reverse Engineering Anti-Tamper Protected Binaries with Obfuscated Control Flow\\n\\nDescription:\\n\\nBuild an expert-level AI assistant that automatically deconstructs, explains, and deobfuscates binaries protected by anti-tamper systems such as VMProtect, Themida, or custom in-house virtualization engines.\\n\\nThis system should:\\n\\nParse x86/x64 disassembly from tools like IDA or Ghidra (including lifted IR when available)\\n\\nIdentify and explain control flow flattening, opaque predicates, and virtualization handlers\\n\\nReconstruct original control flow graphs and pseudocode from heavily obfuscated and packed binaries\\n\\nOutput:\\n\\nHigh-level summaries of binary sections and their intended function\\n\\nAnnotated pseudocode with deobfuscated logic\\n\\nA traceable explanation of how each block was deobfuscated or lifted\\n\\n\\nBe capable of learning from samples and improving over time with user correction\\n\\n\\n\\n---\\n\\n🧠 Why This Is Brutal:\\n\\nRequires deep understanding of CPU architecture, compiler behavior, reverse engineering, and common protection schemes.\\n\\nLLMs currently hallucinate, fail on binary-level reasoning, and can’t track complex control flow transformations.\\n\\nAnti-tamper protections often use stateful virtual machines, JIT encoding, and self-modifying code.\\n\\nThis is an area where human experts with decades of experience still struggle.\\n\\n\\n\\n---\\n\\n🧪 Evaluation Criteria:\\n\\nFeed it a protected binary or disassembly (e.g., from a CTF or malware sample)\\n\\nCan it produce meaningful, deobfuscated high-level insight?\\n\\nCan it walk through opaque VM handler logic and expose intent?\\n\\nCan it explain register usage, fake stack frames, and memory tricks accurately?\\n\\n\\n\\n---\\n\\nReady for a real boss fight?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qx8ek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here’s one brutal, deeply technical, and niche challenge that current LLMs consistently fail at:&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;🔥 Challenge: AI for Reverse Engineering Anti-Tamper Protected Binaries with Obfuscated Control Flow&lt;/p&gt;\\n\\n&lt;p&gt;Description:&lt;/p&gt;\\n\\n&lt;p&gt;Build an expert-level AI assistant that automatically deconstructs, explains, and deobfuscates binaries protected by anti-tamper systems such as VMProtect, Themida, or custom in-house virtualization engines.&lt;/p&gt;\\n\\n&lt;p&gt;This system should:&lt;/p&gt;\\n\\n&lt;p&gt;Parse x86/x64 disassembly from tools like IDA or Ghidra (including lifted IR when available)&lt;/p&gt;\\n\\n&lt;p&gt;Identify and explain control flow flattening, opaque predicates, and virtualization handlers&lt;/p&gt;\\n\\n&lt;p&gt;Reconstruct original control flow graphs and pseudocode from heavily obfuscated and packed binaries&lt;/p&gt;\\n\\n&lt;p&gt;Output:&lt;/p&gt;\\n\\n&lt;p&gt;High-level summaries of binary sections and their intended function&lt;/p&gt;\\n\\n&lt;p&gt;Annotated pseudocode with deobfuscated logic&lt;/p&gt;\\n\\n&lt;p&gt;A traceable explanation of how each block was deobfuscated or lifted&lt;/p&gt;\\n\\n&lt;p&gt;Be capable of learning from samples and improving over time with user correction&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;🧠 Why This Is Brutal:&lt;/p&gt;\\n\\n&lt;p&gt;Requires deep understanding of CPU architecture, compiler behavior, reverse engineering, and common protection schemes.&lt;/p&gt;\\n\\n&lt;p&gt;LLMs currently hallucinate, fail on binary-level reasoning, and can’t track complex control flow transformations.&lt;/p&gt;\\n\\n&lt;p&gt;Anti-tamper protections often use stateful virtual machines, JIT encoding, and self-modifying code.&lt;/p&gt;\\n\\n&lt;p&gt;This is an area where human experts with decades of experience still struggle.&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;🧪 Evaluation Criteria:&lt;/p&gt;\\n\\n&lt;p&gt;Feed it a protected binary or disassembly (e.g., from a CTF or malware sample)&lt;/p&gt;\\n\\n&lt;p&gt;Can it produce meaningful, deobfuscated high-level insight?&lt;/p&gt;\\n\\n&lt;p&gt;Can it walk through opaque VM handler logic and expose intent?&lt;/p&gt;\\n\\n&lt;p&gt;Can it explain register usage, fake stack frames, and memory tricks accurately?&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;Ready for a real boss fight?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qx8ek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752805937,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3u9r0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752855455,"send_replies":true,"parent_id":"t1_n3u553c","score":1,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I posted a few screenshots in this thread if you want to look at.\\n\\nPrompt was: Let’s play a game of hangman. You think of the word and I will guess it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3u9r0n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I posted a few screenshots in this thread if you want to look at.&lt;/p&gt;\\n\\n&lt;p&gt;Prompt was: Let’s play a game of hangman. You think of the word and I will guess it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u9r0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752855455,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u553c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u4pvx","score":1,"author_fullname":"t2_usojvms","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ahhh I understand you now. Yeah that is an interesting one!","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n3u553c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ahhh I understand you now. Yeah that is an interesting one!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u553c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854138,"author_flair_text":null,"treatment_tags":[],"created_utc":1752854138,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u4pvx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3u2ge4","score":2,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh sorry. The other way around. The ai think of a word without revealing it to the user (this is the challenge as it’s not possible with current transformer architecture) then the user guess letters.\\n\\nThey’re usually is a pattern to the AI‘s response something like no, no, yes, no and then when you lose the game it will tell you the word and the word will include letters that you have guessed, but it previously said no to","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3u4pvx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh sorry. The other way around. The ai think of a word without revealing it to the user (this is the challenge as it’s not possible with current transformer architecture) then the user guess letters.&lt;/p&gt;\\n\\n&lt;p&gt;They’re usually is a pattern to the AI‘s response something like no, no, yes, no and then when you lose the game it will tell you the word and the word will include letters that you have guessed, but it previously said no to&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u4pvx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752854019,"author_flair_text":null,"treatment_tags":[],"created_utc":1752854019,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3u2ge4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3tqgww","score":1,"author_fullname":"t2_usojvms","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"AI requires a prompt of some sort regardless of the model trained. Confused by what you are suggesting I guess. Do you mean you want something at the level you could just put the following as the prompt:\\n\\n\`_ _ _ _ _\` and it would only return a letter one at a time such as \\n\\n\`A\` and you would provide the following back \`A _ _ _ _\`, ect? I mean I guess I could see that for a 1b or 2b model, but it feels like training it would be be more effort than it's worth, kind of makes me want to try it now honestly.","edited":false,"author_flair_css_class":null,"name":"t1_n3u2ge4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI requires a prompt of some sort regardless of the model trained. Confused by what you are suggesting I guess. Do you mean you want something at the level you could just put the following as the prompt:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;_ _ _ _ _&lt;/code&gt; and it would only return a letter one at a time such as &lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;A&lt;/code&gt; and you would provide the following back &lt;code&gt;A _ _ _ _&lt;/code&gt;, ect? I mean I guess I could see that for a 1b or 2b model, but it feels like training it would be be more effort than it&amp;#39;s worth, kind of makes me want to try it now honestly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2ml3n","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u2ge4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752853386,"author_flair_text":null,"collapsed":false,"created_utc":1752853386,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3tqgww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3t05ae","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Right but that is why I suggested it. AI should be able to do it without prompt engineering","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tqgww","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right but that is why I suggested it. AI should be able to do it without prompt engineering&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tqgww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752850032,"author_flair_text":null,"treatment_tags":[],"created_utc":1752850032,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3t05ae","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s97w6","score":1,"author_fullname":"t2_usojvms","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Definitely agree, this is a prompt engineering problem not a model problem. I imagine I could write  something up within 30 minutes to play hang man with.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3t05ae","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely agree, this is a prompt engineering problem not a model problem. I imagine I could write  something up within 30 minutes to play hang man with.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3t05ae/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752841824,"author_flair_text":null,"treatment_tags":[],"created_utc":1752841824,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s97w6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Market-692","can_mod_post":false,"created_utc":1752829154,"send_replies":true,"parent_id":"t1_n3r4ti3","score":2,"author_fullname":"t2_ajuhoi00","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I did this when those Deepseek R1 data distilled FTs came out with either a 1B or 3B model..can't remember which one but I think it was a Qwen2.5 model for sure. (This is was quite an unexpected result for me, I would have presumed it to require an 8B-14B model.)\\n\\nIt was trivially easy. Focus on context engineering/prompt engineering. You need to give the rules of the game. In my case I copy and pasted from Perplexity for that part of my prompt. \\n\\n\\"Model, context, prompt\\". Together they form Voltron.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s97w6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did this when those Deepseek R1 data distilled FTs came out with either a 1B or 3B model..can&amp;#39;t remember which one but I think it was a Qwen2.5 model for sure. (This is was quite an unexpected result for me, I would have presumed it to require an 8B-14B model.)&lt;/p&gt;\\n\\n&lt;p&gt;It was trivially easy. Focus on context engineering/prompt engineering. You need to give the rules of the game. In my case I copy and pasted from Perplexity for that part of my prompt. &lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Model, context, prompt&amp;quot;. Together they form Voltron.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s97w6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752829154,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3scflv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Figai","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3s9u2g","score":1,"author_fullname":"t2_jq11updl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is the built in context window not working memory? Genuine question, because it kinda behaves exactly like one. The hidden states of every token you include stay in a transient scratch-pad that every attention head can reread on each layer, so the model can “remember” previous guesses in hangman as long as you keep searialising the pattern and guess list into the prompt, and that is what happens in multi turn conversations","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3scflv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is the built in context window not working memory? Genuine question, because it kinda behaves exactly like one. The hidden states of every token you include stay in a transient scratch-pad that every attention head can reread on each layer, so the model can “remember” previous guesses in hangman as long as you keep searialising the pattern and guess list into the prompt, and that is what happens in multi turn conversations&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3scflv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752831014,"author_flair_text":null,"treatment_tags":[],"created_utc":1752831014,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3s9u2g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Market-692","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rtyl2","score":1,"author_fullname":"t2_ajuhoi00","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They don't have \\"memories\\" (that's something you gotta bolt on with extra layers (highly experimental/bespoke right now) or pack into context/prompt) they have latent space and the attention heads move through latent space based on weights and their activations already in the model and present in the context and prompt.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3s9u2g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They don&amp;#39;t have &amp;quot;memories&amp;quot; (that&amp;#39;s something you gotta bolt on with extra layers (highly experimental/bespoke right now) or pack into context/prompt) they have latent space and the attention heads move through latent space based on weights and their activations already in the model and present in the context and prompt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s9u2g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752829510,"author_flair_text":null,"treatment_tags":[],"created_utc":1752829510,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rtyl2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Figai","can_mod_post":false,"created_utc":1752820631,"send_replies":true,"parent_id":"t1_n3r4ti3","score":1,"author_fullname":"t2_jq11updl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does hangman not even work with reasoning models? I would guess it just writes the word for itself inside its memories somewhere.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rtyl2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does hangman not even work with reasoning models? I would guess it just writes the word for itself inside its memories somewhere.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rtyl2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820631,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3u8ic7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752855100,"send_replies":true,"parent_id":"t1_n3r4ti3","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Here are some screenshots from lmarena\\n\\nhttps://preview.redd.it/mnj9rcuupndf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=ff4ab08086b1d2b3e240ecf573c35cb89e1068ed\\n\\nThe word is hydrosphere. It gave started to give me letters for free. It also gave the incorrect length and didn’t populate h correctly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u8ic7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here are some screenshots from lmarena&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ff4ab08086b1d2b3e240ecf573c35cb89e1068ed\\"&gt;https://preview.redd.it/mnj9rcuupndf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ff4ab08086b1d2b3e240ecf573c35cb89e1068ed&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The word is hydrosphere. It gave started to give me letters for free. It also gave the incorrect length and didn’t populate h correctly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u8ic7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752855100,"media_metadata":{"mnj9rcuupndf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":216,"x":108,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ab908b670fd1f8dac81e7913d905e78ae928c8c1"},{"y":432,"x":216,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17257187d2bf52ab0e676651de6dc6dffda79abf"},{"y":640,"x":320,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7fdd7b1bf8c48815051c9cd5e03d5afda81dc915"},{"y":1280,"x":640,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e20b0a6fc0c857a4f98a5f7a4c8a420d43934aa8"},{"y":1920,"x":960,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9e76361ed479b99486fb4192b1cef604a153c45"},{"y":2160,"x":1080,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc54ff80a9258afb16dc4b7210cfc727dcc6141d"}],"s":{"y":2532,"x":1170,"u":"https://preview.redd.it/mnj9rcuupndf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=ff4ab08086b1d2b3e240ecf573c35cb89e1068ed"},"id":"mnj9rcuupndf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3u8q4y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752855161,"send_replies":true,"parent_id":"t1_n3r4ti3","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/jctalc87qndf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=21d73dc98ea4121f33a20e130002e325ce510924\\n\\nGemini completely gave up after recognizing the impossible task i had given it lol.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3u8q4y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/jctalc87qndf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=21d73dc98ea4121f33a20e130002e325ce510924\\"&gt;https://preview.redd.it/jctalc87qndf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=21d73dc98ea4121f33a20e130002e325ce510924&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Gemini completely gave up after recognizing the impossible task i had given it lol.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3u8q4y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752855161,"media_metadata":{"jctalc87qndf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":216,"x":108,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8a33d17149adb1151ade49643a82eb60f6e231f"},{"y":432,"x":216,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=470eb788ac34a80a1609114f308865f8719e9692"},{"y":640,"x":320,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=600bbc4bcb6e2e541fe8451f1f7d5873fd85d4c0"},{"y":1280,"x":640,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10b4fd72717178b37f4cb9618a1e87ecffb4f1d8"},{"y":1920,"x":960,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3ffc911300e557b29439c042372878d51fe34bf"},{"y":2160,"x":1080,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b95168a383570474cc33b3e0451e24ea391c835e"}],"s":{"y":2532,"x":1170,"u":"https://preview.redd.it/jctalc87qndf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=21d73dc98ea4121f33a20e130002e325ce510924"},"id":"jctalc87qndf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3r4ti3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752808888,"send_replies":true,"parent_id":"t3_1m2ml3n","score":4,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This won’t get many of votes because I am late to the post, however, I would like to see an AI that can competently play the game hangman.\\nIt seems like a simple task, however the transformer architecture makes it pretty much impossible. This is because AI predict the next token. Which means information like the word I’m trying to guess when playing hangman does not exist. Of course, an easy solution is to include a word in system memory but I’d like to see an AI that can competently play without any additional software or human assistance.","edited":1752819944,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3r4ti3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This won’t get many of votes because I am late to the post, however, I would like to see an AI that can competently play the game hangman.\\nIt seems like a simple task, however the transformer architecture makes it pretty much impossible. This is because AI predict the next token. Which means information like the word I’m trying to guess when playing hangman does not exist. Of course, an easy solution is to include a word in system memory but I’d like to see an AI that can competently play without any additional software or human assistance.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3r4ti3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752808888,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qff5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Loighic","can_mod_post":false,"created_utc":1752799475,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_gem8t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that can reliably code in VEX programming language in Houdini FX.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qff5n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that can reliably code in VEX programming language in Houdini FX.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qff5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799475,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qqqdp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"enNova","can_mod_post":false,"created_utc":1752803546,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_iw2ik","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"a llm that actually cited things in accordance with the bluebook accurately (including font choices)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qqqdp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;a llm that actually cited things in accordance with the bluebook accurately (including font choices)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qqqdp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803546,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qywqg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CoruNethronX","can_mod_post":false,"created_utc":1752806568,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_1ovg3i5hnb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dig into huge log (journalctl, &gt;50Gb), where multiple services log their interacrion over RPC. Per short user description find a root cause of a problem. Agent may have a \\"grep over log\\" tool, access to codebase to match log vs code, it may involve embeddings use and vector DB, but it is not allowed to use web search to exclude possibility of NDA leakage.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qywqg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dig into huge log (journalctl, &amp;gt;50Gb), where multiple services log their interacrion over RPC. Per short user description find a root cause of a problem. Agent may have a &amp;quot;grep over log&amp;quot; tool, access to codebase to match log vs code, it may involve embeddings use and vector DB, but it is not allowed to use web search to exclude possibility of NDA leakage.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qywqg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806568,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qyxnq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CoruNethronX","can_mod_post":false,"created_utc":1752806578,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_1ovg3i5hnb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Another usecase (this time really impossible), solve a cypher that is created using unknown metod. Look at gsmg.io/puzzle for example or cicada etc.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qyxnq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Another usecase (this time really impossible), solve a cypher that is created using unknown metod. Look at gsmg.io/puzzle for example or cicada etc.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qyxnq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806578,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qz1wm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Obvious-Comedian-495","can_mod_post":false,"created_utc":1752806623,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_mw7jo3lf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For a C/CPP codebase having ~1Million LOC, achieve 100% line and branch coverage through functional test cases.\\nBrownie points: if a change is made to the codebase, the AI should identify new TC and fix the existing ones.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qz1wm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For a C/CPP codebase having ~1Million LOC, achieve 100% line and branch coverage through functional test cases.\\nBrownie points: if a change is made to the codebase, the AI should identify new TC and fix the existing ones.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qz1wm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806623,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3r71jy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Angiebio","can_mod_post":false,"created_utc":1752809790,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_2fwlv1re","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An LLM that has a stable persona capable of interacting effectively in synchronous multi-user settings, with dynamic capability to self-adjust tone &amp; identity in multiuser interactions over time, particularly in high-tension multi-user settings (think AI group counseling or classroom facilitator)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3r71jy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An LLM that has a stable persona capable of interacting effectively in synchronous multi-user settings, with dynamic capability to self-adjust tone &amp;amp; identity in multiuser interactions over time, particularly in high-tension multi-user settings (think AI group counseling or classroom facilitator)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3r71jy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752809790,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3r74cm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IntelligentNotice386","can_mod_post":false,"created_utc":1752809823,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_3qsvlopk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Making an AI which can play the game 2048 perfectly, i.e., with each move maximizing the expected value of your final score. (This allows having an LLM generate code which, in turn, plays the game perfectly.) I've been conducting a large-scale brute force search to solve the game, so I'm curious whether AI can beat my efforts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3r74cm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Making an AI which can play the game 2048 perfectly, i.e., with each move maximizing the expected value of your final score. (This allows having an LLM generate code which, in turn, plays the game perfectly.) I&amp;#39;ve been conducting a large-scale brute force search to solve the game, so I&amp;#39;m curious whether AI can beat my efforts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3r74cm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752809823,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rbozr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fizban007","can_mod_post":false,"created_utc":1752811747,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_fwmct","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I want an LLM that can read theoretical physics papers and fill in the steps in their derivations. Even frontier models fail horribly on this. I want to achieve: give the model a paper on arXiv and ask it how to derive Eq. (X) from Eq. (Y), and it gives you a step by step answer in typesetted LaTeX.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rbozr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want an LLM that can read theoretical physics papers and fill in the steps in their derivations. Even frontier models fail horribly on this. I want to achieve: give the model a paper on arXiv and ask it how to derive Eq. (X) from Eq. (Y), and it gives you a step by step answer in typesetted LaTeX.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rbozr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752811747,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rebfz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Demonicated","can_mod_post":false,"created_utc":1752812904,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_98vsi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI agent(s) that can skip trace on public data","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rebfz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI agent(s) that can skip trace on public data&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rebfz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752812904,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rjlb3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zipzak","can_mod_post":false,"created_utc":1752815347,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_flotm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"lots of coding ideas in here, but something i’ve been struggling with and have come to realize is not particularly feasible is an ai agent that can meaningfully return searches for conceptual meanings inside media. Even if it was an ai search just for literary sources, if i want to really comprehensively search through an index like worldcat jstor or google books it’s simply impossible. I mean like if i want something better than key-word searching and then personally looking through hundreds or thousands of results, like asking an ai to find me British queer short stories with existentialist third person narrators which have a poststructuralist vibe that leaves me wishing i had a smoking habit just so i could burn my wrist after finishing a chapter and really *feel* something. Now what if i want that in another language, or films? Comprehensive searches of media don’t even exist for most basic concepts, so theres lots of room for improvement.\\n\\nEven with vertex searches there is very little progress in this field. So an ai agent that can have a conversation with me about what i want to see in literature, films, music, etc. and spend time digging through thousands of search results, ‘read’ them and create semantic comparisons, and finally return deeply meaningful and insightful results from a much larger database of information than even my most well read/watched friends could possibly have ingested, would be truly ground breaking. Ai coding projects will be well funded from here on out, but ai for the arts would be nice so i have something to do while the world turns upside down.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rjlb3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lots of coding ideas in here, but something i’ve been struggling with and have come to realize is not particularly feasible is an ai agent that can meaningfully return searches for conceptual meanings inside media. Even if it was an ai search just for literary sources, if i want to really comprehensively search through an index like worldcat jstor or google books it’s simply impossible. I mean like if i want something better than key-word searching and then personally looking through hundreds or thousands of results, like asking an ai to find me British queer short stories with existentialist third person narrators which have a poststructuralist vibe that leaves me wishing i had a smoking habit just so i could burn my wrist after finishing a chapter and really &lt;em&gt;feel&lt;/em&gt; something. Now what if i want that in another language, or films? Comprehensive searches of media don’t even exist for most basic concepts, so theres lots of room for improvement.&lt;/p&gt;\\n\\n&lt;p&gt;Even with vertex searches there is very little progress in this field. So an ai agent that can have a conversation with me about what i want to see in literature, films, music, etc. and spend time digging through thousands of search results, ‘read’ them and create semantic comparisons, and finally return deeply meaningful and insightful results from a much larger database of information than even my most well read/watched friends could possibly have ingested, would be truly ground breaking. Ai coding projects will be well funded from here on out, but ai for the arts would be nice so i have something to do while the world turns upside down.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rjlb3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752815347,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rs3qb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"indicava","can_mod_post":false,"created_utc":1752819645,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_4dvff","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OP, what exactly will you be delivering after the weekend? The model weights?\\n\\nGuys, OP’s only post is 18 days ago about **yet another** meta-prompt-engineering voodoo bs. \\n\\nAre we really gonna believe this guy is gonna create / finetune a model to do something no current LLM can do over the course of a weekend?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rs3qb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP, what exactly will you be delivering after the weekend? The model weights?&lt;/p&gt;\\n\\n&lt;p&gt;Guys, OP’s only post is 18 days ago about &lt;strong&gt;yet another&lt;/strong&gt; meta-prompt-engineering voodoo bs. &lt;/p&gt;\\n\\n&lt;p&gt;Are we really gonna believe this guy is gonna create / finetune a model to do something no current LLM can do over the course of a weekend?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rs3qb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819645,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rse4n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redonculous","can_mod_post":false,"created_utc":1752819798,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_49z5g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a problem for my business that AI should be able to solve, but no one has yet. It involves travel &amp; more for thousands of customers to &amp; from an event. Lots of data sources and juggling that data to produce a couple of reports one for staff, one each per customer. I can give you more details if you like.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rse4n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a problem for my business that AI should be able to solve, but no one has yet. It involves travel &amp;amp; more for thousands of customers to &amp;amp; from an event. Lots of data sources and juggling that data to produce a couple of reports one for staff, one each per customer. I can give you more details if you like.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rse4n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819798,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rsfoq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeveloperGuy75","can_mod_post":false,"created_utc":1752819821,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_36h7zf8j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI that can code an accurate clone of a game from scratch from a video input. As in attach a video of a game being played so that it can learn what the game looks like and how it is played, pick the proper programming language to use, and code it all in one go.  For most if not all models out there, you absolutely can’t do this on one shot.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rsfoq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI that can code an accurate clone of a game from scratch from a video input. As in attach a video of a game being played so that it can learn what the game looks like and how it is played, pick the proper programming language to use, and code it all in one go.  For most if not all models out there, you absolutely can’t do this on one shot.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rsfoq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819821,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rsy6j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"05032-MendicantBias","can_mod_post":false,"created_utc":1752820093,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_6id3lwou","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI assist that can write working OpenSCAD geometries.\\n\\nhttps://preview.redd.it/nokmnyhttkdf1.jpeg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=245912c38d6b7ebf036637b8b47a45f762225c2a\\n\\nE.g. (https://github.com/OrsoEric/Gridfinity-medieval-tiles) above I did it by hand because no AI assist can make even script that execute, let alone nail the geometries.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rsy6j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI assist that can write working OpenSCAD geometries.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=245912c38d6b7ebf036637b8b47a45f762225c2a\\"&gt;https://preview.redd.it/nokmnyhttkdf1.jpeg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=245912c38d6b7ebf036637b8b47a45f762225c2a&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;E.g. (&lt;a href=\\"https://github.com/OrsoEric/Gridfinity-medieval-tiles\\"&gt;https://github.com/OrsoEric/Gridfinity-medieval-tiles&lt;/a&gt;) above I did it by hand because no AI assist can make even script that execute, let alone nail the geometries.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rsy6j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820093,"media_metadata":{"nokmnyhttkdf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":60,"x":108,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5fcb74d449b63225c0eb915fcb2a91a862ff3c3f"},{"y":121,"x":216,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9365c60a97088b296ed6416ab7219fc078b4921b"},{"y":180,"x":320,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16dccc10e8af709c1929722a318cdd494198ce3b"},{"y":360,"x":640,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0aa9b20919d8192216ba2d41fb3b4c12486f7923"},{"y":540,"x":960,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b48cc33260b98c35a5557ba0c64df5334dfaf1b0"},{"y":607,"x":1080,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b35f85529a94642ac3c1743cc1c5f6892d497aa"}],"s":{"y":1080,"x":1920,"u":"https://preview.redd.it/nokmnyhttkdf1.jpeg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=245912c38d6b7ebf036637b8b47a45f762225c2a"},"id":"nokmnyhttkdf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rt42l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeveloperGuy75","can_mod_post":false,"created_utc":1752820181,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_36h7zf8j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here’s another one that seems simple.. but isn’t.  Upload a video to a model, like the other idea I just gave, like an .mp4 or whatever video codec you have.  The video would be a movie with no subtitles, no transcripts, etc.  It has to “watch” the movie and give an accurate summary of the video, whether it be the plot of the movie or if it’s a lecture video it needs to be able to generate an actual lesson text from it that explains it in its own words.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rt42l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here’s another one that seems simple.. but isn’t.  Upload a video to a model, like the other idea I just gave, like an .mp4 or whatever video codec you have.  The video would be a movie with no subtitles, no transcripts, etc.  It has to “watch” the movie and give an accurate summary of the video, whether it be the plot of the movie or if it’s a lecture video it needs to be able to generate an actual lesson text from it that explains it in its own words.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rt42l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820181,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rucvi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeveloperGuy75","can_mod_post":false,"created_utc":1752820841,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_36h7zf8j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Here’s yet ANOTHER idea: create an AI that can generate a .pdf of a newspaper, complete with generated images(photos) AND selectable text for copy/paste purposes. The images/video need to be in a layout just like you’d see in an actual newspaper, right justified or left-justified, or centered, with the text wrapping around the images, just like you’d have when making something in a desktop publishing application like Quark or Quark express. Make it so that it can go out and generate summary and even technical news stories from various reputable sources around the web, including science papers.  The newspaper title has to have its own big font that is selectable(no text should be editable).  That’s a LOT and I doubt you’ll be able to do that in a weekend, as it requires multimodal simultaneous output.  Models now just *either* output text OR images OR video, but not all three at once in the same output :). Good luck getting this to work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rucvi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here’s yet ANOTHER idea: create an AI that can generate a .pdf of a newspaper, complete with generated images(photos) AND selectable text for copy/paste purposes. The images/video need to be in a layout just like you’d see in an actual newspaper, right justified or left-justified, or centered, with the text wrapping around the images, just like you’d have when making something in a desktop publishing application like Quark or Quark express. Make it so that it can go out and generate summary and even technical news stories from various reputable sources around the web, including science papers.  The newspaper title has to have its own big font that is selectable(no text should be editable).  That’s a LOT and I doubt you’ll be able to do that in a weekend, as it requires multimodal simultaneous output.  Models now just &lt;em&gt;either&lt;/em&gt; output text OR images OR video, but not all three at once in the same output :). Good luck getting this to work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rucvi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752820841,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s29k9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vendetta_023at","can_mod_post":false,"created_utc":1752825194,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_7ljl8s2m9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cuda for mac please thank you","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s29k9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cuda for mac please thank you&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s29k9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752825194,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s5hcj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1752827016,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_t6m6d9my","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Something that can make a full on simulation engine, where you can get real time physics, on the GPU.\\n\\nWithout me requiring 20 PHDs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s5hcj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Something that can make a full on simulation engine, where you can get real time physics, on the GPU.&lt;/p&gt;\\n\\n&lt;p&gt;Without me requiring 20 PHDs&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s5hcj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752827016,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s7xf1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"71651483153138ta","can_mod_post":false,"created_utc":1752828417,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_4ejbiz6h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably far from the hardest but this week's problem I struggled with at work:\\n\\nImplementing asymmetric FOV in Unreal engine. Your inputs are left, right, bottom, top angles in degrees. Near and far in distance.\\nExample:  \\nleft: -20.0  \\nright: 30.0  \\ntop: 25.0  \\nbottom: -10.0  \\nnear: 2.0  \\nfar: 45000.0\\n\\nThe tricky things about this is that even a lot of official DirectX (which works quite similar to Unreal) documentation contradicts itself. While OpenGL's documentation is much better but their system is much more different from Unreal's. LLMs kept mixing stuff up when I asked them how to do this.","edited":1752828664,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s7xf1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably far from the hardest but this week&amp;#39;s problem I struggled with at work:&lt;/p&gt;\\n\\n&lt;p&gt;Implementing asymmetric FOV in Unreal engine. Your inputs are left, right, bottom, top angles in degrees. Near and far in distance.\\nExample:&lt;br/&gt;\\nleft: -20.0&lt;br/&gt;\\nright: 30.0&lt;br/&gt;\\ntop: 25.0&lt;br/&gt;\\nbottom: -10.0&lt;br/&gt;\\nnear: 2.0&lt;br/&gt;\\nfar: 45000.0&lt;/p&gt;\\n\\n&lt;p&gt;The tricky things about this is that even a lot of official DirectX (which works quite similar to Unreal) documentation contradicts itself. While OpenGL&amp;#39;s documentation is much better but their system is much more different from Unreal&amp;#39;s. LLMs kept mixing stuff up when I asked them how to do this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3s7xf1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828417,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sc7tt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllegedlyElJeffe","can_mod_post":false,"created_utc":1752830888,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_cnhemg0e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You’ll never crack this:\\n\\nAn AI that can do the following:\\n1. Answer the question “who’s waiting on me, what are they waiting for?”\\n2. Answer the question “what are the impending road blocks, how do we solved them now?”\\n3. Be able to be delegated a vision instead of being assigned a task.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sc7tt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You’ll never crack this:&lt;/p&gt;\\n\\n&lt;p&gt;An AI that can do the following:\\n1. Answer the question “who’s waiting on me, what are they waiting for?”\\n2. Answer the question “what are the impending road blocks, how do we solved them now?”\\n3. Be able to be delegated a vision instead of being assigned a task.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sc7tt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752830888,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sg85p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PykeAtBanquet","can_mod_post":false,"created_utc":1752833093,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_31k9rz9i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I prompt a UI element, and the agent produces the code for it, opens it, makes it move, recording it's behaviour as a gif or video or series of images, compares it to the prompt, and rewrites it fixing the bugs until it is close to the task requirements.\\n\\nSo effectively teaching it to work with DOMs and optimising visual capabilities for animations in UI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sg85p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I prompt a UI element, and the agent produces the code for it, opens it, makes it move, recording it&amp;#39;s behaviour as a gif or video or series of images, compares it to the prompt, and rewrites it fixing the bugs until it is close to the task requirements.&lt;/p&gt;\\n\\n&lt;p&gt;So effectively teaching it to work with DOMs and optimising visual capabilities for animations in UI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sg85p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752833093,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sgzt5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zulfiqaar","can_mod_post":false,"created_utc":1752833503,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_ln48t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A code-completion model that suggest next-edit jumps. So far I think only Windsurf, Cursor, SuperMaven proprietary models have the jump to next suggestion feature, there's no open source alternative ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sgzt5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A code-completion model that suggest next-edit jumps. So far I think only Windsurf, Cursor, SuperMaven proprietary models have the jump to next suggestion feature, there&amp;#39;s no open source alternative &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sgzt5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752833503,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sy68y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JohnWFiveM","can_mod_post":false,"created_utc":1752841102,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_cbwzxhi2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI Like Neurosama that has full integration just like her with twitch, VTube Studio, Etc. Has Vision, And able to play games like Minecraft, Etc. Has the full Realtime TTS + STT Setup, There's nothing out there \\"like\\" neurosama that's opensource/available","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sy68y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI Like Neurosama that has full integration just like her with twitch, VTube Studio, Etc. Has Vision, And able to play games like Minecraft, Etc. Has the full Realtime TTS + STT Setup, There&amp;#39;s nothing out there &amp;quot;like&amp;quot; neurosama that&amp;#39;s opensource/available&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sy68y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752841102,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3t1iud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Old-Cardiologist-633","can_mod_post":false,"created_utc":1752842314,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_9kn8k4e4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An vLLM for searching eroors and pitfalls in PCB Designs. In best case even possible from only PCB Layers in a PDF file.\\nWas one of my hardest challenges 😅","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3t1iud","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An vLLM for searching eroors and pitfalls in PCB Designs. In best case even possible from only PCB Layers in a PDF file.\\nWas one of my hardest challenges 😅&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3t1iud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752842314,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3t66fz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FlatImpact4554","can_mod_post":false,"created_utc":1752843894,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_vmyjavmw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how to please my wife . go!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3t66fz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how to please my wife . go!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3t66fz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752843894,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3tdki0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Monkey_1505","can_mod_post":false,"created_utc":1752846246,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_7qrmh9n9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Embodied logic. How things work in the world. \\n\\nWhere something or someone is in relation to something else, how things or people interact (physics, world modelling, 3d space, distance, technology, biology etc). Embodied reasoning AI fails tremendously badly at. \\n\\nIf you can build that on the weekend, you should build AGI the weekend after lol.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3tdki0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Embodied logic. How things work in the world. &lt;/p&gt;\\n\\n&lt;p&gt;Where something or someone is in relation to something else, how things or people interact (physics, world modelling, 3d space, distance, technology, biology etc). Embodied reasoning AI fails tremendously badly at. &lt;/p&gt;\\n\\n&lt;p&gt;If you can build that on the weekend, you should build AGI the weekend after lol.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3tdki0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752846246,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3thjth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Prudent_Student2839","can_mod_post":false,"created_utc":1752847453,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_czjyzxrs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that predicts baseball game winners that beats Vegas. You will not succeed","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3thjth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that predicts baseball game winners that beats Vegas. You will not succeed&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3thjth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752847453,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uq5nf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-dysangel-","can_mod_post":false,"created_utc":1752860062,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_12ggykute6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that solves P vs NP","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uq5nf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that solves P vs NP&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3uq5nf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752860062,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3uvb27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"boring-developer666","can_mod_post":false,"created_utc":1752861495,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_im63axc3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An LLM that goes through available medical research and find the cure for cancer and aids.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uvb27","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An LLM that goes through available medical research and find the cure for cancer and aids.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3uvb27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752861495,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q7m81","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thoguth","can_mod_post":false,"created_utc":1752796704,"send_replies":true,"parent_id":"t3_1m2ml3n","score":1,"author_fullname":"t2_8ovvo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An LLM \\"counselor\\" that\\n\\n\\n- adheres to professional ethical standards of safety and protection for the client\\n- employs evidence-based techniques to drive rapid and long lasting reduction in harmful behaviors, increase of beneficial behaviors, and long-term quality of life\\n- can demonstrate measurable impacts comparable to professional, licensed counselors in clinical trials, both in short term efficacy and long term sustained improvement for counsel-ees","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q7m81","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An LLM &amp;quot;counselor&amp;quot; that&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;adheres to professional ethical standards of safety and protection for the client&lt;/li&gt;\\n&lt;li&gt;employs evidence-based techniques to drive rapid and long lasting reduction in harmful behaviors, increase of beneficial behaviors, and long-term quality of life&lt;/li&gt;\\n&lt;li&gt;can demonstrate measurable impacts comparable to professional, licensed counselors in clinical trials, both in short term efficacy and long term sustained improvement for counsel-ees&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q7m81/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796704,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qyf8b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FreshmanCult","can_mod_post":false,"created_utc":1752806384,"send_replies":true,"parent_id":"t1_n3q48et","score":2,"author_fullname":"t2_1hf3590","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Check out my recent post","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qyf8b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Check out my recent post&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qyf8b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752806384,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sbz3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CommunityTough1","can_mod_post":false,"created_utc":1752830750,"send_replies":true,"parent_id":"t1_n3q48et","score":1,"author_fullname":"t2_1iuzpxw7eg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Please tune my lawnmower engine to be as fast as a Ferrari!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sbz3f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please tune my lawnmower engine to be as fast as a Ferrari!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3sbz3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752830750,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qnmf0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"theshadowraven","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q6yea","score":1,"author_fullname":"t2_49abw3rv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you're right that they want examples of impossible agents not a totally new or even fine tuned existing LLM. Sorry, my mistake. It is virtually impossible probably even in the next few years. I know they have good smaller models relatively speaking but, yeah. I don't see one that is a small fraction of one of the \\"big ones\\" beating them any time soon. Now...if only they could get an agent to...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qnmf0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you&amp;#39;re right that they want examples of impossible agents not a totally new or even fine tuned existing LLM. Sorry, my mistake. It is virtually impossible probably even in the next few years. I know they have good smaller models relatively speaking but, yeah. I don&amp;#39;t see one that is a small fraction of one of the &amp;quot;big ones&amp;quot; beating them any time soon. Now...if only they could get an agent to...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qnmf0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802409,"author_flair_text":null,"treatment_tags":[],"created_utc":1752802409,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q6yea","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Appropriate-Career62","can_mod_post":false,"created_utc":1752796473,"send_replies":true,"parent_id":"t1_n3q48et","score":1,"author_fullname":"t2_6bcuuj6o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"brother needs some funds for this, especially if he wants to do it in 2 days 🤣 however I think he meant that he will create some sort of agent from an existing ai","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q6yea","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;brother needs some funds for this, especially if he wants to do it in 2 days 🤣 however I think he meant that he will create some sort of agent from an existing ai&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q6yea/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796473,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q48et","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"theshadowraven","can_mod_post":false,"created_utc":1752795549,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_49abw3rv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI that is local, that can run on 8 to 12 GB of VRam, that is no bigger in parameters than 27B (like Gemma 27B), and can compete with Kimi on almost all tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q48et","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI that is local, that can run on 8 to 12 GB of VRam, that is no bigger in parameters than 27B (like Gemma 27B), and can compete with Kimi on almost all tasks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q48et/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795549,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q2tx9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"New_Comfortable7240","can_mod_post":false,"created_utc":1752795079,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_8k6ihe63","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Improve Amica, for example this issue to support Live2D, a format for 3D models\\n\\n\\nhttps://github.com/semperai/amica/issues/166","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q2tx9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Improve Amica, for example this issue to support Live2D, a format for 3D models&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/semperai/amica/issues/166\\"&gt;https://github.com/semperai/amica/issues/166&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q2tx9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795079,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q7rsp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1752796759,"send_replies":true,"parent_id":"t1_n3q4ibs","score":2,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The cure for cancer is to not make it a profitable subscription model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q7rsp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The cure for cancer is to not make it a profitable subscription model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q7rsp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796759,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q4ibs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Direct_Turn_1484","can_mod_post":false,"created_utc":1752795640,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_6ywe9a9n5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that can produce a unique AAA ranked studio grade game on demand.\\n\\nPlot, art, character rigging, animation, music, physics, code to tie each piece together. I think you’d need some serious domain knowledge in many different skill sets in order to even build the basic framework for something like that.\\n\\nThat or a cure for cancer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q4ibs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that can produce a unique AAA ranked studio grade game on demand.&lt;/p&gt;\\n\\n&lt;p&gt;Plot, art, character rigging, animation, music, physics, code to tie each piece together. I think you’d need some serious domain knowledge in many different skill sets in order to even build the basic framework for something like that.&lt;/p&gt;\\n\\n&lt;p&gt;That or a cure for cancer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q4ibs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795640,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qnyww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GrungeWerX","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q93ot","score":1,"author_fullname":"t2_7qduc583w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How? Link?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3qnyww","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How? Link?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qnyww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802537,"author_flair_text":null,"treatment_tags":[],"created_utc":1752802537,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q93ot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1752797231,"send_replies":true,"parent_id":"t1_n3q2yc4","score":2,"author_fullname":"t2_8fu8sqhz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But isn't that doable with whisper? whisper-ctranslate2 has speaker diarization, and with a 16gb gpu it will transcribe much, much faster than realtime even with the large model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q93ot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But isn&amp;#39;t that doable with whisper? whisper-ctranslate2 has speaker diarization, and with a 16gb gpu it will transcribe much, much faster than realtime even with the large model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q93ot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797231,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qeqin","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LilPsychoPanda","can_mod_post":false,"created_utc":1752799234,"send_replies":true,"parent_id":"t1_n3q2yc4","score":1,"author_fullname":"t2_unob1tlpm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’m literally doing this on my 1080ti and it can handle live text-to-speech, streaming and video recording… all at the same time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qeqin","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m literally doing this on my 1080ti and it can handle live text-to-speech, streaming and video recording… all at the same time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qeqin/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752799234,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q2yc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dana4684","can_mod_post":false,"created_utc":1752795120,"send_replies":true,"parent_id":"t3_1m2ml3n","score":-1,"author_fullname":"t2_1bbuh0l9oh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A speech to text model that can easily handle an hour of audio and identify individual speakers and runs on a single 16GB max GPU.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q2yc4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A speech to text model that can easily handle an hour of audio and identify individual speakers and runs on a single 16GB max GPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q2yc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795120,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q3tz6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bralynn2222","can_mod_post":false,"created_utc":1752795414,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_769j0jzd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A model that can reliably code Vulkan base gpu powered games/apps even 2d crippled grok 4 heavy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q3tz6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A model that can reliably code Vulkan base gpu powered games/apps even 2d crippled grok 4 heavy&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q3tz6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795414,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q7c46","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"disspoasting","can_mod_post":false,"created_utc":1752796606,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_69c997s8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Creating Splunk Search Processing Language (SPL) queries and analysing splunk data, including being trained on crowdstrike falcon ingested data, not just standard Windows system logs (windows system log documentation would also be in training data)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q7c46","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Creating Splunk Search Processing Language (SPL) queries and analysing splunk data, including being trained on crowdstrike falcon ingested data, not just standard Windows system logs (windows system log documentation would also be in training data)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q7c46/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796606,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q7eig","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KillerX629","can_mod_post":false,"created_utc":1752796629,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_1ve6ehh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Easy, make an expert at creating drivers for devices!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q7eig","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Easy, make an expert at creating drivers for devices!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q7eig/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796629,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q7q9a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lazy-Pattern-5171","can_mod_post":false,"created_utc":1752796744,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_1lyjk8is25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does ASR/Speech input count as AI for you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q7q9a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does ASR/Speech input count as AI for you?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q7q9a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752796744,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qazij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"created_utc":1752797895,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just have something of existing normal intelligence for a 6-8B params model *but always beats the current ZeroGPT tool at A.I. detection\\"*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qazij","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just have something of existing normal intelligence for a 6-8B params model &lt;em&gt;but always beats the current ZeroGPT tool at A.I. detection&amp;quot;&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qazij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797895,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qkvsh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"linguistic-intuition","can_mod_post":false,"created_utc":1752801413,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_5hcj4y6d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Make it answer the question if P=NP.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qkvsh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Make it answer the question if P=NP.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qkvsh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752801413,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qly70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grady_vuckovic","can_mod_post":false,"created_utc":1752801801,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_2wn7vbbo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that will show up to work for me and no one realises it's an AI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qly70","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that will show up to work for me and no one realises it&amp;#39;s an AI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qly70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752801801,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qm5rz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keyser1884","can_mod_post":false,"created_utc":1752801877,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_h0yti","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Honestly, something that can automatically decompile executables into usable source code would be a really useful tool","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qm5rz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly, something that can automatically decompile executables into usable source code would be a really useful tool&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qm5rz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752801877,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qwa1n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Porespellar","can_mod_post":false,"created_utc":1752805579,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_y35oj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have an LLM solve a WW2 era ENIGMA cipher \\nUse CyberChef to encrypt your plaintext into ENIGMA ciphertext and then give your Expert AI  the encrypted text and see if it can brute force it with its brainpower to solve the cipher. \\nhttps://gchq.github.io/CyberChef/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qwa1n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have an LLM solve a WW2 era ENIGMA cipher \\nUse CyberChef to encrypt your plaintext into ENIGMA ciphertext and then give your Expert AI  the encrypted text and see if it can brute force it with its brainpower to solve the cipher. \\n&lt;a href=\\"https://gchq.github.io/CyberChef/\\"&gt;https://gchq.github.io/CyberChef/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3qwa1n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752805579,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rp64s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zelda_shortener","can_mod_post":false,"created_utc":1752818118,"send_replies":true,"parent_id":"t3_1m2ml3n","score":0,"author_fullname":"t2_11hyit","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An AI that takes the burden of coming up with a weekly meal plan for me. I want to be given a list of groceries and a plan for the week.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rp64s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An AI that takes the burden of coming up with a weekly meal plan for me. I want to be given a list of groceries and a plan for the week.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3rp64s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752818118,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q8qdn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TedHoliday","can_mod_post":false,"created_utc":1752797098,"send_replies":true,"parent_id":"t3_1m2ml3n","score":-1,"author_fullname":"t2_1jmvj3ldz3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"By the time you have identified a technical problem and outlined its solution sufficiently enough that an LLM could solve it, it’s already been solved anyway and the rest is just procedure.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q8qdn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By the time you have identified a technical problem and outlined its solution sufficiently enough that an LLM could solve it, it’s already been solved anyway and the rest is just procedure.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q8qdn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752797098,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3q1hci","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DarkVoid42","can_mod_post":false,"created_utc":1752794631,"send_replies":true,"parent_id":"t3_1m2ml3n","score":-2,"author_fullname":"t2_uqq3944i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI that can detect objects in real time video and classify them with a moving background. think sky or sea.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q1hci","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI that can detect objects in real time video and classify them with a moving background. think sky or sea.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q1hci/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752794631,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3swyou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3q4n1w","score":1,"author_fullname":"t2_13jvln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, they can do those things. Are you using free tools as your reference?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3swyou","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, they can do those things. Are you using free tools as your reference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3swyou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752840651,"author_flair_text":null,"treatment_tags":[],"created_utc":1752840651,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q4n1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Prestigious-Fan118","can_mod_post":false,"created_utc":1752795684,"send_replies":true,"parent_id":"t1_n3q3bww","score":9,"author_fullname":"t2_1khzsxj24m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Current LLMs can explain WHAT a CUDA kernel is. They can’t optimize YOUR specific kernel for a 4090 vs an A100.\\n\\nThey can tell you about race conditions. They can’t find the actual race condition in your production code and generate the mutex implementation to fix it.\\n\\nBig difference between Wikipedia knowledge and actual expertise. But I hear you let’s see what the community comes up with for challenges.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q4n1w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Current LLMs can explain WHAT a CUDA kernel is. They can’t optimize YOUR specific kernel for a 4090 vs an A100.&lt;/p&gt;\\n\\n&lt;p&gt;They can tell you about race conditions. They can’t find the actual race condition in your production code and generate the mutex implementation to fix it.&lt;/p&gt;\\n\\n&lt;p&gt;Big difference between Wikipedia knowledge and actual expertise. But I hear you let’s see what the community comes up with for challenges.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2ml3n","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q4n1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795684,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n3q3bww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"SpacemanCraig3","can_mod_post":false,"created_utc":1752795244,"send_replies":true,"parent_id":"t3_1m2ml3n","score":-5,"author_fullname":"t2_13jvln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Your examples are all things that LLMs can do today.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3q3bww","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your examples are all things that LLMs can do today.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2ml3n/ill_build_an_expert_ai_for_your_impossible/n3q3bww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752795244,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2ml3n","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
