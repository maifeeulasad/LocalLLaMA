import{j as e}from"./index-Ce60G8KS.js";import{R as l}from"./RedditPostRenderer-Dxoi04TZ.js";import"./index-D3PeynhN.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"hi everybody i could use some help running the deepseek r1 1.58bit quant, i have a firm belief that something is capping generation speed. i tried reducing experts, quantizing kv cache, setting the batch eval to 8, 512, or 2048, core count to 16, 8, or 48 and even setting the max context length to a lower number and yet for some reason no matter what i change it wont go higher than 0.4 tokens/sec\\n\\n  \\ni tried adjusting power settings in windows to performance plan, and still it would not go higher. \\n\\n  \\ni'm using 256gb ddr4 8 channel memory @ 2933mhz and a single socket amd epyc7642, no gpu yet, i have one on its way. and the software im using is latest lm studio. \\n\\n  \\ncan anyone think of why their might be some sort of limit or cap? from benchmarks and user reddit posts i found online my cpu should be getting atleast 2 to 3 tokens/sec, so i'm little confused whats happening","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"i bought an epyc server with 7642 cpu, and im only getting 0.4 tokens/sec","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lmd6ns","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_73959oe7","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751081950,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;hi everybody i could use some help running the deepseek r1 1.58bit quant, i have a firm belief that something is capping generation speed. i tried reducing experts, quantizing kv cache, setting the batch eval to 8, 512, or 2048, core count to 16, 8, or 48 and even setting the max context length to a lower number and yet for some reason no matter what i change it wont go higher than 0.4 tokens/sec&lt;/p&gt;\\n\\n&lt;p&gt;i tried adjusting power settings in windows to performance plan, and still it would not go higher. &lt;/p&gt;\\n\\n&lt;p&gt;i&amp;#39;m using 256gb ddr4 8 channel memory @ 2933mhz and a single socket amd epyc7642, no gpu yet, i have one on its way. and the software im using is latest lm studio. &lt;/p&gt;\\n\\n&lt;p&gt;can anyone think of why their might be some sort of limit or cap? from benchmarks and user reddit posts i found online my cpu should be getting atleast 2 to 3 tokens/sec, so i&amp;#39;m little confused whats happening&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lmd6ns","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"pharrowking","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/","subreddit_subscribers":492232,"created_utc":1751081950,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06wi2w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pharrowking","can_mod_post":false,"created_utc":1751086047,"send_replies":true,"parent_id":"t1_n06up3s","score":1,"author_fullname":"t2_73959oe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks ill give that a try, also in the comment below i posted a picture of my ram info, does it seem right to you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06wi2w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks ill give that a try, also in the comment below i posted a picture of my ram info, does it seem right to you?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06wi2w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751086047,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06up3s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dr_Me_123","can_mod_post":false,"created_utc":1751085168,"send_replies":true,"parent_id":"t3_1lmd6ns","score":7,"author_fullname":"t2_59yau29b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Test your memory bandwidth. ( Intel MLC for example )","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06up3s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Test your memory bandwidth. ( Intel MLC for example )&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06up3s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751085168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07kkrp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Total_Activity_7550","can_mod_post":false,"created_utc":1751099127,"send_replies":true,"parent_id":"t3_1lmd6ns","score":3,"author_fullname":"t2_nwfj64go","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With older epyc you might even be compute-bound, not memory-bound. 1 GPU gives a huuuuge boost.\\nI don't use fancy-hacky forks, just use latest llama.cpp compiled from source with --numa distribute - -threads &lt;num phys cores not threads&gt;. If you haven't compiled, or if you have GPU, I will write more instructions to use.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07kkrp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With older epyc you might even be compute-bound, not memory-bound. 1 GPU gives a huuuuge boost.\\nI don&amp;#39;t use fancy-hacky forks, just use latest llama.cpp compiled from source with --numa distribute - -threads &amp;lt;num phys cores not threads&amp;gt;. If you haven&amp;#39;t compiled, or if you have GPU, I will write more instructions to use.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07kkrp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751099127,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07bv64","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"un_passant","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07amtm","score":1,"author_fullname":"t2_7rqtc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1","edited":false,"author_flair_css_class":null,"name":"t1_n07bv64","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmd6ns","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07bv64/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094079,"author_flair_text":null,"collapsed":false,"created_utc":1751094079,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07osfa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07amtm","score":1,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea, that's big bad. Go into bios and set it to just 1 NUMA node. Or to off? Not sure how they word it but yeah, needs to show up as 1 in the end or you'll get performance like that.","edited":false,"author_flair_css_class":null,"name":"t1_n07osfa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, that&amp;#39;s big bad. Go into bios and set it to just 1 NUMA node. Or to off? Not sure how they word it but yeah, needs to show up as 1 in the end or you&amp;#39;ll get performance like that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmd6ns","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07osfa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751101635,"author_flair_text":null,"collapsed":false,"created_utc":1751101635,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07amtm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pharrowking","can_mod_post":false,"send_replies":true,"parent_id":"t1_n079u7b","score":1,"author_fullname":"t2_73959oe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"When i ran mlc latency checker it said there was 15 numa nodes down and across , how many are there supposed to be?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07amtm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When i ran mlc latency checker it said there was 15 numa nodes down and across , how many are there supposed to be?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07amtm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093408,"author_flair_text":null,"treatment_tags":[],"created_utc":1751093408,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n079u7b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06ws2a","score":4,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Read more on this post https://www.reddit.com/r/LocalLLaMA/comments/1kzfrdt/ubergarmdeepseekr10528gguf/\\n\\nYou want that fancy quant and ik_llama.cpp with specificly Nvidia GPU to pair with your epyc CPU. The performance gap is very large.\\n\\nAlso, you probably want to check some of the params being passed. Play around with the threads, don't do all of your threads especially on windows. Any side task what so ever will tank your tokens if you maxed out threads. \\n\\nAlso make sure there isn't a NUMA issue, it can be configured wrong with multiple nodes even on single CPU system. And turn SMT off.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n079u7b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Read more on this post &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1kzfrdt/ubergarmdeepseekr10528gguf/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1kzfrdt/ubergarmdeepseekr10528gguf/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;You want that fancy quant and ik_llama.cpp with specificly Nvidia GPU to pair with your epyc CPU. The performance gap is very large.&lt;/p&gt;\\n\\n&lt;p&gt;Also, you probably want to check some of the params being passed. Play around with the threads, don&amp;#39;t do all of your threads especially on windows. Any side task what so ever will tank your tokens if you maxed out threads. &lt;/p&gt;\\n\\n&lt;p&gt;Also make sure there isn&amp;#39;t a NUMA issue, it can be configured wrong with multiple nodes even on single CPU system. And turn SMT off.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n079u7b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092980,"author_flair_text":null,"treatment_tags":[],"created_utc":1751092980,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07csrt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pharrowking","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07a6s6","score":1,"author_fullname":"t2_73959oe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nps was set to nps4, i changed it to 1 and applied additional performance settings  just doing a quick test now to see if theres improvement\\n\\n\\n\\n\\nUpdate: nope still capped at 0.4","edited":1751095063,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07csrt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nps was set to nps4, i changed it to 1 and applied additional performance settings  just doing a quick test now to see if theres improvement&lt;/p&gt;\\n\\n&lt;p&gt;Update: nope still capped at 0.4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07csrt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094597,"author_flair_text":null,"treatment_tags":[],"created_utc":1751094597,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n07a6s6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06ws2a","score":2,"author_fullname":"t2_8lvrytgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You should switch to the models that I linked \\n\\n\\nNPS ?\\nNb thread should be nb cores.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n07a6s6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should switch to the models that I linked &lt;/p&gt;\\n\\n&lt;p&gt;NPS ?\\nNb thread should be nb cores.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07a6s6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093168,"author_flair_text":null,"treatment_tags":[],"created_utc":1751093168,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n06ws2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pharrowking","can_mod_post":false,"created_utc":1751086182,"send_replies":true,"parent_id":"t1_n06wfmm","score":1,"author_fullname":"t2_73959oe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i am using unsloth dynamic quants at 1.58bits","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06ws2a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i am using unsloth dynamic quants at 1.58bits&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06ws2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751086182,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06wfmm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1751086012,"send_replies":true,"parent_id":"t3_1lmd6ns","score":3,"author_fullname":"t2_8lvrytgw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are you using ik_llama.cpp and specific quants from https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF ?\\n\\n\\nWhat is the NUMA per socket in the BIOS ? Make sure it is NPS1.","edited":1751093043,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06wfmm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you using ik_llama.cpp and specific quants from &lt;a href=\\"https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF\\"&gt;https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF&lt;/a&gt; ?&lt;/p&gt;\\n\\n&lt;p&gt;What is the NUMA per socket in the BIOS ? Make sure it is NPS1.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06wfmm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751086012,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07n4y5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kmouratidis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06vmv7","score":1,"author_fullname":"t2_k6u7rfxb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1466.7 * 2 = 2933.4\\n\\n\\nIt's *Double* Data Rate.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n07n4y5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1466.7 * 2 = 2933.4&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s &lt;em&gt;Double&lt;/em&gt; Data Rate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07n4y5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751100649,"author_flair_text":null,"treatment_tags":[],"created_utc":1751100649,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06vmv7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pharrowking","can_mod_post":false,"created_utc":1751085620,"send_replies":true,"parent_id":"t1_n06txj1","score":1,"author_fullname":"t2_73959oe7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"when i opened it up there are only 8 slots, for 8 channel to work they would all need to be filled, which they are. and my system reports  8 channel ram, in windows task manager my ram is running at 2933, but i'm wondering if im reading this right HWinfo shows the following\\n\\nhttps://preview.redd.it/k12fceakkl9f1.png?width=361&amp;format=png&amp;auto=webp&amp;s=6a275d2dc8ed9396830f17e2cd5cf666fc6e6f3c","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06vmv7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;when i opened it up there are only 8 slots, for 8 channel to work they would all need to be filled, which they are. and my system reports  8 channel ram, in windows task manager my ram is running at 2933, but i&amp;#39;m wondering if im reading this right HWinfo shows the following&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/k12fceakkl9f1.png?width=361&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6a275d2dc8ed9396830f17e2cd5cf666fc6e6f3c\\"&gt;https://preview.redd.it/k12fceakkl9f1.png?width=361&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6a275d2dc8ed9396830f17e2cd5cf666fc6e6f3c&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmd6ns","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06vmv7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751085620,"media_metadata":{"k12fceakkl9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":87,"x":108,"u":"https://preview.redd.it/k12fceakkl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f50c2062d1c619db21927c1f9a30fc19239d7550"},{"y":174,"x":216,"u":"https://preview.redd.it/k12fceakkl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=12dc0d598f03090f14c71afe57af8cd6249291d8"},{"y":257,"x":320,"u":"https://preview.redd.it/k12fceakkl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4f18936d07426d8fe715a7c31febebfae9a9385"}],"s":{"y":291,"x":361,"u":"https://preview.redd.it/k12fceakkl9f1.png?width=361&amp;format=png&amp;auto=webp&amp;s=6a275d2dc8ed9396830f17e2cd5cf666fc6e6f3c"},"id":"k12fceakkl9f1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06txj1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1751084798,"send_replies":true,"parent_id":"t3_1lmd6ns","score":1,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This may be a silly question, but it's best to start with the obvious:  Are your memory sticks all plugged into different channels, or are they plugged into slots which share a channel?  Usually the \\"top\\" memory slot for a given channel is color-coded blue, and the subsidiary slots for the channel are black, or similar coding scheme.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06txj1","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This may be a silly question, but it&amp;#39;s best to start with the obvious:  Are your memory sticks all plugged into different channels, or are they plugged into slots which share a channel?  Usually the &amp;quot;top&amp;quot; memory slot for a given channel is color-coded blue, and the subsidiary slots for the channel are black, or similar coding scheme.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n06txj1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751084798,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07wa38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dc740","can_mod_post":false,"created_utc":1751106057,"send_replies":true,"parent_id":"t3_1lmd6ns","score":1,"author_fullname":"t2_dkwhd0p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This got me really surprised. Using a xeon 6138, with lower speed memory and a crappy nvidia P40 I get above 6tk/s with ik_llama using the unsloth gguf. I'm not even using ik_llama optimized quants. You should be getting higher numbers. There is something very wrong here","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07wa38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This got me really surprised. Using a xeon 6138, with lower speed memory and a crappy nvidia P40 I get above 6tk/s with ik_llama using the unsloth gguf. I&amp;#39;m not even using ik_llama optimized quants. You should be getting higher numbers. There is something very wrong here&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07wa38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751106057,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07a1db","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ciprianveg","can_mod_post":false,"created_utc":1751093087,"send_replies":true,"parent_id":"t3_1lmd6ns","score":1,"author_fullname":"t2_j8fit2p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Add a 3090 24gb to the system and use ik_llama.cpp. you should get 8-10t/s. https://www.reddit.com/r/LocalLLaMA/s/y9RrwGfZCT","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07a1db","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Add a 3090 24gb to the system and use ik_llama.cpp. you should get 8-10t/s. &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/s/y9RrwGfZCT\\"&gt;https://www.reddit.com/r/LocalLLaMA/s/y9RrwGfZCT&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmd6ns/i_bought_an_epyc_server_with_7642_cpu_and_im_only/n07a1db/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093087,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmd6ns","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
