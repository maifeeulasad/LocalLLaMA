import{j as l}from"./index-CWmJdUH_.js";import{R as e}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I‚Äôm working on a browser automation system that follows a planned sequence of UI actions, but needs an LLM to resolve which DOM element to click when there are multiple similar options. I‚Äôve been using **Browser-Use**, which is solid for tracking state/actions, but execution is too slow ‚Äî especially when an LLM is in the loop at each step.\\n\\n**Example flow (on Google settings):**\\n\\n1. Go to [myaccount.google.com](https://myaccount.google.com)\\n2. Click ‚ÄúData &amp; privacy‚Äù\\n3. Scroll down\\n4. Click ‚ÄúDelete a service or your account‚Äù\\n5. Click ‚ÄúDelete your Google Account‚Äù\\n\\n**Looking for suggestions:**\\n\\n* Fastest models for small structured decision tasks \\n* Ways to be under 1s per step (ideally &lt;500ms)\\n\\nI don‚Äôt need full chat reasoning ‚Äî just high-confidence decisions from small JSON lists.\\n\\nWould love to hear what setups/models have worked for you in similar low-latency UI agent tasks üôè","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"[Help] Fastest model for real-time UI automation? (Browser-Use too slow)","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lyjgwv","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.93,"author_flair_background_color":null,"subreddit_type":"public","ups":12,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_8fuwhsmu","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":12,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752379254,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I‚Äôm working on a browser automation system that follows a planned sequence of UI actions, but needs an LLM to resolve which DOM element to click when there are multiple similar options. I‚Äôve been using &lt;strong&gt;Browser-Use&lt;/strong&gt;, which is solid for tracking state/actions, but execution is too slow ‚Äî especially when an LLM is in the loop at each step.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Example flow (on Google settings):&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Go to &lt;a href=\\"https://myaccount.google.com\\"&gt;myaccount.google.com&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Click ‚ÄúData &amp;amp; privacy‚Äù&lt;/li&gt;\\n&lt;li&gt;Scroll down&lt;/li&gt;\\n&lt;li&gt;Click ‚ÄúDelete a service or your account‚Äù&lt;/li&gt;\\n&lt;li&gt;Click ‚ÄúDelete your Google Account‚Äù&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Looking for suggestions:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Fastest models for small structured decision tasks &lt;/li&gt;\\n&lt;li&gt;Ways to be under 1s per step (ideally &amp;lt;500ms)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I don‚Äôt need full chat reasoning ‚Äî just high-confidence decisions from small JSON lists.&lt;/p&gt;\\n\\n&lt;p&gt;Would love to hear what setups/models have worked for you in similar low-latency UI agent tasks üôè&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lyjgwv","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"BulkyAd7044","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/","subreddit_subscribers":498344,"created_utc":1752379254,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ueu3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BulkyAd7044","can_mod_post":false,"created_utc":1752379977,"send_replies":true,"parent_id":"t1_n2uelaw","score":3,"author_fullname":"t2_8fuwhsmu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agreed, I think under 500 ms would only be possible after caching prev","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ueu3b","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agreed, I think under 500 ms would only be possible after caching prev&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyjgwv","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2ueu3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752379977,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uelaw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"created_utc":1752379871,"send_replies":true,"parent_id":"t3_1lyjgwv","score":3,"author_fullname":"t2_usojvms","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it's a flow that's pretty consistent / not dynamic / pre known playwright on it's own sans LLM would be the best option. \\n\\nUnder 500ms is going to be really tough damn near impossible with an LLM in the loop.\\n\\nJust commenting mostly so I can see other opinions as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uelaw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s a flow that&amp;#39;s pretty consistent / not dynamic / pre known playwright on it&amp;#39;s own sans LLM would be the best option. &lt;/p&gt;\\n\\n&lt;p&gt;Under 500ms is going to be really tough damn near impossible with an LLM in the loop.&lt;/p&gt;\\n\\n&lt;p&gt;Just commenting mostly so I can see other opinions as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2uelaw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752379871,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyjgwv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2uu98w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BulkyAd7044","can_mod_post":false,"created_utc":1752387564,"send_replies":true,"parent_id":"t1_n2ukszs","score":1,"author_fullname":"t2_8fuwhsmu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much will check this out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uu98w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much will check this out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyjgwv","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2uu98w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387564,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ukszs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1752382717,"send_replies":true,"parent_id":"t3_1lyjgwv","score":2,"author_fullname":"t2_131eezppgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This would work well:\\n\\n\\n1. DistilBERT layers for DOM node text embeddings\\n\\n\\n2. Tree-LSTM layers\\n\\n\\n3. GNN layers\\n\\n\\n4. Global pooling layer\\n\\n\\n5. MLP classification head","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ukszs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This would work well:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;DistilBERT layers for DOM node text embeddings&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Tree-LSTM layers&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;GNN layers&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Global pooling layer&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;MLP classification head&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2ukszs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752382717,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyjgwv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2uv01w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BulkyAd7044","can_mod_post":false,"created_utc":1752387969,"send_replies":true,"parent_id":"t1_n2ur5od","score":1,"author_fullname":"t2_8fuwhsmu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hmm not sure if this would work, quick glance shows it‚Äôs for repeating fixed flows? I want to dynamically understand and react to ui, thanks tho lmk if anything else I should look into","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uv01w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmm not sure if this would work, quick glance shows it‚Äôs for repeating fixed flows? I want to dynamically understand and react to ui, thanks tho lmk if anything else I should look into&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyjgwv","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2uv01w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387969,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ur5od","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1752385920,"send_replies":true,"parent_id":"t3_1lyjgwv","score":1,"author_fullname":"t2_askwa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"you can use RPA such as UI path or power automate","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ur5od","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can use RPA such as UI path or power automate&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2ur5od/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752385920,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyjgwv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vp8ro","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Porespellar","can_mod_post":false,"created_utc":1752405291,"send_replies":true,"parent_id":"t3_1lyjgwv","score":2,"author_fullname":"t2_y35oj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There are two interesting Microsoft projects you may want to look into.\\n\\nThe Ominoparser 2 stack (Omniparser 2 / Omnitool / Omnibox\\n\\nhttps://github.com/microsoft/OmniParser\\n\\nMagentic UI (with the Ollama option turned on for local model support and Qwen2.5-VL-32b as the vision model)\\n\\nhttps://github.com/microsoft/magentic-ui","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vp8ro","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are two interesting Microsoft projects you may want to look into.&lt;/p&gt;\\n\\n&lt;p&gt;The Ominoparser 2 stack (Omniparser 2 / Omnitool / Omnibox&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/microsoft/OmniParser\\"&gt;https://github.com/microsoft/OmniParser&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Magentic UI (with the Ollama option turned on for local model support and Qwen2.5-VL-32b as the vision model)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/microsoft/magentic-ui\\"&gt;https://github.com/microsoft/magentic-ui&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyjgwv/help_fastest_model_for_realtime_ui_automation/n2vp8ro/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752405291,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyjgwv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>l.jsx(e,{data:t});export{s as default};
