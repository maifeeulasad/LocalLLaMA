import{j as e}from"./index-sMC9-RRY.js";import{R as l}from"./RedditPostRenderer-pY-fX8U9.js";import"./index-8OT1L0zU.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"* Especialized in translation. Mostly from Spanish to English and Japanese.\\n* Model that can be run locally, but I don't mind if it requires a high-end computer.\\n* Should be able to translate very large texts (I'm talking about full novels here). I understand it would need to be divided in sections first, but I would like to know which ones allow for the maximum amount of context per section.\\n* Would like to know if there are any tools that streamline the process, especially when it comes to actual documents like Excel.\\n\\nI've been checking around and there's Ollama as a tool which seems simple enough and I can probably configure further, but I'm not sure if someone made a more straightforward tool just for translation.\\n\\nThen for actual models I'm not sure which ones are better at translating: Gemma? Deepseek? I checked some like nllb that are supposed to be especialized in translation but I think they weren't all that great, even actually worse than non-specialized models. Is this normal or am I doing something wrong?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Looking for a local LLM translator for large documents and especialized tools","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lmxduv","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.72,"author_flair_background_color":null,"subreddit_type":"public","ups":3,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_i8aws","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":3,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751144761,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;ul&gt;\\n&lt;li&gt;Especialized in translation. Mostly from Spanish to English and Japanese.&lt;/li&gt;\\n&lt;li&gt;Model that can be run locally, but I don&amp;#39;t mind if it requires a high-end computer.&lt;/li&gt;\\n&lt;li&gt;Should be able to translate very large texts (I&amp;#39;m talking about full novels here). I understand it would need to be divided in sections first, but I would like to know which ones allow for the maximum amount of context per section.&lt;/li&gt;\\n&lt;li&gt;Would like to know if there are any tools that streamline the process, especially when it comes to actual documents like Excel.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been checking around and there&amp;#39;s Ollama as a tool which seems simple enough and I can probably configure further, but I&amp;#39;m not sure if someone made a more straightforward tool just for translation.&lt;/p&gt;\\n\\n&lt;p&gt;Then for actual models I&amp;#39;m not sure which ones are better at translating: Gemma? Deepseek? I checked some like nllb that are supposed to be especialized in translation but I think they weren&amp;#39;t all that great, even actually worse than non-specialized models. Is this normal or am I doing something wrong?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lmxduv","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Keinart","discussion_type":null,"num_comments":1,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmxduv/looking_for_a_local_llm_translator_for_large/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lmxduv/looking_for_a_local_llm_translator_for_large/","subreddit_subscribers":492625,"created_utc":1751144761,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bx76n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MaruluVR","can_mod_post":false,"created_utc":1751157141,"send_replies":true,"parent_id":"t3_1lmxduv","score":2,"author_fullname":"t2_10ryluzwb5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For Japanese you want to use models specifically trained on it, Shisa is making some great models for this purpose, they currently are working on adding improved Japanese capabilities to Qwen3\\n\\n[https://www.reddit.com/r/LocalLLaMA/comments/1jz2lll/shisa\\\\_v2\\\\_a\\\\_family\\\\_of\\\\_new\\\\_jaen\\\\_bilingual\\\\_models/](https://www.reddit.com/r/LocalLLaMA/comments/1jz2lll/shisa_v2_a_family_of_new_jaen_bilingual_models/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bx76n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For Japanese you want to use models specifically trained on it, Shisa is making some great models for this purpose, they currently are working on adding improved Japanese capabilities to Qwen3&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1jz2lll/shisa_v2_a_family_of_new_jaen_bilingual_models/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jz2lll/shisa_v2_a_family_of_new_jaen_bilingual_models/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmxduv/looking_for_a_local_llm_translator_for_large/n0bx76n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751157141,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lmxduv","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
