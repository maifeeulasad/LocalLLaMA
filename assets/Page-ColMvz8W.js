import{j as e}from"./index-BOnf-UhU.js";import{R as l}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"This model is really fascinating. I find it absolutely amazing. I believe that if this model gets added reasoning abilities it will beat absolutely everything on the market right now.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Would there be a reasoning version of Kimi K2?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m3qc1g","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.82,"author_flair_background_color":null,"subreddit_type":"public","ups":21,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_2ad0xr96","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":21,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752910555,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;This model is really fascinating. I find it absolutely amazing. I believe that if this model gets added reasoning abilities it will beat absolutely everything on the market right now.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m3qc1g","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"christian7670","discussion_type":null,"num_comments":18,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/","subreddit_subscribers":502030,"created_utc":1752910555,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ynkls","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nomorebuttsplz","can_mod_post":false,"created_utc":1752912999,"send_replies":true,"parent_id":"t3_1m3qc1g","score":12,"author_fullname":"t2_syq52","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It already does quite a bit of reasoning when called for, and does it well","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ynkls","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It already does quite a bit of reasoning when called for, and does it well&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3ynkls/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752912999,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n40183e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GreatBigJerk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z0fno","score":3,"author_fullname":"t2_650y4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They said it's coming out this summer.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n40183e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They said it&amp;#39;s coming out this summer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n40183e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752935187,"author_flair_text":null,"treatment_tags":[],"created_utc":1752935187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n40v98d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"davikrehalt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z0fno","score":2,"author_fullname":"t2_6okc6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"should be &lt;1 month","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n40v98d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;should be &amp;lt;1 month&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n40v98d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752944567,"author_flair_text":null,"treatment_tags":[],"created_utc":1752944567,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n40m59x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z0fno","score":1,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"take a look at their latest coding model.\\n\\nIt is currently the 2nd best coder in the world.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n40m59x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;take a look at their latest coding model.&lt;/p&gt;\\n\\n&lt;p&gt;It is currently the 2nd best coder in the world.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n40m59x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752941704,"author_flair_text":null,"treatment_tags":[],"created_utc":1752941704,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z0fno","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TechnoByte_","can_mod_post":false,"created_utc":1752920303,"send_replies":true,"parent_id":"t1_n3yknhq","score":10,"author_fullname":"t2_4w91lkml","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"People have been saying GPT-5 is imminent for over 2 years now.\\n\\nBut OpenAI seems more focused on new GPT-4 and O-series reasoning models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z0fno","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People have been saying GPT-5 is imminent for over 2 years now.&lt;/p&gt;\\n\\n&lt;p&gt;But OpenAI seems more focused on new GPT-4 and O-series reasoning models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3z0fno/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752920303,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n425vrv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Salty-Garage7777","can_mod_post":false,"created_utc":1752959406,"send_replies":true,"parent_id":"t1_n3yknhq","score":2,"author_fullname":"t2_14m2ycs468","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, if it's twenty times cheaper, it won't be! ðŸ˜ƒ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n425vrv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, if it&amp;#39;s twenty times cheaper, it won&amp;#39;t be! ðŸ˜ƒ&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n425vrv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752959406,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yknhq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752911374,"send_replies":true,"parent_id":"t3_1m3qc1g","score":12,"author_fullname":"t2_5hobp6m4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably, but it may be overshadowed since new releases are imminent from other labs. R2, Gemini 3, GPT-5 etc.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yknhq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably, but it may be overshadowed since new releases are imminent from other labs. R2, Gemini 3, GPT-5 etc.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3yknhq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911374,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ykait","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FluffnPuff_Rebirth","can_mod_post":false,"created_utc":1752911173,"send_replies":true,"parent_id":"t3_1m3qc1g","score":1,"author_fullname":"t2_hptjq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Considering how well the other non-reasoning models could reason when that was the new hype thing, even without being specifically trained for it, with just prompting and system instructions, yeah probably. Sure, the performance back then wasn't as performant as for a properly trained reasoning model, but even many non-reasoning models still benefited from yapping to themselves. I suspect a reasoning variant of this will become a thing in one way or another. Officially or otherwise.","edited":1752911453,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ykait","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Considering how well the other non-reasoning models could reason when that was the new hype thing, even without being specifically trained for it, with just prompting and system instructions, yeah probably. Sure, the performance back then wasn&amp;#39;t as performant as for a properly trained reasoning model, but even many non-reasoning models still benefited from yapping to themselves. I suspect a reasoning variant of this will become a thing in one way or another. Officially or otherwise.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3ykait/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911173,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3zd6he","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"synn89","can_mod_post":false,"created_utc":1752926383,"send_replies":true,"parent_id":"t3_1m3qc1g","score":1,"author_fullname":"t2_3jm4t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe. Though I suspect agent use where the AI self inspects and consults external topics may be the next thing. This is what make Grok 4 so good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3zd6he","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe. Though I suspect agent use where the AI self inspects and consults external topics may be the next thing. This is what make Grok 4 so good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3zd6he/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752926383,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n438xqb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1752973192,"send_replies":true,"parent_id":"t3_1m3qc1g","score":1,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I sure hope so because kimi k2 is useless in cline (openrouter)\\n\\nFortunately, it's open weights, so people can likely fine tune that problem away.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n438xqb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I sure hope so because kimi k2 is useless in cline (openrouter)&lt;/p&gt;\\n\\n&lt;p&gt;Fortunately, it&amp;#39;s open weights, so people can likely fine tune that problem away.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n438xqb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752973192,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ymrmq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nullmove","can_mod_post":false,"created_utc":1752912548,"send_replies":true,"parent_id":"t1_n3ykr3n","score":7,"author_fullname":"t2_aq4j0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does know what MCP is, you have to disambiguate it as it's not a unique abbreviation (lots of models get confused too).\\n\\n&gt; Yes. MCP stands for Model Context Protocolâ€”an open, client/server protocol that Anthropic announced in November 2024 .....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ymrmq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does know what MCP is, you have to disambiguate it as it&amp;#39;s not a unique abbreviation (lots of models get confused too).&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Yes. MCP stands for Model Context Protocolâ€”an open, client/server protocol that Anthropic announced in November 2024 .....&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3ymrmq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752912548,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3z2r5e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"bitrumpled","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z0sv0","score":-5,"author_fullname":"t2_z5dk4aa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, I understand what you're saying about hallucinating its own idea about the cutoff date.  But if I am going to rely on a model for important stuff, I don't think it's crazy to expect it to be able to answer things like its cutoff date and quantization, even if they are fed to it by some pre-prompt.","edited":false,"author_flair_css_class":null,"name":"t1_n3z2r5e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, I understand what you&amp;#39;re saying about hallucinating its own idea about the cutoff date.  But if I am going to rely on a model for important stuff, I don&amp;#39;t think it&amp;#39;s crazy to expect it to be able to answer things like its cutoff date and quantization, even if they are fed to it by some pre-prompt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","link_id":"t3_1m3qc1g","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3z2r5e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752921549,"author_flair_text":null,"collapsed":true,"created_utc":1752921549,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z0sv0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TechnoByte_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yqhss","score":6,"author_fullname":"t2_4w91lkml","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You shouldn't expect a model to know its own knowledge cutoff, unless it's specifically told in its system prompt, which it doesn't seem to be, as it hallucinates a completely different date everytime I ask it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z0sv0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You shouldn&amp;#39;t expect a model to know its own knowledge cutoff, unless it&amp;#39;s specifically told in its system prompt, which it doesn&amp;#39;t seem to be, as it hallucinates a completely different date everytime I ask it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3z0sv0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752920505,"author_flair_text":null,"treatment_tags":[],"created_utc":1752920505,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3z4r26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bitrumpled","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z399i","score":1,"author_fullname":"t2_z5dk4aa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes my knowledge about its cutoff date begins and ends with what the model itself chose to say, Jun 2023, and that it did not understand what at 5090 was.\\n\\nMaybe the model it was based on had the Jun 2023 cutoff date and Kimi fine-tuned or otherwise trained it with more things.  That might explain why it can't parse MCP from the context of the discussion supposedly without extra disambiguation.","edited":false,"author_flair_css_class":null,"name":"t1_n3z4r26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes my knowledge about its cutoff date begins and ends with what the model itself chose to say, Jun 2023, and that it did not understand what at 5090 was.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe the model it was based on had the Jun 2023 cutoff date and Kimi fine-tuned or otherwise trained it with more things.  That might explain why it can&amp;#39;t parse MCP from the context of the discussion supposedly without extra disambiguation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m3qc1g","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3z4r26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752922556,"author_flair_text":null,"collapsed":false,"created_utc":1752922556,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z399i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yqhss","score":1,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ask it what the latest Claude model from Anthropic is. It knows about Sonnet-3.5.  That came out 20 June 2024 -- which disproves your Jun 2023 date.\\n\\nEdit:\\n\\n&gt; As of now, the latest Claude model from Anthropic is Claude 3.5 Sonnet. It was released in June 2024 and is positioned as their mid-tier modelâ€”more capable than Claude 3 Haiku and Claude 3 Opus, but optimized for speed and cost-efficiency. Claude 3.5 Sonnet outperforms Claude 3 Opus on most evaluations while being faster and cheaper to run.\\n\\nand what's Deepseek-R1?\\n\\n&gt; DeepSeek-R1 is a large reasoning-focused language model released in January 2025 by the Chinese AI lab DeepSeek. Itâ€™s a 67-billion-parameter mixture-of-experts (MoE) model trained with reinforcement-learning techniques specifically designed to excel at complex reasoning, mathematics, and code generation. DeepSeek-R1 is notable for:\\n\\nIt got the parameters wrong, but knew what it is and the date. This is at 1.8bit locally with no internet access.","edited":1752922036,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z399i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ask it what the latest Claude model from Anthropic is. It knows about Sonnet-3.5.  That came out 20 June 2024 -- which disproves your Jun 2023 date.&lt;/p&gt;\\n\\n&lt;p&gt;Edit:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;As of now, the latest Claude model from Anthropic is Claude 3.5 Sonnet. It was released in June 2024 and is positioned as their mid-tier modelâ€”more capable than Claude 3 Haiku and Claude 3 Opus, but optimized for speed and cost-efficiency. Claude 3.5 Sonnet outperforms Claude 3 Opus on most evaluations while being faster and cheaper to run.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;and what&amp;#39;s Deepseek-R1?&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;DeepSeek-R1 is a large reasoning-focused language model released in January 2025 by the Chinese AI lab DeepSeek. Itâ€™s a 67-billion-parameter mixture-of-experts (MoE) model trained with reinforcement-learning techniques specifically designed to excel at complex reasoning, mathematics, and code generation. DeepSeek-R1 is notable for:&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It got the parameters wrong, but knew what it is and the date. This is at 1.8bit locally with no internet access.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3z399i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752921808,"author_flair_text":null,"treatment_tags":[],"created_utc":1752921808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yqhss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"bitrumpled","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yoc68","score":-8,"author_fullname":"t2_z5dk4aa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This was told by kimi-latest itself, thismorning on platform.moonshot.ai, as below\\n\\n&gt; Those are two very different answers you have given to essentially the same query.  I understand there is a difference with LLMs not being able to acquire knowledge outside the context, but still, from Jun 2025 perspective, not knowing about Model Context Protocol and what an RTX5090 is, makes it difficult to trust your opinion.\\n\\nI apologize for the confusion and any inconsistency in my previous responses. I understand your concern about the reliability of the information provided. Let's clarify and provide a more accurate and consistent answer based on the information available as of June 2023.\\n\\n...\\n\\n\\nThe reason I understand it did not know what a 5090 is, is due to this from earlier in the same conversation, I mentioned \\"plus one or more 5090 (32GB DDR7)\\", its reply contained:\\n\\n\\nGPU: 5090 (32GB GDDR7)\\n\\n    The NVIDIA A100 or H100 (assuming 5090 refers to one of these) with 32GB of GDDR7 memory is excellent for GPU-accelerated tasks. These GPUs are designed for high-performance computing and machine learning workloads.\\n\\n\\nIf you think you know its knowledge cutoff date with more certainty than what it said itself, feel free to share.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3yqhss","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was told by kimi-latest itself, thismorning on platform.moonshot.ai, as below&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Those are two very different answers you have given to essentially the same query.  I understand there is a difference with LLMs not being able to acquire knowledge outside the context, but still, from Jun 2025 perspective, not knowing about Model Context Protocol and what an RTX5090 is, makes it difficult to trust your opinion.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I apologize for the confusion and any inconsistency in my previous responses. I understand your concern about the reliability of the information provided. Let&amp;#39;s clarify and provide a more accurate and consistent answer based on the information available as of June 2023.&lt;/p&gt;\\n\\n&lt;p&gt;...&lt;/p&gt;\\n\\n&lt;p&gt;The reason I understand it did not know what a 5090 is, is due to this from earlier in the same conversation, I mentioned &amp;quot;plus one or more 5090 (32GB DDR7)&amp;quot;, its reply contained:&lt;/p&gt;\\n\\n&lt;p&gt;GPU: 5090 (32GB GDDR7)&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;The NVIDIA A100 or H100 (assuming 5090 refers to one of these) with 32GB of GDDR7 memory is excellent for GPU-accelerated tasks. These GPUs are designed for high-performance computing and machine learning workloads.\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;If you think you know its knowledge cutoff date with more certainty than what it said itself, feel free to share.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3yqhss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752914673,"author_flair_text":null,"treatment_tags":[],"created_utc":1752914673,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yoc68","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fdg_avid","can_mod_post":false,"created_utc":1752913443,"send_replies":true,"parent_id":"t1_n3ykr3n","score":4,"author_fullname":"t2_7vr0myfd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That is not its knowledge cutoff. Not even close.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yoc68","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That is not its knowledge cutoff. Not even close.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3qc1g","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3yoc68/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752913443,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ykr3n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"bitrumpled","can_mod_post":false,"created_utc":1752911429,"send_replies":true,"parent_id":"t3_1m3qc1g","score":-7,"author_fullname":"t2_z5dk4aa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"I was just trying to use kimi-latest on their site.  Its cutoff (according to it) is Jun 2023.  It does not know what MCP is, nor even what an RTX5090 is.\\n\\nI know this is not a problem specific to Kimi but I would not use the words \\"absolutely amazing\\" myself.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ykr3n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was just trying to use kimi-latest on their site.  Its cutoff (according to it) is Jun 2023.  It does not know what MCP is, nor even what an RTX5090 is.&lt;/p&gt;\\n\\n&lt;p&gt;I know this is not a problem specific to Kimi but I would not use the words &amp;quot;absolutely amazing&amp;quot; myself.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3qc1g/would_there_be_a_reasoning_version_of_kimi_k2/n3ykr3n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752911429,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3qc1g","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
