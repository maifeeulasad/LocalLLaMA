import{j as e}from"./index-DAwUrOQb.js";import{R as l}from"./RedditPostRenderer-DESUWA8s.js";import"./index-CA_ihzEz.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm well aware my hardware is... not ideal.. for running LLMs, but I thought I'd at least be able to run small 2B to 4B models at a decent clip. But even the E2B version of Gemma 3n seems fairly slow. The TK/s aren't so bad (\\\\~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.\\n\\nIs this more or less expected for my hardware, or should I be seeing modestly better speeds?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"i5-8500 (6 cores), 24GB DDR4 2666 dual channel, realistic expectations for 3b/4b models?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lmt3kt","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.81,"author_flair_background_color":null,"subreddit_type":"public","ups":6,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_kehp8nb59","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":6,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751133510,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m well aware my hardware is... not ideal.. for running LLMs, but I thought I&amp;#39;d at least be able to run small 2B to 4B models at a decent clip. But even the E2B version of Gemma 3n seems fairly slow. The TK/s aren&amp;#39;t so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.&lt;/p&gt;\\n\\n&lt;p&gt;Is this more or less expected for my hardware, or should I be seeing modestly better speeds?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lmt3kt","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"redoubt515","discussion_type":null,"num_comments":31,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/","subreddit_subscribers":492625,"created_utc":1751133510,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0azyth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ElectronSpiderwort","can_mod_post":false,"created_utc":1751145236,"send_replies":true,"parent_id":"t1_n0aaa0t","score":3,"author_fullname":"t2_mxbu5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My i5-7500 has only 4 cores and Qwen3-30B-A3B-Q8\\\\_0.gguf runs at 25.7 tok/s prompt and 6.34 tok/s generation, for a 1165 token prompt and 1821 token output. Memory use by llama.cpp was \\\\~35GB so OP would need to run a quant.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0azyth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My i5-7500 has only 4 cores and Qwen3-30B-A3B-Q8_0.gguf runs at 25.7 tok/s prompt and 6.34 tok/s generation, for a 1165 token prompt and 1821 token output. Memory use by llama.cpp was ~35GB so OP would need to run a quant.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0azyth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751145236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f95x6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751211842,"send_replies":true,"parent_id":"t1_n0aaa0t","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm going to give Qwen3 30B a try. I thought it was out of reach for me, but from what you and a couple other people are saying, it sounds like it might be the best choice. I'm also going to upgrade to 32GB (2 x 16GB) so that should give me a little more breathing room.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f95x6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m going to give Qwen3 30B a try. I thought it was out of reach for me, but from what you and a couple other people are saying, it sounds like it might be the best choice. I&amp;#39;m also going to upgrade to 32GB (2 x 16GB) so that should give me a little more breathing room.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0f95x6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751211842,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0aaa0t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoffKalast","can_mod_post":false,"created_utc":1751136893,"send_replies":true,"parent_id":"t3_1lmt3kt","score":10,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That actually sounds like a pretty decent speed for your setup, I would be expecting less. And yes all cores you allocate will be used to 100% for the duration since practically any CPU will be compute bound by performance regardless.\\n\\nI think a sparse model like Qwen-30B-A3B could be the best option for your setup, it's 3B active so the speed should be similar, and the 30B total should just about fit into 24 GB, total performance of about a 10B dense.","edited":1751137324,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0aaa0t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That actually sounds like a pretty decent speed for your setup, I would be expecting less. And yes all cores you allocate will be used to 100% for the duration since practically any CPU will be compute bound by performance regardless.&lt;/p&gt;\\n\\n&lt;p&gt;I think a sparse model like Qwen-30B-A3B could be the best option for your setup, it&amp;#39;s 3B active so the speed should be similar, and the 30B total should just about fit into 24 GB, total performance of about a 10B dense.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0aaa0t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751136893,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fbqju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0df4ry","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not an option unfortunately. (riser cable still needs a pcie slot and space in the case (or outside of it) I have neither available)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fbqju","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not an option unfortunately. (riser cable still needs a pcie slot and space in the case (or outside of it) I have neither available)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fbqju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212658,"author_flair_text":null,"treatment_tags":[],"created_utc":1751212658,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0df4ry","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0crapt","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A riser cable + p104-100 = $30. This will give yo massive, 10x speed up.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0df4ry","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A riser cable + p104-100 = $30. This will give yo massive, 10x speed up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0df4ry/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181798,"author_flair_text":null,"treatment_tags":[],"created_utc":1751181798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0crapt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169447,"send_replies":true,"parent_id":"t1_n0aaaam","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately for me, this system *is* already maxed out. 2666 is the max supported memory speeed, and you are correct that dual channel is the best I can do.\\n\\nI have no pcie slots available so the *only \\"\\"*upgrade\\"\\" I have available to me, without full hardware replacement is an RX560 4GB (my server is a non-standard form factor, so this is the only GPU available to me. And that upgrade doesn't really feel worth it just to be able to run a 3B model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0crapt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately for me, this system &lt;em&gt;is&lt;/em&gt; already maxed out. 2666 is the max supported memory speeed, and you are correct that dual channel is the best I can do.&lt;/p&gt;\\n\\n&lt;p&gt;I have no pcie slots available so the &lt;em&gt;only &amp;quot;&amp;quot;&lt;/em&gt;upgrade&amp;quot;&amp;quot; I have available to me, without full hardware replacement is an RX560 4GB (my server is a non-standard form factor, so this is the only GPU available to me. And that upgrade doesn&amp;#39;t really feel worth it just to be able to run a 3B model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0crapt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169447,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dr76z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dpzh2","score":-1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Best of luck with your pointless crusade.","edited":1751189388,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0dr76z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Best of luck with your pointless crusade.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dr76z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751189183,"author_flair_text":null,"treatment_tags":[],"created_utc":1751189183,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dpzh2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dletq","score":3,"author_fullname":"t2_4di8yifm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is very strange attitude.   \\nSo, since the info is limited, i had to assume some of the things (which relevant/important ones are confirmed by OP), while you get in to irrevelant points like RAM slot limit is not caused by CPU its caused by motherboard. And somehow you think that, while i can do calculations about tps i do know nothing about ram slot limit caused by what?  \\n  \\nAlso for some reason, you seem to believe that I'm obligated to explain things you've cherry-picked from my comment, even while your own comments are a cascade of errors and useless advice. Like deliberately twisting OP's \\"the TK/s **aren't so bad** (\\\\~6-7 tk/s)\\" into \\"not caring\\" just to give perfect examples about 4060ti with Ryzen 7 which has definelty relevant or suggesting OP to get **\\"riser cable + GPU\\"** while explicitly stated, **\\"I have no pcie slots available.\\"** is totally relevant and definetly not \\"silly\\".  \\nFrankly, the only thing that matters here is that the OP understood my advice and its rationale. There's no point in continuing with this meaningless argument with someone who has contributed nothing while \\"beeing a nice person\\".   \\nI have work to do. Best of luck with your pointless crusade.","edited":false,"author_flair_css_class":null,"name":"t1_n0dpzh2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is very strange attitude.&lt;br/&gt;\\nSo, since the info is limited, i had to assume some of the things (which relevant/important ones are confirmed by OP), while you get in to irrevelant points like RAM slot limit is not caused by CPU its caused by motherboard. And somehow you think that, while i can do calculations about tps i do know nothing about ram slot limit caused by what?  &lt;/p&gt;\\n\\n&lt;p&gt;Also for some reason, you seem to believe that I&amp;#39;m obligated to explain things you&amp;#39;ve cherry-picked from my comment, even while your own comments are a cascade of errors and useless advice. Like deliberately twisting OP&amp;#39;s &amp;quot;the TK/s &lt;strong&gt;aren&amp;#39;t so bad&lt;/strong&gt; (~6-7 tk/s)&amp;quot; into &amp;quot;not caring&amp;quot; just to give perfect examples about 4060ti with Ryzen 7 which has definelty relevant or suggesting OP to get &lt;strong&gt;&amp;quot;riser cable + GPU&amp;quot;&lt;/strong&gt; while explicitly stated, &lt;strong&gt;&amp;quot;I have no pcie slots available.&amp;quot;&lt;/strong&gt; is totally relevant and definetly not &amp;quot;silly&amp;quot;.&lt;br/&gt;\\nFrankly, the only thing that matters here is that the OP understood my advice and its rationale. There&amp;#39;s no point in continuing with this meaningless argument with someone who has contributed nothing while &amp;quot;beeing a nice person&amp;quot;.&lt;br/&gt;\\nI have work to do. Best of luck with your pointless crusade.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dpzh2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751188423,"author_flair_text":null,"collapsed":false,"created_utc":1751188423,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dletq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0djz17","score":0,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; My advice was grounded in the practical reality of the user's specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.\\n\\nYour advice has incorrect silly info such as \\"i5-8500 only have two slots, therefore u cannot add more ram\\", as this is not a contraint of CPU but motherboard, and that installing 3600 ddr4 will do any improvement to the prompt processing, one of the concern op voiced.\\n\\n\\n&gt; My focus was on inference, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.\\n\\nYou tone is turgid, but I being a nice person will ignore that.\\n\\nThe OP explicitly mentioned concern about PP speeds: \\n\\n&gt; The TK/s aren't so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.\\n\\nIn the other words, **they mentioned they do not care much about inference speed**, but PP speed is concerning.\\n\\nOn their hardware, the only way to improve prompt processing is to install i7-8700, not worth it. No amount of improving memory bandwith will have any influence on PP.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dletq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;My advice was grounded in the practical reality of the user&amp;#39;s specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Your advice has incorrect silly info such as &amp;quot;i5-8500 only have two slots, therefore u cannot add more ram&amp;quot;, as this is not a contraint of CPU but motherboard, and that installing 3600 ddr4 will do any improvement to the prompt processing, one of the concern op voiced.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;My focus was on inference, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;You tone is turgid, but I being a nice person will ignore that.&lt;/p&gt;\\n\\n&lt;p&gt;The OP explicitly mentioned concern about PP speeds: &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The TK/s aren&amp;#39;t so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;In the other words, &lt;strong&gt;they mentioned they do not care much about inference speed&lt;/strong&gt;, but PP speed is concerning.&lt;/p&gt;\\n\\n&lt;p&gt;On their hardware, the only way to improve prompt processing is to install i7-8700, not worth it. No amount of improving memory bandwith will have any influence on PP.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dletq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751185594,"author_flair_text":null,"treatment_tags":[],"created_utc":1751185594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0djz17","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0delyr","score":2,"author_fullname":"t2_4di8yifm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You seem to have missed the entire context of my original comment. I'm not debating the theoretical nature of prompt processing. My advice was grounded in the practical reality of the user's specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.\\n\\nI assumed the user isn't looking to build a new system, but to make incremental improvements. Within that specific context:  \\n\\\\- My focus was on **inference**, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.  \\n\\\\- Your point, while generally true, is impractical here. Suggesting \\"get a GPU\\" is the obvious but trivial answer. If we were ignoring the user's constraints, I could just as easily recommend an RTX 5090 for a 40x increase in inference speed and probably a 1000x increase in prompt processing. There are a billion options, but that wasn't the user's question.\\n\\nIn short, while you are correct that prompt processing is compute-bound, your entire point is irrelevant within the scope of providing actionable advice for the user's existing hardware. My recommendations were about optimizing that system and providing general guidance on how things works in simple terms. Yours are about replacing it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0djz17","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You seem to have missed the entire context of my original comment. I&amp;#39;m not debating the theoretical nature of prompt processing. My advice was grounded in the practical reality of the user&amp;#39;s specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.&lt;/p&gt;\\n\\n&lt;p&gt;I assumed the user isn&amp;#39;t looking to build a new system, but to make incremental improvements. Within that specific context:&lt;br/&gt;\\n- My focus was on &lt;strong&gt;inference&lt;/strong&gt;, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.&lt;br/&gt;\\n- Your point, while generally true, is impractical here. Suggesting &amp;quot;get a GPU&amp;quot; is the obvious but trivial answer. If we were ignoring the user&amp;#39;s constraints, I could just as easily recommend an RTX 5090 for a 40x increase in inference speed and probably a 1000x increase in prompt processing. There are a billion options, but that wasn&amp;#39;t the user&amp;#39;s question.&lt;/p&gt;\\n\\n&lt;p&gt;In short, while you are correct that prompt processing is compute-bound, your entire point is irrelevant within the scope of providing actionable advice for the user&amp;#39;s existing hardware. My recommendations were about optimizing that system and providing general guidance on how things works in simple terms. Yours are about replacing it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0djz17/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184717,"author_flair_text":null,"treatment_tags":[],"created_utc":1751184717,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0delyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181488,"send_replies":true,"parent_id":"t1_n0aaaam","score":0,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I used to think like that too, but prompt processing is compute intensive, and cpu matters too.\\n\\n&gt; Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it's constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are\\n\\nNo, it is not hat simple. CPU can be pinned at 100% both if waiting for data to arrive and also if it is simply saturated at compute - this caqn easily be verified by checking the power consumption, if cpu is like 100% at 20W than it is stuck by memory, if at full 60-80W than it is too weak. Prompt processing is exactly the case of dumb, compute intensive tasks that no cpu will bw good at. Memory bandwith of a conumer GPU (say 4060ti) is not that  much bigger than of DDR4 (5 times) yet prompt processing on 4060ti is 120x of prompt prrocessing on Ryzen 7.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0delyr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I used to think like that too, but prompt processing is compute intensive, and cpu matters too.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it&amp;#39;s constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;No, it is not hat simple. CPU can be pinned at 100% both if waiting for data to arrive and also if it is simply saturated at compute - this caqn easily be verified by checking the power consumption, if cpu is like 100% at 20W than it is stuck by memory, if at full 60-80W than it is too weak. Prompt processing is exactly the case of dumb, compute intensive tasks that no cpu will bw good at. Memory bandwith of a conumer GPU (say 4060ti) is not that  much bigger than of DDR4 (5 times) yet prompt processing on 4060ti is 120x of prompt prrocessing on Ryzen 7.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0delyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181488,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0aaaam","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"created_utc":1751136895,"send_replies":true,"parent_id":"t3_1lmt3kt","score":4,"author_fullname":"t2_4di8yifm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In your case, when running an LLM on the CPU, the primary bottleneck is almost always **memory bandwidth**, not the CPU's raw processing power.  \\nIf you are not using any GPU, your dual-channel DDR4-2666 RAM gives you a approx. maximum bandwidth of 41-42 GB/s.For dense models (not MOE) if you divide this number to your model's total memory usage(eg. model size, kv cache etc.) you will get your approx tps.\\n\\nMoreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it's constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are   \\n1- run on gpu,  \\n2- Upgrade your ddr4 ram to 3600+ mhz. (afaik i5-8500 only have two slots, therefore u cannot add more ram)  \\nfor 6 gb model (with model size, kv cache etc. included)   \\n\\\\- on first scenario u probbly x10 to x20 tps increase **(this is purely based on the GPU's bandwight)**  \\n\\\\- you probbly get (lets say if you upgraded to 4000 mhz) like 1.5x of your current tps.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0aaaam","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In your case, when running an LLM on the CPU, the primary bottleneck is almost always &lt;strong&gt;memory bandwidth&lt;/strong&gt;, not the CPU&amp;#39;s raw processing power.&lt;br/&gt;\\nIf you are not using any GPU, your dual-channel DDR4-2666 RAM gives you a approx. maximum bandwidth of 41-42 GB/s.For dense models (not MOE) if you divide this number to your model&amp;#39;s total memory usage(eg. model size, kv cache etc.) you will get your approx tps.&lt;/p&gt;\\n\\n&lt;p&gt;Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it&amp;#39;s constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are&lt;br/&gt;\\n1- run on gpu,&lt;br/&gt;\\n2- Upgrade your ddr4 ram to 3600+ mhz. (afaik i5-8500 only have two slots, therefore u cannot add more ram)&lt;br/&gt;\\nfor 6 gb model (with model size, kv cache etc. included)&lt;br/&gt;\\n- on first scenario u probbly x10 to x20 tps increase &lt;strong&gt;(this is purely based on the GPU&amp;#39;s bandwight)&lt;/strong&gt;&lt;br/&gt;\\n- you probbly get (lets say if you upgraded to 4000 mhz) like 1.5x of your current tps.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0aaaam/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751136895,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b7p6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1751147872,"send_replies":true,"parent_id":"t1_n0ajcq1","score":3,"author_fullname":"t2_8fu8sqhz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could also be 8+4+8+4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b7p6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could also be 8+4+8+4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b7p6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751147872,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fbub6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0d6gdg","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks, I appreciate the confirmation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fbub6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I appreciate the confirmation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fbub6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212691,"author_flair_text":null,"treatment_tags":[],"created_utc":1751212691,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0d6gdg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0cqeq4","score":3,"author_fullname":"t2_11qlhv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Then it works in flex mode. The first 16GB of the addressable space are accessed in dual channel mode and the last 8 single channel.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0d6gdg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Then it works in flex mode. The first 16GB of the addressable space are accessed in dual channel mode and the last 8 single channel.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0d6gdg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751176872,"author_flair_text":null,"treatment_tags":[],"created_utc":1751176872,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cqeq4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169059,"send_replies":true,"parent_id":"t1_n0ajcq1","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm certain that:\\n\\n1. my system *supports* dual channel (and has only two RAM slots so no chance of using wrong slots)\\n2. I'm using 2 dimms (1 x 16gb + 1 x 8 gb)\\n\\nI'm not *certain* that it is actually *working* as dual channel. I assumed so, I guess this is something I need to confirm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cqeq4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m certain that:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;my system &lt;em&gt;supports&lt;/em&gt; dual channel (and has only two RAM slots so no chance of using wrong slots)&lt;/li&gt;\\n&lt;li&gt;I&amp;#39;m using 2 dimms (1 x 16gb + 1 x 8 gb)&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I&amp;#39;m not &lt;em&gt;certain&lt;/em&gt; that it is actually &lt;em&gt;working&lt;/em&gt; as dual channel. I assumed so, I guess this is something I need to confirm.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cqeq4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169059,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ajcq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wild_Requirement8902","can_mod_post":false,"created_utc":1751139841,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_98yqzbqx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"are you sure you are in dual channel ? or do you have 3 8gb stick ? I am pretty sure you need 2 or 4 stick of the same size for dual channel. maybe getting anoter ram stick and messing with your bios a bit could help what qwant are you running ? q4 km imatrix one ? you should try q4\\\\_0 or even q8\\\\_0 since they are more cpu friendly. and try other model especialy if you are running them trough llama.cpp or ollama","edited":1751140365,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ajcq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are you sure you are in dual channel ? or do you have 3 8gb stick ? I am pretty sure you need 2 or 4 stick of the same size for dual channel. maybe getting anoter ram stick and messing with your bios a bit could help what qwant are you running ? q4 km imatrix one ? you should try q4_0 or even q8_0 since they are more cpu friendly. and try other model especialy if you are running them trough llama.cpp or ollama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ajcq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751139841,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b8hou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1751148146,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_8fu8sqhz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is what Zen 3 + DDR4-3200 inference looks like:\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/\\n\\n\\nIf I had to guess, Skylake + DDR4-2666 should be around 50-60% of this speed. So at the first glance, your results seem fair","edited":1751148388,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b8hou","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is what Zen 3 + DDR4-3200 inference looks like:\\n&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If I had to guess, Skylake + DDR4-2666 should be around 50-60% of this speed. So at the first glance, your results seem fair&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b8hou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148146,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fdmev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ddayf","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; Just don't use --no-mmap if you have an SSD\\n\\nThis is not a terminal command I've ever used, so unless it is an ollama default I think I'm safe there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fdmev","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Just don&amp;#39;t use --no-mmap if you have an SSD&lt;/p&gt;\\n\\n&lt;p&gt;This is not a terminal command I&amp;#39;ve ever used, so unless it is an ollama default I think I&amp;#39;m safe there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fdmev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751213259,"author_flair_text":null,"treatment_tags":[],"created_utc":1751213259,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ddayf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remote_Cap_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0cr37n","score":2,"author_fullname":"t2_1k5euypabx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just don't use --no-mmap if you have an SSD. That 4GB GPU would also help cache shared weights.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ddayf","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just don&amp;#39;t use --no-mmap if you have an SSD. That 4GB GPU would also help cache shared weights.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddayf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751180727,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1751180727,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cr37n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169354,"send_replies":true,"parent_id":"t1_n0c3yj2","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'll give it a try. See how that goes. Thanks for the pointer. I'd be really happy if I could run Qwen 3 30B","edited":1751178499,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cr37n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll give it a try. See how that goes. Thanks for the pointer. I&amp;#39;d be really happy if I could run Qwen 3 30B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cr37n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169354,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0c3yj2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1751159752,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Run Qwen 3 30B A3B @ UD Q2K_XL. This is going to be the best setup for you. You can also use IQ4XS if you want a little more precision at the cost of speed. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0c3yj2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Run Qwen 3 30B A3B @ UD Q2K_XL. This is going to be the best setup for you. You can also use IQ4XS if you want a little more precision at the cost of speed. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0c3yj2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751159752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cs6tv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Consequence-1779","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0cqr5k","score":1,"author_fullname":"t2_1ping1tiaw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I know the oem mfgs make small form factor like Dell. A 2 slot wide and much shorter by inches. Might be worth a look. Ask Gemini)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0cs6tv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know the oem mfgs make small form factor like Dell. A 2 slot wide and much shorter by inches. Might be worth a look. Ask Gemini)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cs6tv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169849,"author_flair_text":null,"treatment_tags":[],"created_utc":1751169849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cqr5k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169205,"send_replies":true,"parent_id":"t1_n0asbid","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately it is an ultra small form factor system (non-standard form factor) so *the only* GPU I have available is a custom *RX560 4GB* for \\\\~$80.\\n\\nI'm always up for a good heist though....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cqr5k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately it is an ultra small form factor system (non-standard form factor) so &lt;em&gt;the only&lt;/em&gt; GPU I have available is a custom &lt;em&gt;RX560 4GB&lt;/em&gt; for ~$80.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m always up for a good heist though....&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cqr5k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169205,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0asbid","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Consequence-1779","can_mod_post":false,"created_utc":1751142736,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_1ping1tiaw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You need to watch the film “The Heist” and then plan one on an electronics store for a gpu. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0asbid","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need to watch the film “The Heist” and then plan one on an electronics store for a gpu. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0asbid/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751142736,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ab9ld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1751137205,"send_replies":true,"parent_id":"t3_1lmt3kt","score":1,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"why not add 3060?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ab9ld","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;why not add 3060?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ab9ld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751137205,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b2nmv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ElectronSpiderwort","can_mod_post":false,"created_utc":1751146140,"send_replies":true,"parent_id":"t3_1lmt3kt","score":1,"author_fullname":"t2_mxbu5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"On an i5-7500 (4 cores) and llama.cpp, Llama-3.2-3B-Instruct-Q8\\\\_0.gguf gives me 36.67 prompt tok/sec and 7.06 generation tok/sec, for a small request of 1163 prompt tokens and 887 generation tokens. Set --threads to the number of cores you have, not the number of \\"threads\\" your CPU thinks it has","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b2nmv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On an i5-7500 (4 cores) and llama.cpp, Llama-3.2-3B-Instruct-Q8_0.gguf gives me 36.67 prompt tok/sec and 7.06 generation tok/sec, for a small request of 1163 prompt tokens and 887 generation tokens. Set --threads to the number of cores you have, not the number of &amp;quot;threads&amp;quot; your CPU thinks it has&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b2nmv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751146140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ddz9m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181119,"send_replies":true,"parent_id":"t3_1lmt3kt","score":0,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ddz9m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddz9m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181119,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ddzv7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181129,"send_replies":true,"parent_id":"t3_1lmt3kt","score":0,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ddzv7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddzv7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181129,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
