import{j as e}from"./index-DLSqWzaI.js";import{R as l}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I have my solution that am trying to test and integrate with LLM/AI. So since my local computer isn't much powerful to host those behemoths of open source LLMs I'm thinking of having some kind of VPS or something where I will test everything from. But since AI is GPU intensive not CPUs I'm stranded. I don't like the per hourly charges as I don't want to be switching machine on and off to reduce costs (correct me if am wrong).\\n\\nTo summarize my question, what is a cheap VPS services that are capable of hosting strong open source AI, preferrably monthly charges? Like I could buy $5 Digital ocean droplet and do my tests?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Cheap hosting where I can host bunch of LLM?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lpa4rc","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_b8hge0ub","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751396196,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I have my solution that am trying to test and integrate with LLM/AI. So since my local computer isn&amp;#39;t much powerful to host those behemoths of open source LLMs I&amp;#39;m thinking of having some kind of VPS or something where I will test everything from. But since AI is GPU intensive not CPUs I&amp;#39;m stranded. I don&amp;#39;t like the per hourly charges as I don&amp;#39;t want to be switching machine on and off to reduce costs (correct me if am wrong).&lt;/p&gt;\\n\\n&lt;p&gt;To summarize my question, what is a cheap VPS services that are capable of hosting strong open source AI, preferrably monthly charges? Like I could buy $5 Digital ocean droplet and do my tests?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lpa4rc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Dodokii","discussion_type":null,"num_comments":20,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/","subreddit_subscribers":493457,"created_utc":1751396196,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tb1wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dodokii","can_mod_post":false,"created_utc":1751398086,"send_replies":true,"parent_id":"t1_n0tagsn","score":1,"author_fullname":"t2_b8hge0ub","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for pointing these options. very helpful indeed!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tb1wo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for pointing these options. very helpful indeed!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tb1wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751398086,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tagsn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"moarmagic","can_mod_post":false,"created_utc":1751397919,"send_replies":true,"parent_id":"t3_1lpa4rc","score":6,"author_fullname":"t2_164x4a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Openrouter hosts models, so you pay per message. If your usage is more sporadic that's going to be cheaper\\n\\nRunpod let's you rent GPU storage by the second or hour. I think their \\\\*most\\\\* expensive one is like 6/hr and they have many cheaper options. There's some overhead fees in transfer/storage, but if you just want to throw hundreds of messages at something over an hour, then won't touch it again for a while- it's a decidedly more cost effective method.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tagsn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Openrouter hosts models, so you pay per message. If your usage is more sporadic that&amp;#39;s going to be cheaper&lt;/p&gt;\\n\\n&lt;p&gt;Runpod let&amp;#39;s you rent GPU storage by the second or hour. I think their *most* expensive one is like 6/hr and they have many cheaper options. There&amp;#39;s some overhead fees in transfer/storage, but if you just want to throw hundreds of messages at something over an hour, then won&amp;#39;t touch it again for a while- it&amp;#39;s a decidedly more cost effective method.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tagsn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751397919,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tclzg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Pipe-5151","can_mod_post":false,"created_utc":1751398540,"send_replies":true,"parent_id":"t3_1lpa4rc","score":3,"author_fullname":"t2_uxbdufm8b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Vast.ai is the cheapest option you have. A beefy gpu like h100 costs less that 2$ per hour\\n\\n\\nBut make sure that choose servers listed as \\"secure\\". Also terminate the server after inference is complete. In order to prevent model weights from being downloaded everytime, you can use a shared block storage volume. Additionally you can use a simple script to pre-warm your inference server.\\n\\n\\nOther than vast, you have options like tensordock, shadeform, koyeb, runpod, modal, hyperbolic etc. But they are all more expensive than vast","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tclzg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Vast.ai is the cheapest option you have. A beefy gpu like h100 costs less that 2$ per hour&lt;/p&gt;\\n\\n&lt;p&gt;But make sure that choose servers listed as &amp;quot;secure&amp;quot;. Also terminate the server after inference is complete. In order to prevent model weights from being downloaded everytime, you can use a shared block storage volume. Additionally you can use a simple script to pre-warm your inference server.&lt;/p&gt;\\n\\n&lt;p&gt;Other than vast, you have options like tensordock, shadeform, koyeb, runpod, modal, hyperbolic etc. But they are all more expensive than vast&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tclzg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751398540,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0uh6ed","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GTHell","can_mod_post":false,"created_utc":1751410715,"send_replies":true,"parent_id":"t3_1lpa4rc","score":3,"author_fullname":"t2_oqe4l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Forget about that and use openrouter. FYI, it’s not cheap","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0uh6ed","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Forget about that and use openrouter. FYI, it’s not cheap&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0uh6ed/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410715,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t7po3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"numsu","can_mod_post":false,"created_utc":1751397125,"send_replies":true,"parent_id":"t3_1lpa4rc","score":1,"author_fullname":"t2_ejgiq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hyperstack is one of the cheapest ones at the moment.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t7po3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hyperstack is one of the cheapest ones at the moment.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t7po3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751397125,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1lpa4rc","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tbhbb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dodokii","can_mod_post":false,"created_utc":1751398211,"send_replies":true,"parent_id":"t1_n0t8n3v","score":2,"author_fullname":"t2_b8hge0ub","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh, nice! Were you able to run on Digital ocean without special GPU or something?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tbhbb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh, nice! Were you able to run on Digital ocean without special GPU or something?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tbhbb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751398211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t8n3v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1lpa4rc","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t8n3v/","num_reports":null,"locked":false,"name":"t1_n0t8n3v","created":1751397392,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751397392,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0td5lg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ne00n","can_mod_post":false,"created_utc":1751398701,"send_replies":true,"parent_id":"t3_1lpa4rc","score":1,"author_fullname":"t2_6d9eitt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OVH, Kimsufi, they had some deals from time to time, CPU only but up to 64gigs for less than 15$ sometimes.  \\nRight now its meh, you can get a Dedi for 11$/m but 10 year old cpu, 32gig though","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0td5lg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OVH, Kimsufi, they had some deals from time to time, CPU only but up to 64gigs for less than 15$ sometimes.&lt;br/&gt;\\nRight now its meh, you can get a Dedi for 11$/m but 10 year old cpu, 32gig though&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0td5lg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751398701,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0v2pf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BasicIngenuity3886","can_mod_post":false,"created_utc":1751418141,"send_replies":true,"parent_id":"t3_1lpa4rc","score":1,"author_fullname":"t2_1snw7mm08r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"well do you want cheap LLM performance ? \\n\\nmost vps have shitty overloaded infrastructure.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0v2pf8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well do you want cheap LLM performance ? &lt;/p&gt;\\n\\n&lt;p&gt;most vps have shitty overloaded infrastructure.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0v2pf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751418141,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"body":"Terraform + AWS","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0vbybz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"flanconleche","can_mod_post":false,"created_utc":1751421398,"send_replies":true,"parent_id":"t3_1lpa4rc","score":1,"author_fullname":"t2_ohc3o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0vbybz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Terraform + AWS&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0vbybz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751421398,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0tqzki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"colin_colout","can_mod_post":false,"created_utc":1751402651,"send_replies":true,"parent_id":"t1_n0tm84i","score":1,"author_fullname":"t2_14l4ya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"capex vs opex. \\n\\nIn also interested in this.  I don't have $$$ for a Blackwell, but there are occasional workloads I'd like to try out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tqzki","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;capex vs opex. &lt;/p&gt;\\n\\n&lt;p&gt;In also interested in this.  I don&amp;#39;t have $$$ for a Blackwell, but there are occasional workloads I&amp;#39;d like to try out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tqzki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751402651,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tm84i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nntb","can_mod_post":false,"created_utc":1751401312,"send_replies":true,"parent_id":"t3_1lpa4rc","score":0,"author_fullname":"t2_btwg6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This may be a crazy idea but maybe you could self host get a computer with the proper equipment to run it and then you're not having to pay to a service you know run it locally","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tm84i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This may be a crazy idea but maybe you could self host get a computer with the proper equipment to run it and then you&amp;#39;re not having to pay to a service you know run it locally&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0tm84i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751401312,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t6yqx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bigchimping420","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t6gjl","score":1,"author_fullname":"t2_w78mv9gsh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"also true","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0t6yqx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;also true&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t6yqx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396910,"author_flair_text":null,"treatment_tags":[],"created_utc":1751396910,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t8tk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dodokii","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t6gjl","score":1,"author_fullname":"t2_b8hge0ub","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Am I right to think hourly (I take it as number of hours it is running not number of hours it is being used) is expensive than ol' good VPSes? Never tried before so practically I do not know if am right or not!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0t8tk2","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Am I right to think hourly (I take it as number of hours it is running not number of hours it is being used) is expensive than ol&amp;#39; good VPSes? Never tried before so practically I do not know if am right or not!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t8tk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751397444,"author_flair_text":null,"treatment_tags":[],"created_utc":1751397444,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t6gjl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NotSylver","can_mod_post":false,"created_utc":1751396765,"send_replies":true,"parent_id":"t1_n0t5gaj","score":13,"author_fullname":"t2_kcwehvi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"AWS is one of the most expensive options there is. I don't think there are \\"cheap\\" LLM-capable VPSes available, especially paying monthly instead of hourly. GPUs are just expensive","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t6gjl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AWS is one of the most expensive options there is. I don&amp;#39;t think there are &amp;quot;cheap&amp;quot; LLM-capable VPSes available, especially paying monthly instead of hourly. GPUs are just expensive&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t6gjl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396765,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0t8l86","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dodokii","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t797o","score":1,"author_fullname":"t2_b8hge0ub","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t8l86","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks you!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t8l86/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751397378,"author_flair_text":null,"treatment_tags":[],"created_utc":1751397378,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t797o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bigchimping420","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0t6mek","score":2,"author_fullname":"t2_w78mv9gsh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"not at a point where i could give directions, but probably just search for a tutorial on hosting an llm on aws its been done a good few times now and documentation is there","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0t797o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;not at a point where i could give directions, but probably just search for a tutorial on hosting an llm on aws its been done a good few times now and documentation is there&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t797o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396994,"author_flair_text":null,"treatment_tags":[],"created_utc":1751396994,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t6mek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dodokii","can_mod_post":false,"created_utc":1751396813,"send_replies":true,"parent_id":"t1_n0t5gaj","score":1,"author_fullname":"t2_b8hge0ub","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! Can you point me in specific direction, especially if you have experience with their services?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t6mek","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! Can you point me in specific direction, especially if you have experience with their services?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpa4rc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t6mek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396813,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0t5gaj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bigchimping420","can_mod_post":false,"created_utc":1751396473,"send_replies":true,"parent_id":"t3_1lpa4rc","score":-3,"author_fullname":"t2_w78mv9gsh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"amazon web service is probably your best bet, im pretty sure most sites hosting local llms base their infrastructure on various aws services","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0t5gaj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;amazon web service is probably your best bet, im pretty sure most sites hosting local llms base their infrastructure on various aws services&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpa4rc/cheap_hosting_where_i_can_host_bunch_of_llm/n0t5gaj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751396473,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpa4rc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
