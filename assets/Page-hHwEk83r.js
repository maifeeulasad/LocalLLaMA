import{j as e}from"./index-Hv65y6gT.js";import{R as t}from"./RedditPostRenderer-DM2tKTZg.js";import"./index-B9NseS5j.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey folks,\\n\\nIâ€™m new to vLLM and (LLM in general) and trying to wrap my head around how vLLM guarantees prompt isolation (ie how user gets their own response not the response intended for another user), especially in the context of integrating custom hardware accelerators. Hoping to get answers to the following questions:\\n\\n1. How exactly does vLLM ensure prompt isolation?\\nFrom what Iâ€™ve seen, thereâ€™s a task_id passed into add_request() which seems to uniquely tag each prompt. My impression is that this ID is solely used internally to keep prompts/responses isolated from one another. Am I getting this right?\\n\\n2. For an organisation integrating their own hardware accelerator, are they expected to use this task_id (or something derived from it) for isolation?\\nLike, if an organisation has a custom accelerator which is not yet supported by vLLM, is it their job to make sure the task separation is respected based on that ID? Or does vLLM abstract that away even if the hardware doesnâ€™t actively use task_id (or any of its derivative) for isolation?\\n\\n3. Have any currently vLLM supported hardware vendors (e.g. NVIDIA, AMD) published any blogs, whitepapers, GitHub notes that detail how they integrated their accelerator with vLLM securely?\\n\\n4. Are there any official privacy/security guidelines from the vLLM team for devs integrating new hardware support?\\nIs there a checklist or architecture doc to follow to avoid sending cross user prompts response.\\n\\nIf anyoneâ€™s gone down this road already or has internal docs/blogs to recommend, please share! ðŸ™\\n\\nThanks in advance!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How Does vLLM Handle Prompt Isolation During Custom Hardware Integration?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lme24s","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_ujwz3dlw","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751084961,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\\n\\n&lt;p&gt;Iâ€™m new to vLLM and (LLM in general) and trying to wrap my head around how vLLM guarantees prompt isolation (ie how user gets their own response not the response intended for another user), especially in the context of integrating custom hardware accelerators. Hoping to get answers to the following questions:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;How exactly does vLLM ensure prompt isolation?\\nFrom what Iâ€™ve seen, thereâ€™s a task_id passed into add_request() which seems to uniquely tag each prompt. My impression is that this ID is solely used internally to keep prompts/responses isolated from one another. Am I getting this right?&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;For an organisation integrating their own hardware accelerator, are they expected to use this task_id (or something derived from it) for isolation?\\nLike, if an organisation has a custom accelerator which is not yet supported by vLLM, is it their job to make sure the task separation is respected based on that ID? Or does vLLM abstract that away even if the hardware doesnâ€™t actively use task_id (or any of its derivative) for isolation?&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Have any currently vLLM supported hardware vendors (e.g. NVIDIA, AMD) published any blogs, whitepapers, GitHub notes that detail how they integrated their accelerator with vLLM securely?&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Are there any official privacy/security guidelines from the vLLM team for devs integrating new hardware support?\\nIs there a checklist or architecture doc to follow to avoid sending cross user prompts response.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;If anyoneâ€™s gone down this road already or has internal docs/blogs to recommend, please share! ðŸ™&lt;/p&gt;\\n\\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lme24s","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"humblehunter_","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lme24s/how_does_vllm_handle_prompt_isolation_during/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lme24s/how_does_vllm_handle_prompt_isolation_during/","subreddit_subscribers":492232,"created_utc":1751084961,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07g03q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"humblehunter_","can_mod_post":false,"created_utc":1751096442,"send_replies":true,"parent_id":"t1_n075984","score":1,"author_fullname":"t2_ujwz3dlw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://docs.vllm.ai/en/latest/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07g03q","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://docs.vllm.ai/en/latest/\\"&gt;https://docs.vllm.ai/en/latest/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lme24s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lme24s/how_does_vllm_handle_prompt_isolation_during/n07g03q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751096442,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07kw3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aaronr_90","can_mod_post":false,"created_utc":1751099312,"send_replies":true,"parent_id":"t1_n075984","score":1,"author_fullname":"t2_jbgpw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Google vLLM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07kw3f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google vLLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lme24s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lme24s/how_does_vllm_handle_prompt_isolation_during/n07kw3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751099312,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n075984","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"32BP","can_mod_post":false,"created_utc":1751090533,"send_replies":true,"parent_id":"t3_1lme24s","score":1,"author_fullname":"t2_f96aq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"link to vLLM ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n075984","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;link to vLLM ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lme24s/how_does_vllm_handle_prompt_isolation_during/n075984/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751090533,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lme24s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),s=()=>e.jsx(t,{data:l});export{s as default};
