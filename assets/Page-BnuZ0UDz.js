import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"What's an open source alternative to LM studio that uses GitHub and can be freely accessible, is generally very feature-rich, and can feasibly stand up to LM studio for people who want a free open source solution?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Open source alternative to LM studio?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":true,"name":"t3_1m81whq","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1sznzjx7fy","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753356654,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s an open source alternative to LM studio that uses GitHub and can be freely accessible, is generally very feature-rich, and can feasibly stand up to LM studio for people who want a free open source solution?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m81whq","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"datascientist2964","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/","subreddit_subscribers":503759,"created_utc":1753356654,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vvi5f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"orak7ee","can_mod_post":false,"created_utc":1753358490,"send_replies":true,"parent_id":"t3_1m81whq","score":2,"author_fullname":"t2_14un99chfv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm happy with https://jan.ai/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vvi5f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m happy with &lt;a href=\\"https://jan.ai/\\"&gt;https://jan.ai/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/n4vvi5f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753358490,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m81whq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vv3kz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"datascientist2964","can_mod_post":false,"created_utc":1753358332,"send_replies":true,"parent_id":"t1_n4vt1nd","score":1,"author_fullname":"t2_1sznzjx7fy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"See, I really did like olama. But my problem is, I don't really like the way it works in the setup. It's not just out of the box easy to use for any user. LM studio you get an EXE, you install it, open it up and choose your model that's it. O llama requires a little bit more poops to jump through, you have to set up the web interface, you have to set up the command line interface, which I'm not against. But when I'm trying to share this sort of process with other people, they just won't do it. People are inherently lazy. If there's an application they can just install and use, that's what they'll turn to and that's exactly why LM studio is so popular","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vv3kz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;See, I really did like olama. But my problem is, I don&amp;#39;t really like the way it works in the setup. It&amp;#39;s not just out of the box easy to use for any user. LM studio you get an EXE, you install it, open it up and choose your model that&amp;#39;s it. O llama requires a little bit more poops to jump through, you have to set up the web interface, you have to set up the command line interface, which I&amp;#39;m not against. But when I&amp;#39;m trying to share this sort of process with other people, they just won&amp;#39;t do it. People are inherently lazy. If there&amp;#39;s an application they can just install and use, that&amp;#39;s what they&amp;#39;ll turn to and that&amp;#39;s exactly why LM studio is so popular&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m81whq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/n4vv3kz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753358332,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4vt1nd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StupidestNerd","can_mod_post":false,"created_utc":1753357525,"send_replies":true,"parent_id":"t3_1m81whq","score":0,"author_fullname":"t2_9xprveow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It depends what you’re trying to run it on. Ollama is quite good as it allows you to install and switch between deepseek, mistral, Gemini and a few other models.\\nIt also integrates with OpenUI will provides a locally hosted web interface for ollama, which is typically a CLI only tool.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vt1nd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It depends what you’re trying to run it on. Ollama is quite good as it allows you to install and switch between deepseek, mistral, Gemini and a few other models.\\nIt also integrates with OpenUI will provides a locally hosted web interface for ollama, which is typically a CLI only tool.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/n4vt1nd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753357525,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m81whq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vxl9u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"teitokurabu","can_mod_post":false,"created_utc":1753359285,"send_replies":true,"parent_id":"t3_1m81whq","score":1,"author_fullname":"t2_1tzynl0cnv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"if you are refering lm studio because of the easy access to lots of models on hf, i think argo is not a bad option.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vxl9u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if you are refering lm studio because of the easy access to lots of models on hf, i think argo is not a bad option.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/n4vxl9u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753359285,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m81whq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4vsfog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jatilq","can_mod_post":false,"created_utc":1753357280,"send_replies":true,"parent_id":"t3_1m81whq","score":0,"author_fullname":"t2_3txs3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Download this to test different options. [https://pinokio.co/](https://pinokio.co/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4vsfog","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Download this to test different options. &lt;a href=\\"https://pinokio.co/\\"&gt;https://pinokio.co/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m81whq/open_source_alternative_to_lm_studio/n4vsfog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753357280,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m81whq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
