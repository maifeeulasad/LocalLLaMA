import{j as e}from"./index-CWmJdUH_.js";import{R as l}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Kimi K2 Fiction.liveBench: On-par with DeepSeek V3, behind GPT-4.1","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2c4hz","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.92,"author_flair_background_color":null,"ups":58,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_7pfgfkis","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":58,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/lXkqXKVLlY-0xp1Ll5U1FeDQqg6ahS6vCiZLMdwfkig.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752769673,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/in8sapsyngdf1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/in8sapsyngdf1.png?auto=webp&amp;s=d560dabde4ddc279eb20ac8e733a207615242adc","width":1694,"height":2488},"resolutions":[{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f85740178e4ec12f06f91b4d07b4d3e4d93060e1","width":108,"height":158},{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e55f25c6da47d62b9a5e21c5b771acbe9b41ac0","width":216,"height":317},{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3fd47b1ea3fca9ddf7ec4bd950022280f0625cdd","width":320,"height":469},{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f072d23b2d5e641467cb234ea0435163e5f1b18","width":640,"height":939},{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4f2f2aa5df360d8b71b7b9b8faf382c71ed9a08a","width":960,"height":1409},{"url":"https://preview.redd.it/in8sapsyngdf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7b42a29cbce67acd8f05e4e46e8cb5850f93f1d9","width":1080,"height":1586}],"variants":{},"id":"-WjA6spujjRUcG1BNuB-nEd7Iwm6-lwudkrySSCBYcU"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m2c4hz","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"fictionlive","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/","stickied":false,"url":"https://i.redd.it/in8sapsyngdf1.png","subreddit_subscribers":501231,"created_utc":1752769673,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3o3e9y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752773906,"send_replies":true,"parent_id":"t1_n3npmvs","score":3,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They said they're going to work on reasoning next.\\n\\n\\\\&gt; While Kimi K2 serves as a strong foundation for open agentic intelligence, a general agent uses more advanced capabilities such as thinking and visual understanding. We plan to add these to Kimi K2 in the future.\\n\\nI hope there will be finetunes for these bigger models once official Unsloth multiGPU support drops. They list unofficial ways to get multigpu though: [https://docs.unsloth.ai/basics/unsloth-multi-gpu-support](https://docs.unsloth.ai/basics/unsloth-multi-gpu-support)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3o3e9y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They said they&amp;#39;re going to work on reasoning next.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;gt; While Kimi K2 serves as a strong foundation for open agentic intelligence, a general agent uses more advanced capabilities such as thinking and visual understanding. We plan to add these to Kimi K2 in the future.&lt;/p&gt;\\n\\n&lt;p&gt;I hope there will be finetunes for these bigger models once official Unsloth multiGPU support drops. They list unofficial ways to get multigpu though: &lt;a href=\\"https://docs.unsloth.ai/basics/unsloth-multi-gpu-support\\"&gt;https://docs.unsloth.ai/basics/unsloth-multi-gpu-support&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2c4hz","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3o3e9y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752773906,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3npmvs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lordpuddingcup","can_mod_post":false,"created_utc":1752770189,"send_replies":true,"parent_id":"t3_1m2c4hz","score":9,"author_fullname":"t2_vc4z2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As i've said elsewhere, whos gonna fine tune, what we really need to blow things up is Kimi K2 with reasoning (like V2.5 vs R1)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3npmvs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As i&amp;#39;ve said elsewhere, whos gonna fine tune, what we really need to blow things up is Kimi K2 with reasoning (like V2.5 vs R1)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3npmvs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752770189,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2c4hz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3nwkh3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752772075,"send_replies":true,"parent_id":"t3_1m2c4hz","score":5,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can anyone add glm4 to the benchmark? Should be awful at long contex","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3nwkh3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can anyone add glm4 to the benchmark? Should be awful at long contex&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3nwkh3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752772075,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2c4hz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3s8r5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jonodonozym","can_mod_post":false,"created_utc":1752828888,"send_replies":true,"parent_id":"t1_n3p8ds4","score":1,"author_fullname":"t2_g46zm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They're not just LLMs but an assembly of in-house systems revolving around the LLM, so they may have better context pre-processing like compression, trimming, or retrieval that an LLM alone like all open-weight models running on llama.cpp or whatever can't match.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3s8r5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;re not just LLMs but an assembly of in-house systems revolving around the LLM, so they may have better context pre-processing like compression, trimming, or retrieval that an LLM alone like all open-weight models running on llama.cpp or whatever can&amp;#39;t match.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2c4hz","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3s8r5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752828888,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p8ds4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dark-light92","can_mod_post":false,"created_utc":1752785541,"send_replies":true,"parent_id":"t3_1m2c4hz","score":2,"author_fullname":"t2_3lvoq8zw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does anybody have any idea why the closed models (o3, gemini &amp; grok) are so much better at long context than other models?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p8ds4","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does anybody have any idea why the closed models (o3, gemini &amp;amp; grok) are so much better at long context than other models?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3p8ds4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752785541,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2c4hz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3ph1pv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752788090,"send_replies":true,"parent_id":"t3_1m2c4hz","score":1,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Per my testing, it's between Llama 4 Scout/Maverick. Not great and doesn't align with these results at all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ph1pv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Per my testing, it&amp;#39;s between Llama 4 Scout/Maverick. Not great and doesn&amp;#39;t align with these results at all.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2c4hz/kimi_k2_fictionlivebench_onpar_with_deepseek_v3/n3ph1pv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752788090,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2c4hz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
