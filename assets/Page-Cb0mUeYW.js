import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const t=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Basically the title. I have mixed architectures in my system, do I really do not want to deal with ROCm. Any ways to take full advantage of 32GB while using Vulkan?\\n\\n\\nEDIT: I might try reflashing BIOS. Does anyone have `113-D1631711QA-10` for MI50?\\n\\n\\nEDIT2: Just tested `113-D1631700-111` vBIOS for MI50 32GB, it seems to have worked! CPU-Visible VRAM is correctly displayed as 32GB and llama.cpp also sees full 32GB (first is non-flashed, second is flashed):\\n\\n    ggml_vulkan: 1 = AMD Radeon Graphics (RADV VEGA20) (radv) | uma: 0 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: none\\n    ggml_vulkan: 2 = AMD Instinct MI60 / MI50 (RADV VEGA20) (radv) | uma: 0 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: none\\n\\nEDIT3: Link to the vBIOS: https://www.techpowerup.com/vgabios/274474/274474\\n\\nEDIT4: Now that this is becoming \\"troubleshoot anything on a MI50\\", here\'s a tip - if you find your system stuttering, check `amd-smi` for `PCIE_REPLAY` and `SINGE/DOUBLE_ECC`. If those numbers are climbing, it means your PCIe is probably not up to the spec or (like me) you\'re using a PCIe 4.0 through a PCIe 3.0 riser. Switching BIOS to PCIe 3.0 for the riser slot fixed all the stutters for me. Weirdly, this only started happening on the `113-D1631700-111` vBIOS.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"32GB Mi50, but llama.cpp Vulkan sees only 16GB","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m389gi","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.7,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_9pixf","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752964247,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752859163,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Basically the title. I have mixed architectures in my system, do I really do not want to deal with ROCm. Any ways to take full advantage of 32GB while using Vulkan?&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: I might try reflashing BIOS. Does anyone have &lt;code&gt;113-D1631711QA-10&lt;/code&gt; for MI50?&lt;/p&gt;\\n\\n&lt;p&gt;EDIT2: Just tested &lt;code&gt;113-D1631700-111&lt;/code&gt; vBIOS for MI50 32GB, it seems to have worked! CPU-Visible VRAM is correctly displayed as 32GB and llama.cpp also sees full 32GB (first is non-flashed, second is flashed):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;ggml_vulkan: 1 = AMD Radeon Graphics (RADV VEGA20) (radv) | uma: 0 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: none\\nggml_vulkan: 2 = AMD Instinct MI60 / MI50 (RADV VEGA20) (radv) | uma: 0 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: none\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;EDIT3: Link to the vBIOS: &lt;a href=\\"https://www.techpowerup.com/vgabios/274474/274474\\"&gt;https://www.techpowerup.com/vgabios/274474/274474&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;EDIT4: Now that this is becoming &amp;quot;troubleshoot anything on a MI50&amp;quot;, here&amp;#39;s a tip - if you find your system stuttering, check &lt;code&gt;amd-smi&lt;/code&gt; for &lt;code&gt;PCIE_REPLAY&lt;/code&gt; and &lt;code&gt;SINGE/DOUBLE_ECC&lt;/code&gt;. If those numbers are climbing, it means your PCIe is probably not up to the spec or (like me) you&amp;#39;re using a PCIe 4.0 through a PCIe 3.0 riser. Switching BIOS to PCIe 3.0 for the riser slot fixed all the stutters for me. Weirdly, this only started happening on the &lt;code&gt;113-D1631700-111&lt;/code&gt; vBIOS.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/GE36MCMpZolX-lqe53_knptQZ0sj5zIo3NOgWQL7sH0.jpeg?auto=webp&amp;s=937fe30d687034fe0c3d18cb19c06bf55d8c5cfb","width":630,"height":270},"resolutions":[{"url":"https://external-preview.redd.it/GE36MCMpZolX-lqe53_knptQZ0sj5zIo3NOgWQL7sH0.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e423f944b71fc93593fff0170c58e9d1a8e93f44","width":108,"height":46},{"url":"https://external-preview.redd.it/GE36MCMpZolX-lqe53_knptQZ0sj5zIo3NOgWQL7sH0.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ce39fe150737080aa58411c9f09397ec8517ecc4","width":216,"height":92},{"url":"https://external-preview.redd.it/GE36MCMpZolX-lqe53_knptQZ0sj5zIo3NOgWQL7sH0.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=51cf876231ecc910be7ebd3b5b95a23af529b042","width":320,"height":137}],"variants":{},"id":"GE36MCMpZolX-lqe53_knptQZ0sj5zIo3NOgWQL7sH0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m389gi","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ashirviskas","discussion_type":null,"num_comments":26,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/","subreddit_subscribers":501527,"created_utc":1752859163,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3w97ik","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uzbx5","score":1,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ty, it\'s already 1am here, will come back to you after some sleep","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w97ik","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ty, it&amp;#39;s already 1am here, will come back to you after some sleep&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3w97ik/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752876491,"author_flair_text":null,"treatment_tags":[],"created_utc":1752876491,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n41lne9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3yt9mj","score":1,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hm.... it doesn\'t look to be a BIOS or a generic driver problem. Since the 32GB is clearly visible. It appears that Vulkan won\'t use more than 16GB before starting to use shared memory. I\'ve seen this before, but I can\'t remember what I did about it.\\n\\nWhen you run llama.cpp, it reports the amount of memory available to the GPU. What does it say about the instincts?","edited":false,"author_flair_css_class":null,"name":"t1_n41lne9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hm.... it doesn&amp;#39;t look to be a BIOS or a generic driver problem. Since the 32GB is clearly visible. It appears that Vulkan won&amp;#39;t use more than 16GB before starting to use shared memory. I&amp;#39;ve seen this before, but I can&amp;#39;t remember what I did about it.&lt;/p&gt;\\n\\n&lt;p&gt;When you run llama.cpp, it reports the amount of memory available to the GPU. What does it say about the instincts?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n41lne9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752952840,"author_flair_text":null,"collapsed":false,"created_utc":1752952840,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3yt9mj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uzbx5","score":1,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"                      radeontop 1.4, running on VEGA20 bus 12, 120 samples/sec                   \\n                                                   │                                             \\n                             Graphics pipe   0.00% │                                             \\n    ───────────────────────────────────────────────┼─────────────────────────────────────────────\\n                              Event Engine   0.00% │                                             \\n                                                   │                                             \\n               Vertex Grouper + Tesselator   0.00% │                                             \\n                                                   │                                             \\n                         Texture Addresser   0.00% │                                             \\n                                                   │                                             \\n                             Shader Export   0.00% │                                             \\n               Sequencer Instruction Cache   0.00% │                                             \\n                       Shader Interpolator   0.00% │                                             \\n                                                   │                                             \\n                            Scan Converter   0.00% │                                             \\n                        Primitive Assembly   0.00% │                                             \\n                                                   │                                             \\n                               Depth Block   0.00% │                                             \\n                               Color Block   0.00% │                                             \\n                                                   │                                             \\n                         10M / 32734M VRAM   0.03% │                                             \\n                          14M / 64351M GTT   0.02% │   \\n\\n\\nVulkaninfo spits out too much for reddit, so here is the output: https://termbin.com/0iy6\\n\\nEDIT:\\nWhen I load ~60GB model into 3 GPUs, I see this for both MI 50s on radeontop: \\n\\n                              16353M / 32734M VRAM  49.96% │                                                        \\n                                4249M / 64351M GTT   6.60% │                                                        \\n                        0.35G / 1.00G Memory Clock  35.00% │                                                        \\n                        0.93G / 1.73G Shader Clock  53.73% │                                                        \\n                                                           │","edited":1752920652,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3yt9mj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;pre&gt;&lt;code&gt;                  radeontop 1.4, running on VEGA20 bus 12, 120 samples/sec                   \\n                                               │                                             \\n                         Graphics pipe   0.00% │                                             \\n───────────────────────────────────────────────┼─────────────────────────────────────────────\\n                          Event Engine   0.00% │                                             \\n                                               │                                             \\n           Vertex Grouper + Tesselator   0.00% │                                             \\n                                               │                                             \\n                     Texture Addresser   0.00% │                                             \\n                                               │                                             \\n                         Shader Export   0.00% │                                             \\n           Sequencer Instruction Cache   0.00% │                                             \\n                   Shader Interpolator   0.00% │                                             \\n                                               │                                             \\n                        Scan Converter   0.00% │                                             \\n                    Primitive Assembly   0.00% │                                             \\n                                               │                                             \\n                           Depth Block   0.00% │                                             \\n                           Color Block   0.00% │                                             \\n                                               │                                             \\n                     10M / 32734M VRAM   0.03% │                                             \\n                      14M / 64351M GTT   0.02% │   \\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Vulkaninfo spits out too much for reddit, so here is the output: &lt;a href=\\"https://termbin.com/0iy6\\"&gt;https://termbin.com/0iy6&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;EDIT:\\nWhen I load ~60GB model into 3 GPUs, I see this for both MI 50s on radeontop: &lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;                          16353M / 32734M VRAM  49.96% │                                                        \\n                            4249M / 64351M GTT   6.60% │                                                        \\n                    0.35G / 1.00G Memory Clock  35.00% │                                                        \\n                    0.93G / 1.73G Shader Clock  53.73% │                                                        \\n                                                       │\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3yt9mj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752916253,"author_flair_text":null,"treatment_tags":[],"created_utc":1752916253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uzbx5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uxabr","score":5,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you post a radeontop screenshot as well as a vulkaninfo summary for the GPU?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3uzbx5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you post a radeontop screenshot as well as a vulkaninfo summary for the GPU?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uzbx5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862664,"author_flair_text":null,"treatment_tags":[],"created_utc":1752862664,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uxabr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1752862065,"send_replies":true,"parent_id":"t1_n3up9ms","score":3,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see 32GB of VRAM in `amdgpu_top`, but it says that CPU-Visible VRAM is only 16GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uxabr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see 32GB of VRAM in &lt;code&gt;amdgpu_top&lt;/code&gt;, but it says that CPU-Visible VRAM is only 16GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uxabr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862065,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3up9ms","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"coolestmage","can_mod_post":false,"created_utc":1752859813,"send_replies":true,"parent_id":"t3_1m389gi","score":5,"author_fullname":"t2_6dtdz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do other things report it correctly? Might be a vbios issue.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3up9ms","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do other things report it correctly? Might be a vbios issue.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3up9ms/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859813,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3v10fc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uzieb","score":2,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I always force everything to pretend it\'s an Rx 6900\\n\\nI have not tried it with non-RDNA (Vega in this case) GPUs though","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3v10fc","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I always force everything to pretend it&amp;#39;s an Rx 6900&lt;/p&gt;\\n\\n&lt;p&gt;I have not tried it with non-RDNA (Vega in this case) GPUs though&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3v10fc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752863156,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752863156,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uzieb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uxvpf","score":1,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I remember having to set env vars per architecture on rocm. Is that why?","edited":false,"author_flair_css_class":null,"name":"t1_n3uzieb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I remember having to set env vars per architecture on rocm. Is that why?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uzieb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862717,"author_flair_text":null,"collapsed":false,"created_utc":1752862717,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uxvpf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3uxe04","score":1,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean it works perfectly if I only use one generation of cards, but I have multiple.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uxvpf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean it works perfectly if I only use one generation of cards, but I have multiple.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uxvpf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862239,"author_flair_text":null,"treatment_tags":[],"created_utc":1752862239,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uxe04","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3ux0rh","score":3,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you installed Arch I\'d imagine you\'re willing to deal with some clunkiness.\\n\\nBut you\'re right. The AMD team is small, and right now Ubuntu LTS is the only first-class customer.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3uxe04","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you installed Arch I&amp;#39;d imagine you&amp;#39;re willing to deal with some clunkiness.&lt;/p&gt;\\n\\n&lt;p&gt;But you&amp;#39;re right. The AMD team is small, and right now Ubuntu LTS is the only first-class customer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uxe04/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862095,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752862095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3ux0rh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1752861989,"send_replies":true,"parent_id":"t1_n3uodjr","score":2,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Arch, ROCm with multiple architectures is clunky.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3ux0rh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Arch, ROCm with multiple architectures is clunky.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3ux0rh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752861989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uodjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"created_utc":1752859563,"send_replies":true,"parent_id":"t3_1m389gi","score":4,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What OS?\\n\\nIf you\'re on Ubuntu dealing with ROCm in regards to Llama CPP is kind of a no-brainer right now, just one big chunky install before you build","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uodjr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What OS?&lt;/p&gt;\\n\\n&lt;p&gt;If you&amp;#39;re on Ubuntu dealing with ROCm in regards to Llama CPP is kind of a no-brainer right now, just one big chunky install before you build&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uodjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752859563,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n40nd2u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bennmann","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3zq879","score":1,"author_fullname":"t2_5lqoi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I\'m not you, but I have flashed a RX 6900 XT vbios multiple times\\n\\n\\nAs long as you have a backup known working vbios, it\'s probably worth the small risk of failure\\n\\n\\nMy risk tolerance may not be yours, but I would be willing to flash and test new bios personally.\\n\\n\\nHope that helps either way ","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n40nd2u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not you, but I have flashed a RX 6900 XT vbios multiple times&lt;/p&gt;\\n\\n&lt;p&gt;As long as you have a backup known working vbios, it&amp;#39;s probably worth the small risk of failure&lt;/p&gt;\\n\\n&lt;p&gt;My risk tolerance may not be yours, but I would be willing to flash and test new bios personally.&lt;/p&gt;\\n\\n&lt;p&gt;Hope that helps either way &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n40nd2u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752942087,"author_flair_text":null,"treatment_tags":[],"created_utc":1752942087,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3zq879","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z5sk3","score":1,"author_fullname":"t2_9pixf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have the same BIOS, I\'ve heard that Radeon VII Pro 32GB Bios should work, but the one I found is unsigned, not sure whether to risk it lol","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n3zq879","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have the same BIOS, I&amp;#39;ve heard that Radeon VII Pro 32GB Bios should work, but the one I found is unsigned, not sure whether to risk it lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3zq879/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752931453,"author_flair_text":null,"treatment_tags":[],"created_utc":1752931453,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z5sk3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z2mtp","score":3,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah okay, but I wonder why rocm is fine with 32gb?\\n\\nllamavk --list-devices\\n\\n    Available devices:\\n\\n    Vulkan0: AMD Radeon Graphics (RADV VEGA20) (16384 MiB, 16384 MiB free)\\n\\n    Vulkan1: AMD Radeon Graphics (RADV VEGA20) (16384 MiB, 16384 MiB free)\\n\\nllamarocm --list-devices\\n\\n    Available devices:\\n\\n    ROCm0: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\\n\\n    ROCm1: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\\n\\nMine are both the latter:\\n\\nrocm-smi --showvbios |grep VBIOS\\\\ version\\n\\n    GPU[0]          : VBIOS version: 113-D1631711-100\\n    GPU[1]          : VBIOS version: 113-D1631711-100\\n\\nEdit: People seem to be posting fixes for rocm (which works fine) lol","edited":1752923272,"author_flair_css_class":null,"name":"t1_n3z5sk3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah okay, but I wonder why rocm is fine with 32gb?&lt;/p&gt;\\n\\n&lt;p&gt;llamavk --list-devices&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Available devices:\\n\\nVulkan0: AMD Radeon Graphics (RADV VEGA20) (16384 MiB, 16384 MiB free)\\n\\nVulkan1: AMD Radeon Graphics (RADV VEGA20) (16384 MiB, 16384 MiB free)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;llamarocm --list-devices&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Available devices:\\n\\nROCm0: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\\n\\nROCm1: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Mine are both the latter:&lt;/p&gt;\\n\\n&lt;p&gt;rocm-smi --showvbios |grep VBIOS\\\\ version&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;GPU[0]          : VBIOS version: 113-D1631711-100\\nGPU[1]          : VBIOS version: 113-D1631711-100\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Edit: People seem to be posting fixes for rocm (which works fine) lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m389gi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3z5sk3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752923062,"author_flair_text":null,"collapsed":false,"created_utc":1752923062,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z2mtp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3z1lbe","score":1,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Someone wrote and deleted a comment here, I might need a different VBIOS. They said that one card is detected with full 32GB using `113-D1631711QA-10`, but not `113-D1631711-10` VBIOS","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3z2mtp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone wrote and deleted a comment here, I might need a different VBIOS. They said that one card is detected with full 32GB using &lt;code&gt;113-D1631711QA-10&lt;/code&gt;, but not &lt;code&gt;113-D1631711-10&lt;/code&gt; VBIOS&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3z2mtp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752921484,"author_flair_text":null,"treatment_tags":[],"created_utc":1752921484,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3z1lbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3w8y27","score":1,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same here. nvtop shows 32gb, rocm+llama.cpp uses 32gb.\\n\\nvulkan+llama.cpp only 16gb.\\n\\nI just use rocm / don\'t both with vulkan.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3z1lbe","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same here. nvtop shows 32gb, rocm+llama.cpp uses 32gb.&lt;/p&gt;\\n\\n&lt;p&gt;vulkan+llama.cpp only 16gb.&lt;/p&gt;\\n\\n&lt;p&gt;I just use rocm / don&amp;#39;t both with vulkan.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3z1lbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752920932,"author_flair_text":null,"treatment_tags":[],"created_utc":1752920932,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3w8y27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1752876403,"send_replies":true,"parent_id":"t1_n3uytug","score":3,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ROCm sees full 32GB, just not Vulkan","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w8y27","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ROCm sees full 32GB, just not Vulkan&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3w8y27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752876403,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3uytug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1752862518,"send_replies":true,"parent_id":"t3_1m389gi","score":1,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how do you know it\'s 32gb and not 16gb?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3uytug","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how do you know it&amp;#39;s 32gb and not 16gb?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3uytug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752862518,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3w8v7g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1752876377,"send_replies":true,"parent_id":"t1_n3w8eyu","score":1,"author_fullname":"t2_9pixf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"One of the first things I did","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w8v7g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One of the first things I did&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m389gi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3w8v7g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752876377,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3w8eyu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1752876227,"send_replies":true,"parent_id":"t3_1m389gi","score":1,"author_fullname":"t2_baavelp5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I would bet that you did not enable resizeable BAR and above 4G decoding in BIOS settings. It needs to be enabled for large VRAM GPUs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w8eyu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would bet that you did not enable resizeable BAR and above 4G decoding in BIOS settings. It needs to be enabled for large VRAM GPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3w8eyu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752876227,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3zuk9p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dc740","can_mod_post":false,"created_utc":1752932985,"send_replies":true,"parent_id":"t3_1m389gi","score":1,"author_fullname":"t2_dkwhd0p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Same here! I have 3 of these cards on my server. In any case, rocm gives me a better performance than Vulkan. To me this has to be some kind of broken Vulkan implementation that assumes these cards are only 16gb, or maybe the implementation itself is limited.  Run a small model that fits into the vulkan 32 gb. Then re run in rocm. I noticed a way better performance on the later, so I have up on vulkan","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3zuk9p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same here! I have 3 of these cards on my server. In any case, rocm gives me a better performance than Vulkan. To me this has to be some kind of broken Vulkan implementation that assumes these cards are only 16gb, or maybe the implementation itself is limited.  Run a small model that fits into the vulkan 32 gb. Then re run in rocm. I noticed a way better performance on the later, so I have up on vulkan&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n3zuk9p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752932985,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n434pmc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1752971601,"send_replies":true,"parent_id":"t3_1m389gi","score":1,"author_fullname":"t2_9pixf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Some results for 1x RX 7900 XTX and 2x MI50 32GB on Vulkan\\n\\nModel: https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/blob/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf\\n\\nSpeed:\\n\\n    prompt eval time =    8640.14 ms /   173 tokens (   49.94 ms per token,    20.02 tokens per second)\\n           eval time =  150167.11 ms /  1330 tokens (  112.91 ms per token,     8.86 tokens per second)\\n          total time =  158807.25 ms /  1503 tokens\\n\\n\\ncmd:\\n\\n    ./build/bin/llama-server \\\\          \\n    --model /path/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf \\\\\\n    --n-gpu-layers 100 -dev Vulkan0,Vulkan1,Vulkan2 \\\\\\n    -fa -ts 34,31,31 --override-tensor \\"blk\\\\.(1|2|3|4|5|6|7|8|9|10|11|12|13)\\\\.ffn_.*_exps\\\\.weight=CPU\\" \\\\\\n    --main-gpu 0\\n\\n\\nI still have like 4GB unused on GPUs and I haven\'t really played with the params. Putting more often used experts on 7900 XTX could probably make it another 20%-60% faster. (Naive loading gave me ~5t/s)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n434pmc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some results for 1x RX 7900 XTX and 2x MI50 32GB on Vulkan&lt;/p&gt;\\n\\n&lt;p&gt;Model: &lt;a href=\\"https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/blob/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf\\"&gt;https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF/blob/main/Q3_K_S/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Speed:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt eval time =    8640.14 ms /   173 tokens (   49.94 ms per token,    20.02 tokens per second)\\n       eval time =  150167.11 ms /  1330 tokens (  112.91 ms per token,     8.86 tokens per second)\\n      total time =  158807.25 ms /  1503 tokens\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;cmd:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;./build/bin/llama-server \\\\          \\n--model /path/Qwen3-235B-A22B-Q3_K_S-00001-of-00003.gguf \\\\\\n--n-gpu-layers 100 -dev Vulkan0,Vulkan1,Vulkan2 \\\\\\n-fa -ts 34,31,31 --override-tensor &amp;quot;blk\\\\.(1|2|3|4|5|6|7|8|9|10|11|12|13)\\\\.ffn_.*_exps\\\\.weight=CPU&amp;quot; \\\\\\n--main-gpu 0\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;I still have like 4GB unused on GPUs and I haven&amp;#39;t really played with the params. Putting more often used experts on 7900 XTX could probably make it another 20%-60% faster. (Naive loading gave me ~5t/s)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m389gi/32gb_mi50_but_llamacpp_vulkan_sees_only_16gb/n434pmc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752971601,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m389gi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),o=()=>e.jsx(l,{data:t});export{o as default};
