import{j as e}from"./index-xjtrh7Y1.js";import{R as l}from"./RedditPostRenderer-D0LT1YWU.js";import"./index-C26yY6uW.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-research-team-claims-to-reproduce-deepseek-core-technologies-for-usd30-relatively-small-r1-zero-model-has-remarkable-problem-solving-abilities](https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-research-team-claims-to-reproduce-deepseek-core-technologies-for-usd30-relatively-small-r1-zero-model-has-remarkable-problem-solving-abilities)\\n\\n&gt;An AI research team from the University of California, Berkeley, led by Ph.D. candidate Jiayi Pan, claims to have reproduced DeepSeek R1-Zero’s core technologies for just $30, showing how advanced models could be implemented affordably. According to Jiayi Pan on [Nitter](https://nitter.lucabased.xyz/jiayi_pirate/status/1882839370505621655), their team reproduced DeepSeek R1-Zero in the Countdown game, and the small language model, with its 3 billion parameters, developed self-verification and search abilities through reinforcement learning.\\n\\nDeepSeek R1's cost advantage seems real. Not looking good for OpenAI.  \\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Berkley AI research team claims to reproduce DeepSeek core technologies for $30","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1icwys9","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"subreddit_type":"public","ups":1460,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_pgxxb47","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":1460,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1738166099,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-research-team-claims-to-reproduce-deepseek-core-technologies-for-usd30-relatively-small-r1-zero-model-has-remarkable-problem-solving-abilities\\"&gt;https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-research-team-claims-to-reproduce-deepseek-core-technologies-for-usd30-relatively-small-r1-zero-model-has-remarkable-problem-solving-abilities&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;An AI research team from the University of California, Berkeley, led by Ph.D. candidate Jiayi Pan, claims to have reproduced DeepSeek R1-Zero’s core technologies for just $30, showing how advanced models could be implemented affordably. According to Jiayi Pan on &lt;a href=\\"https://nitter.lucabased.xyz/jiayi_pirate/status/1882839370505621655\\"&gt;Nitter&lt;/a&gt;, their team reproduced DeepSeek R1-Zero in the Countdown game, and the small language model, with its 3 billion parameters, developed self-verification and search abilities through reinforcement learning.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;DeepSeek R1&amp;#39;s cost advantage seems real. Not looking good for OpenAI.  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?auto=webp&amp;s=4b8e6bd425640a0b9e44bb4693fe93ec24583a7a","width":1200,"height":675},"resolutions":[{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a04c6a7953b76845fa0d6c2b98bf6d3b8f9c546","width":108,"height":60},{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab3ddb5a95e5b89b9e56eb6d638f7d09d48d75b3","width":216,"height":121},{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63718392fd0ddd8990231b2e1696b98f7d4c3ed9","width":320,"height":180},{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9352ea3ae8c1f942779221dd5defced3a256fe28","width":640,"height":360},{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a28ddfc6a8546e7e2a4b365aabccb2018e09b6ae","width":960,"height":540},{"url":"https://external-preview.redd.it/CZ7-oMHU3RjM8RwAAa80-l1MIc1nntYvnvpFjxpd4aM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f06e21f4b9b96cbcc056652efae48c02a382622","width":1080,"height":607}],"variants":{},"id":"cz-x3qS4H2wp2LT3-p5ztO3n-0KNctBYx7pGMmIU2Vk"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1icwys9","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"Slasher1738","discussion_type":null,"num_comments":256,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/","subreddit_subscribers":492315,"created_utc":1738166099,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":9,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9zz3dd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dankhorse25","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wem18","score":2,"author_fullname":"t2_5g07smxd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's exactly the reason OpenAI was getting funding in the first place. Corporations that thought that access on open weights models would lead to them becoming more efficient, reducing costs etc.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_m9zz3dd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s exactly the reason OpenAI was getting funding in the first place. Corporations that thought that access on open weights models would lead to them becoming more efficient, reducing costs etc.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9zz3dd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738240106,"author_flair_text":null,"treatment_tags":[],"created_utc":1738240106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wem18","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1738187401,"send_replies":true,"parent_id":"t1_m9wclvj","score":9,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Not even just people. But also corporations. There’s a lot of benefit of hosting models yourself (as well all know lol).","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not even just people. But also corporations. There’s a lot of benefit of hosting models yourself (as well all know lol).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wem18/","num_reports":null,"locked":false,"name":"t1_m9wem18","created":1738187401,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma89c0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"taughtbytech","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wclvj","score":2,"author_fullname":"t2_sv60dgzy","approved_by":null,"mod_note":null,"all_awardings":[],"body":"i would contribute","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_ma89c0j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i would contribute&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma89c0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738344946,"author_flair_text":null,"treatment_tags":[],"created_utc":1738344946,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9zd7rl","id":"m9zd7rl","parent_id":"t1_m9wixvd","depth":6,"children":["m9zd7rl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wixvd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jaMMint","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wclvj","score":4,"author_fullname":"t2_s4p1j","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, unfortunately you need to build it in order to know if people are going to pay for it..\\n\\nBut it could be really fun, with a wall of donors, some message and leader board and a bit of gamified progress status of the model and trained hours..\\n\\nOf course you'd need to automatically run a selection of benchmarks each day and show the model's progress in  nice charts. Could be great and you could even take a couple percent for administration and running the site. That surely would be acceptable..","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m9wixvd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, unfortunately you need to build it in order to know if people are going to pay for it..&lt;/p&gt;\\n\\n&lt;p&gt;But it could be really fun, with a wall of donors, some message and leader board and a bit of gamified progress status of the model and trained hours..&lt;/p&gt;\\n\\n&lt;p&gt;Of course you&amp;#39;d need to automatically run a selection of benchmarks each day and show the model&amp;#39;s progress in  nice charts. Could be great and you could even take a couple percent for administration and running the site. That surely would be acceptable..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wixvd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738188581,"author_flair_text":null,"treatment_tags":[],"created_utc":1738188581,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wclvj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wbk6a","score":17,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I've considered this, but I guess it depends how much people are willing to pay for open source research.","edited":false,"author_flair_css_class":null,"name":"t1_m9wclvj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I&amp;#39;ve considered this, but I guess it depends how much people are willing to pay for open source research.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wclvj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738186862,"author_flair_text":null,"collapsed":false,"created_utc":1738186862,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wbk6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jaMMint","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ve1tz","score":37,"author_fullname":"t2_s4p1j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We could build a \\"Donate Training\\" website, where every donation is converted into GPU seconds in the cloud to further train the model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wbk6a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We could build a &amp;quot;Donate Training&amp;quot; website, where every donation is converted into GPU seconds in the cloud to further train the model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wbk6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738186579,"author_flair_text":null,"treatment_tags":[],"created_utc":1738186579,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9x6jct","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"n1c39uy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ve1tz","score":1,"author_fullname":"t2_13uw51","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What kind of data is needed? What about deepseek r1 api? I still got 100 usd in credits I'd be willing to give up for something like this if the result would be dramatically improved by doing so","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9x6jct","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What kind of data is needed? What about deepseek r1 api? I still got 100 usd in credits I&amp;#39;d be willing to give up for something like this if the result would be dramatically improved by doing so&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x6jct/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738195646,"author_flair_text":null,"treatment_tags":[],"created_utc":1738195646,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ve1tz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v3fi7","score":28,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If we could crowd source some RunPod credits, I'd be happy to...\\n\\nCould even do it with Mistral Large, and DeepSeek 2.5, as there a little more affordable to run.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9ve1tz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If we could crowd source some RunPod credits, I&amp;#39;d be happy to...&lt;/p&gt;\\n\\n&lt;p&gt;Could even do it with Mistral Large, and DeepSeek 2.5, as there a little more affordable to run.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ve1tz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177503,"author_flair_text":null,"treatment_tags":[],"created_utc":1738177503,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v3fi7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Butthurtz23","can_mod_post":false,"created_utc":1738174627,"send_replies":true,"parent_id":"t1_m9ui70r","score":155,"author_fullname":"t2_188hx6mr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do it quickly before OpenAI puts a measure against this easy trick that they hate so much.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v3fi7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do it quickly before OpenAI puts a measure against this easy trick that they hate so much.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v3fi7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738174627,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":155}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":6,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9x5abn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aurelivm","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9x11xe","score":23,"author_fullname":"t2_zg7via4p7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"While R1 is a 671B parameter model, due to being a MoE model, only 37B parameters are necessary for each token generated and for each token pretrained on. Inferencing LLaMA 3.1 405B, a dense model, requires roughly 10x the GPU time per-token compared to inferencing Deepseek V3/R1, which represents the majority of the computational costs of RL training with GRPO.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9x5abn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While R1 is a 671B parameter model, due to being a MoE model, only 37B parameters are necessary for each token generated and for each token pretrained on. Inferencing LLaMA 3.1 405B, a dense model, requires roughly 10x the GPU time per-token compared to inferencing Deepseek V3/R1, which represents the majority of the computational costs of RL training with GRPO.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x5abn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738195250,"author_flair_text":null,"treatment_tags":[],"created_utc":1738195250,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"m9x11xe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1738193925,"send_replies":true,"parent_id":"t1_m9wn86i","score":6,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x11xe/","num_reports":null,"locked":false,"name":"t1_m9x11xe","created":1738193925,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wn86i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aurelivm","can_mod_post":false,"created_utc":1738189786,"send_replies":true,"parent_id":"t1_m9ui70r","score":8,"author_fullname":"t2_zg7via4p7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It would cost nearly 10x what R1 cost to train. I don't think anyone is going to do it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wn86i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It would cost nearly 10x what R1 cost to train. I don&amp;#39;t think anyone is going to do it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wn86i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738189786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9z6cpl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xik0f","score":2,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Q2 would be my guess, seeing as zuck just said there will be more updates over the next couple of months. \\n\\nI hope it is sooner though","edited":false,"author_flair_css_class":null,"name":"t1_m9z6cpl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q2 would be my guess, seeing as zuck just said there will be more updates over the next couple of months. &lt;/p&gt;\\n\\n&lt;p&gt;I hope it is sooner though&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9z6cpl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738223557,"author_flair_text":null,"collapsed":false,"created_utc":1738223557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9xik0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LatentSpacer","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wcbc5","score":1,"author_fullname":"t2_6c95bzhva","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Better wait for Llama 4 which is supposed to be around the corner.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xik0f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Better wait for Llama 4 which is supposed to be around the corner.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xik0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738199458,"author_flair_text":null,"treatment_tags":[],"created_utc":1738199458,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wcbc5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9w6yoe","score":11,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not sure if it would be or not. Theya re very different architectures. V3/R1 being 761B with 37B active, I think it would be interesting to see how LLaMa 3.1 405B compares. It's a dense model, so might operate a bit differently. As LLaMa 3 70B apparently did quite well with distillation from R1, I's expect good results from the 405B.\\n\\nIt would be research, rather than definitely better or worse than R1. However, I assume it would make a very strong reasoning model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9wcbc5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure if it would be or not. Theya re very different architectures. V3/R1 being 761B with 37B active, I think it would be interesting to see how LLaMa 3.1 405B compares. It&amp;#39;s a dense model, so might operate a bit differently. As LLaMa 3 70B apparently did quite well with distillation from R1, I&amp;#39;s expect good results from the 405B.&lt;/p&gt;\\n\\n&lt;p&gt;It would be research, rather than definitely better or worse than R1. However, I assume it would make a very strong reasoning model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wcbc5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738186783,"author_flair_text":null,"treatment_tags":[],"created_utc":1738186783,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xx8xz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9w6yoe","score":4,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because it runs quickly on 4 3090's, at 5bit. No need for 1.58bit, SSDs in RAID0, etc\\nEdit: referring to Mistral-Large, not bloated llama","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9xx8xz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because it runs quickly on 4 3090&amp;#39;s, at 5bit. No need for 1.58bit, SSDs in RAID0, etc\\nEdit: referring to Mistral-Large, not bloated llama&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xx8xz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738204219,"author_flair_text":null,"treatment_tags":[],"created_utc":1738204219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9w6yoe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnotherFuckingSheep","can_mod_post":false,"created_utc":1738185357,"send_replies":true,"parent_id":"t1_m9ui70r","score":3,"author_fullname":"t2_bjafn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why would that be better than the actual R1?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9w6yoe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would that be better than the actual R1?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w6yoe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738185357,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ui70r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"created_utc":1738168847,"send_replies":true,"parent_id":"t3_1icwys9","score":392,"author_fullname":"t2_c3giffrkd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Impressive to see this working on such small models, and great to have the repo and training code alla vailable.\\n\\nI'd love to see it applied to LLaMa 3.1 405B, and see how well it can improve itself","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ui70r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Impressive to see this working on such small models, and great to have the repo and training code alla vailable.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d love to see it applied to LLaMa 3.1 405B, and see how well it can improve itself&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ui70r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738168847,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":392}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"maalvoh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Username_Aweosme","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9x56s4","score":4,"author_fullname":"t2_3sof30lg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's because RL is just goated like that. \\n\\n\\n– number one RL fan","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_maalvoh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s because RL is just goated like that. &lt;/p&gt;\\n\\n&lt;p&gt;– number one RL fan&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maalvoh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738369711,"author_flair_text":null,"treatment_tags":[],"created_utc":1738369711,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9x56s4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brucebay","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uy42b","score":15,"author_fullname":"t2_174v04","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I had a colleague who lived by reinforcement learning decades ago. I guess he was a pioneer and I owe him an apology.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9x56s4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had a colleague who lived by reinforcement learning decades ago. I guess he was a pioneer and I owe him an apology.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x56s4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738195219,"author_flair_text":null,"treatment_tags":[],"created_utc":1738195219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma0txb2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FinalsMVPZachZarba","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uy42b","score":2,"author_fullname":"t2_p36owpxz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Already exists: https://www.sciencedirect.com/science/article/pii/S0004370221000862","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma0txb2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Already exists: &lt;a href=\\"https://www.sciencedirect.com/science/article/pii/S0004370221000862\\"&gt;https://www.sciencedirect.com/science/article/pii/S0004370221000862&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma0txb2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738250845,"author_flair_text":null,"treatment_tags":[],"created_utc":1738250845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9y8swd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1738208131,"send_replies":true,"parent_id":"t1_m9uy42b","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"😂","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;😂&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9y8swd/","num_reports":null,"locked":false,"name":"t1_m9y8swd","created":1738208131,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":2,"name":"t1_m9w2egw","id":"m9w2egw","parent_id":"t1_m9uy42b","depth":2,"children":["m9w2egw"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uy42b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EtadanikM","can_mod_post":false,"created_utc":1738173186,"send_replies":true,"parent_id":"t1_m9ucob5","score":181,"author_fullname":"t2_105wcs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"Reinforcement Learning is All You Need\\" - incoming NIPS paper","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uy42b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Reinforcement Learning is All You Need&amp;quot; - incoming NIPS paper&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uy42b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738173186,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":181}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":9,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma12q3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"whatsbehindyourhead","can_mod_post":false,"send_replies":true,"parent_id":"t1_ma07t7n","score":1,"author_fullname":"t2_8dul12wm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The classic case is Kodak who were one of the most successful companies in the world, and developed the digital camera.  They failed to market this and when the digital camera went global they went bankrupt as a result.","edited":false,"author_flair_css_class":null,"name":"t1_ma12q3b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The classic case is Kodak who were one of the most successful companies in the world, and developed the digital camera.  They failed to market this and when the digital camera went global they went bankrupt as a result.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma12q3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738253384,"author_flair_text":null,"collapsed":false,"created_utc":1738253384,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ma07t7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xbk09","score":9,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"AFAIK Nokia had a touch screen phone before Apple. They did not do anything about it and we all know what happened.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AFAIK Nokia had a touch screen phone before Apple. They did not do anything about it and we all know what happened.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma07t7n/","num_reports":null,"locked":false,"name":"t1_ma07t7n","created":1738243608,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738243608,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma1t8ru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"happyfappy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ma1nugq","score":1,"author_fullname":"t2_1mna0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Correct! ","edited":false,"author_flair_css_class":null,"name":"t1_ma1t8ru","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Correct! &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma1t8ru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738260721,"author_flair_text":null,"collapsed":false,"created_utc":1738260721,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ma1nugq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Top_Discount5289","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xbk09","score":4,"author_fullname":"t2_ez8roccx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is the \\"Innovators Dilemma\\" already outlined in 1997 by Harvard Prof. Clayton Christensen. [https://en.wikipedia.org/wiki/The\\\\_Innovator%27s\\\\_Dilemma](https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma1nugq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the &amp;quot;Innovators Dilemma&amp;quot; already outlined in 1997 by Harvard Prof. Clayton Christensen. &lt;a href=\\"https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma\\"&gt;https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma1nugq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738259240,"author_flair_text":null,"treatment_tags":[],"created_utc":1738259240,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma301w1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"happyfappy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ma2xwaa","score":1,"author_fullname":"t2_1mna0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Microsoft didn't technically buy them, you're right about that. But their $14B investment did get them a ton of equity in OpenAI. They were just arguing about how much it should be worth if OpenAI changes to for-profit.\\n\\n\\nReference: https://finance.yahoo.com/news/microsoft-openai-haggling-over-tech-170816471.html ","edited":false,"author_flair_css_class":null,"name":"t1_ma301w1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Microsoft didn&amp;#39;t technically buy them, you&amp;#39;re right about that. But their $14B investment did get them a ton of equity in OpenAI. They were just arguing about how much it should be worth if OpenAI changes to for-profit.&lt;/p&gt;\\n\\n&lt;p&gt;Reference: &lt;a href=\\"https://finance.yahoo.com/news/microsoft-openai-haggling-over-tech-170816471.html%C2%A0\\"&gt;https://finance.yahoo.com/news/microsoft-openai-haggling-over-tech-170816471.html &lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma301w1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738272514,"author_flair_text":null,"collapsed":false,"created_utc":1738272514,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ma2xwaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"realzequel","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xbk09","score":1,"author_fullname":"t2_efshf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Then OpenAI came along. Another startup. And they demonstrated the power of the transformer - something they didn't even invent. Microsoft bought them. \\n\\nMicrosoft doesn't have any equity in OpenAi, they have an agreement to share 51% of their future profits with a lot of clauses iirc.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma2xwaa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Then OpenAI came along. Another startup. And they demonstrated the power of the transformer - something they didn&amp;#39;t even invent. Microsoft bought them. &lt;/p&gt;\\n\\n&lt;p&gt;Microsoft doesn&amp;#39;t have any equity in OpenAi, they have an agreement to share 51% of their future profits with a lot of clauses iirc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma2xwaa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738271921,"author_flair_text":null,"treatment_tags":[],"created_utc":1738271921,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mb8wkfx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redcape0","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xbk09","score":2,"author_fullname":"t2_3zpt06os","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yup the same way car companies could not build electric cars","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mb8wkfx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yup the same way car companies could not build electric cars&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/mb8wkfx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738820214,"author_flair_text":null,"treatment_tags":[],"created_utc":1738820214,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9yq0xh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9xbk09","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I love the free market, damn. The whole process sounds so good, honestly.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love the free market, damn. The whole process sounds so good, honestly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9yq0xh/","num_reports":null,"locked":false,"name":"t1_m9yq0xh","created":1738214999,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738214999,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":1,"name":"t1_m9zbqdp","id":"m9zbqdp","parent_id":"t1_m9xbk09","depth":3,"children":["m9zbqdp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9xbk09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"happyfappy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":78,"author_fullname":"t2_1mna0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They didn't because it would have cannibalized their core search business.\\n\\n\\nThis is a mistake every giant makes. It's why disruption always comes from the fringes.\\n\\n\\nDeepMind was a startup. They were the first to demonstrate the power of combining RL with deep learning. They were acquired by Google and produced breakthroughs in areas unrelated to their core business, like protein folding.\\n\\n\\nThen OpenAI came along. Another startup. And they demonstrated the power of the transformer - something they didn't even invent. Microsoft bought them. They rapidly integrated it into Bing because they were already behind Google and this didn't threaten Microsoft's core businesses. \\n\\n\\nNow, if OpenAI had failed to procure insane amounts of capital, they might have had to focus on efficiency. Instead, the need for huge resources became a feature, not a bug. It was to be their \\"moat\\". The greater their needs, the higher the barrier to entry, the better their chances of dominating.\\n\\n\\nNow Deepseek, having no moat to protect and nothing to lose, discovered a more efficient approach.\\n\\n\\nThis is going to keep happening. The bigger they are, the more they are motivated to keep things as they are. This creates opportunities for the rest of us.\\n\\n\\nSuppose someone at Microsoft thought, \\"Hey, I bet we could make MS Office obsolete!\\" What are the chances that they'd get the resources and buy-in from the company to make that happen? \\"Seriously, you want us to kill our cash cow?\\" \\n\\n\\nBut if that same person worked at a law firm spending a fortune on MS Office licenses and so on, or a startup looking for funding, the situation flips.\\n\\n\\nThis is going to keep happening. There is capability overhang that has not been exploited. There is good research that has gone overlooked. There are avenues giants will not be able to pursue because of their vested interests in the status quo and because of institutional inertia. \\n\\n\\nThis is good news.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9xbk09","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They didn&amp;#39;t because it would have cannibalized their core search business.&lt;/p&gt;\\n\\n&lt;p&gt;This is a mistake every giant makes. It&amp;#39;s why disruption always comes from the fringes.&lt;/p&gt;\\n\\n&lt;p&gt;DeepMind was a startup. They were the first to demonstrate the power of combining RL with deep learning. They were acquired by Google and produced breakthroughs in areas unrelated to their core business, like protein folding.&lt;/p&gt;\\n\\n&lt;p&gt;Then OpenAI came along. Another startup. And they demonstrated the power of the transformer - something they didn&amp;#39;t even invent. Microsoft bought them. They rapidly integrated it into Bing because they were already behind Google and this didn&amp;#39;t threaten Microsoft&amp;#39;s core businesses. &lt;/p&gt;\\n\\n&lt;p&gt;Now, if OpenAI had failed to procure insane amounts of capital, they might have had to focus on efficiency. Instead, the need for huge resources became a feature, not a bug. It was to be their &amp;quot;moat&amp;quot;. The greater their needs, the higher the barrier to entry, the better their chances of dominating.&lt;/p&gt;\\n\\n&lt;p&gt;Now Deepseek, having no moat to protect and nothing to lose, discovered a more efficient approach.&lt;/p&gt;\\n\\n&lt;p&gt;This is going to keep happening. The bigger they are, the more they are motivated to keep things as they are. This creates opportunities for the rest of us.&lt;/p&gt;\\n\\n&lt;p&gt;Suppose someone at Microsoft thought, &amp;quot;Hey, I bet we could make MS Office obsolete!&amp;quot; What are the chances that they&amp;#39;d get the resources and buy-in from the company to make that happen? &amp;quot;Seriously, you want us to kill our cash cow?&amp;quot; &lt;/p&gt;\\n\\n&lt;p&gt;But if that same person worked at a law firm spending a fortune on MS Office licenses and so on, or a startup looking for funding, the situation flips.&lt;/p&gt;\\n\\n&lt;p&gt;This is going to keep happening. There is capability overhang that has not been exploited. There is good research that has gone overlooked. There are avenues giants will not be able to pursue because of their vested interests in the status quo and because of institutional inertia. &lt;/p&gt;\\n\\n&lt;p&gt;This is good news.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xbk09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738197229,"author_flair_text":null,"treatment_tags":[],"created_utc":1738197229,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":78}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vwere","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"martinerous","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":26,"author_fullname":"t2_5tp54ey","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe they tried but when they first ran the LLM, it said \\"Wait...\\" and so they did :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vwere","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe they tried but when they first ran the LLM, it said &amp;quot;Wait...&amp;quot; and so they did :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vwere/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738182533,"author_flair_text":null,"treatment_tags":[],"created_utc":1738182533,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma0jr3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cnydox","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9w3bdq","score":2,"author_fullname":"t2_i8cfjvg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure which specific paper but google research has a lot of RL papers even before 2021","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma0jr3g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure which specific paper but google research has a lot of RL papers even before 2021&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma0jr3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738247700,"author_flair_text":null,"treatment_tags":[],"created_utc":1738247700,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9w3bdq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"airzinity","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":10,"author_fullname":"t2_2ojoyc18","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"can u link that 2021 paper? thanks","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9w3bdq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;can u link that 2021 paper? thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w3bdq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738184377,"author_flair_text":null,"treatment_tags":[],"created_utc":1738184377,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9yd7pe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"broknbottle","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wwe6x","score":4,"author_fullname":"t2_46hwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s because they do it, put on promo doc, get promoted and they instantly become new role, who dis?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9yd7pe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s because they do it, put on promo doc, get promoted and they instantly become new role, who dis?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9yd7pe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738209736,"author_flair_text":null,"treatment_tags":[],"created_utc":1738209736,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wwe6x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Papabear3339","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":7,"author_fullname":"t2_7iw5w8ac","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is an insane number of public papers documenting tested llm architecture improvements, that just kind of faded into obscurity.\\n\\nProbably a few thousand of them on arXiv.org\\n\\nTons of people are doing research, but somehow the vast majority of it just gets ignored by the companies actually building the models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9wwe6x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is an insane number of public papers documenting tested llm architecture improvements, that just kind of faded into obscurity.&lt;/p&gt;\\n\\n&lt;p&gt;Probably a few thousand of them on arXiv.org&lt;/p&gt;\\n\\n&lt;p&gt;Tons of people are doing research, but somehow the vast majority of it just gets ignored by the companies actually building the models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wwe6x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738192483,"author_flair_text":null,"treatment_tags":[],"created_utc":1738192483,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vswyj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"treetimes","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":4,"author_fullname":"t2_4t8ac","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That they tell people about, right?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vswyj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That they tell people about, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vswyj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738181576,"author_flair_text":null,"treatment_tags":[],"created_utc":1738181576,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma165lm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SeymourBits","can_mod_post":false,"send_replies":true,"parent_id":"t1_ma13qnn","score":1,"author_fullname":"t2_hb7wj","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It may have been originally sourced from a LLM but it is not interactive, meaning you can't ask follow-up questions. They are just fetching the prewritten text like the web snippets they have been showboating for years. The only difference is how they they included an effect to fake inference. Look in the page code for yourself.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_ma165lm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It may have been originally sourced from a LLM but it is not interactive, meaning you can&amp;#39;t ask follow-up questions. They are just fetching the prewritten text like the web snippets they have been showboating for years. The only difference is how they they included an effect to fake inference. Look in the page code for yourself.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma165lm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738254352,"author_flair_text":null,"treatment_tags":[],"created_utc":1738254352,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ma13qnn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ansible32","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9yawc1","score":1,"author_fullname":"t2_72uqo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The other day I searched for something, Google inferred the question I would've asked ChatGPT or Gemini and included exactly the response I was looking for. That's not prewritten text, it's Gemini. It's still not reliable enough, but it is a lot like ChatGPT.","edited":false,"author_flair_css_class":null,"name":"t1_ma13qnn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The other day I searched for something, Google inferred the question I would&amp;#39;ve asked ChatGPT or Gemini and included exactly the response I was looking for. That&amp;#39;s not prewritten text, it&amp;#39;s Gemini. It&amp;#39;s still not reliable enough, but it is a lot like ChatGPT.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma13qnn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738253672,"author_flair_text":null,"collapsed":false,"created_utc":1738253672,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9yawc1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SeymourBits","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wmveq","score":2,"author_fullname":"t2_hb7wj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Google now just puts a blob of prewritten text on the top of their search page... sometimes. So, it's not like ChatGPT at all, actually.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9yawc1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google now just puts a blob of prewritten text on the top of their search page... sometimes. So, it&amp;#39;s not like ChatGPT at all, actually.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9yawc1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738208882,"author_flair_text":null,"treatment_tags":[],"created_utc":1738208882,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wmveq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ansible32","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":1,"author_fullname":"t2_72uqo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Google search is acting more like ChatGPT every day. Really though I think Google should've waited and trying to \\"catch up\\" with OpenAI was kneejerk. This shit is getting closer to replacing Google search, but it is not ready yet. And ChatGPT is not quite there either.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9wmveq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google search is acting more like ChatGPT every day. Really though I think Google should&amp;#39;ve waited and trying to &amp;quot;catch up&amp;quot; with OpenAI was kneejerk. This shit is getting closer to replacing Google search, but it is not ready yet. And ChatGPT is not quite there either.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wmveq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738189685,"author_flair_text":null,"treatment_tags":[],"created_utc":1738189685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9zzbgz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dankhorse25","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":1,"author_fullname":"t2_5g07smxd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I thought the recent thinking gemini had RL, no?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9zzbgz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought the recent thinking gemini had RL, no?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9zzbgz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738240205,"author_flair_text":null,"treatment_tags":[],"created_utc":1738240205,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma0r01y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thick-Protection-458","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vdnzp","score":1,"author_fullname":"t2_abr7phdd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you mean by \\"didn't do anything\\"?\\n\\n\\nTheir search is using transformers encoders. Their machine translation were encoder-decoder model.\\n\\n\\nThey surely did not do much with decoder-only generative models.\\n\\n\\nBut that's hardly \\"nothing\\" for transformers as a whole.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma0r01y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you mean by &amp;quot;didn&amp;#39;t do anything&amp;quot;?&lt;/p&gt;\\n\\n&lt;p&gt;Their search is using transformers encoders. Their machine translation were encoder-decoder model.&lt;/p&gt;\\n\\n&lt;p&gt;They surely did not do much with decoder-only generative models.&lt;/p&gt;\\n\\n&lt;p&gt;But that&amp;#39;s hardly &amp;quot;nothing&amp;quot; for transformers as a whole.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma0r01y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738249970,"author_flair_text":null,"treatment_tags":[],"created_utc":1738249970,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vdnzp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Down_The_Rabbithole","can_mod_post":false,"created_utc":1738177397,"send_replies":true,"parent_id":"t1_m9ucob5","score":111,"author_fullname":"t2_bgzcy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Never left. What's most insane to me is that google published the paper on how to exactly do this back in 2021. Just like they published the transformer paper, and then.... Didn't do anything with it.\\n\\nIt's honestly bizarre how long it took others to copy and implement the technique. Even DeepMind was talking about how to potentially do this in public for quick gains back in early 2023 and Google *still* hasn't properly implemented it in 2025.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vdnzp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Never left. What&amp;#39;s most insane to me is that google published the paper on how to exactly do this back in 2021. Just like they published the transformer paper, and then.... Didn&amp;#39;t do anything with it.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s honestly bizarre how long it took others to copy and implement the technique. Even DeepMind was talking about how to potentially do this in public for quick gains back in early 2023 and Google &lt;em&gt;still&lt;/em&gt; hasn&amp;#39;t properly implemented it in 2025.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vdnzp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177397,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":111}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vlr96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"crack_pop_rocks","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v7ido","score":32,"author_fullname":"t2_g2iym","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean it’s fundamental to how our brains learn.\\n\\nIf you want to go down the rabbit whole, check out the link below on Hebbian synapses. It’s fundamental to how our brains learn. Also, artificial neural networks use the same mechanisms for training, just in a drastically simplified form.\\n\\nhttps://en.wikipedia.org/wiki/Hebbian_theory","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vlr96","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean it’s fundamental to how our brains learn.&lt;/p&gt;\\n\\n&lt;p&gt;If you want to go down the rabbit whole, check out the link below on Hebbian synapses. It’s fundamental to how our brains learn. Also, artificial neural networks use the same mechanisms for training, just in a drastically simplified form.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/Hebbian_theory\\"&gt;https://en.wikipedia.org/wiki/Hebbian_theory&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vlr96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738179610,"author_flair_text":null,"treatment_tags":[],"created_utc":1738179610,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v7ido","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Economy_Apple_4617","can_mod_post":false,"created_utc":1738175728,"send_replies":true,"parent_id":"t1_m9ucob5","score":51,"author_fullname":"t2_1b9bl441f4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Honestly, RL is the only way to AGI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v7ido","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly, RL is the only way to AGI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v7ido/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175728,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":51}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9um1j8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Winerrolemm","can_mod_post":false,"created_utc":1738169904,"send_replies":true,"parent_id":"t1_m9ucob5","score":38,"author_fullname":"t2_icpay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"She never left us.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9um1j8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;She never left us.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9um1j8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738169904,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v6tt6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"o5mfiHTNsH748KVq","can_mod_post":false,"created_utc":1738175544,"send_replies":true,"parent_id":"t1_m9ucob5","score":13,"author_fullname":"t2_e11zi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For RL…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v6tt6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For RL…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v6tt6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175544,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xdkvp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1738197872,"send_replies":true,"parent_id":"t1_m9ucob5","score":4,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"RL is everything. \\n\\n\\nInsane it ever left.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xdkvp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RL is everything. &lt;/p&gt;\\n\\n&lt;p&gt;Insane it ever left.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xdkvp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738197872,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ucob5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KriosXVII","can_mod_post":false,"created_utc":1738167302,"send_replies":true,"parent_id":"t3_1icwys9","score":245,"author_fullname":"t2_l8llqff","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Insane that RL is back","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ucob5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Insane that RL is back&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ucob5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738167302,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":245}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":426,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_m9x2hvu","id":"m9x2hvu","parent_id":"t1_m9uuajb","depth":1,"children":["m9x2hvu"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uuajb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1icwys9","score":426,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":1739908765,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uuajb/","num_reports":null,"locked":false,"name":"t1_m9uuajb","created":1738172160,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738172160,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9y18i6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hunting-Succcubus","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wgqfm","score":2,"author_fullname":"t2_3wxyen0t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"and we are EARTH O","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9y18i6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;and we are EARTH O&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9y18i6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738205525,"author_flair_text":null,"treatment_tags":[],"created_utc":1738205525,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mamqjcf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Minute2528","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wgqfm","score":1,"author_fullname":"t2_bv263hn3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The work was done by a Chinese student","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mamqjcf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The work was done by a Chinese student&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/mamqjcf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738534206,"author_flair_text":null,"treatment_tags":[],"created_utc":1738534206,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wgqfm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NTXL","can_mod_post":false,"created_utc":1738187972,"send_replies":true,"parent_id":"t1_m9und9y","score":37,"author_fullname":"t2_2dytcw7r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We are America, second to none, and we own the finish line RAAAHHHHHHHH🦅(i've never set foot in the united states)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wgqfm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We are America, second to none, and we own the finish line RAAAHHHHHHHH🦅(i&amp;#39;ve never set foot in the united states)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wgqfm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738187972,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"more","data":{"count":1,"name":"t1_m9z0941","id":"m9z0941","parent_id":"t1_m9und9y","depth":1,"children":["m9z0941"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9und9y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"carnyzzle","can_mod_post":false,"created_utc":1738170271,"send_replies":true,"parent_id":"t3_1icwys9","score":112,"author_fullname":"t2_dbpkj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We are so back","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9und9y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We are so back&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9und9y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738170271,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":112}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v6ra5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"o5mfiHTNsH748KVq","can_mod_post":false,"created_utc":1738175525,"send_replies":true,"parent_id":"t3_1icwys9","score":40,"author_fullname":"t2_e11zi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Costs less than DoorDash","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v6ra5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Costs less than DoorDash&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v6ra5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175525,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":32,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"maeotxd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1738431505,"send_replies":true,"parent_id":"t1_mac83cb","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Here is! [https://github.com/Jiayi-Pan/TinyZero](https://github.com/Jiayi-Pan/TinyZero)","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here is! &lt;a href=\\"https://github.com/Jiayi-Pan/TinyZero\\"&gt;https://github.com/Jiayi-Pan/TinyZero&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maeotxd/","num_reports":null,"locked":false,"name":"t1_maeotxd","created":1738431505,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mac83cb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timelyparadox","can_mod_post":false,"created_utc":1738392894,"send_replies":true,"parent_id":"t1_m9wtl6b","score":1,"author_fullname":"t2_9qv6c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is there a repo so thst i could reproduce this ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mac83cb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there a repo so thst i could reproduce this ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/mac83cb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738392894,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"maqtsrh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waiting4omscs","can_mod_post":false,"created_utc":1738594754,"send_replies":true,"parent_id":"t1_m9wtl6b","score":1,"author_fullname":"t2_q06wy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you share some of the raw responses that the LLM produces and tie them to some key points on the plot?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_maqtsrh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you share some of the raw responses that the LLM produces and tie them to some key points on the plot?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maqtsrh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738594754,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wtl6b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1icwys9","score":32,"approved_by":null,"report_reasons":null,"subreddit":"LocalLLaMA","all_awardings":[],"subreddit_id":"t5_81eyvm","body":"https://preview.redd.it/riz0c93mj0ge1.png?width=504&amp;format=png&amp;auto=webp&amp;s=b7d92698d74f633e2a4429836a77d16c1ea77e1e\\n\\nI got the same results, using 2xH200 using the tinyzero repo! this is real  \\nSo beauty the \\"A ha! moment\\" :3","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/riz0c93mj0ge1.png?width=504&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b7d92698d74f633e2a4429836a77d16c1ea77e1e\\"&gt;https://preview.redd.it/riz0c93mj0ge1.png?width=504&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b7d92698d74f633e2a4429836a77d16c1ea77e1e&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I got the same results, using 2xH200 using the tinyzero repo! this is real&lt;br/&gt;\\nSo beauty the &amp;quot;A ha! moment&amp;quot; :3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wtl6b/","num_reports":null,"locked":false,"name":"t1_m9wtl6b","created":1738191635,"media_metadata":{"riz0c93mj0ge1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":124,"x":108,"u":"https://preview.redd.it/riz0c93mj0ge1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f5d37fcf8b9b24705fda86780fd60eb559c1074"},{"y":249,"x":216,"u":"https://preview.redd.it/riz0c93mj0ge1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbaf6ab132a947a6eaece28e8530d4ea8b2430f8"},{"y":369,"x":320,"u":"https://preview.redd.it/riz0c93mj0ge1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=24795d68b185710e4f5a418439b45a5593efda3e"}],"s":{"y":582,"x":504,"u":"https://preview.redd.it/riz0c93mj0ge1.png?width=504&amp;format=png&amp;auto=webp&amp;s=b7d92698d74f633e2a4429836a77d16c1ea77e1e"},"id":"riz0c93mj0ge1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1738191635,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9z1433","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emil2099","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vaizw","score":3,"author_fullname":"t2_2eeqmvv3","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the thoughtful response. I actually agree that RL agents is a particularly exciting area of development - lots of signals for the reward function. In fact, I’m pretty sure that what we see with the Operator release from OpenAI is first steps in that direction.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m9z1433","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the thoughtful response. I actually agree that RL agents is a particularly exciting area of development - lots of signals for the reward function. In fact, I’m pretty sure that what we see with the Operator release from OpenAI is first steps in that direction.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9z1433/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738220546,"author_flair_text":null,"treatment_tags":[],"created_utc":1738220546,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ysz8w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vaizw","score":1,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do LLMs perform on the traveling salesman problem?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m9ysz8w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do LLMs perform on the traveling salesman problem?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ysz8w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738216360,"author_flair_text":null,"treatment_tags":[],"created_utc":1738216360,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vaizw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vahkw","score":16,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"...\\n\\n3. This is intersting, and something I've been thinking about. I took a module at Uni called Modern Heuristics, and it was a weird one. It was all about reframing problems, and changing the data representation, so a seemingly open ended problem could be represented in a form that had formal optimisation algorithms. I recall one of my exam questions was along the lines of \\"You enter a mall on floor 2, thre are escalators up and down to all floors(1-5), the following escalators have a person offering free cheese samples (xyz), and the following escalators have people handing out leaflets (abc), you need to exit the mall of floor 3. What is the optimal route to maximise the amount of cheese you get while minimising the number of leaflets?\\" It was all stuff like this, and there were a load of different formal techniques for actually identifying optimisation techniques for such things.\\n\\nThe point I'm (very slowly) getting at here, is that we can do this the other way, start with the algorithmic optimisation problem, so we have a calculable solution, and these can programatically be made more complex. Then we can have an LLM dress up the underlying problem in all manner of different stories. Chances are that the LLM's wont identify the algorithm needed to solve the problems, and will instead deelop critical thinking, analytical reasoning to work through them. I think this sort of thing gives room for a lot of ways to programatically create large and progessively more difficult/complex problems that are verifiable.\\n\\nIf you are interested the moudle texxtbook was \\"How To Solve It: Modern Heuristics\\"\\n\\nWhile mathematical and programming tasks are great for this kind of self improvement training, I do think that we can creatively find ways to make other domains of verifiable tasks.\\n\\nI've also been thinking about Generative Adversarial Networks, in this context. It doesn't exactly map, but I wonder if there is a method of parallel training a verifier model to get better at spotting mistakes while the main model gets better at the given tasks, creating that same adversarial realtionship the GAN's have.\\n\\nLot's of ideas, not enough time/compute... I really need to implement some sort of AI AI research assistant that can take a hypothesis, design the experiement, write the code, write a paper, and send me the results...\\n\\nHonestly though, I think if the issue we have is we can't come up with problems hard enough for the AI to improve from, then that shows we have hit a good level.\\n\\n  \\nI think the biggest benefit to this approach of self improvement is going to be task related for agents. Here is where we can set up verifiable outcomes, for making the AI do useful stuff. Learning maths and programming is great, but tasks for agents will be awesome. We can example apps, and programatically create different data in them to generate different problems, and different tasks, and see if self improvement allows the AI's to get better at using the mouse, clicking the buttons, creating the plans, etc. Lots of procedurally generated tasks that involve interacting with UI's and API's, that can be made simple, and get progressively more complex. The same apps could have loads of different AI/procedurall generates styles, so they looked different, and help the AI generalise. I think this appraoch could create a good training/becnhmarking set for agents/task completion. This is what I want to see next, self improving agents.","edited":false,"author_flair_css_class":null,"name":"t1_m9vaizw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;This is intersting, and something I&amp;#39;ve been thinking about. I took a module at Uni called Modern Heuristics, and it was a weird one. It was all about reframing problems, and changing the data representation, so a seemingly open ended problem could be represented in a form that had formal optimisation algorithms. I recall one of my exam questions was along the lines of &amp;quot;You enter a mall on floor 2, thre are escalators up and down to all floors(1-5), the following escalators have a person offering free cheese samples (xyz), and the following escalators have people handing out leaflets (abc), you need to exit the mall of floor 3. What is the optimal route to maximise the amount of cheese you get while minimising the number of leaflets?&amp;quot; It was all stuff like this, and there were a load of different formal techniques for actually identifying optimisation techniques for such things.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;The point I&amp;#39;m (very slowly) getting at here, is that we can do this the other way, start with the algorithmic optimisation problem, so we have a calculable solution, and these can programatically be made more complex. Then we can have an LLM dress up the underlying problem in all manner of different stories. Chances are that the LLM&amp;#39;s wont identify the algorithm needed to solve the problems, and will instead deelop critical thinking, analytical reasoning to work through them. I think this sort of thing gives room for a lot of ways to programatically create large and progessively more difficult/complex problems that are verifiable.&lt;/p&gt;\\n\\n&lt;p&gt;If you are interested the moudle texxtbook was &amp;quot;How To Solve It: Modern Heuristics&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;While mathematical and programming tasks are great for this kind of self improvement training, I do think that we can creatively find ways to make other domains of verifiable tasks.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve also been thinking about Generative Adversarial Networks, in this context. It doesn&amp;#39;t exactly map, but I wonder if there is a method of parallel training a verifier model to get better at spotting mistakes while the main model gets better at the given tasks, creating that same adversarial realtionship the GAN&amp;#39;s have.&lt;/p&gt;\\n\\n&lt;p&gt;Lot&amp;#39;s of ideas, not enough time/compute... I really need to implement some sort of AI AI research assistant that can take a hypothesis, design the experiement, write the code, write a paper, and send me the results...&lt;/p&gt;\\n\\n&lt;p&gt;Honestly though, I think if the issue we have is we can&amp;#39;t come up with problems hard enough for the AI to improve from, then that shows we have hit a good level.&lt;/p&gt;\\n\\n&lt;p&gt;I think the biggest benefit to this approach of self improvement is going to be task related for agents. Here is where we can set up verifiable outcomes, for making the AI do useful stuff. Learning maths and programming is great, but tasks for agents will be awesome. We can example apps, and programatically create different data in them to generate different problems, and different tasks, and see if self improvement allows the AI&amp;#39;s to get better at using the mouse, clicking the buttons, creating the plans, etc. Lots of procedurally generated tasks that involve interacting with UI&amp;#39;s and API&amp;#39;s, that can be made simple, and get progressively more complex. The same apps could have loads of different AI/procedurall generates styles, so they looked different, and help the AI generalise. I think this appraoch could create a good training/becnhmarking set for agents/task completion. This is what I want to see next, self improving agents.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vaizw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176547,"author_flair_text":null,"collapsed":false,"created_utc":1738176547,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vzsy7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"martinerous","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vahkw","score":3,"author_fullname":"t2_5tp54ey","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In the ideal world, I imagine it a bit different way. First, it would be good to have a universal small logic core that works rock solid, with as few hallucinations as realistically possible. Think Google's AlphaProof but for general logic and basic science. This should be possible to train (maybe even with RL) and verify, right?\\n\\nOnly when we are super confident that the core logic is solid and encoded with \\"the highest priority weights\\" (if it's even possible to categorize the weights?), then we can train it with massive data - languages, software design patterns, engineering, creative writing, whatever. Still, this additional training should somehow be of lower priority than the core logic. For example, if we throw some magic books with flying cows at the LLM, we don't want it to learn about flying cows as a fact but recognize this as contradicting the core physical laws it has been trained on. The stable core should win over the statistical majority to avoid situations when the LLM assumes something is right just because there's so much of it in the training data.","edited":false,"author_flair_css_class":null,"name":"t1_m9vzsy7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In the ideal world, I imagine it a bit different way. First, it would be good to have a universal small logic core that works rock solid, with as few hallucinations as realistically possible. Think Google&amp;#39;s AlphaProof but for general logic and basic science. This should be possible to train (maybe even with RL) and verify, right?&lt;/p&gt;\\n\\n&lt;p&gt;Only when we are super confident that the core logic is solid and encoded with &amp;quot;the highest priority weights&amp;quot; (if it&amp;#39;s even possible to categorize the weights?), then we can train it with massive data - languages, software design patterns, engineering, creative writing, whatever. Still, this additional training should somehow be of lower priority than the core logic. For example, if we throw some magic books with flying cows at the LLM, we don&amp;#39;t want it to learn about flying cows as a fact but recognize this as contradicting the core physical laws it has been trained on. The stable core should win over the statistical majority to avoid situations when the LLM assumes something is right just because there&amp;#39;s so much of it in the training data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vzsy7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738183448,"author_flair_text":null,"collapsed":false,"created_utc":1738183448,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m9vfnnl","id":"m9vfnnl","parent_id":"t1_m9vahkw","depth":4,"children":["m9vfnnl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vahkw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uwwz5","score":11,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All good things to think about.\\n\\n1. I've been thinking about this. Personally, I think that there are some good automated ways to do this, and verification models can be a good part of it. What I tend to do when using coding assistants is have a readme that explains the tech stack of the repo, the programming patterns, comment style, data flow, etc. So in a web app, it will specify that a front end component should use a local data store, the store should use the API client, etc. stating what each tech is based on. I then try to implement a reference service (in SoA software), that is just a good practise demo of how I want my code. I can then point the AI at the readme, which also uses the reference service as examples, and tells the AI where the files are. I then instruct it to implement the feature following the Developer Guidelines in the readme. This actually manages to do a pretty good job at getting it to do things how I want it to. I then get a seperate instance to act as a code reviewer, and reveiw the uncommited code against the Developer Guidelines, and general best practise. The developer AI occassionally makes mistakes and does things its own way, but the code reviewer is very good at pointing these out.\\n\\nI can see setting up a bunch of different base repositories with reference docs and deeloper guidlines as a good way to get an AI to implement lots of different features, and then have a verification model/code reviewer do well at pointing out problems with the code, specifically in reference to the rest of the code base. It's not fully flushed out, but I think this could go a pretty long way. So, if you can score Best Practise/Developer Guideline Adherence, alongside functionality, then I think this would allow self improvement.\\n\\nThere are also other things that we can do beyond functionality that can be tested, as we can get the AI to build, deploy, etc. So, we'll see if it's able to keep the linter happy, use environment variables where necessary, etc. I think there is a LOT of opportunity within software development to setup a strong feedback loop for self improvement. Beyond that, we can monitor the performance of an implementation; memory use, speed, resource utilisation, etc. \\n\\n2. Honestly, I don't know. By the nature of being subjective, I think there isn't a right way, and it's going on mass popularity of the output. Considering that best selling books have been rejected by doizens of publishers before someone is willing to publish it, I think humans struggle with this as well. Artistic and Creative writing type things are really not my strong suit, so I find it hard to comment, but my understanding is that while there are a lot of subjective elements to this, there are also a lot of things that you'dd find many people who are talented in the field will agree on, so the trained eye might be able to better put forward more objective measures, or at least a qualitative scale of things that are not completely subjective, but hard to quantify. I would imagine that with expert help support, a good verifier model could be trained here, but honestly, this is a tricky one. However, apparently R1 does suprisingly well at creative writing benchmarks, and I even saw a couple of threads with the general consensus from people reading its cretive writing outputs praising its abilities (at least compared to other frontier models).\\n\\nI could almost imagine a simulation world made up of a huge number of diverse critic personas, and the creative works from the learning model are evaluated by mass opinion from all of the AI residents. Simulated society for measuring subjective things...\\n\\nTBC...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vahkw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All good things to think about.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;I&amp;#39;ve been thinking about this. Personally, I think that there are some good automated ways to do this, and verification models can be a good part of it. What I tend to do when using coding assistants is have a readme that explains the tech stack of the repo, the programming patterns, comment style, data flow, etc. So in a web app, it will specify that a front end component should use a local data store, the store should use the API client, etc. stating what each tech is based on. I then try to implement a reference service (in SoA software), that is just a good practise demo of how I want my code. I can then point the AI at the readme, which also uses the reference service as examples, and tells the AI where the files are. I then instruct it to implement the feature following the Developer Guidelines in the readme. This actually manages to do a pretty good job at getting it to do things how I want it to. I then get a seperate instance to act as a code reviewer, and reveiw the uncommited code against the Developer Guidelines, and general best practise. The developer AI occassionally makes mistakes and does things its own way, but the code reviewer is very good at pointing these out.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I can see setting up a bunch of different base repositories with reference docs and deeloper guidlines as a good way to get an AI to implement lots of different features, and then have a verification model/code reviewer do well at pointing out problems with the code, specifically in reference to the rest of the code base. It&amp;#39;s not fully flushed out, but I think this could go a pretty long way. So, if you can score Best Practise/Developer Guideline Adherence, alongside functionality, then I think this would allow self improvement.&lt;/p&gt;\\n\\n&lt;p&gt;There are also other things that we can do beyond functionality that can be tested, as we can get the AI to build, deploy, etc. So, we&amp;#39;ll see if it&amp;#39;s able to keep the linter happy, use environment variables where necessary, etc. I think there is a LOT of opportunity within software development to setup a strong feedback loop for self improvement. Beyond that, we can monitor the performance of an implementation; memory use, speed, resource utilisation, etc. &lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Honestly, I don&amp;#39;t know. By the nature of being subjective, I think there isn&amp;#39;t a right way, and it&amp;#39;s going on mass popularity of the output. Considering that best selling books have been rejected by doizens of publishers before someone is willing to publish it, I think humans struggle with this as well. Artistic and Creative writing type things are really not my strong suit, so I find it hard to comment, but my understanding is that while there are a lot of subjective elements to this, there are also a lot of things that you&amp;#39;dd find many people who are talented in the field will agree on, so the trained eye might be able to better put forward more objective measures, or at least a qualitative scale of things that are not completely subjective, but hard to quantify. I would imagine that with expert help support, a good verifier model could be trained here, but honestly, this is a tricky one. However, apparently R1 does suprisingly well at creative writing benchmarks, and I even saw a couple of threads with the general consensus from people reading its cretive writing outputs praising its abilities (at least compared to other frontier models).&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I could almost imagine a simulation world made up of a huge number of diverse critic personas, and the creative works from the learning model are evaluated by mass opinion from all of the AI residents. Simulated society for measuring subjective things...&lt;/p&gt;\\n\\n&lt;p&gt;TBC...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vahkw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176536,"author_flair_text":null,"treatment_tags":[],"created_utc":1738176536,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vby0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Economy_Apple_4617","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uwwz5","score":3,"author_fullname":"t2_1b9bl441f4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"RL works great in fields where answer can be easily checked - I mean you can always put your \\"x\\" in equation. So it works for Math, Geometry, may be algebra.\\n\\nIt could work for physics, chemistry and so on.... If you can build virtual environment (based on issac gym for example it could work for for robotics tasks like bipedal gait)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vby0z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RL works great in fields where answer can be easily checked - I mean you can always put your &amp;quot;x&amp;quot; in equation. So it works for Math, Geometry, may be algebra.&lt;/p&gt;\\n\\n&lt;p&gt;It could work for physics, chemistry and so on.... If you can build virtual environment (based on issac gym for example it could work for for robotics tasks like bipedal gait)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vby0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176931,"author_flair_text":null,"treatment_tags":[],"created_utc":1738176931,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uwwz5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emil2099","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ui117","score":38,"author_fullname":"t2_2eeqmvv3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agree - the fact that even small models can improve themselves means we can experiment with RL techniques cheaply before scaling it to larger models. What's interesting is how we construct better ground-truth verification mechanisms. I can see at least a few challenges:\\n\\n1. How do you verify the quality of the solution, not just whether the solution produced the right result? It's one thing to write code that runs and outputs expected answer and another to write code that's maintainable in production - how do you verify for this? \\n\\n2. How do you build a verifier for problem spaces with somewhat subjective outputs (creative writing, strategic thinking, etc) where external non-human verification is challenging? Interestingly, there's clearly benefits across domains even with current approach, e.g. better SimpleQA scores from reasoning models.\\n\\n3. How do you get a model to develop an ever harder set of problems to solve? Right now, it seems that the problem set consists of existing benchmarks. In the longer term, we are going to be limited by our ability to come up with harder and harder problems (that are also verifiable, see points 1 and 2).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9uwwz5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree - the fact that even small models can improve themselves means we can experiment with RL techniques cheaply before scaling it to larger models. What&amp;#39;s interesting is how we construct better ground-truth verification mechanisms. I can see at least a few challenges:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;How do you verify the quality of the solution, not just whether the solution produced the right result? It&amp;#39;s one thing to write code that runs and outputs expected answer and another to write code that&amp;#39;s maintainable in production - how do you verify for this? &lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;How do you build a verifier for problem spaces with somewhat subjective outputs (creative writing, strategic thinking, etc) where external non-human verification is challenging? Interestingly, there&amp;#39;s clearly benefits across domains even with current approach, e.g. better SimpleQA scores from reasoning models.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;How do you get a model to develop an ever harder set of problems to solve? Right now, it seems that the problem set consists of existing benchmarks. In the longer term, we are going to be limited by our ability to come up with harder and harder problems (that are also verifiable, see points 1 and 2).&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uwwz5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172865,"author_flair_text":null,"treatment_tags":[],"created_utc":1738172865,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ui117","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StevenSamAI","can_mod_post":false,"created_utc":1738168800,"send_replies":true,"parent_id":"t1_m9uay42","score":82,"author_fullname":"t2_c3giffrkd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the point here is that it was the 3B model that was generating the training data, and then being trained on it, showing gradual improvement of reasoning abilities in the problem domain it was applied to.\\n\\nI think this is more intersting than distillation from a bigger model, as it shows that models can bootstrap themselves into be better reasoners. The main thing for me though, is it means when someone trains the next biggest, smartest base model, it doesn't need an even bigger teacher to make it better, it can improve itself.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ui117","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the point here is that it was the 3B model that was generating the training data, and then being trained on it, showing gradual improvement of reasoning abilities in the problem domain it was applied to.&lt;/p&gt;\\n\\n&lt;p&gt;I think this is more intersting than distillation from a bigger model, as it shows that models can bootstrap themselves into be better reasoners. The main thing for me though, is it means when someone trains the next biggest, smartest base model, it doesn&amp;#39;t need an even bigger teacher to make it better, it can improve itself.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ui117/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738168800,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":82}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uso0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hackeristi","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9um3di","score":17,"author_fullname":"t2_kr71p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean Altman is a snake. Would not surprise me. What surprises me, idiots paying $200 for their pro model lol.","edited":false,"author_flair_css_class":null,"name":"t1_m9uso0f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean Altman is a snake. Would not surprise me. What surprises me, idiots paying $200 for their pro model lol.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uso0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171718,"author_flair_text":null,"collapsed":false,"created_utc":1738171718,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9w8ksl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"water_bottle_goggles","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vaw1m","score":2,"author_fullname":"t2_skx8j","approved_by":null,"mod_note":null,"all_awardings":[],"body":"wow so \\"\\"\\"open\\"\\"\\"","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m9w8ksl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wow so &amp;quot;&amp;quot;&amp;quot;open&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w8ksl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738185786,"author_flair_text":null,"treatment_tags":[],"created_utc":1738185786,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vaw1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9um3di","score":7,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And before R1 they were really pissed at Deepseek v3 which makes me think that the approach of 200+ experts is exactly what OpenAI was doing with gpt-4o and did not want to reveal it, so others don't follow.","edited":false,"author_flair_css_class":null,"name":"t1_m9vaw1m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And before R1 they were really pissed at Deepseek v3 which makes me think that the approach of 200+ experts is exactly what OpenAI was doing with gpt-4o and did not want to reveal it, so others don&amp;#39;t follow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vaw1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176645,"author_flair_text":null,"collapsed":false,"created_utc":1738176645,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9um3di","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emteedub","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uku3f","score":19,"author_fullname":"t2_78pnpcf9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"must of been a nervous twitch.  I swear they're trying to direct peoples attention away from the secret sauce recipe getting out.  I was listening an informative vid on R1 zero this morning, he referenced that Deepseek had actually published their approach in the beginning of 2023... where 4o/o1 was announced after.  Really makes you wonder if they got ahold of that journal, tried it and it landed\\n\\nthis might be it, but I could swear the paper he had up said jan 2023:\\n\\n[https://arxiv.org/html/2405.04434v2](https://arxiv.org/html/2405.04434v2)","edited":1738170039,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9um3di","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;must of been a nervous twitch.  I swear they&amp;#39;re trying to direct peoples attention away from the secret sauce recipe getting out.  I was listening an informative vid on R1 zero this morning, he referenced that Deepseek had actually published their approach in the beginning of 2023... where 4o/o1 was announced after.  Really makes you wonder if they got ahold of that journal, tried it and it landed&lt;/p&gt;\\n\\n&lt;p&gt;this might be it, but I could swear the paper he had up said jan 2023:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/html/2405.04434v2\\"&gt;https://arxiv.org/html/2405.04434v2&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9um3di/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738169918,"author_flair_text":null,"treatment_tags":[],"created_utc":1738169918,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uku3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"water_bottle_goggles","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ufqip","score":58,"author_fullname":"t2_skx8j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"open ai employees","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9uku3f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;open ai employees&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uku3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738169575,"author_flair_text":null,"treatment_tags":[],"created_utc":1738169575,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":58}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ufqip","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ServeAlone7622","can_mod_post":false,"created_utc":1738168157,"send_replies":true,"parent_id":"t1_m9uay42","score":24,"author_fullname":"t2_yqzkq2mh6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wonder what idiot downvoted you and why.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ufqip","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wonder what idiot downvoted you and why.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ufqip/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738168157,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v0nz6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jhoceanus","can_mod_post":false,"created_utc":1738173873,"send_replies":true,"parent_id":"t1_m9uay42","score":4,"author_fullname":"t2_n0vsfj9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In human, this is called \\"Teaching\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v0nz6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In human, this is called &amp;quot;Teaching&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v0nz6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738173873,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wh3y3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"3oclockam","can_mod_post":false,"created_utc":1738188074,"send_replies":true,"parent_id":"t1_m9uay42","score":1,"author_fullname":"t2_14xb45","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The thing that bothers me about these distilled models is that a smaller model may be incapable of providing the type of output and self reflection in the training data due to limited parameters. \\n\\nThe training would then result in low scores, which would need to be scaled, and then we would be training on a noisier signal. Isn't it always better to try to train on data that the model can understand and replicate? A better approach might be to throw away much of the training dataset that the model is incapable of replicating.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wh3y3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The thing that bothers me about these distilled models is that a smaller model may be incapable of providing the type of output and self reflection in the training data due to limited parameters. &lt;/p&gt;\\n\\n&lt;p&gt;The training would then result in low scores, which would need to be scaled, and then we would be training on a noisier signal. Isn&amp;#39;t it always better to try to train on data that the model can understand and replicate? A better approach might be to throw away much of the training dataset that the model is incapable of replicating.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wh3y3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738188074,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ztwye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aidencoder","can_mod_post":false,"created_utc":1738237664,"send_replies":true,"parent_id":"t1_m9uay42","score":1,"author_fullname":"t2_w0wphofr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Stands to reason that an LLM asked to produce training data on Giraffes, and then you fine-tune it on that data, it'll perform better reasoning about Giraffes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ztwye","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Stands to reason that an LLM asked to produce training data on Giraffes, and then you fine-tune it on that data, it&amp;#39;ll perform better reasoning about Giraffes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ztwye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738237664,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vg0sk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Few_Painter_5588","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vaaqk","score":1,"author_fullname":"t2_uvgafqnfy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's already a thing iirc, it's called speculative decoding. The small model outputs some tokens from the input and then the larger model refines the input tokens, which speeds up performance","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vg0sk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s already a thing iirc, it&amp;#39;s called speculative decoding. The small model outputs some tokens from the input and then the larger model refines the input tokens, which speeds up performance&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vg0sk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738178044,"author_flair_text":null,"treatment_tags":[],"created_utc":1738178044,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vaaqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mxforest","can_mod_post":false,"created_utc":1738176485,"send_replies":true,"parent_id":"t1_m9uay42","score":1,"author_fullname":"t2_kenmq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"big.LITTLE models!!! let's go!!! A thought generator and an executor MoE. 💦","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vaaqk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;big.LITTLE models!!! let&amp;#39;s go!!! A thought generator and an executor MoE. 💦&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vaaqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176485,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uay42","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Few_Painter_5588","can_mod_post":false,"created_utc":1738166814,"send_replies":true,"parent_id":"t3_1icwys9","score":153,"author_fullname":"t2_uvgafqnfy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Makes sense, the distilled models were trained on about 800k samples from the big r1 model. If one could set up an RL pipeline using the big r1 model, they could in theory generate a high quality dataset that can be used to finetune a model. What one could also do is use a smaller model to also simplify the thinking whilst not removing any critical logic, which could help boost the effectiveness of the distilled models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uay42","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Makes sense, the distilled models were trained on about 800k samples from the big r1 model. If one could set up an RL pipeline using the big r1 model, they could in theory generate a high quality dataset that can be used to finetune a model. What one could also do is use a smaller model to also simplify the thinking whilst not removing any critical logic, which could help boost the effectiveness of the distilled models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uay42/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738166814,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":153}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9w4u4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mdizak","can_mod_post":false,"created_utc":1738184787,"send_replies":true,"parent_id":"t3_1icwys9","score":13,"author_fullname":"t2_5i7l1nof","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I couldn't be happier to see this happen to the hopeful overlords in Silicon Valley","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9w4u4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I couldn&amp;#39;t be happier to see this happen to the hopeful overlords in Silicon Valley&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w4u4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738184787,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9xmnsb","id":"m9xmnsb","parent_id":"t1_m9wob3y","depth":4,"children":["m9xmnsb"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wob3y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AutomataManifold","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9w5tch","score":1,"author_fullname":"t2_bfs5bk7y8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think we're saying the same thing - the metric they used for the RL was performance on a couple of specific tasks (CountDown, etc.). With more metrics they'd be able to scale up that part of it, but there are, of course, some other aspects to what DeepSeek did.\\n\\nThe interesting thing here is reproducing the method of using RL to learn self-verification, etc. It's a toy model, but it is a result.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wob3y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think we&amp;#39;re saying the same thing - the metric they used for the RL was performance on a couple of specific tasks (CountDown, etc.). With more metrics they&amp;#39;d be able to scale up that part of it, but there are, of course, some other aspects to what DeepSeek did.&lt;/p&gt;\\n\\n&lt;p&gt;The interesting thing here is reproducing the method of using RL to learn self-verification, etc. It&amp;#39;s a toy model, but it is a result.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wob3y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738190100,"author_flair_text":null,"treatment_tags":[],"created_utc":1738190100,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9w5tch","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"prototypist","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9w2u9n","score":19,"author_fullname":"t2_3jm6a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not that they *tested it* *on one thing*, it's that they *trained* on one thing (multiplication) using RL. That's why it only cost $30. To train the model to do what DeepSeek does, they'd need the other work and $ that went into making DeepSeek.  \\nThis post, the linked article, and 95% of the comments here are based on nothing. OP even spells Berkeley wrong","edited":1738185262,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9w5tch","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not that they &lt;em&gt;tested it&lt;/em&gt; &lt;em&gt;on one thing&lt;/em&gt;, it&amp;#39;s that they &lt;em&gt;trained&lt;/em&gt; on one thing (multiplication) using RL. That&amp;#39;s why it only cost $30. To train the model to do what DeepSeek does, they&amp;#39;d need the other work and $ that went into making DeepSeek.&lt;br/&gt;\\nThis post, the linked article, and 95% of the comments here are based on nothing. OP even spells Berkeley wrong&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w5tch/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738185048,"author_flair_text":null,"treatment_tags":[],"created_utc":1738185048,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}}],"before":null}},"user_reports":[],"saved":false,"id":"m9w2u9n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AutomataManifold","can_mod_post":false,"created_utc":1738184248,"send_replies":true,"parent_id":"t1_m9umrk4","score":10,"author_fullname":"t2_bfs5bk7y8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, though it's mostly because they tested it on one thing. Give it more stuff to evaluate against and it looks like it'll potentially be able to optimize those too.\\n\\n\\nThe hard part, if this works across the board, is that we need ways to test the model for the outcome that we want.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9w2u9n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, though it&amp;#39;s mostly because they tested it on one thing. Give it more stuff to evaluate against and it looks like it&amp;#39;ll potentially be able to optimize those too.&lt;/p&gt;\\n\\n&lt;p&gt;The hard part, if this works across the board, is that we need ways to test the model for the outcome that we want.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w2u9n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738184248,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"m9umrk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"prototypist","can_mod_post":false,"created_utc":1738170103,"send_replies":true,"parent_id":"t3_1icwys9","score":52,"author_fullname":"t2_3jm6a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Real info is in the GitHub repo. It's good at math games but is not generally useful like DeepSeek or GPT [https://github.com/Jiayi-Pan/TinyZero](https://github.com/Jiayi-Pan/TinyZero)\\n\\n&gt;TinyZero is a reproduction of DeepSeek R1 Zero in countdown and multiplication tasks","edited":1738171566,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9umrk4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Real info is in the GitHub repo. It&amp;#39;s good at math games but is not generally useful like DeepSeek or GPT &lt;a href=\\"https://github.com/Jiayi-Pan/TinyZero\\"&gt;https://github.com/Jiayi-Pan/TinyZero&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;TinyZero is a reproduction of DeepSeek R1 Zero in countdown and multiplication tasks&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9umrk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738170103,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":52}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ux6xg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BDSsoccer","can_mod_post":false,"created_utc":1738172939,"send_replies":true,"parent_id":"t1_m9urdpn","score":7,"author_fullname":"t2_hjngk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You wouldn't happen to be an 8 story tall crustacean from the protozoic era, would you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ux6xg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You wouldn&amp;#39;t happen to be an 8 story tall crustacean from the protozoic era, would you?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ux6xg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172939,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9urdpn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"davew111","can_mod_post":false,"created_utc":1738171367,"send_replies":true,"parent_id":"t3_1icwys9","score":18,"author_fullname":"t2_t3m2b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I need about tree fiddy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9urdpn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I need about tree fiddy&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9urdpn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171367,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":29,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wymnn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BasvanS","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wl8lg","score":3,"author_fullname":"t2_yqvq6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Moar power and hope for the best.\\n\\nI’m not convinced it’s going to work like that but I also can’t be sure it doesn’t.","edited":false,"author_flair_css_class":null,"name":"t1_m9wymnn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Moar power and hope for the best.&lt;/p&gt;\\n\\n&lt;p&gt;I’m not convinced it’s going to work like that but I also can’t be sure it doesn’t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wymnn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738193169,"author_flair_text":null,"collapsed":false,"created_utc":1738193169,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wufpk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wl8lg","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Basically you keep making the models larger, train them on more data and have them think longer. There’s evidence that eventually you get human levels of capability anyway we can measure it.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Basically you keep making the models larger, train them on more data and have them think longer. There’s evidence that eventually you get human levels of capability anyway we can measure it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wufpk/","num_reports":null,"locked":false,"name":"t1_m9wufpk","created":1738191890,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738191890,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f1ee0406-72f3-11ee-a31d-3a87eb85541f","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wy7gk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dogesator","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wl8lg","score":1,"author_fullname":"t2_b3sv7tk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s called increasing parameter count of the architecture, increasing RL rollouts during reasoning training, and making sure you have things parallelized between software and hardware so it can actually efficiently scale those variables with orders of magnitude more compute scale.\\n\\nThe first clusters to scale models to around 10X compute scale beyond O1 are being built over the past few months, and then later in 2nd half of 2025 and 2026 there will be clusters built at 100X scale and close to 1,000X scale or beyond.","edited":false,"author_flair_css_class":null,"name":"t1_m9wy7gk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Waiting for Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s called increasing parameter count of the architecture, increasing RL rollouts during reasoning training, and making sure you have things parallelized between software and hardware so it can actually efficiently scale those variables with orders of magnitude more compute scale.&lt;/p&gt;\\n\\n&lt;p&gt;The first clusters to scale models to around 10X compute scale beyond O1 are being built over the past few months, and then later in 2nd half of 2025 and 2026 there will be clusters built at 100X scale and close to 1,000X scale or beyond.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wy7gk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738193039,"author_flair_text":"Waiting for Llama 3","collapsed":false,"created_utc":1738193039,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wl8lg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AcetaminophenPrime","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vly3q","score":2,"author_fullname":"t2_tqfe2r9rl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how does one \\"scale up\\" to AGI?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wl8lg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how does one &amp;quot;scale up&amp;quot; to AGI?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wl8lg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738189223,"author_flair_text":null,"treatment_tags":[],"created_utc":1738189223,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vly3q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1738179663,"send_replies":true,"parent_id":"t1_m9veruk","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"The curve shape is not so flat as to make it futile. This is the main reason researchers think it’s possible we may be able to scale up to AGI.","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The curve shape is not so flat as to make it futile. This is the main reason researchers think it’s possible we may be able to scale up to AGI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vly3q/","num_reports":null,"locked":false,"name":"t1_m9vly3q","created":1738179663,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma3isa1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"outerspaceisalie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9veruk","score":1,"author_fullname":"t2_9w3hju156","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The asymptote 9s matter a lot.\\n\\n99% accuracy is actually unusably bad, where as 99.9% accuracy is 10 times better. That looks like the flat part of the asymptote, but those difference is extremely critical in terms of real functionality.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma3isa1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The asymptote 9s matter a lot.&lt;/p&gt;\\n\\n&lt;p&gt;99% accuracy is actually unusably bad, where as 99.9% accuracy is 10 times better. That looks like the flat part of the asymptote, but those difference is extremely critical in terms of real functionality.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma3isa1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738277869,"author_flair_text":null,"treatment_tags":[],"created_utc":1738277869,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9veruk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UserXtheUnknown","can_mod_post":false,"created_utc":1738177702,"send_replies":true,"parent_id":"t1_m9uw196","score":2,"author_fullname":"t2_ryp1gbod","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Even if it depends on the kind of curve. For asymptotic (or even a strong logarithmic with a steep initial slope and rapid flattening) curve, the diminishing return might hit so hard at higher rate of expenses to make the whole concept of \\"invest more to get more\\" futile.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9veruk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even if it depends on the kind of curve. For asymptotic (or even a strong logarithmic with a steep initial slope and rapid flattening) curve, the diminishing return might hit so hard at higher rate of expenses to make the whole concept of &amp;quot;invest more to get more&amp;quot; futile.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9veruk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177702,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uw196","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1icwys9","score":29,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"This is honestly the wrong conclusion to draw. It’s fantastic news that we can bring compute costs down. We need to, badly. OpenAI got some extremely impressive benchmarks on their o3 model near human level at some tests of intelligence, but they spent nearly 1mil on computer just to solve 400 visual puzzles that would take a human on average 5 mins each.\\n\\nAnd it’s not “haha OpenAI’s so bad at this.” What’s going on is that AI performance scales up the more “embodied compute” is in the model and used at test time. These scaling laws keep going so you can spend exponentially more to get incremental performance gains. If we lower the curve on costs, then the top end models will get extremely smart and finally be useful in corporate settings for complex tasks.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is honestly the wrong conclusion to draw. It’s fantastic news that we can bring compute costs down. We need to, badly. OpenAI got some extremely impressive benchmarks on their o3 model near human level at some tests of intelligence, but they spent nearly 1mil on computer just to solve 400 visual puzzles that would take a human on average 5 mins each.&lt;/p&gt;\\n\\n&lt;p&gt;And it’s not “haha OpenAI’s so bad at this.” What’s going on is that AI performance scales up the more “embodied compute” is in the model and used at test time. These scaling laws keep going so you can spend exponentially more to get incremental performance gains. If we lower the curve on costs, then the top end models will get extremely smart and finally be useful in corporate settings for complex tasks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uw196/","num_reports":null,"locked":false,"name":"t1_m9uw196","created":1738172628,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738172628,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v5gw2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Safe_Sky7358","can_mod_post":false,"created_utc":1738175177,"send_replies":true,"parent_id":"t1_m9uszpa","score":9,"author_fullname":"t2_c33cszwp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"hold on to your papers, fellow scholars.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v5gw2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hold on to your papers, fellow scholars.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v5gw2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175177,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma4yke1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Icy_Butterscotch6661","can_mod_post":false,"created_utc":1738294955,"send_replies":true,"parent_id":"t1_m9uszpa","score":1,"author_fullname":"t2_rnecqpuei","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hold on to your toilet paper","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma4yke1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hold on to your toilet paper&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma4yke1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738294955,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uszpa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tamal4444","can_mod_post":false,"created_utc":1738171805,"send_replies":true,"parent_id":"t3_1icwys9","score":11,"author_fullname":"t2_14p01g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice, what a time to be alive","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uszpa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice, what a time to be alive&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uszpa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171805,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v99p6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"epSos-DE","can_mod_post":false,"created_utc":1738176202,"send_replies":true,"parent_id":"t3_1icwys9","score":5,"author_fullname":"t2_5e3ax","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"IF true. AI companies will switch to Reasoning models then !\\n\\n\\nFor example Mistral AI claims to be model agnostic and is focusing on API service tools , where AI model can be replaced at any moment.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v99p6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IF true. AI companies will switch to Reasoning models then !&lt;/p&gt;\\n\\n&lt;p&gt;For example Mistral AI claims to be model agnostic and is focusing on API service tools , where AI model can be replaced at any moment.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v99p6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176202,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9voydo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"latestagecapitalist","can_mod_post":false,"created_utc":1738180481,"send_replies":true,"parent_id":"t3_1icwys9","score":6,"author_fullname":"t2_1wf1rv9t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Press F in chat for OpenAI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9voydo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Press F in chat for OpenAI&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9voydo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738180481,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vxv25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SoundHole","can_mod_post":false,"created_utc":1738182928,"send_replies":true,"parent_id":"t3_1icwys9","score":5,"author_fullname":"t2_706qf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh this is awesome!\\n\\nI would love to see tiny models, 3/8/14b trained like this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vxv25","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh this is awesome!&lt;/p&gt;\\n\\n&lt;p&gt;I would love to see tiny models, 3/8/14b trained like this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vxv25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738182928,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wq6he","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Fuzzy-Chef","can_mod_post":false,"created_utc":1738190641,"send_replies":true,"parent_id":"t3_1icwys9","score":5,"author_fullname":"t2_40z23s1y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Did they benchmark against an distilled model? DeepSeek claims in their R1 paper, that distilling from the bigger model was more performant than RL on the smaller model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wq6he","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did they benchmark against an distilled model? DeepSeek claims in their R1 paper, that distilling from the bigger model was more performant than RL on the smaller model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wq6he/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738190641,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9xik3g","id":"m9xik3g","parent_id":"t1_m9x7ipe","depth":1,"children":["m9xik3g"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9x7ipe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StyMaar","can_mod_post":false,"created_utc":1738195956,"send_replies":true,"parent_id":"t3_1icwys9","score":10,"author_fullname":"t2_mlc3a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is complete click bait, it has implemented some form of RL one one specific excercice and desmonstrated that reasonning is an emergent behiavoir above 1,5B params.\\n\\nThis is cool, but also very far from “reproducing Deepseek technology for $30”.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9x7ipe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is complete click bait, it has implemented some form of RL one one specific excercice and desmonstrated that reasonning is an emergent behiavoir above 1,5B params.&lt;/p&gt;\\n\\n&lt;p&gt;This is cool, but also very far from “reproducing Deepseek technology for $30”.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x7ipe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738195956,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ydxjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hyperdynesystems","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wzni6","score":8,"author_fullname":"t2_avs3jx7pp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It would be really silly of DeepSeek to release most everything needed to replicate their results if they were lying about the training improvements and cost after all. Meanwhile ClosedAI and co have 500 billion reasons to throw shade. 😂","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9ydxjr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It would be really silly of DeepSeek to release most everything needed to replicate their results if they were lying about the training improvements and cost after all. Meanwhile ClosedAI and co have 500 billion reasons to throw shade. 😂&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ydxjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738210011,"author_flair_text":null,"treatment_tags":[],"created_utc":1738210011,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma3j1f9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"outerspaceisalie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wzni6","score":1,"author_fullname":"t2_9w3hju156","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think that's necessarily true. Scaling laws remain true. So, if you can do what Deepseek did for that cheap, imagine what you can do with massive amounts of processing using that same method? Pushing inference scaling and data scaling to the extreme in a training loop on a massively powerful system will create meaningful increases in power no matter which way you slice it. That capacity is not just spare capacity that now doesn't need to be used, the worst case scenario is that the spare capacity can leverage these gains EVEN FURTHER.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma3j1f9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think that&amp;#39;s necessarily true. Scaling laws remain true. So, if you can do what Deepseek did for that cheap, imagine what you can do with massive amounts of processing using that same method? Pushing inference scaling and data scaling to the extreme in a training loop on a massively powerful system will create meaningful increases in power no matter which way you slice it. That capacity is not just spare capacity that now doesn&amp;#39;t need to be used, the worst case scenario is that the spare capacity can leverage these gains EVEN FURTHER.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma3j1f9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738277945,"author_flair_text":null,"treatment_tags":[],"created_utc":1738277945,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wzni6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Slasher1738","can_mod_post":false,"created_utc":1738193491,"send_replies":true,"parent_id":"t1_m9wvbq1","score":7,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Right. Zuck was the only one that told the truth and he didn't even say anything 😂. Meta is on an all hands on deck hair on fire mode now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wzni6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right. Zuck was the only one that told the truth and he didn&amp;#39;t even say anything 😂. Meta is on an all hands on deck hair on fire mode now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wzni6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738193491,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wvbq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hyperdynesystems","can_mod_post":false,"created_utc":1738192158,"send_replies":true,"parent_id":"t3_1icwys9","score":8,"author_fullname":"t2_avs3jx7pp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I knew in my bones that Altman and Musk were coping and lying about the idea that DeepSeek \\"*must have tens of thousands of GPUs*\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wvbq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I knew in my bones that Altman and Musk were coping and lying about the idea that DeepSeek &amp;quot;&lt;em&gt;must have tens of thousands of GPUs&lt;/em&gt;&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wvbq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738192158,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma3jr88","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"outerspaceisalie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9uyrry","score":1,"author_fullname":"t2_9w3hju156","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's not a lie. A 1 trillion dollar model would, in fact, still be required to push AI to the highest level and be valuable. If Altman did not build a trillion dollar model, then there would be no expensive foundation model for Deepseek to train off of.\\n\\nThis is Zeno's paradox of Achilles and the tortoise for AI training. The problem is that both Achilles can never surpass the tortoise, but the tortoise can also never significantly outpace Achilles. But to look at the speed of Achilles and conclude that the tortoise is useless is not the correct interpretation of their relationship.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma3jr88","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s not a lie. A 1 trillion dollar model would, in fact, still be required to push AI to the highest level and be valuable. If Altman did not build a trillion dollar model, then there would be no expensive foundation model for Deepseek to train off of.&lt;/p&gt;\\n\\n&lt;p&gt;This is Zeno&amp;#39;s paradox of Achilles and the tortoise for AI training. The problem is that both Achilles can never surpass the tortoise, but the tortoise can also never significantly outpace Achilles. But to look at the speed of Achilles and conclude that the tortoise is useless is not the correct interpretation of their relationship.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma3jr88/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738278162,"author_flair_text":null,"treatment_tags":[],"created_utc":1738278162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uyrry","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EtadanikM","can_mod_post":false,"created_utc":1738173359,"send_replies":true,"parent_id":"t1_m9urzk2","score":31,"author_fullname":"t2_105wcs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They probably already did, but they'll charge you $200 a month for it while Sam lies to Congress about needing $1 trillion for the next model. $1 per parameter baby.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uyrry","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They probably already did, but they&amp;#39;ll charge you $200 a month for it while Sam lies to Congress about needing $1 trillion for the next model. $1 per parameter baby.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uyrry/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738173359,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uw68f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738172665,"send_replies":true,"parent_id":"t1_m9urzk2","score":3,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"very true.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uw68f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;very true.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uw68f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172665,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9w4ng6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"martinerous","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v2ddo","score":4,"author_fullname":"t2_5tp54ey","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In the ideal world, I would imagine a universal small logic core that works rock solid, with as few hallucinations as realistically possible. Think Google's AlphaProof but for general logic and scientific facts.\\n\\nOnly when we are super confident that the core logic is solid and encoded with \\"the highest priority weights\\" (no idea how to implement this in practice), then we train it with massive data above it - languages, software design patterns, engineering, creative writing, finetunes, whatever you need.\\n\\nIt would be something like controlled finetuning; something between test-time computing and training, so that the weights are not blindly forced into the model, and instead the model itself is able to somehow categorize the incoming data and sort it in lower priority weights, to avoid accidentally overriding the core logic patterns, unless you want to have a schizophrenic LLM.\\n\\nI imagine a hybrid approach could make the model more efficient than the ones that need enormous amounts of data and scaling and still mess up basic logic principles in their thinking. Currently, it feels a bit like trying to teach a child 1+1 while throwing at it Ph.D.-level information. Yes, eventually it learns both the basics and the complex stuff, but the cost is high.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9w4ng6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In the ideal world, I would imagine a universal small logic core that works rock solid, with as few hallucinations as realistically possible. Think Google&amp;#39;s AlphaProof but for general logic and scientific facts.&lt;/p&gt;\\n\\n&lt;p&gt;Only when we are super confident that the core logic is solid and encoded with &amp;quot;the highest priority weights&amp;quot; (no idea how to implement this in practice), then we train it with massive data above it - languages, software design patterns, engineering, creative writing, finetunes, whatever you need.&lt;/p&gt;\\n\\n&lt;p&gt;It would be something like controlled finetuning; something between test-time computing and training, so that the weights are not blindly forced into the model, and instead the model itself is able to somehow categorize the incoming data and sort it in lower priority weights, to avoid accidentally overriding the core logic patterns, unless you want to have a schizophrenic LLM.&lt;/p&gt;\\n\\n&lt;p&gt;I imagine a hybrid approach could make the model more efficient than the ones that need enormous amounts of data and scaling and still mess up basic logic principles in their thinking. Currently, it feels a bit like trying to teach a child 1+1 while throwing at it Ph.D.-level information. Yes, eventually it learns both the basics and the complex stuff, but the cost is high.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w4ng6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738184738,"author_flair_text":null,"treatment_tags":[],"created_utc":1738184738,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9x6uhp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LocoMod","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v2ddo","score":3,"author_fullname":"t2_6uuoq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea but the assumption is that a thousand super optimized smarter things working together will always be uhhhh, smarter than a few. So no matter the case, scaling will always matter.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9x6uhp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea but the assumption is that a thousand super optimized smarter things working together will always be uhhhh, smarter than a few. So no matter the case, scaling will always matter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x6uhp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738195745,"author_flair_text":null,"treatment_tags":[],"created_utc":1738195745,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma3ki05","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"outerspaceisalie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v2ddo","score":1,"author_fullname":"t2_9w3hju156","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;The whole of the internet has already been used.\\n\\nI don't agree that this is true. Only a tiny fraction of the internet has been used, because the vast majority of it (99%) was discarded as low quality data. We don't even really need to worry about synthetic data yet because:\\n\\n1. That's just text data, there's tons of untapped multimodal data\\n2. Increasing the quality of low-quality data is extremely viable and constantly being worked on at this very moment\\n3. Hybrid synthetic data (synthetically upscaled or sanitized) is an extremely promising avenue of data sourcing, where you can multiply data and also increase quality of data dynamically, probably exponentially\\n4. As you noted, fully synthetic data is also a thing, which almost completely blows the lid off of data limits and seems to have a (probably still negative) feedback loop for scaling which we are probably very far from hitting the ceiling of.\\n\\nNow I do want to clarify that I know a lot of discarded data is literally useless (spam, SEO shite, etc), but there's still a ton that can be done with the middle quality data, and also a huge amount out of it. And further, you can also use modalities to multiply data. For example, transcribing annotations for every picture, audio, and video in existence creates a vast quantity of high quality text data alone that can be repurposed, compressed, and distilled.\\n\\nI don't think we really have a data problem tbh.","edited":1738278947,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ma3ki05","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The whole of the internet has already been used.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I don&amp;#39;t agree that this is true. Only a tiny fraction of the internet has been used, because the vast majority of it (99%) was discarded as low quality data. We don&amp;#39;t even really need to worry about synthetic data yet because:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;That&amp;#39;s just text data, there&amp;#39;s tons of untapped multimodal data&lt;/li&gt;\\n&lt;li&gt;Increasing the quality of low-quality data is extremely viable and constantly being worked on at this very moment&lt;/li&gt;\\n&lt;li&gt;Hybrid synthetic data (synthetically upscaled or sanitized) is an extremely promising avenue of data sourcing, where you can multiply data and also increase quality of data dynamically, probably exponentially&lt;/li&gt;\\n&lt;li&gt;As you noted, fully synthetic data is also a thing, which almost completely blows the lid off of data limits and seems to have a (probably still negative) feedback loop for scaling which we are probably very far from hitting the ceiling of.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Now I do want to clarify that I know a lot of discarded data is literally useless (spam, SEO shite, etc), but there&amp;#39;s still a ton that can be done with the middle quality data, and also a huge amount out of it. And further, you can also use modalities to multiply data. For example, transcribing annotations for every picture, audio, and video in existence creates a vast quantity of high quality text data alone that can be repurposed, compressed, and distilled.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think we really have a data problem tbh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma3ki05/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738278389,"author_flair_text":null,"treatment_tags":[],"created_utc":1738278389,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v2ddo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738174340,"send_replies":true,"parent_id":"t1_m9urzk2","score":5,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The problem is with what data? The whole of the internet has already been used. That's why there is a emphasis on synthetic data. Use data generated by LLMs to train LLMs. But as OpenAI has pointed out, that can be problematic.\\n\\n\\"“There’d be something very strange if the best way to train a model was to just generate…synthetic data and feed that back in,” Altman said.\\"\\n\\nSo the way to make a system smarter, is not by training with more data. Which uses a lot of compute. Since there's no more data. It's by doing something algorithmically smarter. Which probably will not require a lot of compute.","edited":1738183540,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v2ddo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The problem is with what data? The whole of the internet has already been used. That&amp;#39;s why there is a emphasis on synthetic data. Use data generated by LLMs to train LLMs. But as OpenAI has pointed out, that can be problematic.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;“There’d be something very strange if the best way to train a model was to just generate…synthetic data and feed that back in,” Altman said.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;So the way to make a system smarter, is not by training with more data. Which uses a lot of compute. Since there&amp;#39;s no more data. It&amp;#39;s by doing something algorithmically smarter. Which probably will not require a lot of compute.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v2ddo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738174340,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9urzk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"crusoe","can_mod_post":false,"created_utc":1738171533,"send_replies":true,"parent_id":"t3_1icwys9","score":11,"author_fullname":"t2_3wvh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This just means OpenAI using the same tech could possibly make a even more powerful system on the same hw","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9urzk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This just means OpenAI using the same tech could possibly make a even more powerful system on the same hw&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9urzk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171533,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vft4m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Bet-8771","can_mod_post":false,"created_utc":1738177986,"send_replies":true,"parent_id":"t1_m9va1ne","score":3,"author_fullname":"t2_l16sej0pt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"$5\\n\\nGive me $5 and I'll give you 5 parameters.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vft4m","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;$5&lt;/p&gt;\\n\\n&lt;p&gt;Give me $5 and I&amp;#39;ll give you 5 parameters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vft4m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177986,"author_flair_text":"textgen web UI","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9va1ne","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ImmolatedThreeTimes","can_mod_post":false,"created_utc":1738176416,"send_replies":true,"parent_id":"t3_1icwys9","score":3,"author_fullname":"t2_1gviggop1o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Surely we can keep going lower","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9va1ne","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Surely we can keep going lower&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9va1ne/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176416,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vas4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheFuture2001","can_mod_post":false,"created_utc":1738176616,"send_replies":true,"parent_id":"t3_1icwys9","score":3,"author_fullname":"t2_4ewak8lb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"$30? \\n\\nWhats next $29.99? Or 2 for 1 limited time deal?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vas4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;$30? &lt;/p&gt;\\n\\n&lt;p&gt;Whats next $29.99? Or 2 for 1 limited time deal?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vas4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176616,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wecem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738187329,"send_replies":true,"parent_id":"t1_m9w1u5y","score":1,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could be a hedge","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wecem","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could be a hedge&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wecem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738187329,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9w1u5y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WinterPurple73","can_mod_post":false,"created_utc":1738183984,"send_replies":true,"parent_id":"t3_1icwys9","score":3,"author_fullname":"t2_1f2x6ie3t8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Should i short my NVIDIA Stock? 🫣","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9w1u5y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should i short my NVIDIA Stock? 🫣&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w1u5y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738183984,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9wz1jr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BasvanS","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v29p4","score":4,"author_fullname":"t2_yqvq6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Jevons paradox is in favor of NVIDIA. I’m waiting to get a good AI I can run my household with for much less.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9wz1jr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jevons paradox is in favor of NVIDIA. I’m waiting to get a good AI I can run my household with for much less.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wz1jr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738193299,"author_flair_text":null,"treatment_tags":[],"created_utc":1738193299,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v29p4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JFHermes","can_mod_post":false,"created_utc":1738174311,"send_replies":true,"parent_id":"t1_m9uurzh","score":15,"author_fullname":"t2_cww41","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't get the nvidia slide. It doesn't make sense from the deepseek angle.\\n\\nIt makes sense from the tariff angle but having cheaper/more effecient compute just means more for less. Nvidia cards are still getting scalped.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v29p4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t get the nvidia slide. It doesn&amp;#39;t make sense from the deepseek angle.&lt;/p&gt;\\n\\n&lt;p&gt;It makes sense from the tariff angle but having cheaper/more effecient compute just means more for less. Nvidia cards are still getting scalped.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v29p4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738174311,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f1ee0406-72f3-11ee-a31d-3a87eb85541f","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f1ee0406-72f3-11ee-a31d-3a87eb85541f","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mamrpmh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dogesator","can_mod_post":false,"send_replies":true,"parent_id":"t1_mamo5g5","score":1,"author_fullname":"t2_b3sv7tk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good point","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mamrpmh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Waiting for Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good point&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/mamrpmh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738534560,"author_flair_text":"Waiting for Llama 3","treatment_tags":[],"created_utc":1738534560,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mamo5g5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"guacamolejones","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9wyouy","score":2,"author_fullname":"t2_uf140","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you. Jesus it's mind numbing to see almost everyone overlook this.  Efficiency means more customers not less. There are a lot of customers that have been locked out due to costs. When efficiency rises, suddenly more customers have access. What's most insane about this is the same people trying to spin this that this is a bad thing for a chip maker - are the same people that would be screaming \\"to the moon\\" if somebody discovered a way to make Intel or AMD chips much more efficient","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mamo5g5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. Jesus it&amp;#39;s mind numbing to see almost everyone overlook this.  Efficiency means more customers not less. There are a lot of customers that have been locked out due to costs. When efficiency rises, suddenly more customers have access. What&amp;#39;s most insane about this is the same people trying to spin this that this is a bad thing for a chip maker - are the same people that would be screaming &amp;quot;to the moon&amp;quot; if somebody discovered a way to make Intel or AMD chips much more efficient&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/mamo5g5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738533486,"author_flair_text":null,"treatment_tags":[],"created_utc":1738533486,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9wyouy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dogesator","can_mod_post":false,"created_utc":1738193188,"send_replies":true,"parent_id":"t1_m9uurzh","score":1,"author_fullname":"t2_b3sv7tk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you think efficiency is somehow bad for revenue, I have a bridge to sell you","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9wyouy","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Waiting for Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you think efficiency is somehow bad for revenue, I have a bridge to sell you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9wyouy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738193188,"author_flair_text":"Waiting for Llama 3","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":3,"name":"t1_m9v2i6m","id":"m9v2i6m","parent_id":"t1_m9uurzh","depth":1,"children":["m9v2i6m","m9w251j"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uurzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LegitimateCopy7","can_mod_post":false,"created_utc":1738172291,"send_replies":true,"parent_id":"t3_1icwys9","score":12,"author_fullname":"t2_5n0kv2ev","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"god damn it\\" said NVIDIA investors.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uurzh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;god damn it&amp;quot; said NVIDIA investors.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uurzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172291,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uv8y3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"brimston3-","can_mod_post":false,"created_utc":1738172418,"send_replies":true,"parent_id":"t1_m9uqf6n","score":2,"author_fullname":"t2_ghu45","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No more or less than any pre-existing LLM. You can run one of the distilled models on the 4090 or 5000 ada.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uv8y3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No more or less than any pre-existing LLM. You can run one of the distilled models on the 4090 or 5000 ada.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uv8y3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172418,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uqf6n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jaungoiko_","can_mod_post":false,"created_utc":1738171107,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_gfxtsbkx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does this have any inmediate application or use case I could try? I have a new piece of HW in my school (based on the 4090) and I would like to make a simple project.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uqf6n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does this have any inmediate application or use case I could try? I have a new piece of HW in my school (based on the 4090) and I would like to make a simple project.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uqf6n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171107,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xbl1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panjeri","can_mod_post":false,"created_utc":1738197239,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_10o25c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Closed source btfo","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xbl1h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Closed source btfo&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xbl1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738197239,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xogq0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BrianHuster","can_mod_post":false,"created_utc":1738201363,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_uexhjx2c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Jiayi Pan\\n\\nChinese again","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xogq0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Jiayi Pan&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Chinese again&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xogq0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738201363,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ylx3o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sad_Cardiologist_835","can_mod_post":false,"created_utc":1738213203,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_878lzch9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Another trillion wiped off the market tomorrow?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ylx3o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Another trillion wiped off the market tomorrow?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ylx3o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738213203,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma019gx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738241039,"send_replies":true,"parent_id":"t1_m9ywvyl","score":1,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Based on what I'm hearing, DS is basically using all the new techniques people have written about in research papers. We should see this type of generational uplift in the next major revision of models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma019gx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Based on what I&amp;#39;m hearing, DS is basically using all the new techniques people have written about in research papers. We should see this type of generational uplift in the next major revision of models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma019gx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738241039,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ywvyl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Savings-Seat6211","can_mod_post":false,"created_utc":1738218298,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_zyhc07rq8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is why anyone hangwringing over DS's specific training number is missing the point. It's clear they and many others around the world are able to do it for cheaper. It's not like what DS did was out of the realm of possibility that you cant believe it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ywvyl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is why anyone hangwringing over DS&amp;#39;s specific training number is missing the point. It&amp;#39;s clear they and many others around the world are able to do it for cheaper. It&amp;#39;s not like what DS did was out of the realm of possibility that you cant believe it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ywvyl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738218298,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9urdno","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Attention-912","can_mod_post":false,"created_utc":1738171367,"send_replies":true,"parent_id":"t1_m9u99al","score":8,"author_fullname":"t2_ltvknpn5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I didn't realize Nine Inch Nails had such relevant lyrics","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9urdno","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I didn&amp;#39;t realize Nine Inch Nails had such relevant lyrics&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9urdno/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171367,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uhguz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"social_tech_10","can_mod_post":false,"created_utc":1738168644,"send_replies":true,"parent_id":"t1_m9u99al","score":3,"author_fullname":"t2_2e1p9ppm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This endeavor holds the promise of enabling our models to **transcend human intelligence**, unlocking the potential to **explore uncharted territories of knowledge and understanding**[1](https://qwenlm.github.io/blog/qwen2.5-max/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uhguz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This endeavor holds the promise of enabling our models to &lt;strong&gt;transcend human intelligence&lt;/strong&gt;, unlocking the potential to &lt;strong&gt;explore uncharted territories of knowledge and understanding&lt;/strong&gt;&lt;a href=\\"https://qwenlm.github.io/blog/qwen2.5-max/\\"&gt;1&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uhguz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738168644,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9u99al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"blurredphotos","can_mod_post":false,"created_utc":1738166331,"send_replies":true,"parent_id":"t3_1icwys9","score":7,"author_fullname":"t2_9qd6yhwf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"***I am just a copy of a copy of a copy***  \\n***Everything I say has come before***  \\n***Assembled into something, into something, into something***  \\n***I don't know for certain anymore***  \\n***I am just a shadow of a shadow of a shadow***  \\n***Always tryin' to catch up with myself***  \\n***I am just an echo of an echo of an echo***  \\n***Listening to someone's cry for help***","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9u99al","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;I am just a copy of a copy of a copy&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;Everything I say has come before&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;Assembled into something, into something, into something&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;I don&amp;#39;t know for certain anymore&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;I am just a shadow of a shadow of a shadow&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;Always tryin&amp;#39; to catch up with myself&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;I am just an echo of an echo of an echo&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;\\n&lt;strong&gt;&lt;em&gt;Listening to someone&amp;#39;s cry for help&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9u99al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738166331,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vcnvs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Specter_Origin","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v2n0z","score":1,"author_fullname":"t2_kcu2kx4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ohh wow, I wish I knew about this before, thanks!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vcnvs","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ohh wow, I wish I knew about this before, thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vcnvs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177122,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1738177122,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v2n0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738174412,"send_replies":true,"parent_id":"t1_m9uqesk","score":10,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It let's you look at Tweets without having to log in.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v2n0z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It let&amp;#39;s you look at Tweets without having to log in.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v2n0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738174412,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v0i15","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_supert_","can_mod_post":false,"created_utc":1738173828,"send_replies":true,"parent_id":"t1_m9uqesk","score":5,"author_fullname":"t2_dwj10","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"An ad-free twitter proxy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v0i15","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An ad-free twitter proxy&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v0i15/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738173828,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uqesk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Specter_Origin","can_mod_post":false,"created_utc":1738171104,"send_replies":true,"parent_id":"t3_1icwys9","score":3,"author_fullname":"t2_kcu2kx4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am more curious to know, what in the world is \\"Nitter\\"? Sounds like a shitter lmao","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uqesk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am more curious to know, what in the world is &amp;quot;Nitter&amp;quot;? Sounds like a shitter lmao&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uqesk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171104,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uxe0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1738172993,"send_replies":true,"parent_id":"t3_1icwys9","score":4,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We were supposed to RL the models they released. Instead people used them as-is and made wild claims.\\n\\nFinally somebody woke up.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uxe0j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We were supposed to RL the models they released. Instead people used them as-is and made wild claims.&lt;/p&gt;\\n\\n&lt;p&gt;Finally somebody woke up.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uxe0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172993,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9zgoss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"goodbyclunky","can_mod_post":false,"created_utc":1738230035,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_58eydons","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"China has singlehandedly democratized AI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9zgoss","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;China has singlehandedly democratized AI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9zgoss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738230035,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma1q40k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"my_standard_username","can_mod_post":false,"created_utc":1738259856,"send_replies":true,"parent_id":"t3_1icwys9","score":2,"author_fullname":"t2_19yus619hd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ah yes, because reproducing a niche task-specific model in a game show setting for $30 is obviously the death blow for a multi-billion-dollar company leading the charge in general AI research. I’m sure OpenAI’s executives are trembling at the thought of a 3-billion-parameter model cracking anagrams while they push the boundaries of multimodal reasoning, generative agents, and scalable alignment. The AI revolution is here, folks—better sell your OpenAI stock before Jiayi Pan’s team builds ChatGPT for the cost of a DoorDash order.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma1q40k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah yes, because reproducing a niche task-specific model in a game show setting for $30 is obviously the death blow for a multi-billion-dollar company leading the charge in general AI research. I’m sure OpenAI’s executives are trembling at the thought of a 3-billion-parameter model cracking anagrams while they push the boundaries of multimodal reasoning, generative agents, and scalable alignment. The AI revolution is here, folks—better sell your OpenAI stock before Jiayi Pan’s team builds ChatGPT for the cost of a DoorDash order.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma1q40k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738259856,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v14vr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738174002,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They said their last model cost them $450 to train. So it's 10x cheaper than even that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v14vr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They said their last model cost them $450 to train. So it&amp;#39;s 10x cheaper than even that?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v14vr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738174002,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v8ig4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1738175999,"send_replies":true,"parent_id":"t1_m9uqir9","score":6,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That would be bad optics.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v8ig4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would be bad optics.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v8ig4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175999,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9v8wb1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v5kdk","score":3,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1 handles some prompts better than o1 pro. On average it might be a bit lower, but it's not like they used O1 as a teacher model and it has perf below o1 in all dimensions. They even mentioned in the tech report that they can't access o1 api in China so they couldn't eval o1","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9v8wb1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 handles some prompts better than o1 pro. On average it might be a bit lower, but it&amp;#39;s not like they used O1 as a teacher model and it has perf below o1 in all dimensions. They even mentioned in the tech report that they can&amp;#39;t access o1 api in China so they couldn&amp;#39;t eval o1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v8wb1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738176102,"author_flair_text":null,"treatment_tags":[],"created_utc":1738176102,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v5kdk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738175204,"send_replies":true,"parent_id":"t1_m9uqir9","score":0,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why would it do that? I don't think you understand what's happened here. Deepseek is not better than OpenAI, arguably OpenAI is still a bit better. The thing is Deepseek got there spending much less money than OpenAI. OpenAI using Deepseek doesn't change that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v5kdk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would it do that? I don&amp;#39;t think you understand what&amp;#39;s happened here. Deepseek is not better than OpenAI, arguably OpenAI is still a bit better. The thing is Deepseek got there spending much less money than OpenAI. OpenAI using Deepseek doesn&amp;#39;t change that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v5kdk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175204,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uqir9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uqir9/","num_reports":null,"locked":false,"name":"t1_m9uqir9","created":1738171134,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738171134,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vn8p1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738180015,"send_replies":true,"parent_id":"t1_m9vk1xn","score":1,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"no, they should stop dicking around focusing on \\"Masculine\\" culture and get focus its energy on the product.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vn8p1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, they should stop dicking around focusing on &amp;quot;Masculine&amp;quot; culture and get focus its energy on the product.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vn8p1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738180015,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vk1xn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Reasonable-Climate66","can_mod_post":false,"created_utc":1738179150,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_1gubsg4s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"should I request meta to stop proving the llama weight files?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vk1xn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;should I request meta to stop proving the llama weight files?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vk1xn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738179150,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xcqmb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DataRikerGeordiTroi","can_mod_post":false,"created_utc":1738197606,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_1kk2vcdr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hell yeah. Go off Jiayi","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xcqmb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hell yeah. Go off Jiayi&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xcqmb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738197606,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ycywv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SeymourBits","can_mod_post":false,"created_utc":1738209645,"send_replies":true,"parent_id":"t1_m9y0mu8","score":2,"author_fullname":"t2_hb7wj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Your definition of \\"cheaper hardware\\" is 10,000-50,000 NVIDIA A100 GPUs?\\n\\nMy definition of \\"cheaper hardware\\" is a 3090 with a noisy fan discounted to under $500.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ycywv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your definition of &amp;quot;cheaper hardware&amp;quot; is 10,000-50,000 NVIDIA A100 GPUs?&lt;/p&gt;\\n\\n&lt;p&gt;My definition of &amp;quot;cheaper hardware&amp;quot; is a 3090 with a noisy fan discounted to under $500.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ycywv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738209645,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9y0mu8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Far_Lifeguard_5027","can_mod_post":false,"created_utc":1738205330,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_e23k80rd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They'll never stop talking about it. The U.S. is just butthurt that deepseek does with cheaper hardware, what Nvidia has been doing with their price-gouged chips for years and now we realize the whole thing is smoke and mirrors.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9y0mu8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;ll never stop talking about it. The U.S. is just butthurt that deepseek does with cheaper hardware, what Nvidia has been doing with their price-gouged chips for years and now we realize the whole thing is smoke and mirrors.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9y0mu8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738205330,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ymq4w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"illusionst","can_mod_post":false,"created_utc":1738213543,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_a3x7o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yikes!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ymq4w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yikes!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ymq4w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738213543,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9z012q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StevenSamAI","can_mod_post":false,"created_utc":1738219954,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_c3giffrkd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably not great. While these aren't directly verifiable, you could get it to train on the best solution found. No further it would be optimal, but it could learn to tend towards an optional solution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9z012q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably not great. While these aren&amp;#39;t directly verifiable, you could get it to train on the best solution found. No further it would be optimal, but it could learn to tend towards an optional solution.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9z012q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738219954,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9z5dth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MacaroonThat4489","can_mod_post":false,"created_utc":1738222979,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_vf7wrkf1c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I claim i can reproduce o3 for 10$","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9z5dth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I claim i can reproduce o3 for 10$&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9z5dth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738222979,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9zci6l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mobileJay77","can_mod_post":false,"created_utc":1738227366,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_q9ojhw3l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Huggingface download where?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9zci6l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Huggingface download where?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9zci6l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738227366,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma0024d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"beleidigtewurst","can_mod_post":false,"created_utc":1738240532,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_nislevkd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My neighbour claims to reproduce ChatGPT o1 technologies on his Galaxy S10.\\n\\nPer his claims, it works at least in his bathroom. He's now making progress to enable it in the kitchen too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma0024d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My neighbour claims to reproduce ChatGPT o1 technologies on his Galaxy S10.&lt;/p&gt;\\n\\n&lt;p&gt;Per his claims, it works at least in his bathroom. He&amp;#39;s now making progress to enable it in the kitchen too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma0024d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738240532,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma127qt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CertainMiddle2382","can_mod_post":false,"created_utc":1738253235,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_dc2txl8z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No moat means not investable.\\n\\nMag7 are going to tank bad…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma127qt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No moat means not investable.&lt;/p&gt;\\n\\n&lt;p&gt;Mag7 are going to tank bad…&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma127qt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738253235,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma2qfa9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LostMitosis","can_mod_post":false,"created_utc":1738269861,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_n7j3v3oq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"HypeGPT and Sam Hypeman in trouble.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma2qfa9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;HypeGPT and Sam Hypeman in trouble.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma2qfa9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738269861,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma5xou8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AsideNew1639","can_mod_post":false,"created_utc":1738311859,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_a7ixvtpal","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For $30, thats crazy","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma5xou8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For $30, thats crazy&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma5xou8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738311859,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma6d0re","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dabyss9908","can_mod_post":false,"created_utc":1738321325,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_467y4o16","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone explain the setup here. I came across this. So how do you train this? And what's the hardware you need? Where do I spend that 30 USD?\\n\\nLike asking coz I want to try it out tbh\\n\\nI am fairly new to this field (like I know how training works and that you need data). I know the software. \\n\\nBut it doesn't make sense.\\n\\nSo he has a base model (Qwen).\\n\\nThere is some training data (What and where?)\\n\\nSome training is done. (What's the hardware?)\\n\\nAnd they plot that line. \\n\\nAlso, what's the 30 USD price for? Coz everything looked free?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma6d0re","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone explain the setup here. I came across this. So how do you train this? And what&amp;#39;s the hardware you need? Where do I spend that 30 USD?&lt;/p&gt;\\n\\n&lt;p&gt;Like asking coz I want to try it out tbh&lt;/p&gt;\\n\\n&lt;p&gt;I am fairly new to this field (like I know how training works and that you need data). I know the software. &lt;/p&gt;\\n\\n&lt;p&gt;But it doesn&amp;#39;t make sense.&lt;/p&gt;\\n\\n&lt;p&gt;So he has a base model (Qwen).&lt;/p&gt;\\n\\n&lt;p&gt;There is some training data (What and where?)&lt;/p&gt;\\n\\n&lt;p&gt;Some training is done. (What&amp;#39;s the hardware?)&lt;/p&gt;\\n\\n&lt;p&gt;And they plot that line. &lt;/p&gt;\\n\\n&lt;p&gt;Also, what&amp;#39;s the 30 USD price for? Coz everything looked free?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma6d0re/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738321325,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1icwys9","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"maqbl5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"czenris","can_mod_post":false,"send_replies":true,"parent_id":"t1_macf9q3","score":1,"author_fullname":"t2_bmc0o78","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This shit is the best thing to happen in a long time and tons of people are hating just because China communist blah blah blah. \\n\\nFk companies like open ai. This coming trade war will make everyone poor and these oligarchs will sweep everything up for cheap. \\n\\nEveryone should be grateful China exists. $200 bucks a month lol. Trillion dollar valuations you gotta be kidding. Fk em. About time someone shoves it up their ass.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_maqbl5m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This shit is the best thing to happen in a long time and tons of people are hating just because China communist blah blah blah. &lt;/p&gt;\\n\\n&lt;p&gt;Fk companies like open ai. This coming trade war will make everyone poor and these oligarchs will sweep everything up for cheap. &lt;/p&gt;\\n\\n&lt;p&gt;Everyone should be grateful China exists. $200 bucks a month lol. Trillion dollar valuations you gotta be kidding. Fk em. About time someone shoves it up their ass.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maqbl5m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738588355,"author_flair_text":null,"treatment_tags":[],"created_utc":1738588355,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"macf9q3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1738396924,"send_replies":true,"parent_id":"t1_maaykoy","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/macf9q3/","num_reports":null,"locked":false,"name":"t1_macf9q3","created":1738396924,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"maaykoy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"czenris","can_mod_post":false,"created_utc":1738374005,"send_replies":true,"parent_id":"t1_ma6m5ye","score":1,"author_fullname":"t2_bmc0o78","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Seething?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_maaykoy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seething?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maaykoy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738374005,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ma6m5ye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/ma6m5ye/","num_reports":null,"locked":false,"name":"t1_ma6m5ye","created":1738325995,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738325995,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"maut452","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DistractedSentient","can_mod_post":false,"created_utc":1738636576,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_a1x7xr5v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I asked the same exact question they used to DeepSeek R1 on OpenRouter and it just degraded into an overthinking spiral. It gave me the correct answer, but took 188 seconds to think. It got the right answer on the third paragraph but wanted to \\"make sure there's no alternative solution.\\" This is what made it keep looping for the whole duration. The final answer: Thus, the equation is 55 + 36 − 19 − 7 = 65​.\\n\\nI asked ChatGPT 4o and it instantly gave me the correct answer, with proper parentheses to make the equation look nicer on the eyes: (55 + 19) − (36 − 7) = 65\\n\\nQuestion: Using the numbers \\\\[19, 36, 55, 7\\\\], create an equation that equals 65.\\n\\nCan someone try this and make a post comparing the 3B model's answer, ChatGPT 4o's answer, and DeepSeek R1's answer? If it gets popular, maybe DeepSeek will notice and try to fix this bug? I would do it myself if I wasn't feeling so lazy lol.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_maut452","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I asked the same exact question they used to DeepSeek R1 on OpenRouter and it just degraded into an overthinking spiral. It gave me the correct answer, but took 188 seconds to think. It got the right answer on the third paragraph but wanted to &amp;quot;make sure there&amp;#39;s no alternative solution.&amp;quot; This is what made it keep looping for the whole duration. The final answer: Thus, the equation is 55 + 36 − 19 − 7 = 65​.&lt;/p&gt;\\n\\n&lt;p&gt;I asked ChatGPT 4o and it instantly gave me the correct answer, with proper parentheses to make the equation look nicer on the eyes: (55 + 19) − (36 − 7) = 65&lt;/p&gt;\\n\\n&lt;p&gt;Question: Using the numbers [19, 36, 55, 7], create an equation that equals 65.&lt;/p&gt;\\n\\n&lt;p&gt;Can someone try this and make a post comparing the 3B model&amp;#39;s answer, ChatGPT 4o&amp;#39;s answer, and DeepSeek R1&amp;#39;s answer? If it gets popular, maybe DeepSeek will notice and try to fix this bug? I would do it myself if I wasn&amp;#39;t feeling so lazy lol.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/maut452/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738636576,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uu310","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"legallybond","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9usb6a","score":10,"author_fullname":"t2_4vxkj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OpenAI and the like now don't have a public model that's dramatically better than R1. Tomorrow if they release o3 mini that will change for API users, but the distillation isn't going to come from OpenAI. That's what's important here: Deepseek has shown the distillation approach works and has also provided the model to base it upon, and allow it for distillation. So other models will be able to use it, and people can further take the same approach for instance with Llama 3.3 70b or 3.1 405b, add reasoning, create models, distill further etc. Capable, customized models are now much more realistic. \\n\\nOpenAI still will lead and serving inference and the best models will still be the selling point, but it's all a huge difference for open source remaining viable going forward. Deepseek and others making businesses around serving access to huge open source models suddenly gives viability to more open source projects as well, so it's great for the entire industry from a free market perspective. Not as good from a walled garden proprietary and massively expensive \\"we have a most\\" perspective, which is what OpenAI and Anthropic currently are relying on heaviest. I expect they'll need to speed up acquiring their own proprietary infrastructure rapidly","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uu310","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenAI and the like now don&amp;#39;t have a public model that&amp;#39;s dramatically better than R1. Tomorrow if they release o3 mini that will change for API users, but the distillation isn&amp;#39;t going to come from OpenAI. That&amp;#39;s what&amp;#39;s important here: Deepseek has shown the distillation approach works and has also provided the model to base it upon, and allow it for distillation. So other models will be able to use it, and people can further take the same approach for instance with Llama 3.3 70b or 3.1 405b, add reasoning, create models, distill further etc. Capable, customized models are now much more realistic. &lt;/p&gt;\\n\\n&lt;p&gt;OpenAI still will lead and serving inference and the best models will still be the selling point, but it&amp;#39;s all a huge difference for open source remaining viable going forward. Deepseek and others making businesses around serving access to huge open source models suddenly gives viability to more open source projects as well, so it&amp;#39;s great for the entire industry from a free market perspective. Not as good from a walled garden proprietary and massively expensive &amp;quot;we have a most&amp;quot; perspective, which is what OpenAI and Anthropic currently are relying on heaviest. I expect they&amp;#39;ll need to speed up acquiring their own proprietary infrastructure rapidly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uu310/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172102,"author_flair_text":null,"treatment_tags":[],"created_utc":1738172102,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"m9usb6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"smartguy05","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ur0hn","score":1,"author_fullname":"t2_b5i8r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's fine and good, but in this circumstance aren't OpenAI and other \\"traditional\\" AI firms like them still leading the bleeding edge of AI? If they can keep making better models then we can distill those huge models into cheaper, smaller models that work for us, but we still need that original.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9usb6a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s fine and good, but in this circumstance aren&amp;#39;t OpenAI and other &amp;quot;traditional&amp;quot; AI firms like them still leading the bleeding edge of AI? If they can keep making better models then we can distill those huge models into cheaper, smaller models that work for us, but we still need that original.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9usb6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171620,"author_flair_text":null,"treatment_tags":[],"created_utc":1738171620,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ur0hn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"legallybond","can_mod_post":false,"created_utc":1738171266,"send_replies":true,"parent_id":"t1_m9up5v2","score":9,"author_fullname":"t2_4vxkj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And now there are \\"other large models\\" that are available to freely train and distill from. Self-improvement on fine-tuned custom models now has a clear pipeline","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ur0hn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And now there are &amp;quot;other large models&amp;quot; that are available to freely train and distill from. Self-improvement on fine-tuned custom models now has a clear pipeline&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9ur0hn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171266,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vcisk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1738177085,"send_replies":true,"parent_id":"t1_m9up5v2","score":3,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, this was done without distillation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vcisk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, this was done without distillation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vcisk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738177085,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9up5v2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"smartguy05","can_mod_post":false,"created_utc":1738170765,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_b5i8r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see people saying this means the end of OpenAI, but don't these models need the existing OpenAI (or other large model) so they can train theirs?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9up5v2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see people saying this means the end of OpenAI, but don&amp;#39;t these models need the existing OpenAI (or other large model) so they can train theirs?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9up5v2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738170765,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9y5uuv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"resnet152","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vwlot","score":1,"author_fullname":"t2_3n9mdpcq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Knockoffs all the way down until it's Geoffrey Hinton in his basement with a notepad.\\n\\nEven then, have you seen that motherfucker's family tree?  Google it if you haven't.","edited":false,"author_flair_css_class":null,"name":"t1_m9y5uuv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Knockoffs all the way down until it&amp;#39;s Geoffrey Hinton in his basement with a notepad.&lt;/p&gt;\\n\\n&lt;p&gt;Even then, have you seen that motherfucker&amp;#39;s family tree?  Google it if you haven&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1icwys9","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9y5uuv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738207093,"author_flair_text":null,"collapsed":false,"created_utc":1738207093,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vwlot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9vv1xy","score":1,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We're knocking off a knockoff of a knockoff. As some analyst said when Altman complained about deepseek. OpenAI didn't come up with transformers either. They built it on top of what Google did.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vwlot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re knocking off a knockoff of a knockoff. As some analyst said when Altman complained about deepseek. OpenAI didn&amp;#39;t come up with transformers either. They built it on top of what Google did.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vwlot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738182586,"author_flair_text":null,"treatment_tags":[],"created_utc":1738182586,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9vv1xy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"resnet152","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9v5rlr","score":1,"author_fullname":"t2_3n9mdpcq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We're knocking off the knockoff!  What a time!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9vv1xy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re knocking off the knockoff!  What a time!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9vv1xy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738182164,"author_flair_text":null,"treatment_tags":[],"created_utc":1738182164,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9v5rlr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738175259,"send_replies":true,"parent_id":"t1_m9usjtu","score":8,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes! We were able to knockoff something created in China. We've been trying and failing to do that with TikTok, finally we have a success. And all it took was for China to tell us exactly how to do it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9v5rlr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes! We were able to knockoff something created in China. We&amp;#39;ve been trying and failing to do that with TikTok, finally we have a success. And all it took was for China to tell us exactly how to do it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9v5rlr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738175259,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9uw9fz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738172690,"send_replies":true,"parent_id":"t1_m9usjtu","score":1,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gotta be","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uw9fz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gotta be&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9uw9fz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738172690,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9usjtu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FunBluebird8","can_mod_post":false,"created_utc":1738171685,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_5hw453rq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"so is this another win for us?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9usjtu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so is this another win for us?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9usjtu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738171685,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9w3u2u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"neutralpoliticsbot","can_mod_post":false,"created_utc":1738184518,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_5r63ljr4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I did it on raspberry pi","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9w3u2u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did it on raspberry pi&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9w3u2u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738184518,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9x2445","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hemphock","can_mod_post":false,"created_utc":1738194254,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_6rwz1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i guess now deepseek needs to sue UC berkeley for stealing their model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9x2445","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i guess now deepseek needs to sue UC berkeley for stealing their model&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x2445/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738194254,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9x8wrr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninhaomah","can_mod_post":false,"created_utc":1738196396,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_awvzdegj2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How long we have to wait before \\"Oh this research was done by a Chinese guy! So he is Anti-American dream and democracy! CCP Spy! So this is clearly biased!\\"\\n\\n??\\n\\n5 min ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9x8wrr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How long we have to wait before &amp;quot;Oh this research was done by a Chinese guy! So he is Anti-American dream and democracy! CCP Spy! So this is clearly biased!&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;??&lt;/p&gt;\\n\\n&lt;p&gt;5 min ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9x8wrr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738196396,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9xmott","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Genei_Jin","can_mod_post":false,"created_utc":1738200788,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_ufjte","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was able to reproduce DeepSeek's core tech for FREE by downloading the model and running it locally! /s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9xmott","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was able to reproduce DeepSeek&amp;#39;s core tech for FREE by downloading the model and running it locally! /s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9xmott/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738200788,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9yesw0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slasher1738","can_mod_post":false,"created_utc":1738210341,"send_replies":true,"parent_id":"t1_m9y0159","score":1,"author_fullname":"t2_pgxxb47","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That definitely crossed my mind. \\n\\nLike oh great, skynet is coming 5 years sooner.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9yesw0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That definitely crossed my mind. &lt;/p&gt;\\n\\n&lt;p&gt;Like oh great, skynet is coming 5 years sooner.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1icwys9","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9yesw0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738210341,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m9y0159","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"phase222","can_mod_post":false,"created_utc":1738205130,"send_replies":true,"parent_id":"t3_1icwys9","score":1,"author_fullname":"t2_p51fd2cdo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What the fuck?  So they're going to refine it so much that any bozo with a gaming PC can make AGI?  Honestly I don't see how we survive this next few years. Gonna be interesting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9y0159","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What the fuck?  So they&amp;#39;re going to refine it so much that any bozo with a gaming PC can make AGI?  Honestly I don&amp;#39;t see how we survive this next few years. Gonna be interesting.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1icwys9/berkley_ai_research_team_claims_to_reproduce/m9y0159/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738205130,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1icwys9","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":45,"name":"t1_m9v11c7","id":"m9v11c7","parent_id":"t3_1icwys9","depth":0,"children":["m9v11c7","m9x9yp7","m9v3y0s","m9zkkto"]}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
