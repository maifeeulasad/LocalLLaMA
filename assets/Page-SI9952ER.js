import{j as e}from"./index-BgwOAK4-.js";import{R as l}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I was working on a [research](https://www.designarena.ai/) project (note that the votes and data is completely free and open, so not profiting off this, but just showing research as context) where users write a prompt, and then vote on content generated (e.g. websites, games, 3D visualizations) from 4 randomly generated models each. Note that when [voting](https://www.designarena.ai/vote), model names are hidden, so people don't immediately know which models generated what. \\n\\nFrom the data collected so far, Llama 4 Maverick is 19th and Llama 4 Scout is 23rd. On the other extreme, Claude and Deepseek are taking up most of the spots in the top 10 while Mistral and Grok have been surprising dark horses. \\n\\nAnything surprise you here? What models have you noticed been the best for UI/UX and frontend development? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"is_gallery":true,"title":"8.5K people voted on which AI models create the best website, games, and visualizations. Both Llama Models came almost dead last. Claude comes up on top.","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":57,"top_awarded_type":null,"name":"t3_1lthtbn","media_metadata":{"4dvcg5t2vcbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":44,"x":108,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=194c2718bcea83cd83000270555d9c7146124fd9"},{"y":89,"x":216,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=842167269b6c29f1d38ee31b7646452f9c11ca4d"},{"y":131,"x":320,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f50e3c44b76f102fae7967436a8882f6ae1d85cf"},{"y":263,"x":640,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=27d34b01b0e5f02bb43cba8e41399df55825391b"},{"y":395,"x":960,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d79294115167b767b1cc31f2b9343848ca354c2f"},{"y":445,"x":1080,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=458cf1e010ac4847c708c30134c102db2713138f"}],"s":{"y":1128,"x":2736,"u":"https://preview.redd.it/4dvcg5t2vcbf1.png?width=2736&amp;format=png&amp;auto=webp&amp;s=a0c60a48447d75fb57f45e2bd2cc032539ec0090"},"id":"4dvcg5t2vcbf1"},"n0u7huiovcbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":62,"x":108,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b75bbe5b0686af8ed41a6a491dc9bc2d52d32184"},{"y":125,"x":216,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=73b3be1559e3ef7c3f4603ee2bf4dff475a19b55"},{"y":185,"x":320,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=40ae9695bc1269a2e04a386ce0025f37e3c887ee"},{"y":371,"x":640,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=12e3d5bce8a991befed7f1e9f4898963499ada4a"},{"y":556,"x":960,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e6825321e4af272d097398c834cb7de67676a80"},{"y":626,"x":1080,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eaf0268d4271c43fda1a54cd5bcdf1a0940a2b63"}],"s":{"y":1542,"x":2658,"u":"https://preview.redd.it/n0u7huiovcbf1.png?width=2658&amp;format=png&amp;auto=webp&amp;s=301b623986fdee81705deb44c59fa48553c3801f"},"id":"n0u7huiovcbf1"}},"hide_score":false,"quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.78,"author_flair_background_color":null,"ups":91,"domain":"reddit.com","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_c3b3edv5","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"gallery_data":{"items":[{"media_id":"4dvcg5t2vcbf1","id":700330534},{"media_id":"n0u7huiovcbf1","id":700330535}]},"link_flair_text":"Discussion","can_mod_post":false,"score":91,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/YH48KR3uSeLFmipFEDX0ai8FZ4TwQmmccEKSaaUx3Fk.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"subreddit_type":"public","created":1751852148,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I was working on a &lt;a href=\\"https://www.designarena.ai/\\"&gt;research&lt;/a&gt; project (note that the votes and data is completely free and open, so not profiting off this, but just showing research as context) where users write a prompt, and then vote on content generated (e.g. websites, games, 3D visualizations) from 4 randomly generated models each. Note that when &lt;a href=\\"https://www.designarena.ai/vote\\"&gt;voting&lt;/a&gt;, model names are hidden, so people don&amp;#39;t immediately know which models generated what. &lt;/p&gt;\\n\\n&lt;p&gt;From the data collected so far, Llama 4 Maverick is 19th and Llama 4 Scout is 23rd. On the other extreme, Claude and Deepseek are taking up most of the spots in the top 10 while Mistral and Grok have been surprising dark horses. &lt;/p&gt;\\n\\n&lt;p&gt;Anything surprise you here? What models have you noticed been the best for UI/UX and frontend development? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.reddit.com/gallery/1lthtbn","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lthtbn","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"adviceguru25","discussion_type":null,"num_comments":120,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/","stickied":false,"url":"https://www.reddit.com/gallery/1lthtbn","subreddit_subscribers":496034,"created_utc":1751852148,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vgnpo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1v6k1h","score":4,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I get mildly better results if I tell it that I'm going to consider using an open-weight model instead. That seems to instill a sense of panic and urgency","edited":false,"author_flair_css_class":null,"name":"t1_n1vgnpo","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I get mildly better results if I tell it that I&amp;#39;m going to consider using an open-weight model instead. That seems to instill a sense of panic and urgency&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1vgnpo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751922775,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1751922775,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1v6k1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"matjam","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1t2zj6","score":3,"author_fullname":"t2_3pk2i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried insulting it? I find a firm hand can get better results from Claude. I think it might be a little masochistic.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v6k1h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried insulting it? I find a firm hand can get better results from Claude. I think it might be a little masochistic.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1v6k1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751919383,"author_flair_text":null,"treatment_tags":[],"created_utc":1751919383,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1t2zj6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qusel","score":6,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can confirm.\\n\\nI think Sonnet 4.0 edges it out in raw coding, but there's been multiple times when R1-0528 solved things that Claude just couldn't for me.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1t2zj6","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can confirm.&lt;/p&gt;\\n\\n&lt;p&gt;I think Sonnet 4.0 edges it out in raw coding, but there&amp;#39;s been multiple times when R1-0528 solved things that Claude just couldn&amp;#39;t for me.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1t2zj6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751896347,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751896347,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qusel","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ylsid","can_mod_post":false,"created_utc":1751857316,"send_replies":true,"parent_id":"t1_n1qjhmy","score":40,"author_fullname":"t2_6lmlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1 is a real beast at spatial stuff. It's solved issues Claude hasn't for me there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qusel","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 is a real beast at spatial stuff. It&amp;#39;s solved issues Claude hasn&amp;#39;t for me there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qusel/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857316,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1quow7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qkpc9","score":8,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Grok 3 is awesome. Less censored, intelligent enough for most tasks (slightly below sonnet in my experience), and doesn't sound like corporate. Wish there were datasets to distill from it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1quow7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Grok 3 is awesome. Less censored, intelligent enough for most tasks (slightly below sonnet in my experience), and doesn&amp;#39;t sound like corporate. Wish there were datasets to distill from it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1quow7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857276,"author_flair_text":null,"treatment_tags":[],"created_utc":1751857276,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qkpc9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1751853410,"send_replies":true,"parent_id":"t1_n1qjhmy","score":17,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We're very surprised by Mistral as well!  We did recently add it a couple days ago so it'll be interesting to see if it keeps its positioning. \\n\\nI think Grok 3 was also a big surprise for us. It will also be fascinating to see how Grok 4 does (which we will be adding as soon as Elon and xAI releases it lol).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qkpc9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re very surprised by Mistral as well!  We did recently add it a couple days ago so it&amp;#39;ll be interesting to see if it keeps its positioning. &lt;/p&gt;\\n\\n&lt;p&gt;I think Grok 3 was also a big surprise for us. It will also be fascinating to see how Grok 4 does (which we will be adding as soon as Elon and xAI releases it lol).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qkpc9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853410,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rcfb5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dudensen","can_mod_post":false,"created_utc":1751865279,"send_replies":true,"parent_id":"t1_n1qjhmy","score":5,"author_fullname":"t2_6vcmk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's because Claude just generates faster. o3 takes 46 seconds to generate and is a reasoning model. Do you really think Claude can stay so close to R1 without reasoning?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rcfb5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s because Claude just generates faster. o3 takes 46 seconds to generate and is a reasoning model. Do you really think Claude can stay so close to R1 without reasoning?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rcfb5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751865279,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1soupq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Physical-Citron5153","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1r7twp","score":1,"author_fullname":"t2_clhgguip","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try Out GLM Models in that regard definitely not on par with claude, but they give really really good UI components, and they can spout out thousands of lines if you have enough resources","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1soupq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try Out GLM Models in that regard definitely not on par with claude, but they give really really good UI components, and they can spout out thousands of lines if you have enough resources&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1soupq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751891268,"author_flair_text":null,"treatment_tags":[],"created_utc":1751891268,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1r7twp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1751863027,"send_replies":true,"parent_id":"t1_n1qjhmy","score":5,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Claude is fucking OP.\\n\\nThe other day I was showing it to my dad who knows nothing abt tech, so I had Claude make a dummy website to show what it can do expecting some mediocre website.\\n\\nThe free tier of Claude spat out 1300 lines of code, and 3 revisions in one go, and gave a fully complete and functional production ready website in one go. It was genuinely mind blowing.\\n\\nI wouldn’t have been able to tell that it wasn’t a professional website if I didn’t know it already. It genuinely blew my mind bc I mostly stick to local models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r7twp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude is fucking OP.&lt;/p&gt;\\n\\n&lt;p&gt;The other day I was showing it to my dad who knows nothing abt tech, so I had Claude make a dummy website to show what it can do expecting some mediocre website.&lt;/p&gt;\\n\\n&lt;p&gt;The free tier of Claude spat out 1300 lines of code, and 3 revisions in one go, and gave a fully complete and functional production ready website in one go. It was genuinely mind blowing.&lt;/p&gt;\\n\\n&lt;p&gt;I wouldn’t have been able to tell that it wasn’t a professional website if I didn’t know it already. It genuinely blew my mind bc I mostly stick to local models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r7twp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751863027,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qjhmy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"offlinesir","can_mod_post":false,"created_utc":1751852959,"send_replies":true,"parent_id":"t3_1lthtbn","score":118,"author_fullname":"t2_jn5ft2le","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"DeepSeek-R1-0528 being in second surprises me! Although I would assume this is due to Claude 4 not having reasoning enabled (my assumption as the timing per task is lower for Claude models on the list compared to Deepseek.\\n\\nHowever, I'm surprised about the low scores of Gemini 2.5 Pro and o3 compared to Mistral. It's nothing against Mistral, it's just that I don't believe they perform as well as Gemini 2.5 Pro or o3 in my experience or in general.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qjhmy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DeepSeek-R1-0528 being in second surprises me! Although I would assume this is due to Claude 4 not having reasoning enabled (my assumption as the timing per task is lower for Claude models on the list compared to Deepseek.&lt;/p&gt;\\n\\n&lt;p&gt;However, I&amp;#39;m surprised about the low scores of Gemini 2.5 Pro and o3 compared to Mistral. It&amp;#39;s nothing against Mistral, it&amp;#39;s just that I don&amp;#39;t believe they perform as well as Gemini 2.5 Pro or o3 in my experience or in general.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qjhmy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751852959,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":118}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qq7fj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"usernameplshere","can_mod_post":false,"created_utc":1751855497,"send_replies":true,"parent_id":"t3_1lthtbn","score":23,"author_fullname":"t2_1zes6cdw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't deepseek coder like 2 years old? It's absolutely insane that it's still up there with the top performers (in this limited benchmark).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qq7fj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t deepseek coder like 2 years old? It&amp;#39;s absolutely insane that it&amp;#39;s still up there with the top performers (in this limited benchmark).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qq7fj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855497,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qxtp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qu011","score":12,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe Gemini was just generating what it’s crush looks like.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qxtp3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe Gemini was just generating what it’s crush looks like.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qxtp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751858559,"author_flair_text":null,"treatment_tags":[],"created_utc":1751858559,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qu011","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Neither-Phone-7264","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qk8ky","score":19,"author_fullname":"t2_e7yz4055","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"hehehe\\n\\nuser: woman\\n\\nai: ok, here's a robot i guess","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qu011","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hehehe&lt;/p&gt;\\n\\n&lt;p&gt;user: woman&lt;/p&gt;\\n\\n&lt;p&gt;ai: ok, here&amp;#39;s a robot i guess&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qu011/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856992,"author_flair_text":null,"treatment_tags":[],"created_utc":1751856992,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rcrjb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HighOnLevels","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qk8ky","score":5,"author_fullname":"t2_yf9z6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Re. your Gemini 1.5 visual. I believe that is very similar to an very popular existing free 3d asset (can't find it right now), so I think that is just overfitting to training data.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1rcrjb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Re. your Gemini 1.5 visual. I believe that is very similar to an very popular existing free 3d asset (can&amp;#39;t find it right now), so I think that is just overfitting to training data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rcrjb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751865451,"author_flair_text":null,"treatment_tags":[],"created_utc":1751865451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qtug3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GhostArchitect01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qk8ky","score":2,"author_fullname":"t2_1miosjge4f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"More people are using it because of Gemini-CLI","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qtug3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More people are using it because of Gemini-CLI&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qtug3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856928,"author_flair_text":null,"treatment_tags":[],"created_utc":1751856928,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qk8ky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1751853238,"send_replies":true,"parent_id":"t1_n1qj6ts","score":29,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In my experience, Gemini 2.5 has been very hit or miss from what you can see [here](https://www.designarena.ai/models/gemini-2.5-pro). Ironically enough, Gemini 1.5 (though we deprecated it off the leaderboard so it's no longer getting votes), was able to randomly generate a [visual like this](https://www.designarena.ai/battles/detail?tournamentId=tournament_1750041228177_ebvy09pt1) though I haven't really seen Gemini 2.5 get on that level.\\n\\nThat said, we have noticed a steady rise in Gemini 2.5's positioning on the leaderboard. About a weak and a half ago, I think Gemini was in the bottom 20%. It just cracked the top 10 today so it has been rising interestingly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qk8ky","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my experience, Gemini 2.5 has been very hit or miss from what you can see &lt;a href=\\"https://www.designarena.ai/models/gemini-2.5-pro\\"&gt;here&lt;/a&gt;. Ironically enough, Gemini 1.5 (though we deprecated it off the leaderboard so it&amp;#39;s no longer getting votes), was able to randomly generate a &lt;a href=\\"https://www.designarena.ai/battles/detail?tournamentId=tournament_1750041228177_ebvy09pt1\\"&gt;visual like this&lt;/a&gt; though I haven&amp;#39;t really seen Gemini 2.5 get on that level.&lt;/p&gt;\\n\\n&lt;p&gt;That said, we have noticed a steady rise in Gemini 2.5&amp;#39;s positioning on the leaderboard. About a weak and a half ago, I think Gemini was in the bottom 20%. It just cracked the top 10 today so it has been rising interestingly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qk8ky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853238,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rqdvj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Alex_1729","can_mod_post":false,"created_utc":1751872953,"send_replies":true,"parent_id":"t1_n1qj6ts","score":5,"author_fullname":"t2_bxj8lfu4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The latest version is excellent. Gemini kept changing, and perhaps the perception is like that because it's good for 2 weeks, than much worse the next two weeks. And currently, the latest version is great again. I'm not sure what they're doing but they keep changing it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rqdvj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The latest version is excellent. Gemini kept changing, and perhaps the perception is like that because it&amp;#39;s good for 2 weeks, than much worse the next two weeks. And currently, the latest version is great again. I&amp;#39;m not sure what they&amp;#39;re doing but they keep changing it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rqdvj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751872953,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1v9ajj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SamWest98","can_mod_post":false,"created_utc":1751920287,"send_replies":true,"parent_id":"t1_n1qj6ts","score":1,"author_fullname":"t2_1nifd7d825","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I'm on my last few days with Gemini and probably won't renew. It's decent but SO SLOW","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v9ajj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I&amp;#39;m on my last few days with Gemini and probably won&amp;#39;t renew. It&amp;#39;s decent but SO SLOW&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1v9ajj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751920287,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rat3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1r54r2","score":4,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I do think his criticisms are fair and we do know that this isn’t some perfect leaderboard (the real value is in the preference data tbh and then any kind of leaderboard could be extracted from that). That said, for some insight into what we were thinking from a methodology perspective, for 1, models following simple English instructions (i.e. create an HTML/CSS/JS app) is something we thought should be on the model provider if that makes sense.","edited":1751864925,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1rat3p","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I do think his criticisms are fair and we do know that this isn’t some perfect leaderboard (the real value is in the preference data tbh and then any kind of leaderboard could be extracted from that). That said, for some insight into what we were thinking from a methodology perspective, for 1, models following simple English instructions (i.e. create an HTML/CSS/JS app) is something we thought should be on the model provider if that makes sense.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rat3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751864462,"author_flair_text":null,"treatment_tags":[],"created_utc":1751864462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n1se6hb","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n1se6hb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HiddenoO","can_mod_post":false,"created_utc":1751886600,"send_replies":true,"parent_id":"t1_n1s2q4q","score":1,"author_fullname":"t2_8127x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Just to remind you, you made the original claim that your proposed bias is significant enough to make a difference.\\n\\nI never did. Are you confusing me with somebody else?\\n\\nAs for what you posted, you don't do a statistical analysis by picking examples. If you look at the results, just single-digit percentage swings can significantly affect rankings.\\n\\nAnd just to be clear, the examples you posted might very well be biased. To be precise, they look biased towards low-effort prompts because people don't care about what's generated on the site the same way they'd care about something they actually want. Some models will likely deal with low-effort prompts significantly better than others.","edited":1751886982,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1se6hb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Just to remind you, you made the original claim that your proposed bias is significant enough to make a difference.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I never did. Are you confusing me with somebody else?&lt;/p&gt;\\n\\n&lt;p&gt;As for what you posted, you don&amp;#39;t do a statistical analysis by picking examples. If you look at the results, just single-digit percentage swings can significantly affect rankings.&lt;/p&gt;\\n\\n&lt;p&gt;And just to be clear, the examples you posted might very well be biased. To be precise, they look biased towards low-effort prompts because people don&amp;#39;t care about what&amp;#39;s generated on the site the same way they&amp;#39;d care about something they actually want. Some models will likely deal with low-effort prompts significantly better than others.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1se6hb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751886600,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1s2q4q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"B_L_A_C_K_M_A_L_E","can_mod_post":false,"created_utc":1751880395,"send_replies":false,"parent_id":"t1_n1rv5b6","score":2,"author_fullname":"t2_1hy54yxo","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Here's a sampling of prompts from the website:\\n\\n&gt; Make a 3d model of a futuristic car\\n\\n&gt; Build a ui for a hair saloon\\n\\n&gt; a website to conduct psychological studies. users can learn about their intelligence, myths around psychology and overall help research.\\n\\nI'm sorry, what are you talking about? Can you please point out to me what model these prompts are implicitly optimized for? Am I supposed to believe that you're pointing out a \\"logically sound bias\\" that implies the person prompting \\"Make a 3d model of a futuristic car\\" is implicitly biased toward... GPT 4.1? Claude Sonnet 4.0?\\n\\nIt's fine if you want to point out that it's technically possible that the general population is over indexed on prompting ChatGPT, but have a look at the recent submissions on the page for yourself: https://www.designarena.ai/leaderboard -- if we were going to put a number on it, what percentage of the participants are unfairly biased toward any particular model? The effect size is probably vanishingly small. Outside of a few power users, most people just aren't that trained with a specific model.\\n\\nJust to remind you, you made the original claim that your proposed bias is significant enough to make a difference. There's no evidence of that, and all the evidence I see implies that it has no significant difference.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1s2q4q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here&amp;#39;s a sampling of prompts from the website:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Make a 3d model of a futuristic car&lt;/p&gt;\\n\\n&lt;p&gt;Build a ui for a hair saloon&lt;/p&gt;\\n\\n&lt;p&gt;a website to conduct psychological studies. users can learn about their intelligence, myths around psychology and overall help research.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m sorry, what are you talking about? Can you please point out to me what model these prompts are implicitly optimized for? Am I supposed to believe that you&amp;#39;re pointing out a &amp;quot;logically sound bias&amp;quot; that implies the person prompting &amp;quot;Make a 3d model of a futuristic car&amp;quot; is implicitly biased toward... GPT 4.1? Claude Sonnet 4.0?&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s fine if you want to point out that it&amp;#39;s technically possible that the general population is over indexed on prompting ChatGPT, but have a look at the recent submissions on the page for yourself: &lt;a href=\\"https://www.designarena.ai/leaderboard\\"&gt;https://www.designarena.ai/leaderboard&lt;/a&gt; -- if we were going to put a number on it, what percentage of the participants are unfairly biased toward any particular model? The effect size is probably vanishingly small. Outside of a few power users, most people just aren&amp;#39;t that trained with a specific model.&lt;/p&gt;\\n\\n&lt;p&gt;Just to remind you, you made the original claim that your proposed bias is significant enough to make a difference. There&amp;#39;s no evidence of that, and all the evidence I see implies that it has no significant difference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s2q4q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751880395,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rv5b6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HiddenoO","can_mod_post":false,"created_utc":1751875795,"send_replies":true,"parent_id":"t1_n1rtgs1","score":-1,"author_fullname":"t2_8127x","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Without any evidence that people are giving it prompts that are super specialized to some particular model, this is all just speculation on your part.\\n\\nThat's how data analysis works. You don't just throw stats at the wall and then claim they're perfect results unless somebody can prove otherwise. If there's a logically sound bias that's not being controlled for, that's an issue.\\n\\nYou made a positive claim that a model performing lower because it favors a certain prompting style inherently makes it a \\"weakness of the model\\", when in reality it would undoubtedly result in a bias towards more popular models. That's a simple logical conclusion.\\n\\n&gt;It's much more likely that the prompts are given in simple English.\\n\\nBoth a complete novice and an expert in using LLMs will use \\"simple English\\", but you surely aren't going to tell me the prompts of both will be the same, are you?\\n\\n&gt;I don't buy this idea that switching from Claude to Gemini is like switching from QWERTY to Dvorak.\\n\\nI obviously used an extreme example so anybody would understand, but the underlying effect is the same. People tend to get better at using the tools they're actually using, and there are absolutely differences between optimal prompts for different models. The only question is whether those differences are large enough to significantly impact the results. That's why you usually control for these factors in scientific studies, e.g., by asking participants for their current and/or most used tools and then checking if there are any statistically significant correlations behind the tools they're already using and the tools they picked as the best-performing here.\\n\\nRealistically speaking, your only semblance of an argument here is \\"the difference isn't large enough to matter\\", but then again, \\"this is all just speculation on your part\\".","edited":1751876292,"gildings":{},"author_flair_css_class":null,"name":"t1_n1rv5b6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Without any evidence that people are giving it prompts that are super specialized to some particular model, this is all just speculation on your part.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s how data analysis works. You don&amp;#39;t just throw stats at the wall and then claim they&amp;#39;re perfect results unless somebody can prove otherwise. If there&amp;#39;s a logically sound bias that&amp;#39;s not being controlled for, that&amp;#39;s an issue.&lt;/p&gt;\\n\\n&lt;p&gt;You made a positive claim that a model performing lower because it favors a certain prompting style inherently makes it a &amp;quot;weakness of the model&amp;quot;, when in reality it would undoubtedly result in a bias towards more popular models. That&amp;#39;s a simple logical conclusion.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;It&amp;#39;s much more likely that the prompts are given in simple English.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Both a complete novice and an expert in using LLMs will use &amp;quot;simple English&amp;quot;, but you surely aren&amp;#39;t going to tell me the prompts of both will be the same, are you?&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;I don&amp;#39;t buy this idea that switching from Claude to Gemini is like switching from QWERTY to Dvorak.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I obviously used an extreme example so anybody would understand, but the underlying effect is the same. People tend to get better at using the tools they&amp;#39;re actually using, and there are absolutely differences between optimal prompts for different models. The only question is whether those differences are large enough to significantly impact the results. That&amp;#39;s why you usually control for these factors in scientific studies, e.g., by asking participants for their current and/or most used tools and then checking if there are any statistically significant correlations behind the tools they&amp;#39;re already using and the tools they picked as the best-performing here.&lt;/p&gt;\\n\\n&lt;p&gt;Realistically speaking, your only semblance of an argument here is &amp;quot;the difference isn&amp;#39;t large enough to matter&amp;quot;, but then again, &amp;quot;this is all just speculation on your part&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rv5b6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751875795,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rtgs1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"B_L_A_C_K_M_A_L_E","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1rq6hh","score":3,"author_fullname":"t2_1hy54yxo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Without any evidence that people are giving it prompts that are super specialized to some particular model, this is all just speculation on your part. It's much more likely that the prompts are given in simple English. If model X under-performs in the type of queries that people give (that aren't specialized for any model), that's a fault with model X. I don't buy this idea that switching from Claude to Gemini is like switching from QWERTY to Dvorak.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1rtgs1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Without any evidence that people are giving it prompts that are super specialized to some particular model, this is all just speculation on your part. It&amp;#39;s much more likely that the prompts are given in simple English. If model X under-performs in the type of queries that people give (that aren&amp;#39;t specialized for any model), that&amp;#39;s a fault with model X. I don&amp;#39;t buy this idea that switching from Claude to Gemini is like switching from QWERTY to Dvorak.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rtgs1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751874798,"author_flair_text":null,"treatment_tags":[],"created_utc":1751874798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rq6hh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HiddenoO","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1r54r2","score":1,"author_fullname":"t2_8127x","approved_by":null,"mod_note":null,"all_awardings":[],"body":"1 doesn't have to be a weakness of the model. If different models have biases towards prompts written in a certain style, a poll like this will inherently favor models that most people have already been using since those models are what they've learned to prompt for.\\n\\nIt's the same as with anything else that people have to get used to. If e.g. you were trying to determine the most efficient keyboard layout and were to simply give people random keyboard layouts and test (or ask them) what they perform best with, the best performing ones would undoubtedly be the ones that are the widely used because people perform far better with layouts they're already used to.","edited":1751875156,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1rq6hh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1 doesn&amp;#39;t have to be a weakness of the model. If different models have biases towards prompts written in a certain style, a poll like this will inherently favor models that most people have already been using since those models are what they&amp;#39;ve learned to prompt for.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s the same as with anything else that people have to get used to. If e.g. you were trying to determine the most efficient keyboard layout and were to simply give people random keyboard layouts and test (or ask them) what they perform best with, the best performing ones would undoubtedly be the ones that are the widely used because people perform far better with layouts they&amp;#39;re already used to.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rq6hh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751872830,"author_flair_text":null,"treatment_tags":[],"created_utc":1751872830,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1r54r2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"B_L_A_C_K_M_A_L_E","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qqpuj","score":20,"author_fullname":"t2_1hy54yxo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't see how either of your criticisms are really relevant.\\n\\n1. \\"But my favourite model wants to be prompted a specific way\\" that's a weakness of the model. Unless OP is specifically following ONLY the instructions of one particular model, this is a fair point of comparison.\\n\\n2. \\"People just prefer the look/feel of what model X produces\\" -- yes, that's a strength of model X. There isn't anything wrong with incorporating that into the score.","edited":false,"author_flair_css_class":null,"name":"t1_n1r54r2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t see how either of your criticisms are really relevant.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;&amp;quot;But my favourite model wants to be prompted a specific way&amp;quot; that&amp;#39;s a weakness of the model. Unless OP is specifically following ONLY the instructions of one particular model, this is a fair point of comparison.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&amp;quot;People just prefer the look/feel of what model X produces&amp;quot; -- yes, that&amp;#39;s a strength of model X. There isn&amp;#39;t anything wrong with incorporating that into the score.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r54r2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751861761,"author_flair_text":null,"collapsed":false,"created_utc":1751861761,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qs6f7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qqpuj","score":3,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Those are fair criticisms! The benchmark has only been around for a couple weeks so far so this kind of feedback to improve it is super helpful. \\n\\nFor your point on o3 pro, we are working on adding more models, though first trying to get credits! \\n\\nI think your point on prompting is a super fair point that we overlooked and we'll look into!","edited":false,"author_flair_css_class":null,"name":"t1_n1qs6f7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Those are fair criticisms! The benchmark has only been around for a couple weeks so far so this kind of feedback to improve it is super helpful. &lt;/p&gt;\\n\\n&lt;p&gt;For your point on o3 pro, we are working on adding more models, though first trying to get credits! &lt;/p&gt;\\n\\n&lt;p&gt;I think your point on prompting is a super fair point that we overlooked and we&amp;#39;ll look into!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qs6f7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856266,"author_flair_text":null,"collapsed":false,"created_utc":1751856266,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qqpuj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"InterstellarReddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qpivd","score":-11,"author_fullname":"t2_3aooiye4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Even worse of a bias. The same prompts do not work across the same models. \\n\\nGoogle literally has a prompting guide on how to prompt their models, that prompting guide does not carry over to other models. \\n\\nClaude has their prompting guide as well. \\n\\nAgain, I'm not saying that the data is completely off, but I could argue that this data is not as accurate as they're portraying it to be.\\n\\nFinally, I find it kind of odd that o3 Pro is not on there. o3 Pro is the most expensive model on the market right now for a reason. \\n\\nIt's not because they were bored, and decided to charge 5x-10 times as much as the other models\\n\\nEdit - I just did a little bit of voting and there's even a user bias. \\n\\nYou could argue that one user prefers the UI result of one model over another, while another user prefers the other model. \\n\\nI think there's a lot of useful data here that can be extracted, but I wouldn't take this serious considering the few flaws I found in the first few minutes of reviewing","edited":1751855889,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qqpuj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even worse of a bias. The same prompts do not work across the same models. &lt;/p&gt;\\n\\n&lt;p&gt;Google literally has a prompting guide on how to prompt their models, that prompting guide does not carry over to other models. &lt;/p&gt;\\n\\n&lt;p&gt;Claude has their prompting guide as well. &lt;/p&gt;\\n\\n&lt;p&gt;Again, I&amp;#39;m not saying that the data is completely off, but I could argue that this data is not as accurate as they&amp;#39;re portraying it to be.&lt;/p&gt;\\n\\n&lt;p&gt;Finally, I find it kind of odd that o3 Pro is not on there. o3 Pro is the most expensive model on the market right now for a reason. &lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s not because they were bored, and decided to charge 5x-10 times as much as the other models&lt;/p&gt;\\n\\n&lt;p&gt;Edit - I just did a little bit of voting and there&amp;#39;s even a user bias. &lt;/p&gt;\\n\\n&lt;p&gt;You could argue that one user prefers the UI result of one model over another, while another user prefers the other model. &lt;/p&gt;\\n\\n&lt;p&gt;I think there&amp;#39;s a lot of useful data here that can be extracted, but I wouldn&amp;#39;t take this serious considering the few flaws I found in the first few minutes of reviewing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qqpuj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855694,"author_flair_text":null,"treatment_tags":[],"created_utc":1751855694,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-11}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qpivd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qoytn","score":27,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That would be a fair point, but these model rankings are based on people votiing on generated content, not the models directly if that makes sense? You can check out the [voting system here](https://www.designarena.ai/vote), but the idea here is that you start off 4 models with a prompt, those models will generate some content (e.g. website, game, or visualization) and then a user is voting on that content (without seeing the name of the model that generated which content) and then that is being used to rank the models. \\n\\nThe pricing of the models shouldn't be affecting the ranking if that makes sense?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qpivd","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would be a fair point, but these model rankings are based on people votiing on generated content, not the models directly if that makes sense? You can check out the &lt;a href=\\"https://www.designarena.ai/vote\\"&gt;voting system here&lt;/a&gt;, but the idea here is that you start off 4 models with a prompt, those models will generate some content (e.g. website, game, or visualization) and then a user is voting on that content (without seeing the name of the model that generated which content) and then that is being used to rank the models. &lt;/p&gt;\\n\\n&lt;p&gt;The pricing of the models shouldn&amp;#39;t be affecting the ranking if that makes sense?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qpivd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855231,"author_flair_text":null,"treatment_tags":[],"created_utc":1751855231,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ricwx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Captain_D_Buggy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qoytn","score":2,"author_fullname":"t2_14o1on","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It depends. Gemini pro was cheaper initially, then there's preview offer on claude 4 and it costed 0.75x but now costs 2x in tools like cursor.\\n\\nI prefer mostly claude 4 now, gemini response time is also pretty bad now compared to before.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1ricwx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It depends. Gemini pro was cheaper initially, then there&amp;#39;s preview offer on claude 4 and it costed 0.75x but now costs 2x in tools like cursor.&lt;/p&gt;\\n\\n&lt;p&gt;I prefer mostly claude 4 now, gemini response time is also pretty bad now compared to before.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1ricwx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751868417,"author_flair_text":null,"treatment_tags":[],"created_utc":1751868417,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qoytn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"InterstellarReddit","can_mod_post":false,"created_utc":1751855018,"send_replies":true,"parent_id":"t1_n1qj6ts","score":-5,"author_fullname":"t2_3aooiye4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There's something biased about this data. Gemini pro is also more expensive to use than claude so more people are going to use Claude to do more of these kind of projects since it's cheaper. \\n\\nIt may not be that Gemini is a worse model. It's just that people are not using it since its cost is higher than Claude. \\n\\nSame thing goes for o3 Pro - it's a beast of a model, but it's so expensive that nobody's going to use it, at least not enough people to make a difference on this chart. \\n\\nEssentially the chart is saying that more people are driving a Honda to work than a Ferrari. \\n\\nDoes that make sense? How many people own a Ferrari versus how many people own a Honda and go to work etc. Is what I'm trying to explain","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qoytn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s something biased about this data. Gemini pro is also more expensive to use than claude so more people are going to use Claude to do more of these kind of projects since it&amp;#39;s cheaper. &lt;/p&gt;\\n\\n&lt;p&gt;It may not be that Gemini is a worse model. It&amp;#39;s just that people are not using it since its cost is higher than Claude. &lt;/p&gt;\\n\\n&lt;p&gt;Same thing goes for o3 Pro - it&amp;#39;s a beast of a model, but it&amp;#39;s so expensive that nobody&amp;#39;s going to use it, at least not enough people to make a difference on this chart. &lt;/p&gt;\\n\\n&lt;p&gt;Essentially the chart is saying that more people are driving a Honda to work than a Ferrari. &lt;/p&gt;\\n\\n&lt;p&gt;Does that make sense? How many people own a Ferrari versus how many people own a Honda and go to work etc. Is what I&amp;#39;m trying to explain&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qoytn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855018,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qj6ts","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Current-Ticket4214","can_mod_post":false,"created_utc":1751852849,"send_replies":true,"parent_id":"t3_1lthtbn","score":69,"author_fullname":"t2_6yvd3nyy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m surprised by how far Gemini 2.5 Pro has fallen since the preview release. It was phenomenal the first few weeks and then it started to fall apart.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qj6ts","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m surprised by how far Gemini 2.5 Pro has fallen since the preview release. It was phenomenal the first few weeks and then it started to fall apart.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qj6ts/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751852849,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qqgzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robogame_dev","can_mod_post":false,"created_utc":1751855599,"send_replies":true,"parent_id":"t1_n1qoicp","score":14,"author_fullname":"t2_kgsoqf03k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The models haven't necessarily been on the site the same length of time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qqgzh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The models haven&amp;#39;t necessarily been on the site the same length of time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qqgzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855599,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qvfi8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qvbtp","score":5,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And here's the rest of the leaderboard:\\n\\nhttps://preview.redd.it/1m3ruo00cdbf1.png?width=2074&amp;format=png&amp;auto=webp&amp;s=ff4290166872b5a0e3dcd1459e795b6e50c64349","edited":false,"author_flair_css_class":null,"name":"t1_n1qvfi8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And here&amp;#39;s the rest of the leaderboard:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/1m3ruo00cdbf1.png?width=2074&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff4290166872b5a0e3dcd1459e795b6e50c64349\\"&gt;https://preview.redd.it/1m3ruo00cdbf1.png?width=2074&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff4290166872b5a0e3dcd1459e795b6e50c64349&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qvfi8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857576,"media_metadata":{"1m3ruo00cdbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":82,"x":108,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=94b6d768ad04d65b69134b9fbc3327bcfa6dd683"},{"y":164,"x":216,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9884617254e6ebca618bb3361716eb4a0d569322"},{"y":243,"x":320,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7109ae01734a74356078d4a224f9de00a804f340"},{"y":486,"x":640,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c429346568a5424114803c9981d537fe2b6bceaf"},{"y":729,"x":960,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d43d0d52cf128d8e34ccaa970b6bf72efc81ab54"},{"y":820,"x":1080,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9ecfe1a83856a076b0b7f4a46c0f353207cd836"}],"s":{"y":1576,"x":2074,"u":"https://preview.redd.it/1m3ruo00cdbf1.png?width=2074&amp;format=png&amp;auto=webp&amp;s=ff4290166872b5a0e3dcd1459e795b6e50c64349"},"id":"1m3ruo00cdbf1"}},"author_flair_text":null,"collapsed":false,"created_utc":1751857576,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vu6vl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751927168,"send_replies":true,"parent_id":"t1_n1snd89","score":1,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see interesting. Will try it out. Thanks for the suggestion!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vu6vl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see interesting. Will try it out. Thanks for the suggestion!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1vu6vl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751927168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1snd89","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1751890672,"send_replies":true,"parent_id":"t1_n1rbmmo","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"body":"while using openrouter, have you tried to include in the request the arg to sort provider based on latency / token per second? by default it is ranked by price, so it may route you to providers that are really slow.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1snd89","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;while using openrouter, have you tried to include in the request the arg to sort provider based on latency / token per second? by default it is ranked by price, so it may route you to providers that are really slow.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1snd89/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751890672,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rbmmo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1751864876,"send_replies":true,"parent_id":"t1_n1rb9hl","score":5,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"We also tried that but didn't seem to make a difference. I also have had server issues on DeepSeek's UI interfaces so it does seem to be a general problem but perhaps in the future there could be a partnership there where we can get priority on their server (very low possibility though).","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1rbmmo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We also tried that but didn&amp;#39;t seem to make a difference. I also have had server issues on DeepSeek&amp;#39;s UI interfaces so it does seem to be a general problem but perhaps in the future there could be a partnership there where we can get priority on their server (very low possibility though).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rbmmo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751864876,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rb9hl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"philosophical_lens","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qw76x","score":2,"author_fullname":"t2_1pc5yp6c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe try using openrouter api","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1rb9hl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe try using openrouter api&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rb9hl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751864690,"author_flair_text":null,"treatment_tags":[],"created_utc":1751864690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qw76x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qvkk1","score":11,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Our API requests many times are being queued by DeepSeek so their models often fail / take a really long time to generate something. This is a limit of public crowdsource benchmarks that we have been thinking about how to resolve. \\n\\nBut in general, since DeepSeek requests are taking so long, we are seeing a lot of churn during voting for those models (i.e. people quitting voting when one of the DeepSeek models are selected and are taking a long time).","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1qw76x","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Our API requests many times are being queued by DeepSeek so their models often fail / take a really long time to generate something. This is a limit of public crowdsource benchmarks that we have been thinking about how to resolve. &lt;/p&gt;\\n\\n&lt;p&gt;But in general, since DeepSeek requests are taking so long, we are seeing a lot of churn during voting for those models (i.e. people quitting voting when one of the DeepSeek models are selected and are taking a long time).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qw76x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857892,"author_flair_text":null,"treatment_tags":[],"created_utc":1751857892,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qvkk1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"V0dros","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qvbtp","score":4,"author_fullname":"t2_982y1bm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting. How come Deepseek-R1 still has only 10% of the battles of Opus 4?","edited":false,"author_flair_css_class":null,"name":"t1_n1qvkk1","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting. How come Deepseek-R1 still has only 10% of the battles of Opus 4?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qvkk1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857634,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1751857634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qvbtp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qtiuf","score":9,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, here are the top 10 from the last 5 days:\\n\\nhttps://preview.redd.it/l1a8b2msbdbf1.png?width=2610&amp;format=png&amp;auto=webp&amp;s=7cafcb2f3fd81a090a8c3eaee26c89af7ad8f373","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qvbtp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, here are the top 10 from the last 5 days:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/l1a8b2msbdbf1.png?width=2610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7cafcb2f3fd81a090a8c3eaee26c89af7ad8f373\\"&gt;https://preview.redd.it/l1a8b2msbdbf1.png?width=2610&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7cafcb2f3fd81a090a8c3eaee26c89af7ad8f373&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qvbtp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857535,"media_metadata":{"l1a8b2msbdbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":66,"x":108,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a069784182183d46b9842b7a1d5d0a0925baa8fa"},{"y":132,"x":216,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe54461ac56538bc6686f66346a0537b3c50d6f1"},{"y":195,"x":320,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=24564736aaf5754cd8178ba89f0a8f0463b5c9e7"},{"y":391,"x":640,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c358fff1409248a244b7d161cc4e67027606812b"},{"y":587,"x":960,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=77a17f0cf3fa0054148ca71ff4e87339096fadef"},{"y":661,"x":1080,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a59ff2a8755967618bc960f32f6367fc65a7338"}],"s":{"y":1598,"x":2610,"u":"https://preview.redd.it/l1a8b2msbdbf1.png?width=2610&amp;format=png&amp;auto=webp&amp;s=7cafcb2f3fd81a090a8c3eaee26c89af7ad8f373"},"id":"l1a8b2msbdbf1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1751857535,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qtiuf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"V0dros","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qpywf","score":3,"author_fullname":"t2_982y1bm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you maybe show what the table looks like when only considering battles when all listed models were available? (so cut-off date = the date when the last model was added). I wonder how that would affect the results.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qtiuf","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you maybe show what the table looks like when only considering battles when all listed models were available? (so cut-off date = the date when the last model was added). I wonder how that would affect the results.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qtiuf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856798,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751856798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qpywf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1751855404,"send_replies":true,"parent_id":"t1_n1qoicp","score":13,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We added some models earlier than others. Claude Opus was one of the earlier models we added while we added Llama a few days ago. \\n\\nFor your second point, yes, we could very well do that. We kept the leaderboard simple for now using win rate and an approximate Elo score, but the ground truth here is really the vote data, not necessarily the exact ranking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qpywf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We added some models earlier than others. Claude Opus was one of the earlier models we added while we added Llama a few days ago. &lt;/p&gt;\\n\\n&lt;p&gt;For your second point, yes, we could very well do that. We kept the leaderboard simple for now using win rate and an approximate Elo score, but the ground truth here is really the vote data, not necessarily the exact ranking.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qpywf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855404,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qtb0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qshze","score":6,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Really appreciate the feedback. Not sure if we’ll ever be submitting this as a paper, but just something that my team was experimenting with.\\n\\nSorry if the title seemed clickbaity / that wasn’t my intention!","edited":1751864967,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qtb0z","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really appreciate the feedback. Not sure if we’ll ever be submitting this as a paper, but just something that my team was experimenting with.&lt;/p&gt;\\n\\n&lt;p&gt;Sorry if the title seemed clickbaity / that wasn’t my intention!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qtb0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856711,"author_flair_text":null,"treatment_tags":[],"created_utc":1751856711,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qv6uf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"V0dros","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qshze","score":6,"author_fullname":"t2_982y1bm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[The Leaderboard Illusion](https://arxiv.org/pdf/2504.20879) all over again","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qv6uf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/pdf/2504.20879\\"&gt;The Leaderboard Illusion&lt;/a&gt; all over again&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qv6uf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857478,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751857478,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vuok9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751927325,"send_replies":true,"parent_id":"t1_n1tz26z","score":1,"author_fullname":"t2_c3b3edv5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes our bad for not being clear on when models were disabled. We'll post exact details and timelines on that. We disabled some models due to running out of credits (which we are working on getting back up and running) and some of the deprecated models (such as Gemini 1.5) were also disabled. We'll definitely provide a much clearer list and you are absolutely right on that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vuok9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes our bad for not being clear on when models were disabled. We&amp;#39;ll post exact details and timelines on that. We disabled some models due to running out of credits (which we are working on getting back up and running) and some of the deprecated models (such as Gemini 1.5) were also disabled. We&amp;#39;ll definitely provide a much clearer list and you are absolutely right on that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1vuok9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751927325,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tz26z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"created_utc":1751905830,"send_replies":true,"parent_id":"t1_n1tx9g1","score":1,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree with that, but the way you show representativeness is that you associate a p-value with each comparison between two averages. I'm being pedantic though and the real issue to me is disabling models without explanation.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1tz26z","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree with that, but the way you show representativeness is that you associate a p-value with each comparison between two averages. I&amp;#39;m being pedantic though and the real issue to me is disabling models without explanation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tz26z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751905830,"author_flair_text":":X:","treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tx9g1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuisan","can_mod_post":false,"created_utc":1751905312,"send_replies":true,"parent_id":"t1_n1tu7qm","score":2,"author_fullname":"t2_khoah","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean, I agree with you that this data seems suspect at the very least. 1 battle is not representative, but at some number it is. My only nitpick was that it was the number of battles that is what matters and not the percentage. Regardless of what the percentage is, as long as the number of votes is high enough to be representative of the outcome, that is all that matters afaik.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1tx9g1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, I agree with you that this data seems suspect at the very least. 1 battle is not representative, but at some number it is. My only nitpick was that it was the number of battles that is what matters and not the percentage. Regardless of what the percentage is, as long as the number of votes is high enough to be representative of the outcome, that is all that matters afaik.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tx9g1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751905312,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tu7qm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ts8r4","score":1,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If the sample sizes differ then you need to be careful when comparing averages.\\n\\nWinning 100% of 1 battle is different from winning 90% of 1000 battles.\\n\\nWinning 100% of 1 battle against 4o-mini is different from winning 90% of 1000 battles where 900 were against DeepSeek-r1.\\n\\nSo these numbers are all fine individually, but the numbers for different models cannot be compared with each other.\\n\\nThis is why in chess and soccer tournaments for example, you don't have this weird \\"active teams\\" crap. Every team faces every other team exactly once in the round-robin part of the tournament.\\n\\nEdit: The word \\"representative\\" is doing a lot of heavy lifting here. What is representative? How large? Who should the opponent be? Statisticians have actual answers to these questions, and this leaderboard does not use good statistics.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1tu7qm","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the sample sizes differ then you need to be careful when comparing averages.&lt;/p&gt;\\n\\n&lt;p&gt;Winning 100% of 1 battle is different from winning 90% of 1000 battles.&lt;/p&gt;\\n\\n&lt;p&gt;Winning 100% of 1 battle against 4o-mini is different from winning 90% of 1000 battles where 900 were against DeepSeek-r1.&lt;/p&gt;\\n\\n&lt;p&gt;So these numbers are all fine individually, but the numbers for different models cannot be compared with each other.&lt;/p&gt;\\n\\n&lt;p&gt;This is why in chess and soccer tournaments for example, you don&amp;#39;t have this weird &amp;quot;active teams&amp;quot; crap. Every team faces every other team exactly once in the round-robin part of the tournament.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: The word &amp;quot;representative&amp;quot; is doing a lot of heavy lifting here. What is representative? How large? Who should the opponent be? Statisticians have actual answers to these questions, and this leaderboard does not use good statistics.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tu7qm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751904430,"author_flair_text":":X:","treatment_tags":[],"created_utc":1751904430,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ts8r4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuisan","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1tn6u7","score":1,"author_fullname":"t2_khoah","approved_by":null,"mod_note":null,"all_awardings":[],"body":"As far as I was taught, as long as you have enough of a representative sample, the result doesn't really change much with more voting opportunities.\\n\\nSurely even if Opus had 50% of the battles and LLama had 2.5%, as long as that 2.5% of votes is enough to be representative, the comparative amount of votes shouldn't matter? It might get more precise, but the percentage still doesn't seem like the issue here, just the absolute number of votes, is that wrong?\\n\\nI think Llama not being active for certain times is definitely an issue, especially if it didn't have the opportunity to face models that may have been weaker than it that were added when it wasn't active and only ever went up against stronger models, but again that's a different point.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n1ts8r4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As far as I was taught, as long as you have enough of a representative sample, the result doesn&amp;#39;t really change much with more voting opportunities.&lt;/p&gt;\\n\\n&lt;p&gt;Surely even if Opus had 50% of the battles and LLama had 2.5%, as long as that 2.5% of votes is enough to be representative, the comparative amount of votes shouldn&amp;#39;t matter? It might get more precise, but the percentage still doesn&amp;#39;t seem like the issue here, just the absolute number of votes, is that wrong?&lt;/p&gt;\\n\\n&lt;p&gt;I think Llama not being active for certain times is definitely an issue, especially if it didn&amp;#39;t have the opportunity to face models that may have been weaker than it that were added when it wasn&amp;#39;t active and only ever went up against stronger models, but again that&amp;#39;s a different point.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1ts8r4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751903859,"author_flair_text":null,"treatment_tags":[],"created_utc":1751903859,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tn6u7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1t9tma","score":1,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are partly correct. But I'm talking about the number of voting opportunities not the number of winning votes.\\n\\nLlama showed up in just 2.5% of battles. If this battle percentage was the same for all models it would be fine, but \\"active\\" models like Claude 4 Opus were given a lot more opportunities to earn votes than others.\\n\\nIs there a reason for that? Every model should have a similar number of battles IMHO. Unless models are being strategically \\"disabled\\" for unknown reasons.","edited":false,"author_flair_css_class":null,"name":"t1_n1tn6u7","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are partly correct. But I&amp;#39;m talking about the number of voting opportunities not the number of winning votes.&lt;/p&gt;\\n\\n&lt;p&gt;Llama showed up in just 2.5% of battles. If this battle percentage was the same for all models it would be fine, but &amp;quot;active&amp;quot; models like Claude 4 Opus were given a lot more opportunities to earn votes than others.&lt;/p&gt;\\n\\n&lt;p&gt;Is there a reason for that? Every model should have a similar number of battles IMHO. Unless models are being strategically &amp;quot;disabled&amp;quot; for unknown reasons.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lthtbn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tn6u7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751902413,"author_flair_text":":X:","collapsed":false,"created_utc":1751902413,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1t9tma","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuisan","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qshze","score":3,"author_fullname":"t2_khoah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't actually know anything about experimental methodology, so I may be completely off the mark, but I am curious why the 2.4% vote sample matters. Surely the number of votes matters more than the percentage.\\n\\nIf there were 40 models being compared, you would expect about 2.5% vote sample if they were all coming up equally as often. With 24 models, you'd expect about 4%. I feel like as long as there are enough votes to be a representative sample against all other models, surely that is what matters and not the percentage of the overall votes?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1t9tma","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t actually know anything about experimental methodology, so I may be completely off the mark, but I am curious why the 2.4% vote sample matters. Surely the number of votes matters more than the percentage.&lt;/p&gt;\\n\\n&lt;p&gt;If there were 40 models being compared, you would expect about 2.5% vote sample if they were all coming up equally as often. With 24 models, you&amp;#39;d expect about 4%. I feel like as long as there are enough votes to be a representative sample against all other models, surely that is what matters and not the percentage of the overall votes?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1t9tma/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751898466,"author_flair_text":null,"treatment_tags":[],"created_utc":1751898466,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qshze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qqrf8","score":12,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Claude Opus 4 is at the top, but it's also the model that's been in the active pool the longest. That's why it's at the top.\\n\\nAnd wow Llama isn't even in the pool? The post title says \\"Both Llama models came almost dead last\\", but Llama Maverick has been voted on 202 times in total out of 8500 = 2.4% of your total votes. You can't make *any* comparative claims with a 2.4% vote sample.\\n\\nSo the title is basically clickbait.\\n\\nHere's another experimental flaw: this methodology first displays the 2 models *earliest to finish* producing the output. This breaks the randomization: the sequence of choices is biased towards showing the quicker models first and not randomized. I don't know who designed this experimental protocol, but it's not going to pass peer review.\\n\\nIt might pass /r/LocalLlama review though.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qshze","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude Opus 4 is at the top, but it&amp;#39;s also the model that&amp;#39;s been in the active pool the longest. That&amp;#39;s why it&amp;#39;s at the top.&lt;/p&gt;\\n\\n&lt;p&gt;And wow Llama isn&amp;#39;t even in the pool? The post title says &amp;quot;Both Llama models came almost dead last&amp;quot;, but Llama Maverick has been voted on 202 times in total out of 8500 = 2.4% of your total votes. You can&amp;#39;t make &lt;em&gt;any&lt;/em&gt; comparative claims with a 2.4% vote sample.&lt;/p&gt;\\n\\n&lt;p&gt;So the title is basically clickbait.&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s another experimental flaw: this methodology first displays the 2 models &lt;em&gt;earliest to finish&lt;/em&gt; producing the output. This breaks the randomization: the sequence of choices is biased towards showing the quicker models first and not randomized. I don&amp;#39;t know who designed this experimental protocol, but it&amp;#39;s not going to pass peer review.&lt;/p&gt;\\n\\n&lt;p&gt;It might pass &lt;a href=\\"/r/LocalLlama\\"&gt;/r/LocalLlama&lt;/a&gt; review though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qshze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856390,"author_flair_text":":X:","treatment_tags":[],"created_utc":1751856390,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qqrf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751855711,"send_replies":true,"parent_id":"t1_n1qoicp","score":3,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's our bad for not making it clear. All the models currently on the leaderboard were at one point active though this is the list of currently active models that make up the pool:\\n\\nClaude Opus 4, Claude Sonnet 4, Claude 3.7 Sonnet\\n\\nGPT-o4-mini, GPT-4.1, GPT-4.1 Mini, GPT 4.1-Nano, GPT-4o, GPT-o3\\n\\nGemini 2.5 Pro\\n\\nGrok 3, Grok 3 Mini\\n\\nDeepseek Coder, Deepseek Chat (V3-2024), DeepSeek Reasoner R1-0528\\n\\nv0-1.5-md, v0-1.5-lg\\n\\nMistral Medium 3, Codestral 2 (2501)\\n\\nAs for the evaluation, the voting process right now is such that 4 models go against each other in a tournament style where model A goes against model B, and model C goes against model D initially. Then, wlog, if we assume model A wins against B and model C wins against D, then the winners (A and C) will go against each other and the losers (B and D) will then go against each other. Then in the last round, the loser of the winners' bracket (let's say C) will go against the winner from the losers' bracket (let's say B) to decide 2nd and 3rd place. \\n\\nThat said each vote between 2 models is what's being used to determine win rate.","edited":1751855975,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qqrf8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s our bad for not making it clear. All the models currently on the leaderboard were at one point active though this is the list of currently active models that make up the pool:&lt;/p&gt;\\n\\n&lt;p&gt;Claude Opus 4, Claude Sonnet 4, Claude 3.7 Sonnet&lt;/p&gt;\\n\\n&lt;p&gt;GPT-o4-mini, GPT-4.1, GPT-4.1 Mini, GPT 4.1-Nano, GPT-4o, GPT-o3&lt;/p&gt;\\n\\n&lt;p&gt;Gemini 2.5 Pro&lt;/p&gt;\\n\\n&lt;p&gt;Grok 3, Grok 3 Mini&lt;/p&gt;\\n\\n&lt;p&gt;Deepseek Coder, Deepseek Chat (V3-2024), DeepSeek Reasoner R1-0528&lt;/p&gt;\\n\\n&lt;p&gt;v0-1.5-md, v0-1.5-lg&lt;/p&gt;\\n\\n&lt;p&gt;Mistral Medium 3, Codestral 2 (2501)&lt;/p&gt;\\n\\n&lt;p&gt;As for the evaluation, the voting process right now is such that 4 models go against each other in a tournament style where model A goes against model B, and model C goes against model D initially. Then, wlog, if we assume model A wins against B and model C wins against D, then the winners (A and C) will go against each other and the losers (B and D) will then go against each other. Then in the last round, the loser of the winners&amp;#39; bracket (let&amp;#39;s say C) will go against the winner from the losers&amp;#39; bracket (let&amp;#39;s say B) to decide 2nd and 3rd place. &lt;/p&gt;\\n\\n&lt;p&gt;That said each vote between 2 models is what&amp;#39;s being used to determine win rate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qqrf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855711,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qoicp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"created_utc":1751854844,"send_replies":true,"parent_id":"t3_1lthtbn","score":32,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Weird question: if the models are randomized, why is it that Llama 4 Maverick showed up in 180 battles while Claude Opus 4 showed up in 950? Shouldn't every model show up roughly the same number of times?\\n\\nAnd doesn't a model showing up a lower number of times increase the variance and standard errors of the win rate and ELO, so you need a proper one-tailed statistical test to compare models?\\n\\nEdit: I looked for the evaluation code and it's closed source? First time I'm seeing a research project leaderboard with no code available.\\n\\n&gt; Each voting session randomly selects four models from the active pool, plus one backup.\\n\\nWhat is the \\"active pool\\"?","edited":1751855083,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qoicp","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Weird question: if the models are randomized, why is it that Llama 4 Maverick showed up in 180 battles while Claude Opus 4 showed up in 950? Shouldn&amp;#39;t every model show up roughly the same number of times?&lt;/p&gt;\\n\\n&lt;p&gt;And doesn&amp;#39;t a model showing up a lower number of times increase the variance and standard errors of the win rate and ELO, so you need a proper one-tailed statistical test to compare models?&lt;/p&gt;\\n\\n&lt;p&gt;Edit: I looked for the evaluation code and it&amp;#39;s closed source? First time I&amp;#39;m seeing a research project leaderboard with no code available.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Each voting session randomly selects four models from the active pool, plus one backup.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;What is the &amp;quot;active pool&amp;quot;?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qoicp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751854844,"author_flair_text":":X:","treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rmy3f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1rlb9t","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for the suggestion!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rmy3f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the suggestion!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rmy3f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751870980,"author_flair_text":null,"treatment_tags":[],"created_utc":1751870980,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rlb9t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qrisa","score":3,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for sharing these. Mistral Medium 3 is API-only and likely 70b right?\\n\\nDo consider adding Command-A to the list. It doesn't get much attention but I suspect could be the #2 open weight model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1rlb9t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for sharing these. Mistral Medium 3 is API-only and likely 70b right?&lt;/p&gt;\\n\\n&lt;p&gt;Do consider adding Command-A to the list. It doesn&amp;#39;t get much attention but I suspect could be the #2 open weight model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rlb9t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751870061,"author_flair_text":null,"treatment_tags":[],"created_utc":1751870061,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qrisa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751856009,"send_replies":true,"parent_id":"t1_n1qoieo","score":3,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, we'll be adding more models soon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qrisa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, we&amp;#39;ll be adding more models soon.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qrisa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856009,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s7ph4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1rdi3i","score":5,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We’ll be releasing an open-source dataset with a preference dataset and I’ll make a follow-up post about that. \\n\\nAs for why code is closed-source, it’s mostly just because this started out as something internal and since we didn’t want to deal with security immediately, we decided to keep code close-source but all the generations can be viewed on the platform.\\n\\nAs for the code, I can discuss details on the evaluation, but it is very simple. Essentially we’re just having people compare visuals that models generate in groups (through a tournament format) and then based on the number of wins and head-to-heads in those tournaments, that’s how we’re ranking the models. That said, the tournament feature is more of an aesthetic choice. What really matters is how each model is performing against another model directly. \\n\\nLet me know if you want any other details! We realize there are flaws as we are very early with this, but trying to get as much feedback as possible!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1s7ph4","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We’ll be releasing an open-source dataset with a preference dataset and I’ll make a follow-up post about that. &lt;/p&gt;\\n\\n&lt;p&gt;As for why code is closed-source, it’s mostly just because this started out as something internal and since we didn’t want to deal with security immediately, we decided to keep code close-source but all the generations can be viewed on the platform.&lt;/p&gt;\\n\\n&lt;p&gt;As for the code, I can discuss details on the evaluation, but it is very simple. Essentially we’re just having people compare visuals that models generate in groups (through a tournament format) and then based on the number of wins and head-to-heads in those tournaments, that’s how we’re ranking the models. That said, the tournament feature is more of an aesthetic choice. What really matters is how each model is performing against another model directly. &lt;/p&gt;\\n\\n&lt;p&gt;Let me know if you want any other details! We realize there are flaws as we are very early with this, but trying to get as much feedback as possible!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s7ph4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751883266,"author_flair_text":null,"treatment_tags":[],"created_utc":1751883266,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rdi3i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"created_utc":1751865830,"send_replies":false,"parent_id":"t1_n1qoieo","score":3,"author_fullname":"t2_usojvms","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I mentioned that the last time they astro turfed this, but it being a closed source site really makes this leaderboard useless regardless ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rdi3i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I mentioned that the last time they astro turfed this, but it being a closed source site really makes this leaderboard useless regardless &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rdi3i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751865830,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qoieo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"admajic","can_mod_post":false,"created_utc":1751854844,"send_replies":true,"parent_id":"t3_1lthtbn","score":8,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"GLM 4  good for one shot web design throw that in the mix.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qoieo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GLM 4  good for one shot web design throw that in the mix.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qoieo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751854844,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1tjdbd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"meatycowboy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1s9trp","score":2,"author_fullname":"t2_8j8afrcr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Openrouter + Sillytavern","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1tjdbd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Openrouter + Sillytavern&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tjdbd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751901294,"author_flair_text":null,"treatment_tags":[],"created_utc":1751901294,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1s9trp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fullouterjoin","can_mod_post":false,"created_utc":1751884420,"send_replies":true,"parent_id":"t1_n1r8ohe","score":3,"author_fullname":"t2_406sj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are you using it? Open Router?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s9trp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are you using it? Open Router?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s9trp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751884420,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1r8ohe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"meatycowboy","can_mod_post":false,"created_utc":1751863433,"send_replies":true,"parent_id":"t3_1lthtbn","score":6,"author_fullname":"t2_8j8afrcr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"R1-0528 is a beast. I've been using it almost as much as Gemini lately.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r8ohe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1-0528 is a beast. I&amp;#39;ve been using it almost as much as Gemini lately.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r8ohe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751863433,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rn4bo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adviceguru25","can_mod_post":false,"created_utc":1751871078,"send_replies":true,"parent_id":"t1_n1rh5xf","score":7,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, will be doing! We just are waiting on credits from Google","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rn4bo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, will be doing! We just are waiting on credits from Google&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rn4bo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751871078,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rh5xf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1751867768,"send_replies":true,"parent_id":"t3_1lthtbn","score":5,"author_fullname":"t2_4gc7hf3m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Might as well throw GLM 32B and Qwen3 32B in there, see how small local LLMs compete with large cloud ones ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rh5xf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Might as well throw GLM 32B and Qwen3 32B in there, see how small local LLMs compete with large cloud ones &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rh5xf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751867768,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s04ek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Reason_He_Wins_Again","can_mod_post":false,"created_utc":1751878805,"send_replies":true,"parent_id":"t1_n1qk191","score":5,"author_fullname":"t2_3dapkpl3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its good for formatting text for free.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s04ek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its good for formatting text for free.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s04ek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751878805,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qqzi3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robogame_dev","can_mod_post":false,"created_utc":1751855799,"send_replies":true,"parent_id":"t1_n1qk191","score":4,"author_fullname":"t2_kgsoqf03k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've found use for Mav4 as a tool calling model. It's cheap at $0.15 / $0.60 - for comparison Gemini 2.5 Flash is $0.30 / $2.50","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qqzi3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve found use for Mav4 as a tool calling model. It&amp;#39;s cheap at $0.15 / $0.60 - for comparison Gemini 2.5 Flash is $0.30 / $2.50&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qqzi3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855799,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wdc87","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1v9fev","score":1,"author_fullname":"t2_a2uzegb8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I really hope so. Though my real fear is that the underlying problem was caused by the legal issues with their training data. If that's the case I'm not sure if I can see them bouncing back.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1wdc87","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really hope so. Though my real fear is that the underlying problem was caused by the legal issues with their training data. If that&amp;#39;s the case I&amp;#39;m not sure if I can see them bouncing back.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1wdc87/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751933387,"author_flair_text":null,"treatment_tags":[],"created_utc":1751933387,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1v9fev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SamWest98","can_mod_post":false,"created_utc":1751920331,"send_replies":true,"parent_id":"t1_n1qk191","score":0,"author_fullname":"t2_1nifd7d825","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It'll probably be good again (and rebranded) some time this year. They've got a lot of new talent","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v9fev","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;ll probably be good again (and rebranded) some time this year. They&amp;#39;ve got a lot of new talent&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1v9fev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751920331,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qk191","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SillyLilBear","can_mod_post":false,"created_utc":1751853162,"send_replies":true,"parent_id":"t3_1lthtbn","score":9,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wouldn't use llama for anything","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qk191","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wouldn&amp;#39;t use llama for anything&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qk191/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853162,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rkxkv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"R_Duncan","can_mod_post":false,"created_utc":1751869848,"send_replies":true,"parent_id":"t3_1lthtbn","score":4,"author_fullname":"t2_3xd4mwvn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"DeepSeek-R1-0528 is on par with a model 100 times more expensive, A bargain even if it requires 3 times the token.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rkxkv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DeepSeek-R1-0528 is on par with a model 100 times more expensive, A bargain even if it requires 3 times the token.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rkxkv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751869848,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rz4xi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Roubbes","can_mod_post":false,"created_utc":1751878221,"send_replies":true,"parent_id":"t3_1lthtbn","score":3,"author_fullname":"t2_aoir7erh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Kudos to Mistral","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rz4xi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kudos to Mistral&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rz4xi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751878221,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rk5tx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Monkey_1505","can_mod_post":false,"created_utc":1751869414,"send_replies":true,"parent_id":"t3_1lthtbn","score":3,"author_fullname":"t2_7qrmh9n9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"More interesting that deepseek and mistral medium beat out openAI's o3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rk5tx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More interesting that deepseek and mistral medium beat out openAI&amp;#39;s o3&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rk5tx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751869414,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qlg79","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"created_utc":1751853689,"send_replies":true,"parent_id":"t3_1lthtbn","score":7,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In my experience, Llama 4 Maverick is actually worse than Mistral Small 2506, which is just slightly larger than a single one of Maverick’s 128(!) experts.\\n\\nIt’s been a long time since I’ve seen a major technology company embarrass themselves as bad as Meta did with Llama 4.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qlg79","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my experience, Llama 4 Maverick is actually worse than Mistral Small 2506, which is just slightly larger than a single one of Maverick’s 128(!) experts.&lt;/p&gt;\\n\\n&lt;p&gt;It’s been a long time since I’ve seen a major technology company embarrass themselves as bad as Meta did with Llama 4.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qlg79/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853689,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s3xfz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751881118,"send_replies":true,"parent_id":"t1_n1s3579","score":2,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We’re focusing more on visuals for now (starting with interfaces) and the planning to add image and video","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s3xfz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We’re focusing more on visuals for now (starting with interfaces) and the planning to add image and video&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s3xfz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751881118,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1s3579","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fish312","can_mod_post":false,"created_utc":1751880651,"send_replies":true,"parent_id":"t3_1lthtbn","score":4,"author_fullname":"t2_mogjd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It seems like you are missing a very valuable catgegory: Writing (fiction + non fiction)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s3579","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems like you are missing a very valuable catgegory: Writing (fiction + non fiction)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s3579/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751880651,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s70x5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lissanro","can_mod_post":false,"created_utc":1751882883,"send_replies":true,"parent_id":"t3_1lthtbn","score":2,"author_fullname":"t2_fpfao9g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I like R1 because I can run it locally as my daily driver, due to its MoE architecture making GPU+CPU inference practical. DeepSeek R1 0528 is great, and seeing it at the second place outsmarting even Grok 3 (which has 2.7 trillion parameters, 4 times more than R1) just illustrates how good it is. I do not know how many parameters Cloud Opus 4 has, but I bet also few times more than R1.","edited":1751922785,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s70x5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like R1 because I can run it locally as my daily driver, due to its MoE architecture making GPU+CPU inference practical. DeepSeek R1 0528 is great, and seeing it at the second place outsmarting even Grok 3 (which has 2.7 trillion parameters, 4 times more than R1) just illustrates how good it is. I do not know how many parameters Cloud Opus 4 has, but I bet also few times more than R1.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s70x5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751882883,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rb9z0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SouthernSkin1255","can_mod_post":false,"created_utc":1751864697,"send_replies":true,"parent_id":"t3_1lthtbn","score":2,"author_fullname":"t2_8pev0y42","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really hate Llama, I don't understand how you manage to make something as bad as Llama 4 having the capacity that Meta is, even Mistral with 2 server potatoes delivers something more decent than Llama4, it only served to dirty everything that Llama3 achieved","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rb9z0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really hate Llama, I don&amp;#39;t understand how you manage to make something as bad as Llama 4 having the capacity that Meta is, even Mistral with 2 server potatoes delivers something more decent than Llama4, it only served to dirty everything that Llama3 achieved&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rb9z0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751864697,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1td1hw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751899427,"send_replies":true,"parent_id":"t1_n1sz3y0","score":2,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fair","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1td1hw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fair&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1td1hw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751899427,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1sz3y0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-lq_pl-","can_mod_post":false,"created_utc":1751895024,"send_replies":true,"parent_id":"t3_1lthtbn","score":2,"author_fullname":"t2_16rvbe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, what? The title should say: the most expensive Claude Opus \\\\*\\\\*and\\\\*\\\\* DeepSeek R1 come up on top, while DeepSeek R1 costs 1/30 of Opus.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1sz3y0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, what? The title should say: the most expensive Claude Opus **and** DeepSeek R1 come up on top, while DeepSeek R1 costs 1/30 of Opus.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1sz3y0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751895024,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qr2ut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArtPrestigious5481","can_mod_post":false,"created_utc":1751855835,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_syp98gcf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"claude 4 is a beast, i am tech art which do many things (writing shader, writing custom tools, creating custom render feature for unity) tried gpt 4.5 to help me writing render feature and it fail every single time, and then when i tried claude 4 it works nicely sure i need to fix somethings but it's almost perfect just need slight adjustment never feels this \\"free\\", now i can focus on shader writing which is my favorite field","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qr2ut","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;claude 4 is a beast, i am tech art which do many things (writing shader, writing custom tools, creating custom render feature for unity) tried gpt 4.5 to help me writing render feature and it fail every single time, and then when i tried claude 4 it works nicely sure i need to fix somethings but it&amp;#39;s almost perfect just need slight adjustment never feels this &amp;quot;free&amp;quot;, now i can focus on shader writing which is my favorite field&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qr2ut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855835,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qrviv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sunomonodekani","can_mod_post":false,"created_utc":1751856147,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_1lurun92nv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemini 1.5 PRO is infinitely superior to Llama, not only in website building but in everything else.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qrviv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemini 1.5 PRO is infinitely superior to Llama, not only in website building but in everything else.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qrviv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856147,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qupho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1751857283,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I feel like \\"best\\" is doing a lot of heavy lifting in the title here. Nonetheless great project!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qupho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I feel like &amp;quot;best&amp;quot; is doing a lot of heavy lifting in the title here. Nonetheless great project!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qupho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751857283,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1r3s6h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sam439","can_mod_post":false,"created_utc":1751861147,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_53hd8h4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For me Claude Sonnet 3.7 always failed for complex games. 2.5 Pro always one shot every game I tried. Recently, I built an anti-missile defense game with its own mini-ai and 3.7 Sonnet and R1 both failed horribly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r3s6h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For me Claude Sonnet 3.7 always failed for complex games. 2.5 Pro always one shot every game I tried. Recently, I built an anti-missile defense game with its own mini-ai and 3.7 Sonnet and R1 both failed horribly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r3s6h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751861147,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1r90ei","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"beezbos_trip","can_mod_post":false,"created_utc":1751863590,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_sn20tzjr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am a fan of llama in spirit, but it has never been good. It's just a cool thing to have available locally and a sign of what was to come in that space, which is still underway.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r90ei","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am a fan of llama in spirit, but it has never been good. It&amp;#39;s just a cool thing to have available locally and a sign of what was to come in that space, which is still underway.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r90ei/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751863590,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ra5jb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751864140,"send_replies":true,"parent_id":"t1_n1r9mn3","score":3,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just showed 2 screenshots, but you can see the [entire leaderboard here](https://www.designarena.ai/leaderboard).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ra5jb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just showed 2 screenshots, but you can see the &lt;a href=\\"https://www.designarena.ai/leaderboard\\"&gt;entire leaderboard here&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1ra5jb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751864140,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1r9mn3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MatterMean5176","can_mod_post":false,"created_utc":1751863886,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_1ju039btvf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So where are 11 through 17? Weird.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r9mn3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So where are 11 through 17? Weird.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r9mn3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751863886,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ri58x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Captain_D_Buggy","can_mod_post":false,"created_utc":1751868301,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_14o1on","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemini pro 2.5 was my go-to model in cursor but now replaced by claude 4 sonnet. Although it costs 2x now, it was 0.75x during preview offer. \\n\\nSurprised by deepseek being #2 there, never actually tried it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ri58x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemini pro 2.5 was my go-to model in cursor but now replaced by claude 4 sonnet. Although it costs 2x now, it was 0.75x during preview offer. &lt;/p&gt;\\n\\n&lt;p&gt;Surprised by deepseek being #2 there, never actually tried it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1ri58x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751868301,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rtp9d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751874937,"send_replies":true,"parent_id":"t1_n1rqcz3","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the suggestion!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rtp9d","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the suggestion!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rtp9d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751874937,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rqcz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nixellion","can_mod_post":false,"created_utc":1751872937,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_12fajr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Quite interesting. It would be nice to have similar test but with tasks requiring larger context. In my experience, for use with an agentic code editor like RooCode\\\\\\\\Cline 30K is needed for most projects except some very small projects, as well as model being capable of executing tool calls and knowing when and how to use them. This is where Codestral should shine, with it's large context and being just a 24B (or 22?) in size, and this is where DeepSeek Coder would likely fail with just 16K context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rqcz3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Quite interesting. It would be nice to have similar test but with tasks requiring larger context. In my experience, for use with an agentic code editor like RooCode\\\\Cline 30K is needed for most projects except some very small projects, as well as model being capable of executing tool calls and knowing when and how to use them. This is where Codestral should shine, with it&amp;#39;s large context and being just a 24B (or 22?) in size, and this is where DeepSeek Coder would likely fail with just 16K context.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rqcz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751872937,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rrp0i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redballooon","can_mod_post":false,"created_utc":1751873739,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_o80da","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What measures were taken to prevent random factors like biases of the audience from influencing the polls? For example a light theme is hugely unpopular in programming and gamer circles, so leaving the theme choice to the model may impact the vote  much more than it objectively should.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rrp0i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What measures were taken to prevent random factors like biases of the audience from influencing the polls? For example a light theme is hugely unpopular in programming and gamer circles, so leaving the theme choice to the model may impact the vote  much more than it objectively should.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rrp0i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751873739,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rspyd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shibe5","can_mod_post":false,"created_utc":1751874359,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_14bah0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In voting UI it doesn't have an option for a tie.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rspyd","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In voting UI it doesn&amp;#39;t have an option for a tie.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rspyd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751874359,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rx3mw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1751876986,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How do they know the votes were from people?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rx3mw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do they know the votes were from people?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rx3mw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751876986,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s7t5a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751883322,"send_replies":true,"parent_id":"t1_n1rxvb0","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s a great idea! Thanks for the suggestion","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s7t5a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s a great idea! Thanks for the suggestion&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s7t5a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751883322,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rxvb0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karim_acing_it","can_mod_post":false,"created_utc":1751877462,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_omawcpyf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Amazing effort, I added a prompt from my field as well and judged.\\n\\nI would suggest to use a \\"high water\\" method as in instead of selecting LLMs randomly, choose the ones with a higher likelihood that have had the fewest yet. As such, each LLM gets the same amount of challenges, making their scores comparable (maybe you do that already)? A strickt high water method  would distort the results though if all it does is pair the same 4 LLMs for many battles until everything evens out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rxvb0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Amazing effort, I added a prompt from my field as well and judged.&lt;/p&gt;\\n\\n&lt;p&gt;I would suggest to use a &amp;quot;high water&amp;quot; method as in instead of selecting LLMs randomly, choose the ones with a higher likelihood that have had the fewest yet. As such, each LLM gets the same amount of challenges, making their scores comparable (maybe you do that already)? A strickt high water method  would distort the results though if all it does is pair the same 4 LLMs for many battles until everything evens out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rxvb0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751877462,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1skq5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Persistent_Dry_Cough","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1s6okf","score":1,"author_fullname":"t2_pv39w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is less aligned, so it definitely has the wind at its back.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1skq5x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is less aligned, so it definitely has the wind at its back.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1skq5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751889568,"author_flair_text":null,"treatment_tags":[],"created_utc":1751889568,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1s6okf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751882691,"send_replies":true,"parent_id":"t1_n1s6c0o","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes that was a surprise for us too! Grok 3 seems to be quite a capable model. Will be super interesting to see how Grok 4 will perform when it’s released soon","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s6okf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes that was a surprise for us too! Grok 3 seems to be quite a capable model. Will be super interesting to see how Grok 4 will perform when it’s released soon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s6okf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751882691,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1s6c0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"created_utc":1751882491,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"im surprised grok-3 generated a competitive result at half or even 1/3 of the time as any other model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s6c0o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;im surprised grok-3 generated a competitive result at half or even 1/3 of the time as any other model&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s6c0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751882491,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1td4r4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751899455,"send_replies":true,"parent_id":"t1_n1srhq7","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the suggestion!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1td4r4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the suggestion!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1td4r4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751899455,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1srhq7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1751892296,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just to see if we can see a model with 'llama' in the name higher in this leaderboard, could you add llama Nemotron ultra\\n?\\n\\nbasically it is built on top of llama 3.1 405B from nvidia using Neural Architecture Search (the final model has ~235B param) plus continued pretraining / KD, SFT and RL for reasoning. (I think it is the 'biggest' open source reasoning model, at least in terms of active parameters since it is not a MoE). \\n\\nthe reasoning is both \\"distilled\\" from R1 with SFT and trained with RL \\nthe model include both reasoning on and off mode (like qwen 3)\\n\\nI used this model a lot via openrouter, and I really like it.... that model feels really 'smart', \\n\\nEDIT: 253B parameters, not 235B. my bad.\\n\\nhttps://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1 \\n\\nAlso, even the 49B (derived from llama 3.3 70B) is really interesting Imo (from my experience, it beat others R1 distilled into llama 70B, while being smaller)\\n\\n\\n\\nJust in case someone is interested, those are the related papers from Nvidia:\\n\\nhttps://arxiv.org/pdf/2505.00949 (Llama-Nemotron: Efficient Reasoning Models)\\n\\nhttps://arxiv.org/abs/2503.18908 (FFN Fusion: Rethinking Sequential Computation in Large Language Models)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1srhq7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just to see if we can see a model with &amp;#39;llama&amp;#39; in the name higher in this leaderboard, could you add llama Nemotron ultra\\n?&lt;/p&gt;\\n\\n&lt;p&gt;basically it is built on top of llama 3.1 405B from nvidia using Neural Architecture Search (the final model has ~235B param) plus continued pretraining / KD, SFT and RL for reasoning. (I think it is the &amp;#39;biggest&amp;#39; open source reasoning model, at least in terms of active parameters since it is not a MoE). &lt;/p&gt;\\n\\n&lt;p&gt;the reasoning is both &amp;quot;distilled&amp;quot; from R1 with SFT and trained with RL \\nthe model include both reasoning on and off mode (like qwen 3)&lt;/p&gt;\\n\\n&lt;p&gt;I used this model a lot via openrouter, and I really like it.... that model feels really &amp;#39;smart&amp;#39;, &lt;/p&gt;\\n\\n&lt;p&gt;EDIT: 253B parameters, not 235B. my bad.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1\\"&gt;https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Also, even the 49B (derived from llama 3.3 70B) is really interesting Imo (from my experience, it beat others R1 distilled into llama 70B, while being smaller)&lt;/p&gt;\\n\\n&lt;p&gt;Just in case someone is interested, those are the related papers from Nvidia:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/pdf/2505.00949\\"&gt;https://arxiv.org/pdf/2505.00949&lt;/a&gt; (Llama-Nemotron: Efficient Reasoning Models)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2503.18908\\"&gt;https://arxiv.org/abs/2503.18908&lt;/a&gt; (FFN Fusion: Rethinking Sequential Computation in Large Language Models)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1srhq7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751892296,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1tcyzl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751899407,"send_replies":true,"parent_id":"t1_n1tcn3w","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We’re going to be activate qwen back soon (just need to take it down on vertex ai bc we need more credits from google).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1tcyzl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We’re going to be activate qwen back soon (just need to take it down on vertex ai bc we need more credits from google).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tcyzl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751899407,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tcn3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"taoyx","can_mod_post":false,"created_utc":1751899308,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_s21rt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not surprised but Gemma and Qwen 3 are very solid. Qwen is better at coding but Gemma is vision enabled.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1tcn3w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not surprised but Gemma and Qwen 3 are very solid. Qwen is better at coding but Gemma is vision enabled.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1tcn3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751899308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1upsaj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Voxandr","can_mod_post":false,"created_utc":1751913845,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_86dk0gye","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How Deepseek coder above qwen3?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1upsaj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How Deepseek coder above qwen3?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1upsaj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751913845,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1v9zok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751920521,"send_replies":true,"parent_id":"t1_n1v95rg","score":2,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What biases do you think there are?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v9zok","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What biases do you think there are?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1v9zok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751920521,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1v95rg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SamWest98","can_mod_post":false,"created_utc":1751920243,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_1nifd7d825","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems like a very biased way to stack rank","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v95rg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems like a very biased way to stack rank&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1v95rg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751920243,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1x8r6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OGWashingMachine1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1x6hh3","score":1,"author_fullname":"t2_7ttl2kyy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, it's def expensive but has been very worth it in terms of what I can automate and have code, especially for doing work off of templates.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1x8r6a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, it&amp;#39;s def expensive but has been very worth it in terms of what I can automate and have code, especially for doing work off of templates.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1x8r6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751944387,"author_flair_text":null,"treatment_tags":[],"created_utc":1751944387,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1x6hh3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751943520,"send_replies":true,"parent_id":"t1_n1x31zn","score":2,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s pretty incredible for a lot of things with the exception of my bank account haha.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1x6hh3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s pretty incredible for a lot of things with the exception of my bank account haha.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1x6hh3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751943520,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1x31zn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OGWashingMachine1","can_mod_post":false,"created_utc":1751942264,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_7ttl2kyy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Opus has been incredible for me thus far in experimental propulsion and physics coding for my thesis work, UI dev for separate projects in python/JS/Css, and a concurrent app in C++. It’s also been incredible in pure python/html/dash dev of an accurate solar system model that I’m working on too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1x31zn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Opus has been incredible for me thus far in experimental propulsion and physics coding for my thesis work, UI dev for separate projects in python/JS/Css, and a concurrent app in C++. It’s also been incredible in pure python/html/dash dev of an accurate solar system model that I’m working on too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1x31zn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751942264,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xab50","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SadWolverine24","can_mod_post":false,"created_utc":1751944997,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_7a1jtru1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am surprised R1 can hold on with the new generation of models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xab50","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am surprised R1 can hold on with the new generation of models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1xab50/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751944997,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ycbjg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ashirviskas","can_mod_post":false,"created_utc":1751964296,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_9pixf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I found some 3D models totally borked. Then I vote randomly and turns out grok beats everything. Any way to say that all models are borked and not even rendered?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ycbjg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found some 3D models totally borked. Then I vote randomly and turns out grok beats everything. Any way to say that all models are borked and not even rendered?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1ycbjg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751964296,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qj1dm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mnt_brain","can_mod_post":false,"created_utc":1751852792,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_1mtt9dytfn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Claude is matching R1?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qj1dm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude is matching R1?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1qj1dm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751852792,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1r6drg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jesus_fucking_marry","can_mod_post":false,"created_utc":1751862343,"send_replies":true,"parent_id":"t3_1lthtbn","score":1,"author_fullname":"t2_r3aq0368","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Deepseek R1 is really good for frontend web development.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1r6drg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek R1 is really good for frontend web development.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1r6drg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751862343,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1req3l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adviceguru25","can_mod_post":false,"created_utc":1751866463,"send_replies":true,"parent_id":"t1_n1rczro","score":1,"author_fullname":"t2_c3b3edv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sorry we are planning to add glm we just need some more credits from Google 😢.\\n\\nCode is closed but all the data is open on the site. It’s just collected from votes that people are putting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1req3l","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry we are planning to add glm we just need some more credits from Google 😢.&lt;/p&gt;\\n\\n&lt;p&gt;Code is closed but all the data is open on the site. It’s just collected from votes that people are putting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lthtbn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1req3l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751866463,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1rczro","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"created_utc":1751865570,"send_replies":false,"parent_id":"t3_1lthtbn","score":0,"author_fullname":"t2_usojvms","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Bro still never tried Glm. You posted this the other day as well. Regardless without seeing the prompts the data is meaningless on the site. It's closed source so can't trust it not sure why it's on locallama..","edited":1751865877,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rczro","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bro still never tried Glm. You posted this the other day as well. Regardless without seeing the prompts the data is meaningless on the site. It&amp;#39;s closed source so can&amp;#39;t trust it not sure why it&amp;#39;s on locallama..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1rczro/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751865570,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1slsht","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ChezMere","can_mod_post":false,"created_utc":1751890018,"send_replies":true,"parent_id":"t3_1lthtbn","score":0,"author_fullname":"t2_8nm9m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's a reason Claude is what r/WebSim uses.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1slsht","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a reason Claude is what &lt;a href=\\"/r/WebSim\\"&gt;r/WebSim&lt;/a&gt; uses.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1slsht/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751890018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s3a4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"created_utc":1751880734,"send_replies":true,"parent_id":"t3_1lthtbn","score":-1,"author_fullname":"t2_c2f558x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is very sus.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s3a4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is very sus.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lthtbn/85k_people_voted_on_which_ai_models_create_the/n1s3a4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751880734,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lthtbn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
