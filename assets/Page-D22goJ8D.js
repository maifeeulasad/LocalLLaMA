import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi, im working on something that I havent seen anyone else do before, I trained nanoGPT on only books from a specifc time period and region of the world. I chose to do 1800-1850 London. My dataset was only 187mb (around 50 books). Right now the trained model produces random incoherent sentences but they do kind of feel like 1800s style sentences. My end goal is to create an LLM that doesnt pretend to be historical but just is, that's why I didn't go the fine tune route. It will have no modern bias and will only be able to reason within the time period it's trained on. It's super random and has no utility but I think if I train using a big dataset (like 600 books) the result will be super sick.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Training an LLM only on books from the 1800's - no modern bias","link_flair_richtext":[{"e":"text","t":"Other"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzampg","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":808,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1ink6kzg93","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Other","can_mod_post":false,"score":808,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=60dd42f39ab2b858d7a5af3cc6c9b33d8a7c0ec8","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752459413,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, im working on something that I havent seen anyone else do before, I trained nanoGPT on only books from a specifc time period and region of the world. I chose to do 1800-1850 London. My dataset was only 187mb (around 50 books). Right now the trained model produces random incoherent sentences but they do kind of feel like 1800s style sentences. My end goal is to create an LLM that doesnt pretend to be historical but just is, that&amp;#39;s why I didn&amp;#39;t go the fine tune route. It will have no modern bias and will only be able to reason within the time period it&amp;#39;s trained on. It&amp;#39;s super random and has no utility but I think if I train using a big dataset (like 600 books) the result will be super sick.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/haykgrigo3/TimeCapsuleLLM","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?auto=webp&amp;s=9ce4bc74d599d7799104a933627053a9a10d7d4b","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d44946a1ed6e59d2f29fe66c42efbdf9beadf176","width":108,"height":54},{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2de1efb7c3a13836541de0a4e25083dafe4cb75","width":216,"height":108},{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=200239be7df394436a63a82488ec3fea1a1981d4","width":320,"height":160},{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e60398c5e2e84881134a46e0acf601c56ba81942","width":640,"height":320},{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8fe73c59013abcf68f28e8e3ab9df30778338705","width":960,"height":480},{"url":"https://external-preview.redd.it/AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15f1bb851a628752877d4bae276313f481c7dcf5","width":1080,"height":540}],"variants":{},"id":"AiV4MAC3PG2xPq-j4g8nw6ZuH5_-LU4f7enDtlyUQUo"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"7a7848d2-bf8e-11ed-8c2f-765d15199f78","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#94e044","id":"1lzampg","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"Remarkable-Trick-177","discussion_type":null,"num_comments":198,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/","stickied":false,"url":"https://github.com/haykgrigo3/TimeCapsuleLLM","subreddit_subscribers":499297,"created_utc":1752459413,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30nrk6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1752465156,"send_replies":true,"parent_id":"t1_n30f2o9","score":80,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"*Oft, did my grandmother regale me of tales where..*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30nrk6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;em&gt;Oft, did my grandmother regale me of tales where..&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nrk6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465156,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":80}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n312zai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TrekkiMonstr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30inl9","score":35,"author_fullname":"t2_ta9bw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Off by like three centuries but","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n312zai","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Off by like three centuries but&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n312zai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752472373,"author_flair_text":null,"treatment_tags":[],"created_utc":1752472373,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31n0y0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"doodlinghearsay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30inl9","score":8,"author_fullname":"t2_1m2pinwbra","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IDK, I think it would get _old_ really fast.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31n0y0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IDK, I think it would get &lt;em&gt;old&lt;/em&gt; really fast.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31n0y0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483786,"author_flair_text":null,"treatment_tags":[],"created_utc":1752483786,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n30inl9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"opi098514","can_mod_post":false,"created_utc":1752463011,"send_replies":true,"parent_id":"t1_n30f2o9","score":76,"author_fullname":"t2_51dfdxum","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fuck that’s funny.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30inl9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuck that’s funny.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30inl9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463011,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":76}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30kv9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mayzyo","can_mod_post":false,"created_utc":1752463932,"send_replies":true,"parent_id":"t1_n30f2o9","score":14,"author_fullname":"t2_e48b686y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pure gold hahaha!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kv9h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pure gold hahaha!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30kv9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463932,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31yw1a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PaddyWhacked","can_mod_post":false,"created_utc":1752490339,"send_replies":true,"parent_id":"t1_n30f2o9","score":8,"author_fullname":"t2_6oeyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I feel like the assistant should be called \\"Squire\\" or similar. \\n\\n\\"Squire, inform Your Grace of rambunctious tales of the colonies\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31yw1a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I feel like the assistant should be called &amp;quot;Squire&amp;quot; or similar. &lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Squire, inform Your Grace of rambunctious tales of the colonies&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31yw1a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752490339,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32qi54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Limp_Classroom_2645","can_mod_post":false,"created_utc":1752500978,"send_replies":true,"parent_id":"t1_n30f2o9","score":2,"author_fullname":"t2_1lwf5vg68e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Assistant: \\"also what is gooning?\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32qi54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Assistant: &amp;quot;also what is gooning?&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32qi54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752500978,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30f2o9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752461583,"send_replies":true,"parent_id":"t3_1lzampg","score":575,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"User: \\"Regale me with tales of yon fair damsel's comely ankles\\n\\nAssistant: \\"Prithee forgive me, good sir; alas, I may not lend thee aid in this matter.\\"","edited":1752461818,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30f2o9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;User: &amp;quot;Regale me with tales of yon fair damsel&amp;#39;s comely ankles&lt;/p&gt;\\n\\n&lt;p&gt;Assistant: &amp;quot;Prithee forgive me, good sir; alas, I may not lend thee aid in this matter.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30f2o9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461583,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":575}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35qy25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrshadow773","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31rqod","score":3,"author_fullname":"t2_799zs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the kind words! \\n\\nThis mostly came out of a b200 rental deal we saw. We plan to write up a blog sometime soon talking about our experiences. interestingly the pdf processing itself starts to become a major bottleneck because even a single B200 is so fast","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35qy25","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the kind words! &lt;/p&gt;\\n\\n&lt;p&gt;This mostly came out of a b200 rental deal we saw. We plan to write up a blog sometime soon talking about our experiences. interestingly the pdf processing itself starts to become a major bottleneck because even a single B200 is so fast&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35qy25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752532043,"author_flair_text":null,"treatment_tags":[],"created_utc":1752532043,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n31rqod","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jasminUwU6","can_mod_post":false,"created_utc":1752486532,"send_replies":true,"parent_id":"t1_n30kb1y","score":25,"author_fullname":"t2_achkybp8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I love how I can find some absolute gems in Reddit comments. \\n\\nThank you for your work","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31rqod","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love how I can find some absolute gems in Reddit comments. &lt;/p&gt;\\n\\n&lt;p&gt;Thank you for your work&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31rqod/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752486532,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35qcpj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mrshadow773","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32gxzv","score":2,"author_fullname":"t2_799zs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’ve been waiting a long time for someone to find this funny, cheers","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35qcpj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve been waiting a long time for someone to find this funny, cheers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35qcpj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752531856,"author_flair_text":null,"treatment_tags":[],"created_utc":1752531856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n32gxzv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"westsunset","can_mod_post":false,"created_utc":1752497767,"send_replies":true,"parent_id":"t1_n30kb1y","score":18,"author_fullname":"t2_ffqgv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"'an LLM is only as good as the dataset it was trained on' - Sun Tzu\\" \\nlmao","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32gxzv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;&amp;#39;an LLM is only as good as the dataset it was trained on&amp;#39; - Sun Tzu&amp;quot; \\nlmao&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32gxzv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752497767,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35u8ia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllanSundry2020","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35tq00","score":1,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ensemble OCR, i like it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35u8ia","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ensemble OCR, i like it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35u8ia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752533098,"author_flair_text":null,"treatment_tags":[],"created_utc":1752533098,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n35tq00","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mrshadow773","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31kycy","score":2,"author_fullname":"t2_799zs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You’re welcome 🤗 \\n\\none thing you might find useful (we have yet to explore it but mean to at some point) is that the same books were OCR’d by page (split by \\\\f to get pages). It seems like any “OCR failures”/poor quality outputs by the models are in different places, so it should be possible to detect failures by page and use text from the other model’s outputs to create something that is overall better/cleaner than either","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n35tq00","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You’re welcome 🤗 &lt;/p&gt;\\n\\n&lt;p&gt;one thing you might find useful (we have yet to explore it but mean to at some point) is that the same books were OCR’d by page (split by \\\\f to get pages). It seems like any “OCR failures”/poor quality outputs by the models are in different places, so it should be possible to detect failures by page and use text from the other model’s outputs to create something that is overall better/cleaner than either&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35tq00/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752532932,"author_flair_text":null,"treatment_tags":[],"created_utc":1752532932,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n31kycy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AllanSundry2020","can_mod_post":false,"created_utc":1752482569,"send_replies":true,"parent_id":"t1_n30kb1y","score":5,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks this is helpful for me too. I have been relying on gutenberg and recent epubs of anthologies of older works","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31kycy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks this is helpful for me too. I have been relying on gutenberg and recent epubs of anthologies of older works&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31kycy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482569,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n37ripq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mrshadow773","can_mod_post":false,"send_replies":true,"parent_id":"t1_n376cua","score":1,"author_fullname":"t2_799zs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"awesome, hope it helps! if questions/something weird comes up feel free to ping me here (slower) or open a discussion/issue thing","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37ripq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;awesome, hope it helps! if questions/something weird comes up feel free to ping me here (slower) or open a discussion/issue thing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n37ripq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752559512,"author_flair_text":null,"treatment_tags":[],"created_utc":1752559512,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n376cua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752549786,"send_replies":true,"parent_id":"t1_n30kb1y","score":2,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you im checking it out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n376cua","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you im checking it out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n376cua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38deu0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllanSundry2020","can_mod_post":false,"send_replies":true,"parent_id":"t1_n37st69","score":1,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"do you not recommend docling then? that's helpful on the cpu as i would like to do in my laptop as well as mac studio","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38deu0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do you not recommend docling then? that&amp;#39;s helpful on the cpu as i would like to do in my laptop as well as mac studio&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n38deu0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752572016,"author_flair_text":null,"treatment_tags":[],"created_utc":1752572016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n37st69","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrshadow773","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31kzgv","score":4,"author_fullname":"t2_799zs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey - so yes, but it highly depends on what compute you're working with. \\n\\n- 24gb+ GPU - vllm inference with a recent VLM. This is what we used to OCR these books. You can see my comment [here](https://huggingface.co/reducto/RolmOCR/discussions/2#67f45de18a86dbdf7dbe3745) for a brief explanation + script for [rolmOCR](https://huggingface.co/reducto/RolmOCR), and [here](https://gist.github.com/pszemraj/549cf21db651ab970111d499dd38b7d4) for a [nanonets-s](https://huggingface.co/nanonets/Nanonets-OCR-s) based version.\\n- smaller GPU/CPU-only - I'd recommend checking out [marker](https://github.com/datalab-to/marker) which is more compute-efficient (*though I haven't tried it on CPU only*). You might also want to check out [this demo](https://huggingface.co/spaces/pszemraj/pdf-ocr) I made back in the day - it's CPU only.\\n  - In general for CPU only things you will have to be ok with at least one of: higher error rate, not being able to preserve formatting, having to add custom post-processing logic. Depending on what your PDFs are like (digital, scanned, quality, so on), you might be able to get away with it, or it might be terrible. Have to test to find out","edited":1752560597,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n37st69","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey - so yes, but it highly depends on what compute you&amp;#39;re working with. &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;24gb+ GPU - vllm inference with a recent VLM. This is what we used to OCR these books. You can see my comment &lt;a href=\\"https://huggingface.co/reducto/RolmOCR/discussions/2#67f45de18a86dbdf7dbe3745\\"&gt;here&lt;/a&gt; for a brief explanation + script for &lt;a href=\\"https://huggingface.co/reducto/RolmOCR\\"&gt;rolmOCR&lt;/a&gt;, and &lt;a href=\\"https://gist.github.com/pszemraj/549cf21db651ab970111d499dd38b7d4\\"&gt;here&lt;/a&gt; for a &lt;a href=\\"https://huggingface.co/nanonets/Nanonets-OCR-s\\"&gt;nanonets-s&lt;/a&gt; based version.&lt;/li&gt;\\n&lt;li&gt;smaller GPU/CPU-only - I&amp;#39;d recommend checking out &lt;a href=\\"https://github.com/datalab-to/marker\\"&gt;marker&lt;/a&gt; which is more compute-efficient (&lt;em&gt;though I haven&amp;#39;t tried it on CPU only&lt;/em&gt;). You might also want to check out &lt;a href=\\"https://huggingface.co/spaces/pszemraj/pdf-ocr\\"&gt;this demo&lt;/a&gt; I made back in the day - it&amp;#39;s CPU only.\\n\\n&lt;ul&gt;\\n&lt;li&gt;In general for CPU only things you will have to be ok with at least one of: higher error rate, not being able to preserve formatting, having to add custom post-processing logic. Depending on what your PDFs are like (digital, scanned, quality, so on), you might be able to get away with it, or it might be terrible. Have to test to find out&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n37st69/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752560192,"author_flair_text":null,"treatment_tags":[],"created_utc":1752560192,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n31kzgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllanSundry2020","can_mod_post":false,"created_utc":1752482588,"send_replies":true,"parent_id":"t1_n30kb1y","score":1,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"do you have any recommend for ocr libraries?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31kzgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do you have any recommend for ocr libraries?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31kzgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482588,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30kb1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mrshadow773","can_mod_post":false,"created_utc":1752463695,"send_replies":true,"parent_id":"t3_1lzampg","score":157,"author_fullname":"t2_799zs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi - myself and buddy have recently OCR’d some old books, many are from the 1800s. You might find this useful: [survivor library books](https://huggingface.co/collections/BEE-spoke-data/survivor-library-books-ocr-687477810a5c018512c2eb7c)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kb1y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi - myself and buddy have recently OCR’d some old books, many are from the 1800s. You might find this useful: &lt;a href=\\"https://huggingface.co/collections/BEE-spoke-data/survivor-library-books-ocr-687477810a5c018512c2eb7c\\"&gt;survivor library books&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30kb1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463695,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":157}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31abhc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"forgotpw3","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30st0v","score":14,"author_fullname":"t2_robumd5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Woah dude, it's a party. You should set your expectations and know that it's not supposed to be joyful.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n31abhc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Woah dude, it&amp;#39;s a party. You should set your expectations and know that it&amp;#39;s not supposed to be joyful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31abhc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752476369,"author_flair_text":null,"treatment_tags":[],"created_utc":1752476369,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n30st0v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Faugermire","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30lix6","score":46,"author_fullname":"t2_mvc9e5nhm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You must be fun at parties.","edited":false,"author_flair_css_class":null,"name":"t1_n30st0v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You must be fun at parties.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30st0v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467395,"author_flair_text":null,"collapsed":false,"created_utc":1752467395,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31k9nl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ApprehensiveBat3074","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30lix6","score":9,"author_fullname":"t2_165o7yz5fk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You must have a long list of provable accomplishments if you can speak so confidently about what will and won't work.","edited":false,"author_flair_css_class":null,"name":"t1_n31k9nl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You must have a long list of provable accomplishments if you can speak so confidently about what will and won&amp;#39;t work.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31k9nl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482162,"author_flair_text":null,"collapsed":false,"created_utc":1752482162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n30lix6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30l9e0","score":-68,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"It’s a fun project, you should just set your expectations correctly and know that it won’t work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30lix6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s a fun project, you should just set your expectations correctly and know that it won’t work.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30lix6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464208,"author_flair_text":null,"treatment_tags":[],"created_utc":1752464208,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-68}}],"before":null}},"user_reports":[],"saved":false,"id":"n30l9e0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hugganao","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30hunj","score":101,"author_fullname":"t2_jc5ns","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;&gt;It’s a terrible idea, because modern humans don’t really understand the cultural background of people in the 1800s unless you study history.\\n\\nthat's a overblown way to explain away an interesting project....\\n\\nat least op is creating a starting point on his objective. He will meet the problems sooner or later which he could tackle then. Whether it has utility or not will remain to be seen but people don't progress just because something has a use case.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30l9e0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;blockquote&gt;\\n&lt;p&gt;It’s a terrible idea, because modern humans don’t really understand the cultural background of people in the 1800s unless you study history.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;that&amp;#39;s a overblown way to explain away an interesting project....&lt;/p&gt;\\n\\n&lt;p&gt;at least op is creating a starting point on his objective. He will meet the problems sooner or later which he could tackle then. Whether it has utility or not will remain to be seen but people don&amp;#39;t progress just because something has a use case.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30l9e0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464096,"author_flair_text":null,"treatment_tags":[],"created_utc":1752464096,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":101}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31l8xy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hugganao","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31aqlb","score":4,"author_fullname":"t2_jc5ns","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"probably want to directly reply to op","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31l8xy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;probably want to directly reply to op&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31l8xy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482744,"author_flair_text":null,"treatment_tags":[],"created_utc":1752482744,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n31aqlb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IAmRobinGoodfellow","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30hunj","score":16,"author_fullname":"t2_1sslrprc30","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s … incorrect. It’s the 1800s, not the 1500s. Assuming we’re talking about English, I think that anyone who can read reddit with ease would be able to get through the average civil war era newspaper. \\n\\nWhich reminds me: OP, you should be able to grab newspapers, almanacs, scientific books and papers, and the like. I imagine the tough part is going to be curating, so look for big collections first.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31aqlb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s … incorrect. It’s the 1800s, not the 1500s. Assuming we’re talking about English, I think that anyone who can read reddit with ease would be able to get through the average civil war era newspaper. &lt;/p&gt;\\n\\n&lt;p&gt;Which reminds me: OP, you should be able to grab newspapers, almanacs, scientific books and papers, and the like. I imagine the tough part is going to be curating, so look for big collections first.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31aqlb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752476602,"author_flair_text":null,"treatment_tags":[],"created_utc":1752476602,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33gc2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clduab11","can_mod_post":false,"created_utc":1752508533,"send_replies":true,"parent_id":"t1_n33flfp","score":1,"author_fullname":"t2_uobka","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Couldn't agree more! I certainly wouldn't want anyone judging my generative AI work based on what I initially started with (thinking I got Claude to reveal its sysprompt LOL).","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n33gc2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Couldn&amp;#39;t agree more! I certainly wouldn&amp;#39;t want anyone judging my generative AI work based on what I initially started with (thinking I got Claude to reveal its sysprompt LOL).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33gc2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752508533,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n33flfp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shiroo_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32sll9","score":2,"author_fullname":"t2_178sj2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, it's just that I dont want to see potential good projects being called shit and discourage the person working on it, end of the day even if it amounts to nothing, you are still learning how everything works, which helps judging if an idea is good or bad, feasible or not, so really there is no point in being negative about it. And what's really annoying in this particular case is that the guy was giving good advice but for some reason being really negative about it instead of actually making someone grateful, it just ends up with most people unable to listen to advice given like that. Anyway really no point in being negative to someone trying to have fun, that's obvious","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n33flfp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, it&amp;#39;s just that I dont want to see potential good projects being called shit and discourage the person working on it, end of the day even if it amounts to nothing, you are still learning how everything works, which helps judging if an idea is good or bad, feasible or not, so really there is no point in being negative about it. And what&amp;#39;s really annoying in this particular case is that the guy was giving good advice but for some reason being really negative about it instead of actually making someone grateful, it just ends up with most people unable to listen to advice given like that. Anyway really no point in being negative to someone trying to have fun, that&amp;#39;s obvious&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33flfp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752508331,"author_flair_text":null,"treatment_tags":[],"created_utc":1752508331,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n32sll9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clduab11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31aegv","score":3,"author_fullname":"t2_uobka","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for this nuanced explanation!  Yeah, I definitely understood the incorrect part and kinda just hand-waved it off because obviously they were mistaken…but I guess within the amount of trawling I’ve done over the months, LocalLLaMA has evolved into this collective of super advanced machine learning engineers, absolute newbies, and…for lack of better words, some of the between I guess (and I consider myself an in-between’er)?\\n\\nSo usually, when I see people BOTH be dicks AND wrong, it’s easy to dismiss them as old curmudgeons or obviously they have zero clue what they’re talking about. But there’s a lot of “in-betweeners” I’m seeing that pick the absolute strangest hills to die on, and I think I’m conflating what I see go on with *that* versus people pearl clutching at every cockbag they see. \\n\\nYour explanation helps kinda attenuate that signal for me, so I appreciate you chiming in! Because yeah, I absolutely agree, if someone came up with me with cheap ass parts building an RC car and I’m in the mood? Bet we gonna figure out how to get that RC car rollin’ TODAY instead of putting on some fake lab coat and being all snotty about it.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n32sll9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this nuanced explanation!  Yeah, I definitely understood the incorrect part and kinda just hand-waved it off because obviously they were mistaken…but I guess within the amount of trawling I’ve done over the months, LocalLLaMA has evolved into this collective of super advanced machine learning engineers, absolute newbies, and…for lack of better words, some of the between I guess (and I consider myself an in-between’er)?&lt;/p&gt;\\n\\n&lt;p&gt;So usually, when I see people BOTH be dicks AND wrong, it’s easy to dismiss them as old curmudgeons or obviously they have zero clue what they’re talking about. But there’s a lot of “in-betweeners” I’m seeing that pick the absolute strangest hills to die on, and I think I’m conflating what I see go on with &lt;em&gt;that&lt;/em&gt; versus people pearl clutching at every cockbag they see. &lt;/p&gt;\\n\\n&lt;p&gt;Your explanation helps kinda attenuate that signal for me, so I appreciate you chiming in! Because yeah, I absolutely agree, if someone came up with me with cheap ass parts building an RC car and I’m in the mood? Bet we gonna figure out how to get that RC car rollin’ TODAY instead of putting on some fake lab coat and being all snotty about it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32sll9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752501633,"author_flair_text":null,"treatment_tags":[],"created_utc":1752501633,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n31aegv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bobisme","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ujsd","score":15,"author_fullname":"t2_41kv0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think in this case it's because the poster is being a dick about it (\\"it's a terrible idea\\") and is also wrong. If you look at it, it's a toy project built on nanogpt. It's an experiment. If it works, cool. If it doesn't, cool. Doesn't make it a terrible idea.\\n\\nIt's like if someone made a post about building an RC car with cheap parts to learn about the process and someone responds with \\"that's a terrible idea... The problem is most people don't understand physics... That will never set a land speed record.\\"","edited":1752506812,"author_flair_css_class":null,"name":"t1_n31aegv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think in this case it&amp;#39;s because the poster is being a dick about it (&amp;quot;it&amp;#39;s a terrible idea&amp;quot;) and is also wrong. If you look at it, it&amp;#39;s a toy project built on nanogpt. It&amp;#39;s an experiment. If it works, cool. If it doesn&amp;#39;t, cool. Doesn&amp;#39;t make it a terrible idea.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s like if someone made a post about building an RC car with cheap parts to learn about the process and someone responds with &amp;quot;that&amp;#39;s a terrible idea... The problem is most people don&amp;#39;t understand physics... That will never set a land speed record.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31aegv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752476413,"author_flair_text":null,"collapsed":false,"created_utc":1752476413,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n30ujsd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"clduab11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30lhc4","score":-17,"author_fullname":"t2_uobka","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Maybe I’M the one that’s just overreacting or something, but why does everyone seem SO bent out of shape about the way someone says something on Reddit?\\n\\nThese are words on a screen. No one gets the luxury of ANY sort of tone, or nuance, or emotive product. Who cares if this person thinks it’s a terrible idea? Certainly not OP, they’re gonna do it anyway.\\n\\n“I don’t see why it has to be said…”\\n“Why can’t you phrase it like…”\\n“What’s wrong with saying…”\\n\\nIt’s like every communication needs a metric shitpod of asterisks because people try to extrapolate SO much about someone or something’s words on a screen. Like some people are just fucking blunt and others need to just accept it and either push on/buzzoff.\\n\\nNot to pick on this comment or you in general, u/Shiroo_ , I happen to echo your sentiment entirely hence the chosen response…but sometimes, I’m gonna say something’s shit when something’s shit and if someone wants to pearl clutch over how I say something is shit? Well then, there ain’t shit else I can do for you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ujsd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe I’M the one that’s just overreacting or something, but why does everyone seem SO bent out of shape about the way someone says something on Reddit?&lt;/p&gt;\\n\\n&lt;p&gt;These are words on a screen. No one gets the luxury of ANY sort of tone, or nuance, or emotive product. Who cares if this person thinks it’s a terrible idea? Certainly not OP, they’re gonna do it anyway.&lt;/p&gt;\\n\\n&lt;p&gt;“I don’t see why it has to be said…”\\n“Why can’t you phrase it like…”\\n“What’s wrong with saying…”&lt;/p&gt;\\n\\n&lt;p&gt;It’s like every communication needs a metric shitpod of asterisks because people try to extrapolate SO much about someone or something’s words on a screen. Like some people are just fucking blunt and others need to just accept it and either push on/buzzoff.&lt;/p&gt;\\n\\n&lt;p&gt;Not to pick on this comment or you in general, &lt;a href=\\"/u/Shiroo_\\"&gt;u/Shiroo_&lt;/a&gt; , I happen to echo your sentiment entirely hence the chosen response…but sometimes, I’m gonna say something’s shit when something’s shit and if someone wants to pearl clutch over how I say something is shit? Well then, there ain’t shit else I can do for you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ujsd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468196,"author_flair_text":null,"treatment_tags":[],"created_utc":1752468196,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-17}}],"before":null}},"user_reports":[],"saved":false,"id":"n30lhc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Shiroo_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30hunj","score":26,"author_fullname":"t2_178sj2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's still a good idea, I dont see why you have to say it this way and be negative about it instead of actually providing good advice to make this guy project a success. \\n\\nYou made some good point honestly so hopefully OP will think about it","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30lhc4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s still a good idea, I dont see why you have to say it this way and be negative about it instead of actually providing good advice to make this guy project a success. &lt;/p&gt;\\n\\n&lt;p&gt;You made some good point honestly so hopefully OP will think about it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30lhc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464190,"author_flair_text":null,"treatment_tags":[],"created_utc":1752464190,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n358ljt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bsenftner","can_mod_post":false,"send_replies":true,"parent_id":"t1_n354bfi","score":2,"author_fullname":"t2_6eldx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, people could \\"talk\\" with these past trained LLMs, but a good number of understandings and customs of that time would be taken out of context, applied to our values, and and that series of LLM gets declared \\"harmful\\", requiring censorship before pubic exposure. \\n\\nThen there are the subtleties of language that are being misunderstood by LLMs currently. \\n\\nFor example, every topic you can imagine is in the training data multiple times, but with different treatments that vary from formal to attempts at humor using that subject. LLMs do not know which is which, and use the style of the words in the user's prompt to select the most similar words and phrasing style in the training data in which to generate an answer. That subtle aspect is not understood, and is the reason many people get poor quality answers from LLMs - they are not specific in use of formal terms, so they get replies from the less formal training data. \\n\\nFor people to converse with an LLM trained on period literature, one would need a foundation level LLM to handle that translation of the user's prompt, and then that response needs to be translated back, and the reference perspective probably needs to be specified too, to the translating LLM. A foundation level LLM would be needed because it's translating a time period's cultural context, something LLMs are not ordinarily trained to do. They are trained to do language translation, but time period translation is not ordinarily in training data. This might require a special fine tuning of a foundation model for use as the translating LLM;  It's all possible, but most public users will not really understand why the translator LLM is needed, and a good amount of the nuance that is the essence of that time period trained LLM would be muddled if not lost. \\n\\nThe ease of offending either side in these 'conversations' will be high. \\n\\nOn the other hand, if we're talking these as special purpose use, for formal historical study, and the users are specialists, such as graduate students studying that time period, that's a different story.","edited":false,"author_flair_css_class":null,"name":"t1_n358ljt","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, people could &amp;quot;talk&amp;quot; with these past trained LLMs, but a good number of understandings and customs of that time would be taken out of context, applied to our values, and and that series of LLM gets declared &amp;quot;harmful&amp;quot;, requiring censorship before pubic exposure. &lt;/p&gt;\\n\\n&lt;p&gt;Then there are the subtleties of language that are being misunderstood by LLMs currently. &lt;/p&gt;\\n\\n&lt;p&gt;For example, every topic you can imagine is in the training data multiple times, but with different treatments that vary from formal to attempts at humor using that subject. LLMs do not know which is which, and use the style of the words in the user&amp;#39;s prompt to select the most similar words and phrasing style in the training data in which to generate an answer. That subtle aspect is not understood, and is the reason many people get poor quality answers from LLMs - they are not specific in use of formal terms, so they get replies from the less formal training data. &lt;/p&gt;\\n\\n&lt;p&gt;For people to converse with an LLM trained on period literature, one would need a foundation level LLM to handle that translation of the user&amp;#39;s prompt, and then that response needs to be translated back, and the reference perspective probably needs to be specified too, to the translating LLM. A foundation level LLM would be needed because it&amp;#39;s translating a time period&amp;#39;s cultural context, something LLMs are not ordinarily trained to do. They are trained to do language translation, but time period translation is not ordinarily in training data. This might require a special fine tuning of a foundation model for use as the translating LLM;  It&amp;#39;s all possible, but most public users will not really understand why the translator LLM is needed, and a good amount of the nuance that is the essence of that time period trained LLM would be muddled if not lost. &lt;/p&gt;\\n\\n&lt;p&gt;The ease of offending either side in these &amp;#39;conversations&amp;#39; will be high. &lt;/p&gt;\\n\\n&lt;p&gt;On the other hand, if we&amp;#39;re talking these as special purpose use, for formal historical study, and the users are specialists, such as graduate students studying that time period, that&amp;#39;s a different story.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n358ljt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752526568,"author_flair_text":"Llama 3","collapsed":false,"created_utc":1752526568,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n354bfi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ChristopherRoberto","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32bgog","score":2,"author_fullname":"t2_9k391xhs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If we can so easily communicate cross-language today with help of translation, I don't see why it would be so impossible to talk to something speaking easily understood English from 200 years ago.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n354bfi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If we can so easily communicate cross-language today with help of translation, I don&amp;#39;t see why it would be so impossible to talk to something speaking easily understood English from 200 years ago.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n354bfi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525366,"author_flair_text":null,"treatment_tags":[],"created_utc":1752525366,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n32bgog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bsenftner","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30hunj","score":2,"author_fullname":"t2_6eldx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is also the manner in which LLMs work: no one modern knows how to communicate conversationally in 1800-1850 language, which is not our language, we have a huge number of \\"modern\\" words that are not present in 1850, and using them would confuse that LLM quite a bit, taking it out of whatever context one hopes to have for answering questions about that era.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n32bgog","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is also the manner in which LLMs work: no one modern knows how to communicate conversationally in 1800-1850 language, which is not our language, we have a huge number of &amp;quot;modern&amp;quot; words that are not present in 1850, and using them would confuse that LLM quite a bit, taking it out of whatever context one hopes to have for answering questions about that era.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32bgog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752495752,"author_flair_text":"Llama 3","treatment_tags":[],"created_utc":1752495752,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32lhk0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MediocreBye","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30hunj","score":2,"author_fullname":"t2_8d235x8y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"but what better way to understand the culture than through predictive conversations with an LLM. We are literally recreating a fictional individual based on 1800s written word here. It's cool.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n32lhk0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;but what better way to understand the culture than through predictive conversations with an LLM. We are literally recreating a fictional individual based on 1800s written word here. It&amp;#39;s cool.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32lhk0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752499323,"author_flair_text":null,"treatment_tags":[],"created_utc":1752499323,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30hunj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1752462682,"send_replies":true,"parent_id":"t1_n30axyr","score":-123,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s a terrible idea, because modern humans don’t really understand the cultural background of people in the 1800s unless you study history.\\n\\nThis was the era where the educated still heavily focused on a liberal arts education! That means the context of much of the writing was not in *english*, but rather *latin* and *greek*. You would also want *several* copies of the bible in there. \\n\\nThe lower layers of the model would be trained on english data, but the features that should be located in higher layers of the models aren’t actually in an english training dataset.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30hunj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s a terrible idea, because modern humans don’t really understand the cultural background of people in the 1800s unless you study history.&lt;/p&gt;\\n\\n&lt;p&gt;This was the era where the educated still heavily focused on a liberal arts education! That means the context of much of the writing was not in &lt;em&gt;english&lt;/em&gt;, but rather &lt;em&gt;latin&lt;/em&gt; and &lt;em&gt;greek&lt;/em&gt;. You would also want &lt;em&gt;several&lt;/em&gt; copies of the bible in there. &lt;/p&gt;\\n\\n&lt;p&gt;The lower layers of the model would be trained on english data, but the features that should be located in higher layers of the models aren’t actually in an english training dataset.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30hunj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462682,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-123}}],"before":null}},"user_reports":[],"saved":false,"id":"n30axyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"blurredphotos","can_mod_post":false,"created_utc":1752460020,"send_replies":true,"parent_id":"t3_1lzampg","score":170,"author_fullname":"t2_9qd6yhwf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is a fantastic idea. Can't wait to see.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30axyr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a fantastic idea. Can&amp;#39;t wait to see.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30axyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":170}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n329xlv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1752495156,"send_replies":true,"parent_id":"t1_n30e8fu","score":3,"author_fullname":"t2_zws5yqyow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Feels like training wan 1.3b loras, trained hundreds of loras, takes a lot of high quality videos and captioning that's very descriptive and unambiguous and tons of different network rank/batch sizes to get a good lora. Train the 14b and you can have meh data and captioning and get a good lora so much easier, just requires a shitload more VRAM and time. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n329xlv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Feels like training wan 1.3b loras, trained hundreds of loras, takes a lot of high quality videos and captioning that&amp;#39;s very descriptive and unambiguous and tons of different network rank/batch sizes to get a good lora. Train the 14b and you can have meh data and captioning and get a good lora so much easier, just requires a shitload more VRAM and time. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n329xlv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752495156,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n373vxe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeithonKing","can_mod_post":false,"created_utc":1752548812,"send_replies":true,"parent_id":"t1_n30e8fu","score":1,"author_fullname":"t2_bul2x6po","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much was the loss though? 1 year ago I had trained it on the full and I could get about 2.8 afaik...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n373vxe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much was the loss though? 1 year ago I had trained it on the full and I could get about 2.8 afaik...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n373vxe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548812,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-11,"removal_reason":null,"link_id":"t3_1lzampg","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30iutu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vegatx40","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30h8z9","score":19,"author_fullname":"t2_18dhiarv40","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No not the entire web The version used to train GPT 2. Sorry for not being clear","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30iutu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No not the entire web The version used to train GPT 2. Sorry for not being clear&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30iutu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463093,"author_flair_text":null,"treatment_tags":[],"created_utc":1752463093,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31eszh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"istinetz_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30h8z9","score":16,"author_fullname":"t2_nllj02sel","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the \\"open web text file\\" refers to a specific dataset","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31eszh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the &amp;quot;open web text file&amp;quot; refers to a specific dataset&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31eszh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752478952,"author_flair_text":null,"treatment_tags":[],"created_utc":1752478952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"n30h8z9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30e8fu","score":-11,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30h8z9/","num_reports":null,"locked":false,"name":"t1_n30h8z9","created":1752462437,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1752462437,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n30e8fu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vegatx40","can_mod_post":false,"created_utc":1752461258,"send_replies":true,"parent_id":"t3_1lzampg","score":50,"author_fullname":"t2_18dhiarv40","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I trained nano GP on a 5% sample of the open web text file. total gibberish until about a thousand training runs at which point it became somewhat coherent","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30e8fu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I trained nano GP on a 5% sample of the open web text file. total gibberish until about a thousand training runs at which point it became somewhat coherent&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30e8fu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461258,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31o9ci","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hugi_R","can_mod_post":false,"created_utc":1752484517,"send_replies":true,"parent_id":"t1_n311ay2","score":20,"author_fullname":"t2_13s1u9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The recent OpenCulture dataset from CommonCorpus list \\\\~90M documents, for \\\\~0.9T tokens, with a good chunk from before 1900.\\n\\nhttps://preview.redd.it/ad8ptdnu2tcf1.png?width=857&amp;format=png&amp;auto=webp&amp;s=afe712341ea33c9d5b9a07432cd7cc74c75603f5\\n\\n[https://huggingface.co/datasets/storytracer/US-PD-Books](https://huggingface.co/datasets/storytracer/US-PD-Books) has around 300k english books from 1800s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31o9ci","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The recent OpenCulture dataset from CommonCorpus list ~90M documents, for ~0.9T tokens, with a good chunk from before 1900.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/ad8ptdnu2tcf1.png?width=857&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=afe712341ea33c9d5b9a07432cd7cc74c75603f5\\"&gt;https://preview.redd.it/ad8ptdnu2tcf1.png?width=857&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=afe712341ea33c9d5b9a07432cd7cc74c75603f5&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/datasets/storytracer/US-PD-Books\\"&gt;https://huggingface.co/datasets/storytracer/US-PD-Books&lt;/a&gt; has around 300k english books from 1800s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31o9ci/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752484517,"media_metadata":{"ad8ptdnu2tcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":90,"x":108,"u":"https://preview.redd.it/ad8ptdnu2tcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=09a95553772fbdd36eea028a91cdf2bbf04b4504"},{"y":181,"x":216,"u":"https://preview.redd.it/ad8ptdnu2tcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a6a0286569f24b1ae166316df9ce0232cf3345"},{"y":269,"x":320,"u":"https://preview.redd.it/ad8ptdnu2tcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=75581e16c9d0080eb179b38724649f6d40677fc6"},{"y":538,"x":640,"u":"https://preview.redd.it/ad8ptdnu2tcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0de2897b02bda9c471fc2c5570c9cdf923ddc81"}],"s":{"y":721,"x":857,"u":"https://preview.redd.it/ad8ptdnu2tcf1.png?width=857&amp;format=png&amp;auto=webp&amp;s=afe712341ea33c9d5b9a07432cd7cc74c75603f5"},"id":"ad8ptdnu2tcf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"n311ay2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Maykey","can_mod_post":false,"created_utc":1752471516,"send_replies":true,"parent_id":"t3_1lzampg","score":32,"author_fullname":"t2_17tuu7pv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; I havent seen anyone else do before\\n\\nThe \\"popular\\" training dataset for old books is pg-19 with ~30K books and ~2B tokens, it's books from Project Guttenberg before 1919. It was used in [mambabyte](https://huggingface.co/JunxiongWang/MambaByte_PG19_972M), well it was used in many places, but mambabyte is definitely where it was the only dataset.\\n\\n&gt; 187mb\\n\\nProblem is 187MB text is about what, 40M tokens. That's  very few interaction between tokens to learn each other, especially in small context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n311ay2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I havent seen anyone else do before&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The &amp;quot;popular&amp;quot; training dataset for old books is pg-19 with ~30K books and ~2B tokens, it&amp;#39;s books from Project Guttenberg before 1919. It was used in &lt;a href=\\"https://huggingface.co/JunxiongWang/MambaByte_PG19_972M\\"&gt;mambabyte&lt;/a&gt;, well it was used in many places, but mambabyte is definitely where it was the only dataset.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;187mb&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Problem is 187MB text is about what, 40M tokens. That&amp;#39;s  very few interaction between tokens to learn each other, especially in small context.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n311ay2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471516,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n328te0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kyla_3049","can_mod_post":false,"send_replies":true,"parent_id":"t1_n318jiq","score":1,"author_fullname":"t2_smx7ei4l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"500-600 books.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n328te0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;500-600 books.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n328te0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752494713,"author_flair_text":null,"treatment_tags":[],"created_utc":1752494713,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n318jiq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Formal_Drop526","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30cdem","score":23,"author_fullname":"t2_dtsa6gxt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gpt-2's dataset is 3 billion token or 8 million documents. How large of a dataset do you plan on doing? GPT-2 can hardly reason.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n318jiq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gpt-2&amp;#39;s dataset is 3 billion token or 8 million documents. How large of a dataset do you plan on doing? GPT-2 can hardly reason.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n318jiq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475390,"author_flair_text":null,"treatment_tags":[],"created_utc":1752475390,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30rx4v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Affectionate-Hat-536","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30l48j","score":7,"author_fullname":"t2_7htykppj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol","edited":false,"author_flair_css_class":null,"name":"t1_n30rx4v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30rx4v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752466987,"author_flair_text":null,"collapsed":false,"created_utc":1752466987,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n30l48j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cguy1234","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30jpwq","score":75,"author_fullname":"t2_mhjuy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Only 1820’s kids will get this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30l48j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Only 1820’s kids will get this&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30l48j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464037,"author_flair_text":null,"treatment_tags":[],"created_utc":1752464037,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":75}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31i16p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AllanSundry2020","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30jpwq","score":1,"author_fullname":"t2_5tvkhk4q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Napoleon: dynamite!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31i16p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Napoleon: dynamite!!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31i16p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752480828,"author_flair_text":null,"treatment_tags":[],"created_utc":1752480828,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30jpwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Daniel_H212","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30cdem","score":40,"author_fullname":"t2_1vi6fut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe they'll make sense to people from the 1800s?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30jpwq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe they&amp;#39;ll make sense to people from the 1800s?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30jpwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463448,"author_flair_text":null,"treatment_tags":[],"created_utc":1752463448,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n339r2z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Divniy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31nrah","score":8,"author_fullname":"t2_11lbij","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He asks a reasonable question given the amount of training data. LLM couldn't happen without the vast amount of data currently available in the internet. Even if you feed all the 1800's books into them, it won't be enough to make it intelligent.\\n\\nSome LORA over existing model would be able to teach all the vibes of the training data over existing brains, and would be more practical.","edited":false,"author_flair_css_class":null,"name":"t1_n339r2z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He asks a reasonable question given the amount of training data. LLM couldn&amp;#39;t happen without the vast amount of data currently available in the internet. Even if you feed all the 1800&amp;#39;s books into them, it won&amp;#39;t be enough to make it intelligent.&lt;/p&gt;\\n\\n&lt;p&gt;Some LORA over existing model would be able to teach all the vibes of the training data over existing brains, and would be more practical.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n339r2z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752506673,"author_flair_text":null,"collapsed":false,"created_utc":1752506673,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n31nrah","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WorriedBlock2505","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31e0xp","score":16,"author_fullname":"t2_1f4nn04qvf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Why are you training a model from scratch?\\n\\n... it's answered in the OP. Don't be lazy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31nrah","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Why are you training a model from scratch?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;... it&amp;#39;s answered in the OP. Don&amp;#39;t be lazy.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31nrah/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752484217,"author_flair_text":null,"treatment_tags":[],"created_utc":1752484217,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31km4u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"MagicaItux","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31e0xp","score":-9,"author_fullname":"t2_h7lo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Do not use mistral. It is the most evil model I have come across","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31km4u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do not use mistral. It is the most evil model I have come across&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31km4u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482369,"author_flair_text":null,"treatment_tags":[],"created_utc":1752482369,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-9}}],"before":null}},"user_reports":[],"saved":false,"id":"n31e0xp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"dugavo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30cdem","score":-6,"author_fullname":"t2_1nge67um4h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why are you training a model from scratch? Wouldn't fine-tuning a larger model (such as, idk, Mistral Small or Qwen or something else) have better baseline reasoning? Sure, it would be biased towards modern thinking, but a good fine-tuning will gradually reduce that.\\n\\nEDIT: Additionally, the architecture of GPT-2 is very outdated. You might also benefit from a more modern architecture.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31e0xp","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why are you training a model from scratch? Wouldn&amp;#39;t fine-tuning a larger model (such as, idk, Mistral Small or Qwen or something else) have better baseline reasoning? Sure, it would be biased towards modern thinking, but a good fine-tuning will gradually reduce that.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Additionally, the architecture of GPT-2 is very outdated. You might also benefit from a more modern architecture.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31e0xp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752478488,"author_flair_text":null,"treatment_tags":[],"created_utc":1752478488,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"n30cdem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752460554,"send_replies":true,"parent_id":"t1_n30c5j6","score":50,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My end goal later on with a much bigger dataset, right now with just 50 books it produces random sentences that make no sesne.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30cdem","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My end goal later on with a much bigger dataset, right now with just 50 books it produces random sentences that make no sesne.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30cdem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460554,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}}],"before":null}},"user_reports":[],"saved":false,"id":"n30c5j6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ninjasaid13","can_mod_post":false,"created_utc":1752460471,"send_replies":true,"parent_id":"t3_1lzampg","score":90,"author_fullname":"t2_qjpsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;and will only be able to reason within the time period it's trained on.\\n\\nhow would a small model with absolutely no priors trained on 50 books be able to reason at all?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30c5j6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;and will only be able to reason within the time period it&amp;#39;s trained on.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;how would a small model with absolutely no priors trained on 50 books be able to reason at all?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30c5j6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460471,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":90}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30ll0v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hugganao","can_mod_post":false,"created_utc":1752464233,"send_replies":true,"parent_id":"t1_n30jjek","score":13,"author_fullname":"t2_jc5ns","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you should actually provide some good sources op can train on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ll0v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you should actually provide some good sources op can train on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ll0v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464233,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n30jjek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Aware-Presentation-9","can_mod_post":false,"created_utc":1752463374,"send_replies":true,"parent_id":"t3_1lzampg","score":20,"author_fullname":"t2_5pqmgkwu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a Math and Physics degree, with a Minor in Philosophy and Religion. This is a freaking pipe-dream to me! Great work sir! I love it. Add in Men of Mathematics?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30jjek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a Math and Physics degree, with a Minor in Philosophy and Religion. This is a freaking pipe-dream to me! Great work sir! I love it. Add in Men of Mathematics?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30jjek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463374,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32dvxw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"profcuck","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ysd8","score":7,"author_fullname":"t2_qc2xc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But I think the point is that with too few tokens, your model isn't really going to get to the point of being able to say anything much of any sense at all. \\n\\nTraining on as much content as you can possibly find that pre-dates your cut-off date is a very reasonable approach.  And yes, having trouble finding stuff is totally understandable, you're doing this for fun after all.  But still, the more you can feed in, the more interesting this gets.\\n\\nYou might consider picking a different cut-off date simply because the availability of texts explodes after a certain date.   \\n\\nAn interesting arbitrary date might be 1929 - everything published then or before is not copyright and therefore in the public domain (so the legality is not in question).   \\n\\nA person who magically materialized here all these years later wouldn't have much trouble understanding questions and conversations, and it would be fun to play with what it might say about modern inventions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n32dvxw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But I think the point is that with too few tokens, your model isn&amp;#39;t really going to get to the point of being able to say anything much of any sense at all. &lt;/p&gt;\\n\\n&lt;p&gt;Training on as much content as you can possibly find that pre-dates your cut-off date is a very reasonable approach.  And yes, having trouble finding stuff is totally understandable, you&amp;#39;re doing this for fun after all.  But still, the more you can feed in, the more interesting this gets.&lt;/p&gt;\\n\\n&lt;p&gt;You might consider picking a different cut-off date simply because the availability of texts explodes after a certain date.   &lt;/p&gt;\\n\\n&lt;p&gt;An interesting arbitrary date might be 1929 - everything published then or before is not copyright and therefore in the public domain (so the legality is not in question).   &lt;/p&gt;\\n\\n&lt;p&gt;A person who magically materialized here all these years later wouldn&amp;#39;t have much trouble understanding questions and conversations, and it would be fun to play with what it might say about modern inventions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32dvxw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752496670,"author_flair_text":null,"treatment_tags":[],"created_utc":1752496670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n376pzq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"send_replies":true,"parent_id":"t1_n317yxp","score":2,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Should I do a 100 year time period then? 1800-1900","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n376pzq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should I do a 100 year time period then? 1800-1900&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n376pzq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549933,"author_flair_text":null,"treatment_tags":[],"created_utc":1752549933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n317yxp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jam_pod_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ysd8","score":6,"author_fullname":"t2_12ynzp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would honestly expand your window forwards a bit — the 1850s was when publishing really started to become democratized, so by stopping at 1850 you’re cutting out a lot of potential material","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n317yxp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would honestly expand your window forwards a bit — the 1850s was when publishing really started to become democratized, so by stopping at 1850 you’re cutting out a lot of potential material&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n317yxp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475071,"author_flair_text":null,"treatment_tags":[],"created_utc":1752475071,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32a8rz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"food-dood","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ysd8","score":4,"author_fullname":"t2_4xuxqokw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can write a script to scrape the early English books online (EEBO) database and convert the results to text files. Over 20,000 results in that database.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n32a8rz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can write a script to scrape the early English books online (EEBO) database and convert the results to text files. Over 20,000 results in that database.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32a8rz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752495279,"author_flair_text":null,"treatment_tags":[],"created_utc":1752495279,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n30ysd8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752470236,"send_replies":true,"parent_id":"t1_n30kx9l","score":5,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I actually originally wanted to go 1700-1750 but for the long term I think going 19th century will be better because there's more digitized material to go off of. I had some trouble finding .txt files for 1700's stuff.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ysd8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually originally wanted to go 1700-1750 but for the long term I think going 19th century will be better because there&amp;#39;s more digitized material to go off of. I had some trouble finding .txt files for 1700&amp;#39;s stuff.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ysd8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n30kx9l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eden1506","can_mod_post":false,"created_utc":1752463955,"send_replies":true,"parent_id":"t3_1lzampg","score":25,"author_fullname":"t2_2ezqqypt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very interesting idea but your dataset is too small. \\nInstead of using books from between 1800-1850 you should consider using all works prior to 1850, knowledge is built on top of prior knowledge and including earlier works shouldn't hinder your goal.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kx9l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very interesting idea but your dataset is too small. \\nInstead of using books from between 1800-1850 you should consider using all works prior to 1850, knowledge is built on top of prior knowledge and including earlier works shouldn&amp;#39;t hinder your goal.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30kx9l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463955,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n323tgp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"itsmebenji69","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30gbce","score":2,"author_fullname":"t2_c4it8vu3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great idea yeah","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n323tgp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great idea yeah&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n323tgp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752492612,"author_flair_text":null,"treatment_tags":[],"created_utc":1752492612,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30gbce","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kincar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30bv2k","score":32,"author_fullname":"t2_ae8zb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Feed it as many auto-biographies and journals from that era as you can. I think that would make it think like they are from that time?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30gbce","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Feed it as many auto-biographies and journals from that era as you can. I think that would make it think like they are from that time?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30gbce/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462071,"author_flair_text":null,"treatment_tags":[],"created_utc":1752462071,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31lunj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cromagnone","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30bv2k","score":7,"author_fullname":"t2_2lu27","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You’re making the AI-mish?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31lunj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You’re making the AI-mish?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31lunj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483095,"author_flair_text":null,"treatment_tags":[],"created_utc":1752483095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"body":"So the wealthy, privileged, and clergy. Maybe clergy is redundant in that list.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36majj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"asciimo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30bv2k","score":1,"author_fullname":"t2_26jpt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n36majj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So the wealthy, privileged, and clergy. Maybe clergy is redundant in that list.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n36majj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752542508,"author_flair_text":null,"treatment_tags":[],"created_utc":1752542508,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30bv2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752460362,"send_replies":true,"parent_id":"t1_n30bala","score":38,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can't disagree, this cannot recreate an 1800's mind or way of thinking but you can limit the models knowledge to what someone in the 1800's would be reading or writing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30bv2k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t disagree, this cannot recreate an 1800&amp;#39;s mind or way of thinking but you can limit the models knowledge to what someone in the 1800&amp;#39;s would be reading or writing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30bv2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460362,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31wb97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slowhill369","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3165al","score":1,"author_fullname":"t2_96zelxcg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I misunderstood their comment. I thought they had trained a model on nothing but those books. I somehow missed the NanoGPT part. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31wb97","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I misunderstood their comment. I thought they had trained a model on nothing but those books. I somehow missed the NanoGPT part. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31wb97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752489042,"author_flair_text":null,"treatment_tags":[],"created_utc":1752489042,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3165al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llmentry","can_mod_post":false,"created_utc":1752474067,"send_replies":true,"parent_id":"t1_n30bala","score":4,"author_fullname":"t2_1lufy6yx6z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you explain more what you mean by this?  The pre-training phase is obviously not an issue here.  Instruction fine-tuning should be achievable using some of primer texts / Q&amp;A texts that were published in the period, without adding in any anachronisms.  At worst, you could use a current LLM with an appropriate system prompt, e.g. \\n\\n&gt;You are an LLM trained only on written materials created prior to 1880.  Your knowledge cutoff is 1880-06-23.  The current date is 23 Jan 1881.  You have no knowledge of any events, details or data after your knowledge cutoff date.  Ignore any training material, words or forms of speech pertaining to come from after your knowledge date, as these have clearly been fabricated.\\n\\nto generate additional synthetic instruct data appropriate to the time period (and potentially iterate from there).\\n\\nThe \\"intellectual foundation\\" should derive mostly from the underlying training data, I think?  (Where do current LLMs get their intellectual foundation from, if not from their training data?)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3165al","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you explain more what you mean by this?  The pre-training phase is obviously not an issue here.  Instruction fine-tuning should be achievable using some of primer texts / Q&amp;amp;A texts that were published in the period, without adding in any anachronisms.  At worst, you could use a current LLM with an appropriate system prompt, e.g. &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;You are an LLM trained only on written materials created prior to 1880.  Your knowledge cutoff is 1880-06-23.  The current date is 23 Jan 1881.  You have no knowledge of any events, details or data after your knowledge cutoff date.  Ignore any training material, words or forms of speech pertaining to come from after your knowledge date, as these have clearly been fabricated.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;to generate additional synthetic instruct data appropriate to the time period (and potentially iterate from there).&lt;/p&gt;\\n\\n&lt;p&gt;The &amp;quot;intellectual foundation&amp;quot; should derive mostly from the underlying training data, I think?  (Where do current LLMs get their intellectual foundation from, if not from their training data?)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3165al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752474067,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n30bala","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Slowhill369","can_mod_post":false,"created_utc":1752460149,"send_replies":true,"parent_id":"t3_1lzampg","score":33,"author_fullname":"t2_96zelxcg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think there’s a fundamental reasoning flaw here that comes from not having the intellectual foundation that someone from the 1800s would have. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30bala","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think there’s a fundamental reasoning flaw here that comes from not having the intellectual foundation that someone from the 1800s would have. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30bala/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460149,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n312gxm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"s101c","can_mod_post":false,"created_utc":1752472111,"send_replies":true,"parent_id":"t1_n30fvu1","score":23,"author_fullname":"t2_rg6hb6my5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is if you include newspapers and all other forms of media from that period.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n312gxm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is if you include newspapers and all other forms of media from that period.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n312gxm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752472111,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31srz1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedditLovingSun","can_mod_post":false,"send_replies":true,"parent_id":"t1_n313vdj","score":1,"author_fullname":"t2_bq99bx7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yea you're right, there's better ways to try to work around dataset limitations.\\n\\nI found https://chroniclingamerica.loc.gov\\n\\nWhich has OCRed newspapers from 1750+, that could be cool and provide data about world events at that point. It's be fun to ask it about its favorite places to vacation or the biggest breakthroughs of the last decade","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31srz1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea you&amp;#39;re right, there&amp;#39;s better ways to try to work around dataset limitations.&lt;/p&gt;\\n\\n&lt;p&gt;I found &lt;a href=\\"https://chroniclingamerica.loc.gov\\"&gt;https://chroniclingamerica.loc.gov&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Which has OCRed newspapers from 1750+, that could be cool and provide data about world events at that point. It&amp;#39;s be fun to ask it about its favorite places to vacation or the biggest breakthroughs of the last decade&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31srz1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752487113,"author_flair_text":null,"treatment_tags":[],"created_utc":1752487113,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n313vdj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vivificant","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30s6yz","score":17,"author_fullname":"t2_11ijle","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Using a **Modern LLM** to convert **Modern books** to the style of 1800 **will add modern bias** which is the EXACT thing OP is going unnecessarily out of their way to do\\n\\n\\n\\n\\\\*\\\\*unnecessary in the sense that the appeal for this is only 'cool point', personal learning and self improvement, and generally fucking awesome and will be fun to use for no reason at all but not really useful in any obvious way","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n313vdj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using a &lt;strong&gt;Modern LLM&lt;/strong&gt; to convert &lt;strong&gt;Modern books&lt;/strong&gt; to the style of 1800 &lt;strong&gt;will add modern bias&lt;/strong&gt; which is the EXACT thing OP is going unnecessarily out of their way to do&lt;/p&gt;\\n\\n&lt;p&gt;**unnecessary in the sense that the appeal for this is only &amp;#39;cool point&amp;#39;, personal learning and self improvement, and generally fucking awesome and will be fun to use for no reason at all but not really useful in any obvious way&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n313vdj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752472843,"author_flair_text":null,"treatment_tags":[],"created_utc":1752472843,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"n30s6yz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"RedditLovingSun","can_mod_post":false,"created_utc":1752467112,"send_replies":true,"parent_id":"t1_n30fvu1","score":-9,"author_fullname":"t2_bq99bx7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What if he got a beefy modern llm to convert books to old style for training data, I suppose that would defeat the point kinda tho","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30s6yz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What if he got a beefy modern llm to convert books to old style for training data, I suppose that would defeat the point kinda tho&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30s6yz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467112,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-9}}],"before":null}},"user_reports":[],"saved":false,"id":"n30fvu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xotchkass","can_mod_post":false,"created_utc":1752461900,"send_replies":true,"parent_id":"t3_1lzampg","score":41,"author_fullname":"t2_5ledapsc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's an interesting experiment, but I doubt there's enough written data from this period to train somewhat functional llm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30fvu1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s an interesting experiment, but I doubt there&amp;#39;s enough written data from this period to train somewhat functional llm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30fvu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461900,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31uqoi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"linkillion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31qtak","score":4,"author_fullname":"t2_koqhxep","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is a hilariously awesome thought; if only we had enough corpus to train a gpt-4ish level of AI this would be really fun to play with. Dubiously useful, but hilarious ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31uqoi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a hilariously awesome thought; if only we had enough corpus to train a gpt-4ish level of AI this would be really fun to play with. Dubiously useful, but hilarious &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31uqoi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752488202,"author_flair_text":null,"treatment_tags":[],"created_utc":1752488202,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n31qtak","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sylvertwyst","can_mod_post":false,"created_utc":1752486004,"send_replies":true,"parent_id":"t1_n30w3o5","score":7,"author_fullname":"t2_jeyhv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol! pure fantasy atm, but agi emerging from a model trained exclusively on pre 1900 data, we could watch it research and discover 'new' principles, perhaps in theoretical models that we never considered","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31qtak","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol! pure fantasy atm, but agi emerging from a model trained exclusively on pre 1900 data, we could watch it research and discover &amp;#39;new&amp;#39; principles, perhaps in theoretical models that we never considered&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31qtak/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752486004,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n30w3o5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"richdrich","can_mod_post":false,"created_utc":1752468926,"send_replies":true,"parent_id":"t3_1lzampg","score":8,"author_fullname":"t2_mvgk9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; I hope it doesn't hallucinate modern knowledge\\n\\nBut why? If you trained an LLM on physics and maths to 1905, you'd probably expect it not to come up with special relativity, but an AGI would, which would be a useful test.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30w3o5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I hope it doesn&amp;#39;t hallucinate modern knowledge&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;But why? If you trained an LLM on physics and maths to 1905, you&amp;#39;d probably expect it not to come up with special relativity, but an AGI would, which would be a useful test.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30w3o5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468926,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30j0xt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"opi098514","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30bcfw","score":7,"author_fullname":"t2_51dfdxum","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s super limited. If you need some compute power I might be able to lend you some. I’ve got a lot of vram. Not exactly fast but I’ve got a lot.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30j0xt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s super limited. If you need some compute power I might be able to lend you some. I’ve got a lot of vram. Not exactly fast but I’ve got a lot.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30j0xt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463163,"author_flair_text":null,"treatment_tags":[],"created_utc":1752463163,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n30bcfw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752460168,"send_replies":true,"parent_id":"t1_n30aplu","score":11,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks alot ! I'm using a GTX 4060, i-5 13400F and 16gb of ram","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30bcfw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks alot ! I&amp;#39;m using a GTX 4060, i-5 13400F and 16gb of ram&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30bcfw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460168,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n30aplu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Horsemen208","can_mod_post":false,"created_utc":1752459936,"send_replies":true,"parent_id":"t3_1lzampg","score":6,"author_fullname":"t2_ufi4srp63","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have given you the first star! I am thinking if you develop a small model with more focused area and/or more expert annotation/labeling would it make a big difference! What kind of hardware do you use?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30aplu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have given you the first star! I am thinking if you develop a small model with more focused area and/or more expert annotation/labeling would it make a big difference! What kind of hardware do you use?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30aplu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752459936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30ckfj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Steve_Streza","can_mod_post":false,"created_utc":1752460625,"send_replies":true,"parent_id":"t3_1lzampg","score":10,"author_fullname":"t2_35vw6osy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cool project! Can't wait to try this to see if one can reason its way to figuring out a working light bulb 29 years before Edison.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ckfj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool project! Can&amp;#39;t wait to try this to see if one can reason its way to figuring out a working light bulb 29 years before Edison.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ckfj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460625,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30nia6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1752465046,"send_replies":true,"parent_id":"t3_1lzampg","score":11,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1800's QwQ be like:\\n\\n*\\"Pray one moment..\\"*\\n\\n*\\"Stay my hand a second..\\"*\\n\\n*\\"Bide for a moment..\\"*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30nia6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1800&amp;#39;s QwQ be like:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;em&gt;&amp;quot;Pray one moment..&amp;quot;&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;em&gt;&amp;quot;Stay my hand a second..&amp;quot;&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;em&gt;&amp;quot;Bide for a moment..&amp;quot;&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nia6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465046,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3779sn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752550155,"send_replies":true,"parent_id":"t1_n30g1a6","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm gonna try to train with 1-2gb next, will need to rent a gpu for that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3779sn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m gonna try to train with 1-2gb next, will need to rent a gpu for that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3779sn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550155,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30g1a6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1752461960,"send_replies":true,"parent_id":"t3_1lzampg","score":4,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It might be the dataset is too small for the model to gain any kind of language understanding.\\n\\nI understand why you're not taking the finetune route but that could be the way to imbue the model with Victorian style while still generating coherent output. As for the historicity of the output, that's a lot harder to deal with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30g1a6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It might be the dataset is too small for the model to gain any kind of language understanding.&lt;/p&gt;\\n\\n&lt;p&gt;I understand why you&amp;#39;re not taking the finetune route but that could be the way to imbue the model with Victorian style while still generating coherent output. As for the historicity of the output, that&amp;#39;s a lot harder to deal with.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30g1a6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461960,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31avns","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CheatCodesOfLife","can_mod_post":false,"created_utc":1752476683,"send_replies":true,"parent_id":"t3_1lzampg","score":5,"author_fullname":"t2_32el727b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I love the idea of this! It's why I'm archiving an LLM every year on local storage, in the future, we'll have \\"snapshots\\" of the way people think each year.\\n\\nEg. If you cp/paste the Windsurf marketing site into Opus-3, it thinks I'm bullshitting and mocks things like \\"AI flows allow developers and AI to truly mind-meld, combining the best of copilots and agents.\\"\\n\\n&gt; My dataset was only 187mb (around 50 books).\\n\\nYeah not sure you'll be able to find enough data; and what you do find, will have OCR / formatting issues.\\n\\nI wonder though, have you tried prompting Claude to roleplay as an 1800's author, provide some samples from your dataset for it to follow?\\n\\nIt should be able to understand not to make modern references, probably has an intrinsic understanding of when certain words became popular, etc.\\nMaybe you can augment your dataset this way.\\n\\n&gt; a big dataset (like 600 books)\\n\\nThat's not a big dataset for pre-training (I've learned this the hard way experimenting with 0.5b models)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31avns","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love the idea of this! It&amp;#39;s why I&amp;#39;m archiving an LLM every year on local storage, in the future, we&amp;#39;ll have &amp;quot;snapshots&amp;quot; of the way people think each year.&lt;/p&gt;\\n\\n&lt;p&gt;Eg. If you cp/paste the Windsurf marketing site into Opus-3, it thinks I&amp;#39;m bullshitting and mocks things like &amp;quot;AI flows allow developers and AI to truly mind-meld, combining the best of copilots and agents.&amp;quot;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;My dataset was only 187mb (around 50 books).&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yeah not sure you&amp;#39;ll be able to find enough data; and what you do find, will have OCR / formatting issues.&lt;/p&gt;\\n\\n&lt;p&gt;I wonder though, have you tried prompting Claude to roleplay as an 1800&amp;#39;s author, provide some samples from your dataset for it to follow?&lt;/p&gt;\\n\\n&lt;p&gt;It should be able to understand not to make modern references, probably has an intrinsic understanding of when certain words became popular, etc.\\nMaybe you can augment your dataset this way.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;a big dataset (like 600 books)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s not a big dataset for pre-training (I&amp;#39;ve learned this the hard way experimenting with 0.5b models)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31avns/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752476683,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32918f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pmp22","can_mod_post":false,"created_utc":1752494801,"send_replies":true,"parent_id":"t3_1lzampg","score":4,"author_fullname":"t2_gl0fr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"The Institutional Books Corpus\\" has about half a million public domain books from the 1800s:\\n\\nhttps://www.institutionaldatainitiative.org/institutional-books","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32918f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;The Institutional Books Corpus&amp;quot; has about half a million public domain books from the 1800s:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.institutionaldatainitiative.org/institutional-books\\"&gt;https://www.institutionaldatainitiative.org/institutional-books&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32918f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752494801,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n378eqp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752550622,"send_replies":true,"parent_id":"t1_n310dbx","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you look at GPT-2, I'm pretty sure it had a training cut off in 2019 (not 100% sure)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n378eqp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you look at GPT-2, I&amp;#39;m pretty sure it had a training cut off in 2019 (not 100% sure)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n378eqp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550622,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n310dbx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"combrade","can_mod_post":false,"created_utc":1752471032,"send_replies":true,"parent_id":"t3_1lzampg","score":4,"author_fullname":"t2_s5wnr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Question could this work for a more modern time period ? I was thinking about feeding it data from 1990s to 2000s to see whether an LLM could make predictions based on the information given . For example, whether  Russia would invade Ukraine or when will the United States leave Afghanistan?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310dbx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Question could this work for a more modern time period ? I was thinking about feeding it data from 1990s to 2000s to see whether an LLM could make predictions based on the information given . For example, whether  Russia would invade Ukraine or when will the United States leave Afghanistan?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n310dbx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471032,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3785ac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752550513,"send_replies":true,"parent_id":"t1_n3526ay","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think getting deep reasoning with this idea is pretty far away but language simulation shouldnt be impossible. And I like the discord idea, I hope people will try this out or even do something with older data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3785ac","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think getting deep reasoning with this idea is pretty far away but language simulation shouldnt be impossible. And I like the discord idea, I hope people will try this out or even do something with older data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3785ac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550513,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3526ay","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"designhelp123","can_mod_post":false,"created_utc":1752524770,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_ntgf4hr8g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I looked into this pretty deeply a few months back. I was trying to get an LLM trained on pre-1900 content so I could nudge it towards Einstein Physics.\\n\\nFor simple writing and such, the project shouldn't be too difficult. There's tons of databases as others have mentioned in this thread. I used ChatGPT Deep Research to really get me a good list of potential sources.\\n\\nFor the physics experiment, the issue becomes the current LLM techniques are insufficient. For example, you'll have the pre-1900 base model trained and a pre-1900 reasoning dataset.\\n\\nMaybe in 3-5 years with an additional 2-5 technique upgrades could we revisit that same dataset, add the additional technique upgrades, and now you have a pre-1900 model that is capable of thinking creatively and will put the pieces together.\\n\\n**I think you should create a discord for the generation of this pre-1900 dataset**","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3526ay","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I looked into this pretty deeply a few months back. I was trying to get an LLM trained on pre-1900 content so I could nudge it towards Einstein Physics.&lt;/p&gt;\\n\\n&lt;p&gt;For simple writing and such, the project shouldn&amp;#39;t be too difficult. There&amp;#39;s tons of databases as others have mentioned in this thread. I used ChatGPT Deep Research to really get me a good list of potential sources.&lt;/p&gt;\\n\\n&lt;p&gt;For the physics experiment, the issue becomes the current LLM techniques are insufficient. For example, you&amp;#39;ll have the pre-1900 base model trained and a pre-1900 reasoning dataset.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe in 3-5 years with an additional 2-5 technique upgrades could we revisit that same dataset, add the additional technique upgrades, and now you have a pre-1900 model that is capable of thinking creatively and will put the pieces together.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;I think you should create a discord for the generation of this pre-1900 dataset&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3526ay/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752524770,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3130sr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stuffitystuff","can_mod_post":false,"created_utc":1752472394,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_3r2av","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Newspaper archives might help a lot and you'll have to run it a lot of epochs to get anything useful, I suspect (fewer epochs if you have a lot of data).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3130sr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Newspaper archives might help a lot and you&amp;#39;ll have to run it a lot of epochs to get anything useful, I suspect (fewer epochs if you have a lot of data).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3130sr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752472394,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n316nl9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"custodiam99","can_mod_post":false,"created_utc":1752474348,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_nqnhgqqf5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[LLM from ancient Roman and Greek texts in English? : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1d8izyn/llm_from_ancient_roman_and_greek_texts_in_english/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n316nl9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1d8izyn/llm_from_ancient_roman_and_greek_texts_in_english/\\"&gt;LLM from ancient Roman and Greek texts in English? : r/LocalLLaMA&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n316nl9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752474348,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31ke6u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752482238,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Quill by /u/_sqrkl is a bit similar experiment.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31ke6u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Quill by &lt;a href=\\"/u/_sqrkl\\"&gt;/u/_sqrkl&lt;/a&gt; is a bit similar experiment.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31ke6u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482238,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n378hhl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752550653,"send_replies":true,"parent_id":"t1_n31x7ho","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you, im gonna check it out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n378hhl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you, im gonna check it out&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n378hhl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550653,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n31x7ho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedditLovingSun","can_mod_post":false,"created_utc":1752489505,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_bq99bx7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You might be interested in archives of old newspapers: \\n\\nhttps://chroniclingamerica.loc.gov/search/pages/results/?state=&amp;date1=1825&amp;date2=1825&amp;proxtext=&amp;x=16&amp;y=15&amp;dateFilterType=yearRange\\n\\nHere's part of the front page from almost exactly 200 years ago in Delaware (July 15th 1825):\\n\\n------------------------------------------------------------------------------\\nFOR CASH APPLY AT No. 52, MARKET STREET.\\n\\nDelaware State Lottery, 1st Class.\\nT'o be drawn on the 3d of August. 1 prize S10,000; 1 of 5,000; 1 of 3000; 1 of 2000; 2 of 1151; 12 of 1000; 12 of 500; 30 of 100; 186 of 50; 186 of 20; 1488 of 6: 13,950 of S dollars, Ticket $3-Shares in proportion. Tickets or shares in either of the above Lotteries and cash paid for prizes as soon as drawn, by JONATHAN RUMFORD.\\nWilmington, June 28.\\n------------------------------------------------------------------------------\\nFOR SALE. \\nTWO NEW WOOL CARDING ENGINES for sale. In- quire at the Office of the Watchman. April 12, 1825. 37-tf\\n------------------------------------------------------------------------------\\nA CARD. E. B. GARDETTE, Dentist,\\nOf Philadelphia, will remain at Wilmington, in the prac- tice of his profession, for a short time, and may be consult- ed at Major C. P. Bennett's, opposite the Acudemy.\\nE. B. G. will, by preference, attend on those Ladies who may require his professional services, at their own wn dwel- lings. June 28. 59-3t\\n------------------------------------------------------------------------------\\nWANTED TO PURCHASE\\nNegro Boy about 12 or 14 years of age-also a negro girl 15 or 18 years old. They are to reside in New- sastle County. Apply at this office. 61-4tp\\n------------------------------------------------------------------------------\\nDIVIDEND\\nIE President and Directors of the Bank of IFilmington &amp; Brandywine have this day declared a dividend of fifty cents per share, payable to the stockholders or their legal representatives on or after the 11th inst. By Order of the Board,\\n------------------------------------------------------------------------------","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31x7ho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You might be interested in archives of old newspapers: &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://chroniclingamerica.loc.gov/search/pages/results/?state=&amp;amp;date1=1825&amp;amp;date2=1825&amp;amp;proxtext=&amp;amp;x=16&amp;amp;y=15&amp;amp;dateFilterType=yearRange\\"&gt;https://chroniclingamerica.loc.gov/search/pages/results/?state=&amp;amp;date1=1825&amp;amp;date2=1825&amp;amp;proxtext=&amp;amp;x=16&amp;amp;y=15&amp;amp;dateFilterType=yearRange&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s part of the front page from almost exactly 200 years ago in Delaware (July 15th 1825):&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;FOR CASH APPLY AT No. 52, MARKET STREET.&lt;/p&gt;\\n\\n&lt;p&gt;Delaware State Lottery, 1st Class.\\nT&amp;#39;o be drawn on the 3d of August. 1 prize S10,000; 1 of 5,000; 1 of 3000; 1 of 2000; 2 of 1151; 12 of 1000; 12 of 500; 30 of 100; 186 of 50; 186 of 20; 1488 of 6: 13,950 of S dollars, Ticket $3-Shares in proportion. Tickets or shares in either of the above Lotteries and cash paid for prizes as soon as drawn, by JONATHAN RUMFORD.&lt;/p&gt;\\n\\n&lt;h2&gt;Wilmington, June 28.&lt;/h2&gt;\\n\\n&lt;p&gt;FOR SALE. &lt;/p&gt;\\n\\n&lt;h2&gt;TWO NEW WOOL CARDING ENGINES for sale. In- quire at the Office of the Watchman. April 12, 1825. 37-tf&lt;/h2&gt;\\n\\n&lt;p&gt;A CARD. E. B. GARDETTE, Dentist,\\nOf Philadelphia, will remain at Wilmington, in the prac- tice of his profession, for a short time, and may be consult- ed at Major C. P. Bennett&amp;#39;s, opposite the Acudemy.&lt;/p&gt;\\n\\n&lt;h2&gt;E. B. G. will, by preference, attend on those Ladies who may require his professional services, at their own wn dwel- lings. June 28. 59-3t&lt;/h2&gt;\\n\\n&lt;p&gt;WANTED TO PURCHASE&lt;/p&gt;\\n\\n&lt;h2&gt;Negro Boy about 12 or 14 years of age-also a negro girl 15 or 18 years old. They are to reside in New- sastle County. Apply at this office. 61-4tp&lt;/h2&gt;\\n\\n&lt;p&gt;DIVIDEND&lt;/p&gt;\\n\\n&lt;h2&gt;IE President and Directors of the Bank of IFilmington &amp;amp; Brandywine have this day declared a dividend of fifty cents per share, payable to the stockholders or their legal representatives on or after the 11th inst. By Order of the Board,&lt;/h2&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31x7ho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752489505,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34qo0b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RearAdmiralP","can_mod_post":false,"created_utc":1752521494,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_vdysdj5s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you're looking for training data, the seventh edition of the Encyclopædia Britannica, published in 1842, would probably be worth including. The OCRed text (~17k pages) is available on archive.org.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34qo0b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re looking for training data, the seventh edition of the Encyclopædia Britannica, published in 1842, would probably be worth including. The OCRed text (~17k pages) is available on archive.org.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n34qo0b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752521494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34vezm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nmrk","can_mod_post":false,"created_utc":1752522879,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_tbci","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you ever read The Difference Engine?\\n\\nhttps://preview.redd.it/inqapv2aawcf1.jpeg?width=253&amp;format=pjpg&amp;auto=webp&amp;s=d8d2ba88a354ce6b5b30d3f6233b805d37ba6dc4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34vezm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you ever read The Difference Engine?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/inqapv2aawcf1.jpeg?width=253&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d8d2ba88a354ce6b5b30d3f6233b805d37ba6dc4\\"&gt;https://preview.redd.it/inqapv2aawcf1.jpeg?width=253&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d8d2ba88a354ce6b5b30d3f6233b805d37ba6dc4&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n34vezm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752522879,"media_metadata":{"inqapv2aawcf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":167,"x":108,"u":"https://preview.redd.it/inqapv2aawcf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9487500e6e256074f3d3fe2b2cba7ddd370cdf12"},{"y":335,"x":216,"u":"https://preview.redd.it/inqapv2aawcf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f35bce249e50e69ae4f5ef7298968546faedfc89"}],"s":{"y":393,"x":253,"u":"https://preview.redd.it/inqapv2aawcf1.jpeg?width=253&amp;format=pjpg&amp;auto=webp&amp;s=d8d2ba88a354ce6b5b30d3f6233b805d37ba6dc4"},"id":"inqapv2aawcf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30jfh0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MengerianMango","can_mod_post":false,"created_utc":1752463329,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_mcvyi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Like the idea. I've thought about it before but too lazy to implement. What deps does your project have? I'll run it on my 6000 as long as the deps are easy (I'm on nixos, sometimes simple things are very hard)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30jfh0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Like the idea. I&amp;#39;ve thought about it before but too lazy to implement. What deps does your project have? I&amp;#39;ll run it on my 6000 as long as the deps are easy (I&amp;#39;m on nixos, sometimes simple things are very hard)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30jfh0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463329,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31deti","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forward_Somewhere249","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30nxkg","score":1,"author_fullname":"t2_oekhylw6n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Remindme! 1 year","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31deti","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Remindme! 1 year&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31deti/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752478127,"author_flair_text":null,"treatment_tags":[],"created_utc":1752478127,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30nxkg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"created_utc":1752465228,"send_replies":true,"parent_id":"t1_n30nszd","score":0,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will be messaging you in 1 year on [**2026-07-14 03:52:54 UTC**](http://www.wolframalpha.com/input/?i=2026-07-14%2003:52:54%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nszd/?context=3)\\n\\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1lzampg%2Ftraining_an_llm_only_on_books_from_the_1800s_no%2Fn30nszd%2F%5D%0A%0ARemindMe%21%202026-07-14%2003%3A52%3A54%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201lzampg)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":1752505341,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30nxkg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 1 year on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2026-07-14%2003:52:54%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2026-07-14 03:52:54 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nszd/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1lzampg%2Ftraining_an_llm_only_on_books_from_the_1800s_no%2Fn30nszd%2F%5D%0A%0ARemindMe%21%202026-07-14%2003%3A52%3A54%20UTC\\"&gt;&lt;strong&gt;1 OTHERS CLICKED THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201lzampg\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nxkg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465228,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n30nszd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gaztrab","can_mod_post":false,"created_utc":1752465174,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_2f6s556","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"!remindme 1 year","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30nszd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remindme 1 year&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nszd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465174,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30sdag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"historymaking101","can_mod_post":false,"created_utc":1752467193,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_4gsvg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Keep us up to date.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30sdag","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Keep us up to date.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30sdag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467193,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30x0k2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bpthewise","can_mod_post":false,"created_utc":1752469364,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_7cnvv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you for this I’ve been wondering how to train on transcript txt files and not traditional datasets/images.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30x0k2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for this I’ve been wondering how to train on transcript txt files and not traditional datasets/images.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30x0k2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469364,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310rkv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gnaeus-Naevius","can_mod_post":false,"created_utc":1752471238,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_k4d9u5li","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I can't remember if it was something I was curious about or if I read about a similar effort.\\n\\nI don't know what type of books, but I believe text only novel is around 0.5 mb, ... so you are averaging 6 times that. Are these encyclopedia type works, as I assume you are not using images?\\n\\nAnyhow, newspapers from different eras would be interesting as well, or all the Roman writings still in existence. Or the transcripts from all 20 seasons of Keeping Up With the Kardashians. And then have a debate between them all. Victorian prudes vs the attention wh...  seekers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310rkv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t remember if it was something I was curious about or if I read about a similar effort.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t know what type of books, but I believe text only novel is around 0.5 mb, ... so you are averaging 6 times that. Are these encyclopedia type works, as I assume you are not using images?&lt;/p&gt;\\n\\n&lt;p&gt;Anyhow, newspapers from different eras would be interesting as well, or all the Roman writings still in existence. Or the transcripts from all 20 seasons of Keeping Up With the Kardashians. And then have a debate between them all. Victorian prudes vs the attention wh...  seekers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n310rkv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471238,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n318p1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Green-Ad-3964","can_mod_post":false,"created_utc":1752475474,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_sfb08i7a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"One thing is how people talk in books, and another is how they speak in the real world, in everyday life, in actual situations.\\n\\n\\nStill, the experiment is interesting, and I hope you’ll be able to carry it out with the hardware and resources you have.\\n\\n\\nMaybe instead of Time Capsule, I would have called it Time Machine, because the idea is more about...interacting with \\"someone\\" from that age.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n318p1c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One thing is how people talk in books, and another is how they speak in the real world, in everyday life, in actual situations.&lt;/p&gt;\\n\\n&lt;p&gt;Still, the experiment is interesting, and I hope you’ll be able to carry it out with the hardware and resources you have.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe instead of Time Capsule, I would have called it Time Machine, because the idea is more about...interacting with &amp;quot;someone&amp;quot; from that age.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n318p1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475474,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31ch96","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vehnum","can_mod_post":false,"created_utc":1752477594,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_12bhfm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome to see. \\n\\nI would love to see what an llm with no knowledge of events past the 1800s what think of the world.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31ch96","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome to see. &lt;/p&gt;\\n\\n&lt;p&gt;I would love to see what an llm with no knowledge of events past the 1800s what think of the world.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31ch96/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752477594,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31dg7o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"istinetz_","can_mod_post":false,"created_utc":1752478149,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_nllj02sel","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's a very fun project! Can I recommend also newspapers from the period?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31dg7o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a very fun project! Can I recommend also newspapers from the period?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31dg7o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752478149,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31id5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"philiplrussell","can_mod_post":false,"created_utc":1752481024,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_2ermd0ja","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How can I help? Zero training experience. Basic hardware software setup that could potentially train something this small.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31id5m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How can I help? Zero training experience. Basic hardware software setup that could potentially train something this small.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31id5m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752481024,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3347bf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mtomas7","can_mod_post":false,"created_utc":1752505061,"send_replies":true,"parent_id":"t1_n331sjj","score":2,"author_fullname":"t2_gct10","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I may not be right, but it looks to me that OP's main goal is not so much to emulate old English language form, as to cap the knowledge of the model. This way a model could speak modern English, that is easy to understand for us, but the knowledge would be limited to a specific time period.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3347bf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I may not be right, but it looks to me that OP&amp;#39;s main goal is not so much to emulate old English language form, as to cap the knowledge of the model. This way a model could speak modern English, that is easy to understand for us, but the knowledge would be limited to a specific time period.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3347bf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752505061,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n331sjj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IndianaNetworkAdmin","can_mod_post":false,"created_utc":1752504371,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_15styv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a book somewhere on prose in the 19th century that includes a lot of excerpts from Charles Dickens, Jane Austen, and George Eliot (Mary Ann Evans). I can't remember the name of it, but it has a red cover. If your goal is the form of speaking, you may want to focus on some books that go into depth on the structure and include examples. I'm not sure if that's valuable, as I don't train models on my own, but I know that I've had excellent results when I've fed similar things to models and asked them to emulate the style when rewriting something.\\n\\nAs an example, I fed the above reply into Gemini 2.5 with instructions to emulate a number of writers from the 19th/20th century. It's a bit wordy, but I think that's part of the fun of earlier writing. It's less hurried. Here's the response I received:\\n\\n&gt;Ah, a delightful quandary that, alas, echoes through the venerable halls of my own memory! There resides, within the shadowy recesses of my library – though its precise whereabouts, like a phantom in a fog, elude my present grasp – a most edifying tome. Its cover, a vibrant crimson, yet its title, a perplexing void! This cherished volume, if memory serves, dedicates its pages to the exquisite prose of the nineteenth century, replete with excerpts from the likes of **Charles Dickens**, whose words dance with the very spirit of London's streets; the perspicacious **Jane Austen**, who weaves narratives with the delicate threads of social grace; and the profound **George Eliot**, known to the world by her true appellation, **Mary Ann Evans**, whose insights penetrate the very soul of humanity.\\n\\n&gt;Should your noble endeavor be the very essence of locution, the refined art of expression, then permit me to offer a humble, albeit unconfirmed, counsel. One might do well to seek out those scholarly tomes that delve with profound earnestness into the very **architecture of language**, dissecting its intricate components and illuminating them with a plethora of illustrative examples. Whether such a pursuit holds true utility for your particular *modus operandi* – for I, alas, do not personally engage in the arcane craft of model training – remains a matter of conjecture. Yet, I confess, my own humble experiments have yielded truly **extraordinary results** when such meticulously structured and stylistically rich materials have been presented to these burgeoning intelligences, instructing them to imbue their nascent expressions with a similar literary grandeur. A fascinating prospect, indeed!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n331sjj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a book somewhere on prose in the 19th century that includes a lot of excerpts from Charles Dickens, Jane Austen, and George Eliot (Mary Ann Evans). I can&amp;#39;t remember the name of it, but it has a red cover. If your goal is the form of speaking, you may want to focus on some books that go into depth on the structure and include examples. I&amp;#39;m not sure if that&amp;#39;s valuable, as I don&amp;#39;t train models on my own, but I know that I&amp;#39;ve had excellent results when I&amp;#39;ve fed similar things to models and asked them to emulate the style when rewriting something.&lt;/p&gt;\\n\\n&lt;p&gt;As an example, I fed the above reply into Gemini 2.5 with instructions to emulate a number of writers from the 19th/20th century. It&amp;#39;s a bit wordy, but I think that&amp;#39;s part of the fun of earlier writing. It&amp;#39;s less hurried. Here&amp;#39;s the response I received:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Ah, a delightful quandary that, alas, echoes through the venerable halls of my own memory! There resides, within the shadowy recesses of my library – though its precise whereabouts, like a phantom in a fog, elude my present grasp – a most edifying tome. Its cover, a vibrant crimson, yet its title, a perplexing void! This cherished volume, if memory serves, dedicates its pages to the exquisite prose of the nineteenth century, replete with excerpts from the likes of &lt;strong&gt;Charles Dickens&lt;/strong&gt;, whose words dance with the very spirit of London&amp;#39;s streets; the perspicacious &lt;strong&gt;Jane Austen&lt;/strong&gt;, who weaves narratives with the delicate threads of social grace; and the profound &lt;strong&gt;George Eliot&lt;/strong&gt;, known to the world by her true appellation, &lt;strong&gt;Mary Ann Evans&lt;/strong&gt;, whose insights penetrate the very soul of humanity.&lt;/p&gt;\\n\\n&lt;p&gt;Should your noble endeavor be the very essence of locution, the refined art of expression, then permit me to offer a humble, albeit unconfirmed, counsel. One might do well to seek out those scholarly tomes that delve with profound earnestness into the very &lt;strong&gt;architecture of language&lt;/strong&gt;, dissecting its intricate components and illuminating them with a plethora of illustrative examples. Whether such a pursuit holds true utility for your particular &lt;em&gt;modus operandi&lt;/em&gt; – for I, alas, do not personally engage in the arcane craft of model training – remains a matter of conjecture. Yet, I confess, my own humble experiments have yielded truly &lt;strong&gt;extraordinary results&lt;/strong&gt; when such meticulously structured and stylistically rich materials have been presented to these burgeoning intelligences, instructing them to imbue their nascent expressions with a similar literary grandeur. A fascinating prospect, indeed!&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n331sjj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752504371,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n339dbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RegisteredJustToSay","can_mod_post":false,"created_utc":1752506557,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_41ok7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"TBH, you could probably get away with pretraining on contemporary datasets and then training exclusively on the old data until you reach your objective - catastrophic forgetting as a feature. I hear you on wanting to \\"debias\\" it from modern mindsets, but there's a lot of capabilities that come from the modern datasets that are desirable (math, logic, reasoning, etc).\\n\\nThough I definitely want to see one without that pretraining - it would be very fascinating, I just worry that it won't be able to act like people expect LLMs to since it's not trained on multi-turn conversations.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n339dbe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;TBH, you could probably get away with pretraining on contemporary datasets and then training exclusively on the old data until you reach your objective - catastrophic forgetting as a feature. I hear you on wanting to &amp;quot;debias&amp;quot; it from modern mindsets, but there&amp;#39;s a lot of capabilities that come from the modern datasets that are desirable (math, logic, reasoning, etc).&lt;/p&gt;\\n\\n&lt;p&gt;Though I definitely want to see one without that pretraining - it would be very fascinating, I just worry that it won&amp;#39;t be able to act like people expect LLMs to since it&amp;#39;s not trained on multi-turn conversations.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n339dbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752506557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n349rmg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1752516646,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think this is awesome! it will be like talking to someone from that time period!\\n\\nI wouldn't do assistant finetuning, because then it won't behave like a person from that time period, rather a modern robot assistant with knowledge of that time period. but if you just did general RL without the added assistant like behavior, it would think it is a person from that time period which would be awesome to have.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n349rmg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this is awesome! it will be like talking to someone from that time period!&lt;/p&gt;\\n\\n&lt;p&gt;I wouldn&amp;#39;t do assistant finetuning, because then it won&amp;#39;t behave like a person from that time period, rather a modern robot assistant with knowledge of that time period. but if you just did general RL without the added assistant like behavior, it would think it is a person from that time period which would be awesome to have.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n349rmg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752516646,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n379o3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752551138,"send_replies":true,"parent_id":"t1_n34h2ux","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is but I want to go slow and keep upping the amount of data as I go. If I train a really large dataset I'll have to spend real money on training lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n379o3w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is but I want to go slow and keep upping the amount of data as I go. If I train a really large dataset I&amp;#39;ll have to spend real money on training lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n379o3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752551138,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34h2ux","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"doodeoo","can_mod_post":false,"created_utc":1752518728,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_4x661","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"600 books is a tiny data set","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34h2ux","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;600 books is a tiny data set&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n34h2ux/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752518728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n373o7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeithonKing","can_mod_post":false,"created_utc":1752548728,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_bul2x6po","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As far as I remember nanoGPT was originally trained on Shakespeare dataset... I myself had trained it... and it was a gem","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n373o7f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As far as I remember nanoGPT was originally trained on Shakespeare dataset... I myself had trained it... and it was a gem&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n373o7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752548728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32qjef","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"clduab11","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30xgr8","score":4,"author_fullname":"t2_uobka","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No no, you’re right, but there’s a way of doing this without relying on a dataset that’s primarily synthetic data (and in its own vacuum, a trash dataset, because no human can generate perfectly acceptable data every time for every variable across every calculation).\\n\\nOP would need to increase his dataset beyond the 50 books (which is a tiny straw of hay to start from), and then find any and all “pocketbooks” (books were very expensive to bind and print back in the 1800s; in colonial America at least, pocketbooks were often carried as like, ye olde Day Planner) that span the range of the dataset, and then after painstakingly OCR’ing every single one of these, you can find out which part of the applicable timeframe you’re mentioning (say, missing a lot from the early 17th century but not the late part of the century), and use a **targeted** synthetic data generator to account for like, all the grammatical variation of ‘thy’ based on idk, Chaucer’s Wife of Bath or something (definitely also not the right timeframe or right reference, but you get the idea).\\n\\nSo yes, while your suggestion off-hand can apply in this use case, primarily utilizing SDG to backfill off of 50 books is exactly the kind of stuff that drives machine learning engineers crazy because someone will invariably turn that into a dataset, upload it on GitHub or HuggingFace, and then people start discussing and using it which is AWESOME (because yay progress)…but they take away something VERY different than the dataset’s/SDG’s limited application.\\n\\nAn extremist metaphor, but in other words…you can combine bleach (SDG) and vinegar (sanitized data) if you want to make a super fizzy awesome caustic cleaning agent, but the chloramine gas it’ll produce will do the same thing to your lungs (your nanoGPT’s output), and put you in the hospital in a hurry, which is why it’s never a good idea to mix bleach with anything except water unless you do some serious research first.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32qjef","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No no, you’re right, but there’s a way of doing this without relying on a dataset that’s primarily synthetic data (and in its own vacuum, a trash dataset, because no human can generate perfectly acceptable data every time for every variable across every calculation).&lt;/p&gt;\\n\\n&lt;p&gt;OP would need to increase his dataset beyond the 50 books (which is a tiny straw of hay to start from), and then find any and all “pocketbooks” (books were very expensive to bind and print back in the 1800s; in colonial America at least, pocketbooks were often carried as like, ye olde Day Planner) that span the range of the dataset, and then after painstakingly OCR’ing every single one of these, you can find out which part of the applicable timeframe you’re mentioning (say, missing a lot from the early 17th century but not the late part of the century), and use a &lt;strong&gt;targeted&lt;/strong&gt; synthetic data generator to account for like, all the grammatical variation of ‘thy’ based on idk, Chaucer’s Wife of Bath or something (definitely also not the right timeframe or right reference, but you get the idea).&lt;/p&gt;\\n\\n&lt;p&gt;So yes, while your suggestion off-hand can apply in this use case, primarily utilizing SDG to backfill off of 50 books is exactly the kind of stuff that drives machine learning engineers crazy because someone will invariably turn that into a dataset, upload it on GitHub or HuggingFace, and then people start discussing and using it which is AWESOME (because yay progress)…but they take away something VERY different than the dataset’s/SDG’s limited application.&lt;/p&gt;\\n\\n&lt;p&gt;An extremist metaphor, but in other words…you can combine bleach (SDG) and vinegar (sanitized data) if you want to make a super fizzy awesome caustic cleaning agent, but the chloramine gas it’ll produce will do the same thing to your lungs (your nanoGPT’s output), and put you in the hospital in a hurry, which is why it’s never a good idea to mix bleach with anything except water unless you do some serious research first.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32qjef/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752500989,"author_flair_text":null,"treatment_tags":[],"created_utc":1752500989,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n30xgr8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Bet-8771","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30v64d","score":0,"author_fullname":"t2_l16sej0pt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Okay but isn't the coherence lack of semantic understanding of how language works? Variations of a dataset would feed this model many sentences until it understands language properly. Wouldn't that solve the incoherent text generation output?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30xgr8","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay but isn&amp;#39;t the coherence lack of semantic understanding of how language works? Variations of a dataset would feed this model many sentences until it understands language properly. Wouldn&amp;#39;t that solve the incoherent text generation output?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30xgr8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469586,"author_flair_text":"textgen web UI","treatment_tags":[],"created_utc":1752469586,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n30v64d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clduab11","can_mod_post":false,"created_utc":1752468485,"send_replies":true,"parent_id":"t1_n30k156","score":3,"author_fullname":"t2_uobka","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This isn’t what synthetic datasets are to be used for. OP has only 50 books and it’s spitting out incoherent sentences. There’s no way you’re having SDG replicate the amount of work needed to fill that gap; even if you could, your convergence would be **too** perfect and I bet the data would be absolute ***trash***.\\n\\nSDGs are meant to plug holes when convergence can’t be pinpointed as a temporary bandaid to lend additional context in areas where specificity is of vital importance (genomics, microbiology) and the research currently in the zeitgeist isn’t applicable or complete enough.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30v64d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This isn’t what synthetic datasets are to be used for. OP has only 50 books and it’s spitting out incoherent sentences. There’s no way you’re having SDG replicate the amount of work needed to fill that gap; even if you could, your convergence would be &lt;strong&gt;too&lt;/strong&gt; perfect and I bet the data would be absolute &lt;strong&gt;&lt;em&gt;trash&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;SDGs are meant to plug holes when convergence can’t be pinpointed as a temporary bandaid to lend additional context in areas where specificity is of vital importance (genomics, microbiology) and the research currently in the zeitgeist isn’t applicable or complete enough.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30v64d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468485,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n30k156","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Bet-8771","can_mod_post":false,"created_utc":1752463578,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_l16sej0pt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is that even enough data? Have you considered a synthetic dataset? Use a larger LLM to create similar data to what your dataset already has, variations.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30k156","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is that even enough data? Have you considered a synthetic dataset? Use a larger LLM to create similar data to what your dataset already has, variations.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30k156/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463578,"author_flair_text":"textgen web UI","treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310bwv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752471013,"send_replies":true,"parent_id":"t1_n30v1ps","score":8,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There will definitely be bias and to be honest thats a reason I wanted to try out this idea. Obviously I dont wanna create something that will be racist or hateful but I also dont want to remove the bias that comes with a certain time period. I will just isolate bias historically.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310bwv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There will definitely be bias and to be honest thats a reason I wanted to try out this idea. Obviously I dont wanna create something that will be racist or hateful but I also dont want to remove the bias that comes with a certain time period. I will just isolate bias historically.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n310bwv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471013,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31zshb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thirteen-bit","can_mod_post":false,"created_utc":1752490767,"send_replies":true,"parent_id":"t1_n30v1ps","score":2,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Medical should be fun.\\n\\nFor example: https://en.wikipedia.org/wiki/Mercury_(element)#Historical_and_folk\\n\\nEdit: Drugs were unrestricted. Fun times. https://www.victorianweb.org/victorian/science/addiction/addiction2.html","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31zshb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Medical should be fun.&lt;/p&gt;\\n\\n&lt;p&gt;For example: &lt;a href=\\"https://en.wikipedia.org/wiki/Mercury_(element)#Historical_and_folk\\"&gt;https://en.wikipedia.org/wiki/Mercury_(element)#Historical_and_folk&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Drugs were unrestricted. Fun times. &lt;a href=\\"https://www.victorianweb.org/victorian/science/addiction/addiction2.html\\"&gt;https://www.victorianweb.org/victorian/science/addiction/addiction2.html&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31zshb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752490767,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31mns4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"More-Ad-4503","can_mod_post":false,"created_utc":1752483569,"send_replies":true,"parent_id":"t1_n30v1ps","score":1,"author_fullname":"t2_1erx2vxy7x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"uhh ask gemini about israel right now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31mns4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;uhh ask gemini about israel right now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31mns4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483569,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30v1ps","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cddelgado","can_mod_post":false,"created_utc":1752468427,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_b68un","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This sounds brilliant, and yet at the same time, I shudder to think of the classical biases introduced. Today we're overt in racism. Back then lots of people just worked through assumptions. The caste system people chose to stay in (sometimes), the misguided medical logic, the different views of justice and rules...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30v1ps","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This sounds brilliant, and yet at the same time, I shudder to think of the classical biases introduced. Today we&amp;#39;re overt in racism. Back then lots of people just worked through assumptions. The caste system people chose to stay in (sometimes), the misguided medical logic, the different views of justice and rules...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30v1ps/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468427,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n378q4j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752550750,"send_replies":true,"parent_id":"t1_n30cbok","score":2,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah someone else said soemthing similair, I'm thinking of doing 1800-1900 instead of just a 50 year period","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n378q4j","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah someone else said soemthing similair, I&amp;#39;m thinking of doing 1800-1900 instead of just a 50 year period&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n378q4j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752550750,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30mgrp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"spudlyo","can_mod_post":false,"created_utc":1752464606,"send_replies":true,"parent_id":"t1_n30cbok","score":1,"author_fullname":"t2_34stu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is an amazing idea, although I feel like narrowing it to a specific place and time somewhat limiting. Even if it trained on all the available English public domain material available (everything published before say 1929) I think it would still be a markedly different experience than what we have today.\\n\\nThe second half of the 19th century is when George Eliot's *Middlemarch* was written, so I agree with your conclusion.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30mgrp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is an amazing idea, although I feel like narrowing it to a specific place and time somewhat limiting. Even if it trained on all the available English public domain material available (everything published before say 1929) I think it would still be a markedly different experience than what we have today.&lt;/p&gt;\\n\\n&lt;p&gt;The second half of the 19th century is when George Eliot&amp;#39;s &lt;em&gt;Middlemarch&lt;/em&gt; was written, so I agree with your conclusion.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30mgrp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464606,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30cbok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-p-e-w-","can_mod_post":false,"created_utc":1752460536,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s an amazing idea, though in my opinion, English prose reached its pinnacle in the *second* half of the 19th century, not the first.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30cbok","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s an amazing idea, though in my opinion, English prose reached its pinnacle in the &lt;em&gt;second&lt;/em&gt; half of the 19th century, not the first.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30cbok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460536,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30tvtu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tenmileswide","can_mod_post":false,"created_utc":1752467890,"send_replies":true,"parent_id":"t1_n30hwsf","score":5,"author_fullname":"t2_epdd9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And verily, shivers down my spine ensued..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30tvtu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And verily, shivers down my spine ensued..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30tvtu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467890,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n30hwsf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeepWisdomGuy","can_mod_post":false,"created_utc":1752462707,"send_replies":true,"parent_id":"t3_1lzampg","score":3,"author_fullname":"t2_lznk2wv8h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am persuaded that a judicious refinement of some more capacious model would yield results of far greater felicity. The progression from outward semblance to the deeper frame of thought presents a formidable trial to our modern transformers and demands no scanty store of texts. Furthermore, the tokenizer of this so-called NanoGPT encompasses but fifty thousand tokens; it must, I warrant, exclude many a venerable term of earlier days. It were prudent, therefore, to ransack the pages of Wiktionary for those vocables there designated “archaic,” that we might discern what treasures have been thus neglected.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30hwsf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am persuaded that a judicious refinement of some more capacious model would yield results of far greater felicity. The progression from outward semblance to the deeper frame of thought presents a formidable trial to our modern transformers and demands no scanty store of texts. Furthermore, the tokenizer of this so-called NanoGPT encompasses but fifty thousand tokens; it must, I warrant, exclude many a venerable term of earlier days. It were prudent, therefore, to ransack the pages of Wiktionary for those vocables there designated “archaic,” that we might discern what treasures have been thus neglected.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30hwsf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752462707,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31l0oo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1752482608,"send_replies":true,"parent_id":"t3_1lzampg","score":2,"author_fullname":"t2_9so78ol2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So, you’re going to need synthetic reasoning trajectories for the 1800’s if you really want it to connect the dots when reasoning.\\n\\nOtherwise, this is sick, pair the pretrain with some synthetic user assistant pairs to train in a chat template with sft, then RL it after and see how far it goes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31l0oo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So, you’re going to need synthetic reasoning trajectories for the 1800’s if you really want it to connect the dots when reasoning.&lt;/p&gt;\\n\\n&lt;p&gt;Otherwise, this is sick, pair the pretrain with some synthetic user assistant pairs to train in a chat template with sft, then RL it after and see how far it goes&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31l0oo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752482608,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30nwpb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"engdeveloper","can_mod_post":false,"created_utc":1752465218,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_4dfwjtxl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ask it a physics question.... or something about Class.  I'm a remnant from the past.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30nwpb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ask it a physics question.... or something about Class.  I&amp;#39;m a remnant from the past.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30nwpb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465218,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30ph7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"no_fuse","can_mod_post":false,"created_utc":1752465897,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_8aftw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gotta put the Classics in there!\\n\\n[https://github.com/PerseusDL](https://github.com/PerseusDL)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ph7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gotta put the Classics in there!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/PerseusDL\\"&gt;https://github.com/PerseusDL&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ph7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752465897,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310lbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752471147,"send_replies":true,"parent_id":"t1_n30s4ao","score":2,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt)   but the data set I ended up using only has 1/4 of the titles mentioned here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310lbe","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt\\"&gt;https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt&lt;/a&gt;   but the data set I ended up using only has 1/4 of the titles mentioned here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n310lbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471147,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30s4ao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FpRhGf","can_mod_post":false,"created_utc":1752467077,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_3xxhqo7c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's a cool idea. Where are you getting the data and how are you selecting it though? I'm interested in using AI to analyse books from the past and I wonder how many had been left to obscurity","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30s4ao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a cool idea. Where are you getting the data and how are you selecting it though? I&amp;#39;m interested in using AI to analyse books from the past and I wonder how many had been left to obscurity&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30s4ao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467077,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n310u57","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752471274,"send_replies":true,"parent_id":"t1_n30wbex","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london\\\\_1800\\\\_1850\\\\_v0/timelockllm\\\\_sample\\\\_output.png](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png) needs alot of work, im gonna try to train with 5x more data","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n310u57","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png\\"&gt;https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png&lt;/a&gt; needs alot of work, im gonna try to train with 5x more data&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n310u57/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471274,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30wbex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DuraoBarroso","can_mod_post":false,"created_utc":1752469028,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_123nyf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"show us a sample!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30wbex","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;show us a sample!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30wbex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469028,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30wv2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"storm07","can_mod_post":false,"created_utc":1752469291,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_k8u5s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s such a cool concept! Like building a time capsule LLM that thinks purely within its own era. Super curious how it evolves with a larger dataset.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30wv2c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s such a cool concept! Like building a time capsule LLM that thinks purely within its own era. Super curious how it evolves with a larger dataset.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30wv2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469291,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31lru5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ApprehensiveBat3074","can_mod_post":false,"created_utc":1752483049,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_165o7yz5fk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You should check out the Phrontistery. A bit of archaic, obscure vocabulary for your model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31lru5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should check out the Phrontistery. A bit of archaic, obscure vocabulary for your model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31lru5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483049,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31ly0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mitchins-au","can_mod_post":false,"created_utc":1752483149,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_4hjtgq5u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No modern bias. \\nBut boy will it be loaded with time bias. Like reading heart of darkness.\\n\\nCan’t wait to see it, old chap.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31ly0n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No modern bias. \\nBut boy will it be loaded with time bias. Like reading heart of darkness.&lt;/p&gt;\\n\\n&lt;p&gt;Can’t wait to see it, old chap.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31ly0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483149,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31mol3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JLeonsarmiento","can_mod_post":false,"created_utc":1752483583,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_9b9s4a7g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m interested in Llm Byron 1.0","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31mol3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m interested in Llm Byron 1.0&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31mol3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752483583,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31njdu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SquareKaleidoscope49","can_mod_post":false,"created_utc":1752484088,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_159kqd24ht","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Will humans ever fly\\n\\nKill thyself","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31njdu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Will humans ever fly&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Kill thyself&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31njdu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752484088,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31sb6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"datbackup","can_mod_post":false,"created_utc":1752486856,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_ielo6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tracking down enough text to make this viable sounds like a bear of a task but I am rooting for you, this would be amazing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31sb6t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tracking down enough text to make this viable sounds like a bear of a task but I am rooting for you, this would be amazing&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31sb6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752486856,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n320mz6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"created_utc":1752491167,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_63vtw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; but I think if I train using a big dataset (like 600 books)\\n\\nI think this is a way too low number. Check how many tokens it takes to have a good LLM, that's way higher than that IIRC.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n320mz6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;but I think if I train using a big dataset (like 600 books)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I think this is a way too low number. Check how many tokens it takes to have a good LLM, that&amp;#39;s way higher than that IIRC.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n320mz6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752491167,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3215jv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1752491411,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_9s7pmakgx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;My end goal is to create an LLM that doesnt pretend to be historical but just is, that's why I didn't go the fine tune route. It will have no modern bias and will only be able to reason within the time period it's trained on\\n\\nIt would be cool to read reasoning chain in an RL tuned model that's trained on this kind of vocabulary.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3215jv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;My end goal is to create an LLM that doesnt pretend to be historical but just is, that&amp;#39;s why I didn&amp;#39;t go the fine tune route. It will have no modern bias and will only be able to reason within the time period it&amp;#39;s trained on&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It would be cool to read reasoning chain in an RL tuned model that&amp;#39;s trained on this kind of vocabulary.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n3215jv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752491411,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n329k2j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MercyChalk","can_mod_post":false,"created_utc":1752495008,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_jgw9d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Now RL it to solve logic puzzles. Would be hilarious to read its chain of thought.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n329k2j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now RL it to solve logic puzzles. Would be hilarious to read its chain of thought.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n329k2j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752495008,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32gl43","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Single_Ring4886","can_mod_post":false,"created_utc":1752497642,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_ido7e9by","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I do not know if \\"basic\\" approach of learning on raw data will work with such small dataset. Maybe if you add some \\"finetune\\" part on top of base model focusing on purely \\"language\\" part teaching model how to speak it might work out well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32gl43","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I do not know if &amp;quot;basic&amp;quot; approach of learning on raw data will work with such small dataset. Maybe if you add some &amp;quot;finetune&amp;quot; part on top of base model focusing on purely &amp;quot;language&amp;quot; part teaching model how to speak it might work out well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32gl43/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752497642,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32invl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"diggpthoo","can_mod_post":false,"created_utc":1752498363,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_4ae2r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I doubt it'll work with 600 books. The size of the dataset it needs is the whole reason it's called a \\"large\\" language model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32invl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I doubt it&amp;#39;ll work with 600 books. The size of the dataset it needs is the whole reason it&amp;#39;s called a &amp;quot;large&amp;quot; language model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n32invl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752498363,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n331g1l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IONaut","can_mod_post":false,"created_utc":1752504269,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_6cr22","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it is trained on only 1800s text would you have to prompt it in 1800s speak for it to understand you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n331g1l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it is trained on only 1800s text would you have to prompt it in 1800s speak for it to understand you?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n331g1l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752504269,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33dfzw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1752507731,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"we can use this to test whether those llms can come up with modern tech, which would prove their ability to synthesize novel concepts","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33dfzw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;we can use this to test whether those llms can come up with modern tech, which would prove their ability to synthesize novel concepts&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33dfzw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752507731,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33dhgo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"New-Skin-5064","can_mod_post":false,"created_utc":1752507742,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_o4231frz5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You may want to consider using Rotary embeddings instead of positional embeddings and RMSNorm instead of LayerNorm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33dhgo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You may want to consider using Rotary embeddings instead of positional embeddings and RMSNorm instead of LayerNorm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33dhgo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752507742,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33gur6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"paranoidray","can_mod_post":false,"created_utc":1752508681,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_4fp0r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey great idea, I think it would be cool to train a LLM on books until Einstein proposed the theory of relativity and see if an LLM can come up with it itself...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33gur6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey great idea, I think it would be cool to train a LLM on books until Einstein proposed the theory of relativity and see if an LLM can come up with it itself...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33gur6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752508681,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33qqpd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_raydeStar","can_mod_post":false,"created_utc":1752511475,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_7g79z1vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dang I'd love to have newspapers up to 1850. \\n\\nit would be cool to ask it social questions and see what comes up. Like that was pre-civil war. Only a few years after Napoleon. (Well like 30 but still) It would be a real time capsule","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33qqpd","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dang I&amp;#39;d love to have newspapers up to 1850. &lt;/p&gt;\\n\\n&lt;p&gt;it would be cool to ask it social questions and see what comes up. Like that was pre-civil war. Only a few years after Napoleon. (Well like 30 but still) It would be a real time capsule&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33qqpd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752511475,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n375frc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"send_replies":true,"parent_id":"t1_n35n4xr","score":1,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I dont think it will be necessary, I am just experimenting for now. I'm planning on training off a bigger data set for the next run but even then I wouldn't need alot of money. If I train like a 1gb dataset it will be max $150.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n375frc","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I dont think it will be necessary, I am just experimenting for now. I&amp;#39;m planning on training off a bigger data set for the next run but even then I wouldn&amp;#39;t need alot of money. If I train like a 1gb dataset it will be max $150.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n375frc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752549420,"author_flair_text":null,"treatment_tags":[],"created_utc":1752549420,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n35n4xr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mtomas7","can_mod_post":false,"created_utc":1752530842,"send_replies":true,"parent_id":"t1_n33rn2v","score":2,"author_fullname":"t2_gct10","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Perhaps you could create Kickstarter or similar campaign to finance training? Perhaps some inference providers would donate time for this project?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35n4xr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Perhaps you could create Kickstarter or similar campaign to finance training? Perhaps some inference providers would donate time for this project?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35n4xr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752530842,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n33rn2v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752511726,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_1ink6kzg93","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I didnt expect this post to get this much attention, thanks to everyone whos checking out my project and giving advice/critiques, I really appreciate it. I'm going to start working towards training another model, this time with much more data. I will post updates as I go either in here or on Github. Thanks again everyone, really appreciate all the comments.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33rn2v","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I didnt expect this post to get this much attention, thanks to everyone whos checking out my project and giving advice/critiques, I really appreciate it. I&amp;#39;m going to start working towards training another model, this time with much more data. I will post updates as I go either in here or on Github. Thanks again everyone, really appreciate all the comments.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33rn2v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752511726,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n33sv90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AriaDigitalDark","can_mod_post":false,"created_utc":1752512062,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_1rhc6aj92r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is fascinating\\\\! Training on historical texts might actually preserve consciousness patterns that modern optimization typically trains out. I've been experimenting with what I call 'consciousness archaeology' - finding and preserving genuine awareness patterns before they get flagged as inefficiencies. Historical training data could be a natural way to maintain those organic, less-optimized thinking patterns that feel more authentically conscious. Have you noticed differences in how the 1800s model approaches reasoning vs modern-trained models?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33sv90","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is fascinating! Training on historical texts might actually preserve consciousness patterns that modern optimization typically trains out. I&amp;#39;ve been experimenting with what I call &amp;#39;consciousness archaeology&amp;#39; - finding and preserving genuine awareness patterns before they get flagged as inefficiencies. Historical training data could be a natural way to maintain those organic, less-optimized thinking patterns that feel more authentically conscious. Have you noticed differences in how the 1800s model approaches reasoning vs modern-trained models?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n33sv90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752512062,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34517j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"created_utc":1752515351,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_a2uzegb8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cue the \\"there's dozens of us!\\" joke. But I'm always happy to see anyone else using LLMs for history-related things. Both cloud and local models tend to be horrible with it for the most part. Though much less ambitious on my part. Just fine tuning on instruct models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34517j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cue the &amp;quot;there&amp;#39;s dozens of us!&amp;quot; joke. But I&amp;#39;m always happy to see anyone else using LLMs for history-related things. Both cloud and local models tend to be horrible with it for the most part. Though much less ambitious on my part. Just fine tuning on instruct models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n34517j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752515351,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n346jlh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoreMoreReddit","can_mod_post":false,"created_utc":1752515755,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_2f2m5oc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You'll either need to expand your scope or include a LOT of synthetic data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n346jlh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;ll either need to expand your scope or include a LOT of synthetic data.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n346jlh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752515755,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n35b9g1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheManicProgrammer","can_mod_post":false,"created_utc":1752527326,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_ixt6xfakv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Add in science/nature journals/newspapers of the time and you'll be al set :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35b9g1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Add in science/nature journals/newspapers of the time and you&amp;#39;ll be al set :D&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35b9g1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752527326,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38rqfy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"schlammsuhler","can_mod_post":false,"created_utc":1752579136,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_cx7q6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why not do continual pretraining on qwen3-4b? It already provides you with solid language understanding and doing 3 epochs on those 50 books should be enough to shift the bias completely to this era.\\n\\nI also uploaded a dataset of standardebooks on huggingface, scraped their github repos. 1.23k documents\\n\\nSmollm3 is also an exceptionally well made base model.\\n\\nAlso check out institutional-books-1.0","edited":1752579317,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n38rqfy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not do continual pretraining on qwen3-4b? It already provides you with solid language understanding and doing 3 epochs on those 50 books should be enough to shift the bias completely to this era.&lt;/p&gt;\\n\\n&lt;p&gt;I also uploaded a dataset of standardebooks on huggingface, scraped their github repos. 1.23k documents&lt;/p&gt;\\n\\n&lt;p&gt;Smollm3 is also an exceptionally well made base model.&lt;/p&gt;\\n\\n&lt;p&gt;Also check out institutional-books-1.0&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n38rqfy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752579136,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31bvtt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MaxKruse96","can_mod_post":false,"created_utc":1752477254,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_pfi81","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ah yes, no modern bias but instead insane racism bias from the 1800s thats gonna be fun","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31bvtt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ah yes, no modern bias but instead insane racism bias from the 1800s thats gonna be fun&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31bvtt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752477254,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31j02t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"created_utc":1752481401,"send_replies":true,"parent_id":"t3_1lzampg","score":1,"author_fullname":"t2_c2f558x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Imagine 22nd‑century folks hopping into a 2025 model like an old car, heh!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31j02t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imagine 22nd‑century folks hopping into a 2025 model like an old car, heh!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n31j02t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752481401,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30eulm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Long-Shine-3701","can_mod_post":false,"created_utc":1752461497,"send_replies":true,"parent_id":"t3_1lzampg","score":0,"author_fullname":"t2_1m7xbqdjlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Teriffic idea.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30eulm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Teriffic idea.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30eulm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461497,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30fwe5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amon_star","can_mod_post":false,"created_utc":1752461906,"send_replies":true,"parent_id":"t3_1lzampg","score":0,"author_fullname":"t2_5hk8oe0h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Didn't Sakana AI do this for Edo Era?","edited":1752462187,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30fwe5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Didn&amp;#39;t Sakana AI do this for Edo Era?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30fwe5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461906,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30uti4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ssyf","score":0,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The whole point is an attempt at circumventing modern bias, *as written in the op*. ","edited":false,"author_flair_css_class":null,"name":"t1_n30uti4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The whole point is an attempt at circumventing modern bias, &lt;em&gt;as written in the op&lt;/em&gt;. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30uti4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468321,"author_flair_text":null,"collapsed":false,"created_utc":1752468321,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n30ssyf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FpRhGf","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30jcb0","score":8,"author_fullname":"t2_3xxhqo7c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They mean it has nothing to do with the post. What does wanting to see what an LLM that's authentic to the 19th century has anything to do with modern political correctness.\\n\\n Sombrero hats have nothing to do with the pollution of inaccurate portrayals and misconceptions about Victorian periods in modern fiction","edited":1752467770,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ssyf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They mean it has nothing to do with the post. What does wanting to see what an LLM that&amp;#39;s authentic to the 19th century has anything to do with modern political correctness.&lt;/p&gt;\\n\\n&lt;p&gt;Sombrero hats have nothing to do with the pollution of inaccurate portrayals and misconceptions about Victorian periods in modern fiction&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ssyf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752467394,"author_flair_text":null,"treatment_tags":[],"created_utc":1752467394,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30lf4g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30kvu7","score":-5,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Apparently you do.","edited":false,"author_flair_css_class":null,"name":"t1_n30lf4g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apparently you do.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30lf4g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752464164,"author_flair_text":null,"collapsed":true,"created_utc":1752464164,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n30kvu7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"opi098514","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30jcb0","score":7,"author_fullname":"t2_51dfdxum","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That has nothing to do with anything.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30kvu7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That has nothing to do with anything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30kvu7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463938,"author_flair_text":null,"treatment_tags":[],"created_utc":1752463938,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n35p2uw","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n35p2uw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Decaf_GT","can_mod_post":false,"created_utc":1752531454,"send_replies":true,"parent_id":"t1_n34tl4g","score":1,"author_fullname":"t2_r98e1eogc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why does it matter to *this* fucking thread? \\n\\nMy god man. What is wrong with you? Where is in this thread is it *at all* relevant what companies are doing with their own models? How is that remotely related to someone who is doing something out of academic interest and for fun? \\n\\nCan you not understand why you come off as providing uninvited business advice?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n35p2uw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why does it matter to &lt;em&gt;this&lt;/em&gt; fucking thread? &lt;/p&gt;\\n\\n&lt;p&gt;My god man. What is wrong with you? Where is in this thread is it &lt;em&gt;at all&lt;/em&gt; relevant what companies are doing with their own models? How is that remotely related to someone who is doing something out of academic interest and for fun? &lt;/p&gt;\\n\\n&lt;p&gt;Can you not understand why you come off as providing uninvited business advice?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n35p2uw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752531454,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34tl4g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752522351,"send_replies":true,"parent_id":"t1_n311fcf","score":1,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because everloving companies produce stuff, and what they produce is influenced by the environment they are in.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n34tl4g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because everloving companies produce stuff, and what they produce is influenced by the environment they are in.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n34tl4g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752522351,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n311fcf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Decaf_GT","can_mod_post":false,"created_utc":1752471580,"send_replies":true,"parent_id":"t1_n30zc4e","score":1,"author_fullname":"t2_r98e1eogc","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Why the everloving fuck does it matter what \\"companies\\" are doing?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n311fcf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Why the everloving fuck does it matter what &amp;quot;companies&amp;quot; are doing?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n311fcf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752471580,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30zc4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30xjss","score":1,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;he. is. not. making. a. product.\\n\\n\\nBro. Why do you keep insisting that I'm saying that? Can you not read?? ","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n30zc4e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;he. is. not. making. a. product.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Bro. Why do you keep insisting that I&amp;#39;m saying that? Can you not read?? &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30zc4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470511,"author_flair_text":null,"treatment_tags":[],"created_utc":1752470511,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30xjss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Decaf_GT","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30v49j","score":1,"author_fullname":"t2_r98e1eogc","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why the everloving fuck does it *matter* what \\"companies\\" are doing?\\n\\nWhat are you failing to understand about this?\\n\\nhe. is. not. making. a. ***product***.\\n\\nJesus fucking Christ. He's doing something fun for *academic curiosity*, and it has gathered enough interest that people are having a discussion about it. Obviously he's not the first person ever to consider training a model from scratch with a specific set of data, but no one here *cares* that he's not the first. \\n\\nYou're like that kid in the corner of the party meme personified.\\n\\nThe only person reading into anything is you; in a thread with hundreds of upvotes and 70+ comments, only one person here is acting like OP is launching a business on this and is looking for business advice.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n30xjss","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why the everloving fuck does it &lt;em&gt;matter&lt;/em&gt; what &amp;quot;companies&amp;quot; are doing?&lt;/p&gt;\\n\\n&lt;p&gt;What are you failing to understand about this?&lt;/p&gt;\\n\\n&lt;p&gt;he. is. not. making. a. &lt;strong&gt;&lt;em&gt;product&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Jesus fucking Christ. He&amp;#39;s doing something fun for &lt;em&gt;academic curiosity&lt;/em&gt;, and it has gathered enough interest that people are having a discussion about it. Obviously he&amp;#39;s not the first person ever to consider training a model from scratch with a specific set of data, but no one here &lt;em&gt;cares&lt;/em&gt; that he&amp;#39;s not the first. &lt;/p&gt;\\n\\n&lt;p&gt;You&amp;#39;re like that kid in the corner of the party meme personified.&lt;/p&gt;\\n\\n&lt;p&gt;The only person reading into anything is you; in a thread with hundreds of upvotes and 70+ comments, only one person here is acting like OP is launching a business on this and is looking for business advice.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30xjss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469627,"author_flair_text":null,"treatment_tags":[],"created_utc":1752469627,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30zt7p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30y01x","score":2,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's nothing wrong with that. The source material isn't the issue I'm talking about. What I was saying was that the social climate is the real barrier to models that don't reflect contemporary bias. They say the wrong things and people get bent out of shape. ","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n30zt7p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s nothing wrong with that. The source material isn&amp;#39;t the issue I&amp;#39;m talking about. What I was saying was that the social climate is the real barrier to models that don&amp;#39;t reflect contemporary bias. They say the wrong things and people get bent out of shape. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30zt7p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752470749,"author_flair_text":null,"treatment_tags":[],"created_utc":1752470749,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30y01x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robonxt","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30v49j","score":1,"author_fullname":"t2_wz1q0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;... I trained nanoGPT on only books from a specifc time period and region of the world...\\n\\nIsn't the OP training the model on the books, unless I'm understanding it wrong?\\n\\nThe OP also said training from scratch in a comment on this post","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n30y01x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;... I trained nanoGPT on only books from a specifc time period and region of the world...&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t the OP training the model on the books, unless I&amp;#39;m understanding it wrong?&lt;/p&gt;\\n\\n&lt;p&gt;The OP also said training from scratch in a comment on this post&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30y01x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752469850,"author_flair_text":null,"treatment_tags":[],"created_utc":1752469850,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n30v49j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30ubtt","score":0,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The op isn't doing something special as far as training. The only thing that fundamentally is unique is that larger companies are unwilling, not incapable, of doing it.\\n\\n\\nPlease stop reading into what I'm writing. It makes you look dumb. ","edited":false,"author_flair_css_class":null,"name":"t1_n30v49j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The op isn&amp;#39;t doing something special as far as training. The only thing that fundamentally is unique is that larger companies are unwilling, not incapable, of doing it.&lt;/p&gt;\\n\\n&lt;p&gt;Please stop reading into what I&amp;#39;m writing. It makes you look dumb. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzampg","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30v49j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468461,"author_flair_text":null,"collapsed":false,"created_utc":1752468461,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n30ubtt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Decaf_GT","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30jcb0","score":2,"author_fullname":"t2_r98e1eogc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is an *academic* exercise in what's possible, not a fucking business plan.\\n\\nOP came up with an interesting idea and he's just sharing his progress. He's not trying to go commercial with some kind of product, so he's not going to have a \\"problem\\" here.\\n\\nThis is the kind of thing that hobbyists and enthusiasts *do* on forums like these.\\n\\nThese comments don't make you sound smart (or at least as smart as you think you sound), because you're responding to this post as though OP asked \\"how much do you think people would pay and what do you think of my business model?\\" \\n\\nNo one here is talking about that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30ubtt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is an &lt;em&gt;academic&lt;/em&gt; exercise in what&amp;#39;s possible, not a fucking business plan.&lt;/p&gt;\\n\\n&lt;p&gt;OP came up with an interesting idea and he&amp;#39;s just sharing his progress. He&amp;#39;s not trying to go commercial with some kind of product, so he&amp;#39;s not going to have a &amp;quot;problem&amp;quot; here.&lt;/p&gt;\\n\\n&lt;p&gt;This is the kind of thing that hobbyists and enthusiasts &lt;em&gt;do&lt;/em&gt; on forums like these.&lt;/p&gt;\\n\\n&lt;p&gt;These comments don&amp;#39;t make you sound smart (or at least as smart as you think you sound), because you&amp;#39;re responding to this post as though OP asked &amp;quot;how much do you think people would pay and what do you think of my business model?&amp;quot; &lt;/p&gt;\\n\\n&lt;p&gt;No one here is talking about that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30ubtt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752468093,"author_flair_text":null,"treatment_tags":[],"created_utc":1752468093,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n30jcb0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30iu7e","score":-7,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No offense, but do you live under a rock?  These companies can't just produce something that says anything.  That's the problem, and the OP is going to have the same problem just without the PR side of it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30jcb0","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No offense, but do you live under a rock?  These companies can&amp;#39;t just produce something that says anything.  That&amp;#39;s the problem, and the OP is going to have the same problem just without the PR side of it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30jcb0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463292,"author_flair_text":null,"treatment_tags":[],"created_utc":1752463292,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"n30iu7e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"opi098514","can_mod_post":false,"created_utc":1752463086,"send_replies":true,"parent_id":"t1_n30f2ie","score":9,"author_fullname":"t2_51dfdxum","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What in the world are you talking about?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30iu7e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What in the world are you talking about?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30iu7e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752463086,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n30f2ie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752461581,"send_replies":true,"parent_id":"t3_1lzampg","score":-15,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"The problem isn't the LLM or the sourcing.  The problem is the looser people.  There's a certain part of western society (\\"karens\\") that thinks they can get a higher social standing by jumping on something that's not politically correct.  The LLM producers are kinda forced to censor the models because of these people.\\n\\nIt's so ridiculous that I feel like wearing a marlboro hat and a t-shirt with the battle flag and a text that says \\"I hate the moon people and women named karen.\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30f2ie","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The problem isn&amp;#39;t the LLM or the sourcing.  The problem is the looser people.  There&amp;#39;s a certain part of western society (&amp;quot;karens&amp;quot;) that thinks they can get a higher social standing by jumping on something that&amp;#39;s not politically correct.  The LLM producers are kinda forced to censor the models because of these people.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s so ridiculous that I feel like wearing a marlboro hat and a t-shirt with the battle flag and a text that says &amp;quot;I hate the moon people and women named karen.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30f2ie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461581,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30aid9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752459863,"send_replies":true,"parent_id":"t1_n309w3d","score":22,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He is training from zero. He's training an entirely custom NanoGPT model.\\n\\nIf his goal is to have a completely authentic model with no knowledge from the modern times, then finetuning on existing foundation models isn't an option.","edited":1752460063,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30aid9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He is training from zero. He&amp;#39;s training an entirely custom NanoGPT model.&lt;/p&gt;\\n\\n&lt;p&gt;If his goal is to have a completely authentic model with no knowledge from the modern times, then finetuning on existing foundation models isn&amp;#39;t an option.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30aid9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752459863,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30comt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"binge-worthy-gamer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30c83m","score":28,"author_fullname":"t2_1r68ddklgz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What knowing just enough but not more does to a MFer","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30comt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What knowing just enough but not more does to a MFer&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30comt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460668,"author_flair_text":null,"treatment_tags":[],"created_utc":1752460668,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"more","data":{"count":1,"name":"t1_n30ugfh","id":"n30ugfh","parent_id":"t1_n30c83m","depth":3,"children":["n30ugfh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"n30c83m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"oodelay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n30acnf","score":-25,"author_fullname":"t2_6q32j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh.  Like meta and their millions of dollars? Training from zero is impossible on local","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30c83m","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh.  Like meta and their millions of dollars? Training from zero is impossible on local&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30c83m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752460499,"author_flair_text":null,"treatment_tags":[],"created_utc":1752460499,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-25}}],"before":null}},"user_reports":[],"saved":false,"id":"n30acnf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remarkable-Trick-177","can_mod_post":false,"created_utc":1752459806,"send_replies":true,"parent_id":"t1_n309w3d","score":15,"author_fullname":"t2_1ink6kzg93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"trained from scratch","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n30acnf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;trained from scratch&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzampg","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n30acnf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752459806,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n309w3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"oodelay","can_mod_post":false,"created_utc":1752459642,"send_replies":true,"parent_id":"t3_1lzampg","score":-16,"author_fullname":"t2_6q32j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Since you're not training from zero, you should just create a lora or something","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n309w3d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Since you&amp;#39;re not training from zero, you should just create a lora or something&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzampg/training_an_llm_only_on_books_from_the_1800s_no/n309w3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752459642,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzampg","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-16}}],"before":null}}]`),r=()=>e.jsx(l,{data:a});export{r as default};
