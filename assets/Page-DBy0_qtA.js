import{j as t}from"./index-Bu7qcPAU.js";import{R as e}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I am trying to Lora fine-tune `SmolLM2-135M-Instruct` on the following dataset: [https://huggingface.co/datasets/nvidia/OpenMathInstruct-2](https://huggingface.co/datasets/nvidia/OpenMathInstruct-2) (Data Credit: u/mlabonne).\\n\\nI want the model to be able to reason properly and generate accurate answers. The dataset provides well-structured examples that include both the reasoning process and the final answer.\\n\\nFor fine-tuning, I used a small subset of the source dataset: 1000 samples (train + validation) for training, 200 for testing, and 600 for reinforcement learning using GRPO — as implementing GRPO on a supervised fine-tuned (SFT) model is my primary goal.\\n\\nHowever, the model consistently overfits, regardless of the training parameters I set.\\n\\n**Configurations Tried:**\\n\\n* Rank (r): 32 to 256\\n* Alpha: 64 to 512\\n* Learning Rate: 1e-5 to 2e-5\\n* Dropout: 0.1 to 0.15\\n* Training Samples: 500 to 1000\\n* Epochs: 3 to 5\\n\\nDespite these variations, I consistently observe the following pattern (Overfitting)\\n\\n|Step|Training Loss|Validation Loss|\\n|:-|:-|:-|\\n|500|1.196400|0.323741|\\n|1000|0.296100|0.291743|\\n|1500|0.287000|0.285877|\\n|2000|0.281500|0.283573|\\n|2500|0.276700|0.282866|\\n\\nWhen testing the updated model on training data, it rarely follows the expected output format or produces coherent reasoning.\\n\\nAm I missing something here?\\n\\nWhat potential solutions could actually help?  \\nShould I increase the training dataset size or the number of epochs?\\n\\nOr is the data inherently too complex for a 135M-parameter model to reason well? If that were the case, increasing **LoRA** rank and alpha should have shown some improvement — but it didn’t.\\n\\nLooking for suggestions or best practices to move forward effectively.\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Difficulty in fine tuning (Llora) SmolLM2-135M-Instruct on \\"GSM8K and MATH\\" training data.","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvek0j","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.72,"author_flair_background_color":null,"subreddit_type":"public","ups":3,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_5udv460k0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":3,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752054024,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I am trying to Lora fine-tune &lt;code&gt;SmolLM2-135M-Instruct&lt;/code&gt; on the following dataset: &lt;a href=\\"https://huggingface.co/datasets/nvidia/OpenMathInstruct-2\\"&gt;https://huggingface.co/datasets/nvidia/OpenMathInstruct-2&lt;/a&gt; (Data Credit: &lt;a href=\\"/u/mlabonne\\"&gt;u/mlabonne&lt;/a&gt;).&lt;/p&gt;\\n\\n&lt;p&gt;I want the model to be able to reason properly and generate accurate answers. The dataset provides well-structured examples that include both the reasoning process and the final answer.&lt;/p&gt;\\n\\n&lt;p&gt;For fine-tuning, I used a small subset of the source dataset: 1000 samples (train + validation) for training, 200 for testing, and 600 for reinforcement learning using GRPO — as implementing GRPO on a supervised fine-tuned (SFT) model is my primary goal.&lt;/p&gt;\\n\\n&lt;p&gt;However, the model consistently overfits, regardless of the training parameters I set.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Configurations Tried:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Rank (r): 32 to 256&lt;/li&gt;\\n&lt;li&gt;Alpha: 64 to 512&lt;/li&gt;\\n&lt;li&gt;Learning Rate: 1e-5 to 2e-5&lt;/li&gt;\\n&lt;li&gt;Dropout: 0.1 to 0.15&lt;/li&gt;\\n&lt;li&gt;Training Samples: 500 to 1000&lt;/li&gt;\\n&lt;li&gt;Epochs: 3 to 5&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Despite these variations, I consistently observe the following pattern (Overfitting)&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Step&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Training Loss&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Validation Loss&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;500&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1.196400&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.323741&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1000&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.296100&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.291743&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1500&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.287000&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.285877&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2000&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.281500&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.283573&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2500&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.276700&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0.282866&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;When testing the updated model on training data, it rarely follows the expected output format or produces coherent reasoning.&lt;/p&gt;\\n\\n&lt;p&gt;Am I missing something here?&lt;/p&gt;\\n\\n&lt;p&gt;What potential solutions could actually help?&lt;br/&gt;\\nShould I increase the training dataset size or the number of epochs?&lt;/p&gt;\\n\\n&lt;p&gt;Or is the data inherently too complex for a 135M-parameter model to reason well? If that were the case, increasing &lt;strong&gt;LoRA&lt;/strong&gt; rank and alpha should have shown some improvement — but it didn’t.&lt;/p&gt;\\n\\n&lt;p&gt;Looking for suggestions or best practices to move forward effectively.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?auto=webp&amp;s=6f62117033fbd51d6e16e62b3d8dc4fa78be2fd1","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=19ac8df165c71d6637604e5d011a7d67effb0c8b","width":108,"height":58},{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=87b2bb64908b63d3a687df8a9bbbdbb60f960365","width":216,"height":116},{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c0c7a08d02fce00ea7a8d862c33ce00df7b4a96","width":320,"height":172},{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=67bbb7157bbb66d26bd701b28236d68ca6dff9b6","width":640,"height":345},{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bcbb7e8068fa08a545d7b513071943ec6eb77c3c","width":960,"height":518},{"url":"https://external-preview.redd.it/gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=edf5dd82dc434a9d68a1136edf6924bf96af78da","width":1080,"height":583}],"variants":{},"id":"gUh3kUi-FubXvGXK7mVFv9rSuNEqRPbzwtKv35rb3aU"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lvek0j","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Evening-Power-3302","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/","subreddit_subscribers":497025,"created_utc":1752054024,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cebwf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ExtremeAcceptable289","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cbdru","score":1,"author_fullname":"t2_8hpbax1b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its most likely just the model is too small to get anything useful whatsoever out of it. Tr a bigger model like smollm2 360b or qwen3 0.6b","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cebwf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its most likely just the model is too small to get anything useful whatsoever out of it. Tr a bigger model like smollm2 360b or qwen3 0.6b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvek0j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/n2cebwf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752146298,"author_flair_text":null,"treatment_tags":[],"created_utc":1752146298,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cbdru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening-Power-3302","can_mod_post":false,"created_utc":1752144966,"send_replies":true,"parent_id":"t1_n25ivc0","score":1,"author_fullname":"t2_5udv460k0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But isn\'t the case that the model should at least be able to generated some correct answers or follow the output format, so that RL has some positive rewards to build upon?\\n\\nAbove idea is the reason I decided to perform Supervised Fine Tuning before RL, as I wanted the LLM to be capable of doing at least some things correctly.\\n\\nDo let me know if my understanding or method is incorrect.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cbdru","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But isn&amp;#39;t the case that the model should at least be able to generated some correct answers or follow the output format, so that RL has some positive rewards to build upon?&lt;/p&gt;\\n\\n&lt;p&gt;Above idea is the reason I decided to perform Supervised Fine Tuning before RL, as I wanted the LLM to be capable of doing at least some things correctly.&lt;/p&gt;\\n\\n&lt;p&gt;Do let me know if my understanding or method is incorrect.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvek0j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/n2cbdru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752144966,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n25ivc0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ExtremeAcceptable289","can_mod_post":false,"created_utc":1752058627,"send_replies":true,"parent_id":"t3_1lvek0j","score":2,"author_fullname":"t2_8hpbax1b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For one your loss is approaching zero, which is bad, as this most likely means your model is being overfitted and loses performance on tasks outside the training data.\\n\\nSecond, if you want reasoning, you\'ll have to look into GRPO/reinforcement learning training as opposed to QLora\\n\\nHere is a good guide anout it https://docs.unsloth.ai/basics/reinforcement-learning-guide/tutorial-train-your-own-reasoning-model-with-grpo","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25ivc0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For one your loss is approaching zero, which is bad, as this most likely means your model is being overfitted and loses performance on tasks outside the training data.&lt;/p&gt;\\n\\n&lt;p&gt;Second, if you want reasoning, you&amp;#39;ll have to look into GRPO/reinforcement learning training as opposed to QLora&lt;/p&gt;\\n\\n&lt;p&gt;Here is a good guide anout it &lt;a href=\\"https://docs.unsloth.ai/basics/reinforcement-learning-guide/tutorial-train-your-own-reasoning-model-with-grpo\\"&gt;https://docs.unsloth.ai/basics/reinforcement-learning-guide/tutorial-train-your-own-reasoning-model-with-grpo&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/n25ivc0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752058627,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvek0j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cbiaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening-Power-3302","can_mod_post":false,"created_utc":1752145025,"send_replies":true,"parent_id":"t1_n25iuow","score":1,"author_fullname":"t2_5udv460k0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, sure. Will try out few things and give you details.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cbiaa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, sure. Will try out few things and give you details.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvek0j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/n2cbiaa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752145025,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n25iuow","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"created_utc":1752058619,"send_replies":true,"parent_id":"t3_1lvek0j","score":1,"author_fullname":"t2_9so78ol2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1000 examples is too low, it’s just going to learn surface level elements.\\n\\nand i feel like i would’ve preferred a wall of text of straight detail rather than this nice concise post.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25iuow","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1000 examples is too low, it’s just going to learn surface level elements.&lt;/p&gt;\\n\\n&lt;p&gt;and i feel like i would’ve preferred a wall of text of straight detail rather than this nice concise post.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvek0j/difficulty_in_fine_tuning_llora/n25iuow/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752058619,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvek0j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),o=()=>t.jsx(e,{data:l});export{o as default};
