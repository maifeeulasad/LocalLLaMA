const e=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Just sharing my efforts, really, and thank you for reading in advance.  \\n  \\nI am working on an LLM engine nicknamed Nyra in rust and c++20.  \\n  \\nSo managed to do local LLM Inference on iPhone in 70ms and 15 TPS (could be massively improved once metal is in motion)  \\n\\n\\nOne of the images shows that previously I optimized safetensors loading on-device for my custom runtime. That was step one.  \\nSince then, after some really hard push over the last 48 hours, I've integrated inference, built tokenizer support. So today Nyra generated her first poem.   \\nThat was step two.  \\n  \\nIt is fully offline. Started to work after I nearly gave up multiple times, fully loaded with coffee and being lost between calculations, kernels and the like. Also occasionally my face took the shape of the keyboard falling asleep on it.  \\n  \\nSo what is it that I am showing?  \\n\\\\-&gt; iphone in flight mode, check.  \\n\\\\-&gt; No cloud. No API. No fluff. Just pure, local inference, check.  \\n\\\\-&gt; Loaded 1.1B model in &lt;2s, check.  \\n\\\\-&gt; Ran inference at 15 tokens/sec, well could be better as there is no Metal just yet, but check.  \\n\\\\-&gt; CLI-based stream loop, well for devs thats cool, swiftui coming up, check.  \\n\\\\-&gt; All native Rust + C++20 + SwiftUI pipeline, possibility to improve speed, check.  \\n\\\\-&gt; Zero cloud, full privacy and full locality, yes thats my core philosophy, check.  \\n  \\nCloud? no. All local privacy driven. So yes, lets be sovereign.If one doesn't have the proper hardware AI is slow. I try to change that by running AI (LLMs) with acceptable speed on any hardware and anywhere.   \\nNyra is different: she's modular, fast, local - and soon pluggable.\\n\\nThanks for reading  \\nErvin\\n\\nhttps://preview.redd.it/s14m8e4bj1af1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=6e1b0c1f95a26d2b284a9e18b5936dfc7e0340f9\\n\\nhttps://preview.redd.it/amav0e4bj1af1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=2a878999d57ab1d386ff367d6ca84792da082804\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"From the trenches, running TinyLlama-1.1B-Chat-v0.1 on iPhone","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":105,"top_awarded_type":null,"hide_score":false,"media_metadata":{"s14m8e4bj1af1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":81,"x":108,"u":"https://preview.redd.it/s14m8e4bj1af1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66e6e0db25ce395d2b6f8f5cb77dd3bc96044649"},{"y":162,"x":216,"u":"https://preview.redd.it/s14m8e4bj1af1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=300525c782f564662a2e68eebba8385f036d4d82"},{"y":240,"x":320,"u":"https://preview.redd.it/s14m8e4bj1af1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fbc1d1e6d4463038c8d83698cba2f09ce60e1071"},{"y":480,"x":640,"u":"https://preview.redd.it/s14m8e4bj1af1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=432c328de403aa3060e0ea8e7a3737c084757ac9"}],"s":{"y":600,"x":800,"u":"https://preview.redd.it/s14m8e4bj1af1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=6e1b0c1f95a26d2b284a9e18b5936dfc7e0340f9"},"id":"s14m8e4bj1af1"},"amav0e4bj1af1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":81,"x":108,"u":"https://preview.redd.it/amav0e4bj1af1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=10452933904ae438857305a0e2ebd9ab983fde13"},{"y":162,"x":216,"u":"https://preview.redd.it/amav0e4bj1af1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b640c9fc8bb192442a8ddb40b98bd5c2574ead86"},{"y":240,"x":320,"u":"https://preview.redd.it/amav0e4bj1af1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e11704e7a6bd54ac16299113af34a23a168bea3"},{"y":480,"x":640,"u":"https://preview.redd.it/amav0e4bj1af1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b29485e27577d6a8db01f6c3d2b78ef685d4fd6d"}],"s":{"y":600,"x":800,"u":"https://preview.redd.it/amav0e4bj1af1.jpg?width=800&amp;format=pjpg&amp;auto=webp&amp;s=2a878999d57ab1d386ff367d6ca84792da082804"},"id":"amav0e4bj1af1"}},"name":"t3_1lo3y10","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.86,"author_flair_background_color":null,"subreddit_type":"public","ups":10,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1q37ljt3oe","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":10,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://a.thumbs.redditmedia.com/BmhTBEiot-JKM8Kb5v3YYr7Ub3MMnW26yW31Xikq6X4.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751278905,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Just sharing my efforts, really, and thank you for reading in advance.  &lt;/p&gt;\\n\\n&lt;p&gt;I am working on an LLM engine nicknamed Nyra in rust and c++20.  &lt;/p&gt;\\n\\n&lt;p&gt;So managed to do local LLM Inference on iPhone in 70ms and 15 TPS (could be massively improved once metal is in motion)  &lt;/p&gt;\\n\\n&lt;p&gt;One of the images shows that previously I optimized safetensors loading on-device for my custom runtime. That was step one.&lt;br/&gt;\\nSince then, after some really hard push over the last 48 hours, I&amp;#39;ve integrated inference, built tokenizer support. So today Nyra generated her first poem.&lt;br/&gt;\\nThat was step two.  &lt;/p&gt;\\n\\n&lt;p&gt;It is fully offline. Started to work after I nearly gave up multiple times, fully loaded with coffee and being lost between calculations, kernels and the like. Also occasionally my face took the shape of the keyboard falling asleep on it.  &lt;/p&gt;\\n\\n&lt;p&gt;So what is it that I am showing?&lt;br/&gt;\\n-&amp;gt; iphone in flight mode, check.&lt;br/&gt;\\n-&amp;gt; No cloud. No API. No fluff. Just pure, local inference, check.&lt;br/&gt;\\n-&amp;gt; Loaded 1.1B model in &amp;lt;2s, check.  \\n\\\\-&amp;gt; Ran inference at 15 tokens/sec, well could be better as there is no Metal just yet, but check.&lt;br/&gt;\\n-&amp;gt; CLI-based stream loop, well for devs thats cool, swiftui coming up, check.&lt;br/&gt;\\n-&amp;gt; All native Rust + C++20 + SwiftUI pipeline, possibility to improve speed, check.&lt;br/&gt;\\n-&amp;gt; Zero cloud, full privacy and full locality, yes thats my core philosophy, check.  &lt;/p&gt;\\n\\n&lt;p&gt;Cloud? no. All local privacy driven. So yes, lets be sovereign.If one doesn&amp;#39;t have the proper hardware AI is slow. I try to change that by running AI (LLMs) with acceptable speed on any hardware and anywhere.&lt;br/&gt;\\nNyra is different: she&amp;#39;s modular, fast, local - and soon pluggable.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for reading&lt;br/&gt;\\nErvin&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/s14m8e4bj1af1.jpg?width=800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6e1b0c1f95a26d2b284a9e18b5936dfc7e0340f9\\"&gt;https://preview.redd.it/s14m8e4bj1af1.jpg?width=800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=6e1b0c1f95a26d2b284a9e18b5936dfc7e0340f9&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/amav0e4bj1af1.jpg?width=800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2a878999d57ab1d386ff367d6ca84792da082804\\"&gt;https://preview.redd.it/amav0e4bj1af1.jpg?width=800&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2a878999d57ab1d386ff367d6ca84792da082804&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lo3y10","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"rvnllm","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lo3y10/from_the_trenches_running_tinyllama11bchatv01_on/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lo3y10/from_the_trenches_running_tinyllama11bchatv01_on/","subreddit_subscribers":492927,"created_utc":1751278905,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kc7vk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rvnllm","can_mod_post":false,"created_utc":1751285636,"send_replies":true,"parent_id":"t1_n0k5fiv","score":1,"author_fullname":"t2_1q37ljt3oe","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Haha it has. Ill have a look.  The difficulty is that my mac is old MPS capable but not MLX while my phone is so there is no way to test it on mac or using a simulator, i9 vs M2/M3 etc. Why it takes longer to build the proper kernel for matmul and the like. Oh well. I think I could ramp up the TPS to 20-40?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kc7vk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haha it has. Ill have a look.  The difficulty is that my mac is old MPS capable but not MLX while my phone is so there is no way to test it on mac or using a simulator, i9 vs M2/M3 etc. Why it takes longer to build the proper kernel for matmul and the like. Oh well. I think I could ramp up the TPS to 20-40?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lo3y10","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo3y10/from_the_trenches_running_tinyllama11bchatv01_on/n0kc7vk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751285636,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0k5fiv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1751282683,"send_replies":true,"parent_id":"t3_1lo3y10","score":3,"author_fullname":"t2_p45er6oo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great work mate!\\n\\n\\nI hope your face has recovered from the keycap imprint. Otherwise, you'd be my nightmare come true, the one that adults used to tell me about when I was a child: that my eyes would eventually get square shaped if I looked at the CRT monitor too much.\\n\\n\\nBy the way: are you familiar with LLMFarm for ios from the developer guinmoon?\\n\\n\\nYou might find inspiration for the Metal implementation there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0k5fiv","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great work mate!&lt;/p&gt;\\n\\n&lt;p&gt;I hope your face has recovered from the keycap imprint. Otherwise, you&amp;#39;d be my nightmare come true, the one that adults used to tell me about when I was a child: that my eyes would eventually get square shaped if I looked at the CRT monitor too much.&lt;/p&gt;\\n\\n&lt;p&gt;By the way: are you familiar with LLMFarm for ios from the developer guinmoon?&lt;/p&gt;\\n\\n&lt;p&gt;You might find inspiration for the Metal implementation there.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lo3y10/from_the_trenches_running_tinyllama11bchatv01_on/n0k5fiv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751282683,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lo3y10","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`);export{e as default};
