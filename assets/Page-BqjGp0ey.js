import{j as e}from"./index-DACS7Nh6.js";import{R as l}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Deepseek v3","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1jj6i4m","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"ups":1523,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_4wyp4xpi","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":1523,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/Qv5uXkfZCEujqL5ORaUXDqh9nAEcU1nRap_-gaZW6xE.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1742861971,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/xaic503gbqqe1.jpeg","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?auto=webp&amp;s=f17a795d64bb65f9b957a15a77818de62006b330","width":1289,"height":2040},"resolutions":[{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a285029f37c7c0078baab2da09fc42604df3dc6","width":108,"height":170},{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=30b5620ff751102bd1be6858261186cd7f7b69a2","width":216,"height":341},{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0c792c3b365b55de02c06798fff58b546e05aa3","width":320,"height":506},{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=616bfd3de239ef7db7a2416bc9be3a95051f9c0b","width":640,"height":1012},{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2787c8f12b9413d1d2c5541c4e3a405f9eff64c2","width":960,"height":1519},{"url":"https://preview.redd.it/xaic503gbqqe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=638722dcf4598ebe0cf4113cc72f54bafc99e858","width":1080,"height":1709}],"variants":{},"id":"J40p3sAKcvWsz53B8Isv-zuxiqJi7lKwdO_BuwYFaOc"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1jj6i4m","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"TheLogiqueViper","discussion_type":null,"num_comments":185,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/","stickied":false,"url":"https://i.redd.it/xaic503gbqqe1.jpeg","subreddit_subscribers":492315,"created_utc":1742861971,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mk50yof","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Stuff-347","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmmbwo","score":-1,"author_fullname":"t2_m5u9f1xs1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Any computer ever created can be thermally throttled","edited":false,"author_flair_css_class":null,"name":"t1_mk50yof","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any computer ever created can be thermally throttled&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mk50yof/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743139684,"author_flair_text":null,"collapsed":false,"created_utc":1743139684,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmmbwo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kweglinski","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmi5rw","score":16,"author_fullname":"t2_7gw03ro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"mac studio can get thermally throttled? didn't know that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmmbwo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mac studio can get thermally throttled? didn&amp;#39;t know that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmmbwo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895684,"author_flair_text":null,"treatment_tags":[],"created_utc":1742895684,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjtgeza","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vaddieg","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjrygs8","score":1,"author_fullname":"t2_10g07z","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I never heard about thermal issues on mac studio. Maxed out M1 ultra GPU consumes up to 80W in prompt processing and 60W when generating tokens","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjtgeza","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I never heard about thermal issues on mac studio. Maxed out M1 ultra GPU consumes up to 80W in prompt processing and 60W when generating tokens&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjtgeza/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742989768,"author_flair_text":null,"treatment_tags":[],"created_utc":1742989768,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mk2v9wc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llamaCTO","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjrygs8","score":1,"author_fullname":"t2_xmk202i3y","approved_by":null,"mod_note":null,"all_awardings":[],"body":"can't say for the ultra (which I have but have yet to get going to put through the paces) - but that's definitely true for the m4max - I use TG Pro with \\"Auto Max\\" setting which basically gets way more aggressive about ramping\\n\\nWhat I've noticed with inference is it \\\\*appears\\\\* that once you are throttled for temp the process remains throttled. (Which is decided untrue for battery low-power vs high power; if you manually set high power you can visible watch the token speed \\\\~triple)\\n\\nbut I recently experimented, got myself throttled, and even between generations speed did not recover (eg, gpu was COOL again) - but the moment I restarted the process it was back to full speed.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mk2v9wc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;can&amp;#39;t say for the ultra (which I have but have yet to get going to put through the paces) - but that&amp;#39;s definitely true for the m4max - I use TG Pro with &amp;quot;Auto Max&amp;quot; setting which basically gets way more aggressive about ramping&lt;/p&gt;\\n\\n&lt;p&gt;What I&amp;#39;ve noticed with inference is it *appears* that once you are throttled for temp the process remains throttled. (Which is decided untrue for battery low-power vs high power; if you manually set high power you can visible watch the token speed ~triple)&lt;/p&gt;\\n\\n&lt;p&gt;but I recently experimented, got myself throttled, and even between generations speed did not recover (eg, gpu was COOL again) - but the moment I restarted the process it was back to full speed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mk2v9wc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743111940,"author_flair_text":null,"treatment_tags":[],"created_utc":1743111940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjrygs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheDreamSymphonic","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmnkhn","score":1,"author_fullname":"t2_531u9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, I don't disagree about the math aspect, but significantly earlier than long context mine slows down due to heat. I am looking into changing the fan curves because I think they are probably too relaxed","edited":false,"author_flair_css_class":null,"name":"t1_mjrygs8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, I don&amp;#39;t disagree about the math aspect, but significantly earlier than long context mine slows down due to heat. I am looking into changing the fan curves because I think they are probably too relaxed&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjrygs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742959332,"author_flair_text":null,"collapsed":false,"created_utc":1742959332,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmnkhn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Vaddieg","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmi5rw","score":13,"author_fullname":"t2_10g07z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it's being throttled mathematically. M1 ultra + QwQ 32B Generates 28 t/s on small contexts and 4.5 t/s when going full 128k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmnkhn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s being throttled mathematically. M1 ultra + QwQ 32B Generates 28 t/s on small contexts and 4.5 t/s when going full 128k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmnkhn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742896455,"author_flair_text":null,"treatment_tags":[],"created_utc":1742896455,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mk43x44","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheDreamWoken","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmi5rw","score":1,"author_fullname":"t2_151ddpzf3g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems like a huge bottleneck. And I usually use LLMs with far more context than 69 prompt tokens, these speed tests need to really be standardized on a 8192 token sized prompt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mk43x44","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems like a huge bottleneck. And I usually use LLMs with far more context than 69 prompt tokens, these speed tests need to really be standardized on a 8192 token sized prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mk43x44/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743126133,"author_flair_text":"textgen web UI","treatment_tags":[],"created_utc":1743126133,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmi5rw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheDreamSymphonic","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm5rub","score":17,"author_fullname":"t2_531u9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mine gets thermally throttled on long context (m2 ultra 192gb)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjmi5rw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mine gets thermally throttled on long context (m2 ultra 192gb)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmi5rw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742892938,"author_flair_text":null,"treatment_tags":[],"created_utc":1742892938,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"mjm5rub","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Justicia-Gai","can_mod_post":false,"created_utc":1742884630,"send_replies":true,"parent_id":"t1_mjltq0a","score":57,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In total seconds:\\n\\n- Prompt: processing 1.19 sec, generation 8.9 sec.\\n- 1k prompt: processing 13.89 sec, generation 12 sec\\n- 16k prompt: processing 227 sec, generation 83 sec\\n\\n\\nThe bottleneck is the prompt processing speed but it’s quite decent? The slower token generation at higher context size happens with any hardware or it’s more pronounced in Apple’s hardware?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm5rub","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In total seconds:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Prompt: processing 1.19 sec, generation 8.9 sec.&lt;/li&gt;\\n&lt;li&gt;1k prompt: processing 13.89 sec, generation 12 sec&lt;/li&gt;\\n&lt;li&gt;16k prompt: processing 227 sec, generation 83 sec&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The bottleneck is the prompt processing speed but it’s quite decent? The slower token generation at higher context size happens with any hardware or it’s more pronounced in Apple’s hardware?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm5rub/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742884630,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":57}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndb9x8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aphid_red","can_mod_post":false,"created_utc":1744786171,"send_replies":true,"parent_id":"t1_mjltq0a","score":1,"author_fullname":"t2_csn2q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Context shouldn't be using that much; the software is still not properly doing MLA (instead, it's literally doing *worse* than MHA, even worse than GQA that llama-3 uses). See: [https://mccormickml.com/2025/02/12/the-inner-workings-of-deep-seek-v3/](https://mccormickml.com/2025/02/12/the-inner-workings-of-deep-seek-v3/) \\n\\nReal context size should be 7.6GB at 160K, less than 1/100th of what you're seeing (12K+16K width is compressed down to 2x512); or; instead of 80GB of context it should be &lt;3GB. (See: [https://github.com/pzhao-eng/FlashMLA](https://github.com/pzhao-eng/FlashMLA) and [https://github.com/deepseek-ai/FlashMLA/](https://github.com/deepseek-ai/FlashMLA/) )\\n\\nI have a feeling the programmers aren't testing longer contexts at all, just trying to max out pp512/tg128. Which is great and all, but not reflective of all use cases.","edited":1744787154,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndb9x8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Context shouldn&amp;#39;t be using that much; the software is still not properly doing MLA (instead, it&amp;#39;s literally doing &lt;em&gt;worse&lt;/em&gt; than MHA, even worse than GQA that llama-3 uses). See: &lt;a href=\\"https://mccormickml.com/2025/02/12/the-inner-workings-of-deep-seek-v3/\\"&gt;https://mccormickml.com/2025/02/12/the-inner-workings-of-deep-seek-v3/&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Real context size should be 7.6GB at 160K, less than 1/100th of what you&amp;#39;re seeing (12K+16K width is compressed down to 2x512); or; instead of 80GB of context it should be &amp;lt;3GB. (See: &lt;a href=\\"https://github.com/pzhao-eng/FlashMLA\\"&gt;https://github.com/pzhao-eng/FlashMLA&lt;/a&gt; and &lt;a href=\\"https://github.com/deepseek-ai/FlashMLA/\\"&gt;https://github.com/deepseek-ai/FlashMLA/&lt;/a&gt; )&lt;/p&gt;\\n\\n&lt;p&gt;I have a feeling the programmers aren&amp;#39;t testing longer contexts at all, just trying to max out pp512/tg128. Which is great and all, but not reflective of all use cases.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mndb9x8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744786171,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjltq0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"davewolfs","can_mod_post":false,"created_utc":1742877655,"send_replies":true,"parent_id":"t3_1jj6i4m","score":163,"author_fullname":"t2_pms20","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not entirely accurate!\\n\\nM3 Ultra with MLX and DeepSeek-V3-0324-4bit\\nContext size tests!\\n\\nPrompt: 69 tokens, 58.077 tokens-per-sec\\nGeneration: 188 tokens, 21.05 tokens-per-sec\\nPeak memory: 380.235 GB\\n\\n1k:\\nPrompt: 1145 tokens, 82.483 tokens-per-sec\\nGeneration: 220 tokens, 17.812 tokens-per-sec\\nPeak memory: 385.420 GB\\n\\n16k:\\nPrompt: 15777 tokens, 69.450 tokens-per-sec\\nGeneration: 480 tokens, 5.792 tokens-per-sec\\nPeak memory: 464.764 GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjltq0a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not entirely accurate!&lt;/p&gt;\\n\\n&lt;p&gt;M3 Ultra with MLX and DeepSeek-V3-0324-4bit\\nContext size tests!&lt;/p&gt;\\n\\n&lt;p&gt;Prompt: 69 tokens, 58.077 tokens-per-sec\\nGeneration: 188 tokens, 21.05 tokens-per-sec\\nPeak memory: 380.235 GB&lt;/p&gt;\\n\\n&lt;p&gt;1k:\\nPrompt: 1145 tokens, 82.483 tokens-per-sec\\nGeneration: 220 tokens, 17.812 tokens-per-sec\\nPeak memory: 385.420 GB&lt;/p&gt;\\n\\n&lt;p&gt;16k:\\nPrompt: 15777 tokens, 69.450 tokens-per-sec\\nGeneration: 480 tokens, 5.792 tokens-per-sec\\nPeak memory: 464.764 GB&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjltq0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742877655,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":163}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm0ghd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ComprehensiveBird317","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjldsz2","score":39,"author_fullname":"t2_iaby02kl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Openwebui","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjm0ghd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Openwebui&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm0ghd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742881330,"author_flair_text":null,"treatment_tags":[],"created_utc":1742881330,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmzoyn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjml8oy","score":7,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"normies will use it. they like to talk. I'm just happy to chat with memes and show the AI stuff it can comment on. If that involves sound and video and not just jpegs, I'll use it.\\n\\nIf I *have* to talk then it's kinda meh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmzoyn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;normies will use it. they like to talk. I&amp;#39;m just happy to chat with memes and show the AI stuff it can comment on. If that involves sound and video and not just jpegs, I&amp;#39;ll use it.&lt;/p&gt;\\n\\n&lt;p&gt;If I &lt;em&gt;have&lt;/em&gt; to talk then it&amp;#39;s kinda meh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmzoyn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742902933,"author_flair_text":null,"treatment_tags":[],"created_utc":1742902933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mjml8oy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kweglinski","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjldsz2","score":10,"author_fullname":"t2_7gw03ro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I genuinely wonder how many people would actually use that. Like I really don't know.  \\n\\nPersonally, I'm absolutely unable to force myself to go talk with LLMs and text only is my only choice. Is there any research what would be distribution between the users?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjml8oy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I genuinely wonder how many people would actually use that. Like I really don&amp;#39;t know.  &lt;/p&gt;\\n\\n&lt;p&gt;Personally, I&amp;#39;m absolutely unable to force myself to go talk with LLMs and text only is my only choice. Is there any research what would be distribution between the users?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjml8oy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742894973,"author_flair_text":null,"treatment_tags":[],"created_utc":1742894973,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjpufbs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thetaFAANG","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjoxfcx","score":0,"author_fullname":"t2_da5i8ajs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LM Studio accepts microphone input and voice models that reply back, and loads models that do that? where is that in the interface","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjpufbs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LM Studio accepts microphone input and voice models that reply back, and loads models that do that? where is that in the interface&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpufbs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742934347,"author_flair_text":null,"treatment_tags":[],"created_utc":1742934347,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjoxfcx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Elegant-Ad3211","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjldsz2","score":1,"author_fullname":"t2_shhqswh4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Easy way: LM studio + Gemma3 (I used 12b on macbook m2 pro)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjoxfcx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Easy way: LM studio + Gemma3 (I used 12b on macbook m2 pro)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjoxfcx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742924730,"author_flair_text":null,"treatment_tags":[],"created_utc":1742924730,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjldsz2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thetaFAANG","can_mod_post":false,"created_utc":1742870701,"send_replies":true,"parent_id":"t1_mjkq8pu","score":20,"author_fullname":"t2_da5i8ajs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"does anyone have an omnimodal GUI?\\n\\nthis area seems to have stalled in the open source space. I don't want these anxiety riddled reasoning models or tokens per second. I want to speak and be spoken back to in an interface that's on par with ChatGPT or better","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjldsz2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does anyone have an omnimodal GUI?&lt;/p&gt;\\n\\n&lt;p&gt;this area seems to have stalled in the open source space. I don&amp;#39;t want these anxiety riddled reasoning models or tokens per second. I want to speak and be spoken back to in an interface that&amp;#39;s on par with ChatGPT or better&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjldsz2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742870701,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnda5c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"davewolfs","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl179h","score":9,"author_fullname":"t2_pms20","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are completely right. I have tried prompting it in many ways so that it can actually complete a task and it just cannot. This makes me think it’s been completely overfitted to these tests.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjnda5c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are completely right. I have tried prompting it in many ways so that it can actually complete a task and it just cannot. This makes me think it’s been completely overfitted to these tests.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnda5c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742908399,"author_flair_text":null,"treatment_tags":[],"created_utc":1742908399,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjoa1nz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheElectroPrince","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmoacr","score":6,"author_fullname":"t2_3uyku4tt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You could say the o3 mini high model is high.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjoa1nz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could say the o3 mini high model is high.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjoa1nz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742918647,"author_flair_text":null,"treatment_tags":[],"created_utc":1742918647,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjn8i59","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Responsible-Clue-687","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmzdnz","score":5,"author_fullname":"t2_8fygs72q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Every YouTuber i follow that presented o3 mini in graphs took OpenAi's word on it. \\nAnd it's inaccurate, is what I am saying.","edited":false,"author_flair_css_class":null,"name":"t1_mjn8i59","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Every YouTuber i follow that presented o3 mini in graphs took OpenAi&amp;#39;s word on it. \\nAnd it&amp;#39;s inaccurate, is what I am saying.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn8i59/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742906627,"author_flair_text":null,"collapsed":false,"created_utc":1742906627,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmzdnz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmoacr","score":3,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well o3-mini-high is just o3-mini with more reasoning tokens. It’s not smarter, just thinks longer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmzdnz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well o3-mini-high is just o3-mini with more reasoning tokens. It’s not smarter, just thinks longer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmzdnz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742902788,"author_flair_text":null,"treatment_tags":[],"created_utc":1742902788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmoacr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Responsible-Clue-687","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl179h","score":15,"author_fullname":"t2_8fygs72q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"o3 mini high is stupid. Yet they presented it like a o1 killer in coding. \\n\\nIt can't even focus on a simple task.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjmoacr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;o3 mini high is stupid. Yet they presented it like a o1 killer in coding. &lt;/p&gt;\\n\\n&lt;p&gt;It can&amp;#39;t even focus on a simple task.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmoacr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742896886,"author_flair_text":null,"treatment_tags":[],"created_utc":1742896886,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjqj5kr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GradatimRecovery","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl179h","score":1,"author_fullname":"t2_z67jm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"better results with r1 for my use case","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjqj5kr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;better results with r1 for my use case&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjqj5kr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742941814,"author_flair_text":null,"treatment_tags":[],"created_utc":1742941814,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl179h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"davikrehalt","can_mod_post":false,"created_utc":1742866131,"send_replies":true,"parent_id":"t1_mjkq8pu","score":55,"author_fullname":"t2_6okc6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I hope not. I think the OpenAI lead is the o3 results they announced on programming math and arc. If they all are replicated the lead is over. Leave omnimodal to companies with more $$$ just focus on core deepseek","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl179h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope not. I think the OpenAI lead is the o3 results they announced on programming math and arc. If they all are replicated the lead is over. Leave omnimodal to companies with more $$$ just focus on core deepseek&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl179h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742866131,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":55}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjn03ze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm2wvg","score":7,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"| Model          | Param Size   | Reasoning Runtime |\\n|----------------|--------------|-------------------|\\n| o1             | 100b–1t      | medium            |\\n| o1-pro         | 100b–1t      | high              |\\n| o1-mini        | 10b–100b     | medium            |\\n| o3             | 100b–1t      | medium            |\\n| o3-mini        | 10b–100b     | medium            |\\n| o3-mini-high   | 10b–100b     | high              |","edited":false,"author_flair_css_class":null,"name":"t1_mjn03ze","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Model&lt;/th&gt;\\n&lt;th&gt;Param Size&lt;/th&gt;\\n&lt;th&gt;Reasoning Runtime&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o1&lt;/td&gt;\\n&lt;td&gt;100b–1t&lt;/td&gt;\\n&lt;td&gt;medium&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o1-pro&lt;/td&gt;\\n&lt;td&gt;100b–1t&lt;/td&gt;\\n&lt;td&gt;high&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o1-mini&lt;/td&gt;\\n&lt;td&gt;10b–100b&lt;/td&gt;\\n&lt;td&gt;medium&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o3&lt;/td&gt;\\n&lt;td&gt;100b–1t&lt;/td&gt;\\n&lt;td&gt;medium&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o3-mini&lt;/td&gt;\\n&lt;td&gt;10b–100b&lt;/td&gt;\\n&lt;td&gt;medium&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;o3-mini-high&lt;/td&gt;\\n&lt;td&gt;10b–100b&lt;/td&gt;\\n&lt;td&gt;high&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn03ze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742903123,"author_flair_text":null,"collapsed":false,"created_utc":1742903123,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm9pk8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EmilPi","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm2wvg","score":4,"author_fullname":"t2_jti45lwl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"low/high - How much thinking and parallel runs with consensus it can do (how much electricity it eats).","edited":false,"author_flair_css_class":null,"name":"t1_mjm9pk8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;low/high - How much thinking and parallel runs with consensus it can do (how much electricity it eats).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm9pk8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742887180,"author_flair_text":null,"collapsed":false,"created_utc":1742887180,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmm9ex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Busy_Ordinary8456","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm2wvg","score":3,"author_fullname":"t2_x5ly20fgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Random.","edited":false,"author_flair_css_class":null,"name":"t1_mjmm9ex","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Random.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmm9ex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895639,"author_flair_text":null,"collapsed":false,"created_utc":1742895639,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjm2wvg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thawab","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl1h3a","score":1,"author_fullname":"t2_40qdp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Whats the naming convention on the O models?\\n O3 high,low, mini and pro?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm2wvg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Whats the naming convention on the O models?\\n O3 high,low, mini and pro?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm2wvg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742882813,"author_flair_text":null,"treatment_tags":[],"created_utc":1742882813,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl1l0c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheLogiqueViper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl1h3a","score":0,"author_fullname":"t2_4wyp4xpi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ok thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl1l0c","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl1l0c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742866267,"author_flair_text":null,"treatment_tags":[],"created_utc":1742866267,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl1h3a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkqfaq","score":9,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"o3 low .... they are predicting 15-20% for o3 high ...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjl1h3a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;o3 low .... they are predicting 15-20% for o3 high ...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl1h3a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742866228,"author_flair_text":null,"treatment_tags":[],"created_utc":1742866228,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkqfaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheLogiqueViper","can_mod_post":false,"created_utc":1742862374,"send_replies":true,"parent_id":"t1_mjkq8pu","score":29,"author_fullname":"t2_4wyp4xpi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am waiting to see what r2 can do , arc agi 2 results are out and o3 low has scored less than 5% spending 200$ per task deepseek r1 stands at 1.3 percent","edited":1742866295,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkqfaq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am waiting to see what r2 can do , arc agi 2 results are out and o3 low has scored less than 5% spending 200$ per task deepseek r1 stands at 1.3 percent&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkqfaq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742862374,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlmpm2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1742874342,"send_replies":true,"parent_id":"t1_mjkq8pu","score":3,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"doubt it, if they were going to implement that, they would need significantly more compute, which they are already at a disadvantage for, and they would've already done it for the updated version of V3 since for R1 at least, they made it out of v3.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlmpm2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;doubt it, if they were going to implement that, they would need significantly more compute, which they are already at a disadvantage for, and they would&amp;#39;ve already done it for the updated version of V3 since for R1 at least, they made it out of v3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlmpm2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742874342,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl7ng6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"philguyaz","can_mod_post":false,"created_utc":1742868412,"send_replies":true,"parent_id":"t1_mjkq8pu","score":11,"author_fullname":"t2_36dfv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You don’t need Omni models to produce Omni results you just need a collection of agentic models. My own software leverages this approach optimizing each task by model instead of searching for an all in one solution","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl7ng6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don’t need Omni models to produce Omni results you just need a collection of agentic models. My own software leverages this approach optimizing each task by model instead of searching for an all in one solution&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl7ng6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868412,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlnsus","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iory1998","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlksiw","score":4,"author_fullname":"t2_byt5wa14","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I second this. u/Specter_Origin comment says exactly that v4 was out, which is not true.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjlnsus","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I second this. &lt;a href=\\"/u/Specter_Origin\\"&gt;u/Specter_Origin&lt;/a&gt; comment says exactly that v4 was out, which is not true.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlnsus/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742874829,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1742874829,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlmpq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cannavor","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlla2u","score":14,"author_fullname":"t2_3ytzq0hd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The subjunctive here is being used to describe a present tense hypothetical. Ask an English teacher not an LLM. It was clear from your second sentence that you were wishing for something that didn't yet exist but you still should have used would be for the future tense.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjlmpq5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The subjunctive here is being used to describe a present tense hypothetical. Ask an English teacher not an LLM. It was clear from your second sentence that you were wishing for something that didn&amp;#39;t yet exist but you still should have used would be for the future tense.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlmpq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742874343,"author_flair_text":null,"treatment_tags":[],"created_utc":1742874343,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjls6a0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MidAirRunner","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlla2u","score":14,"author_fullname":"t2_qwhykwm6l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nah, you should have said \\"I wish v4 *will be* an omni model.\\"\\n\\nYour usage of \\"were\\" indicates that v4 is already out, which it isn't.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjls6a0","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nah, you should have said &amp;quot;I wish v4 &lt;em&gt;will be&lt;/em&gt; an omni model.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Your usage of &amp;quot;were&amp;quot; indicates that v4 is already out, which it isn&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjls6a0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742876882,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1742876882,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlla2u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Specter_Origin","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlksiw","score":-11,"author_fullname":"t2_kcu2kx4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I actually Llmed it for ya:\\n“Based on the sentence provided, v4 appears to be something that is being wished for, not something that already exists. The person is expressing a desire that “v4 were an omni-model,” using the subjunctive mood (“were” rather than “is”), which indicates a hypothetical or wishful scenario rather than a current reality.”","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjlla2u","is_submitter":false,"collapsed":true,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually Llmed it for ya:\\n“Based on the sentence provided, v4 appears to be something that is being wished for, not something that already exists. The person is expressing a desire that “v4 were an omni-model,” using the subjunctive mood (“were” rather than “is”), which indicates a hypothetical or wishful scenario rather than a current reality.”&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlla2u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742873724,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1742873724,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-11}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlksiw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cannavor","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjla5m7","score":11,"author_fullname":"t2_3ytzq0hd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"By saying you \\"wish v4 were\\" you're implying it already exists and was something different. Were is past tense after all. So he read your comment fine you just made a grammatical error. Speculating about a potential future the appropriate thing to say would be \\"I wish v4 would be\\".","edited":false,"author_flair_css_class":null,"name":"t1_mjlksiw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By saying you &amp;quot;wish v4 were&amp;quot; you&amp;#39;re implying it already exists and was something different. Were is past tense after all. So he read your comment fine you just made a grammatical error. Speculating about a potential future the appropriate thing to say would be &amp;quot;I wish v4 would be&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlksiw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742873514,"author_flair_text":null,"collapsed":false,"created_utc":1742873514,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm9k7l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjla5m7","score":1,"author_fullname":"t2_idhb522c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My condolences for the obstinate grammar nazis harassing your following comments.\\n\\nIt baffling how these people behave in an deliberately obtuse manner. Its obvious that v4 is not out and anyone who thinks you meant that it was out, is deliberately misconstruing your comment. Especially as the second sentence contains a \\"would\\".\\n\\nReddit truly is full of weirdos.","edited":false,"author_flair_css_class":null,"name":"t1_mjm9k7l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My condolences for the obstinate grammar nazis harassing your following comments.&lt;/p&gt;\\n\\n&lt;p&gt;It baffling how these people behave in an deliberately obtuse manner. Its obvious that v4 is not out and anyone who thinks you meant that it was out, is deliberately misconstruing your comment. Especially as the second sentence contains a &amp;quot;would&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;Reddit truly is full of weirdos.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm9k7l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742887082,"author_flair_text":null,"collapsed":false,"created_utc":1742887082,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjla5m7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Specter_Origin","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjla04n","score":-7,"author_fullname":"t2_kcu2kx4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"You might want to re-read my comment...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjla5m7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You might want to re-read my comment...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjla5m7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742869332,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1742869332,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"mjla04n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MrRandom04","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjksx16","score":6,"author_fullname":"t2_1779nu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We don't have v4 yet. Could still be omni.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjla04n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We don&amp;#39;t have v4 yet. Could still be omni.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjla04n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742869274,"author_flair_text":null,"treatment_tags":[],"created_utc":1742869274,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjksx16","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Specter_Origin","can_mod_post":false,"created_utc":1742863246,"send_replies":true,"parent_id":"t1_mjkq8pu","score":11,"author_fullname":"t2_kcu2kx4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To be honest, I wish v4 were an omni-model. Even at higher TPS, r1 takes too long to produce the final output, which makes it frustrating at lower TPS. However, v4—even at 25-45 TPS would be a very good alternative to ClosedAI and their models for local inference.","edited":1742863511,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjksx16","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be honest, I wish v4 were an omni-model. Even at higher TPS, r1 takes too long to produce the final output, which makes it frustrating at lower TPS. However, v4—even at 25-45 TPS would be a very good alternative to ClosedAI and their models for local inference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjksx16/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742863246,"author_flair_text":"Ollama","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjn18uc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm44ln","score":3,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"819GB/s\\n\\nThe 3090 is 936GB/s\\n\\nThe 4080 is 1008GB/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjn18uc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;819GB/s&lt;/p&gt;\\n\\n&lt;p&gt;The 3090 is 936GB/s&lt;/p&gt;\\n\\n&lt;p&gt;The 4080 is 1008GB/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn18uc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742903625,"author_flair_text":null,"treatment_tags":[],"created_utc":1742903625,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjm44ln","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlh4au","score":7,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It doesn’t have the bandwidth of a dGPU but it does have 800-900 Gbps bandwidth on M3 Studio Ultra, which is very decent.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjm44ln","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn’t have the bandwidth of a dGPU but it does have 800-900 Gbps bandwidth on M3 Studio Ultra, which is very decent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm44ln/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742883574,"author_flair_text":null,"treatment_tags":[],"created_utc":1742883574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlh4au","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious-Tap-4670","can_mod_post":false,"created_utc":1742871991,"send_replies":true,"parent_id":"t1_mjkq8pu","score":1,"author_fullname":"t2_n2zhoqg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My understanding is macs don't have high bandwidth so they will not actually reap the benefits of their large unified memory when it comes to VLM and other modalities.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlh4au","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My understanding is macs don&amp;#39;t have high bandwidth so they will not actually reap the benefits of their large unified memory when it comes to VLM and other modalities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlh4au/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742871991,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl4ojk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shyt4brains","can_mod_post":false,"created_utc":1742867357,"send_replies":true,"parent_id":"t1_mjkq8pu","score":1,"author_fullname":"t2_5zrmj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agree audio output is my main use case vs other llms.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl4ojk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree audio output is my main use case vs other llms.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl4ojk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867357,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm009s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"newdoria88","can_mod_post":false,"created_utc":1742881072,"send_replies":true,"parent_id":"t1_mjkq8pu","score":1,"author_fullname":"t2_f4psz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Being MoE should help with adding multimodal capabilities, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm009s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Being MoE should help with adding multimodal capabilities, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm009s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742881072,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjn0mj3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dampflokfreund","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmzjjk","score":2,"author_fullname":"t2_lis7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Specialist models only make sense for very small models, like 3B and below. For native multimodality like its the case with Gemma 3, Gemini and OpenAI models, there's a benefit even when you are using just one modality. Native multimodal models are pretrained not only with text but with images also. This gives these models much more information than what just text could provide, meaning a better world model and enhanced general performance. You can describe an apple with thousands words, but having a picture of an apple is an entirely different story.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjn0mj3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Specialist models only make sense for very small models, like 3B and below. For native multimodality like its the case with Gemma 3, Gemini and OpenAI models, there&amp;#39;s a benefit even when you are using just one modality. Native multimodal models are pretrained not only with text but with images also. This gives these models much more information than what just text could provide, meaning a better world model and enhanced general performance. You can describe an apple with thousands words, but having a picture of an apple is an entirely different story.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn0mj3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742903352,"author_flair_text":null,"treatment_tags":[],"created_utc":1742903352,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjxynzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PersonOfDisinterest9","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmzjjk","score":1,"author_fullname":"t2_y3y2wghfu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Multimodal, particularly textual and visual modalities, is important for many types of useful work.  \\n  \\nThink about something as simple as geometry, and how many ways geometry is integrated into life.  \\n  \\nIf we're going to have robots driving around, in homes and offices, or doing anything physical, they're going to need spatial intelligence and image understanding to go with the language and reasoning skills.   \\nIt's also going to be an enormous benefit if they've got auditory understanding beyond speech to text, where there is sentiment analysis, and the ability to understand the collection of various noises in the world.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjxynzh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Multimodal, particularly textual and visual modalities, is important for many types of useful work.  &lt;/p&gt;\\n\\n&lt;p&gt;Think about something as simple as geometry, and how many ways geometry is integrated into life.  &lt;/p&gt;\\n\\n&lt;p&gt;If we&amp;#39;re going to have robots driving around, in homes and offices, or doing anything physical, they&amp;#39;re going to need spatial intelligence and image understanding to go with the language and reasoning skills.&lt;br/&gt;\\nIt&amp;#39;s also going to be an enormous benefit if they&amp;#39;ve got auditory understanding beyond speech to text, where there is sentiment analysis, and the ability to understand the collection of various noises in the world.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjxynzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743040355,"author_flair_text":null,"treatment_tags":[],"created_utc":1743040355,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmzjjk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Far_Buyer_7281","can_mod_post":false,"created_utc":1742902864,"send_replies":true,"parent_id":"t1_mjkq8pu","score":1,"author_fullname":"t2_vyvxdjqyp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I never understood this, nobody ever explained why multi modal would be better.  \\nI rather  have 2 specialist models instead of 1 average one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmzjjk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I never understood this, nobody ever explained why multi modal would be better.&lt;br/&gt;\\nI rather  have 2 specialist models instead of 1 average one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmzjjk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742902864,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmnnq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hv_V","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlgp75","score":3,"author_fullname":"t2_nwlx2jvp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"By default llms are trained on text only that is why they are called ‘language’ model. Any image or audio capabilities are added as a separate module. However it is deeply integrated within the llm during training process so that the llm can use it smoothly(eg gemini and gpt-4o).\\nI still believe that existing text only models can be fine tuned to let them use api of image models or tts to give illusion of an omni model. Similar to how llms are given RAG capabilities like in agentic coding(cursor, trae). Even deepseek on web extend to image capabilities by simply performing OCR and passing it to the model.","edited":1742911994,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmnnq5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By default llms are trained on text only that is why they are called ‘language’ model. Any image or audio capabilities are added as a separate module. However it is deeply integrated within the llm during training process so that the llm can use it smoothly(eg gemini and gpt-4o).\\nI still believe that existing text only models can be fine tuned to let them use api of image models or tts to give illusion of an omni model. Similar to how llms are given RAG capabilities like in agentic coding(cursor, trae). Even deepseek on web extend to image capabilities by simply performing OCR and passing it to the model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmnnq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742896509,"author_flair_text":null,"treatment_tags":[],"created_utc":1742896509,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlgp75","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"poli-cya","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl4vjr","score":6,"author_fullname":"t2_q8g93lhv4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bold claim there","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjlgp75","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bold claim there&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlgp75/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742871824,"author_flair_text":null,"treatment_tags":[],"created_utc":1742871824,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl4vjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hv_V","can_mod_post":false,"created_utc":1742867424,"send_replies":true,"parent_id":"t1_mjkq8pu","score":-4,"author_fullname":"t2_nwlx2jvp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can just attach a tts and a dedicated image recognition model to existing llms and it will work just as well as models which support image/audio natively.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl4vjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can just attach a tts and a dedicated image recognition model to existing llms and it will work just as well as models which support image/audio natively.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl4vjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867424,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkq8pu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dampflokfreund","can_mod_post":false,"created_utc":1742862310,"send_replies":true,"parent_id":"t3_1jj6i4m","score":395,"author_fullname":"t2_lis7z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not yet a nightmare for OpenAI, as DeepSeek's flagship models are still text only. However, when they are able to have visual input and audio output, then OpenAi will be in trouble. Truly hope R2 is going to be omnimodal.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkq8pu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not yet a nightmare for OpenAI, as DeepSeek&amp;#39;s flagship models are still text only. However, when they are able to have visual input and audio output, then OpenAi will be in trouble. Truly hope R2 is going to be omnimodal.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkq8pu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742862310,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":395}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjljjpq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Account1893242379482","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlaoiv","score":22,"author_fullname":"t2_5f2x2t4r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Apple basically pre-ordering much of the chip production capacity is really paying off.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjljjpq","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apple basically pre-ordering much of the chip production capacity is really paying off.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjljjpq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742872987,"author_flair_text":"textgen web UI","treatment_tags":[],"created_utc":1742872987,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlzeng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BrooklynQuips","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlph3w","score":6,"author_fullname":"t2_a8mvljh7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"also a huge advantage for them is including it in a ton of GWS services at low or no cost. enterprise clients are pushing it hard because they can offer models and features to their employees for cheap. \\n\\nusers revolted at mine and made us switch back to chatgpt enterprise (and other models but we use them a lot less), but friends at other corps tell me it’s full gemini. \\n\\n&gt;  A single department in google has more funding and access to compute and talent than the entire OpenAI org.\\n\\nobligatory: “I’m good for my $100 billion” lol","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjlzeng","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;also a huge advantage for them is including it in a ton of GWS services at low or no cost. enterprise clients are pushing it hard because they can offer models and features to their employees for cheap. &lt;/p&gt;\\n\\n&lt;p&gt;users revolted at mine and made us switch back to chatgpt enterprise (and other models but we use them a lot less), but friends at other corps tell me it’s full gemini. &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;A single department in google has more funding and access to compute and talent than the entire OpenAI org.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;obligatory: “I’m good for my $100 billion” lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlzeng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742880728,"author_flair_text":null,"treatment_tags":[],"created_utc":1742880728,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlph3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mescallan","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjln5pa","score":15,"author_fullname":"t2_3ykrc","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm the same (but with claude), but I can assure you the vast majority of people are still using google for most things. I live in a developing country and chatGPT is only really used by students and 20 somethings.\\n\\nLike I said in my op, they could leapfrog OpenAI if it became a priority. A single department in google has more funding and access to compute and talent than the entire OpenAI org.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjlph3w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m the same (but with claude), but I can assure you the vast majority of people are still using google for most things. I live in a developing country and chatGPT is only really used by students and 20 somethings.&lt;/p&gt;\\n\\n&lt;p&gt;Like I said in my op, they could leapfrog OpenAI if it became a priority. A single department in google has more funding and access to compute and talent than the entire OpenAI org.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlph3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742875598,"author_flair_text":null,"treatment_tags":[],"created_utc":1742875598,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mjln5pa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"liqui_date_me","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlkzhy","score":8,"author_fullname":"t2_awwos9h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ngl, I’ve stopped using Google for the past few years and use ChatGPT a lot more, especially for coding questions and to learn about new things. Everyone else in my friend circle uses Google less too","edited":false,"author_flair_css_class":null,"name":"t1_mjln5pa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ngl, I’ve stopped using Google for the past few years and use ChatGPT a lot more, especially for coding questions and to learn about new things. Everyone else in my friend circle uses Google less too&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjln5pa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742874539,"author_flair_text":null,"collapsed":false,"created_utc":1742874539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlkzhy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mescallan","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlfjr9","score":36,"author_fullname":"t2_3ykrc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"whenever they want\\"\\n\\nthey are actually making some noise right now for delaying it again after they used it in marketing to sell the most recent iPhone. Their head of AI was just forced to step down and their stock prices are down because of it.\\n\\nGoogle is the real winner by virtually every metric other than mindshare. No one thinks about google models, but everyone uses them almost every day already. Their LLM department is a lower priority than their narrow AI projects and far horizon stuff. If they put all that effort into LLMs like OpenAI is they would leapfrog capabilities overnight, but DeepMind is still more focused on material science and biology than language and coding tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlkzhy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;whenever they want&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;they are actually making some noise right now for delaying it again after they used it in marketing to sell the most recent iPhone. Their head of AI was just forced to step down and their stock prices are down because of it.&lt;/p&gt;\\n\\n&lt;p&gt;Google is the real winner by virtually every metric other than mindshare. No one thinks about google models, but everyone uses them almost every day already. Their LLM department is a lower priority than their narrow AI projects and far horizon stuff. If they put all that effort into LLMs like OpenAI is they would leapfrog capabilities overnight, but DeepMind is still more focused on material science and biology than language and coding tasks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlkzhy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742873597,"author_flair_text":null,"treatment_tags":[],"created_utc":1742873597,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlyav0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Careless_Garlic1438","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlvzz3","score":6,"author_fullname":"t2_w3uuzkpbi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Use it every day, think you might be confusing it with the delayed Siri enhancement. Granted, it will utilize the same Apple Intelligence features as well, but the delay is specific to Siri. I use A.I. daily in my professional life for proofreading and rewriting text, all without the need for cumbersome copying and pasting.","edited":false,"author_flair_css_class":null,"name":"t1_mjlyav0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use it every day, think you might be confusing it with the delayed Siri enhancement. Granted, it will utilize the same Apple Intelligence features as well, but the delay is specific to Siri. I use A.I. daily in my professional life for proofreading and rewriting text, all without the need for cumbersome copying and pasting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlyav0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742880099,"author_flair_text":null,"collapsed":false,"created_utc":1742880099,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnh62v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hefty-Horror-5762","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjnfcf1","score":1,"author_fullname":"t2_9eh4wwkl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That does seem to be the main complaint (prompt processing speed). From what I’ve read that’s more an issue for larger prompts, so I guess it depends on your use case.\\n\\nI just see it as a place where Apple is quietly making inroads that I think a lot of folks haven’t realized yet. We will continue to see improvement on the software side, and given the availability of Mac options, I suspect we could see models tuned to run better on Mac hardware in the future.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjnh62v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That does seem to be the main complaint (prompt processing speed). From what I’ve read that’s more an issue for larger prompts, so I guess it depends on your use case.&lt;/p&gt;\\n\\n&lt;p&gt;I just see it as a place where Apple is quietly making inroads that I think a lot of folks haven’t realized yet. We will continue to see improvement on the software side, and given the availability of Mac options, I suspect we could see models tuned to run better on Mac hardware in the future.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnh62v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742909783,"author_flair_text":null,"treatment_tags":[],"created_utc":1742909783,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjnfcf1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Such_Advantage_6949","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjnck5y","score":1,"author_fullname":"t2_a548b491","approved_by":null,"mod_note":null,"all_awardings":[],"body":"The unified ram is decent, but their prompt processing is too slow. For small size footprint, probably they are the best. But if you need anything that is fast, running multiple model etc, it will struggle. I have an m4 max btw, abit regretted it. I should have gone for the pro instead","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjnfcf1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The unified ram is decent, but their prompt processing is too slow. For small size footprint, probably they are the best. But if you need anything that is fast, running multiple model etc, it will struggle. I have an m4 max btw, abit regretted it. I should have gone for the pro instead&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnfcf1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742909139,"author_flair_text":null,"treatment_tags":[],"created_utc":1742909139,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjnck5y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hefty-Horror-5762","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlvzz3","score":1,"author_fullname":"t2_9eh4wwkl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I feel like the way Apple is quietly succeeding is on the hardware side. The high end M series chips offer unified memory with high bandwidth at a price point that is competitive with nvidia. Apple’s own AI isn’t on par with the most popular models, but their hardware seems well positioned to allow people to run their own models locally.","edited":false,"author_flair_css_class":null,"name":"t1_mjnck5y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I feel like the way Apple is quietly succeeding is on the hardware side. The high end M series chips offer unified memory with high bandwidth at a price point that is competitive with nvidia. Apple’s own AI isn’t on par with the most popular models, but their hardware seems well positioned to allow people to run their own models locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnck5y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742908141,"author_flair_text":null,"collapsed":false,"created_utc":1742908141,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlvzz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Such_Advantage_6949","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlfjr9","score":14,"author_fullname":"t2_a548b491","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Think you are not up to date with how failed and delayed apple intelligence is","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlvzz3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Think you are not up to date with how failed and delayed apple intelligence is&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlvzz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742878831,"author_flair_text":null,"treatment_tags":[],"created_utc":1742878831,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlxutj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Careless_Garlic1438","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlqbh6","score":4,"author_fullname":"t2_w3uuzkpbi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah running tiny models the GPU will “win” hands down, 32B or more at a descent quant … you are looking at 20K worth of GPU’s + system … I run QWQ 32B on my M4 Max at 15 tokens / s on my laptop on battery power when traveling … So yeah GPU’s are faster but consume a lot more power and are not able to run large models, unless you spent a fortune and are willing to burn a lot of electricity …","edited":false,"author_flair_css_class":null,"name":"t1_mjlxutj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah running tiny models the GPU will “win” hands down, 32B or more at a descent quant … you are looking at 20K worth of GPU’s + system … I run QWQ 32B on my M4 Max at 15 tokens / s on my laptop on battery power when traveling … So yeah GPU’s are faster but consume a lot more power and are not able to run large models, unless you spent a fortune and are willing to burn a lot of electricity …&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlxutj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742879848,"author_flair_text":null,"collapsed":false,"created_utc":1742879848,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm4bpu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlqbh6","score":0,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You’d have to choose between running dumber models faster or smarter models slower.\\n\\nI know what I’d pick.","edited":false,"author_flair_css_class":null,"name":"t1_mjm4bpu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You’d have to choose between running dumber models faster or smarter models slower.&lt;/p&gt;\\n\\n&lt;p&gt;I know what I’d pick.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm4bpu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742883698,"author_flair_text":null,"collapsed":false,"created_utc":1742883698,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlqbh6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"giant3","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlfjr9","score":-6,"author_fullname":"t2_82esi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Unlikely. Dropping $10K on a Mac vs dropping $1K on a high end GPU is an easy call. \\n\\nIs there a comparison  of Mac &amp; GPUs on GFLOPs per dollar?  I bet the GPU wins that on? A very weak RX 7600 is 75 GFLOPS/$.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlqbh6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unlikely. Dropping $10K on a Mac vs dropping $1K on a high end GPU is an easy call. &lt;/p&gt;\\n\\n&lt;p&gt;Is there a comparison  of Mac &amp;amp; GPUs on GFLOPs per dollar?  I bet the GPU wins that on? A very weak RX 7600 is 75 GFLOPS/$.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlqbh6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742875990,"author_flair_text":null,"treatment_tags":[],"created_utc":1742875990,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlfjr9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"liqui_date_me","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlaoiv","score":14,"author_fullname":"t2_awwos9h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They’re probably the real winner in the AI race, everyone else is in a price war to the bottom and they can implement an LLM based Siri and roll\\nIt out to 2 billion users whenever they want while also selling Mac Studios like hot cakes","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjlfjr9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They’re probably the real winner in the AI race, everyone else is in a price war to the bottom and they can implement an LLM based Siri and roll\\nIt out to 2 billion users whenever they want while also selling Mac Studios like hot cakes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlfjr9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742871373,"author_flair_text":null,"treatment_tags":[],"created_utc":1742871373,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlaoiv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1742869528,"send_replies":true,"parent_id":"t1_mjks4h5","score":38,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a dream for Apple though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlaoiv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a dream for Apple though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlaoiv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742869528,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":12,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":16,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlpuo3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"auradragon1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlis5m","score":14,"author_fullname":"t2_4atixtm8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I thought we were 3-4 years away from GPT4-level LLMs locally. Turns out it was 1 year instead and beyond GPT4. Crazy. The combination of hardware and software advancement blew me away.","edited":false,"author_flair_css_class":null,"name":"t1_mjlpuo3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought we were 3-4 years away from GPT4-level LLMs locally. Turns out it was 1 year instead and beyond GPT4. Crazy. The combination of hardware and software advancement blew me away.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlpuo3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742875772,"author_flair_text":null,"collapsed":false,"created_utc":1742875772,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlis5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlhmrs","score":16,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"That and algorithms and architectures will likely continue to improve as well. It wasn't two years ago that people believed you could only run models like these in a data center.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That and algorithms and architectures will likely continue to improve as well. It wasn&amp;#39;t two years ago that people believed you could only run models like these in a data center.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlis5m/","num_reports":null,"locked":false,"name":"t1_mjlis5m","created":1742872664,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742872664,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlhmrs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gethooge","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkzqu2","score":1,"author_fullname":"t2_tlhe8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do you mean, because the hardware will continue to improve?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjlhmrs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you mean, because the hardware will continue to improve?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlhmrs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742872197,"author_flair_text":null,"treatment_tags":[],"created_utc":1742872197,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkzqu2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjks4h5","score":12,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"It's the worst it's ever going to be.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s the worst it&amp;#39;s ever going to be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkzqu2/","num_reports":null,"locked":false,"name":"t1_mjkzqu2","created":1742865619,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742865619,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnspn0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"runforpeace2021","can_mod_post":false,"created_utc":1742913476,"send_replies":true,"parent_id":"t1_mjks4h5","score":2,"author_fullname":"t2_ecn5dlu3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Running LLM privately is for privacy reason, not because it’s cheaper to run over cloud based solutions. Everybody knows that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjnspn0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Running LLM privately is for privacy reason, not because it’s cheaper to run over cloud based solutions. Everybody knows that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnspn0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742913476,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmqadq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vaddieg","can_mod_post":false,"created_utc":1742898072,"send_replies":true,"parent_id":"t1_mjks4h5","score":1,"author_fullname":"t2_10g07z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"prompt processing is not a bottleneck in practical use cases. For reasoning models \\"thinking\\" token generation takes much longer than processing a 128k tokens prompt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmqadq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;prompt processing is not a bottleneck in practical use cases. For reasoning models &amp;quot;thinking&amp;quot; token generation takes much longer than processing a 128k tokens prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmqadq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742898072,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjks4h5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"synn89","can_mod_post":false,"created_utc":1742862972,"send_replies":true,"parent_id":"t3_1jj6i4m","score":171,"author_fullname":"t2_3jm4t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, that's $10k hardware and who knows what the prompt processing is on longer prompts. I think the nightmare for them is that it costs $1.20 on Fireworks and 0.40/0.89 per million tokens on DeepInfra.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjks4h5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, that&amp;#39;s $10k hardware and who knows what the prompt processing is on longer prompts. I think the nightmare for them is that it costs $1.20 on Fireworks and 0.40/0.89 per million tokens on DeepInfra.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjks4h5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742862972,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":171}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"03eba0e8-72f2-11ee-96eb-9a14648159ce","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ml8i1lt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SamSlate","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjnlb9p","score":1,"author_fullname":"t2_9lhpk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i wonder what openAi/deepseek hardware looks like","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ml8i1lt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i wonder what openAi/deepseek hardware looks like&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/ml8i1lt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743702025,"author_flair_text":null,"treatment_tags":[],"created_utc":1743702025,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjnlb9p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmmicf","score":3,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I guess YMMV on efficiency but you can definitely run it cheaper.  You can build a Sapphire Rapids server for about $3500 using an ES chip and it will give maybe 186t/s PP (300% Mac) and 9t/s TG (40% Mac) on short contexts according to ktransformers.   So that's not bad and then you also have a server with a bunch of PCIe that can also deploy GPUs moving forward if you want.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjnlb9p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I guess YMMV on efficiency but you can definitely run it cheaper.  You can build a Sapphire Rapids server for about $3500 using an ES chip and it will give maybe 186t/s PP (300% Mac) and 9t/s TG (40% Mac) on short contexts according to ktransformers.   So that&amp;#39;s not bad and then you also have a server with a bunch of PCIe that can also deploy GPUs moving forward if you want.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnlb9p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742911147,"author_flair_text":null,"treatment_tags":[],"created_utc":1742911147,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjog5da","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"muntaxitome","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmmicf","score":2,"author_fullname":"t2_so28y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; It's the cheapest and most efficient way to run 671b q4 model locally. prevails mostly with low context. \\n \\nThere are a couple of usecases where it makes sense. \\n \\n10k is a lot of money though and would buy you a lot of credits at the likes of runpod to run your own model. I honestly would wait to see what is coming out on the PC side in terms of unified memory before spending that. \\n \\nIt's a cool machine, but calling it cheap is only possible because they are a little ahead of the competition that is yet to come out, and comparing it to like h200 datacenter mostrosities is a little exaggerated.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjog5da","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;It&amp;#39;s the cheapest and most efficient way to run 671b q4 model locally. prevails mostly with low context. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;There are a couple of usecases where it makes sense. &lt;/p&gt;\\n\\n&lt;p&gt;10k is a lot of money though and would buy you a lot of credits at the likes of runpod to run your own model. I honestly would wait to see what is coming out on the PC side in terms of unified memory before spending that. &lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a cool machine, but calling it cheap is only possible because they are a little ahead of the competition that is yet to come out, and comparing it to like h200 datacenter mostrosities is a little exaggerated.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjog5da/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742920463,"author_flair_text":null,"treatment_tags":[],"created_utc":1742920463,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmmicf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlphaPrime90","can_mod_post":false,"created_utc":1742895796,"send_replies":true,"parent_id":"t1_mjkv2oo","score":14,"author_fullname":"t2_104g23","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's the cheapest and most efficient way to run 671b q4 model locally. prevails mostly with low context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmmicf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s the cheapest and most efficient way to run 671b q4 model locally. prevails mostly with low context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmmicf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895796,"author_flair_text":"koboldcpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmekwc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vb_33","can_mod_post":false,"created_utc":1742890468,"send_replies":true,"parent_id":"t1_mjkv2oo","score":4,"author_fullname":"t2_1616b950ru","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fucking seriously. Man I can't wait for a UDNA Ryzen AI successor with LPDDR6 and more memory channels. It's gonna be awhile tho and more memory channels aren't guaranteed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmekwc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fucking seriously. Man I can&amp;#39;t wait for a UDNA Ryzen AI successor with LPDDR6 and more memory channels. It&amp;#39;s gonna be awhile tho and more memory channels aren&amp;#39;t guaranteed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmekwc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742890468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkv2oo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cmndr_spanky","can_mod_post":false,"created_utc":1742863989,"send_replies":true,"parent_id":"t3_1jj6i4m","score":67,"author_fullname":"t2_r41b1kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I would be more excited if I didn’t have to buy a $10k Mac to run it …","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkv2oo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would be more excited if I didn’t have to buy a $10k Mac to run it …&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkv2oo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742863989,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":67}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mkq00ra","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Unlucky_Owl4174","can_mod_post":false,"send_replies":true,"parent_id":"t1_mkou8zn","score":1,"author_fullname":"t2_oetsvvp5s","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not about \\"purity\\" its about an illogical contradiction. (*\\"ClosedAI = Bad because proprietary, use Apple's proprietary software+hardware instead to avoid proprietary ClosedAI.\\"* that is not rational)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mkq00ra","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not about &amp;quot;purity&amp;quot; its about an illogical contradiction. (&lt;em&gt;&amp;quot;ClosedAI = Bad because proprietary, use Apple&amp;#39;s proprietary software+hardware instead to avoid proprietary ClosedAI.&amp;quot;&lt;/em&gt; that is not rational)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mkq00ra/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743443563,"author_flair_text":null,"treatment_tags":[],"created_utc":1743443563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mkou8zn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tapancnallan","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjpexiu","score":0,"author_fullname":"t2_tdbw4h7i8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fuck Purity. you will tie yourself into knots going that route. Embrace pragmatism, and -Anti\\\\_X is right, Apple's hardware being closed is the real issue, not its OS. no body gives a fuck about the OS being closed as we can just install something else if the underlying hardware was open enough","edited":false,"author_flair_css_class":null,"name":"t1_mkou8zn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuck Purity. you will tie yourself into knots going that route. Embrace pragmatism, and -Anti_X is right, Apple&amp;#39;s hardware being closed is the real issue, not its OS. no body gives a fuck about the OS being closed as we can just install something else if the underlying hardware was open enough&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mkou8zn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743431025,"author_flair_text":null,"collapsed":false,"created_utc":1743431025,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjpexiu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjp8341","score":3,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; software =! hardware\\n\\nAn operating system *is* *software*.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjpexiu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; software =! hardware&lt;/p&gt;\\n\\n&lt;p&gt;An operating system &lt;em&gt;is&lt;/em&gt; &lt;em&gt;software&lt;/em&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpexiu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742929840,"author_flair_text":null,"treatment_tags":[],"created_utc":1742929840,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjp8341","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Anti_X","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmdx7l","score":2,"author_fullname":"t2_133pxp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"software =! hardware and I don't see OP saying the word \\"business\\" anywhere.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjp8341","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;software =! hardware and I don&amp;#39;t see OP saying the word &amp;quot;business&amp;quot; anywhere.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjp8341/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742927835,"author_flair_text":null,"treatment_tags":[],"created_utc":1742927835,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmdx7l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1742890011,"send_replies":true,"parent_id":"t1_mjl45jj","score":21,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt; Screw ClosedAI and their proprietary garbage.\\n\\nI mean.. I'm with you, but if your primary criticism is *proprietary software, and a closed source business model*, Throwing 10k at *Apple*, a company that is well known and widely disliked for the closed source closed off development model and business model is not exactly a purer solution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmdx7l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Screw ClosedAI and their proprietary garbage.&lt;/p&gt;\\n\\n&lt;p&gt;I mean.. I&amp;#39;m with you, but if your primary criticism is &lt;em&gt;proprietary software, and a closed source business model&lt;/em&gt;, Throwing 10k at &lt;em&gt;Apple&lt;/em&gt;, a company that is well known and widely disliked for the closed source closed off development model and business model is not exactly a purer solution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmdx7l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742890011,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm8f5t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Squik67","can_mod_post":false,"created_utc":1742886330,"send_replies":true,"parent_id":"t1_mjl45jj","score":4,"author_fullname":"t2_mplfl4mo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are very few open source models, since when throwing out freely a big binary is open source !??, the only one I know is allenai.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm8f5t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are very few open source models, since when throwing out freely a big binary is open source !??, the only one I know is allenai.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm8f5t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742886330,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnczfj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Basic-Pay-9535","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl70js","score":1,"author_fullname":"t2_lnbhv5rp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep this is true . As long as they keep releasing the next SOTA models which beat open source, they will be in the spotlight and people would buy their memberships with OpenAI .","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjnczfj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep this is true . As long as they keep releasing the next SOTA models which beat open source, they will be in the spotlight and people would buy their memberships with OpenAI .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnczfj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742908293,"author_flair_text":null,"treatment_tags":[],"created_utc":1742908293,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl70js","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheLogiqueViper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl6ofy","score":5,"author_fullname":"t2_4wyp4xpi","approved_by":null,"mod_note":null,"all_awardings":[],"body":"They will remain in spotlight as long as their model is best in the world , o3 destroyed previous arc agi benchmark \\nUnless open source ai beats OpenAI model they will dominate still","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjl70js","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They will remain in spotlight as long as their model is best in the world , o3 destroyed previous arc agi benchmark \\nUnless open source ai beats OpenAI model they will dominate still&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl70js/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868180,"author_flair_text":null,"treatment_tags":[],"created_utc":1742868180,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl6ofy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AbdelMuhaymin","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl62lt","score":5,"author_fullname":"t2_16tfe5y1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The lesson is, you can open source your model, which will be used by outliers like us. But, the general public will still rather pay for the ease of use. Most people can't afford higher vram GPUs or even know how to daisy chain 4 RTX 5090s. \\n\\nIllustrious XL just got millions of dollars from AI bros who enjoy their generative AI models. They've been raising hundreds of thousands per model and releasing it open sourced for all to use. But again, most people would rather just pay for MJ.\\n\\nGoing completely closed source is counterproductive to humanity. I'm tired of OpenAI being in the spotlight.","edited":false,"author_flair_css_class":null,"name":"t1_mjl6ofy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The lesson is, you can open source your model, which will be used by outliers like us. But, the general public will still rather pay for the ease of use. Most people can&amp;#39;t afford higher vram GPUs or even know how to daisy chain 4 RTX 5090s. &lt;/p&gt;\\n\\n&lt;p&gt;Illustrious XL just got millions of dollars from AI bros who enjoy their generative AI models. They&amp;#39;ve been raising hundreds of thousands per model and releasing it open sourced for all to use. But again, most people would rather just pay for MJ.&lt;/p&gt;\\n\\n&lt;p&gt;Going completely closed source is counterproductive to humanity. I&amp;#39;m tired of OpenAI being in the spotlight.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl6ofy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868059,"author_flair_text":null,"collapsed":false,"created_utc":1742868059,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjncqyg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Basic-Pay-9535","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl62lt","score":1,"author_fullname":"t2_lnbhv5rp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are they profiting ? Genuine question as I’m not sure how that’d work . but yeah, DeepSeek is so good .","edited":false,"author_flair_css_class":null,"name":"t1_mjncqyg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are they profiting ? Genuine question as I’m not sure how that’d work . but yeah, DeepSeek is so good .&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjncqyg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742908208,"author_flair_text":null,"collapsed":false,"created_utc":1742908208,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl62lt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheLogiqueViper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl4vqu","score":12,"author_fullname":"t2_4wyp4xpi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Deepseek is open source still profitable\\nI think Sam Altman thought no one can build ai model and planned a monopoly hoping they gain immense power and get to control the future","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl62lt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek is open source still profitable\\nI think Sam Altman thought no one can build ai model and planned a monopoly hoping they gain immense power and get to control the future&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl62lt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867842,"author_flair_text":null,"treatment_tags":[],"created_utc":1742867842,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl6qi5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rude-Proposal-9600","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl4vqu","score":1,"author_fullname":"t2_sbuok4xy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Let them be butt frustrated","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl6qi5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let them be butt frustrated&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl6qi5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868079,"author_flair_text":null,"treatment_tags":[],"created_utc":1742868079,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl4vqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AbdelMuhaymin","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl4eeu","score":25,"author_fullname":"t2_16tfe5y1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They're already doing everything in their power to ban Chinese open source LLMs. Just look at the Chinese open source generative AI videos like Wan and Hunyuan. OpenAI are pissed.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjl4vqu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;re already doing everything in their power to ban Chinese open source LLMs. Just look at the Chinese open source generative AI videos like Wan and Hunyuan. OpenAI are pissed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl4vqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867426,"author_flair_text":null,"treatment_tags":[],"created_utc":1742867426,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm5zaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl4eeu","score":3,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He sounds like a dictator in the making. We’ll see what happens in future elections and how they might try to influence those.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjm5zaz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He sounds like a dictator in the making. We’ll see what happens in future elections and how they might try to influence those.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm5zaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742884761,"author_flair_text":null,"treatment_tags":[],"created_utc":1742884761,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl4eeu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheLogiqueViper","can_mod_post":false,"created_utc":1742867258,"send_replies":true,"parent_id":"t1_mjl45jj","score":15,"author_fullname":"t2_4wyp4xpi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I won’t be surprised if open ai weaponises ai against humans in future \\nJust to strip people off money and surveil them","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl4eeu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I won’t be surprised if open ai weaponises ai against humans in future \\nJust to strip people off money and surveil them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl4eeu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867258,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlzazm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InternationalPlan325","can_mod_post":false,"created_utc":1742880670,"send_replies":true,"parent_id":"t1_mjl45jj","score":3,"author_fullname":"t2_2lujzty7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You sound like someone I'd be friends with. 😆","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlzazm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You sound like someone I&amp;#39;d be friends with. 😆&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlzazm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742880670,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmgp56","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pier4r","can_mod_post":false,"created_utc":1742891944,"send_replies":true,"parent_id":"t1_mjl45jj","score":1,"author_fullname":"t2_ci7ay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; they can't even tell the difference between their ass and their elbows. \\n\\n\\n&gt; Elbows up and fuck 'em.\\n\\nInstruction unclear I put my butt up and it wasn't nice.\\n\\nbtw: it is no different than most software. Most SW is closed source and people don't freak out. Further the LLMs are mostly open weight, not even real open source. It would be similar to a freeware in classic software.\\n\\nI am for open weight models, but I can see that investors want closed source products to feel like investing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmgp56","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;they can&amp;#39;t even tell the difference between their ass and their elbows. &lt;/p&gt;\\n\\n&lt;p&gt;Elbows up and fuck &amp;#39;em.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Instruction unclear I put my butt up and it wasn&amp;#39;t nice.&lt;/p&gt;\\n\\n&lt;p&gt;btw: it is no different than most software. Most SW is closed source and people don&amp;#39;t freak out. Further the LLMs are mostly open weight, not even real open source. It would be similar to a freeware in classic software.&lt;/p&gt;\\n\\n&lt;p&gt;I am for open weight models, but I can see that investors want closed source products to feel like investing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmgp56/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742891944,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl45jj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AbdelMuhaymin","can_mod_post":false,"created_utc":1742867175,"send_replies":true,"parent_id":"t3_1jj6i4m","score":85,"author_fullname":"t2_16tfe5y1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Screw ClosedAI and their proprietary garbage. If you're not open source you're the villain in this story. Plenty of ways to monetize and still remain open source. 99% of people will never run LLMs locally - they can't even tell the difference between their ass and their elbows. They could've released their models like Deepseek did. Instead, they opted for greed.\\n\\nElbows up and fuck 'em.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl45jj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Screw ClosedAI and their proprietary garbage. If you&amp;#39;re not open source you&amp;#39;re the villain in this story. Plenty of ways to monetize and still remain open source. 99% of people will never run LLMs locally - they can&amp;#39;t even tell the difference between their ass and their elbows. They could&amp;#39;ve released their models like Deepseek did. Instead, they opted for greed.&lt;/p&gt;\\n\\n&lt;p&gt;Elbows up and fuck &amp;#39;em.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl45jj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867175,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":85}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjn4i66","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"skerit","can_mod_post":false,"created_utc":1742905018,"send_replies":true,"parent_id":"t3_1jj6i4m","score":4,"author_fullname":"t2_2bpem","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wish the official DeepSeek API could reach 20 tokens per second.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjn4i66","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wish the official DeepSeek API could reach 20 tokens per second.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn4i66/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742905018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjljtjd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"particlecore","can_mod_post":false,"created_utc":1742873103,"send_replies":true,"parent_id":"t1_mjkrnwr","score":3,"author_fullname":"t2_4i2ak2kk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"let me think about that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjljtjd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;let me think about that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjljtjd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742873103,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm65iv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"created_utc":1742884871,"send_replies":true,"parent_id":"t1_mjkrnwr","score":3,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"3 minutes and a half with 16k prompts, based on what another commenter said.\\n\\nI think that’s not too bad.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm65iv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3 minutes and a half with 16k prompts, based on what another commenter said.&lt;/p&gt;\\n\\n&lt;p&gt;I think that’s not too bad.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm65iv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742884871,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjkxboq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"McSendo","can_mod_post":false,"created_utc":1742864772,"send_replies":true,"parent_id":"t1_mjkrnwr","score":4,"author_fullname":"t2_2544z5xm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LMAO HAHAHHAHAHAHHAA","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkxboq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LMAO HAHAHHAHAHAHHAA&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkxboq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742864772,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl6t7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stddealer","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjksadw","score":16,"author_fullname":"t2_5gk3j2hj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a MOE. It's fast at generating tokens because only a fraction of the full model needs to be activated for a single token. But when processing the prompt as a batch, pretty much all the model is used because each consecutive tokens will activate a different set of experts. This slows down the batch processing a lot, and it becomes barely faster or even slower than processing each token separately.","edited":1742895696,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjl6t7z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a MOE. It&amp;#39;s fast at generating tokens because only a fraction of the full model needs to be activated for a single token. But when processing the prompt as a batch, pretty much all the model is used because each consecutive tokens will activate a different set of experts. This slows down the batch processing a lot, and it becomes barely faster or even slower than processing each token separately.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl6t7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868105,"author_flair_text":null,"treatment_tags":[],"created_utc":1742868105,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"03eba0e8-72f2-11ee-96eb-9a14648159ce","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmpvbm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AlphaPrime90","can_mod_post":false,"created_utc":1742897826,"send_replies":true,"parent_id":"t1_mjlc312","score":1,"author_fullname":"t2_104g23","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Another user https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjltq0a/  \\ntested it on M3 Ultra and got 6t/s @ 16k context.  \\nBut that's 380GB MoE model vs regular 70GB model. interesting numbers for sure","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjmpvbm","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Another user &lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjltq0a/\\"&gt;https://old.reddit.com/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjltq0a/&lt;/a&gt;&lt;br/&gt;\\ntested it on M3 Ultra and got 6t/s @ 16k context.&lt;br/&gt;\\nBut that&amp;#39;s 380GB MoE model vs regular 70GB model. interesting numbers for sure&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmpvbm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742897826,"author_flair_text":"koboldcpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-2,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":0,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mjlm5x6","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlm5x6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjles1k","score":0,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlm5x6/","num_reports":null,"locked":false,"name":"t1_mjlm5x6","created":1742874105,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742874105,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mjles1k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1742871072,"send_replies":true,"parent_id":"t1_mjld3yr","score":6,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is something that in classic (non-AI) tooling we'd all have a good laugh about if someone said 75k was extreme! In fact 75k is a small and highly constraining amount of the code for my use case in which I need to do these kinds of operations repeatedly over many gigs of code!\\n\\nAnd it's nowhere near $40k, holy shit. All my gear is used, mostly broken (and fixed by my own fair hand, thank you very much) to get good stuff at for-parts prices. Even the RAM is bulk you-get-what-you-get datacenter pulls. It's been a tedious process, sometimes frustrating, but it's been fun. And, yes, expensive. Just not _that_ expensive.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjles1k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is something that in classic (non-AI) tooling we&amp;#39;d all have a good laugh about if someone said 75k was extreme! In fact 75k is a small and highly constraining amount of the code for my use case in which I need to do these kinds of operations repeatedly over many gigs of code!&lt;/p&gt;\\n\\n&lt;p&gt;And it&amp;#39;s nowhere near $40k, holy shit. All my gear is used, mostly broken (and fixed by my own fair hand, thank you very much) to get good stuff at for-parts prices. Even the RAM is bulk you-get-what-you-get datacenter pulls. It&amp;#39;s been a tedious process, sometimes frustrating, but it&amp;#39;s been fun. And, yes, expensive. Just not &lt;em&gt;that&lt;/em&gt; expensive.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjles1k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742871072,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjld3yr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlc312","score":-2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjld3yr/","num_reports":null,"locked":false,"name":"t1_mjld3yr","created":1742870437,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742870437,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlc312","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl6flc","score":7,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I run an Epyc 9135 with 288GB DDR5-6000 and 3x RTX A6000s. My main model is Qwen2.5 72B Instruct exl2 quant at 8.0bpw with speculative decoding draft model 1.5B @ 8.0bpw. I get virtually instant PP with small contexts, and inference runs at a solid 45 tokens/sec.\\n\\nHowever, if I submit 72k tokens (not bytes, _tokens_) of Python code and ask Qwen a question about that code I get:\\n\\n    401 tokens generated in 129.47 seconds (Queue: 0.0 s, Process: 0 cached tokens and 72703 new tokens at 680.24 T/s,\\nGenerate: 17.75 T/s, Context: 72703 tokens)\\n\\nThat's 1 minute 46 seconds just for PP with three A6000s... I dread to think what the equivalent task would take on a Mac!","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjlc312","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I run an Epyc 9135 with 288GB DDR5-6000 and 3x RTX A6000s. My main model is Qwen2.5 72B Instruct exl2 quant at 8.0bpw with speculative decoding draft model 1.5B @ 8.0bpw. I get virtually instant PP with small contexts, and inference runs at a solid 45 tokens/sec.&lt;/p&gt;\\n\\n&lt;p&gt;However, if I submit 72k tokens (not bytes, &lt;em&gt;tokens&lt;/em&gt;) of Python code and ask Qwen a question about that code I get:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;401 tokens generated in 129.47 seconds (Queue: 0.0 s, Process: 0 cached tokens and 72703 new tokens at 680.24 T/s,\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Generate: 17.75 T/s, Context: 72703 tokens)&lt;/p&gt;\\n\\n&lt;p&gt;That&amp;#39;s 1 minute 46 seconds just for PP with three A6000s... I dread to think what the equivalent task would take on a Mac!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlc312/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742870049,"author_flair_text":null,"treatment_tags":[],"created_utc":1742870049,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl6flc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1742867972,"send_replies":true,"parent_id":"t1_mjl5ds7","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl6flc/","num_reports":null,"locked":false,"name":"t1_mjl6flc","created":1742867972,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlc6tv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlaf3w","score":3,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Heh, you're clearly not running enormous volumes/batches of prompts ;)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mjlc6tv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Heh, you&amp;#39;re clearly not running enormous volumes/batches of prompts ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlc6tv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742870089,"author_flair_text":null,"treatment_tags":[],"created_utc":1742870089,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlaf3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JacketHistorical2321","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl5ds7","score":0,"author_fullname":"t2_bsvkuoyj","approved_by":null,"mod_note":null,"all_awardings":[],"body":"“…OVER A MINUTE!!!” …so walk away and go grab a glass of water lol","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjlaf3w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;“…OVER A MINUTE!!!” …so walk away and go grab a glass of water lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlaf3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742869430,"author_flair_text":null,"treatment_tags":[],"created_utc":1742869430,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl5ds7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl1mva","score":9,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's _very_ long depending on your context. You could be waiting well over a minute for PP if you're pushing the limits of a 32k model.","edited":false,"author_flair_css_class":null,"name":"t1_mjl5ds7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s &lt;em&gt;very&lt;/em&gt; long depending on your context. You could be waiting well over a minute for PP if you&amp;#39;re pushing the limits of a 32k model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl5ds7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867601,"author_flair_text":null,"collapsed":false,"created_utc":1742867601,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl1mva","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkvuuy","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl1mva/","num_reports":null,"locked":false,"name":"t1_mjl1mva","created":1742866285,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742866285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjpc4ka","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Live-Adagio2589","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlk8nz","score":2,"author_fullname":"t2_qos7blrn","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very insightful. Thanks for sharing.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjpc4ka","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very insightful. Thanks for sharing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpc4ka/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742929015,"author_flair_text":null,"treatment_tags":[],"created_utc":1742929015,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmmfn0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henfiber","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlq6dk","score":2,"author_fullname":"t2_lw9me25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The Tensor cores also run FP16 at 4x the throughput of regular raster cores. So, even if an Apple M3 Ultra has equivalent raster performance to a 4070, the matrix multiplication performance is 1/4 of that, and around 1/10 of a 4090.\\n\\nPrompt processing should be about 10 times slower on a Mac 3 Ultra compared to a 4090 (for models fitting on the 4090 VRAM).\\n\\nMulltiply that Nvidia advantage by 2 for FP8, and by 4 for FP4 (Blackwell and newer - not commonly used yet).","edited":1742896038,"gildings":{},"author_flair_css_class":null,"name":"t1_mjmmfn0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The Tensor cores also run FP16 at 4x the throughput of regular raster cores. So, even if an Apple M3 Ultra has equivalent raster performance to a 4070, the matrix multiplication performance is 1/4 of that, and around 1/10 of a 4090.&lt;/p&gt;\\n\\n&lt;p&gt;Prompt processing should be about 10 times slower on a Mac 3 Ultra compared to a 4090 (for models fitting on the 4090 VRAM).&lt;/p&gt;\\n\\n&lt;p&gt;Mulltiply that Nvidia advantage by 2 for FP8, and by 4 for FP4 (Blackwell and newer - not commonly used yet).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmmfn0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895749,"author_flair_text":null,"treatment_tags":[],"created_utc":1742895749,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlq6dk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"auradragon1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlk8nz","score":0,"author_fullname":"t2_4atixtm8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nvidia GPUs have dedicated 8bit and 4 bit acceleration called Tensor cores. As far as I know, Macs don't have dedicated cores for 8/4bit.\\n\\nMaybe Apple will add them in the M5 generation. Or maybe Apple will figure out a way to combine their Neural Engine's 8bit acceleration and the raw power of the GPU for LLMs.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mjlq6dk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nvidia GPUs have dedicated 8bit and 4 bit acceleration called Tensor cores. As far as I know, Macs don&amp;#39;t have dedicated cores for 8/4bit.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe Apple will add them in the M5 generation. Or maybe Apple will figure out a way to combine their Neural Engine&amp;#39;s 8bit acceleration and the raw power of the GPU for LLMs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlq6dk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742875923,"author_flair_text":null,"treatment_tags":[],"created_utc":1742875923,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlk8nz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"trshimizu","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl3eow","score":24,"author_fullname":"t2_4uy1w5ww","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because Mac Studio’s raw computational power is weaker compared to high-end/data center NVIDIA GPUs.\\n\\nWhen generating tokens, the machine loads the model parameters from DRAM to the GPU and applies them to one token at a time. The computation needed here is light, so memory bandwidth becomes the bottleneck. Mac Studio with M3 Ultra performs well in this scenario because its memory bandwidth is comparable to NVIDIA’s.\\n\\nHowever, when processing a long prompt, the machine loads the model parameters and applies them to multiple tokens at once—for example, 512 tokens. In this case, memory bandwidth is no longer the bottleneck, and computational power becomes critical for handling calculations across all these tokens simultaneously. This is where Mac Studio’s weaker computational power makes it slower compared to NVIDIA.","edited":false,"author_flair_css_class":null,"name":"t1_mjlk8nz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because Mac Studio’s raw computational power is weaker compared to high-end/data center NVIDIA GPUs.&lt;/p&gt;\\n\\n&lt;p&gt;When generating tokens, the machine loads the model parameters from DRAM to the GPU and applies them to one token at a time. The computation needed here is light, so memory bandwidth becomes the bottleneck. Mac Studio with M3 Ultra performs well in this scenario because its memory bandwidth is comparable to NVIDIA’s.&lt;/p&gt;\\n\\n&lt;p&gt;However, when processing a long prompt, the machine loads the model parameters and applies them to multiple tokens at once—for example, 512 tokens. In this case, memory bandwidth is no longer the bottleneck, and computational power becomes critical for handling calculations across all these tokens simultaneously. This is where Mac Studio’s weaker computational power makes it slower compared to NVIDIA.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlk8nz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742873282,"author_flair_text":null,"collapsed":false,"created_utc":1742873282,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl5lqq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Umthrfcker","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl3eow","score":-2,"author_fullname":"t2_mtnfuaa7g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The cpus have to load all the weights to ram, that takes some time. But only load once since it can be cached onto the memory. Correct me if i am wrong.","edited":false,"author_flair_css_class":null,"name":"t1_mjl5lqq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The cpus have to load all the weights to ram, that takes some time. But only load once since it can be cached onto the memory. Correct me if i am wrong.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl5lqq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867677,"author_flair_text":null,"collapsed":false,"created_utc":1742867677,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl3eow","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"weight_matrix","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkvuuy","score":0,"author_fullname":"t2_53znhdy3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you explain why the prompt processing is generally slow? Is it due to KV cache?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl3eow","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you explain why the prompt processing is generally slow? Is it due to KV cache?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl3eow/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742866912,"author_flair_text":null,"treatment_tags":[],"created_utc":1742866912,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm6d06","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkvuuy","score":-1,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, APIs shouldn’t be compared here, any local hardware would lose.\\n\\nAnd try fitting Deepsek using NVIDIA VRAM…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm6d06","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, APIs shouldn’t be compared here, any local hardware would lose.&lt;/p&gt;\\n\\n&lt;p&gt;And try fitting Deepsek using NVIDIA VRAM…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm6d06/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742884999,"author_flair_text":null,"treatment_tags":[],"created_utc":1742884999,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkvuuy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"1uckyb","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjksadw","score":24,"author_fullname":"t2_87zdar50","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, prompt processing is quite slow for long contexts in a Mac compared to what we are used to with APIs and NVIDIA GPUs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjkvuuy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, prompt processing is quite slow for long contexts in a Mac compared to what we are used to with APIs and NVIDIA GPUs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkvuuy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742864257,"author_flair_text":null,"treatment_tags":[],"created_utc":1742864257,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmrcmr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MMAgeezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjla8dy","score":1,"author_fullname":"t2_34hhuqbx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the speed one can expect from prompt processing? \\n\\nIs my understanding that you'd be waiting multiple minutes for prompt processing of 5-10k tokens incorrect?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmrcmr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the speed one can expect from prompt processing? &lt;/p&gt;\\n\\n&lt;p&gt;Is my understanding that you&amp;#39;d be waiting multiple minutes for prompt processing of 5-10k tokens incorrect?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmrcmr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742898687,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1742898687,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjla8dy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JacketHistorical2321","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjksadw","score":0,"author_fullname":"t2_bsvkuoyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its been proven that prompt processing time is nowhere near as bad as people like OP here is making it out to be.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjla8dy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its been proven that prompt processing time is nowhere near as bad as people like OP here is making it out to be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjla8dy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742869361,"author_flair_text":null,"treatment_tags":[],"created_utc":1742869361,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjksadw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Specter_Origin","can_mod_post":false,"created_utc":1742863030,"send_replies":true,"parent_id":"t1_mjkrnwr","score":3,"author_fullname":"t2_kcu2kx4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think that would only be the case when the model is not in memory, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjksadw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think that would only be the case when the model is not in memory, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjksadw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742863030,"author_flair_text":"Ollama","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjkzeaj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bick_nyers","can_mod_post":false,"created_utc":1742865498,"send_replies":true,"parent_id":"t1_mjkrnwr","score":-1,"author_fullname":"t2_6nwld4d3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So true.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkzeaj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So true.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkzeaj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742865498,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkrnwr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Salendron2","can_mod_post":false,"created_utc":1742862809,"send_replies":true,"parent_id":"t3_1jj6i4m","score":51,"author_fullname":"t2_13l1i5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"“And only a 20 minute wait for that first token!”","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkrnwr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;“And only a 20 minute wait for that first token!”&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkrnwr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742862809,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":51}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmazsv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hurrdurrmeh","can_mod_post":false,"created_utc":1742888042,"send_replies":true,"parent_id":"t3_1jj6i4m","score":4,"author_fullname":"t2_i63k7zcc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"But what is the time to the first token?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmazsv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But what is the time to the first token?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmazsv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742888042,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mkgfhv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MonitorAway2394","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjpurjm","score":1,"author_fullname":"t2_14ragprxny","approved_by":null,"mod_note":null,"all_awardings":[],"body":"CORE.... AUDIO\\n\\n  \\nheathen..","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mkgfhv6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;CORE.... AUDIO&lt;/p&gt;\\n\\n&lt;p&gt;heathen..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mkgfhv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743300588,"author_flair_text":null,"treatment_tags":[],"created_utc":1743300588,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjpurjm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cptbeard","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjpo5zh","score":1,"author_fullname":"t2_r2qh3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it was sarcasm. not a lot to do with arm-based mac with 500GB of ram besides AI, least of all games","edited":false,"author_flair_css_class":null,"name":"t1_mjpurjm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it was sarcasm. not a lot to do with arm-based mac with 500GB of ram besides AI, least of all games&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jj6i4m","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpurjm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742934447,"author_flair_text":null,"collapsed":false,"created_utc":1742934447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjpo5zh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Recommended_For_You","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjp04al","score":2,"author_fullname":"t2_80eerrz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sure honey. Now go brush your teeth, it's way past your bedtime.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjpo5zh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure honey. Now go brush your teeth, it&amp;#39;s way past your bedtime.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpo5zh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742932563,"author_flair_text":null,"treatment_tags":[],"created_utc":1742932563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjp04al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cptbeard","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmlu5n","score":2,"author_fullname":"t2_r2qh3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"like.. play games?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjp04al","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;like.. play games?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjp04al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742925501,"author_flair_text":null,"treatment_tags":[],"created_utc":1742925501,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmlu5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Recommended_For_You","can_mod_post":false,"created_utc":1742895365,"send_replies":true,"parent_id":"t1_mjm8sr1","score":3,"author_fullname":"t2_80eerrz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The difference being, if you buy a 10k computer, you own a 10k computer to do computer stuff.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmlu5n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The difference being, if you buy a 10k computer, you own a 10k computer to do computer stuff.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmlu5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895365,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjm8sr1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"surrealize","can_mod_post":false,"created_utc":1742886578,"send_replies":true,"parent_id":"t3_1jj6i4m","score":10,"author_fullname":"t2_3bqdl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Take the $10k, put it in the bank, pay for a chatgpt subscription with the interest, lol\\n\\nObviously on LocalLLama, folks want to run locally.  But the wider world?  Probably at least as happy with a subscription.  Probably more resource-efficient too","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm8sr1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Take the $10k, put it in the bank, pay for a chatgpt subscription with the interest, lol&lt;/p&gt;\\n\\n&lt;p&gt;Obviously on LocalLLama, folks want to run locally.  But the wider world?  Probably at least as happy with a subscription.  Probably more resource-efficient too&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm8sr1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742886578,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnaq4b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sigiel","can_mod_post":false,"created_utc":1742907467,"send_replies":true,"parent_id":"t1_mjmr8a1","score":2,"author_fullname":"t2_r8611p6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You look at it wrong, the shift is in manufacturing new motherboard with unified memory on pc that will also get gpu,  and could run deep seek way better, \\n\\nit the long game, in 2 years max , those motherboard will be common, and then open ai will be realy realy fucked.\\n\\nno wonder Sam the prophet is on a rampage about ai safety…. His only option now is to regulate","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjnaq4b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You look at it wrong, the shift is in manufacturing new motherboard with unified memory on pc that will also get gpu,  and could run deep seek way better, &lt;/p&gt;\\n\\n&lt;p&gt;it the long game, in 2 years max , those motherboard will be common, and then open ai will be realy realy fucked.&lt;/p&gt;\\n\\n&lt;p&gt;no wonder Sam the prophet is on a rampage about ai safety…. His only option now is to regulate&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnaq4b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742907467,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmuzpf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"randomrealname","can_mod_post":false,"created_utc":1742900658,"send_replies":true,"parent_id":"t1_mjmr8a1","score":1,"author_fullname":"t2_5ixluafj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for this comment, I was wondering the specs needed to run it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmuzpf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this comment, I was wondering the specs needed to run it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmuzpf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742900658,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjwdj4n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Psychological-Taste3","can_mod_post":false,"created_utc":1743022105,"send_replies":true,"parent_id":"t1_mjmr8a1","score":1,"author_fullname":"t2_782c1cu8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On the other hand, hiring a dedicated software engineer to answer you 24/7 is going to be way more expensive than this. Some of y’all expectations are wild. This is really impressive stuff.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjwdj4n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On the other hand, hiring a dedicated software engineer to answer you 24/7 is going to be way more expensive than this. Some of y’all expectations are wild. This is really impressive stuff.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjwdj4n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743022105,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmr8a1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThatInternetGuy","can_mod_post":false,"created_utc":1742898618,"send_replies":true,"parent_id":"t3_1jj6i4m","score":7,"author_fullname":"t2_49uhy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Talking like everyone had $14K to drop on a Mac Studio with 512GB RAM. That's $14/month for 83 years if to be purchased by someone would just buy a Mac Studio for the AI.\\n\\nIt makes sense only for those who own a Mac Studio for their works, not practical for anyone to buy it just for AI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmr8a1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Talking like everyone had $14K to drop on a Mac Studio with 512GB RAM. That&amp;#39;s $14/month for 83 years if to be purchased by someone would just buy a Mac Studio for the AI.&lt;/p&gt;\\n\\n&lt;p&gt;It makes sense only for those who own a Mac Studio for their works, not practical for anyone to buy it just for AI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmr8a1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742898618,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlsvi0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AriyaSavaka","can_mod_post":false,"created_utc":1742877234,"send_replies":true,"parent_id":"t3_1jj6i4m","score":3,"author_fullname":"t2_ddd5dxdn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"R2 need to have at least 200k tokens for enterprise tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlsvi0","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R2 need to have at least 200k tokens for enterprise tasks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlsvi0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742877234,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":7,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjq3r69","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"askho","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjq1ozc","score":2,"author_fullname":"t2_8edgi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The model being talked about can be run on the highest end mac studio with 500gb of RAM. It costs 10k. Or you can use a cloud provider like open router. It would cost you less than a dollar per million tokens.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjq3r69","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The model being talked about can be run on the highest end mac studio with 500gb of RAM. It costs 10k. Or you can use a cloud provider like open router. It would cost you less than a dollar per million tokens.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjq3r69/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742937075,"author_flair_text":null,"treatment_tags":[],"created_utc":1742937075,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjq1ozc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1742936457,"send_replies":true,"parent_id":"t1_mjpagg9","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjq1ozc/","num_reports":null,"locked":false,"name":"t1_mjq1ozc","created":1742936457,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mjpagg9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"askho","can_mod_post":false,"created_utc":1742928532,"send_replies":true,"parent_id":"t1_mjlqavn","score":4,"author_fullname":"t2_8edgi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can get a computer that runs an LLM as good as OpenAI's.  Most people won't, but server costs for a similar LLM are way cheaper with DeepSeek v3 than OpenAI's.  We're talking under a dollar per million tokens with DeepSeek v3, compared to $15 per million input tokens *plus* $60 per million output tokens with OpenAI.","edited":1742928721,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjpagg9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can get a computer that runs an LLM as good as OpenAI&amp;#39;s.  Most people won&amp;#39;t, but server costs for a similar LLM are way cheaper with DeepSeek v3 than OpenAI&amp;#39;s.  We&amp;#39;re talking under a dollar per million tokens with DeepSeek v3, compared to $15 per million input tokens &lt;em&gt;plus&lt;/em&gt; $60 per million output tokens with OpenAI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpagg9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742928532,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mkghk6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MonitorAway2394","can_mod_post":false,"send_replies":true,"parent_id":"t1_mkghil0","score":1,"author_fullname":"t2_14ragprxny","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"again sorry I just, umm... I suck :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mkghk6t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;again sorry I just, umm... I suck :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mkghk6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743301393,"author_flair_text":null,"treatment_tags":[],"created_utc":1743301393,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mkghil0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MonitorAway2394","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjpdh36","score":1,"author_fullname":"t2_14ragprxny","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"remember what these models are Distilled from... Just don't get so excited lol, all models are OpenAI Models, at least, initially.... (sry I'm manic and trying to be humorous whilst also making a maybe, maybe ignorant? maybe? commentary err or comment on the fact that we got Deepsy's cause we had GPT... Which means. The best model as much as Claude simps will hate me saying this cause guess what Claude is... GPT bababababy! LOL :P) \\n\\nOk so for real tho, they're all distillations, initially, of GPT right? And/or verily my theory for which I've had a bunch of local LLMs happily reinforce such that it's become delusion! O.o jkjk, but that it is\\n\\n  \\nAll of them are using the same model base // maybe even kick back models from OpenAI/Soft, cause to be honest, how quickly did each company create what took OpenAI a decade o years, I'm throwing out totally \\"from the ass\\" numbers here, anyone FEEL TOTALLY FREE to rip my shit apart, I'm again, theorizing here also not sure why I'm speaking like, to more than one person, damn I suck at commenting... ANYWAYS so O.o \\n\\nThink about it right, Google, IP issues would be FREAKING RIDICULOUS insofar as much as \\"Hey OpenAI you ripped youtube off like, so hard we could... make your great great great great great great great great great grandchildren still have to be paying off the lawsuit if we want or you could just ya know, give us Gemini we'll call it Gemini and make lil Gemmaz too! \\n\\n  \\nThen you have Facebook Mark's surfing with the flags of America the USA portion whilst calling Alt-man, \\"HEY SAM, wtf. WHAT THE F\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\*\\\\* YOU \\\\*\\\\*\\\\* BITCH?! I'm surfing up the coast I'ma kick your ass for training your GPT on everything I bought I mean built! Wait, wait, Llalal, Llam, lala, Llama, I want a copy, I'm going to call it, Llama, for fuck-all who knows why? MERIKKA!\\" \\n\\nThen the rest, like.. EVERYONE got ripped off except ... the one that doesn't have AI right now other than well, they're getting there, a little help from a bunch of friends that just don't care as much about ya I guess-----\\n\\n  \\nWHY IS APPLE STRUGGLING SO HARD?\\n\\n  \\nCause Apple was the one friend who hated sharing shit and thus after awhile people quit inviting them to the whatever peoples do these days I've been isolated and became weird a decade ago but ya know? RIGHT? \\n\\n  \\nLMFAO sorry I normally would edit/delete this shit but I had fun, have fun reading it, take what you will from my rambling shit above, and massive apologies to the person I was responding to, m808, I forgot where I was and just went with it. and still, feel lost. O.o","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mkghil0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;remember what these models are Distilled from... Just don&amp;#39;t get so excited lol, all models are OpenAI Models, at least, initially.... (sry I&amp;#39;m manic and trying to be humorous whilst also making a maybe, maybe ignorant? maybe? commentary err or comment on the fact that we got Deepsy&amp;#39;s cause we had GPT... Which means. The best model as much as Claude simps will hate me saying this cause guess what Claude is... GPT bababababy! LOL :P) &lt;/p&gt;\\n\\n&lt;p&gt;Ok so for real tho, they&amp;#39;re all distillations, initially, of GPT right? And/or verily my theory for which I&amp;#39;ve had a bunch of local LLMs happily reinforce such that it&amp;#39;s become delusion! O.o jkjk, but that it is&lt;/p&gt;\\n\\n&lt;p&gt;All of them are using the same model base // maybe even kick back models from OpenAI/Soft, cause to be honest, how quickly did each company create what took OpenAI a decade o years, I&amp;#39;m throwing out totally &amp;quot;from the ass&amp;quot; numbers here, anyone FEEL TOTALLY FREE to rip my shit apart, I&amp;#39;m again, theorizing here also not sure why I&amp;#39;m speaking like, to more than one person, damn I suck at commenting... ANYWAYS so O.o &lt;/p&gt;\\n\\n&lt;p&gt;Think about it right, Google, IP issues would be FREAKING RIDICULOUS insofar as much as &amp;quot;Hey OpenAI you ripped youtube off like, so hard we could... make your great great great great great great great great great grandchildren still have to be paying off the lawsuit if we want or you could just ya know, give us Gemini we&amp;#39;ll call it Gemini and make lil Gemmaz too! &lt;/p&gt;\\n\\n&lt;p&gt;Then you have Facebook Mark&amp;#39;s surfing with the flags of America the USA portion whilst calling Alt-man, &amp;quot;HEY SAM, wtf. WHAT THE F*********** YOU *** BITCH?! I&amp;#39;m surfing up the coast I&amp;#39;ma kick your ass for training your GPT on everything I bought I mean built! Wait, wait, Llalal, Llam, lala, Llama, I want a copy, I&amp;#39;m going to call it, Llama, for fuck-all who knows why? MERIKKA!&amp;quot; &lt;/p&gt;\\n\\n&lt;p&gt;Then the rest, like.. EVERYONE got ripped off except ... the one that doesn&amp;#39;t have AI right now other than well, they&amp;#39;re getting there, a little help from a bunch of friends that just don&amp;#39;t care as much about ya I guess-----&lt;/p&gt;\\n\\n&lt;p&gt;WHY IS APPLE STRUGGLING SO HARD?&lt;/p&gt;\\n\\n&lt;p&gt;Cause Apple was the one friend who hated sharing shit and thus after awhile people quit inviting them to the whatever peoples do these days I&amp;#39;ve been isolated and became weird a decade ago but ya know? RIGHT? &lt;/p&gt;\\n\\n&lt;p&gt;LMFAO sorry I normally would edit/delete this shit but I had fun, have fun reading it, take what you will from my rambling shit above, and massive apologies to the person I was responding to, m808, I forgot where I was and just went with it. and still, feel lost. O.o&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mkghil0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743301375,"author_flair_text":null,"treatment_tags":[],"created_utc":1743301375,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjpdh36","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Substantial-Thing303","can_mod_post":false,"created_utc":1742929411,"send_replies":true,"parent_id":"t1_mjlqavn","score":3,"author_fullname":"t2_jvi0f8cv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's open source and any company can offer the service from their own paid servers. The cost per token is about 15 times cheaper than OpenAI for similar performance, or more.  The performance on benchmarks is very close to their flagship models, better in some situations, worse in others. \\n\\nOn top of that, it is not a reasoning model, but it's punching within the range of reasoning models, meaning that we can hope for a future DeepSeek R2 that could literally destroy them in benchmarks.\\n\\nOpenAI's business model only make sense if they have the best models. People are willing to pay 15X the price for an extra 20% or 30% performance in many situations, because in many cases, price is not an issue, and the extra performance is more valuable. They would not be affected by models that have better ROI, as long as those models cannot match the performance of their flagship models. \\n\\nIf you look at the [aider leaderboard](https://aider.chat/docs/leaderboards/), the best OpenAI model is currently on third position and the cost for testing was 186$. They have a cheaper model at the 5th position at 18$ per run. DeekSeek V3 is 7th at 1$ (no joke) per run, but it's not a reasoning model, while the other 2 are. DeepSeek R1 (reasoning model), with the old Sonnet 3.5, is currently at the 2nd position.\\n\\nConsidering that DeekSeek V3 beats Sonnet 3.5, we can already expect a full DeekSeek solution (R1 + V3) to beat that combo, at a fraction of the cost (probably under 5$ per run).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjpdh36","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s open source and any company can offer the service from their own paid servers. The cost per token is about 15 times cheaper than OpenAI for similar performance, or more.  The performance on benchmarks is very close to their flagship models, better in some situations, worse in others. &lt;/p&gt;\\n\\n&lt;p&gt;On top of that, it is not a reasoning model, but it&amp;#39;s punching within the range of reasoning models, meaning that we can hope for a future DeepSeek R2 that could literally destroy them in benchmarks.&lt;/p&gt;\\n\\n&lt;p&gt;OpenAI&amp;#39;s business model only make sense if they have the best models. People are willing to pay 15X the price for an extra 20% or 30% performance in many situations, because in many cases, price is not an issue, and the extra performance is more valuable. They would not be affected by models that have better ROI, as long as those models cannot match the performance of their flagship models. &lt;/p&gt;\\n\\n&lt;p&gt;If you look at the &lt;a href=\\"https://aider.chat/docs/leaderboards/\\"&gt;aider leaderboard&lt;/a&gt;, the best OpenAI model is currently on third position and the cost for testing was 186$. They have a cheaper model at the 5th position at 18$ per run. DeekSeek V3 is 7th at 1$ (no joke) per run, but it&amp;#39;s not a reasoning model, while the other 2 are. DeepSeek R1 (reasoning model), with the old Sonnet 3.5, is currently at the 2nd position.&lt;/p&gt;\\n\\n&lt;p&gt;Considering that DeekSeek V3 beats Sonnet 3.5, we can already expect a full DeekSeek solution (R1 + V3) to beat that combo, at a fraction of the cost (probably under 5$ per run).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjpdh36/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742929411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlqavn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jj6i4m","score":7,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlqavn/","num_reports":null,"locked":false,"name":"t1_mjlqavn","created":1742875982,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742875982,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnmtg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"akumaburn","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjnjr05","score":4,"author_fullname":"t2_8qi7g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They slow down significantly at higher context sizes is the point I'm trying to make.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjnmtg6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They slow down significantly at higher context sizes is the point I&amp;#39;m trying to make.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnmtg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742911627,"author_flair_text":null,"treatment_tags":[],"created_utc":1742911627,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mjnjr05","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"power97992","can_mod_post":false,"created_utc":1742910647,"send_replies":true,"parent_id":"t1_mjndb2e","score":2,"author_fullname":"t2_64yf00b9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Local models  can do more 16k, more like 128 k .","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjnjr05","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Local models  can do more 16k, more like 128 k .&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnjr05/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742910647,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjndb2e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"akumaburn","can_mod_post":false,"created_utc":1742908408,"send_replies":true,"parent_id":"t3_1jj6i4m","score":3,"author_fullname":"t2_8qi7g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For coding, even a 16K context (This was only around 1K I'm guessing) is insufficient. Local LLMs are fine as chat assistants but commodity hardware has a long way to go before it can be used efficiently for agentic coding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjndb2e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For coding, even a 16K context (This was only around 1K I&amp;#39;m guessing) is insufficient. Local LLMs are fine as chat assistants but commodity hardware has a long way to go before it can be used efficiently for agentic coding.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjndb2e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742908408,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmxy56","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1742902113,"send_replies":true,"parent_id":"t3_1jj6i4m","score":2,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ok Llama-4 team, you got this, you only need to release a model better than Deepseek, that's about O3-high.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmxy56","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok Llama-4 team, you got this, you only need to release a model better than Deepseek, that&amp;#39;s about O3-high.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmxy56/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742902113,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmyqs7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1742902492,"send_replies":true,"parent_id":"t3_1jj6i4m","score":2,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah it's hard to run, that' means that instead of 100 million competitors that offer your service for free, you only have 1 million. All closed-AIs are completely fucked.\\n\\nSmart move from China, destroying nascent companies before their monopolize the industry.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmyqs7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it&amp;#39;s hard to run, that&amp;#39; means that instead of 100 million competitors that offer your service for free, you only have 1 million. All closed-AIs are completely fucked.&lt;/p&gt;\\n\\n&lt;p&gt;Smart move from China, destroying nascent companies before their monopolize the industry.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmyqs7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742902492,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmeukq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Practical-Rub-1190","can_mod_post":false,"created_utc":1742890653,"send_replies":true,"parent_id":"t3_1jj6i4m","score":2,"author_fullname":"t2_54s6gr2o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OpenAI never competed in this era, as it's not their goal to have people run local llms. OpenAI is leading because of the brand, but they also has the complete infrastructure package. The fine-tuning, the real-time voice, etc. What deepseek has done will only help OpenAI improve. Deepseek is actually far behind OpenAI because it's not all about those percentages in % benchmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmeukq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenAI never competed in this era, as it&amp;#39;s not their goal to have people run local llms. OpenAI is leading because of the brand, but they also has the complete infrastructure package. The fine-tuning, the real-time voice, etc. What deepseek has done will only help OpenAI improve. Deepseek is actually far behind OpenAI because it&amp;#39;s not all about those percentages in % benchmarks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmeukq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742890653,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmkt27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tim_Andromeda","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmgb7i","score":5,"author_fullname":"t2_yd8k9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I updooted not because I think that’s a good thing but because I think you’re right.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmkt27","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I updooted not because I think that’s a good thing but because I think you’re right.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmkt27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742894691,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1742894691,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmgb7i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Iory1998","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjm0osq","score":8,"author_fullname":"t2_byt5wa14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am 70% certain that if the next R model is a generational leap, the US will ban deepseek completely.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjmgb7i","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am 70% certain that if the next R model is a generational leap, the US will ban deepseek completely.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmgb7i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742891675,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1742891675,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mjm0osq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LostMitosis","can_mod_post":false,"created_utc":1742881468,"send_replies":true,"parent_id":"t1_mjlnh1g","score":6,"author_fullname":"t2_n7j3v3oq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Blog post from some gatekeeper: “DeepSeek is a threat to national security. We have to be protected, we have investors who need to make $$”.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm0osq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Blog post from some gatekeeper: “DeepSeek is a threat to national security. We have to be protected, we have investors who need to make $$”.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm0osq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742881468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlnh1g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Iory1998","can_mod_post":false,"created_utc":1742874680,"send_replies":true,"parent_id":"t3_1jj6i4m","score":2,"author_fullname":"t2_byt5wa14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We all know what's coming next? 😂😂😂😁😁😁😊😊😊","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlnh1g","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We all know what&amp;#39;s coming next? 😂😂😂😁😁😁😊😊😊&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlnh1g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742874680,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl83ut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emport1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl767k","score":2,"author_fullname":"t2_ubae0chn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"me too, but then what are the news being shared here lol","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjl83ut","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;me too, but then what are the news being shared here lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl83ut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868577,"author_flair_text":null,"treatment_tags":[],"created_utc":1742868577,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjnkxve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjl767k","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think it is R1 with cut off reasoning.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjnkxve","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it is R1 with cut off reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjnkxve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742911030,"author_flair_text":null,"treatment_tags":[],"created_utc":1742911030,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl767k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stddealer","can_mod_post":false,"created_utc":1742868238,"send_replies":true,"parent_id":"t1_mjl5l2k","score":7,"author_fullname":"t2_5gk3j2hj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm pretty sure the \\"new\\" V3 is just the same model as the original V3, but with more training.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl767k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m pretty sure the &amp;quot;new&amp;quot; V3 is just the same model as the original V3, but with more training.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl767k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742868238,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mjl5l2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emport1","can_mod_post":false,"created_utc":1742867671,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_ubae0chn0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what did he get on the original v3? has it been further optimized?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl5l2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what did he get on the original v3? has it been further optimized?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl5l2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742867671,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlfrug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"muchcharles","can_mod_post":false,"created_utc":1742871460,"send_replies":true,"parent_id":"t1_mjlexhb","score":1,"author_fullname":"t2_aipkc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Useful for single questions without reasoning (they did say v3 and not r1).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlfrug","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Useful for single questions without reasoning (they did say v3 and not r1).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlfrug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742871460,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlexhb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlexhb/","num_reports":null,"locked":false,"name":"t1_mjlexhb","created":1742871131,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742871131,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjsygeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oh_my_right_leg","can_mod_post":false,"created_utc":1742979887,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_838sm24m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah like at 4 tokens per second, so not really. And I think that was even with a small context length. Imagine trying to feed a whole codebase","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjsygeg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah like at 4 tokens per second, so not really. And I think that was even with a small context length. Imagine trying to feed a whole codebase&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjsygeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742979887,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjtsfal","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"goingsplit","can_mod_post":false,"created_utc":1742994494,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_avw6ghg9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The question is if or when it will do the same or close on Intel integrated graphics..\\nIt seems intel is persisting in crippling its mobile platforms to low bandwidth,  2 memory channels, and everything that makes it slow to run llm..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjtsfal","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The question is if or when it will do the same or close on Intel integrated graphics..\\nIt seems intel is persisting in crippling its mobile platforms to low bandwidth,  2 memory channels, and everything that makes it slow to run llm..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjtsfal/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742994494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjtsv1b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"goingsplit","can_mod_post":false,"created_utc":1742994653,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_avw6ghg9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I lately practically stopped using chatgpt, it seems it performs worse than before, definitely worst of the deepseek grok claude bunch","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjtsv1b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I lately practically stopped using chatgpt, it seems it performs worse than before, definitely worst of the deepseek grok claude bunch&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjtsv1b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742994653,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjvmhio","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"qu4rk3","can_mod_post":false,"created_utc":1743014321,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_1lixh26qnv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why is the android app says internet search has technical difficulties ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjvmhio","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why is the android app says internet search has technical difficulties ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjvmhio/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743014321,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjm0fkc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"putrasherni","can_mod_post":false,"created_utc":1742881315,"send_replies":true,"parent_id":"t3_1jj6i4m","score":1,"author_fullname":"t2_14cwky","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what configuration , definitely not 128GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjm0fkc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what configuration , definitely not 128GB&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjm0fkc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742881315,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":0,"removal_reason":null,"link_id":"t3_1jj6i4m","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjqpi3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HatZinn","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjmvmb5","score":1,"author_fullname":"t2_d48zfy2x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wonder how the new V3 will perform once they merge it with the R1 reasoner.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjqpi3g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder how the new V3 will perform once they merge it with the R1 reasoner.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjqpi3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742943804,"author_flair_text":null,"treatment_tags":[],"created_utc":1742943804,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmvmb5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"R_Duncan","can_mod_post":false,"created_utc":1742900982,"send_replies":true,"parent_id":"t1_mjmkqex","score":6,"author_fullname":"t2_3xd4mwvn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/lzq78d35jtqe1.png?width=759&amp;format=png&amp;auto=webp&amp;s=1f94ed9e5a7bd490fef24b02b3ca67cfe8cac5df\\n\\nIt's better than 3.5 for 1/12th of the price, of o3 mini (med) for 1/8th, still under quite more expensive models, but definitely best bang for your bucks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmvmb5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/lzq78d35jtqe1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f94ed9e5a7bd490fef24b02b3ca67cfe8cac5df\\"&gt;https://preview.redd.it/lzq78d35jtqe1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f94ed9e5a7bd490fef24b02b3ca67cfe8cac5df&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s better than 3.5 for 1/12th of the price, of o3 mini (med) for 1/8th, still under quite more expensive models, but definitely best bang for your bucks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmvmb5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742900982,"media_metadata":{"lzq78d35jtqe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":123,"x":108,"u":"https://preview.redd.it/lzq78d35jtqe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8b2a759438d93e97383a5fe5dd54258cab9ec8d"},{"y":246,"x":216,"u":"https://preview.redd.it/lzq78d35jtqe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d705005e4f5233f8ee15da57bd671459bf8816e"},{"y":365,"x":320,"u":"https://preview.redd.it/lzq78d35jtqe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=61dfd6f0623dd166673d743e22207109ea4abb55"},{"y":730,"x":640,"u":"https://preview.redd.it/lzq78d35jtqe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16ad4b4651c7aec2b7e9077ebcbb49a8c856015c"}],"s":{"y":866,"x":759,"u":"https://preview.redd.it/lzq78d35jtqe1.png?width=759&amp;format=png&amp;auto=webp&amp;s=1f94ed9e5a7bd490fef24b02b3ca67cfe8cac5df"},"id":"lzq78d35jtqe1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjmkqex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jj6i4m","score":0,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmkqex/","num_reports":null,"locked":false,"name":"t1_mjmkqex","created":1742894643,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1742894643,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjmlfyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"psycholustmord","can_mod_post":false,"created_utc":1742895107,"send_replies":true,"parent_id":"t3_1jj6i4m","score":0,"author_fullname":"t2_dyjq7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"pp please","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjmlfyk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;pp please&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjmlfyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742895107,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjrvozc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Alice3173","can_mod_post":false,"created_utc":1742958219,"send_replies":true,"parent_id":"t1_mjn4lwr","score":2,"author_fullname":"t2_65kg3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Max token context history affects memory usage. For example, I'm messing with a local version of Gemma 3 with 12b parameters at the moment. When set to its max context history setting (131k tokens), it uses up almost 60gb of ram. With a context setting of 12k, it's only using up 12.5gb of memory instead.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjrvozc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Max token context history affects memory usage. For example, I&amp;#39;m messing with a local version of Gemma 3 with 12b parameters at the moment. When set to its max context history setting (131k tokens), it uses up almost 60gb of ram. With a context setting of 12k, it&amp;#39;s only using up 12.5gb of memory instead.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjrvozc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742958219,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mjn4lwr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Turbulent-Cupcake-66","can_mod_post":false,"created_utc":1742905063,"send_replies":true,"parent_id":"t3_1jj6i4m","score":0,"author_fullname":"t2_cictxfyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't deepseek a llm with only 36b parametrs to theoreticaly 48gb ram mac should run whole q4 model? Why you have houndreds of GB RAM used?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjn4lwr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t deepseek a llm with only 36b parametrs to theoreticaly 48gb ram mac should run whole q4 model? Why you have houndreds of GB RAM used?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjn4lwr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742905063,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjsaw78","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UnluckyGold13","can_mod_post":false,"created_utc":1742965062,"send_replies":true,"parent_id":"t3_1jj6i4m","score":0,"author_fullname":"t2_10pb3duzil","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Who gives a sh*t gemimi 2.5 just blew deep seek away!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjsaw78","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Who gives a sh*t gemimi 2.5 just blew deep seek away!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjsaw78/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742965062,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjl3mtz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sebastianmicu24","can_mod_post":false,"created_utc":1742866992,"send_replies":true,"parent_id":"t1_mjkv99a","score":17,"author_fullname":"t2_15qzm1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I like to imagine that this is Sam Altman faking to be a normal person","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjl3mtz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like to imagine that this is Sam Altman faking to be a normal person&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjl3mtz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742866992,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjlxl0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aimoony","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlqmyr","score":6,"author_fullname":"t2_qgjnhlpa9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Groupthink? Dude is making assertions after playing with OpenAI for a month? \\"Once \\\\[GPT 4.5\\\\] is tuned up to GPT 5 nothing will touch it\\". That doesnt even make sense as OpenAI said GPT 5 will likely just be better at using different models.\\n\\nI don't mind ignorance but pretending you have a clue when you're talking out of your ass is not a way to get a conversation going if you want the community to take you seriously.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlxl0a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Groupthink? Dude is making assertions after playing with OpenAI for a month? &amp;quot;Once [GPT 4.5] is tuned up to GPT 5 nothing will touch it&amp;quot;. That doesnt even make sense as OpenAI said GPT 5 will likely just be better at using different models.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t mind ignorance but pretending you have a clue when you&amp;#39;re talking out of your ass is not a way to get a conversation going if you want the community to take you seriously.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlxl0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742879694,"author_flair_text":null,"treatment_tags":[],"created_utc":1742879694,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlqmyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Application-2261","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjkyhjv","score":0,"author_fullname":"t2_3qmqtbmo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah yes, the timeless wisdom of Reddit elders: 'You have to hang around a while before sharing your nonsense opinions. Translation: Please marinate in our groupthink long enough to forget how to think for yourself. Nice one.\\n\\n\\"You might want to hang around for a while before sharing nonsense opinions\\" lmfao, what is this, Hogwarts? Do I need to complete some sacred Reddit pilgrimage before I’m allowed to say something you don’t agree with?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjlqmyr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah yes, the timeless wisdom of Reddit elders: &amp;#39;You have to hang around a while before sharing your nonsense opinions. Translation: Please marinate in our groupthink long enough to forget how to think for yourself. Nice one.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;You might want to hang around for a while before sharing nonsense opinions&amp;quot; lmfao, what is this, Hogwarts? Do I need to complete some sacred Reddit pilgrimage before I’m allowed to say something you don’t agree with?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlqmyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742876142,"author_flair_text":null,"treatment_tags":[],"created_utc":1742876142,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkyhjv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aimoony","can_mod_post":false,"created_utc":1742865179,"send_replies":true,"parent_id":"t1_mjkv99a","score":19,"author_fullname":"t2_qgjnhlpa9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ummm welcome to the world of LLM? You might want to hang around for a while before giving nonsensical opinions :P","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkyhjv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ummm welcome to the world of LLM? You might want to hang around for a while before giving nonsensical opinions :P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkyhjv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742865179,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjy9s31","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HauntingAd8395","can_mod_post":false,"send_replies":true,"parent_id":"t1_mjlycm8","score":1,"author_fullname":"t2_17khmwh2r0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Frfr, another the beauty of local LLM is that you can run it from day to night with all sorts of information that others reluctant to process;\\n\\nThat's 1.7 million tokens per day.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mjy9s31","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Frfr, another the beauty of local LLM is that you can run it from day to night with all sorts of information that others reluctant to process;&lt;/p&gt;\\n\\n&lt;p&gt;That&amp;#39;s 1.7 million tokens per day.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjy9s31/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743044448,"author_flair_text":null,"treatment_tags":[],"created_utc":1743044448,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mjlycm8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lmvg","can_mod_post":false,"created_utc":1742880127,"send_replies":true,"parent_id":"t1_mjkv99a","score":3,"author_fullname":"t2_g88zf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I think most people who can afford a PC that can run a local LLM can probably afford $20/month its not that bad\\n\\nThis is the beauty of local LLMs, they come in all shapes and sizes. Even in a toaster you can run one. $20 doesn't sound like much but considering the alternatives, if I used OpenAI's models I'd feel like I was throwing away my money. specially considering I can run Qwen 2.5 max, QwQ and DeepSeek V2 and R1 for free","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjlycm8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I think most people who can afford a PC that can run a local LLM can probably afford $20/month its not that bad&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;This is the beauty of local LLMs, they come in all shapes and sizes. Even in a toaster you can run one. $20 doesn&amp;#39;t sound like much but considering the alternatives, if I used OpenAI&amp;#39;s models I&amp;#39;d feel like I was throwing away my money. specially considering I can run Qwen 2.5 max, QwQ and DeepSeek V2 and R1 for free&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jj6i4m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjlycm8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742880127,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mjkv99a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Ok-Application-2261","can_mod_post":false,"created_utc":1742864051,"send_replies":true,"parent_id":"t3_1jj6i4m","score":-32,"author_fullname":"t2_3qmqtbmo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"I actually bought a 1 month membership on OpenAI. I have to say i think DeepSeek is over-rated. GPT 4o is funny and charming. I also tested GPT 4.5 a bit. Once that's been tuned up to GPT 5 nothing will touch it. OpenAI can also do deep-research which is absolutely incredible. I think most people who can afford a PC that can run a local LLM can probably afford $20/month its not that bad.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjkv99a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually bought a 1 month membership on OpenAI. I have to say i think DeepSeek is over-rated. GPT 4o is funny and charming. I also tested GPT 4.5 a bit. Once that&amp;#39;s been tuned up to GPT 5 nothing will touch it. OpenAI can also do deep-research which is absolutely incredible. I think most people who can afford a PC that can run a local LLM can probably afford $20/month its not that bad.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjkv99a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742864051,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mjp9wmk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"narrowbuys","can_mod_post":false,"created_utc":1742928370,"send_replies":true,"parent_id":"t3_1jj6i4m","score":-1,"author_fullname":"t2_a2jkl1aw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Don't really believe news reporters. M4 Mac studio does 4-7tokens/sec in the models I can load in 100gb of memory. That's not really the problem, it's the terrible chat UIs I find that cause me so many headaches.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mjp9wmk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t really believe news reporters. M4 Mac studio does 4-7tokens/sec in the models I can load in 100gb of memory. That&amp;#39;s not really the problem, it&amp;#39;s the terrible chat UIs I find that cause me so many headaches.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jj6i4m/deepseek_v3/mjp9wmk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742928370,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jj6i4m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
