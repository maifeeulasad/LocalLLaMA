import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I have been wondering this for a while now - why is nobody building custom instruct versions from public base models that don't include the typical sycophantic behavior of official releases where every dumb idea the user has is just SO insightful? The most I see is some RP specific tunes, but for more general purpose assistants there are slim pickings.\\n\\nAnd what about asking for just some formated JSON output and specifiying that you want nothing else? you do it and the model wafles on about \\"here is your data formated as JSON...\\". I just want some plain json that i can just parse, okay?\\n\\nIsn't what we really want a model that gives unbiased, straight to the point answers and can be steered to act how we want it to? maybe even with some special commands similar to how it works with qwen 3? i want some /no\\\\_fluff and some /no\\\\_bias please! Am i the only one here or are others also interested in such instruct tunes?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Why not build instruct models that give you straight answers with no positivity bias and no bs?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5pig4","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.27,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_3wi6j7vwh","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753119570,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been wondering this for a while now - why is nobody building custom instruct versions from public base models that don&amp;#39;t include the typical sycophantic behavior of official releases where every dumb idea the user has is just SO insightful? The most I see is some RP specific tunes, but for more general purpose assistants there are slim pickings.&lt;/p&gt;\\n\\n&lt;p&gt;And what about asking for just some formated JSON output and specifiying that you want nothing else? you do it and the model wafles on about &amp;quot;here is your data formated as JSON...&amp;quot;. I just want some plain json that i can just parse, okay?&lt;/p&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t what we really want a model that gives unbiased, straight to the point answers and can be steered to act how we want it to? maybe even with some special commands similar to how it works with qwen 3? i want some /no_fluff and some /no_bias please! Am i the only one here or are others also interested in such instruct tunes?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m5pig4","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"LagOps91","discussion_type":null,"num_comments":42,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/","subreddit_subscribers":502721,"created_utc":1753119570,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dxeyq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1753122714,"send_replies":true,"parent_id":"t1_n4dx0le","score":2,"author_fullname":"t2_1k4sjdwzk2","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;goon tunes\\n\\n\\nGooners will do anything. Sex is a powerful motivator. After all it's an instinct. I don't think such a thing exists for an unbiased LLM. ","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4dxeyq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;goon tunes&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Gooners will do anything. Sex is a powerful motivator. After all it&amp;#39;s an instinct. I don&amp;#39;t think such a thing exists for an unbiased LLM. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dxeyq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122714,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dx0le","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753122603,"send_replies":true,"parent_id":"t1_n4dvf70","score":1,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes, the initial dataset would cost quite a bit of money / effort. but somehow, at the same time, you see tons of \\"goon tunes\\", some made from just base models with custom instructs. you even see full GRPO deepseek style thinking tune for originally non-thinking models. you also see people throw a ton of money on inference rigs just to have huge models run locally.\\n\\nit's true that money is a barrier and not everyone has the ability to throw money at it, but quite clearly throwing money around isn't exactly rare in this community.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4dx0le","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, the initial dataset would cost quite a bit of money / effort. but somehow, at the same time, you see tons of &amp;quot;goon tunes&amp;quot;, some made from just base models with custom instructs. you even see full GRPO deepseek style thinking tune for originally non-thinking models. you also see people throw a ton of money on inference rigs just to have huge models run locally.&lt;/p&gt;\\n\\n&lt;p&gt;it&amp;#39;s true that money is a barrier and not everyone has the ability to throw money at it, but quite clearly throwing money around isn&amp;#39;t exactly rare in this community.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dx0le/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122603,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dvf70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4du843","score":1,"author_fullname":"t2_1k4sjdwzk2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;HF to put in the effort to make a dataset and then it should be relatively affordable to tune a model\\n\\n\\nThis takes a lot of money, idk how much. 1000 dollars? 10,000? Maybe 50,000? How will you make it come true? If no one has done it for free on HF, it's because people expect money to do it. There are companies specialized in doing this such as Scale AI aka Outlier AI, and Accenture. ","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4dvf70","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;HF to put in the effort to make a dataset and then it should be relatively affordable to tune a model&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;This takes a lot of money, idk how much. 1000 dollars? 10,000? Maybe 50,000? How will you make it come true? If no one has done it for free on HF, it&amp;#39;s because people expect money to do it. There are companies specialized in doing this such as Scale AI aka Outlier AI, and Accenture. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dvf70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122154,"author_flair_text":null,"treatment_tags":[],"created_utc":1753122154,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4du843","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dsfek","score":1,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"is investment really needed? we are not talking about making models from scratch. merely about datasets to instruct tune models, that should be much more managable! i'm not asking to make a startup or anything, you just need some folks on HF to put in the effort to make a dataset and then it should be relatively affordable to tune a model on it.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4du843","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;is investment really needed? we are not talking about making models from scratch. merely about datasets to instruct tune models, that should be much more managable! i&amp;#39;m not asking to make a startup or anything, you just need some folks on HF to put in the effort to make a dataset and then it should be relatively affordable to tune a model on it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4du843/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121818,"author_flair_text":null,"treatment_tags":[],"created_utc":1753121818,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dsfek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dqva8","score":0,"author_fullname":"t2_1k4sjdwzk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;what stops us from trying to make as unbiased and un-fluffed instruct dataset \\n\\n\\nMoney. It's always money. You live in a developing country do you? I do too, good luck getting any investors interested in \\"unbiased\\" AI. People love the positive bias AI has even if they don't know about it. ","edited":1753121892,"author_flair_css_class":null,"name":"t1_n4dsfek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;what stops us from trying to make as unbiased and un-fluffed instruct dataset &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Money. It&amp;#39;s always money. You live in a developing country do you? I do too, good luck getting any investors interested in &amp;quot;unbiased&amp;quot; AI. People love the positive bias AI has even if they don&amp;#39;t know about it. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dsfek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121314,"author_flair_text":null,"collapsed":false,"created_utc":1753121314,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dqva8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dq4kd","score":2,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yes that's true, but with open weights / open source, we don't have to abide with that, do we? what stops us from trying to make as unbiased and un-fluffed instruct dataset that helps the models do what is asked for and nothing more?\\n\\nit's true that perfectly unbiased isn't a thing we can achieve, but getting close should be quite possible and, imo, worthwhile.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dqva8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes that&amp;#39;s true, but with open weights / open source, we don&amp;#39;t have to abide with that, do we? what stops us from trying to make as unbiased and un-fluffed instruct dataset that helps the models do what is asked for and nothing more?&lt;/p&gt;\\n\\n&lt;p&gt;it&amp;#39;s true that perfectly unbiased isn&amp;#39;t a thing we can achieve, but getting close should be quite possible and, imo, worthwhile.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dqva8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120877,"author_flair_text":null,"treatment_tags":[],"created_utc":1753120877,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dq4kd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dodsl","score":1,"author_fullname":"t2_1k4sjdwzk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;i am quite sure that current models are intentionally being biased\\n\\n\\nWell yes, because it's what sells, specially in developing countries where ai is the only useful way to get information from the internet ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dq4kd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;i am quite sure that current models are intentionally being biased&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Well yes, because it&amp;#39;s what sells, specially in developing countries where ai is the only useful way to get information from the internet &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dq4kd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120675,"author_flair_text":null,"treatment_tags":[],"created_utc":1753120675,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dodsl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753120203,"send_replies":true,"parent_id":"t1_n4dnct2","score":3,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i think it's far less subjective than it's made out to be. positivity-bias is very apparent in all major models. and no bias could also mean to just train the model's instruct tuning on datasets that don't touch controversial topics and then just see how the model generalizes to those areas.\\n\\ni am quite sure that current models are intentionally being biased, especially towards overly positive responses and that could be something that's easily fixed with a custom instruct training.\\n\\nin terms of making it as transparent and unbiased as possible, the datasets for instruct tuning could be made public, so you can check for bias yourself (well at least give it a coursory glance, it would likely be a large dataset in the end.)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dodsl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i think it&amp;#39;s far less subjective than it&amp;#39;s made out to be. positivity-bias is very apparent in all major models. and no bias could also mean to just train the model&amp;#39;s instruct tuning on datasets that don&amp;#39;t touch controversial topics and then just see how the model generalizes to those areas.&lt;/p&gt;\\n\\n&lt;p&gt;i am quite sure that current models are intentionally being biased, especially towards overly positive responses and that could be something that&amp;#39;s easily fixed with a custom instruct training.&lt;/p&gt;\\n\\n&lt;p&gt;in terms of making it as transparent and unbiased as possible, the datasets for instruct tuning could be made public, so you can check for bias yourself (well at least give it a coursory glance, it would likely be a large dataset in the end.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dodsl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4doqbb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753120297,"send_replies":true,"parent_id":"t1_n4dnct2","score":3,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"in terms of making the AI more transparent to how arrived at answers... i don't think that works. research has already shown that answers by the ai in this regard don't align with it's actual internal thinking process.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4doqbb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;in terms of making the AI more transparent to how arrived at answers... i don&amp;#39;t think that works. research has already shown that answers by the ai in this regard don&amp;#39;t align with it&amp;#39;s actual internal thinking process.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4doqbb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120297,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4du98d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"created_utc":1753121827,"send_replies":true,"parent_id":"t1_n4dnct2","score":1,"author_fullname":"t2_1tpuoj72sa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nope, IMHO, positivity is not that subjective at all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4du98d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope, IMHO, positivity is not that subjective at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4du98d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121827,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dnct2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1753119924,"send_replies":true,"parent_id":"t3_1m5pig4","score":6,"author_fullname":"t2_1k4sjdwzk2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;straight answers with no positivity bias and no bs?\\n\\n\\nBecause this is highly subjective. What could be done is create an AI that is highly transparent on how it arrives to every single answer","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dnct2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;straight answers with no positivity bias and no bs?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Because this is highly subjective. What could be done is create an AI that is highly transparent on how it arrives to every single answer&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dnct2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119924,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ds3d8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753121220,"send_replies":true,"parent_id":"t1_n4drbya","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it's true that you could do that. personally i don't have the skills, nor the dataset required for such a finetune (in addition to money). i did see some RP focussed tunes for base models however and have been wondering why nobody did what i suggested yet (as far as i'm aware of).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ds3d8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s true that you could do that. personally i don&amp;#39;t have the skills, nor the dataset required for such a finetune (in addition to money). i did see some RP focussed tunes for base models however and have been wondering why nobody did what i suggested yet (as far as i&amp;#39;m aware of).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4ds3d8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4drbya","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1753121007,"send_replies":true,"parent_id":"t3_1m5pig4","score":3,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's nothing stopping you, have fun.\\n\\nDoing a full parameter fine tune for instruct tuning is probably something like $1,000 to $10,000 depending on the model size, as per information in the Tulu papers.\\n\\nIt's possible with modern PEFT methods it might be possible to bring that down somewhat.\\n\\nOnce you have an instruct model, you can then do a specialized RL run for your specific areas of performance you're concerned about (you could run the inference rollout on CPU; the actual weight updates are quite cheap relatively. The CPU rollout will take you about a month and a half), and you won't know if you've gotten it right until you test it on a wide variety of relevant tasks to your needs, or you set up an automated test harness.\\n\\nAdditionally, there's no guarantee you'll match the performance of existing instruction tunes, so you may be taking a hit to performance comparatively.\\n\\n...Oooooooooor, you could just use existing instruct-tune and give them an appropriate system prompt. DSPy can help you automate this (the example you gave going for JSON is a pretty easy example because if the model delivers anything outside the JSON that's verifiable. You can also provide a penalty if the JSON can't parse correctly).\\n\\nMost instruct models are capable of behaving mostly however you want them to and there's a lot of ways of framing the issue such that they give you a plain and unembelished output.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4drbya","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s nothing stopping you, have fun.&lt;/p&gt;\\n\\n&lt;p&gt;Doing a full parameter fine tune for instruct tuning is probably something like $1,000 to $10,000 depending on the model size, as per information in the Tulu papers.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s possible with modern PEFT methods it might be possible to bring that down somewhat.&lt;/p&gt;\\n\\n&lt;p&gt;Once you have an instruct model, you can then do a specialized RL run for your specific areas of performance you&amp;#39;re concerned about (you could run the inference rollout on CPU; the actual weight updates are quite cheap relatively. The CPU rollout will take you about a month and a half), and you won&amp;#39;t know if you&amp;#39;ve gotten it right until you test it on a wide variety of relevant tasks to your needs, or you set up an automated test harness.&lt;/p&gt;\\n\\n&lt;p&gt;Additionally, there&amp;#39;s no guarantee you&amp;#39;ll match the performance of existing instruction tunes, so you may be taking a hit to performance comparatively.&lt;/p&gt;\\n\\n&lt;p&gt;...Oooooooooor, you could just use existing instruct-tune and give them an appropriate system prompt. DSPy can help you automate this (the example you gave going for JSON is a pretty easy example because if the model delivers anything outside the JSON that&amp;#39;s verifiable. You can also provide a penalty if the JSON can&amp;#39;t parse correctly).&lt;/p&gt;\\n\\n&lt;p&gt;Most instruct models are capable of behaving mostly however you want them to and there&amp;#39;s a lot of ways of framing the issue such that they give you a plain and unembelished output.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4drbya/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121007,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_n4ejmjl","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ejmjl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753129028,"send_replies":true,"parent_id":"t1_n4eimnw","score":0,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yes and no. the model already knows the correct response, but it's just trained to complete text before instruct tuning. at that point, it doesn't care about providing a correct response or not. all it does is provide a plausible completion.  \\n  \\nif you train the model to give correct answers, it can generalize that to questions it hasn't been asked before.\\n\\nwhat you reward it for in this process, is important! if you reward agreeableness, it will be more agreeable. if you reward more positive responses, it will be more positive.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ejmjl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes and no. the model already knows the correct response, but it&amp;#39;s just trained to complete text before instruct tuning. at that point, it doesn&amp;#39;t care about providing a correct response or not. all it does is provide a plausible completion.  &lt;/p&gt;\\n\\n&lt;p&gt;if you train the model to give correct answers, it can generalize that to questions it hasn&amp;#39;t been asked before.&lt;/p&gt;\\n\\n&lt;p&gt;what you reward it for in this process, is important! if you reward agreeableness, it will be more agreeable. if you reward more positive responses, it will be more positive.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4ejmjl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753129028,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eimnw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"created_utc":1753128747,"send_replies":true,"parent_id":"t1_n4eft5z","score":1,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"body":"it pretty much answered all your questions there\\n\\nwhen you train a model you need to give it material that has the correct answer, so its been trained on having question/answer pairs for example. the model doesn't inherently know that this was a correct answer, it just knows when this question or similar come up i need to provide this response\\n\\nas you can see from your results there is more research happening to mitigate the agreeableness that comes as an after effect of that","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4eimnw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it pretty much answered all your questions there&lt;/p&gt;\\n\\n&lt;p&gt;when you train a model you need to give it material that has the correct answer, so its been trained on having question/answer pairs for example. the model doesn&amp;#39;t inherently know that this was a correct answer, it just knows when this question or similar come up i need to provide this response&lt;/p&gt;\\n\\n&lt;p&gt;as you can see from your results there is more research happening to mitigate the agreeableness that comes as an after effect of that&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4eimnw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753128747,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eft5z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753127944,"send_replies":true,"parent_id":"t1_n4ec1oo","score":1,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"no, this also happens if the model knows the correct answer and sometimes even if the correct answer is provided earlier in the context.\\n\\ni have had it happen to me several times where the model agreed with me, even when it turned out i was wrong. that was despite using web-search and having the correct answer in context.\\n\\ni don't have a good example ready for you, but i did some admittedly surface-level search with chatgpt. have a look if you are interested: [https://chatgpt.com/share/687e9b3a-fe90-8010-bf3b-fb63d7950690](https://chatgpt.com/share/687e9b3a-fe90-8010-bf3b-fb63d7950690)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4eft5z","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, this also happens if the model knows the correct answer and sometimes even if the correct answer is provided earlier in the context.&lt;/p&gt;\\n\\n&lt;p&gt;i have had it happen to me several times where the model agreed with me, even when it turned out i was wrong. that was despite using web-search and having the correct answer in context.&lt;/p&gt;\\n\\n&lt;p&gt;i don&amp;#39;t have a good example ready for you, but i did some admittedly surface-level search with chatgpt. have a look if you are interested: &lt;a href=\\"https://chatgpt.com/share/687e9b3a-fe90-8010-bf3b-fb63d7950690\\"&gt;https://chatgpt.com/share/687e9b3a-fe90-8010-bf3b-fb63d7950690&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4eft5z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127944,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ec1oo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4e8klf","score":1,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; asking leading questions \\"X is correct, right?\\" and having the model agree, even if X is obviously wrong.\\n\\nthat will happen if the model **doesn't** know the correct answer. if they know the correct answer they will stick to it.\\n\\n&gt;tell a model to be objective\\n\\nobjective isn't a thing a model can be, you can't be objective even if you think you are.\\n\\nDo you have an example of this?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4ec1oo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;asking leading questions &amp;quot;X is correct, right?&amp;quot; and having the model agree, even if X is obviously wrong.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;that will happen if the model &lt;strong&gt;doesn&amp;#39;t&lt;/strong&gt; know the correct answer. if they know the correct answer they will stick to it.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;tell a model to be objective&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;objective isn&amp;#39;t a thing a model can be, you can&amp;#39;t be objective even if you think you are.&lt;/p&gt;\\n\\n&lt;p&gt;Do you have an example of this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4ec1oo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753126877,"author_flair_text":null,"treatment_tags":[],"created_utc":1753126877,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4e8klf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4e5pfb","score":1,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"biased basically means that the model has learned a default mode of interaction where it leans towards certain behaviors, such as being overly agreeable.\\n\\na common example is asking leading questions \\"X is correct, right?\\" and having the model agree, even if X is obviously wrong.\\n\\neven if you tell a model to be objective and not agreeable, it will still tend to exhibit such behavior more often than compared to a model that has been instruct-trained on data with less positivity bias / agreeablenes.\\n\\neffectively, i want to have a model that does what it's told and remains objective as much as could be expected of a model. i want the model to correct me if i'm wrong and give me the true answer instead of the model giving me responses that conform to my biases.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4e8klf","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;biased basically means that the model has learned a default mode of interaction where it leans towards certain behaviors, such as being overly agreeable.&lt;/p&gt;\\n\\n&lt;p&gt;a common example is asking leading questions &amp;quot;X is correct, right?&amp;quot; and having the model agree, even if X is obviously wrong.&lt;/p&gt;\\n\\n&lt;p&gt;even if you tell a model to be objective and not agreeable, it will still tend to exhibit such behavior more often than compared to a model that has been instruct-trained on data with less positivity bias / agreeablenes.&lt;/p&gt;\\n\\n&lt;p&gt;effectively, i want to have a model that does what it&amp;#39;s told and remains objective as much as could be expected of a model. i want the model to correct me if i&amp;#39;m wrong and give me the true answer instead of the model giving me responses that conform to my biases.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e8klf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753125872,"author_flair_text":null,"treatment_tags":[],"created_utc":1753125872,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4e5pfb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4e44qj","score":1,"author_fullname":"t2_1gew47j6vy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you’re confusing a couple things.\\n\\nIf you put in the system prompt of a model to respond with the answer only and nothing else if it’s a python code request for example, they will absolutely adhere to that 100%\\n\\nIf you tell it to ask clarifying question it will. I don’t understand exactly what you mean by biased unbiased","edited":false,"author_flair_css_class":null,"name":"t1_n4e5pfb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you’re confusing a couple things.&lt;/p&gt;\\n\\n&lt;p&gt;If you put in the system prompt of a model to respond with the answer only and nothing else if it’s a python code request for example, they will absolutely adhere to that 100%&lt;/p&gt;\\n\\n&lt;p&gt;If you tell it to ask clarifying question it will. I don’t understand exactly what you mean by biased unbiased&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e5pfb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753125058,"author_flair_text":null,"collapsed":false,"created_utc":1753125058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4e44qj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4e2v4k","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i don't think most models properly abide by this. overly positive models are still overly positive, even when you tell them not to be. it helps to some degree, but the models just aren't great at being unbiased if their default mode is to be biased.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e44qj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i don&amp;#39;t think most models properly abide by this. overly positive models are still overly positive, even when you tell them not to be. it helps to some degree, but the models just aren&amp;#39;t great at being unbiased if their default mode is to be biased.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e44qj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753124615,"author_flair_text":null,"treatment_tags":[],"created_utc":1753124615,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4e2v4k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dneb5","score":1,"author_fullname":"t2_1gew47j6vy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s what I explained on the second point. You can train a model to only respond in a certain tone but why would anyone spend time doing that when you can do that with a simple system prompt?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4e2v4k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s what I explained on the second point. You can train a model to only respond in a certain tone but why would anyone spend time doing that when you can do that with a simple system prompt?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e2v4k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753124255,"author_flair_text":null,"treatment_tags":[],"created_utc":1753124255,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dneb5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753119935,"send_replies":true,"parent_id":"t1_n4dmocu","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i'm not sure what you mean - you can train a base model to align with your prefrences, right? this isn't about a model not knowing what is right, this is about models being trained to be overly positive and being unable to give a straight answers.\\n\\neffectively, you would just need a dataset for instruct tuning with to the point and accurate assistant responses so you can train the model to respond in the same tone, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dneb5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m not sure what you mean - you can train a base model to align with your prefrences, right? this isn&amp;#39;t about a model not knowing what is right, this is about models being trained to be overly positive and being unable to give a straight answers.&lt;/p&gt;\\n\\n&lt;p&gt;effectively, you would just need a dataset for instruct tuning with to the point and accurate assistant responses so you can train the model to respond in the same tone, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dneb5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119935,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dmocu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"created_utc":1753119741,"send_replies":true,"parent_id":"t3_1m5pig4","score":2,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1. The model doesn’t know what is right \\n\\n2. the models are general purpose. You can use models that for example only transform text from images to json and can’t chat","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dmocu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;The model doesn’t know what is right &lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;the models are general purpose. You can use models that for example only transform text from images to json and can’t chat&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dmocu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119741,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4e4fb9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753124699,"send_replies":true,"parent_id":"t1_n4e3yqu","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it does work to some extent, but it's not really a great solution in my book. the model default still shines through more often than not.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e4fb9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it does work to some extent, but it&amp;#39;s not really a great solution in my book. the model default still shines through more often than not.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e4fb9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753124699,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4e3yqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"itroot","can_mod_post":false,"created_utc":1753124568,"send_replies":true,"parent_id":"t3_1m5pig4","score":2,"author_fullname":"t2_59hyp5s9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The datasets are rotten with bias =) . But you can ask model to be brief/concise/don't ramble. And it should do the trick.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e3yqu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The datasets are rotten with bias =) . But you can ask model to be brief/concise/don&amp;#39;t ramble. And it should do the trick.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4e3yqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753124568,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1m5pig4","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dtqzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RhubarbSimilar1683","can_mod_post":false,"created_utc":1753121685,"send_replies":true,"parent_id":"t1_n4dnooz","score":1,"author_fullname":"t2_1k4sjdwzk2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"One of the reasons why AI is so \\"revolutionary\\" is because search results are useless in developing countries so AI gives you US-based, English data and translates it in real time, ignoring algorithms such as Google's Pigeon algorithm. ","edited":1753122508,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dtqzs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One of the reasons why AI is so &amp;quot;revolutionary&amp;quot; is because search results are useless in developing countries so AI gives you US-based, English data and translates it in real time, ignoring algorithms such as Google&amp;#39;s Pigeon algorithm. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dtqzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121685,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dnooz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1m5pig4","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dnooz/","num_reports":null,"locked":false,"name":"t1_n4dnooz","created":1753120014,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1753120014,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"body":"From what I understand about instruct models ... they are more rigid and act more like a database of weighted values and less accurate if they don't have everything defined I could be wrong. But that is just what they seem like\\n\\nTesting them in the wild the certainly are faster than Thinking models, because the lack of thinking time. They do however get tripped up very easy. Something Thinking models seem to have a lot less of.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Yes this is the way I have understood it.\\n\\nI will say a model designed to fill out paper work is interesting, however it might be better served with a simple algorithm. I think some times people forget we have used Simple if then or else statements to make software that works great at fill out paper work for decades now. \\n\\nThey are very resource efficient compared to an AI and really not to hard to make. In fact an AI might actually be better served to write the program to make the software to fill out the Paperwork.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"that is totally on me I thought you said complete text forms.\\n\\nEDIT: But what you said was: \\n\\n&gt;which just knows how to complete text","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I understand, I just simply misread what you wrote. \\n\\nAnd that is why I was like man a static program could totally handle that... And for sure A program would he a better way to understand and fill out paperwork... As long as it had it defined.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dtp80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dsigo","score":1,"author_fullname":"t2_zq180","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4dtp80","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I understand, I just simply misread what you wrote. &lt;/p&gt;\\n\\n&lt;p&gt;And that is why I was like man a static program could totally handle that... And for sure A program would he a better way to understand and fill out paperwork... As long as it had it defined.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dtp80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121671,"author_flair_text":null,"treatment_tags":[],"created_utc":1753121671,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dsigo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ds5lo","score":1,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"it was just one example - if you want a model to extract some information from a document and return let's say JSON only, the current models often don't really do it, but add additional text to the output, which is unwanted. i just intended that to be a simple example of whre i feel most models fall short.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4dsigo","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it was just one example - if you want a model to extract some information from a document and return let&amp;#39;s say JSON only, the current models often don&amp;#39;t really do it, but add additional text to the output, which is unwanted. i just intended that to be a simple example of whre i feel most models fall short.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dsigo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121338,"author_flair_text":null,"treatment_tags":[],"created_utc":1753121338,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ds5lo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4drj3d","score":1,"author_fullname":"t2_zq180","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"author_flair_css_class":null,"name":"t1_n4ds5lo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that is totally on me I thought you said complete text forms.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: But what you said was: &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;which just knows how to complete text&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5pig4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4ds5lo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121237,"author_flair_text":null,"collapsed":false,"created_utc":1753121237,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4drj3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dqwcq","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i'm not sure what you mean in regards to making models fill out paperwork? i would want a fully capable, general ai assistant model, but one which doesn't suffer from the typical positivity bias and can be brief with no fluff if prompted for that. you could use this model for all the same tasks covered by propriatary models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4drj3d","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m not sure what you mean in regards to making models fill out paperwork? i would want a fully capable, general ai assistant model, but one which doesn&amp;#39;t suffer from the typical positivity bias and can be brief with no fluff if prompted for that. you could use this model for all the same tasks covered by propriatary models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4drj3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121063,"author_flair_text":null,"treatment_tags":[],"created_utc":1753121063,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dqwcq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dpivt","score":1,"author_fullname":"t2_zq180","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dqwcq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes this is the way I have understood it.&lt;/p&gt;\\n\\n&lt;p&gt;I will say a model designed to fill out paper work is interesting, however it might be better served with a simple algorithm. I think some times people forget we have used Simple if then or else statements to make software that works great at fill out paper work for decades now. &lt;/p&gt;\\n\\n&lt;p&gt;They are very resource efficient compared to an AI and really not to hard to make. In fact an AI might actually be better served to write the program to make the software to fill out the Paperwork.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dqwcq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120885,"author_flair_text":null,"treatment_tags":[],"created_utc":1753120885,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dpivt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753120513,"send_replies":true,"parent_id":"t1_n4dnx9a","score":1,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh this isn't quite what i meant. this isn't about thinking vs non-thinking.\\n\\nit's more about getting a model that can act as an assistant from a base model, which just knows how to complete text, but doesn't understand chat scenarios.\\n\\nthis assistant model could be thinking or non-thinking. instruct just used to mean that the model knows how to follow instructions, but i suppose with all the thinking models the meaning has shifted to mean a non-thinking model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dpivt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh this isn&amp;#39;t quite what i meant. this isn&amp;#39;t about thinking vs non-thinking.&lt;/p&gt;\\n\\n&lt;p&gt;it&amp;#39;s more about getting a model that can act as an assistant from a base model, which just knows how to complete text, but doesn&amp;#39;t understand chat scenarios.&lt;/p&gt;\\n\\n&lt;p&gt;this assistant model could be thinking or non-thinking. instruct just used to mean that the model knows how to follow instructions, but i suppose with all the thinking models the meaning has shifted to mean a non-thinking model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5pig4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dpivt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120513,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dnx9a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"created_utc":1753120078,"send_replies":true,"parent_id":"t3_1m5pig4","score":1,"author_fullname":"t2_zq180","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dnx9a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From what I understand about instruct models ... they are more rigid and act more like a database of weighted values and less accurate if they don&amp;#39;t have everything defined I could be wrong. But that is just what they seem like&lt;/p&gt;\\n\\n&lt;p&gt;Testing them in the wild the certainly are faster than Thinking models, because the lack of thinking time. They do however get tripped up very easy. Something Thinking models seem to have a lot less of.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dnx9a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753120078,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fr1ng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Scott_Tx","can_mod_post":false,"created_utc":1753142618,"send_replies":true,"parent_id":"t3_1m5pig4","score":1,"author_fullname":"t2_l07bb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just feed the large model's answer into a smaller model to summarize it 😛","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fr1ng","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just feed the large model&amp;#39;s answer into a smaller model to summarize it 😛&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4fr1ng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753142618,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fy3lk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xchaos4ux","can_mod_post":false,"created_utc":1753145070,"send_replies":true,"parent_id":"t3_1m5pig4","score":1,"author_fullname":"t2_qys5z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is not how they are trained.  they relied on datasets in such numbers that its nearly impossible to comprehend to train these ai.  meaning they needed material.  and where else to get the source of this material in the numbers they needed ?.  the internet forums.  where they found the wealth of resources needed to train the language models on how to string sentences together into something comprehensible. \\n\\n  \\nunfortunately a side effect of this is that as you know internet forums are full of bias.  and naturally polarizes the model as certain words are often seen with one another often enough to create the bias.  not that the model is biased. it has no fraking idea.  just that word A will most likely be seen with word B and that it fits in the grammatical syntax that was defined. .\\n\\n  \\nunfortunately the task to create a unbiased pure factual model with no bias would take quite the herculean task.  and untelling how many people scanning in magazines, books, encyclopedias, and papers. that have all been curated in an acceptable fashion  to create such a model.  and even then depending on world view.  it still would fail at being unbiased.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fy3lk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is not how they are trained.  they relied on datasets in such numbers that its nearly impossible to comprehend to train these ai.  meaning they needed material.  and where else to get the source of this material in the numbers they needed ?.  the internet forums.  where they found the wealth of resources needed to train the language models on how to string sentences together into something comprehensible. &lt;/p&gt;\\n\\n&lt;p&gt;unfortunately a side effect of this is that as you know internet forums are full of bias.  and naturally polarizes the model as certain words are often seen with one another often enough to create the bias.  not that the model is biased. it has no fraking idea.  just that word A will most likely be seen with word B and that it fits in the grammatical syntax that was defined. .&lt;/p&gt;\\n\\n&lt;p&gt;unfortunately the task to create a unbiased pure factual model with no bias would take quite the herculean task.  and untelling how many people scanning in magazines, books, encyclopedias, and papers. that have all been curated in an acceptable fashion  to create such a model.  and even then depending on world view.  it still would fail at being unbiased.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4fy3lk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753145070,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dufa6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"created_utc":1753121874,"send_replies":true,"parent_id":"t3_1m5pig4","score":1,"author_fullname":"t2_1tpuoj72sa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, that is the way!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dufa6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, that is the way!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5pig4/why_not_build_instruct_models_that_give_you/n4dufa6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121874,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5pig4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
