import{j as t}from"./index-CWmJdUH_.js";import{R as e}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"HI there guys, hoping you're doing fine.\\n\\nAs always related to PPL benchmarks, take them with a grain of salt as it may not represent the quality of the model itself, but it may help as a guide at how much a model could get affected by quantization.\\n\\nAs it has been mentioned sometimes, and a bit of spoiler, quantization on DeepSeek models is pretty impressive, because either quantization methods nowadays are really good and/or DeepSeek being natively FP8, it changes the paradigm a bit.\\n\\nAlso many thanks to ubergarm (u/VoidAlchemy) for his data on his quants and Q8\\\\_0/FP8 baseline!\\n\\nFor the quants that aren't from him, I did run them with the same command he did, with wiki.text.raw:\\n\\n    ./llama-perplexity -m 'model_name.gguf' \\\\\\n    -c 512 --no-mmap -ngl 999 \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA0\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA1\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA2\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA3\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA4\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA5\\" \\\\\\n    -ot \\"blk.(layers_depending_on_model).ffn.=CUDA6\\" \\\\\\n    -ot exps=CPU \\\\\\n    -fa -mg 0 -mla 3 -amb 256 -fmoe \\\\\\n    -f wiki.test.raw\\n\\n\\\\--------------------------\\n\\nFor baselines, we have this data:\\n\\n* DeepSeek R1 0528 Q8: 3.2119\\n* DeepSeek V3 0324 Q8 and q8\\\\_cache (important\\\\*): 3.2454\\n* DeepSeek V3 0324 Q8 and F16 cache extrapolated\\\\*: 3.2443\\n\\n\\\\*Based on [https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/discussions/2#686fdceb17516435632a4241](https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/discussions/2#686fdceb17516435632a4241), on R1 0528 at Q8\\\\_0, the difference between F16 and Q8\\\\_0 cache is:\\n\\n* \`-ctk fp16\` \`3.2119 +/- 0.01697\`\\n* \`-ctk q8_0\` \`3.2130 +/- 0.01698\`\\n\\nSo then, F16 cache is 0.03% better than Q8\\\\_0 for this model. Extrapolating that to V3, then V3 0324 Q8 at F16 should have 3.2443 PPL.\\n\\nQuants tested for R1 0528:\\n\\n* IQ1\\\\_S\\\\_R4 (ubergarm)\\n* UD-TQ1\\\\_0\\n* IQ2\\\\_KT (ubergarm)\\n* IQ2\\\\_K\\\\_R4 (ubergarm)\\n* Q2\\\\_K\\\\_XL\\n* IQ3\\\\_XXS\\n* IQ3\\\\_KS (ubergarm, my bad here as I named it IQ3\\\\_KT)\\n* Q3\\\\_K\\\\_XL\\n* IQ3\\\\_K\\\\_R4 (ubergarm)\\n* IQ4\\\\_XS\\n* q4\\\\_0 (pure)\\n* IQ4\\\\_KS\\\\_R4 (ubergarm)\\n* Q8\\\\_0 (ubergarm)\\n\\nQuants tested for V3 0324:\\n\\n* Q1\\\\_S\\\\_R4 (ubergarm)\\n* IQ2\\\\_K\\\\_R4 (ubergarm)\\n* Q2\\\\_K\\\\_XL\\n* IQ3\\\\_XXS\\n* Q3\\\\_K\\\\_XL\\n* IQ3\\\\_K\\\\_R4 (ubergarm)\\n* IQ3\\\\_K\\\\_R4\\\\_Pure (ubergarm)\\n* IQ4\\\\_XS\\n* IQ4\\\\_K\\\\_R4 (ubergarm)\\n* Q8\\\\_0 (ubergarm)\\n\\nSo here we go:\\n\\n# DeepSeek R1 0528\\n\\n[R1 0528 comparison \\\\(IQ3\\\\_KT is IQ3\\\\_KS, my bad\\\\)](https://preview.redd.it/ioqbx5iv0pcf1.png?width=4135&amp;format=png&amp;auto=webp&amp;s=4f1a3feb6e2143aaa739d1c4d61d45df80494abb)\\n\\nAs can you see, near 3.3bpw and above it gets quite good!. So now using different baselines to compare, using 100% for Q2\\\\_K\\\\_XL, Q3\\\\_K\\\\_XL, IQ4\\\\_XS and Q8\\\\_0.\\n\\n[R1 0528 Q2\\\\_K\\\\_XL](https://preview.redd.it/tfu0yvn21pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=f2b75d15eecfd49481db1a066b04fb57f5ac3542)\\n\\n[R1 0528 Q3\\\\_K\\\\_XL](https://preview.redd.it/i5tb2cx41pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=02a12f2c12b6ef657397b60fc8e87d022bc6c5b0)\\n\\n[R1 0528 IQ4\\\\_XS](https://preview.redd.it/8oart9461pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=1723d977f7c034496eb7a95bed576b6b53572542)\\n\\n[R1 0528 Q8\\\\_0](https://preview.redd.it/dszt1qw71pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=a77fc375c2e197346034a962fdff96ddea5ac49a)\\n\\nSo with a table format, it looks like this (ordered by best to worse PPL)\\n\\n|Model|Size (GB)|BPW|PPL|\\n|:-|:-|:-|:-|\\n|Q8\\\\_0|665.3|8.000|3.2119|\\n|IQ4\\\\_KS\\\\_R4|367.8|4.701|3.2286|\\n|IQ4\\\\_XS|333.1|4.260|3.2598|\\n|q4\\\\_0|352.6|4.508|3.2895|\\n|IQ3\\\\_K\\\\_R4|300.9|3.847|3.2730|\\n|IQ3\\\\_KT|272.5|3.483|3.3056|\\n|Q3\\\\_K\\\\_XL|275.6|3.520|3.3324|\\n|IQ3\\\\_XXS|254.2|3.250|3.3805|\\n|IQ2\\\\_K\\\\_R4|220.0|2.799|3.5069|\\n|Q2\\\\_K\\\\_XL|233.9|2.990|3.6062|\\n|IQ2\\\\_KT|196.7|2.514|3.6378|\\n|UD-TQ1\\\\_0|150.8|1.927|4.7567|\\n|IQ1\\\\_S\\\\_R4|130.2|1.664|4.8805|\\n\\n# DeepSeek V3 0324\\n\\n[V3 0324 Comparison](https://preview.redd.it/l1nuh3r22pcf1.png?width=4139&amp;format=png&amp;auto=webp&amp;s=16bd4c33d941c65b4fa439bf621e0e7f69195f81)\\n\\nHere Q2\\\\_K\\\\_XL performs really good, even better than R1 Q2\\\\_K\\\\_XL. Reason is unkown for now. ALso, IQ3\\\\_XXS is not here as it failed the test with nan, also unkown.\\n\\n[V3 0324 Q2\\\\_K\\\\_XL](https://preview.redd.it/6bheilba2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=0e278431b88fa49e69f8e32bd2bf881fd7e57357)\\n\\n[V3 0324 Q3\\\\_K\\\\_XL](https://preview.redd.it/7rmqc55d2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=5389b135a13c86ff471d38540909a7586e2282ff)\\n\\n[V3 0324 IQ4\\\\_XS](https://preview.redd.it/yih3wq9e2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=23fdbeaec51b4e226da035042bfcf80da5a5f4e9)\\n\\n[V3 0324 Q8\\\\_0](https://preview.redd.it/teu0yiof2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=9e69256c7c5d098956ed1063c4bdb029aa9631ea)\\n\\nSo with a table format, from best to lower PPL:\\n\\n|Model|Size (GB)|BPW|PPL|\\n|:-|:-|:-|:-|\\n|Q8\\\\_0|665.3|8.000|3.2454|\\n|IQ4\\\\_K\\\\_R4|386.2|4.936|3.2596|\\n|IQ4\\\\_XS|333.1|4.260|3.2598|\\n|IQ3\\\\_K\\\\_R4\\\\_Pure|352.5|4.505|3.2942|\\n|IQ3\\\\_K\\\\_R4|324.0|4.141|3.3193|\\n|Q3\\\\_K\\\\_XL|281.5|3.600|3.3690|\\n|Q2\\\\_K\\\\_XL|233.9|2.990|3.5264|\\n|IQ2\\\\_K\\\\_R4|226.0|2.889|3.5614|\\n|IQ1\\\\_S\\\\_R4|130.2|1.664|5.1292|\\n|IQ3\\\\_XXS|254.2|3.250|NaN (failed)|\\n\\n\\\\-----------------------------------------\\n\\nFinally, a small comparison between R1 0528 and V3 0324\\n\\nhttps://preview.redd.it/s50qgpnr2pcf1.png?width=4164&amp;format=png&amp;auto=webp&amp;s=4bf3e1a6544913d76462b6486b76ad570c6eb779\\n\\n\\\\-------------------------------------\\n\\nSo that's all! Again, PPL is not in a indicator of everything, so take everything with a grain of salt.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Some small PPL benchmarks on DeepSeek R1 0528 quants, from Unlosh and ubergarm, from 1.6bpw (1Q_S_R4) to 4.7bpw (IQ4_KS_R4) (and Q8/FP8 baseline). Also a few V3 0324 ones.","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"media_metadata":{"8oart9461pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/8oart9461pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=615a76c2eb11dbcbba71bcde5e8b14a9b26955e3"},{"y":143,"x":216,"u":"https://preview.redd.it/8oart9461pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c9139d1b2905964e6745bf2fd14259b9a426ef3"},{"y":212,"x":320,"u":"https://preview.redd.it/8oart9461pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=936018d1934011acf9e5a0fc6e5d1e12d392b3c9"},{"y":424,"x":640,"u":"https://preview.redd.it/8oart9461pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4aa90341e104747b8a053980c3ab9602ade859c"},{"y":636,"x":960,"u":"https://preview.redd.it/8oart9461pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bb633b4c9c3893c7f7c42033f9e4f89a812c598"},{"y":716,"x":1080,"u":"https://preview.redd.it/8oart9461pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=83fc06d5dd5479b8d4a44ba237e86a2bd273256b"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/8oart9461pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=1723d977f7c034496eb7a95bed576b6b53572542"},"id":"8oart9461pcf1"},"7rmqc55d2pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=87ab3d79391658c24f8eb175eb96cd85e9a00da6"},{"y":143,"x":216,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=956f56f00765d9ad2c0793039e5de22c7092e14f"},{"y":212,"x":320,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cc7798ea477051b35e7007cb17e3c41394c51212"},{"y":424,"x":640,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8b29a30d6cb56832e224a01ba1c5b7550e96bfc2"},{"y":636,"x":960,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=12171abe12ae972d53b8deabb974efd754c7e52c"},{"y":716,"x":1080,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=180b1fd5de5280cacff280251987f6c88c055812"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/7rmqc55d2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=5389b135a13c86ff471d38540909a7586e2282ff"},"id":"7rmqc55d2pcf1"},"l1nuh3r22pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":77,"x":108,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b9568c5d650c2cd7c0446713e1cea84ab15e770"},{"y":155,"x":216,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ecec583e68c2f6b061401ecfc9ae823d8ccf9330"},{"y":230,"x":320,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47ab80310d3fcdbbc3296ef62140f3a2a623564e"},{"y":460,"x":640,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f58a9f33959d704d9383bed69b04b4d8823d3bfc"},{"y":690,"x":960,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=55ea27ccead37bc0748ca76af9beb6cef79b2bd6"},{"y":777,"x":1080,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0184ecd6a22d35f76c80d17a07a20fbd976c79a2"}],"s":{"y":2979,"x":4139,"u":"https://preview.redd.it/l1nuh3r22pcf1.png?width=4139&amp;format=png&amp;auto=webp&amp;s=16bd4c33d941c65b4fa439bf621e0e7f69195f81"},"id":"l1nuh3r22pcf1"},"teu0yiof2pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9573603bf90a5ff2ef935a4a813d1bb8c111ff24"},{"y":143,"x":216,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ac9b2792909e2e52b968b2584ad6829dd49793a"},{"y":212,"x":320,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba5ecaf0e1bf7a286da0f5d65f0099deaf5577f0"},{"y":424,"x":640,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=33b414c7be5afc38a8a4bdc20cecaf50a65b7b13"},{"y":636,"x":960,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=396b89d26216bb1c9604ce42988c34519ad44938"},{"y":716,"x":1080,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=936016288947f75add8ea488474c6ccf0b60468b"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/teu0yiof2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=9e69256c7c5d098956ed1063c4bdb029aa9631ea"},"id":"teu0yiof2pcf1"},"i5tb2cx41pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ccd1eb06c1618b728e8a0604331877f92d9acf4"},{"y":143,"x":216,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c6a3f76ae75b7812bf935d8472fe5c847bf221fc"},{"y":212,"x":320,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=71f6875de4d3c999cba1ed1e72a875f02940c517"},{"y":424,"x":640,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f502525fe41dc6b42397b8d9c585cbee2ac18028"},{"y":636,"x":960,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b248d089bf7ed3769b453c8696436b9fdaaf8458"},{"y":716,"x":1080,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=836822fc69fbd55912f352f05dc701c9bbfef2f9"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/i5tb2cx41pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=02a12f2c12b6ef657397b60fc8e87d022bc6c5b0"},"id":"i5tb2cx41pcf1"},"dszt1qw71pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf982e76cfe91939c03204063797f16a8434b727"},{"y":143,"x":216,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c56734e22cf419ace70839ef50bfe69d9b523e8e"},{"y":212,"x":320,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9ca8ee8ae47c017f473ea4c5b681827b319b10b"},{"y":424,"x":640,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31b498d68bb4c16bc4fb62e800f5feea76bd531b"},{"y":636,"x":960,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=45e796875cf5c42de8161e1c2ae74e8ef6daedc0"},{"y":716,"x":1080,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b1ec5abb73f5e058697589587ac177114c9f33c"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/dszt1qw71pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=a77fc375c2e197346034a962fdff96ddea5ac49a"},"id":"dszt1qw71pcf1"},"tfu0yvn21pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2afda21ba96b06391f3628938bdc7dea4a34001f"},{"y":143,"x":216,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d364400f8233f61d0041646a762803b428fe8388"},{"y":212,"x":320,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3004c72b817e4b50b842bf597633c3ad280437de"},{"y":424,"x":640,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f78198a60a934140599f55840257d46e1081ff3c"},{"y":636,"x":960,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d64fc5371534bbf7ffbf4c9e22abf3c2d855108"},{"y":716,"x":1080,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77d97017393854e480b59a604456ed04cddcc741"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/tfu0yvn21pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=f2b75d15eecfd49481db1a066b04fb57f5ac3542"},"id":"tfu0yvn21pcf1"},"s50qgpnr2pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":77,"x":108,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=feb259d1b93d378f1fc631775da3c556d54ab2c3"},{"y":154,"x":216,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c1c022151fbf8eee7c87904451af64a5f70873e"},{"y":228,"x":320,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=49532cb0b7328f5418bffbe6e1746b5627742b4c"},{"y":457,"x":640,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=68d831e0f1ae10968624015e06e0ddb82149726d"},{"y":685,"x":960,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1562dbd9c9e944eeac38e77d6f927fd93a9e32f"},{"y":771,"x":1080,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d504b01aba8ee14725e22e75fc13ff875e387897"}],"s":{"y":2975,"x":4164,"u":"https://preview.redd.it/s50qgpnr2pcf1.png?width=4164&amp;format=png&amp;auto=webp&amp;s=4bf3e1a6544913d76462b6486b76ad570c6eb779"},"id":"s50qgpnr2pcf1"},"6bheilba2pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1569b2dae00bec9751f2e7d88e8f29915d3048cd"},{"y":143,"x":216,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a602548870ac5cf6308a610bb48aa701c3604ed0"},{"y":212,"x":320,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=195d11ff9a75f766e7e8af3ad94c6d80f27f23f7"},{"y":424,"x":640,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=171355dcfe1b8e13e22e52b9273acefdcb621c9d"},{"y":636,"x":960,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=052d6b680a3a36129025d576418b9a3a6dfaa16f"},{"y":716,"x":1080,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f7342a6d1ff58f621faccfdaba720a1dbc94ff78"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/6bheilba2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=0e278431b88fa49e69f8e32bd2bf881fd7e57357"},"id":"6bheilba2pcf1"},"ioqbx5iv0pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":77,"x":108,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88177c33bbced92cd375a627a732dcdb99ada4c3"},{"y":155,"x":216,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=afcadfe2e58344c29a65d3f25c56f50c21f82a74"},{"y":230,"x":320,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6228278b0a3825f057c1380f6faf30cc8e6dce2c"},{"y":461,"x":640,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bbf3294de2c4b4f094213870c79018afa953b1e0"},{"y":691,"x":960,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=98e2a31b9a2f976126b5ed3721512a573c83ef24"},{"y":778,"x":1080,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e0f867696a8e177b4b8751cf2500d16e53e57b6"}],"s":{"y":2979,"x":4135,"u":"https://preview.redd.it/ioqbx5iv0pcf1.png?width=4135&amp;format=png&amp;auto=webp&amp;s=4f1a3feb6e2143aaa739d1c4d61d45df80494abb"},"id":"ioqbx5iv0pcf1"},"yih3wq9e2pcf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":71,"x":108,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7ae430a69347c77320a2f651f4376e13371e0b7"},{"y":143,"x":216,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b2c8a06a57a5cb3e3792d7a1866f9916c96b4518"},{"y":212,"x":320,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e51ea3017eca682a4c9a3d64a5210b8c7f183c3b"},{"y":424,"x":640,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=43e84a68887262c6667e3431a3f70d4306376485"},{"y":636,"x":960,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad6f4ac874038b2e6b39a2dce2002d94354d9478"},{"y":716,"x":1080,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28096bc4f5f8b1ee053a97b51c9047e079854d30"}],"s":{"y":2364,"x":3565,"u":"https://preview.redd.it/yih3wq9e2pcf1.png?width=3565&amp;format=png&amp;auto=webp&amp;s=23fdbeaec51b4e226da035042bfcf80da5a5f4e9"},"id":"yih3wq9e2pcf1"}},"name":"t3_1lz1s8x","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":"#bbbdbf","ups":84,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","is_original_content":false,"author_fullname":"t2_j1kqr","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":84,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=8688e9a81e04dfb9541beabf3f5c89f9d553f07b","edited":1752441951,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1752435641,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;HI there guys, hoping you&amp;#39;re doing fine.&lt;/p&gt;\\n\\n&lt;p&gt;As always related to PPL benchmarks, take them with a grain of salt as it may not represent the quality of the model itself, but it may help as a guide at how much a model could get affected by quantization.&lt;/p&gt;\\n\\n&lt;p&gt;As it has been mentioned sometimes, and a bit of spoiler, quantization on DeepSeek models is pretty impressive, because either quantization methods nowadays are really good and/or DeepSeek being natively FP8, it changes the paradigm a bit.&lt;/p&gt;\\n\\n&lt;p&gt;Also many thanks to ubergarm (&lt;a href=\\"/u/VoidAlchemy\\"&gt;u/VoidAlchemy&lt;/a&gt;) for his data on his quants and Q8_0/FP8 baseline!&lt;/p&gt;\\n\\n&lt;p&gt;For the quants that aren&amp;#39;t from him, I did run them with the same command he did, with wiki.text.raw:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;./llama-perplexity -m &amp;#39;model_name.gguf&amp;#39; \\\\\\n-c 512 --no-mmap -ngl 999 \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA0&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA1&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA2&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA3&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA4&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA5&amp;quot; \\\\\\n-ot &amp;quot;blk.(layers_depending_on_model).ffn.=CUDA6&amp;quot; \\\\\\n-ot exps=CPU \\\\\\n-fa -mg 0 -mla 3 -amb 256 -fmoe \\\\\\n-f wiki.test.raw\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;--------------------------&lt;/p&gt;\\n\\n&lt;p&gt;For baselines, we have this data:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;DeepSeek R1 0528 Q8: 3.2119&lt;/li&gt;\\n&lt;li&gt;DeepSeek V3 0324 Q8 and q8_cache (important*): 3.2454&lt;/li&gt;\\n&lt;li&gt;DeepSeek V3 0324 Q8 and F16 cache extrapolated*: 3.2443&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;*Based on &lt;a href=\\"https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/discussions/2#686fdceb17516435632a4241\\"&gt;https://huggingface.co/ubergarm/DeepSeek-TNG-R1T2-Chimera-GGUF/discussions/2#686fdceb17516435632a4241&lt;/a&gt;, on R1 0528 at Q8_0, the difference between F16 and Q8_0 cache is:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;code&gt;-ctk fp16&lt;/code&gt; &lt;code&gt;3.2119 +/- 0.01697&lt;/code&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;code&gt;-ctk q8_0&lt;/code&gt; &lt;code&gt;3.2130 +/- 0.01698&lt;/code&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;So then, F16 cache is 0.03% better than Q8_0 for this model. Extrapolating that to V3, then V3 0324 Q8 at F16 should have 3.2443 PPL.&lt;/p&gt;\\n\\n&lt;p&gt;Quants tested for R1 0528:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;IQ1_S_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;UD-TQ1_0&lt;/li&gt;\\n&lt;li&gt;IQ2_KT (ubergarm)&lt;/li&gt;\\n&lt;li&gt;IQ2_K_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;Q2_K_XL&lt;/li&gt;\\n&lt;li&gt;IQ3_XXS&lt;/li&gt;\\n&lt;li&gt;IQ3_KS (ubergarm, my bad here as I named it IQ3_KT)&lt;/li&gt;\\n&lt;li&gt;Q3_K_XL&lt;/li&gt;\\n&lt;li&gt;IQ3_K_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;IQ4_XS&lt;/li&gt;\\n&lt;li&gt;q4_0 (pure)&lt;/li&gt;\\n&lt;li&gt;IQ4_KS_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;Q8_0 (ubergarm)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Quants tested for V3 0324:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Q1_S_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;IQ2_K_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;Q2_K_XL&lt;/li&gt;\\n&lt;li&gt;IQ3_XXS&lt;/li&gt;\\n&lt;li&gt;Q3_K_XL&lt;/li&gt;\\n&lt;li&gt;IQ3_K_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;IQ3_K_R4_Pure (ubergarm)&lt;/li&gt;\\n&lt;li&gt;IQ4_XS&lt;/li&gt;\\n&lt;li&gt;IQ4_K_R4 (ubergarm)&lt;/li&gt;\\n&lt;li&gt;Q8_0 (ubergarm)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;So here we go:&lt;/p&gt;\\n\\n&lt;h1&gt;DeepSeek R1 0528&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/ioqbx5iv0pcf1.png?width=4135&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4f1a3feb6e2143aaa739d1c4d61d45df80494abb\\"&gt;R1 0528 comparison (IQ3_KT is IQ3_KS, my bad)&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;As can you see, near 3.3bpw and above it gets quite good!. So now using different baselines to compare, using 100% for Q2_K_XL, Q3_K_XL, IQ4_XS and Q8_0.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/tfu0yvn21pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f2b75d15eecfd49481db1a066b04fb57f5ac3542\\"&gt;R1 0528 Q2_K_XL&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/i5tb2cx41pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=02a12f2c12b6ef657397b60fc8e87d022bc6c5b0\\"&gt;R1 0528 Q3_K_XL&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/8oart9461pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1723d977f7c034496eb7a95bed576b6b53572542\\"&gt;R1 0528 IQ4_XS&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/dszt1qw71pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a77fc375c2e197346034a962fdff96ddea5ac49a\\"&gt;R1 0528 Q8_0&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;So with a table format, it looks like this (ordered by best to worse PPL)&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Model&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Size (GB)&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;BPW&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;PPL&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q8_0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;665.3&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;8.000&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2119&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ4_KS_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;367.8&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.701&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2286&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ4_XS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;333.1&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.260&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2598&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;q4_0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;352.6&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.508&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2895&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_K_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;300.9&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.847&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2730&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_KT&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;272.5&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.483&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.3056&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q3_K_XL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;275.6&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.520&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.3324&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_XXS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;254.2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.250&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.3805&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ2_K_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;220.0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2.799&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.5069&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q2_K_XL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;233.9&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2.990&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.6062&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ2_KT&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;196.7&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2.514&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.6378&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;UD-TQ1_0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;150.8&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1.927&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.7567&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ1_S_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;130.2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1.664&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.8805&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;h1&gt;DeepSeek V3 0324&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/l1nuh3r22pcf1.png?width=4139&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16bd4c33d941c65b4fa439bf621e0e7f69195f81\\"&gt;V3 0324 Comparison&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Here Q2_K_XL performs really good, even better than R1 Q2_K_XL. Reason is unkown for now. ALso, IQ3_XXS is not here as it failed the test with nan, also unkown.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/6bheilba2pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e278431b88fa49e69f8e32bd2bf881fd7e57357\\"&gt;V3 0324 Q2_K_XL&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/7rmqc55d2pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5389b135a13c86ff471d38540909a7586e2282ff\\"&gt;V3 0324 Q3_K_XL&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/yih3wq9e2pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=23fdbeaec51b4e226da035042bfcf80da5a5f4e9\\"&gt;V3 0324 IQ4_XS&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/teu0yiof2pcf1.png?width=3565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e69256c7c5d098956ed1063c4bdb029aa9631ea\\"&gt;V3 0324 Q8_0&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;So with a table format, from best to lower PPL:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Model&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Size (GB)&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;BPW&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;PPL&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q8_0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;665.3&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;8.000&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2454&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ4_K_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;386.2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.936&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2596&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ4_XS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;333.1&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.260&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2598&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_K_R4_Pure&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;352.5&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.505&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.2942&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_K_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;324.0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4.141&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.3193&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q3_K_XL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;281.5&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.600&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.3690&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Q2_K_XL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;233.9&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2.990&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.5264&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ2_K_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;226.0&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2.889&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.5614&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ1_S_R4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;130.2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1.664&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;5.1292&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;IQ3_XXS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;254.2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;3.250&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;NaN (failed)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;-----------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;Finally, a small comparison between R1 0528 and V3 0324&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/s50qgpnr2pcf1.png?width=4164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bf3e1a6544913d76462b6486b76ad570c6eb779\\"&gt;https://preview.redd.it/s50qgpnr2pcf1.png?width=4164&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4bf3e1a6544913d76462b6486b76ad570c6eb779&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;-------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;So that&amp;#39;s all! Again, PPL is not in a indicator of everything, so take everything with a grain of salt.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?auto=webp&amp;s=8216ca1903562c8f1a410d204c99985dbb7b3108","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=916df2f54c0cd22cd11ed7809b3c140706edfcee","width":108,"height":58},{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3e1dbcdca4fa3782c38fd3d119431d344a540668","width":216,"height":116},{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7924ff592a988d2740e535ed06a0e5c6b9fe1ae5","width":320,"height":172},{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=34bb099dc9d99a1928035eecc7f6474b2da46ba7","width":640,"height":345},{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bdda7d98fc08d38df0a76903dbc3720bcf1ae1d","width":960,"height":518},{"url":"https://external-preview.redd.it/7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfaf0e47961251e127029f745bd8fda90457859c","width":1080,"height":583}],"variants":{},"id":"7ISepN1ZhP4X7ew10cBPIuuqsS75KZVYV_G0DmVulbM"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Llama 405B","treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lz1s8x","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"panchovix","discussion_type":null,"num_comments":17,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/","subreddit_subscribers":499297,"created_utc":1752435641,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n314cxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ciprianveg","can_mod_post":false,"created_utc":1752473100,"send_replies":true,"parent_id":"t1_n2yj8ur","score":1,"author_fullname":"t2_j8fit2p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you for this. Did you forget ik3-ks r1 from uber?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n314cxk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for this. Did you forget ik3-ks r1 from uber?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n314cxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752473100,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yj8ur","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VoidAlchemy","can_mod_post":false,"created_utc":1752438578,"send_replies":true,"parent_id":"t3_1lz1s8x","score":27,"author_fullname":"t2_n321yfw5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey great job presenting all the values and doing a great writeup u/panchovix !\\n\\nIts been one heck of a journey over the past few months quantizing these behemoth models, and now Kimi-K2-Instruct-1000B-A32B is gonna need over 768GB RAM to generate an good imatrix for quantizing lol :sob: haha... I think my hardware guru Wendell at level1techs has something in mind that could do the trick!\\n\\nAlso excited about ik's latest SOTA quant the IQ2\\\\_KL \\\\~2.69BPW which could come in handy for future recipes on these big MoEs. See ya round and as always I love your enthusiasm (and seeing your \\\\\`-ot ...\\\\\` commands for 5+ GPUs haha...)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2yj8ur","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey great job presenting all the values and doing a great writeup &lt;a href=\\"/u/panchovix\\"&gt;u/panchovix&lt;/a&gt; !&lt;/p&gt;\\n\\n&lt;p&gt;Its been one heck of a journey over the past few months quantizing these behemoth models, and now Kimi-K2-Instruct-1000B-A32B is gonna need over 768GB RAM to generate an good imatrix for quantizing lol :sob: haha... I think my hardware guru Wendell at level1techs has something in mind that could do the trick!&lt;/p&gt;\\n\\n&lt;p&gt;Also excited about ik&amp;#39;s latest SOTA quant the IQ2_KL ~2.69BPW which could come in handy for future recipes on these big MoEs. See ya round and as always I love your enthusiasm (and seeing your \`-ot ...\` commands for 5+ GPUs haha...)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yj8ur/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438578,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ycefe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Threatening-Silence-","can_mod_post":false,"created_utc":1752436558,"send_replies":true,"parent_id":"t3_1lz1s8x","score":11,"author_fullname":"t2_15wqsifdjf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fantastic thread, it's so helpful to have this all in one place! I was digging through threads and GitHub repos trying to piece this all together before 😄","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ycefe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fantastic thread, it&amp;#39;s so helpful to have this all in one place! I was digging through threads and GitHub repos trying to piece this all together before 😄&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2ycefe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752436558,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2z118o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VoidAlchemy","can_mod_post":false,"created_utc":1752444002,"send_replies":true,"parent_id":"t1_n2yjoph","score":8,"author_fullname":"t2_n321yfw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've been working with Wendell on this some and have tested mainline llama.cpp with both Vulkan and ROCm/HIP backends with small test quants on an RX 7900 XTX 24GB @ 291 Watts with some success, but that project is still a work in progress.\\n\\nRegarding AMD support on ik\\\\_llama.cpp, working on it right now specifically for Vulkan backend where you can run some models now, but we're not quite there for DeepSeek but at least there is some hope now! Follow along here if you want to try ik's fork with Vulkan on your AMD GPUs and help out: [https://github.com/ikawrakow/ik\\\\_llama.cpp/pull/607](https://github.com/ikawrakow/ik_llama.cpp/pull/607)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2z118o","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve been working with Wendell on this some and have tested mainline llama.cpp with both Vulkan and ROCm/HIP backends with small test quants on an RX 7900 XTX 24GB @ 291 Watts with some success, but that project is still a work in progress.&lt;/p&gt;\\n\\n&lt;p&gt;Regarding AMD support on ik_llama.cpp, working on it right now specifically for Vulkan backend where you can run some models now, but we&amp;#39;re not quite there for DeepSeek but at least there is some hope now! Follow along here if you want to try ik&amp;#39;s fork with Vulkan on your AMD GPUs and help out: &lt;a href=\\"https://github.com/ikawrakow/ik_llama.cpp/pull/607\\"&gt;https://github.com/ikawrakow/ik_llama.cpp/pull/607&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2z118o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752444002,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ysvkd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panchovix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2yq3yk","score":2,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ah I see. Then yes, for that range I would go Q3_K_XL (or IQ3_KS if AMD can run it)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ysvkd","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah I see. Then yes, for that range I would go Q3_K_XL (or IQ3_KS if AMD can run it)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2ysvkd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752441432,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1752441432,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yq3yk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MLDataScientist","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ykv07","score":1,"author_fullname":"t2_3zy7pnf1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have 96GB DDR4 3200Mhz RAM dual channel using AMD 5950x CPU.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2yq3yk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have 96GB DDR4 3200Mhz RAM dual channel using AMD 5950x CPU.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yq3yk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752440607,"author_flair_text":null,"treatment_tags":[],"created_utc":1752440607,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ykv07","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panchovix","can_mod_post":false,"created_utc":1752439050,"send_replies":true,"parent_id":"t1_n2yjoph","score":3,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think they have been adding support recently IIRC? /u/VoidAlchemy maybe it can confirm.\\n\\nAnd yep! But how much ram do have? If it's 256GB you maybe can run Q4_K_S with offloading.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ykv07","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think they have been adding support recently IIRC? &lt;a href=\\"/u/VoidAlchemy\\"&gt;/u/VoidAlchemy&lt;/a&gt; maybe it can confirm.&lt;/p&gt;\\n\\n&lt;p&gt;And yep! But how much ram do have? If it&amp;#39;s 256GB you maybe can run Q4_K_S with offloading.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2ykv07/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752439050,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yjoph","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MLDataScientist","can_mod_post":false,"created_utc":1752438706,"send_replies":true,"parent_id":"t3_1lz1s8x","score":8,"author_fullname":"t2_3zy7pnf1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for sharing! Great to have them all in here. Regarding ubergarm quants, I assume those can only run with ik\\\\_llama, right? For those of us that have AMD GPUs, ik\\\\_llama does not work. Then looking at quants supported by llama.cpp, I see Q3\\\\_K\\\\_XL (276GB for R1) is the best quant for 256GB VRAM (8xMI50) with some CPU RAM offloading. Thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2yjoph","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for sharing! Great to have them all in here. Regarding ubergarm quants, I assume those can only run with ik_llama, right? For those of us that have AMD GPUs, ik_llama does not work. Then looking at quants supported by llama.cpp, I see Q3_K_XL (276GB for R1) is the best quant for 256GB VRAM (8xMI50) with some CPU RAM offloading. Thank you!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yjoph/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438706,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n38e175","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pyr0kid","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2yjur4","score":1,"author_fullname":"t2_utk4aim","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"dumb question: is ik llamacpp basically a beta branch of llamacpp or is it a divergence point and none of this is going to eventually reach mainstream llamacpp?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n38e175","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;dumb question: is ik llamacpp basically a beta branch of llamacpp or is it a divergence point and none of this is going to eventually reach mainstream llamacpp?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n38e175/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752572372,"author_flair_text":null,"treatment_tags":[],"created_utc":1752572372,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yjur4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"panchovix","can_mod_post":false,"created_utc":1752438756,"send_replies":true,"parent_id":"t1_n2yivt1","score":6,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ik llamacpp, as it supports ubergarm quants.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2yjur4","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ik llamacpp, as it supports ubergarm quants.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yjur4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438756,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yivt1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Paint-9490","can_mod_post":false,"created_utc":1752438470,"send_replies":true,"parent_id":"t3_1lz1s8x","score":3,"author_fullname":"t2_rpm5owysg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this llama.cpp or ik-llama.cpp?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2yivt1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this llama.cpp or ik-llama.cpp?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yivt1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438470,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2zbzfg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752447673,"send_replies":true,"parent_id":"t3_1lz1s8x","score":3,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder how UD iQ1_S is.. it's 168gb. Hopefully not fall off a cliff like the R4 version.\\n\\nAlso there is new numa supporting engine in town: https://github.com/ztxz16/fastllm\\n\\nNot as many quants but it claims fast speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2zbzfg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder how UD iQ1_S is.. it&amp;#39;s 168gb. Hopefully not fall off a cliff like the R4 version.&lt;/p&gt;\\n\\n&lt;p&gt;Also there is new numa supporting engine in town: &lt;a href=\\"https://github.com/ztxz16/fastllm\\"&gt;https://github.com/ztxz16/fastllm&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Not as many quants but it claims fast speed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2zbzfg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752447673,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n301mrn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1752456656,"send_replies":true,"parent_id":"t3_1lz1s8x","score":2,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah. I am occasional preacher of the Q2KXL UD quant. In fact, I would rather use a bigger better model at UD Q2KXL than a smaller model at Q4 if I am VRAM constrained. \\n\\nQ2KXL UD is not your run of the mill Q2. That stuff is magic. ","edited":1752456949,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n301mrn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. I am occasional preacher of the Q2KXL UD quant. In fact, I would rather use a bigger better model at UD Q2KXL than a smaller model at Q4 if I am VRAM constrained. &lt;/p&gt;\\n\\n&lt;p&gt;Q2KXL UD is not your run of the mill Q2. That stuff is magic. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n301mrn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752456656,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n337j0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"choose_a_guest","can_mod_post":false,"created_utc":1752506020,"send_replies":true,"parent_id":"t3_1lz1s8x","score":2,"author_fullname":"t2_cbnw4l4g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I appreciate the work that you (and all the devs) have put into creating and analyzing these quants. I hope we will see more information about the tradeoffs that come with different quantization specs in the future.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n337j0o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I appreciate the work that you (and all the devs) have put into creating and analyzing these quants. I hope we will see more information about the tradeoffs that come with different quantization specs in the future.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n337j0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752506020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n30fwsv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ykg0h","score":1,"author_fullname":"t2_1l3z4stvkq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Really good job with the analysis","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n30fwsv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really good job with the analysis&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n30fwsv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752461911,"author_flair_text":null,"treatment_tags":[],"created_utc":1752461911,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ykg0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"panchovix","can_mod_post":false,"created_utc":1752438929,"send_replies":true,"parent_id":"t1_n2yk6pe","score":3,"author_fullname":"t2_j1kqr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sadly I don't have enough RAM + VRAM to run it :( IQ4_XS is about the max I can run comfortably.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ykg0h","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sadly I don&amp;#39;t have enough RAM + VRAM to run it :( IQ4_XS is about the max I can run comfortably.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lz1s8x","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2ykg0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438929,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2yk6pe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"created_utc":1752438853,"send_replies":true,"parent_id":"t3_1lz1s8x","score":1,"author_fullname":"t2_1l3z4stvkq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would love to see where Q4_X_S sits in those graphs, it's consistently quicker.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2yk6pe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would love to see where Q4_X_S sits in those graphs, it&amp;#39;s consistently quicker.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/n2yk6pe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752438853,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lz1s8x","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),d=()=>t.jsx(e,{data:a});export{d as default};
