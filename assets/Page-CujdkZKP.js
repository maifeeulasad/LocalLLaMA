import{j as e}from"./index-F0NXdzZX.js";import{R as t}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello devs,\\n\\nThe idea came from while I was working on a personal project. When I tried to deploy my agent into the cloud, I ran into a lot of headaches — setting up VMs, writing config, handling crashes. I decided to build a solution for it and called it Agentainer.\\n\\nAgentainer’s goal is to let anyone (even coding agents) deploy LLM agents into production without spending hours setting up infrastructure.\\n\\nHere’s what Agentainer does:\\n\\n* One-click deployment: Deploy your containerized LLM agent (any language) as a Docker image\\n* Lifecycle management: Start, stop, pause, resume, and auto-recover via UI or API\\n* Auto-recovery: Agents restart automatically after a crash and return to their last working state\\n* State persistence: Uses Redis for in-memory state and PostgreSQL for snapshots\\n* Per-agent secure APIs: Each agent gets its own REST/gRPC endpoint with token-based auth and usage logging (e.g. `https://agentainer.io/{agentId}/{agentEndpoint}`)\\n\\nMost cloud platforms are designed for stateless apps or short-lived functions. They’re not ideal for long-running autonomous agents. Since a lot of dev work is now being done by coding agents themselves, Agentainer exposes all platform functions through an API. That means even non-technical founders can ship their own agents into production without needing to manage infrastructure.\\n\\nIf you visit the website ( [https://agentainer.io/](https://agentainer.io/) ) , you’ll find a link to our GitHub repo with a working demo that includes all the features above. You can also sign up for early access to the production version, which is launching soon.\\n\\nhttps://preview.redd.it/elzllmzvz4ef1.png?width=1266&amp;format=png&amp;auto=webp&amp;s=58673daaa292d998e6d89d7af4878f7a398d2056\\n\\nI would love to hear feedback — especially from folks running agents in production or building with them now. If you try [Agentainer Lab (GitHub)](https://github.com/oso95/Agentainer-lab), I’d really appreciate any thoughts (good and bad) or feature suggestions.\\n\\nNote: Agentainer doesn’t provide any LLM models or reasoning frameworks. We’re infrastructure only — you bring the agent, and we handle deployment, state, and APIs.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"A solution to deploy your LLM agent with one click","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":77,"top_awarded_type":null,"hide_score":false,"media_metadata":{"elzllmzvz4ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":60,"x":108,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eacdf14901ba02b5139a700003b97cef06111520"},{"y":120,"x":216,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c85d6aea7f5165ed20b5adb45ff4214a7906d97"},{"y":178,"x":320,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bcc4043d6af492941e4b63f2d932aea14383666"},{"y":356,"x":640,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e25c0f9f99ed80b21e35f6f6fc6f5dd7d2a0dc4d"},{"y":534,"x":960,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=42250f4125da0c648bc1190950ab4f6090bbd976"},{"y":601,"x":1080,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a820df79a5538838f37f2b29408324e7420dee3f"}],"s":{"y":705,"x":1266,"u":"https://preview.redd.it/elzllmzvz4ef1.png?width=1266&amp;format=png&amp;auto=webp&amp;s=58673daaa292d998e6d89d7af4878f7a398d2056"},"id":"elzllmzvz4ef1"}},"name":"t3_1m56x5u","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.13,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_6mhhxj8ry","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/_hNhxOlJGohyQo1t7_1jEp2uUFZpEvxm0QAXuurPBpI.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753064166,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello devs,&lt;/p&gt;\\n\\n&lt;p&gt;The idea came from while I was working on a personal project. When I tried to deploy my agent into the cloud, I ran into a lot of headaches — setting up VMs, writing config, handling crashes. I decided to build a solution for it and called it Agentainer.&lt;/p&gt;\\n\\n&lt;p&gt;Agentainer’s goal is to let anyone (even coding agents) deploy LLM agents into production without spending hours setting up infrastructure.&lt;/p&gt;\\n\\n&lt;p&gt;Here’s what Agentainer does:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;One-click deployment: Deploy your containerized LLM agent (any language) as a Docker image&lt;/li&gt;\\n&lt;li&gt;Lifecycle management: Start, stop, pause, resume, and auto-recover via UI or API&lt;/li&gt;\\n&lt;li&gt;Auto-recovery: Agents restart automatically after a crash and return to their last working state&lt;/li&gt;\\n&lt;li&gt;State persistence: Uses Redis for in-memory state and PostgreSQL for snapshots&lt;/li&gt;\\n&lt;li&gt;Per-agent secure APIs: Each agent gets its own REST/gRPC endpoint with token-based auth and usage logging (e.g. &lt;code&gt;https://agentainer.io/{agentId}/{agentEndpoint}&lt;/code&gt;)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Most cloud platforms are designed for stateless apps or short-lived functions. They’re not ideal for long-running autonomous agents. Since a lot of dev work is now being done by coding agents themselves, Agentainer exposes all platform functions through an API. That means even non-technical founders can ship their own agents into production without needing to manage infrastructure.&lt;/p&gt;\\n\\n&lt;p&gt;If you visit the website ( &lt;a href=\\"https://agentainer.io/\\"&gt;https://agentainer.io/&lt;/a&gt; ) , you’ll find a link to our GitHub repo with a working demo that includes all the features above. You can also sign up for early access to the production version, which is launching soon.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/elzllmzvz4ef1.png?width=1266&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58673daaa292d998e6d89d7af4878f7a398d2056\\"&gt;https://preview.redd.it/elzllmzvz4ef1.png?width=1266&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58673daaa292d998e6d89d7af4878f7a398d2056&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I would love to hear feedback — especially from folks running agents in production or building with them now. If you try &lt;a href=\\"https://github.com/oso95/Agentainer-lab\\"&gt;Agentainer Lab (GitHub)&lt;/a&gt;, I’d really appreciate any thoughts (good and bad) or feature suggestions.&lt;/p&gt;\\n\\n&lt;p&gt;Note: Agentainer doesn’t provide any LLM models or reasoning frameworks. We’re infrastructure only — you bring the agent, and we handle deployment, state, and APIs.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m56x5u","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Tradingoso","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m56x5u/a_solution_to_deploy_your_llm_agent_with_one_click/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m56x5u/a_solution_to_deploy_your_llm_agent_with_one_click/","subreddit_subscribers":502273,"created_utc":1753064166,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4adefr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tradingoso","can_mod_post":false,"created_utc":1753072855,"send_replies":true,"parent_id":"t1_n49xtjr","score":1,"author_fullname":"t2_6mhhxj8ry","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I apologize for the error, apparently I missed on pushing the cmd folder. I have fixed it, please try again and let me know you it works now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4adefr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I apologize for the error, apparently I missed on pushing the cmd folder. I have fixed it, please try again and let me know you it works now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m56x5u","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m56x5u/a_solution_to_deploy_your_llm_agent_with_one_click/n4adefr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753072855,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49xtjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Mountain3817","can_mod_post":false,"created_utc":1753066235,"send_replies":true,"parent_id":"t3_1m56x5u","score":1,"author_fullname":"t2_hylfch6q5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"    =&gt; [builder 5/6] COPY . .                                                                                                                        0.0s\\n     =&gt; ERROR [builder 6/6] RUN go build -o agentainer ./cmd/agentainer                  0.1s\\n    ------                                                                               \\n     &gt; [builder 6/6] RUN go build -o agentainer ./cmd/agentainer:\\n    0.081 no Go files in /app/cmd/agentainer\\n    ------\\n    Dockerfile:9\\n    --------------------\\n       7 |     \\n       8 |     COPY . .\\n       9 | &gt;&gt;&gt; RUN go build -o agentainer ./cmd/agentainer\\n      10 |     \\n      11 |     FROM alpine:latest\\n    --------------------\\n    failed to solve: process \\"/bin/sh -c go build -o agentainer ./cmd/agentainer\\" did not complete successfully: exit code: 1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49xtjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;pre&gt;&lt;code&gt;=&amp;gt; [builder 5/6] COPY . .                                                                                                                        0.0s\\n =&amp;gt; ERROR [builder 6/6] RUN go build -o agentainer ./cmd/agentainer                  0.1s\\n------                                                                               \\n &amp;gt; [builder 6/6] RUN go build -o agentainer ./cmd/agentainer:\\n0.081 no Go files in /app/cmd/agentainer\\n------\\nDockerfile:9\\n--------------------\\n   7 |     \\n   8 |     COPY . .\\n   9 | &amp;gt;&amp;gt;&amp;gt; RUN go build -o agentainer ./cmd/agentainer\\n  10 |     \\n  11 |     FROM alpine:latest\\n--------------------\\nfailed to solve: process &amp;quot;/bin/sh -c go build -o agentainer ./cmd/agentainer&amp;quot; did not complete successfully: exit code: 1\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m56x5u/a_solution_to_deploy_your_llm_agent_with_one_click/n49xtjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066235,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m56x5u","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4aykpe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MelodicRecognition7","can_mod_post":false,"created_utc":1753084084,"send_replies":true,"parent_id":"t3_1m56x5u","score":1,"author_fullname":"t2_1eex9ug5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"we are going to see more and more useless bullshit software in the nearest future lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4aykpe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;we are going to see more and more useless bullshit software in the nearest future lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m56x5u/a_solution_to_deploy_your_llm_agent_with_one_click/n4aykpe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753084084,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m56x5u","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),r=()=>e.jsx(t,{data:a});export{r as default};
