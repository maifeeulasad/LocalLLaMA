import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Maybe Gemma3 is the best model for vision tasks? Each image uses only 256 tokens. In my own hardware tests, it was the only model capable of processing 60 images simultaneously.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Best Local Model for Vision?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lovqjc","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_fqt8cuoy","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751355976,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe Gemma3 is the best model for vision tasks? Each image uses only 256 tokens. In my own hardware tests, it was the only model capable of processing 60 images simultaneously.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lovqjc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"xukecheng","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/","subreddit_subscribers":493458,"created_utc":1751355976,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0v0c2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"colin_colout","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qmf6u","score":1,"author_fullname":"t2_14l4ya","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0v0c2t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0v0c2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751417298,"author_flair_text":null,"treatment_tags":[],"created_utc":1751417298,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0w13zj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lazy-Pattern-5171","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qmf6u","score":1,"author_fullname":"t2_1lyjk8is25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is it even a joke these days. 2025 has been alright but 2024 completely suffocated me with the releases one after the other.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0w13zj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it even a joke these days. 2025 has been alright but 2024 completely suffocated me with the releases one after the other.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0w13zj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751431254,"author_flair_text":null,"treatment_tags":[],"created_utc":1751431254,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qmf6u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MidAirRunner","can_mod_post":false,"created_utc":1751368481,"send_replies":true,"parent_id":"t1_n0qel5y","score":15,"author_fullname":"t2_qwhykwm6l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'll trust your unbiased opinion.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qmf6u","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll trust your unbiased opinion.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0qmf6u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751368481,"author_flair_text":"Ollama","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ugin7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tc2a7","score":2,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also FWIW thatâ€™s why I built the tool to wrap the (evolving) GGUF-du-jour\\n\\nTo confirm my suspicions around what VLM was best at helping me index and annotate the corpus of Pokemon cards more effectively","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ugin7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also FWIW thatâ€™s why I built the tool to wrap the (evolving) GGUF-du-jour&lt;/p&gt;\\n\\n&lt;p&gt;To confirm my suspicions around what VLM was best at helping me index and annotate the corpus of Pokemon cards more effectively&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0ugin7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410498,"author_flair_text":null,"treatment_tags":[],"created_utc":1751410498,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0w1mwc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Foreign-Beginning-49","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0uy7uo","score":1,"author_fullname":"t2_83u2l6o4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cool experience there thank you for the feedback.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0w1mwc","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool experience there thank you for the feedback.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0w1mwc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751431498,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751431498,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0uy7uo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"My_Unbiased_Opinion","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tc2a7","score":2,"author_fullname":"t2_esiyl0yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So I actually used the Mistral 3.2 on a graduate level nursing exam. Mistral scored much higher and was on the level of Gemini Flash 2.5 in my testing. This exam was definitely not in the training data. It was able to read the text more effectively despite irrelevant data on screen. Gemma would not follow instructions as precisely either.Â ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0uy7uo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I actually used the Mistral 3.2 on a graduate level nursing exam. Mistral scored much higher and was on the level of Gemini Flash 2.5 in my testing. This exam was definitely not in the training data. It was able to read the text more effectively despite irrelevant data on screen. Gemma would not follow instructions as precisely either.Â &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0uy7uo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751416542,"author_flair_text":null,"treatment_tags":[],"created_utc":1751416542,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ug6vp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0tc2a7","score":1,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can just [modify the prompt](https://github.com/rabbidave/ZeroDay.Tools/blob/main/ABxJudge.py) of [ABxJudge](https://github.com/rabbidave/ZeroDay.Tools/blob/main/ABxJudge.mp4)\\n\\nAdding post-processing for  key n-grams and a readme.md soon ðŸ“„ ðŸ“Š","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ug6vp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can just &lt;a href=\\"https://github.com/rabbidave/ZeroDay.Tools/blob/main/ABxJudge.py\\"&gt;modify the prompt&lt;/a&gt; of &lt;a href=\\"https://github.com/rabbidave/ZeroDay.Tools/blob/main/ABxJudge.mp4\\"&gt;ABxJudge&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Adding post-processing for  key n-grams and a readme.md soon ðŸ“„ ðŸ“Š&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0ug6vp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751410390,"author_flair_text":null,"treatment_tags":[],"created_utc":1751410390,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0tc2a7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Foreign-Beginning-49","can_mod_post":false,"created_utc":1751398381,"send_replies":true,"parent_id":"t1_n0qel5y","score":1,"author_fullname":"t2_83u2l6o4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you know of a benchmark that supports your assertion? Honestly I weight yours higher than a benchmark but im also wondering if that is a tested consensus atm. Thank you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0tc2a7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know of a benchmark that supports your assertion? Honestly I weight yours higher than a benchmark but im also wondering if that is a tested consensus atm. Thank you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0tc2a7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751398381,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qel5y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1751364494,"send_replies":true,"parent_id":"t3_1lovqjc","score":8,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mistral 3.2 is the best. By quite a margin IMHO.Â ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qel5y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral 3.2 is the best. By quite a margin IMHO.Â &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0qel5y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751364494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lovqjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0rdniu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kironlau","can_mod_post":false,"created_utc":1751378582,"send_replies":true,"parent_id":"t3_1lovqjc","score":6,"author_fullname":"t2_tb0dz2ds","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You should specify what vision tasks you look for?\\n\\nImage interrogration?\\n\\n\\\\- for image2 prompt?  (generate a similar image)  \\n\\\\-for lora training? (describe character,style, and lighting)  \\n\\\\-image2video prompt? (need to understand multiple image, and give a smooth transition)\\n\\nOCR?  \\n\\\\- handwriten? font?  \\n\\\\- English only? Any specific language?  \\n\\\\- latex of formular?  \\n\\\\- pdf structure?\\n\\nObject Recongnition?  \\n\\\\-Drawing square  \\n\\\\-giving exact coordinate  \\n\\\\-counting object)\\n\\nVideo understanding?\\n\\nI think for general use, gemma3 is very good.\\n\\nBut at least some areas I tested, cannot fulfill my usage.  \\nE.g. Img2prompt, cannot good enough for flux to replicate an image. (joycaption is far better)  \\nChinese recongition, let alone QwenVL or internVL from China, Mistral Small 2506 is much better than Gemma3 (I used Gemma 3 27B from Openrouter for a while).\\n\\nAnd there is lots of Vision models, fintuned from Qwen2.5VL is quite usefully at many task. Some are good at OCR, some even can think (reasoning). Any speicified need, a well finetuned model is usually better, if their base model is not too outweighted others.","edited":1751378859,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0rdniu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should specify what vision tasks you look for?&lt;/p&gt;\\n\\n&lt;p&gt;Image interrogration?&lt;/p&gt;\\n\\n&lt;p&gt;- for image2 prompt?  (generate a similar image)&lt;br/&gt;\\n-for lora training? (describe character,style, and lighting)&lt;br/&gt;\\n-image2video prompt? (need to understand multiple image, and give a smooth transition)&lt;/p&gt;\\n\\n&lt;p&gt;OCR?&lt;br/&gt;\\n- handwriten? font?&lt;br/&gt;\\n- English only? Any specific language?&lt;br/&gt;\\n- latex of formular?&lt;br/&gt;\\n- pdf structure?&lt;/p&gt;\\n\\n&lt;p&gt;Object Recongnition?&lt;br/&gt;\\n-Drawing square&lt;br/&gt;\\n-giving exact coordinate&lt;br/&gt;\\n-counting object)&lt;/p&gt;\\n\\n&lt;p&gt;Video understanding?&lt;/p&gt;\\n\\n&lt;p&gt;I think for general use, gemma3 is very good.&lt;/p&gt;\\n\\n&lt;p&gt;But at least some areas I tested, cannot fulfill my usage.&lt;br/&gt;\\nE.g. Img2prompt, cannot good enough for flux to replicate an image. (joycaption is far better)&lt;br/&gt;\\nChinese recongition, let alone QwenVL or internVL from China, Mistral Small 2506 is much better than Gemma3 (I used Gemma 3 27B from Openrouter for a while).&lt;/p&gt;\\n\\n&lt;p&gt;And there is lots of Vision models, fintuned from Qwen2.5VL is quite usefully at many task. Some are good at OCR, some even can think (reasoning). Any speicified need, a well finetuned model is usually better, if their base model is not too outweighted others.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0rdniu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751378582,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lovqjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0r942t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"temech5","can_mod_post":false,"created_utc":1751377123,"send_replies":true,"parent_id":"t3_1lovqjc","score":7,"author_fullname":"t2_quw6zofb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try internvl3. Worked best for my tasks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0r942t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try internvl3. Worked best for my tasks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0r942t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751377123,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lovqjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ucnju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Current-Rabbit-620","can_mod_post":false,"created_utc":1751409225,"send_replies":true,"parent_id":"t1_n0qxbml","score":1,"author_fullname":"t2_9mvs9oc9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All qwen 2.5 vl are the best compared to equal sized rivals","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ucnju","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All qwen 2.5 vl are the best compared to equal sized rivals&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lovqjc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0ucnju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751409225,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qxbml","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tengo_harambe","can_mod_post":false,"created_utc":1751373029,"send_replies":true,"parent_id":"t3_1lovqjc","score":6,"author_fullname":"t2_sgx7w7mb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen2.5-VL-72B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qxbml","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen2.5-VL-72B&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lovqjc/best_local_model_for_vision/n0qxbml/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373029,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lovqjc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
