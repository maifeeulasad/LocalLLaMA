import{j as e}from"./index-CeRg6Q3f.js";import{R as l}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Which means it has to fullfill 2 requirements:\\n\\n- small, as it needs runing local, ideally no more than 2B;\\n- able to do agents work, means it shouldn't be very dumb;\\n\\neventhough you might ask why not using cloud api, well, it's a typical question about data sensetive and price.\\n\\nJust wanna talk about if this is a trend, or do we nearly this situation which can do agents, that can just work in local, with bareable speed and free price.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Is that possible built a local gemini-cli totally in local and workable?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lsye88","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.45,"author_flair_background_color":"#bbbdbf","subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","is_original_content":false,"author_fullname":"t2_huncw1e","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751799086,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Which means it has to fullfill 2 requirements:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;small, as it needs runing local, ideally no more than 2B;&lt;/li&gt;\\n&lt;li&gt;able to do agents work, means it shouldn&amp;#39;t be very dumb;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;eventhough you might ask why not using cloud api, well, it&amp;#39;s a typical question about data sensetive and price.&lt;/p&gt;\\n\\n&lt;p&gt;Just wanna talk about if this is a trend, or do we nearly this situation which can do agents, that can just work in local, with bareable speed and free price.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Llama 405B","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lsye88","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"LewisJin","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/","subreddit_subscribers":495650,"created_utc":1751799086,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1m64mk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Equivalent_Cut_5845","can_mod_post":false,"created_utc":1751799313,"send_replies":true,"parent_id":"t3_1lsye88","score":8,"author_fullname":"t2_1oy2v7xti6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean gemini cli is open source. Someone just need to make it use openai compatible api and hook it up to a local model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m64mk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean gemini cli is open source. Someone just need to make it use openai compatible api and hook it up to a local model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1m64mk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751799313,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsye88","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1mc9ze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"phhusson","can_mod_post":false,"created_utc":1751802443,"send_replies":true,"parent_id":"t1_n1m6tnl","score":5,"author_fullname":"t2_qwewv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's really not what this repository does. It exposes the free tokens of Gemini 2.5 Pro in Google Cloud you get through gemini-cli into an OpenAI-compatible server.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1mc9ze","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s really not what this repository does. It exposes the free tokens of Gemini 2.5 Pro in Google Cloud you get through gemini-cli into an OpenAI-compatible server.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsye88","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1mc9ze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751802443,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1m6tnl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1751799682,"send_replies":true,"parent_id":"t3_1lsye88","score":2,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Someone already did\\n\\nhttps://github.com/GewoonJaap/gemini-cli-openai?tab=readme-ov-file","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m6tnl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone already did&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/GewoonJaap/gemini-cli-openai?tab=readme-ov-file\\"&gt;https://github.com/GewoonJaap/gemini-cli-openai?tab=readme-ov-file&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1m6tnl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751799682,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsye88","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1m6ary","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustinPooDough","can_mod_post":false,"created_utc":1751799403,"send_replies":true,"parent_id":"t3_1lsye88","score":1,"author_fullname":"t2_4kns99rz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes if you learn to program you can do this. Something like Llama 3.2 3b could do this, but it would be crude and make mistakes.\\n\\nEven the best models still get stuck and make mistakes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m6ary","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes if you learn to program you can do this. Something like Llama 3.2 3b could do this, but it would be crude and make mistakes.&lt;/p&gt;\\n\\n&lt;p&gt;Even the best models still get stuck and make mistakes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1m6ary/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751799403,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsye88","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1m9ypo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"reginakinhi","can_mod_post":false,"created_utc":1751801306,"send_replies":true,"parent_id":"t3_1lsye88","score":2,"author_fullname":"t2_47jf22jq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The concept itself; sure. As someone pointed out, there already is a fork of gemini-cli that can work with any openAI compatible API endpoint. A 2B model doing agentic work seems questionable at best, however. There are some models that might be workable at isolated &amp; small tasks, but you aren't getting a rapid speed coding agent out of this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1m9ypo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The concept itself; sure. As someone pointed out, there already is a fork of gemini-cli that can work with any openAI compatible API endpoint. A 2B model doing agentic work seems questionable at best, however. There are some models that might be workable at isolated &amp;amp; small tasks, but you aren&amp;#39;t getting a rapid speed coding agent out of this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1m9ypo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751801306,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsye88","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1mej84","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"created_utc":1751803493,"send_replies":true,"parent_id":"t3_1lsye88","score":3,"author_fullname":"t2_e9jh97s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://github.com/google-gemini/gemini-cli/pull/1975\\n\\n/u/phhusson /u/admajic","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1mej84","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/google-gemini/gemini-cli/pull/1975\\"&gt;https://github.com/google-gemini/gemini-cli/pull/1975&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"/u/phhusson\\"&gt;/u/phhusson&lt;/a&gt; &lt;a href=\\"/u/admajic\\"&gt;/u/admajic&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsye88/is_that_possible_built_a_local_geminicli_totally/n1mej84/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751803493,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsye88","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
