import{j as e}from"./index-Dh2YTDbC.js";import{R as l}from"./RedditPostRenderer-BwWe7STC.js";import"./index-D7FMfiLd.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Automated-AI-Web-Researcher: After months of work, I've made a python program that turns local LLMs running on Ollama into online researchers for you, Literally type a single question or topic and wait until you come back to a text document full of research content with links to the sources and a summary and ask it questions too! and more!\\n\\n**What My Project Does**:\\n\\nThis automated researcher uses internet searching and web scraping to gather information, based on your topic or question of choice, it will generate focus areas relating to your topic designed to explore various aspects of your topic and investigate various related aspects of your topic or question to retrieve relevant information through online research to respond to your topic or question. The LLM breaks down your query into up to 5 specific research focuses, prioritising them based on relevance, then systematically investigates each one through targeted web searches and content analysis starting with the most relevant.\\n\\nThen after gathering the content from those searching and exhausting all of the focus areas, it will then review the content and use the information within to generate new focus areas, and in the past it has often finding new, relevant focus areas based on findings in research content it has already gathered (like specific case studies which it then looks for specifically relating to your topic or question for example), previously this use of research content already gathered to develop new areas to investigate has ended up leading to interesting and novel research focuses in some cases that would never occur to humans although mileage may vary this program is still a prototype but shockingly it, it actually works!.\\n\\nKey features:\\n\\n* Continuously generates new research focuses based on what it discovers\\n* Saves every piece of content it finds in full, along with source URLs\\n* Creates a comprehensive summary when you're done of the research contents and uses it to respond to your original query/question\\n* Enters conversation mode after providing the summary, where you can ask specific questions about its findings and research even things not mentioned in the summary should the research it found provide relevant information about said things.\\n* You can run it as long as you want until the LLM’s context is at it’s max which will then automatically stop it’s research and still allow for summary and questions to be asked. Or stop it at anytime which will cause it to generate the summary.\\n* But it also Includes pause feature to assess research progress to determine if enough has been gathered, allowing you the choice to unpause and continue or to terminate the research and receive the summary.\\n* Works with popular Ollama local models (recommended phi3:3.8b-mini-128k-instruct or phi3:14b-medium-128k-instruct which are the ones I have so far tested and have worked)\\n* Everything runs locally on your machine, and yet still gives you results from the internet with only a single query you can have a massive amount of actual research given back to you in a relatively short time.\\n\\nThe best part? You can let it run in the background while you do other things. Come back to find a detailed research document with dozens of relevant sources and extracted content, all organised and ready for review. Plus a summary of relevant findings AND able to ask the LLM questions about those findings. Perfect for research, hard to research and novel questions that you can’t be bothered to actually look into yourself, or just satisfying your curiosity about complex topics!\\n\\nGitHub repo with full instructions and a demo video:\\n\\n[https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama](https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama)\\n\\n(Built using Python, fully open source, and should work with any Ollama-compatible LLM, although only phi 3 has been tested by me)\\n\\n**Target Audience**:\\n\\nAnyone who values locally run LLMs, anyone who wants to do comprehensive research within a single input, anyone who like innovative and novel uses of AI which even large companies (to my knowledge) haven't tried yet.\\n\\nIf your into AI, if your curious about what it can do, how easily you can find quality information using it to find stuff for you online, check this out!\\n\\n**Comparison**:\\n\\nWhere this differs from per-existing programs and applications, is that it conducts research continuously with a single query online, for potentially hundreds of searches, gathering content from each search, saving that content into a document with the links to each website it gathered information from.\\n\\nAgain potentially hundreds of searches all from a single query, not just random searches either each is well thought out and explores various aspects of your topic/query to gather as much usable information as possible.\\n\\nNot only does it gather this information, but it summaries it all as well, extracting all the relevant aspects of the info it's gathered when you end it's research session, it goes through all it's found and gives you the important parts relevant to your question. Then you can still even ask it anything you want about the research it has found, which it will then use any of the info it has gathered to respond to your questions.\\n\\nTo top it all off compared to other services like how ChatGPT can search the internet, this is completely open source and 100% running locally on your own device, with any LLM model of your choosing although I have only tested Phi 3, others likely work too!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I Created an AI Research Assistant that actually DOES research! Feed it ANY topic, it searches the web, scrapes content, saves sources, and gives you a full research document + summary. Uses Ollama (FREE) - Just ask a question and let it work! No API costs, open source, runs locally!","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1gvlzug","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":null,"subreddit_type":"public","ups":1562,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_6247e517","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":1562,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1732098537,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1732096284,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Automated-AI-Web-Researcher: After months of work, I&amp;#39;ve made a python program that turns local LLMs running on Ollama into online researchers for you, Literally type a single question or topic and wait until you come back to a text document full of research content with links to the sources and a summary and ask it questions too! and more!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;What My Project Does&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;This automated researcher uses internet searching and web scraping to gather information, based on your topic or question of choice, it will generate focus areas relating to your topic designed to explore various aspects of your topic and investigate various related aspects of your topic or question to retrieve relevant information through online research to respond to your topic or question. The LLM breaks down your query into up to 5 specific research focuses, prioritising them based on relevance, then systematically investigates each one through targeted web searches and content analysis starting with the most relevant.&lt;/p&gt;\\n\\n&lt;p&gt;Then after gathering the content from those searching and exhausting all of the focus areas, it will then review the content and use the information within to generate new focus areas, and in the past it has often finding new, relevant focus areas based on findings in research content it has already gathered (like specific case studies which it then looks for specifically relating to your topic or question for example), previously this use of research content already gathered to develop new areas to investigate has ended up leading to interesting and novel research focuses in some cases that would never occur to humans although mileage may vary this program is still a prototype but shockingly it, it actually works!.&lt;/p&gt;\\n\\n&lt;p&gt;Key features:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Continuously generates new research focuses based on what it discovers&lt;/li&gt;\\n&lt;li&gt;Saves every piece of content it finds in full, along with source URLs&lt;/li&gt;\\n&lt;li&gt;Creates a comprehensive summary when you&amp;#39;re done of the research contents and uses it to respond to your original query/question&lt;/li&gt;\\n&lt;li&gt;Enters conversation mode after providing the summary, where you can ask specific questions about its findings and research even things not mentioned in the summary should the research it found provide relevant information about said things.&lt;/li&gt;\\n&lt;li&gt;You can run it as long as you want until the LLM’s context is at it’s max which will then automatically stop it’s research and still allow for summary and questions to be asked. Or stop it at anytime which will cause it to generate the summary.&lt;/li&gt;\\n&lt;li&gt;But it also Includes pause feature to assess research progress to determine if enough has been gathered, allowing you the choice to unpause and continue or to terminate the research and receive the summary.&lt;/li&gt;\\n&lt;li&gt;Works with popular Ollama local models (recommended phi3:3.8b-mini-128k-instruct or phi3:14b-medium-128k-instruct which are the ones I have so far tested and have worked)&lt;/li&gt;\\n&lt;li&gt;Everything runs locally on your machine, and yet still gives you results from the internet with only a single query you can have a massive amount of actual research given back to you in a relatively short time.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The best part? You can let it run in the background while you do other things. Come back to find a detailed research document with dozens of relevant sources and extracted content, all organised and ready for review. Plus a summary of relevant findings AND able to ask the LLM questions about those findings. Perfect for research, hard to research and novel questions that you can’t be bothered to actually look into yourself, or just satisfying your curiosity about complex topics!&lt;/p&gt;\\n\\n&lt;p&gt;GitHub repo with full instructions and a demo video:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama\\"&gt;https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;(Built using Python, fully open source, and should work with any Ollama-compatible LLM, although only phi 3 has been tested by me)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Target Audience&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;Anyone who values locally run LLMs, anyone who wants to do comprehensive research within a single input, anyone who like innovative and novel uses of AI which even large companies (to my knowledge) haven&amp;#39;t tried yet.&lt;/p&gt;\\n\\n&lt;p&gt;If your into AI, if your curious about what it can do, how easily you can find quality information using it to find stuff for you online, check this out!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Comparison&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;Where this differs from per-existing programs and applications, is that it conducts research continuously with a single query online, for potentially hundreds of searches, gathering content from each search, saving that content into a document with the links to each website it gathered information from.&lt;/p&gt;\\n\\n&lt;p&gt;Again potentially hundreds of searches all from a single query, not just random searches either each is well thought out and explores various aspects of your topic/query to gather as much usable information as possible.&lt;/p&gt;\\n\\n&lt;p&gt;Not only does it gather this information, but it summaries it all as well, extracting all the relevant aspects of the info it&amp;#39;s gathered when you end it&amp;#39;s research session, it goes through all it&amp;#39;s found and gives you the important parts relevant to your question. Then you can still even ask it anything you want about the research it has found, which it will then use any of the info it has gathered to respond to your questions.&lt;/p&gt;\\n\\n&lt;p&gt;To top it all off compared to other services like how ChatGPT can search the internet, this is completely open source and 100% running locally on your own device, with any LLM model of your choosing although I have only tested Phi 3, others likely work too!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?auto=webp&amp;s=213b60efdb4d236b610d87960df94f0ff0a3ba72","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d90818c328ebe96535c1ea182cbf06a1e489a23","width":108,"height":54},{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a0fbc7bd4cafd5ac89aee0ee7d47c16d0d655775","width":216,"height":108},{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cee05b718cd50418fee4c44b2045dee5befbf2b","width":320,"height":160},{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e2feb546e8bc486e8b5146feaac3316a79f400f","width":640,"height":320},{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7492385faa427cfdf5011d8d728d49818b17508","width":960,"height":480},{"url":"https://external-preview.redd.it/MHViIZts2uBQZiu2wLzu6MuHcRm68v6V6F2UVqfRN1k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f2b539e3473702067abd2bc4b2f022276da12e1","width":1080,"height":540}],"variants":{},"id":"iUaCf6BagQiGU62zOz1Z6bqg059VXHQhpiEBqqAEVlE"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1gvlzug","is_robot_indexable":true,"num_duplicates":3,"report_reasons":null,"author":"CuriousAustralianBoy","discussion_type":null,"num_comments":169,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/","subreddit_subscribers":492315,"created_utc":1732096284,"num_crossposts":4,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly85nem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ViperAMD","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5b9qc","score":3,"author_fullname":"t2_32o3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Use selenium base, even better!","edited":false,"author_flair_css_class":null,"name":"t1_ly85nem","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use selenium base, even better!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly85nem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732180377,"author_flair_text":null,"collapsed":false,"created_utc":1732180377,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lyae85b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RikuDesu","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5b9qc","score":2,"author_fullname":"t2_jvkux","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah scrapegraph ai does this well","edited":false,"author_flair_css_class":null,"name":"t1_lyae85b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah scrapegraph ai does this well&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lyae85b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732215258,"author_flair_text":null,"collapsed":false,"created_utc":1732215258,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5b9qc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JustinPooDough","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3a1o5","score":15,"author_fullname":"t2_4kns99rz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OP Should consider enhancing this with undetectable chrome driver and possibly also a proxy server rotation. Basically, implement strategies that existing industrial scraping solutions use.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5b9qc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP Should consider enhancing this with undetectable chrome driver and possibly also a proxy server rotation. Basically, implement strategies that existing industrial scraping solutions use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5b9qc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732130807,"author_flair_text":null,"treatment_tags":[],"created_utc":1732130807,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3a1o5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"help_all","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2wywx","score":22,"author_fullname":"t2_64rf6xn7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does it take care of bot detection when scraping sites. Most sites will have it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly3a1o5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it take care of bot detection when scraping sites. Most sites will have it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3a1o5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732106773,"author_flair_text":null,"treatment_tags":[],"created_utc":1732106773,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly56viu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MmmmMorphine","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2wywx","score":4,"author_fullname":"t2_ea78a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Phew, so glad someone beat me to the punch here. Knew something like this (background as well as active/chat-available knowledge development and iteration with 'versioning' and references using nearly exclusively local resources, to put it as briefly as possible) would be necessarily a part of my larger goal\\n\\nThank you for your work, this does look very promising indeed","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly56viu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phew, so glad someone beat me to the punch here. Knew something like this (background as well as active/chat-available knowledge development and iteration with &amp;#39;versioning&amp;#39; and references using nearly exclusively local resources, to put it as briefly as possible) would be necessarily a part of my larger goal&lt;/p&gt;\\n\\n&lt;p&gt;Thank you for your work, this does look very promising indeed&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly56viu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732129467,"author_flair_text":null,"treatment_tags":[],"created_utc":1732129467,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4hsx2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"David_Delaune","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2wywx","score":1,"author_fullname":"t2_e81mw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think it's a really neat project, thanks for sharing it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly4hsx2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think it&amp;#39;s a really neat project, thanks for sharing it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4hsx2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732121856,"author_flair_text":null,"treatment_tags":[],"created_utc":1732121856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2wywx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732099939,"send_replies":true,"parent_id":"t1_ly2vkkm","score":50,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks very much! Yeah it took a lot of thought and quite a lot of effort to get it functional I appreciate it! Let me know what you think!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2wywx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks very much! Yeah it took a lot of thought and quite a lot of effort to get it functional I appreciate it! Let me know what you think!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2wywx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732099939,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2vkkm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Fragrant-Purple504","can_mod_post":false,"created_utc":1732099062,"send_replies":true,"parent_id":"t3_1gvlzug","score":183,"author_fullname":"t2_rur29r7m2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Took a quick look and can see you've put some thought and effort into this, thanks for sharing! Will hopefully get to test it out this week.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2vkkm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Took a quick look and can see you&amp;#39;ve put some thought and effort into this, thanks for sharing! Will hopefully get to test it out this week.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2vkkm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732099062,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":183}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5tzy3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheTerrasque","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5plpc","score":48,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Most local llm solutions that offers an api support the openai api.\\n\\nEdit: Some local llm runners that have an openai endpoint:\\n\\n* KoboldCPP\\n* vLLM\\n* LM Studio\\n* Ollama\\n* oobabooga/text-generation-webui\\n* tabbyAPI\\n* llama.cpp server\\n\\nAlong with cloud solutions:\\n\\n* OpenRouter\\n* OpenAI\\n* Mistral (?)","edited":1732142860,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly5tzy3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most local llm solutions that offers an api support the openai api.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Some local llm runners that have an openai endpoint:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;KoboldCPP&lt;/li&gt;\\n&lt;li&gt;vLLM&lt;/li&gt;\\n&lt;li&gt;LM Studio&lt;/li&gt;\\n&lt;li&gt;Ollama&lt;/li&gt;\\n&lt;li&gt;oobabooga/text-generation-webui&lt;/li&gt;\\n&lt;li&gt;tabbyAPI&lt;/li&gt;\\n&lt;li&gt;llama.cpp server&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Along with cloud solutions:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;OpenRouter&lt;/li&gt;\\n&lt;li&gt;OpenAI&lt;/li&gt;\\n&lt;li&gt;Mistral (?)&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5tzy3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732141343,"author_flair_text":null,"treatment_tags":[],"created_utc":1732141343,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":48}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly61dxn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"my_name_isnt_clever","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5plpc","score":15,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I host my own LiteLLM proxy so I can run everything through it. If something supports openai spec I can use any models I want.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly61dxn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I host my own LiteLLM proxy so I can run everything through it. If something supports openai spec I can use any models I want.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly61dxn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732146188,"author_flair_text":null,"treatment_tags":[],"created_utc":1732146188,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6ige0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RazzmatazzReal4129","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5plpc","score":12,"author_fullname":"t2_flbicsbbj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think they mean openai api...not openai the hosted llm.  It's just a standard for communicating with a llm.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly6ige0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think they mean openai api...not openai the hosted llm.  It&amp;#39;s just a standard for communicating with a llm.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6ige0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732152674,"author_flair_text":null,"treatment_tags":[],"created_utc":1732152674,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly82ut8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"allegedrc4","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly70q3s","score":6,"author_fullname":"t2_d1duubmy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not even a necessary evil. It's just something that has OpenAI's name on it but nothing to do with them, from your perspective. It doesn't support them, it doesn't use their services, they don't make money off of it somehow.","edited":false,"author_flair_css_class":null,"name":"t1_ly82ut8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not even a necessary evil. It&amp;#39;s just something that has OpenAI&amp;#39;s name on it but nothing to do with them, from your perspective. It doesn&amp;#39;t support them, it doesn&amp;#39;t use their services, they don&amp;#39;t make money off of it somehow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly82ut8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732178497,"author_flair_text":null,"collapsed":false,"created_utc":1732178497,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"ly70q3s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5vg4e","score":-4,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"a necessary evil that doesn't really benefit OAI that much. I'll pay that tax.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly70q3s","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;a necessary evil that doesn&amp;#39;t really benefit OAI that much. I&amp;#39;ll pay that tax.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly70q3s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732159142,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1732159142,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5vg4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bunchedupwalrus","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5plpc","score":7,"author_fullname":"t2_lqk0d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s become the standard in a lot of ways tbf. Simplifies swapping providers from local to cloud etc","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly5vg4e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s become the standard in a lot of ways tbf. Simplifies swapping providers from local to cloud etc&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5vg4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732143096,"author_flair_text":null,"treatment_tags":[],"created_utc":1732143096,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6huv1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rhet0rica","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5plpc","score":5,"author_fullname":"t2_eki6y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To clarify the other responses, the API is just the protocol that chatbots use to communicate with frontends. Everyone standardized on the format that OpenAI originated for their own services because it was a decent design. Tools must use the same API to be compatible.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly6huv1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To clarify the other responses, the API is just the protocol that chatbots use to communicate with frontends. Everyone standardized on the format that OpenAI originated for their own services because it was a decent design. Tools must use the same API to be compatible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6huv1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732152462,"author_flair_text":null,"treatment_tags":[],"created_utc":1732152462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5plpc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bronkula","can_mod_post":false,"created_utc":1732138206,"send_replies":true,"parent_id":"t1_ly39fmp","score":12,"author_fullname":"t2_3nt9m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It seems odd to suggest supporting openai, when it seems the whole pitch is local llm usage.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5plpc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems odd to suggest supporting openai, when it seems the whole pitch is local llm usage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5plpc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732138206,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9rj66","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5wq69","score":5,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The reasons was because not of the code, would have worked it's made specifically for Ollama, if you just throw in a single open AI endpoint in the config file it's not gonna work hence the rejection!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly9rj66","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The reasons was because not of the code, would have worked it&amp;#39;s made specifically for Ollama, if you just throw in a single open AI endpoint in the config file it&amp;#39;s not gonna work hence the rejection!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9rj66/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732208522,"author_flair_text":null,"treatment_tags":[],"created_utc":1732208522,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9rld6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly61l4y","score":5,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The reasons was because not of the code, would have worked it's made specifically for Ollama, if you just throw in a single open AI endpoint in the config file it's not gonna work hence the rejection!","edited":false,"author_flair_css_class":null,"name":"t1_ly9rld6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The reasons was because not of the code, would have worked it&amp;#39;s made specifically for Ollama, if you just throw in a single open AI endpoint in the config file it&amp;#39;s not gonna work hence the rejection!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9rld6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732208540,"author_flair_text":null,"collapsed":false,"created_utc":1732208540,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9k5hr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"randomanoni","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly61l4y","score":3,"author_fullname":"t2_tmyziykn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, this project is not for power users. I mean: \\"1. Do not make up anything that isn't actually true.\\". \\nhttps://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama/blob/e3cb357c3b1ddd1d225e087e99dbf3fa3cf40e93/research_manager.py#L1361\\n\\nI know many of us have been there. Optimism and gratitude.","edited":false,"author_flair_css_class":null,"name":"t1_ly9k5hr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, this project is not for power users. I mean: &amp;quot;1. Do not make up anything that isn&amp;#39;t actually true.&amp;quot;. \\n&lt;a href=\\"https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama/blob/e3cb357c3b1ddd1d225e087e99dbf3fa3cf40e93/research_manager.py#L1361\\"&gt;https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama/blob/e3cb357c3b1ddd1d225e087e99dbf3fa3cf40e93/research_manager.py#L1361&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I know many of us have been there. Optimism and gratitude.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9k5hr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732206268,"author_flair_text":null,"collapsed":false,"created_utc":1732206268,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"ly61l4y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"my_name_isnt_clever","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5wq69","score":7,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is probably not the project for me then. That's a shame.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly61l4y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is probably not the project for me then. That&amp;#39;s a shame.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly61l4y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732146273,"author_flair_text":null,"treatment_tags":[],"created_utc":1732146273,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lystn8a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BedlamiteSeer","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5wq69","score":1,"author_fullname":"t2_ark0ssfd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You could fork the project.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lystn8a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could fork the project.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lystn8a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732481937,"author_flair_text":null,"treatment_tags":[],"created_utc":1732481937,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5wq69","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheTerrasque","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly5w5lx","score":7,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Someone already made a [PR](https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama/pull/1) for adding openai api support. .. Which got rejected.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly5wq69","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone already made a &lt;a href=\\"https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama/pull/1\\"&gt;PR&lt;/a&gt; for adding openai api support. .. Which got rejected.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5wq69/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732143821,"author_flair_text":null,"treatment_tags":[],"created_utc":1732143821,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5w5lx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"The_Seeker_25920","can_mod_post":false,"created_utc":1732143490,"send_replies":true,"parent_id":"t1_ly39fmp","score":1,"author_fullname":"t2_vanr6mzh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Great suggestions here, this is a cool project, maybe I’ll throw some of these in a PR","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5w5lx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great suggestions here, this is a cool project, maybe I’ll throw some of these in a PR&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5w5lx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732143490,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly39fmp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheTerrasque","can_mod_post":false,"created_utc":1732106505,"send_replies":true,"parent_id":"t3_1gvlzug","score":92,"author_fullname":"t2_9uv8v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks nice. I haven't really looked at the code yet, but some suggestions:\\n\\n* Put the non-user-runnable files in a subfolder, for example \\"lib\\". If you add an empty file called \\"\\\\_\\\\_init__.py\\" in that folder you can import python files from there like so : *\\"from lib.Self_Improving_Search import EnhancedSelfImprovingSearch\\"*\\n* Support openai api, most local services support it, along with cloud systems. That gives your project a long reach regarding backends. I think you might have some support already if you use llama.cpp server as a possible backend. \\n*  A bit more long term, but consider writing a REST api backend that wraps the functions, and a simple web frontend. qwen2.5-coder:72b or claude sonnet will probably manage to do most of this if you give it the relevant functions overview and a clear description of wanted functionality.\\n\\nEdit:\\n\\n* Get config from env vars / file / command line. Some options:\\n  * https://docs.pydantic.dev/latest/concepts/pydantic_settings/\\n  * https://github.com/omry/omegaconf\\n  * https://github.com/rbgirshick/yacs\\n  * And my own solution: https://github.com/TheTerrasque/python-configclass - Got a few problems the bigger ones does better, but is super easy to set up and is imho great for small projects","edited":1732106993,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly39fmp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks nice. I haven&amp;#39;t really looked at the code yet, but some suggestions:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Put the non-user-runnable files in a subfolder, for example &amp;quot;lib&amp;quot;. If you add an empty file called &amp;quot;__init__.py&amp;quot; in that folder you can import python files from there like so : &lt;em&gt;&amp;quot;from lib.Self_Improving_Search import EnhancedSelfImprovingSearch&amp;quot;&lt;/em&gt;&lt;/li&gt;\\n&lt;li&gt;Support openai api, most local services support it, along with cloud systems. That gives your project a long reach regarding backends. I think you might have some support already if you use llama.cpp server as a possible backend. &lt;/li&gt;\\n&lt;li&gt; A bit more long term, but consider writing a REST api backend that wraps the functions, and a simple web frontend. qwen2.5-coder:72b or claude sonnet will probably manage to do most of this if you give it the relevant functions overview and a clear description of wanted functionality.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Edit:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Get config from env vars / file / command line. Some options:\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;a href=\\"https://docs.pydantic.dev/latest/concepts/pydantic_settings/\\"&gt;https://docs.pydantic.dev/latest/concepts/pydantic_settings/&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://github.com/omry/omegaconf\\"&gt;https://github.com/omry/omegaconf&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://github.com/rbgirshick/yacs\\"&gt;https://github.com/rbgirshick/yacs&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;And my own solution: &lt;a href=\\"https://github.com/TheTerrasque/python-configclass\\"&gt;https://github.com/TheTerrasque/python-configclass&lt;/a&gt; - Got a few problems the bigger ones does better, but is super easy to set up and is imho great for small projects&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39fmp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732106505,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":92}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":46,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9rq1p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732208581,"send_replies":true,"parent_id":"t1_ly78wcn","score":5,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i'll look into it thanks for the suggestions I am very busy rn but i'll look into it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly9rq1p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;ll look into it thanks for the suggestions I am very busy rn but i&amp;#39;ll look into it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9rq1p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732208581,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lytxxem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Rooster_6215","can_mod_post":false,"send_replies":true,"parent_id":"t1_lytpcuj","score":1,"author_fullname":"t2_ds20at85","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"search Ordo Nexus / Nexus Bot / Nexus Search-- there are ones for requests, searches and dev info. Ones with most subscribers are right ones.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lytxxem","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;search Ordo Nexus / Nexus Bot / Nexus Search-- there are ones for requests, searches and dev info. Ones with most subscribers are right ones.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lytxxem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732495473,"author_flair_text":null,"treatment_tags":[],"created_utc":1732495473,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lytpcuj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AbrarHossainHimself","can_mod_post":false,"send_replies":true,"parent_id":"t1_lycenr9","score":1,"author_fullname":"t2_129fmm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can I get the link to the telegram channel?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lytpcuj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can I get the link to the telegram channel?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lytpcuj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732492411,"author_flair_text":null,"treatment_tags":[],"created_utc":1732492411,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"lycenr9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evening_Rooster_6215","can_mod_post":false,"created_utc":1732238979,"send_replies":true,"parent_id":"t1_ly78wcn","score":5,"author_fullname":"t2_ds20at85","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Scihub is no longer up to date-- Nexus STC project has picked up where they left off. Check that out as well. [https://libstc.cc/#/](https://libstc.cc/#/)  annd annas-archive mirrors part of it. Also have very active telegram bots/channels.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lycenr9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Scihub is no longer up to date-- Nexus STC project has picked up where they left off. Check that out as well. &lt;a href=\\"https://libstc.cc/#/\\"&gt;https://libstc.cc/#/&lt;/a&gt;  annd annas-archive mirrors part of it. Also have very active telegram bots/channels.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lycenr9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732238979,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly78wcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gvlzug","score":46,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly78wcn/","num_reports":null,"locked":false,"name":"t1_ly78wcn","created":1732162312,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732162312,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":43,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m2a85ev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madiscientist","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly7tfba","score":2,"author_fullname":"t2_islm4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"This isn't leading non-coders step by step, this is just basic documentation that should already be in the readme","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m2a85ev","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This isn&amp;#39;t leading non-coders step by step, this is just basic documentation that should already be in the readme&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/m2a85ev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1734323930,"author_flair_text":null,"treatment_tags":[],"created_utc":1734323930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly7tfba","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gilgameshcomputing","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly38n9f","score":2,"author_fullname":"t2_i5ettea7e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Brilliant, thank you for leading us non-coders step by step. Much appreciated 🙏🏻","edited":false,"author_flair_css_class":null,"name":"t1_ly7tfba","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Brilliant, thank you for leading us non-coders step by step. Much appreciated 🙏🏻&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7tfba/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732172469,"author_flair_text":null,"collapsed":false,"created_utc":1732172469,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly38n9f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly35x2z","score":34,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"well where are you getting stuck?  \\nYou need ollama, then after that's setup completely follow these steps (i'll put everything I can think of so that you don't miss any steps):\\n\\n1. in a terminal you type:  \\nollama serve  \\n2. now in another terminal window while the ollama serve window is still running you type:  \\nollama run phi3:3.8b-mini-128k-instruct-q6\\\\_K  \\n3. wait for it to install, then while your waiting, create a text file, remove the extension and all the name including the .txt and call it \\"MODELFILE\\"   \\n4. open up the MODELFILE and put inside:  \\nFROM phi3:3.8b-mini-128k-instruct-q6\\\\_K\\n\\nPARAMETER num\\\\_ctx 38000  \\n5. Once the model is done downloading and lets you talk to it from the ollama run window close the window and open a new one, make a python virtual environment by typing in the terminal (the first bit is to navigate to the program files):  \\ncd Automated-AI-Web-Researcher-Ollama  \\npython -m venv venv source venv/bin/activate  \\n6. then in that terminal once your in the virtual environment type:  \\npip install -r requirements.txt\\n\\n7. this will install the requirements, now when done you need to type (with the ollama serve window still running) in terminal (The one you are in from installing the requirements is fine):  \\nollama create research-phi3 -f MODELFILE\\n\\n8. now last thing before running the program, you go to llm\\\\_config.py script you will see a section that looks like this:  \\nLLM\\\\_CONFIG\\\\_OLLAMA = {\\n\\n\\"llm\\\\_type\\": \\"ollama\\",\\n\\n\\"base\\\\_url\\": \\"http://localhost:11434\\",  # default Ollama server URL\\n\\n\\"model\\\\_name\\": \\"custom-phi3-32k-Q4\\\\_K\\\\_M\\",  # Replace with your Ollama model name\\n\\n\\"temperature\\": 0.7,\\n\\n\\"top\\\\_p\\": 0.9,\\n\\n\\"n\\\\_ctx\\": 55000,\\n\\n\\"context\\\\_length\\": 55000,\\n\\n\\"stop\\": \\\\[\\"User:\\", \\"\\\\\\\\n\\\\\\\\n\\"\\\\]\\n\\n}  \\nWhere it says model name replace \\"custom-phi3-32k-Q4\\\\_K\\\\_M\\" with the model you just made with the model file which would be \\"research-phi3\\" Then save it.\\n\\n9. and now your ready to run the program! Ensure that you in the virtual environment otherwise it won't work because you installed the pre-requisites to the venv, simply cd to the project directory (or use the terminal you already had cd'd into the directory to install the requirements) and type in the terminal:  \\npython [Web-LLM.py](http://Web-LLM.py) \\n\\nAnd thats it should work! Please let me know if you have any issues! Sorry for the long guide I just wanted to make it as clear as possible!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly38n9f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well where are you getting stuck?&lt;br/&gt;\\nYou need ollama, then after that&amp;#39;s setup completely follow these steps (i&amp;#39;ll put everything I can think of so that you don&amp;#39;t miss any steps):&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;in a terminal you type:&lt;br/&gt;\\nollama serve&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;now in another terminal window while the ollama serve window is still running you type:&lt;br/&gt;\\nollama run phi3:3.8b-mini-128k-instruct-q6_K&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;wait for it to install, then while your waiting, create a text file, remove the extension and all the name including the .txt and call it &amp;quot;MODELFILE&amp;quot;&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;open up the MODELFILE and put inside:&lt;br/&gt;\\nFROM phi3:3.8b-mini-128k-instruct-q6_K&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;PARAMETER num_ctx 38000&lt;br/&gt;\\n5. Once the model is done downloading and lets you talk to it from the ollama run window close the window and open a new one, make a python virtual environment by typing in the terminal (the first bit is to navigate to the program files):&lt;br/&gt;\\ncd Automated-AI-Web-Researcher-Ollama&lt;br/&gt;\\npython -m venv venv source venv/bin/activate&lt;br/&gt;\\n6. then in that terminal once your in the virtual environment type:&lt;br/&gt;\\npip install -r requirements.txt&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;this will install the requirements, now when done you need to type (with the ollama serve window still running) in terminal (The one you are in from installing the requirements is fine):&lt;br/&gt;\\nollama create research-phi3 -f MODELFILE&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;now last thing before running the program, you go to llm_config.py script you will see a section that looks like this:&lt;br/&gt;\\nLLM_CONFIG_OLLAMA = {&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;&amp;quot;llm_type&amp;quot;: &amp;quot;ollama&amp;quot;,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;base_url&amp;quot;: &amp;quot;http://localhost:11434&amp;quot;,  # default Ollama server URL&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;model_name&amp;quot;: &amp;quot;custom-phi3-32k-Q4_K_M&amp;quot;,  # Replace with your Ollama model name&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;temperature&amp;quot;: 0.7,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;top_p&amp;quot;: 0.9,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;n_ctx&amp;quot;: 55000,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;context_length&amp;quot;: 55000,&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;stop&amp;quot;: [&amp;quot;User:&amp;quot;, &amp;quot;\\\\n\\\\n&amp;quot;]&lt;/p&gt;\\n\\n&lt;p&gt;}&lt;br/&gt;\\nWhere it says model name replace &amp;quot;custom-phi3-32k-Q4_K_M&amp;quot; with the model you just made with the model file which would be &amp;quot;research-phi3&amp;quot; Then save it.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;and now your ready to run the program! Ensure that you in the virtual environment otherwise it won&amp;#39;t work because you installed the pre-requisites to the venv, simply cd to the project directory (or use the terminal you already had cd&amp;#39;d into the directory to install the requirements) and type in the terminal:&lt;br/&gt;\\npython &lt;a href=\\"http://Web-LLM.py\\"&gt;Web-LLM.py&lt;/a&gt; &lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;And thats it should work! Please let me know if you have any issues! Sorry for the long guide I just wanted to make it as clear as possible!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly38n9f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732106150,"author_flair_text":null,"treatment_tags":[],"created_utc":1732106150,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}}],"before":null}},"user_reports":[],"saved":false,"id":"ly35x2z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Purple-Test-7139","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2xnp6","score":5,"author_fullname":"t2_timynfdz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’m still not super sure on how to set it up. This might be too basic. But would it be possible for you to give slightly more detailed / exact syntax for the setup.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly35x2z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m still not super sure on how to set it up. This might be too basic. But would it be possible for you to give slightly more detailed / exact syntax for the setup.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly35x2z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732104870,"author_flair_text":null,"treatment_tags":[],"created_utc":1732104870,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2xnp6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732100361,"send_replies":true,"parent_id":"t1_ly2x6qm","score":22,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"haha thanks I just fixed the readme, I was in a rush to get it out there.\\n\\nand yeah the llm\\\\_config.py file is where you change the name and stuff!  \\nthanks for your input, I was speechless too when I saw how it worked, shocked at first by the numerous NUMEROUS bugs I had to painstakingly fix, but then after that I was just shocked I could make something like this in a month or two, although I did spend most of my time on it, just glad it seems to have resulted in something quite cool by the end!  \\nbut let me know what you think!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2xnp6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;haha thanks I just fixed the readme, I was in a rush to get it out there.&lt;/p&gt;\\n\\n&lt;p&gt;and yeah the llm_config.py file is where you change the name and stuff!&lt;br/&gt;\\nthanks for your input, I was speechless too when I saw how it worked, shocked at first by the numerous NUMEROUS bugs I had to painstakingly fix, but then after that I was just shocked I could make something like this in a month or two, although I did spend most of my time on it, just glad it seems to have resulted in something quite cool by the end!&lt;br/&gt;\\nbut let me know what you think!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2xnp6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100361,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2x6qm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gvlzug","score":43,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Oh wow! What a share! I'm kinda speechless but I have to say thank you! Really!\\n\\nI even managed to get this going. It's going right now, so I can't say how it works out in the end but apparently it's going very well! I was dumb-funded at first to what I was even going to research as a test lol.\\n\\nBtw, in the instructions for git clone, you have \\"YourUserName\\" instead of your actual github name, just FYI.\\n\\nOh and I found that I actually had to name the Ollama model \\"custom-phi3-32k-Q4\\\\_K\\\\_M\\", regardless of which I used in the FROM field in the \\"Modelfile\\" file (I used mistral-nemo 12B Q4\\\\_0 atm). At 38000 context length, my 16 GB VRAM divides it at 3% CPU / 97% GPU (so not much slowdown).\\n\\n(Ah, I found where to change the model name now, guess I should RTFM to the end 😁)\\n\\n\\n\\nEDIT: I also want to add I'm actually pretty tired atm but I just HAD to test this! Awesome stuff, awesome share, thank you!","edited":1732100342,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh wow! What a share! I&amp;#39;m kinda speechless but I have to say thank you! Really!&lt;/p&gt;\\n\\n&lt;p&gt;I even managed to get this going. It&amp;#39;s going right now, so I can&amp;#39;t say how it works out in the end but apparently it&amp;#39;s going very well! I was dumb-funded at first to what I was even going to research as a test lol.&lt;/p&gt;\\n\\n&lt;p&gt;Btw, in the instructions for git clone, you have &amp;quot;YourUserName&amp;quot; instead of your actual github name, just FYI.&lt;/p&gt;\\n\\n&lt;p&gt;Oh and I found that I actually had to name the Ollama model &amp;quot;custom-phi3-32k-Q4_K_M&amp;quot;, regardless of which I used in the FROM field in the &amp;quot;Modelfile&amp;quot; file (I used mistral-nemo 12B Q4_0 atm). At 38000 context length, my 16 GB VRAM divides it at 3% CPU / 97% GPU (so not much slowdown).&lt;/p&gt;\\n\\n&lt;p&gt;(Ah, I found where to change the model name now, guess I should RTFM to the end 😁)&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: I also want to add I&amp;#39;m actually pretty tired atm but I just HAD to test this! Awesome stuff, awesome share, thank you!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2x6qm/","num_reports":null,"locked":false,"name":"t1_ly2x6qm","created":1732100073,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732100073,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly7igag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"solidsnakeblue","can_mod_post":false,"created_utc":1732166544,"send_replies":true,"parent_id":"t1_ly4f5ji","score":5,"author_fullname":"t2_7zh6fslk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I solved this by importing 'windows-curses', hope it helps","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7igag","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I solved this by importing &amp;#39;windows-curses&amp;#39;, hope it helps&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7igag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732166544,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly81cvc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simqune","can_mod_post":false,"created_utc":1732177478,"send_replies":true,"parent_id":"t1_ly4f5ji","score":2,"author_fullname":"t2_gegdmk1tt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, on windows you wanna open the requirements.txt and change curses-windows to windows-curses","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly81cvc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, on windows you wanna open the requirements.txt and change curses-windows to windows-curses&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly81cvc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732177478,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9d1ki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GreenHell","can_mod_post":false,"created_utc":1732201131,"send_replies":true,"parent_id":"t1_ly4f5ji","score":1,"author_fullname":"t2_6518p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Someone already made a few pull requests to fix the Windows issues.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly9d1ki","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone already made a few pull requests to fix the Windows issues.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9d1ki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732201131,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly4f5ji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AdHominemMeansULost","can_mod_post":false,"created_utc":1732121045,"send_replies":true,"parent_id":"t3_1gvlzug","score":9,"author_fullname":"t2_x6jz1gh7w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the curses requirement you have doesnt exist on windows","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4f5ji","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the curses requirement you have doesnt exist on windows&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4f5ji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732121045,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4vlgt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LeBoulu777","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2uprk","score":-1,"author_fullname":"t2_30xcxoa9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; my computer isn't very powerful \\n\\nI'm new to AI and I'm building a computer with 2 X 3060 = 24gb vram, would it be enough to use your script in a efficient way? 🤔","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly4vlgt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;my computer isn&amp;#39;t very powerful &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m new to AI and I&amp;#39;m building a computer with 2 X 3060 = 24gb vram, would it be enough to use your script in a efficient way? 🤔&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4vlgt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732126051,"author_flair_text":null,"treatment_tags":[],"created_utc":1732126051,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2uprk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732098508,"send_replies":true,"parent_id":"t1_ly2tj7i","score":28,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"haha I just uploaded a video demo to the github before I saw this comment, check it out!  \\nand no I have not, my computer isn't very powerful and I was very focused on getting it working properly rather then testing different LLMs if you feel like testing it though, i'd be curious to hear how it performs!  \\nall good if not though I am just happy it's done took months!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2uprk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;haha I just uploaded a video demo to the github before I saw this comment, check it out!&lt;br/&gt;\\nand no I have not, my computer isn&amp;#39;t very powerful and I was very focused on getting it working properly rather then testing different LLMs if you feel like testing it though, i&amp;#39;d be curious to hear how it performs!&lt;br/&gt;\\nall good if not though I am just happy it&amp;#39;s done took months!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2uprk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732098508,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":9,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3v7lg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ab2377","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3fxr5","score":1,"author_fullname":"t2_144o7g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3v7lg","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3v7lg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732114720,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1732114720,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly44hl2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GimmePanties","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly42lyw","score":16,"author_fullname":"t2_o42ku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Off course it works, lol, I wouldn't have submitted it without testing. It's not thousands of lines of code that needed to be rewritten, the API endpoint is an abstraction, so whether you're passing the prompt to ollama, or llama.cpp or passing it to the openAI library (which has the thousands of lines of code already written for you), its functionally the same to the rest of your code in that it returns a response.\\n\\nAll the local providers (LMStudio, Ollama, Oobabooga, Kobold, etc) provide an OpenAI compatible endpoint, as do most of the online providers. The nice part of this for a developer is that you can write one bit of code, and then repoint to different providers just by changing the base\\\\_url, model and optionally, the api\\\\_key.\\n\\nAnthropic is the only one I can think of that doesn't have an openAI endpoint now that Google implemented one last week. But Anthropic has their own library which is just as simple to call.","edited":false,"author_flair_css_class":null,"name":"t1_ly44hl2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Off course it works, lol, I wouldn&amp;#39;t have submitted it without testing. It&amp;#39;s not thousands of lines of code that needed to be rewritten, the API endpoint is an abstraction, so whether you&amp;#39;re passing the prompt to ollama, or llama.cpp or passing it to the openAI library (which has the thousands of lines of code already written for you), its functionally the same to the rest of your code in that it returns a response.&lt;/p&gt;\\n\\n&lt;p&gt;All the local providers (LMStudio, Ollama, Oobabooga, Kobold, etc) provide an OpenAI compatible endpoint, as do most of the online providers. The nice part of this for a developer is that you can write one bit of code, and then repoint to different providers just by changing the base_url, model and optionally, the api_key.&lt;/p&gt;\\n\\n&lt;p&gt;Anthropic is the only one I can think of that doesn&amp;#39;t have an openAI endpoint now that Google implemented one last week. But Anthropic has their own library which is just as simple to call.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44hl2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117718,"author_flair_text":null,"collapsed":false,"created_utc":1732117718,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"ly42lyw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3fxr5","score":2,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I reviewed it, does it work? I really would be surprised, like none of the functions are written for it and theres thousands of lines of code, if it works that's great I just seriously don't think it would based on what I say in your code.\\n\\nBut if it does please let me know!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly42lyw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I reviewed it, does it work? I really would be surprised, like none of the functions are written for it and theres thousands of lines of code, if it works that&amp;#39;s great I just seriously don&amp;#39;t think it would based on what I say in your code.&lt;/p&gt;\\n\\n&lt;p&gt;But if it does please let me know!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly42lyw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117127,"author_flair_text":null,"treatment_tags":[],"created_utc":1732117127,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3fxr5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GimmePanties","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly329tk","score":15,"author_fullname":"t2_o42ku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It wasn’t hard at all. I added support for Anthropic and OpenAI / OpenAI like models. That would let you use it with Kobold and Oobabooga because they support OpenAi calls, just set your server as the base URL. \\n\\nI’ve sent OP a PR, but you can grab the fork here: https://github.com/NimbleAINinja/Automated-AI-Web-Researcher-Hosted - the files you want are llm_config.py and llm_wrapper.py","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly3fxr5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It wasn’t hard at all. I added support for Anthropic and OpenAI / OpenAI like models. That would let you use it with Kobold and Oobabooga because they support OpenAi calls, just set your server as the base URL. &lt;/p&gt;\\n\\n&lt;p&gt;I’ve sent OP a PR, but you can grab the fork here: &lt;a href=\\"https://github.com/NimbleAINinja/Automated-AI-Web-Researcher-Hosted\\"&gt;https://github.com/NimbleAINinja/Automated-AI-Web-Researcher-Hosted&lt;/a&gt; - the files you want are llm_config.py and llm_wrapper.py&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3fxr5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109213,"author_flair_text":null,"treatment_tags":[],"created_utc":1732109213,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"ly329tk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2tj7i","score":9,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly329tk/","num_reports":null,"locked":false,"name":"t1_ly329tk","created":1732103022,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732103022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2tj7i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"theeditor__","can_mod_post":false,"created_utc":1732097736,"send_replies":true,"parent_id":"t3_1gvlzug","score":16,"author_fullname":"t2_180bh4tqoc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"nice! Have you tried using more powerful LLMs? A video demo would be nice!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2tj7i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nice! Have you tried using more powerful LLMs? A video demo would be nice!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2tj7i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732097736,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lybytl7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"snorkfroken__","can_mod_post":false,"created_utc":1732233229,"send_replies":true,"parent_id":"t1_ly5yd0l","score":2,"author_fullname":"t2_trancnd5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"+1!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lybytl7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;+1!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lybytl7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732233229,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly5yd0l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"planetearth80","can_mod_post":false,"created_utc":1732144724,"send_replies":true,"parent_id":"t3_1gvlzug","score":6,"author_fullname":"t2_tqgev","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please consider adding docker support. Great work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5yd0l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please consider adding docker support. Great work!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5yd0l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732144724,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly57oho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DomeGIS","can_mod_post":false,"created_utc":1732129712,"send_replies":true,"parent_id":"t3_1gvlzug","score":6,"author_fullname":"t2_m87h5f129","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey this is great, this was exactly what I was looking for! I was always wondering why nobody built it so far.  \\nI just had a peak at the web scraping part and noted that it \\"only\\" scrapes the html part. if you call it \\"research\\" assistant it might be mistaken for academic research which would require scientific resources like papers.\\n\\nIn case you want to consider Google Scholar papers as additional resource: [https://github.com/do-me/research-agent](https://github.com/do-me/research-agent) It's very simple but works.  \\nA friend of mine developed something more advanced: [https://github.com/ferru97/PyPaperBot](https://github.com/ferru97/PyPaperBot)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly57oho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey this is great, this was exactly what I was looking for! I was always wondering why nobody built it so far.&lt;br/&gt;\\nI just had a peak at the web scraping part and noted that it &amp;quot;only&amp;quot; scrapes the html part. if you call it &amp;quot;research&amp;quot; assistant it might be mistaken for academic research which would require scientific resources like papers.&lt;/p&gt;\\n\\n&lt;p&gt;In case you want to consider Google Scholar papers as additional resource: &lt;a href=\\"https://github.com/do-me/research-agent\\"&gt;https://github.com/do-me/research-agent&lt;/a&gt; It&amp;#39;s very simple but works.&lt;br/&gt;\\nA friend of mine developed something more advanced: &lt;a href=\\"https://github.com/ferru97/PyPaperBot\\"&gt;https://github.com/ferru97/PyPaperBot&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly57oho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732129712,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly46fdn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eugr","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly42amz","score":5,"author_fullname":"t2_f3l6q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can send context window size in a request. For Ollama it’s n_ctx parameter in options. You could even set it automatically to max size the model supports by reading model info and getting its trained context size from there.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly46fdn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can send context window size in a request. For Ollama it’s n_ctx parameter in options. You could even set it automatically to max size the model supports by reading model info and getting its trained context size from there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly46fdn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732118318,"author_flair_text":null,"treatment_tags":[],"created_utc":1732118318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly8yao6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Refrigerator-1672","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly42amz","score":1,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So I gave the script another go with phi3:14b. This time it actually generated various research topics and it looked like it actually does the proper research, but it still generates garbage in summaries. It looks like heavy hallucinations, so I guess the temperature is way too high. I will later give it one final go with phi3:3.8b as per your github page.\\n\\n&gt;================================================================================\\n\\n&gt;RESEARCH SUMMARY\\n\\n&gt;================================================================================\\n\\n&gt;\\n\\n&gt;Original Query: Find out how to detect hydrogen peroxide with electrochemical sensors using nanostructured metal oxide electrodes. Use academic research if possible.\\n\\n&gt;Generated on: 2024-11-21 13:15:04\\n\\n&gt;\\n\\n&gt;Here is the topic of detecting hydrogen peroxide with electrochemical sensors using nanostructure-based metal oxides. The objective is to design a transmission electron microscope and observes in-situation. Metal oxides nitride (a) Sensitivity, response speed, and so on\\n\\n&gt;&lt;|assistant|&gt;&lt;|assistant|&gt;&lt;|assistant|&gt;&lt;|assistant|&gt; 12:\\n\\n&gt;\\n\\n&gt;================================================================================\\n\\n&gt;End of Summary\\n\\n&gt;================================================================================\\n\\nI didn't adjust the default model's context length; but I don't consider this as a problem cause your readme asks for 38k long context, and Ollama actually defaults to 128k for phi3, so I can't see how this can be an issue.\\n\\n\`root@ollama:~# ollama show phi3:14b\`\\n\\n\`Model\`\\n\\n\`architecture phi3\`\\n\\n\`parameters 14.0B\`\\n\\n\`context length 131072\`\\n\\n\`embedding length 5120\`\\n\\n\`quantization Q4_0\`\\n\\n\`Parameters\`\\n\\n\`stop \\"&lt;|end|&gt;\\"\`\\n\\n\`stop \\"&lt;|user|&gt;\\"\`\\n\\n\`stop \\"&lt;|assistant|&gt;\\"\`\\n\\n\`License\`\\n\\n\`Microsoft.\`\\n\\n\`Copyright (c) Microsoft Corporation.\`","edited":1732196110,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly8yao6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I gave the script another go with phi3:14b. This time it actually generated various research topics and it looked like it actually does the proper research, but it still generates garbage in summaries. It looks like heavy hallucinations, so I guess the temperature is way too high. I will later give it one final go with phi3:3.8b as per your github page.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;RESEARCH SUMMARY&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;Original Query: Find out how to detect hydrogen peroxide with electrochemical sensors using nanostructured metal oxide electrodes. Use academic research if possible.&lt;/p&gt;\\n\\n&lt;p&gt;Generated on: 2024-11-21 13:15:04&lt;/p&gt;\\n\\n&lt;p&gt;Here is the topic of detecting hydrogen peroxide with electrochemical sensors using nanostructure-based metal oxides. The objective is to design a transmission electron microscope and observes in-situation. Metal oxides nitride (a) Sensitivity, response speed, and so on&lt;/p&gt;\\n\\n&lt;p&gt;&amp;lt;|assistant|&amp;gt;&amp;lt;|assistant|&amp;gt;&amp;lt;|assistant|&amp;gt;&amp;lt;|assistant|&amp;gt; 12:&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;End of Summary&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I didn&amp;#39;t adjust the default model&amp;#39;s context length; but I don&amp;#39;t consider this as a problem cause your readme asks for 38k long context, and Ollama actually defaults to 128k for phi3, so I can&amp;#39;t see how this can be an issue.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;root@ollama:~# ollama show phi3:14b&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;Model&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;architecture phi3&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;parameters 14.0B&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;context length 131072&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;embedding length 5120&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;quantization Q4_0&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;Parameters&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;stop &amp;quot;&amp;lt;|end|&amp;gt;&amp;quot;&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;stop &amp;quot;&amp;lt;|user|&amp;gt;&amp;quot;&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;stop &amp;quot;&amp;lt;|assistant|&amp;gt;&amp;quot;&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;License&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;Microsoft.&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;Copyright (c) Microsoft Corporation.&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly8yao6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732195768,"author_flair_text":null,"treatment_tags":[],"created_utc":1732195768,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly42amz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117027,"send_replies":true,"parent_id":"t1_ly380k1","score":15,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah I also found llama3 to work, honestly try phi 3 instead it's just a quick download away! again it's literally the model I tested the whole program with so I have no clue what any others are liable to do, you can try medium or mini  \\nHOWEVER as I specified in the instructions on the github page, you need to make a new custom model because even models that should hard larger context sizes are for some reason defaulting to like 2k tokens max, so if you don't do that, it could explain the lack of summary as the LLM just runs out of context after like 2 searches, but that's just a theory!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly42amz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah I also found llama3 to work, honestly try phi 3 instead it&amp;#39;s just a quick download away! again it&amp;#39;s literally the model I tested the whole program with so I have no clue what any others are liable to do, you can try medium or mini&lt;br/&gt;\\nHOWEVER as I specified in the instructions on the github page, you need to make a new custom model because even models that should hard larger context sizes are for some reason defaulting to like 2k tokens max, so if you don&amp;#39;t do that, it could explain the lack of summary as the LLM just runs out of context after like 2 searches, but that&amp;#39;s just a theory!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly42amz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117027,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"ly380k1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1732105859,"send_replies":true,"parent_id":"t3_1gvlzug","score":13,"author_fullname":"t2_baavelp5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've tried this script and want to provide some feedback:\\n\\nI don't have the phi3 downloaded, so I tried the script both with Lamma3.2-vision:11b and Qwen2.5:14b, giving them up to 15 minutes to do the research. In both cases, the script did not work as expected. Both models generate completely empty research summaries. Both models always investigate the same search query over and over again, occasionally changing 1 or 2 words in the query. Llama3.2-vision always assesses the research as sufficient, but then generates empty summaries and anwers that there's not enough data in q&amp;a mode. Qwen2.5 seems to adequately assess the research itself, but completely fails at q&amp;a. At this moment it seems like the project is incompatible with anything but phi3. I may donwload phi3 and test it again later.\\n\\nIn case if you need an example, below is my test results with Qwen 2.5.\\n\\n&gt;================================================================================\\n\\n&gt;RESEARCH SUMMARY\\n\\n&gt;================================================================================\\n\\n&gt;Original Query: Compare Tesla M40 and P102-100 refromance for LLM inference using llama.cpp, ollama, exllamav2, vllm, and possibly other software if you find it.\\n\\n&gt;Generated on: 2024-11-20 12:19:13\\n\\n&gt;\\\\### Comparison of Tesla M40 and P102-100 for LLM Inference Using llama.cpp, ollama, exllamav2, vllm\\n\\n&gt;================================================================================\\n\\n&gt;End of Summary\\n\\n&gt;================================================================================\\n\\n&gt;================================================================================\\n\\n&gt;Research Conversation Mode\\n\\n&gt;================================================================================\\n\\n&gt;Instructions:\\n\\n&gt;\\\\- Type your question and press CTRL+D to submit\\n\\n&gt;\\\\- Type 'quit' and press CTRL+D to exit\\n\\n&gt;\\\\- Your messages appear in green\\n\\n&gt;\\\\- AI responses appear in cyan\\n\\n&gt;Your question (Press CTRL+D to submit):\\n\\n&gt;So what's your verdict?\\n\\n&gt;Submitted question:\\n\\n&gt;So what's your verdict?\\n\\n&gt;AI Response:\\n\\n&gt;Based on the provided research content:\\n\\n&gt;\\\\--------------------------------------------------------------------------------\\n\\n&gt;Your question (Press CTRL+D to submit):","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly380k1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tried this script and want to provide some feedback:&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t have the phi3 downloaded, so I tried the script both with Lamma3.2-vision:11b and Qwen2.5:14b, giving them up to 15 minutes to do the research. In both cases, the script did not work as expected. Both models generate completely empty research summaries. Both models always investigate the same search query over and over again, occasionally changing 1 or 2 words in the query. Llama3.2-vision always assesses the research as sufficient, but then generates empty summaries and anwers that there&amp;#39;s not enough data in q&amp;amp;a mode. Qwen2.5 seems to adequately assess the research itself, but completely fails at q&amp;amp;a. At this moment it seems like the project is incompatible with anything but phi3. I may donwload phi3 and test it again later.&lt;/p&gt;\\n\\n&lt;p&gt;In case if you need an example, below is my test results with Qwen 2.5.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;RESEARCH SUMMARY&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;Original Query: Compare Tesla M40 and P102-100 refromance for LLM inference using llama.cpp, ollama, exllamav2, vllm, and possibly other software if you find it.&lt;/p&gt;\\n\\n&lt;p&gt;Generated on: 2024-11-20 12:19:13&lt;/p&gt;\\n\\n&lt;p&gt;### Comparison of Tesla M40 and P102-100 for LLM Inference Using llama.cpp, ollama, exllamav2, vllm&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;End of Summary&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;Research Conversation Mode&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;Instructions:&lt;/p&gt;\\n\\n&lt;p&gt;- Type your question and press CTRL+D to submit&lt;/p&gt;\\n\\n&lt;p&gt;- Type &amp;#39;quit&amp;#39; and press CTRL+D to exit&lt;/p&gt;\\n\\n&lt;p&gt;- Your messages appear in green&lt;/p&gt;\\n\\n&lt;p&gt;- AI responses appear in cyan&lt;/p&gt;\\n\\n&lt;p&gt;Your question (Press CTRL+D to submit):&lt;/p&gt;\\n\\n&lt;p&gt;So what&amp;#39;s your verdict?&lt;/p&gt;\\n\\n&lt;p&gt;Submitted question:&lt;/p&gt;\\n\\n&lt;p&gt;So what&amp;#39;s your verdict?&lt;/p&gt;\\n\\n&lt;p&gt;AI Response:&lt;/p&gt;\\n\\n&lt;p&gt;Based on the provided research content:&lt;/p&gt;\\n\\n&lt;p&gt;--------------------------------------------------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;Your question (Press CTRL+D to submit):&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly380k1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732105859,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly8v3gn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wizardpostulate","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly7hqnb","score":5,"author_fullname":"t2_gbhdidcq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/hafeezhmha/Automated-AI-Web-Researcher-Ollama.git](https://github.com/hafeezhmha/Automated-AI-Web-Researcher-Ollama.git) here's the windows implementation if you wanna try!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly8v3gn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/hafeezhmha/Automated-AI-Web-Researcher-Ollama.git\\"&gt;https://github.com/hafeezhmha/Automated-AI-Web-Researcher-Ollama.git&lt;/a&gt; here&amp;#39;s the windows implementation if you wanna try!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly8v3gn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732194495,"author_flair_text":null,"treatment_tags":[],"created_utc":1732194495,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly7hqnb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"solidsnakeblue","can_mod_post":false,"created_utc":1732166203,"send_replies":true,"parent_id":"t1_ly6670e","score":3,"author_fullname":"t2_7zh6fslk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ChatGPT and I re-wrote the parts around the termios problem and got it running.  So far I've got it working with:\\n\\nLM Studio  \\nOpenAI  \\nOpenRouter  \\nGoogle API via an OpenAI proxy\\n\\nThis thing is great!  I've been making some tweaks to the amount it scrapes per site and the amount of sites\\n\\nIt doesn't seem to summarize correctly.  I'm having to manually grab the .txt file and give it to the AI manually, I'll try to solve that next","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7hqnb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ChatGPT and I re-wrote the parts around the termios problem and got it running.  So far I&amp;#39;ve got it working with:&lt;/p&gt;\\n\\n&lt;p&gt;LM Studio&lt;br/&gt;\\nOpenAI&lt;br/&gt;\\nOpenRouter&lt;br/&gt;\\nGoogle API via an OpenAI proxy&lt;/p&gt;\\n\\n&lt;p&gt;This thing is great!  I&amp;#39;ve been making some tweaks to the amount it scrapes per site and the amount of sites&lt;/p&gt;\\n\\n&lt;p&gt;It doesn&amp;#39;t seem to summarize correctly.  I&amp;#39;m having to manually grab the .txt file and give it to the AI manually, I&amp;#39;ll try to solve that next&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7hqnb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732166203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"ly6670e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"solidsnakeblue","can_mod_post":false,"created_utc":1732148081,"send_replies":true,"parent_id":"t3_1gvlzug","score":5,"author_fullname":"t2_7zh6fslk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How are all the Windows users getting this to run?  Getting a \\"No Module Named 'termios'\\" error (research\\\\_manager.py line 17) and google suggests that's not something Windows can install.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6670e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are all the Windows users getting this to run?  Getting a &amp;quot;No Module Named &amp;#39;termios&amp;#39;&amp;quot; error (research_manager.py line 17) and google suggests that&amp;#39;s not something Windows can install.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6670e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732148081,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly70wxo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"created_utc":1732159213,"send_replies":true,"parent_id":"t1_ly3gbn8","score":0,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ollama is as user-friendly as these tools get I feel. It's worth spending 15 minutes or so with to figure it out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly70wxo","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama is as user-friendly as these tools get I feel. It&amp;#39;s worth spending 15 minutes or so with to figure it out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly70wxo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732159213,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly42qp2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117168,"send_replies":true,"parent_id":"t1_ly3gbn8","score":1,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it was written for ollama I have never used LM Studio unfortunately","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly42qp2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it was written for ollama I have never used LM Studio unfortunately&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly42qp2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117168,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3gbn8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Arkonias","can_mod_post":false,"created_utc":1732109365,"send_replies":true,"parent_id":"t3_1gvlzug","score":9,"author_fullname":"t2_6jyyd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't use ollama, I use LM Studio. Is it easy to use the LM Studio API with it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3gbn8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t use ollama, I use LM Studio. Is it easy to use the LM Studio API with it?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3gbn8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109365,"author_flair_text":"Llama 3","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly56sis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"winkler1","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly44cdp","score":1,"author_fullname":"t2_46mjt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ahhh... it's under the View All. Was not seeing any instruct models in the short list. Thx.\\n\\nhttps://preview.redd.it/r8vd97z1u32e1.png?width=564&amp;format=png&amp;auto=webp&amp;s=36f16d2ad7ed92fd2dcb1921e23f23538543bb80","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly56sis","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ahhh... it&amp;#39;s under the View All. Was not seeing any instruct models in the short list. Thx.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/r8vd97z1u32e1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36f16d2ad7ed92fd2dcb1921e23f23538543bb80\\"&gt;https://preview.redd.it/r8vd97z1u32e1.png?width=564&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36f16d2ad7ed92fd2dcb1921e23f23538543bb80&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly56sis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732129442,"media_metadata":{"r8vd97z1u32e1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":143,"x":108,"u":"https://preview.redd.it/r8vd97z1u32e1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=308cf84b58daeee731d787578fa7bf4850ef51b1"},{"y":287,"x":216,"u":"https://preview.redd.it/r8vd97z1u32e1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=40b9b56c7ae0db9b23500cfb928bdbe826b7b70e"},{"y":425,"x":320,"u":"https://preview.redd.it/r8vd97z1u32e1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa9ce066ed04aa0b8700bf43f68ce3602709535e"}],"s":{"y":750,"x":564,"u":"https://preview.redd.it/r8vd97z1u32e1.png?width=564&amp;format=png&amp;auto=webp&amp;s=36f16d2ad7ed92fd2dcb1921e23f23538543bb80"},"id":"r8vd97z1u32e1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1732129442,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly44cdp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117671,"send_replies":true,"parent_id":"t1_ly3m2ws","score":3,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you have to pick a specific quant, I swear I put in an example in the readme, but just look for one on the ollama website model list  \\n[Ollama](https://ollama.com/search)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly44cdp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you have to pick a specific quant, I swear I put in an example in the readme, but just look for one on the ollama website model list&lt;br/&gt;\\n&lt;a href=\\"https://ollama.com/search\\"&gt;Ollama&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44cdp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117671,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3m2ws","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"winkler1","can_mod_post":false,"created_utc":1732111547,"send_replies":true,"parent_id":"t3_1gvlzug","score":3,"author_fullname":"t2_46mjt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The \\\\\`phi3:14b-medium-128k-instruct\\\\\` model referenced in the readme seems invalid?\\n\\n\\\\\`\\\\\`\\\\\`\\n\\nresearcher ❯ ollama create research-phi3 -f modelfile\\n\\ntransferring model data\\n\\npulling manifest\\n\\nError: pull model manifest: file does not exist\\n\\n\\\\\`\\\\\`\\\\\`\\n\\n  \\n[https://ollama.com/search?q=phi3%3A14b-medium-128k-instruct](https://ollama.com/search?q=phi3%3A14b-medium-128k-instruct) \\\\-&gt; no models found","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3m2ws","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The \`phi3:14b-medium-128k-instruct\` model referenced in the readme seems invalid?&lt;/p&gt;\\n\\n&lt;p&gt;\`\`\`&lt;/p&gt;\\n\\n&lt;p&gt;researcher ❯ ollama create research-phi3 -f modelfile&lt;/p&gt;\\n\\n&lt;p&gt;transferring model data&lt;/p&gt;\\n\\n&lt;p&gt;pulling manifest&lt;/p&gt;\\n\\n&lt;p&gt;Error: pull model manifest: file does not exist&lt;/p&gt;\\n\\n&lt;p&gt;\`\`\`&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ollama.com/search?q=phi3%3A14b-medium-128k-instruct\\"&gt;https://ollama.com/search?q=phi3%3A14b-medium-128k-instruct&lt;/a&gt; -&amp;gt; no models found&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3m2ws/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732111547,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly44wvu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly44o4e","score":2,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yeah I will do that right now good call","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly44wvu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah I will do that right now good call&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44wvu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117849,"author_flair_text":null,"treatment_tags":[],"created_utc":1732117849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly44o4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GimmePanties","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly43b3a","score":2,"author_fullname":"t2_o42ku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"okay, take the / operator out of the menu maybe? it confused me, since it's the first option.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly44o4e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;okay, take the / operator out of the menu maybe? it confused me, since it&amp;#39;s the first option.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44o4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117775,"author_flair_text":null,"treatment_tags":[],"created_utc":1732117775,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly43b3a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117346,"send_replies":true,"parent_id":"t1_ly3gtzm","score":3,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have considered it, maybe I will in the future, and yeah search mode is actually a left over part of my previous program that was this programs predecessor, and it only really did web searches and scraping, and in the process of implementing this massive new version I totally broke it, and haven't had the time to fix it, thanks for the input though!\\n\\nThe research mode is essentially a better version of the search anyways!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly43b3a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have considered it, maybe I will in the future, and yeah search mode is actually a left over part of my previous program that was this programs predecessor, and it only really did web searches and scraping, and in the process of implementing this massive new version I totally broke it, and haven&amp;#39;t had the time to fix it, thanks for the input though!&lt;/p&gt;\\n\\n&lt;p&gt;The research mode is essentially a better version of the search anyways!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly43b3a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117346,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3gtzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GimmePanties","can_mod_post":false,"created_utc":1732109566,"send_replies":true,"parent_id":"t3_1gvlzug","score":5,"author_fullname":"t2_o42ku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OP nice work. I would consider ignoring robots.txt if it exists because that’s more for mass web scraping and this is a user directed tool. I was getting a lot of urls skipped because that was being enforced. \\n\\nSearch mode doesn’t seem to be implemented? Research mode works fine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3gtzm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP nice work. I would consider ignoring robots.txt if it exists because that’s more for mass web scraping and this is a user directed tool. I was getting a lot of urls skipped because that was being enforced. &lt;/p&gt;\\n\\n&lt;p&gt;Search mode doesn’t seem to be implemented? Research mode works fine.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3gtzm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109566,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly44e52","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3r9pw","score":1,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks very much!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly44e52","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks very much!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44e52/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117687,"author_flair_text":null,"treatment_tags":[],"created_utc":1732117687,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3r9pw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fleiJ","can_mod_post":false,"created_utc":1732113392,"send_replies":true,"parent_id":"t1_ly3r88s","score":5,"author_fullname":"t2_4kfyshce","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hm this is not how it works I guess😂\\n\\nAnyway looks super interesting, I will need something like this soon and am stoked to test your solution!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3r9pw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hm this is not how it works I guess😂&lt;/p&gt;\\n\\n&lt;p&gt;Anyway looks super interesting, I will need something like this soon and am stoked to test your solution!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3r9pw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732113392,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly65xab","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dogcomplex","can_mod_post":false,"created_utc":1732147976,"send_replies":true,"parent_id":"t1_ly3r88s","score":0,"author_fullname":"t2_6frdz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"RemindMe! 4 weeks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly65xab","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RemindMe! 4 weeks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly65xab/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732147976,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3r88s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fleiJ","can_mod_post":false,"created_utc":1732113377,"send_replies":true,"parent_id":"t3_1gvlzug","score":4,"author_fullname":"t2_4kfyshce","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"!remind me 4 weeks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3r88s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remind me 4 weeks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3r88s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732113377,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly58ict","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Platfizzle","can_mod_post":false,"created_utc":1732129966,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_5pv1t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No option for a self hosted openai endpoint for Tabby/etc users?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly58ict","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No option for a self hosted openai endpoint for Tabby/etc users?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly58ict/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732129966,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6s7m2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ornery_Meat1055","can_mod_post":false,"created_utc":1732156096,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_jotdoiey2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I want to see the hallucination benchmark for this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6s7m2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to see the hallucination benchmark for this&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6s7m2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732156096,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly8mk26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LeanEntropy","can_mod_post":false,"created_utc":1732190652,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_j4cfv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is a really cool project!\\n\\nQuestion - How does it handles contradicting data?   \\nFor example, if one paper claims X and another explicitly contradicts X. How does it settles the issue?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly8mk26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a really cool project!&lt;/p&gt;\\n\\n&lt;p&gt;Question - How does it handles contradicting data?&lt;br/&gt;\\nFor example, if one paper claims X and another explicitly contradicts X. How does it settles the issue?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly8mk26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732190652,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m25gpy5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Unusual-Secretary769","can_mod_post":false,"created_utc":1734259291,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_c5cvacfk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tried running the install instructions in the python app and step one threw a syntax error so no idea what to do.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m25gpy5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried running the install instructions in the python app and step one threw a syntax error so no idea what to do.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/m25gpy5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1734259291,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4a3ea","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyHats","can_mod_post":false,"created_utc":1732119459,"send_replies":true,"parent_id":"t3_1gvlzug","score":3,"author_fullname":"t2_4y82h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think you can rely on your audience to have their inference backend already set up fine. (I figure, anyone who would need to be walked through installing ollama, is probably not going to be interested in trying a CLI tool). So, simplify all of that stuff in the README down to \\"give my thing your backend's URL in [whatever way]\\".\\n\\nAnd make that [whatever way] something clean and straightforward - right now I see llm_config.py has a base_url field for ollama, but not llama.cpp, so I'm not clear how it would even use llama.cpp; I guess it just assumes 127.0.0.1:8080? (I have my llama.cpp setup all nicely tucked away on its own server, so any AI tool that wants any backend configuration beyond a single plain URL is a non-starter for me; I would imagine a lot of other local people might be similar)\\n\\nBut: it looks like you've done a good deal of coding legwork to build a thing I've been wanting, so thanks very much! I wouldn't be critiquing it if I didn't think there was something worthwhile here! I'm definitely going to take a close look. Also this appears vastly more presentable than anything I would have thrown together in college, lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4a3ea","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you can rely on your audience to have their inference backend already set up fine. (I figure, anyone who would need to be walked through installing ollama, is probably not going to be interested in trying a CLI tool). So, simplify all of that stuff in the README down to &amp;quot;give my thing your backend&amp;#39;s URL in [whatever way]&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;And make that [whatever way] something clean and straightforward - right now I see llm_config.py has a base_url field for ollama, but not llama.cpp, so I&amp;#39;m not clear how it would even use llama.cpp; I guess it just assumes 127.0.0.1:8080? (I have my llama.cpp setup all nicely tucked away on its own server, so any AI tool that wants any backend configuration beyond a single plain URL is a non-starter for me; I would imagine a lot of other local people might be similar)&lt;/p&gt;\\n\\n&lt;p&gt;But: it looks like you&amp;#39;ve done a good deal of coding legwork to build a thing I&amp;#39;ve been wanting, so thanks very much! I wouldn&amp;#39;t be critiquing it if I didn&amp;#39;t think there was something worthwhile here! I&amp;#39;m definitely going to take a close look. Also this appears vastly more presentable than anything I would have thrown together in college, lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4a3ea/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732119459,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lyej6sa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"noises1990","can_mod_post":false,"created_utc":1732277477,"send_replies":true,"parent_id":"t1_ly4dink","score":1,"author_fullname":"t2_3tldvs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes please +1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lyej6sa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes please +1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lyej6sa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732277477,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly4dink","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Psychedelic_Traveler","can_mod_post":false,"created_utc":1732120541,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_nu51p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Support for LM studio ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4dink","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Support for LM studio ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4dink/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732120541,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly39mjn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yehiaserag","can_mod_post":false,"created_utc":1732106589,"send_replies":true,"parent_id":"t3_1gvlzug","score":4,"author_fullname":"t2_xfnx16t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it possible to have this in a docker image or a compose?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly39mjn","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it possible to have this in a docker image or a compose?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39mjn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732106589,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly30lhj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahmcode","can_mod_post":false,"created_utc":1732102101,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_1crc8690dp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks awesome !!! And the video is very funny, I learned something today 😁","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly30lhj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks awesome !!! And the video is very funny, I learned something today 😁&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly30lhj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732102101,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly43zpw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117562,"send_replies":true,"parent_id":"t1_ly3fdxq","score":1,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks mate I appreciate it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly43zpw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks mate I appreciate it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly43zpw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117562,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3fdxq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"drAndric","can_mod_post":false,"created_utc":1732108995,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_4ahc9ny","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Instant Star. I'll check it later today, sounds awesome. Thanks for the hard work and sharing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3fdxq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Instant Star. I&amp;#39;ll check it later today, sounds awesome. Thanks for the hard work and sharing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3fdxq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732108995,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3gcvr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GimmePanties","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2y8ji","score":11,"author_fullname":"t2_o42ku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I sent you a PR which adds wider support. It does OpenAI calls now, which supports pretty much anything that isn’t Anthropic, just set the base url to your preferred endpoint.","edited":false,"author_flair_css_class":null,"name":"t1_ly3gcvr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I sent you a PR which adds wider support. It does OpenAI calls now, which supports pretty much anything that isn’t Anthropic, just set the base url to your preferred endpoint.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3gcvr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109378,"author_flair_text":null,"collapsed":false,"created_utc":1732109378,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3jc1k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RedditPolluter","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2y8ji","score":7,"author_fullname":"t2_g0lqqzb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Making it compatible with OpenAI's endpoint is the best way of maximizing support with the least effort, since it's fairly standardized now. Even Google has just added support for that protocol. Mistral API and Ollama also support it. It's not default for Ollama but it can be accessed by mirroring the paths, like /v1/chat/completions. If you use the libraries for OpenAI's API, people can simply swap out the domain name and plug in virtually anything.","edited":1732110756,"author_flair_css_class":null,"name":"t1_ly3jc1k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Making it compatible with OpenAI&amp;#39;s endpoint is the best way of maximizing support with the least effort, since it&amp;#39;s fairly standardized now. Even Google has just added support for that protocol. Mistral API and Ollama also support it. It&amp;#39;s not default for Ollama but it can be accessed by mirroring the paths, like /v1/chat/completions. If you use the libraries for OpenAI&amp;#39;s API, people can simply swap out the domain name and plug in virtually anything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3jc1k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732110523,"author_flair_text":null,"collapsed":false,"created_utc":1732110523,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly2zj8q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Just-Contract7493","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2y8ji","score":3,"author_fullname":"t2_12k5kmnww0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh it okie and thank","edited":false,"author_flair_css_class":null,"name":"t1_ly2zj8q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh it okie and thank&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2zj8q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732101485,"author_flair_text":null,"collapsed":false,"created_utc":1732101485,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2y8ji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2y43x","score":9,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's just for Ollama at the moment unfortunately! Getting it to work at all was quite a challenge and I have never even used anything other then llama.cpp or ollama before, sorry!  \\nBut ollama's free so you can still try it if you want.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2y8ji","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s just for Ollama at the moment unfortunately! Getting it to work at all was quite a challenge and I have never even used anything other then llama.cpp or ollama before, sorry!&lt;br/&gt;\\nBut ollama&amp;#39;s free so you can still try it if you want.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2y8ji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100715,"author_flair_text":null,"treatment_tags":[],"created_utc":1732100715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2y43x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Just-Contract7493","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly2xpiv","score":5,"author_fullname":"t2_12k5kmnww0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"an API from, for instance, kobold","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly2y43x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;an API from, for instance, kobold&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2y43x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100640,"author_flair_text":null,"treatment_tags":[],"created_utc":1732100640,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2xpiv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732100392,"send_replies":true,"parent_id":"t1_ly2xlp3","score":5,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what does that mean?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2xpiv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what does that mean?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2xpiv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100392,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2xlp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Just-Contract7493","can_mod_post":false,"created_utc":1732100327,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_12k5kmnww0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wonder if this can take apis....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2xlp3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wonder if this can take apis....&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2xlp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100327,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3gty0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wontreadterms","can_mod_post":false,"created_utc":1732109565,"send_replies":true,"parent_id":"t3_1gvlzug","score":2,"author_fullname":"t2_6n5b6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is neat. Its an interesting implementation of CoT with web scraping. It would be interesting if the agent had other tools to retrieve information, not just web scraping, like direct API access to search engines. \\n\\nIt would be amazing to port this flow as a Task in my framework: [https://github.com/MarianoMolina/project\\\\_alice](https://github.com/MarianoMolina/project_alice)\\n\\nThe web scraping functionality, and other search APIs, are already implemented as tools/tasks, and a complex task flow like yours could be a good way of exploiting all these tools while building better/more complex agent structures. You can use multiple API providers by default, including LM Studio as a local deployment. \\n\\nI'm planning on adding cuda support by v0.4 (and probably ollama), and I'm launching v0.3 in a few days with a bunch of cool updates (to get an early look: https://github.com/MarianoMolina/project\\\\_alice/tree/development)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3gty0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is neat. Its an interesting implementation of CoT with web scraping. It would be interesting if the agent had other tools to retrieve information, not just web scraping, like direct API access to search engines. &lt;/p&gt;\\n\\n&lt;p&gt;It would be amazing to port this flow as a Task in my framework: &lt;a href=\\"https://github.com/MarianoMolina/project_alice\\"&gt;https://github.com/MarianoMolina/project_alice&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The web scraping functionality, and other search APIs, are already implemented as tools/tasks, and a complex task flow like yours could be a good way of exploiting all these tools while building better/more complex agent structures. You can use multiple API providers by default, including LM Studio as a local deployment. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m planning on adding cuda support by v0.4 (and probably ollama), and I&amp;#39;m launching v0.3 in a few days with a bunch of cool updates (to get an early look: &lt;a href=\\"https://github.com/MarianoMolina/project%5C_alice/tree/development\\"&gt;https://github.com/MarianoMolina/project\\\\_alice/tree/development&lt;/a&gt;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3gty0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109565,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly36v3j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SophiaBackstein","can_mod_post":false,"created_utc":1732105323,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_50ujxplxy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I will check that out :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly36v3j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will check that out :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly36v3j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732105323,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lz8gt0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"send_replies":true,"parent_id":"t1_lz8goue","score":2,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I will be messaging you in 21 days on [**2024-12-18 12:51:53 UTC**](http://www.wolframalpha.com/input/?i=2024-12-18%2012:51:53%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lz8goue/?context=3)\\n\\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1gvlzug%2Fi_created_an_ai_research_assistant_that_actually%2Flz8goue%2F%5D%0A%0ARemindMe%21%202024-12-18%2012%3A51%3A53%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201gvlzug)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lz8gt0x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 21 days on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2024-12-18%2012:51:53%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2024-12-18 12:51:53 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lz8goue/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1gvlzug%2Fi_created_an_ai_research_assistant_that_actually%2Flz8goue%2F%5D%0A%0ARemindMe%21%202024-12-18%2012%3A51%3A53%20UTC\\"&gt;&lt;strong&gt;CLICK THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201gvlzug\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lz8gt0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732711964,"author_flair_text":null,"treatment_tags":[],"created_utc":1732711964,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lz8goue","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"microcandella","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly39k1l","score":1,"author_fullname":"t2_3gxob","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\n!remindme 3 weeks","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_lz8goue","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remindme 3 weeks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lz8goue/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732711913,"author_flair_text":null,"treatment_tags":[],"created_utc":1732711913,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly39k1l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"created_utc":1732106559,"send_replies":true,"parent_id":"t1_ly39frs","score":1,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will be messaging you in 7 days on [**2024-11-27 12:41:46 UTC**](http://www.wolframalpha.com/input/?i=2024-11-27%2012:41:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39frs/?context=3)\\n\\n[**8 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1gvlzug%2Fi_created_an_ai_research_assistant_that_actually%2Fly39frs%2F%5D%0A%0ARemindMe%21%202024-11-27%2012%3A41%3A46%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201gvlzug)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":1732325333,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly39k1l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 7 days on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2024-11-27%2012:41:46%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2024-11-27 12:41:46 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39frs/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1gvlzug%2Fi_created_an_ai_research_assistant_that_actually%2Fly39frs%2F%5D%0A%0ARemindMe%21%202024-11-27%2012%3A41%3A46%20UTC\\"&gt;&lt;strong&gt;8 OTHERS CLICKED THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201gvlzug\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39k1l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732106559,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly39frs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly39frs/","num_reports":null,"locked":false,"name":"t1_ly39frs","created":1732106506,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732106506,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4tzvd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eggs-benedryl","can_mod_post":false,"created_utc":1732125567,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_8nlxwtdi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'll have to look at this once i get home. I will say stuff like this probably gets a bit more adoption if it has even a basic UI, but if it works it works, \\n\\nVery cool looking","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4tzvd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll have to look at this once i get home. I will say stuff like this probably gets a bit more adoption if it has even a basic UI, but if it works it works, &lt;/p&gt;\\n\\n&lt;p&gt;Very cool looking&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4tzvd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732125567,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"41af45de-fdc0-11ee-a05e-8227e0534943","likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4xg6s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"micseydel","can_mod_post":false,"created_utc":1732126615,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_gfdbo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How easy would it be to point it at and limit it to a local Obsidian vault? (No internet access.) An Obsidian vault is essentially just a wiki of Markdown notes that use \\\\[\\\\[wikilinks\\\\]\\\\].","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4xg6s","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 8B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How easy would it be to point it at and limit it to a local Obsidian vault? (No internet access.) An Obsidian vault is essentially just a wiki of Markdown notes that use [[wikilinks]].&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4xg6s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732126615,"author_flair_text":"Llama 8B","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4zmta","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"frobnosticus","can_mod_post":false,"created_utc":1732127276,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_qw6xz5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Okay This seems fantastic.  I can't get involved in the yak shaving required to play with it right now.  But I absolutely will.\\n\\no7\\n\\n!RemindMe 1 week","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4zmta","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay This seems fantastic.  I can&amp;#39;t get involved in the yak shaving required to play with it right now.  But I absolutely will.&lt;/p&gt;\\n\\n&lt;p&gt;o7&lt;/p&gt;\\n\\n&lt;p&gt;!RemindMe 1 week&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4zmta/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732127276,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5mvh6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RikuDesu","can_mod_post":false,"created_utc":1732135349,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_jvkux","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks cool, I've been using ScrapeGraphAI this to do something similar, but i'm excited to try your solution\\n\\nIf you start hitting a search error (due to rate limited or captchas) you might want to intergrate a service like a google search api like at serper.dev","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5mvh6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks cool, I&amp;#39;ve been using ScrapeGraphAI this to do something similar, but i&amp;#39;m excited to try your solution&lt;/p&gt;\\n\\n&lt;p&gt;If you start hitting a search error (due to rate limited or captchas) you might want to intergrate a service like a google search api like at serper.dev&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5mvh6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732135349,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6fehc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"flitzbitz","can_mod_post":false,"created_utc":1732151572,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_kr6hh1w9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"!RemindMe 1 month","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6fehc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!RemindMe 1 month&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6fehc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732151572,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6s5xd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Daarrell","can_mod_post":false,"created_utc":1732156080,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_2ca7mfyg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I got some error trying to install curses requirement on windows :/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6s5xd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I got some error trying to install curses requirement on windows :/&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6s5xd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732156080,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly756gp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ornery_Meat1055","can_mod_post":false,"created_utc":1732160827,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_jotdoiey2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"after a bit of tinkering got it working and submitted my research question via @ ... and control+D (im on mac).  \\nBut dont see anything progressing so far?\\n\\nhttps://preview.redd.it/0glw6hcgf62e1.png?width=2720&amp;format=png&amp;auto=webp&amp;s=0477cdacc246cc1abce37f5901f458e44db23dfe","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly756gp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;after a bit of tinkering got it working and submitted my research question via @ ... and control+D (im on mac).&lt;br/&gt;\\nBut dont see anything progressing so far?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/0glw6hcgf62e1.png?width=2720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0477cdacc246cc1abce37f5901f458e44db23dfe\\"&gt;https://preview.redd.it/0glw6hcgf62e1.png?width=2720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0477cdacc246cc1abce37f5901f458e44db23dfe&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly756gp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732160827,"media_metadata":{"0glw6hcgf62e1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":4,"x":108,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88b8446455737f5ed415d4ff7735a038b8c1161e"},{"y":8,"x":216,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=30e6bc764ef17bdd0a39d4a9b5f53ca9a60c1ec7"},{"y":12,"x":320,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f1ac2ee438f64d3bb3b076d0e17b5e5f72e2a6a"},{"y":25,"x":640,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=30904cee90f2e94eeeddcd895ab909e5c32e6078"},{"y":38,"x":960,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9df4dad3b584739aec3907483abe05bc3875a5c5"},{"y":42,"x":1080,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=600a39b30dd84e9f411582a6424ba5c583aac25f"}],"s":{"y":108,"x":2720,"u":"https://preview.redd.it/0glw6hcgf62e1.png?width=2720&amp;format=png&amp;auto=webp&amp;s=0477cdacc246cc1abce37f5901f458e44db23dfe"},"id":"0glw6hcgf62e1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly78ush","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"trantrungtin","can_mod_post":false,"created_utc":1732162294,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_a9ioy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"RemindMe! 1 month","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly78ush","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RemindMe! 1 month&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly78ush/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732162294,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly7e0ac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"created_utc":1732164484,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_32el727b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Note: This specific configuration is necessary as recent Ollama versions have reduced context windows on models like phi3:3.8b-mini-128k-instruct despite the name suggesing high context which is why the modelfile step is necessary due to the high amount of information being used during the research process.\\n\\nThanks for this, explains a lot. I hate dealing with ollama and am very glad exllamav2 are adding vision models now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7e0ac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Note: This specific configuration is necessary as recent Ollama versions have reduced context windows on models like phi3:3.8b-mini-128k-instruct despite the name suggesing high context which is why the modelfile step is necessary due to the high amount of information being used during the research process.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Thanks for this, explains a lot. I hate dealing with ollama and am very glad exllamav2 are adding vision models now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7e0ac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732164484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lyejd04","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"noises1990","can_mod_post":false,"created_utc":1732277561,"send_replies":true,"parent_id":"t1_lyac8hx","score":2,"author_fullname":"t2_3tldvs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"first of all, it's free and you can use whichever model you want","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lyejd04","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;first of all, it&amp;#39;s free and you can use whichever model you want&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lyejd04/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732277561,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"lyac8hx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iamhelltoday","can_mod_post":false,"created_utc":1732214668,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_8nkh4f0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does it differ from perplexity?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lyac8hx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does it differ from perplexity?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lyac8hx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732214668,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lybi7m7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"soovek","can_mod_post":false,"created_utc":1732227510,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_30kwi8zq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"!remindme 20 hours this looks cool, have to give it a spin as soon as possible!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lybi7m7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remindme 20 hours this looks cool, have to give it a spin as soon as possible!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lybi7m7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732227510,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lyrilsd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"awesomeveer001","can_mod_post":false,"created_utc":1732467449,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_30k5c9gd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"!remindme 3 days","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lyrilsd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remindme 3 days&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lyrilsd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732467449,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lz27izn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Obvious-Theory-8707","can_mod_post":false,"created_utc":1732621679,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_12qybchlpd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good work !!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lz27izn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good work !!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lz27izn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732621679,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"lzhmxiy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rafaelspecta","can_mod_post":false,"created_utc":1732840685,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_3lwsxbhq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am anxious to try it. Seems awesome","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_lzhmxiy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am anxious to try it. Seems awesome&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/lzhmxiy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732840685,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m0cfzkr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pondretti","can_mod_post":false,"created_utc":1733305324,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_unx9zjtf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you have a local AI rig?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m0cfzkr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have a local AI rig?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/m0cfzkr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1733305324,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m1q71dk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amoosebitmymom","can_mod_post":false,"created_utc":1734026828,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_3x0269gj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi, I'm working on a similar project (smaller scale), and I was wondering about your decision to use the requests library when scraping? \\n\\nI have opted to use a web driver library (playwright in my case), because it allows me to avoid bot detection and even bypass paywalls (by using a pre-installed chrome extension).\\nI will concede that this method increases latency by a lot\\n\\nDid you avoid this approach due to the performance hit, or because of another reason?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m1q71dk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, I&amp;#39;m working on a similar project (smaller scale), and I was wondering about your decision to use the requests library when scraping? &lt;/p&gt;\\n\\n&lt;p&gt;I have opted to use a web driver library (playwright in my case), because it allows me to avoid bot detection and even bypass paywalls (by using a pre-installed chrome extension).\\nI will concede that this method increases latency by a lot&lt;/p&gt;\\n\\n&lt;p&gt;Did you avoid this approach due to the performance hit, or because of another reason?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/m1q71dk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1734026828,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mad4i5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Adro_95","can_mod_post":false,"created_utc":1738411749,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_3ezgff1j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dumb question: minimum PC requirements?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mad4i5n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dumb question: minimum PC requirements?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/mad4i5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738411749,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"myllnrg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AI_is_the_rake","can_mod_post":false,"created_utc":1750322697,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_5bbysz0b2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_myllnrg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/myllnrg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1750322697,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5c2a2958-309b-11ee-9109-22869f0a11dc","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly43m5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117444,"send_replies":true,"parent_id":"t1_ly34il4","score":4,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ALSO the beauty of this is that you can directly see every single source it's used in the summary in the research text file, what site it came from and what it said, so if your wanting to check out the authenticity of the research you absolutely can!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly43m5p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ALSO the beauty of this is that you can directly see every single source it&amp;#39;s used in the summary in the research text file, what site it came from and what it said, so if your wanting to check out the authenticity of the research you absolutely can!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly43m5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117444,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4602e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SillyHats","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly42xx1","score":7,"author_fullname":"t2_4y82h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a respectful phrasing of a legitimate concern. I completely understand perceiving it as an attack, but this sort of thing you have to just force yourself to not take personally.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly4602e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a respectful phrasing of a legitimate concern. I completely understand perceiving it as an attack, but this sort of thing you have to just force yourself to not take personally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4602e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732118186,"author_flair_text":null,"treatment_tags":[],"created_utc":1732118186,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4firr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dyonizius","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly42xx1","score":1,"author_fullname":"t2_bmvq80nf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i was going to ask this too which search engine it supports can you slap a self hosted search aggregator there?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly4firr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i was going to ask this too which search engine it supports can you slap a self hosted search aggregator there?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4firr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732121158,"author_flair_text":null,"treatment_tags":[],"created_utc":1732121158,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly42xx1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117231,"send_replies":true,"parent_id":"t1_ly34il4","score":4,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"why don't you actually test it before you try to diss the thing mate!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly42xx1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;why don&amp;#39;t you actually test it before you try to diss the thing mate!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly42xx1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117231,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3eq9z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pohui","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3bekt","score":9,"author_fullname":"t2_87tjx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bad bot.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly3eq9z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bad bot.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3eq9z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732108733,"author_flair_text":null,"treatment_tags":[],"created_utc":1732108733,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3u2qi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Orolol","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3bekt","score":3,"author_fullname":"t2_fbzx9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's always sad to see people fall for Oil corporations propaganda.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_ly3u2qi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s always sad to see people fall for Oil corporations propaganda.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3u2qi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732114347,"author_flair_text":null,"treatment_tags":[],"created_utc":1732114347,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-8,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3z9tp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AuggieKC","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3g9pv","score":-2,"author_fullname":"t2_kvbmf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"People in general don't like to hear that the vast areas of permafrost that will become agriculturally viable hugely outweigh the already highly variable coastlines they are so attached to.","edited":false,"author_flair_css_class":null,"name":"t1_ly3z9tp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People in general don&amp;#39;t like to hear that the vast areas of permafrost that will become agriculturally viable hugely outweigh the already highly variable coastlines they are so attached to.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1gvlzug","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3z9tp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732116056,"author_flair_text":null,"collapsed":false,"created_utc":1732116056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3g9pv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"send_replies":true,"parent_id":"t1_ly3fe9h","score":-17,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"There are actual upsides to an increase in temperature. There's no reason to scare children into thinking we're all going to die. Humans have existed with much higher and lower global temperatures. With modern advancements, I think we'll be fine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3g9pv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are actual upsides to an increase in temperature. There&amp;#39;s no reason to scare children into thinking we&amp;#39;re all going to die. Humans have existed with much higher and lower global temperatures. With modern advancements, I think we&amp;#39;ll be fine.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3g9pv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732109344,"author_flair_text":null,"treatment_tags":[],"created_utc":1732109344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-17}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3fe9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1732108999,"send_replies":true,"parent_id":"t1_ly3bekt","score":-8,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3fe9h/","num_reports":null,"locked":false,"name":"t1_ly3fe9h","created":1732108999,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3bekt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1732107358,"send_replies":true,"parent_id":"t1_ly34il4","score":-28,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The ocean will rise about 6.5 inches or 165 mm and no one will notice. Oxygen levels are higher due to increased vegetative growth from the increase in CO2 accompanied by greater crop harvests. There are less climate related deaths because cold weather kills far more people than hot weather. Finally, climate grifters are once again predicting the upcoming ice age that will end humanity if our world governments don't give huge sums of money to large corporations to save us from climate change. Society once again fails to see through the lobbying campaigns and propaganda because still few people can think for themselves.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3bekt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The ocean will rise about 6.5 inches or 165 mm and no one will notice. Oxygen levels are higher due to increased vegetative growth from the increase in CO2 accompanied by greater crop harvests. There are less climate related deaths because cold weather kills far more people than hot weather. Finally, climate grifters are once again predicting the upcoming ice age that will end humanity if our world governments don&amp;#39;t give huge sums of money to large corporations to save us from climate change. Society once again fails to see through the lobbying campaigns and propaganda because still few people can think for themselves.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3bekt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732107358,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-28}}],"before":null}},"user_reports":[],"saved":false,"id":"ly34il4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"candre23","can_mod_post":false,"created_utc":1732104182,"send_replies":true,"parent_id":"t3_1gvlzug","score":-1,"author_fullname":"t2_4wc8s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does this account for the fact that at least half the information on the internet is factually false, and 87% of statistics are made up?  Is there any kind of source validation process, or is this a likely scenario:\\n\\n    {{HUMAN}}: What are the most likely effects of climate change in the next 50 years?\\n\\n    {{ASSISTANT}}: According to most researchers, climate change doesn't exist and you should kill yourself. (source: 4chan)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly34il4","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does this account for the fact that at least half the information on the internet is factually false, and 87% of statistics are made up?  Is there any kind of source validation process, or is this a likely scenario:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;{{HUMAN}}: What are the most likely effects of climate change in the next 50 years?\\n\\n{{ASSISTANT}}: According to most researchers, climate change doesn&amp;#39;t exist and you should kill yourself. (source: 4chan)\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly34il4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732104182,"author_flair_text":"koboldcpp","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3el4t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bil_Wi_theScience_Fi","can_mod_post":false,"created_utc":1732108674,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_47484ww1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Saved! Can’t wait to try it out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3el4t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Saved! Can’t wait to try it out&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3el4t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732108674,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly44mfr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117760,"send_replies":true,"parent_id":"t1_ly3iz58","score":2,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think you can poison your profile with this, because:\\n\\n* The searches would be clearly automated (rapid, patterned)\\n* Data brokers can easily distinguish automated traffic from human behavior\\n* The search patterns would be too uniform to appear human\\n\\nbut that's just imo","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly44mfr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think you can poison your profile with this, because:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;The searches would be clearly automated (rapid, patterned)&lt;/li&gt;\\n&lt;li&gt;Data brokers can easily distinguish automated traffic from human behavior&lt;/li&gt;\\n&lt;li&gt;The search patterns would be too uniform to appear human&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;but that&amp;#39;s just imo&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44mfr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3iz58","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I want to use this to change my digital footprint. Does this make sense. I hate the ads I get from data brokers. I want have this running on my M4 Mac mini with 16g of RAM that I'm currently using as an Apple TV replacement and just have search AI scholarly stuff 24/7 or better yet guitars. I have a visceral hatred for data brokers and would love to poison my profile with this!","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to use this to change my digital footprint. Does this make sense. I hate the ads I get from data brokers. I want have this running on my M4 Mac mini with 16g of RAM that I&amp;#39;m currently using as an Apple TV replacement and just have search AI scholarly stuff 24/7 or better yet guitars. I have a visceral hatred for data brokers and would love to poison my profile with this!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3iz58/","num_reports":null,"locked":false,"name":"t1_ly3iz58","created":1732110388,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732110388,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3jr7r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shepbryan","can_mod_post":false,"created_utc":1732110681,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_fsjy6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hurrah!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3jr7r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hurrah!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3jr7r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732110681,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly3l9yw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"young_picassoo","can_mod_post":false,"created_utc":1732111247,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_tz79jfzl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Really nice","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3l9yw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really nice&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3l9yw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732111247,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5wktt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"The_Seeker_25920","can_mod_post":false,"created_utc":1732143732,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_vanr6mzh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Super cool project, I need to check this out! Are you open to having more contributors?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5wktt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Super cool project, I need to check this out! Are you open to having more contributors?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5wktt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732143732,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6fr0u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ben52646","can_mod_post":false,"created_utc":1732151700,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_b98te","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are awesome! Thank you!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6fr0u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are awesome! Thank you!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6fr0u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732151700,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9h8jl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mikolai007","can_mod_post":false,"created_utc":1732205316,"send_replies":true,"parent_id":"t3_1gvlzug","score":1,"author_fullname":"t2_en1akpac","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does it work differently than how Perplexity does?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly9h8jl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it work differently than how Perplexity does?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9h8jl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732205316,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly2v9ff","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1732098864,"send_replies":true,"parent_id":"t3_1gvlzug","score":-4,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"step towards AGI :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2v9ff","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;step towards AGI :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2v9ff/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732098864,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly33qfw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"worry_always","can_mod_post":false,"created_utc":1732103787,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_5czw3z5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks cool, will try it out soon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly33qfw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks cool, will try it out soon.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly33qfw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732103787,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly4iq7y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dax_Thrushbane","can_mod_post":false,"created_utc":1732122139,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_cbbuicaw1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for this - looks very good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly4iq7y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this - looks very good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly4iq7y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732122139,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly51hnl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"estebansaa","can_mod_post":false,"created_utc":1732127836,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_m8971","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this is awesome, you can remove the context window limitation by using RAG to store and retrieve the data as the work progresses.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly51hnl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this is awesome, you can remove the context window limitation by using RAG to store and retrieve the data as the work progresses.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly51hnl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732127836,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly556b1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LoadingALIAS","can_mod_post":false,"created_utc":1732128951,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_ufzvkub2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, this is awesome. Thank you so much. I’ll about to dive in!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly556b1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, this is awesome. Thank you so much. I’ll about to dive in!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly556b1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732128951,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly56qck","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"goqsane","can_mod_post":false,"created_utc":1732129423,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_o0mwp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Starred. Am impressed. Please tell me, do you support the use case of using a separate llama? (I.e.: not on your computer but another one on your network). I got a whole server full of LLMs and I don’t like to run it on my “work” computer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly56qck","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Starred. Am impressed. Please tell me, do you support the use case of using a separate llama? (I.e.: not on your computer but another one on your network). I got a whole server full of LLMs and I don’t like to run it on my “work” computer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly56qck/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732129423,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5afyo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"schorhr","can_mod_post":false,"created_utc":1732130555,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_gc6ja","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is awesome.\\n\\nStill, now I'm curious what'll happen if your research topic is \\"actually, the earth is flat\\", and what kind of sources it would dig up ;-)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5afyo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is awesome.&lt;/p&gt;\\n\\n&lt;p&gt;Still, now I&amp;#39;m curious what&amp;#39;ll happen if your research topic is &amp;quot;actually, the earth is flat&amp;quot;, and what kind of sources it would dig up ;-)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5afyo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732130555,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5mizt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bladablu","can_mod_post":false,"created_utc":1732134780,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_540e8on","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks great, thank you for sharing, I will test it soon and report back.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5mizt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks great, thank you for sharing, I will test it soon and report back.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5mizt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732134780,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly5nond","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ElegantGrocery8081","can_mod_post":false,"created_utc":1732136396,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_ajpmyel3f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Testing it now! Super simple to setup.\\nThanks from Spain","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly5nond","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Testing it now! Super simple to setup.\\nThanks from Spain&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly5nond/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732136396,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6jaue","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UsualYodl","can_mod_post":false,"created_utc":1732152974,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_12nhvjffpq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just need to add my positive feedback to the concert. This is  great and inspiring. Note; i recently gave myself 6 months to come up with something similar.  (i want a feature that weighs research quality according to various criterions ) . Thank you for the sharing and inherent tips !","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6jaue","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just need to add my positive feedback to the concert. This is  great and inspiring. Note; i recently gave myself 6 months to come up with something similar.  (i want a feature that weighs research quality according to various criterions ) . Thank you for the sharing and inherent tips !&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6jaue/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732152974,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6r4x7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate_Bet_820","can_mod_post":false,"created_utc":1732155723,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_6o0xqqy8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome work OP, kudos. I was always in need of such solution. Will definitely explore. \\nBy the way does anyone have any list of similar open-source tools/research agents? I am still figuring it what will be best for for my use case. So, I'll appreciate if somebody can point me towards a repo listing such agentic frameworks that are customised for academic research work, if any.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6r4x7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome work OP, kudos. I was always in need of such solution. Will definitely explore. \\nBy the way does anyone have any list of similar open-source tools/research agents? I am still figuring it what will be best for for my use case. So, I&amp;#39;ll appreciate if somebody can point me towards a repo listing such agentic frameworks that are customised for academic research work, if any.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6r4x7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732155723,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly6u7yu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hugganao","can_mod_post":false,"created_utc":1732156800,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_jc5ns","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"awesome! thanks for the share. So which opensource model have you had the best results with?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly6u7yu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;awesome! thanks for the share. So which opensource model have you had the best results with?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly6u7yu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732156800,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly71285","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eleqtriq","can_mod_post":false,"created_utc":1732159268,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_66vte","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":" Can’t wait to try it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly71285","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can’t wait to try it!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly71285/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732159268,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly7irbj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleReign007","can_mod_post":false,"created_utc":1732166690,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_13vvun","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome! Stoked to try this on some research","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7irbj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome! Stoked to try this on some research&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7irbj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732166690,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly7l90f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"D0TTTT","can_mod_post":false,"created_utc":1732167930,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_hvpkkcmg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks great! will try it out on weekend and let you know.  Thankyou for sharing this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7l90f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks great! will try it out on weekend and let you know.  Thankyou for sharing this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7l90f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732167930,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly7lh98","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Icy_distribution8763","can_mod_post":false,"created_utc":1732168045,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_136rjj0n59","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dude! This is amazing! Definitely will be trying it out this week","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly7lh98","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dude! This is amazing! Definitely will be trying it out this week&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly7lh98/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732168045,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly83pqa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NewZealandIsNotFree","can_mod_post":false,"created_utc":1732179072,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_p4dbe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly83pqa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly83pqa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732179072,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly8jbbo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wikarina","can_mod_post":false,"created_utc":1732188978,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_msndi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think in linux you can also use the combo: End, then Shift+Home then delete to delete all typed text in one go - Anyways loved the work","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly8jbbo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think in linux you can also use the combo: End, then Shift+Home then delete to delete all typed text in one go - Anyways loved the work&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly8jbbo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732188978,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":0,"removal_reason":null,"link_id":"t3_1gvlzug","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly94l0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"How do you handle user privacy?","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you handle user privacy?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly94l0j/","num_reports":null,"locked":false,"name":"t1_ly94l0j","created":1732198124,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1732198124,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly9fjy0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LetterRip","can_mod_post":false,"created_utc":1732204656,"send_replies":true,"parent_id":"t3_1gvlzug","score":0,"author_fullname":"t2_3zb81","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for using a descriptive name - hate repositories that are some clever acronym that leaves me no idea why I have it on my computer or what I might use it for when I look at the list of repositories I've downloaded a month or so later.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly9fjy0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for using a descriptive name - hate repositories that are some clever acronym that leaves me no idea why I have it on my computer or what I might use it for when I look at the list of repositories I&amp;#39;ve downloaded a month or so later.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly9fjy0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732204656,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly44wq7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Butthurtz23","can_mod_post":false,"created_utc":1732117848,"send_replies":true,"parent_id":"t3_1gvlzug","score":-5,"author_fullname":"t2_188hx6mr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Wow, it's great that it will totally shut down those fake Karen researchers! Too bad universities just love to accept papers that have been peer-reviewed by experts like Karen with doctoral degrees. But your project will be challenged and don’t let that deter you from continuing your work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly44wq7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, it&amp;#39;s great that it will totally shut down those fake Karen researchers! Too bad universities just love to accept papers that have been peer-reviewed by experts like Karen with doctoral degrees. But your project will be challenged and don’t let that deter you from continuing your work!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly44wq7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117848,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly2x9q9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732100124,"send_replies":true,"parent_id":"t1_ly2vfzh","score":23,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The whole point is that it's locally running, free, and doesn't require external services, and why would I generate papers especially when i'm running such small LLMs?\\n\\nit's only a 3.8b model that I mostly tested on, the point is to find reliable real papers and information, and then to gather the info for you from real research with links to it, not to try and make some up yourself!  \\nthat's just my 2 cents on it, but thanks for the input though!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2x9q9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The whole point is that it&amp;#39;s locally running, free, and doesn&amp;#39;t require external services, and why would I generate papers especially when i&amp;#39;m running such small LLMs?&lt;/p&gt;\\n\\n&lt;p&gt;it&amp;#39;s only a 3.8b model that I mostly tested on, the point is to find reliable real papers and information, and then to gather the info for you from real research with links to it, not to try and make some up yourself!&lt;br/&gt;\\nthat&amp;#39;s just my 2 cents on it, but thanks for the input though!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2x9q9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732100124,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"ly2vfzh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"XhoniShollaj","can_mod_post":false,"created_utc":1732098980,"send_replies":true,"parent_id":"t3_1gvlzug","score":-5,"author_fullname":"t2_3s7gldef","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Thats pretty cool, thank you for sharing. Next step could be to integrate agents with resources / cloud services for automated experimentation + documentation &amp; paper generation","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2vfzh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thats pretty cool, thank you for sharing. Next step could be to integrate agents with resources / cloud services for automated experimentation + documentation &amp;amp; paper generation&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2vfzh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732098980,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly43t0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CuriousAustralianBoy","can_mod_post":false,"created_utc":1732117504,"send_replies":true,"parent_id":"t1_ly3bxdx","score":1,"author_fullname":"t2_6247e517","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's just a demo to show how it works, if you wanna test it out more thoroughly feel free to do so!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly43t0f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s just a demo to show how it works, if you wanna test it out more thoroughly feel free to do so!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1gvlzug","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly43t0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732117504,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"ly3bxdx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"no_username_for_me","can_mod_post":false,"created_utc":1732107579,"send_replies":true,"parent_id":"t3_1gvlzug","score":-2,"author_fullname":"t2_4g4qh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This looks kinda cool but perhaps a demonstration that the top LLMs can’t handle off the shelf would be more effective. Here is 4os response to the question you asked in the demo which I think you will agree is much more comprehensive:\\n\\nSmelling salts work through a combination of chemical and biological mechanisms that stimulate the body’s nervous system. Here’s a breakdown of their function:\\n\\nChemical Mechanism\\n\\nSmelling salts typically contain ammonium carbonate (NH₄HCO₃) or a similar compound. When the salts are exposed to air, they release ammonia gas (NH₃), which has a strong, pungent smell.\\n\\t•\\tReaction:\\nAmmonium carbonate decomposes when exposed to air or heat:\\n￼\\n\\t•\\tThe released ammonia gas is highly volatile and easily inhaled through the nose.\\n\\nBiological Mechanism\\n\\n\\t1.\\tStimulation of Nasal Mucosa:\\nWhen inhaled, the ammonia gas irritates the nasal mucosa and the lining of the respiratory tract. This irritation triggers a reflexive response in the nervous system.\\n\\t2.\\tActivation of the Sympathetic Nervous System:\\nThe irritation stimulates the trigeminal nerve (cranial nerve V), which activates the sympathetic nervous system. This results in:\\n\\t•\\tIncreased respiratory rate (rapid inhalation).\\n\\t•\\tIncreased heart rate and blood pressure.\\n\\t•\\tHeightened alertness.\\n\\t3.\\tArousal Response:\\nThe body’s reflexive reaction to the strong odor acts as a wake-up call, jolting a person out of a faint or drowsy state. It can momentarily counteract light-headedness or fainting by increasing oxygen intake and blood flow to the brain.\\n\\nUses and Limitations\\n\\n\\t•\\tPrimary Use: Smelling salts are used to revive individuals who have fainted or feel faint, often in sports or medical emergencies.\\n\\t•\\tLimitations: While effective for temporary arousal, they do not treat the underlying cause of fainting, which could be dehydration, low blood sugar, or a serious medical condition.\\n\\nSafety Concerns\\n\\nOveruse or prolonged exposure to ammonia gas can cause:\\n\\t•\\tIrritation to the respiratory system.\\n\\t•\\tDamage to mucous membranes.\\n\\t•\\tReflexive choking or coughing.\\n\\nThey should be used sparingly and under proper supervision.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly3bxdx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This looks kinda cool but perhaps a demonstration that the top LLMs can’t handle off the shelf would be more effective. Here is 4os response to the question you asked in the demo which I think you will agree is much more comprehensive:&lt;/p&gt;\\n\\n&lt;p&gt;Smelling salts work through a combination of chemical and biological mechanisms that stimulate the body’s nervous system. Here’s a breakdown of their function:&lt;/p&gt;\\n\\n&lt;p&gt;Chemical Mechanism&lt;/p&gt;\\n\\n&lt;p&gt;Smelling salts typically contain ammonium carbonate (NH₄HCO₃) or a similar compound. When the salts are exposed to air, they release ammonia gas (NH₃), which has a strong, pungent smell.\\n    • Reaction:\\nAmmonium carbonate decomposes when exposed to air or heat:\\n￼\\n    • The released ammonia gas is highly volatile and easily inhaled through the nose.&lt;/p&gt;\\n\\n&lt;p&gt;Biological Mechanism&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;1.  Stimulation of Nasal Mucosa:\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;When inhaled, the ammonia gas irritates the nasal mucosa and the lining of the respiratory tract. This irritation triggers a reflexive response in the nervous system.\\n    2.  Activation of the Sympathetic Nervous System:\\nThe irritation stimulates the trigeminal nerve (cranial nerve V), which activates the sympathetic nervous system. This results in:\\n    • Increased respiratory rate (rapid inhalation).\\n    • Increased heart rate and blood pressure.\\n    • Heightened alertness.\\n    3.  Arousal Response:\\nThe body’s reflexive reaction to the strong odor acts as a wake-up call, jolting a person out of a faint or drowsy state. It can momentarily counteract light-headedness or fainting by increasing oxygen intake and blood flow to the brain.&lt;/p&gt;\\n\\n&lt;p&gt;Uses and Limitations&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;• Primary Use: Smelling salts are used to revive individuals who have fainted or feel faint, often in sports or medical emergencies.\\n• Limitations: While effective for temporary arousal, they do not treat the underlying cause of fainting, which could be dehydration, low blood sugar, or a serious medical condition.\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Safety Concerns&lt;/p&gt;\\n\\n&lt;p&gt;Overuse or prolonged exposure to ammonia gas can cause:\\n    • Irritation to the respiratory system.\\n    • Damage to mucous membranes.\\n    • Reflexive choking or coughing.&lt;/p&gt;\\n\\n&lt;p&gt;They should be used sparingly and under proper supervision.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly3bxdx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732107579,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ly2zhba","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"TanaMango","can_mod_post":false,"created_utc":1732101454,"send_replies":true,"parent_id":"t3_1gvlzug","score":-10,"author_fullname":"t2_15vzaw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Does anyone wanna build some app with me or help me with a project? I really need a bi project for my resume, thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ly2zhba","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does anyone wanna build some app with me or help me with a project? I really need a bi project for my resume, thank you!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1gvlzug/i_created_an_ai_research_assistant_that_actually/ly2zhba/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1732101454,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1gvlzug","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-10}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
