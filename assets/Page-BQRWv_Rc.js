import{j as e}from"./index-CNyNkRpk.js";import{R as t}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Title. I wonder if there is any collections/rankings for open-to-use LLMs in the area of generating dataset. As far as I know (please correct me if I'm wrong):\\n- ChatGPT disallows \\"using ChatGPT to build a competitive model against itself\\". Though the terms is quite vague, it wouldn't be safe to assume that they're \\"open AI\\" (pun intended).\\n- DeepSeek allows for the use case, but they require us to note where exactly their LLM was used. Good, isn't it?\\n- Llama also allows for the use case, but they require models that inherited their data to be named after them (maybe I misremembered, could be \\"your fine-tuned llama model must also be named llama\\").\\n\\nThat's all folks. Hopefully I can get some valuable suggestions!\\n\\nEdit: Found this useful link.\\nhttps://github.com/eugeneyan/open-llms","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"License-friendly LLMs for generating synthetic datasets","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lrzom4","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_42ba8hq5","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751700226,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751683192,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Title. I wonder if there is any collections/rankings for open-to-use LLMs in the area of generating dataset. As far as I know (please correct me if I&amp;#39;m wrong):\\n- ChatGPT disallows &amp;quot;using ChatGPT to build a competitive model against itself&amp;quot;. Though the terms is quite vague, it wouldn&amp;#39;t be safe to assume that they&amp;#39;re &amp;quot;open AI&amp;quot; (pun intended).\\n- DeepSeek allows for the use case, but they require us to note where exactly their LLM was used. Good, isn&amp;#39;t it?\\n- Llama also allows for the use case, but they require models that inherited their data to be named after them (maybe I misremembered, could be &amp;quot;your fine-tuned llama model must also be named llama&amp;quot;).&lt;/p&gt;\\n\\n&lt;p&gt;That&amp;#39;s all folks. Hopefully I can get some valuable suggestions!&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Found this useful link.\\n&lt;a href=\\"https://github.com/eugeneyan/open-llms\\"&gt;https://github.com/eugeneyan/open-llms&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?auto=webp&amp;s=520466ad7a3c4073d001b3a28918f2559a6af892","width":1200,"height":630},"resolutions":[{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c854207e0586cf8b3235769c68e916f5c8c84aec","width":108,"height":56},{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2dd3401a5fb7174d2e6054b541afeeca78efe0e7","width":216,"height":113},{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b8a6e7d7febaa7e19ec4441f4c1187736170d17","width":320,"height":168},{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3a3927f95304dddc9f72eab4d1e5b1ff6be532b7","width":640,"height":336},{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b55d494067e868a8c2095b6ceff8fc271f6082ed","width":960,"height":504},{"url":"https://external-preview.redd.it/5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb34443b4d882d5f30403e26a8f0147cb8c1d06f","width":1080,"height":567}],"variants":{},"id":"5HE7KGF_L1EksV4d9v3Dw9DfwLTMriQo2T312gJwv3o"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lrzom4","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"blankboy2022","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lrzom4/licensefriendly_llms_for_generating_synthetic/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lrzom4/licensefriendly_llms_for_generating_synthetic/","subreddit_subscribers":494987,"created_utc":1751683192,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ewvl4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ewafo","score":2,"author_fullname":"t2_cpegz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Quite welcome, though I noticed a mistype, now corrected.  I meant to say that *Qwen3* was published under Apache 2.0, not Gemma3.\\n\\nGemma3's license is unfortunately extremely invasive and restricted.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1ewvl4","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Quite welcome, though I noticed a mistype, now corrected.  I meant to say that &lt;em&gt;Qwen3&lt;/em&gt; was published under Apache 2.0, not Gemma3.&lt;/p&gt;\\n\\n&lt;p&gt;Gemma3&amp;#39;s license is unfortunately extremely invasive and restricted.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrzom4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrzom4/licensefriendly_llms_for_generating_synthetic/n1ewvl4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751685417,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751685417,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ewafo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"blankboy2022","can_mod_post":false,"created_utc":1751685150,"send_replies":true,"parent_id":"t1_n1evcf5","score":2,"author_fullname":"t2_42ba8hq5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ewafo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lrzom4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrzom4/licensefriendly_llms_for_generating_synthetic/n1ewafo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751685150,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1evcf5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1751684726,"send_replies":true,"parent_id":"t3_1lrzom4","score":6,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Phi-4 is licensed MIT, and has *excellent* Evol-Instruct skills.\\n\\nThe Phi-4-25B self-merge is particularly competent at Evol-Instruct, comparable to the very restrictively licensed Gemma3-27B.\\n\\nQwen3 is also good for synthetic dataset generation (though its Evol-Instruct competence is poor), and it is published under the permissive Apache 2.0 license.\\n\\nOLMo2 is also published under Apache 2.0, and it has very good critique skills, though its applicability is somewhat limited by its short context limit.\\n\\nIf you go to Huggingface's page for Qwen3-32B, and click on the license, it gives you the option of seeing what other models are published under that license.","edited":1751685361,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1evcf5","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi-4 is licensed MIT, and has &lt;em&gt;excellent&lt;/em&gt; Evol-Instruct skills.&lt;/p&gt;\\n\\n&lt;p&gt;The Phi-4-25B self-merge is particularly competent at Evol-Instruct, comparable to the very restrictively licensed Gemma3-27B.&lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 is also good for synthetic dataset generation (though its Evol-Instruct competence is poor), and it is published under the permissive Apache 2.0 license.&lt;/p&gt;\\n\\n&lt;p&gt;OLMo2 is also published under Apache 2.0, and it has very good critique skills, though its applicability is somewhat limited by its short context limit.&lt;/p&gt;\\n\\n&lt;p&gt;If you go to Huggingface&amp;#39;s page for Qwen3-32B, and click on the license, it gives you the option of seeing what other models are published under that license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lrzom4/licensefriendly_llms_for_generating_synthetic/n1evcf5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751684726,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lrzom4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
