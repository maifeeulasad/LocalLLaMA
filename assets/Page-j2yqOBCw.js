import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Claude 4 is out. Grok 4 performed way better then any model in humanity last exam. Kimi K2 has launched with significantly improved creative writing. MiniMax M1 and Qwen 235B are here. Even hints of \\"Gemini 3\\" have been found in Git repositories. OpenAI will release their next major model (probably GPT-5) in few months and in few weeks we will see a open source model.\\nMeanwhile‚Ä¶ DeepSeek?\\nNot a word. No announcement. No \\"We‚Äôre working on it\\", nothing. Well yeah they have relesead some new checkpoints but nothing else then that. A few weeks ago, I was checking every day, excitedly waiting for DeepSeek R2 but not anymore. At this point, I just hope they silently drop the model and it turns out to be better than everything else.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Where is DeepsSeek R2?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m4ta0f","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.26,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_y1vyie97k","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1753030787,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753029087,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude 4 is out. Grok 4 performed way better then any model in humanity last exam. Kimi K2 has launched with significantly improved creative writing. MiniMax M1 and Qwen 235B are here. Even hints of &amp;quot;Gemini 3&amp;quot; have been found in Git repositories. OpenAI will release their next major model (probably GPT-5) in few months and in few weeks we will see a open source model.\\nMeanwhile‚Ä¶ DeepSeek?\\nNot a word. No announcement. No &amp;quot;We‚Äôre working on it&amp;quot;, nothing. Well yeah they have relesead some new checkpoints but nothing else then that. A few weeks ago, I was checking every day, excitedly waiting for DeepSeek R2 but not anymore. At this point, I just hope they silently drop the model and it turns out to be better than everything else.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m4ta0f","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ba2sYd","discussion_type":null,"num_comments":32,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/","subreddit_subscribers":502273,"created_utc":1753029087,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47e1jg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47bl28","score":3,"author_fullname":"t2_y1vyie97k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wouldn‚Äôt call myself a fan, but I genuinely love coding and technological advancements, researches in these areas. And when I see still how good DeepSeek is, even after many other big models have been released and some time has passed, it still impresses me. I can‚Äôt help but think, \\"Wow, they really know what they're doing!\\" or \\"If DeepSeek R1 is like this, how good will R2 be?\\"... It's hard to wait good things","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n47e1jg","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wouldn‚Äôt call myself a fan, but I genuinely love coding and technological advancements, researches in these areas. And when I see still how good DeepSeek is, even after many other big models have been released and some time has passed, it still impresses me. I can‚Äôt help but think, &amp;quot;Wow, they really know what they&amp;#39;re doing!&amp;quot; or &amp;quot;If DeepSeek R1 is like this, how good will R2 be?&amp;quot;... It&amp;#39;s hard to wait good things&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47e1jg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035125,"author_flair_text":null,"treatment_tags":[],"created_utc":1753035125,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n47bl28","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n479anp","score":1,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For the record the POV I‚Äôm sharing comes from being adjacent to the music industry. LLMs are so hot and opaque that they really do get hype cycles like music or video games.\\n\\nIt‚Äôs been a wild ride seeing something that used to be so niche like ‚ÄúNLP‚Äù have fans (I consider myself a Qwen fan ü§£üò≠) now.","edited":false,"author_flair_css_class":null,"name":"t1_n47bl28","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For the record the POV I‚Äôm sharing comes from being adjacent to the music industry. LLMs are so hot and opaque that they really do get hype cycles like music or video games.&lt;/p&gt;\\n\\n&lt;p&gt;It‚Äôs been a wild ride seeing something that used to be so niche like ‚ÄúNLP‚Äù have fans (I consider myself a Qwen fan ü§£üò≠) now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47bl28/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753034384,"author_flair_text":null,"collapsed":false,"created_utc":1753034384,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n479anp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n478mrb","score":1,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If just announcing would make them rush, then yeah I'd rather to wait","edited":1753036732,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n479anp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If just announcing would make them rush, then yeah I&amp;#39;d rather to wait&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n479anp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033716,"author_flair_text":null,"treatment_tags":[],"created_utc":1753033716,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n478mrb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46x2v4","score":1,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"An early announcement can lead to overgrown hype cycles or rushed deadlines.\\n\\nI‚Äôd rather a surprise than they risk problems like model collapse chasing a schedule.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n478mrb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An early announcement can lead to overgrown hype cycles or rushed deadlines.&lt;/p&gt;\\n\\n&lt;p&gt;I‚Äôd rather a surprise than they risk problems like model collapse chasing a schedule.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n478mrb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033524,"author_flair_text":null,"treatment_tags":[],"created_utc":1753033524,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n46x2v4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"created_utc":1753030143,"send_replies":true,"parent_id":"t1_n46uj7o","score":1,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're right, companies shouldn't just focus on making larger LLMs, training them with more (especially synthetic) data, or apply more rl, only to release a new model just for having a new product. What we really need is innovation, a model that does something new and I know creating new big models takes time. It requires massive resources, and even with those, training can take months. But still, is it normal for it to take this long? Also, other Chinese companies are releasing new models (I know they might be training them for a while but still.) and deepseek team doesn't even announce or tell anything about r2.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46x2v4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re right, companies shouldn&amp;#39;t just focus on making larger LLMs, training them with more (especially synthetic) data, or apply more rl, only to release a new model just for having a new product. What we really need is innovation, a model that does something new and I know creating new big models takes time. It requires massive resources, and even with those, training can take months. But still, is it normal for it to take this long? Also, other Chinese companies are releasing new models (I know they might be training them for a while but still.) and deepseek team doesn&amp;#39;t even announce or tell anything about r2.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46x2v4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030143,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n46uj7o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DorphinPack","can_mod_post":false,"created_utc":1753029380,"send_replies":true,"parent_id":"t3_1m4ta0f","score":22,"author_fullname":"t2_zebuyjw9s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you want them keeping pace with the marketing cadence or producing good models?\\n\\nDoing both requires an OpenAI amount of resources (and I think it‚Äôs a waste how we do ‚Äúcompetition‚Äù these days).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46uj7o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you want them keeping pace with the marketing cadence or producing good models?&lt;/p&gt;\\n\\n&lt;p&gt;Doing both requires an OpenAI amount of resources (and I think it‚Äôs a waste how we do ‚Äúcompetition‚Äù these days).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46uj7o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029380,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46y4ky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Fun-Wolf-2007","can_mod_post":false,"created_utc":1753030453,"send_replies":true,"parent_id":"t3_1m4ta0f","score":8,"author_fullname":"t2_lsixf36sr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"DeepSeek shocked the industry once , they are not falling into the game here in the US where companies want to release their new model even if it is not ready \\n\\nMy perspective is that DeepSeek wants to raise the bar, but I don't know what  their CEOs concept of what good looks like \\n\\nSo let's wait and see","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46y4ky","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DeepSeek shocked the industry once , they are not falling into the game here in the US where companies want to release their new model even if it is not ready &lt;/p&gt;\\n\\n&lt;p&gt;My perspective is that DeepSeek wants to raise the bar, but I don&amp;#39;t know what  their CEOs concept of what good looks like &lt;/p&gt;\\n\\n&lt;p&gt;So let&amp;#39;s wait and see&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46y4ky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030453,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49csrq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nullmove","can_mod_post":false,"send_replies":true,"parent_id":"t1_n487l20","score":1,"author_fullname":"t2_aq4j0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\n&gt; \\"Yeah we are working on new base model or R2\\"\\n\\nI am sorry but the fact that you think \\"R2\\" can be worked on without first doing a new base model suggests you have no idea how DeepSeek version nomenclature (historically) works, and you are just instead using it as a placeholder/fanfiction for some new thing that will automagically be super extra awesome without actually caring about how that can come to be.\\n\\nLet me put a damper on your fantasies, they don't bump major versions unless they do architectural change (new base model V4). The main reason they will work on a new base model is because it's mid 2025 and they are still not multimodal, so vision would be the primary focus of V4 (aside from perhaps agentic training and some long context tricks, which may still benefit certain things like agentic coding however). \\n\\nIf they slap on long CoT on V4, then and only then they will call it R2, even if it's *worse* than R1 0528 in pure coding, because inherently R2 doesn't mean it's much better than R1. Considering that vision doesn't translate into smarter text, it's likely that fantasised quality of R2 won't be a thing until months after V4 which itself could still be a couple of months away from now easily.\\n\\nYou are moaning about lack of clarity on their direction of R2 without realising that R2 can't possibly be a thing without V4, which is again another lapse of common sense.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n49csrq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;&amp;quot;Yeah we are working on new base model or R2&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I am sorry but the fact that you think &amp;quot;R2&amp;quot; can be worked on without first doing a new base model suggests you have no idea how DeepSeek version nomenclature (historically) works, and you are just instead using it as a placeholder/fanfiction for some new thing that will automagically be super extra awesome without actually caring about how that can come to be.&lt;/p&gt;\\n\\n&lt;p&gt;Let me put a damper on your fantasies, they don&amp;#39;t bump major versions unless they do architectural change (new base model V4). The main reason they will work on a new base model is because it&amp;#39;s mid 2025 and they are still not multimodal, so vision would be the primary focus of V4 (aside from perhaps agentic training and some long context tricks, which may still benefit certain things like agentic coding however). &lt;/p&gt;\\n\\n&lt;p&gt;If they slap on long CoT on V4, then and only then they will call it R2, even if it&amp;#39;s &lt;em&gt;worse&lt;/em&gt; than R1 0528 in pure coding, because inherently R2 doesn&amp;#39;t mean it&amp;#39;s much better than R1. Considering that vision doesn&amp;#39;t translate into smarter text, it&amp;#39;s likely that fantasised quality of R2 won&amp;#39;t be a thing until months after V4 which itself could still be a couple of months away from now easily.&lt;/p&gt;\\n\\n&lt;p&gt;You are moaning about lack of clarity on their direction of R2 without realising that R2 can&amp;#39;t possibly be a thing without V4, which is again another lapse of common sense.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n49csrq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753058349,"author_flair_text":null,"treatment_tags":[],"created_utc":1753058349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n487l20","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n482wal","score":1,"author_fullname":"t2_y1vyie97k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I didn't know RL is that expensive, I mean I know but I didn't know going 03'' to 05'' that expensive. Also I wouldn't say they are not doing anything, I saw a research they did so (I really looked so long to find it, but I really can't. As i remember it was something like transfering data or gpu related thing not sure). I know they work, do things or they want to release a good model to meet expactations and they shouldn't yap about this, tweet every morning, praise their model for nothing like openai but they could just say \\"Yeah we are working on new base model or R2\\"","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n487l20","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I didn&amp;#39;t know RL is that expensive, I mean I know but I didn&amp;#39;t know going 03&amp;#39;&amp;#39; to 05&amp;#39;&amp;#39; that expensive. Also I wouldn&amp;#39;t say they are not doing anything, I saw a research they did so (I really looked so long to find it, but I really can&amp;#39;t. As i remember it was something like transfering data or gpu related thing not sure). I know they work, do things or they want to release a good model to meet expactations and they shouldn&amp;#39;t yap about this, tweet every morning, praise their model for nothing like openai but they could just say &amp;quot;Yeah we are working on new base model or R2&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n487l20/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753044302,"author_flair_text":null,"treatment_tags":[],"created_utc":1753044302,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n482wal","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nullmove","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47zuz3","score":1,"author_fullname":"t2_aq4j0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":".....It's a checkpoint in exactly the same way Grok 4 is a checkpoint of Grok 3 (difference being Grok update major version for marketing reasons when DeepSeek didn't, in both cases it's still the same base model). Doing RL is still computationally expensive, and it's unrealistic (and undesirable) to be churning out new base model every 6 months, just to go through the cycle all over again. They had a good base model, why on earth would they just abandon it prematurely?\\n\\nObviously not angry, just disappointed at some perceived lack of common sense. Most glaring one being, just because they aren't yapping in public must mean they aren't working on anything (cue hysteria).","edited":false,"author_flair_css_class":null,"name":"t1_n482wal","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;.....It&amp;#39;s a checkpoint in exactly the same way Grok 4 is a checkpoint of Grok 3 (difference being Grok update major version for marketing reasons when DeepSeek didn&amp;#39;t, in both cases it&amp;#39;s still the same base model). Doing RL is still computationally expensive, and it&amp;#39;s unrealistic (and undesirable) to be churning out new base model every 6 months, just to go through the cycle all over again. They had a good base model, why on earth would they just abandon it prematurely?&lt;/p&gt;\\n\\n&lt;p&gt;Obviously not angry, just disappointed at some perceived lack of common sense. Most glaring one being, just because they aren&amp;#39;t yapping in public must mean they aren&amp;#39;t working on anything (cue hysteria).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n482wal/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753042867,"author_flair_text":null,"collapsed":false,"created_utc":1753042867,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47zuz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47whlg","score":1,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"0528 is just a checkpoint so but yeah still 2 month is short. and I know people probably don't know more then me but still wanted to ask, maybe someone know something or to discuss like this. Are you angry?... I am sorry please relax a bit","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47zuz3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;0528 is just a checkpoint so but yeah still 2 month is short. and I know people probably don&amp;#39;t know more then me but still wanted to ask, maybe someone know something or to discuss like this. Are you angry?... I am sorry please relax a bit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47zuz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753041928,"author_flair_text":null,"treatment_tags":[],"created_utc":1753041928,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47whlg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nullmove","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47uwch","score":2,"author_fullname":"t2_aq4j0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How is it a long time? 0528 isn't even two months old yet and it still holds up well with respect to frontier.\\n\\n&gt; why there isn't anything offical.\\n\\nPeople here wouldn't know about that any more than you do, would they? Find someone affiliated with DeepSeek and shoot them a DM/email if you really must, that would be actually productive instead of this.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47whlg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How is it a long time? 0528 isn&amp;#39;t even two months old yet and it still holds up well with respect to frontier.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;why there isn&amp;#39;t anything offical.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;People here wouldn&amp;#39;t know about that any more than you do, would they? Find someone affiliated with DeepSeek and shoot them a DM/email if you really must, that would be actually productive instead of this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47whlg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040873,"author_flair_text":null,"treatment_tags":[],"created_utc":1753040873,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n47uwch","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"created_utc":1753040370,"send_replies":true,"parent_id":"t1_n47si1r","score":0,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wouldn't say I am suffering, I can live without deepseek too, or without any llm at all. It's not affecting my life directly but it's just deepseek r1 is so good and I can't wait for new model, so excited. Also it's not about letting people know I am suffering or so excited, I was really wondering if this long time is normal or why there isn't anything offical. If the model is going to be good, I don't really care a delay, I can wait 1 month or even a year but there isn't even anything offical at all...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47uwch","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wouldn&amp;#39;t say I am suffering, I can live without deepseek too, or without any llm at all. It&amp;#39;s not affecting my life directly but it&amp;#39;s just deepseek r1 is so good and I can&amp;#39;t wait for new model, so excited. Also it&amp;#39;s not about letting people know I am suffering or so excited, I was really wondering if this long time is normal or why there isn&amp;#39;t anything offical. If the model is going to be good, I don&amp;#39;t really care a delay, I can wait 1 month or even a year but there isn&amp;#39;t even anything offical at all...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47uwch/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040370,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n47si1r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nullmove","can_mod_post":false,"created_utc":1753039603,"send_replies":true,"parent_id":"t3_1m4ta0f","score":6,"author_fullname":"t2_aq4j0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Some people really can't deal with delayed gratification. On top of it, they have to let rest of us know of their \\"suffering\\". So weird.\\n\\nDeepSeek doesn't owe you anything. Not even an update, let alone the model. If your wellbeing requires \\"we're working on it\\" confirmation, that's a distinctly you problem. Get a grip.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47si1r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some people really can&amp;#39;t deal with delayed gratification. On top of it, they have to let rest of us know of their &amp;quot;suffering&amp;quot;. So weird.&lt;/p&gt;\\n\\n&lt;p&gt;DeepSeek doesn&amp;#39;t owe you anything. Not even an update, let alone the model. If your wellbeing requires &amp;quot;we&amp;#39;re working on it&amp;quot; confirmation, that&amp;#39;s a distinctly you problem. Get a grip.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47si1r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039603,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46vk97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SAPPHIR3ROS3","can_mod_post":false,"created_utc":1753029690,"send_replies":true,"parent_id":"t3_1m4ta0f","score":4,"author_fullname":"t2_2vre9dh1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A few weeks ago I read something about the fact that the ceo is holding the release until he is satisfied with the results of R2, from what i know R2 is ‚Äúalready here‚Äù with optimal results in benchmark (as every model release ever) but the ceo strive another V3/R1 moment. This could mean literally anything: tomorrow, next week, after openai open model, after gpt5, claude 4.5. I think he is waiting probably on some move from openai but it‚Äôs just my theory","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46vk97","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A few weeks ago I read something about the fact that the ceo is holding the release until he is satisfied with the results of R2, from what i know R2 is ‚Äúalready here‚Äù with optimal results in benchmark (as every model release ever) but the ceo strive another V3/R1 moment. This could mean literally anything: tomorrow, next week, after openai open model, after gpt5, claude 4.5. I think he is waiting probably on some move from openai but it‚Äôs just my theory&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46vk97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029690,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47oliq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SidneyFong","can_mod_post":false,"created_utc":1753038383,"send_replies":true,"parent_id":"t1_n470kii","score":1,"author_fullname":"t2_929ppz18","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah it would be weird for them to release a big update less than two months after R1-0528 which was released in late May.\\n\\nSure they might have a new base model (analogous to DeepSeek V3) to base R2 on top of, but then why wouldn't they release the base model (as V4 or whatever) first...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47oliq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it would be weird for them to release a big update less than two months after R1-0528 which was released in late May.&lt;/p&gt;\\n\\n&lt;p&gt;Sure they might have a new base model (analogous to DeepSeek V3) to base R2 on top of, but then why wouldn&amp;#39;t they release the base model (as V4 or whatever) first...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47oliq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753038383,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n470kii","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GlassGhost","can_mod_post":false,"created_utc":1753031173,"send_replies":true,"parent_id":"t3_1m4ta0f","score":2,"author_fullname":"t2_cm2c8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"TL;DR Deepseek R1-0528 is basically R2 but you should try Dhanishtha if you haven't already.\\n\\n\\\\------\\n\\nWhen I go into a pizza place, I remember quality takes time‚ÄîI'd rather wait a bit for something made with care than rush it.  Remember \\"R2\\" is a number on the side of the box, R1-0528 might as well be called R2 when you look at the benchmarks compared to the original R1, and you also have to remember what we're looking for here isn't just performance benchmarks, but cost per teraflop per billion parameters per 1,000 tokens.\\n\\nAnd there are far too many models posting high benchmark scores, but none showing average token cost per answer on these benchmarks.\\n\\nWhat there is a open-weight 14b model that does questions using 5x less tokens than the 671b Deepseek R1-0528 and then you also have to  estimate \\n\\n671B model R1-0528 ‚Üí 2 √ó 1,000 √ó 671B = 1,342 trillion FLOPs (1,342 TFLOPs) per 1000 tokens\\n\\nHere is an interesting model - https://huggingface.co/HelpingAI/Dhanishtha-2.0-preview.\\n\\n14B model ‚Üí 2 √ó 1,000 √ó 14B = 28 trillion FLOPs (28 TFLOPs) per 1000 tokens\\n\\nhere is an example prompt that usually takes a model like R1-0528 671b like 7000 tokens and Dhanishtha about 1000:\\n\\nLine segments or edges G=(E,Q), W= (E,P), and F=(Q,P) connect vertices Q = (0, 0), E = ( length(G), 0), and P = ( length(F) cos(Œ±), length(F) sin(Œ±)). We know segment lengths F, W, and angle EQP = Œ± at Q. What is the equation for the length of G; the x-coordinate of E? Please reason step by step, and put your final answer within \\\\\\\\boxed{}.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n470kii","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;TL;DR Deepseek R1-0528 is basically R2 but you should try Dhanishtha if you haven&amp;#39;t already.&lt;/p&gt;\\n\\n&lt;p&gt;------&lt;/p&gt;\\n\\n&lt;p&gt;When I go into a pizza place, I remember quality takes time‚ÄîI&amp;#39;d rather wait a bit for something made with care than rush it.  Remember &amp;quot;R2&amp;quot; is a number on the side of the box, R1-0528 might as well be called R2 when you look at the benchmarks compared to the original R1, and you also have to remember what we&amp;#39;re looking for here isn&amp;#39;t just performance benchmarks, but cost per teraflop per billion parameters per 1,000 tokens.&lt;/p&gt;\\n\\n&lt;p&gt;And there are far too many models posting high benchmark scores, but none showing average token cost per answer on these benchmarks.&lt;/p&gt;\\n\\n&lt;p&gt;What there is a open-weight 14b model that does questions using 5x less tokens than the 671b Deepseek R1-0528 and then you also have to  estimate &lt;/p&gt;\\n\\n&lt;p&gt;671B model R1-0528 ‚Üí 2 √ó 1,000 √ó 671B = 1,342 trillion FLOPs (1,342 TFLOPs) per 1000 tokens&lt;/p&gt;\\n\\n&lt;p&gt;Here is an interesting model - &lt;a href=\\"https://huggingface.co/HelpingAI/Dhanishtha-2.0-preview\\"&gt;https://huggingface.co/HelpingAI/Dhanishtha-2.0-preview&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;14B model ‚Üí 2 √ó 1,000 √ó 14B = 28 trillion FLOPs (28 TFLOPs) per 1000 tokens&lt;/p&gt;\\n\\n&lt;p&gt;here is an example prompt that usually takes a model like R1-0528 671b like 7000 tokens and Dhanishtha about 1000:&lt;/p&gt;\\n\\n&lt;p&gt;Line segments or edges G=(E,Q), W= (E,P), and F=(Q,P) connect vertices Q = (0, 0), E = ( length(G), 0), and P = ( length(F) cos(Œ±), length(F) sin(Œ±)). We know segment lengths F, W, and angle EQP = Œ± at Q. What is the equation for the length of G; the x-coordinate of E? Please reason step by step, and put your final answer within \\\\boxed{}.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n470kii/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031173,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47v1pc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"created_utc":1753040418,"send_replies":true,"parent_id":"t1_n47swmr","score":1,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As I know it was just a rumor, probably real but not official thing at all","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47v1pc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As I know it was just a rumor, probably real but not official thing at all&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47v1pc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040418,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47swmr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Important_Concept967","can_mod_post":false,"created_utc":1753039733,"send_replies":true,"parent_id":"t3_1m4ta0f","score":2,"author_fullname":"t2_10htrrqujv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what do you mean not a word? They stated like a week ago they are working on it and pushed back the release because the CEO wasn't happy with the performance yet","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47swmr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what do you mean not a word? They stated like a week ago they are working on it and pushed back the release because the CEO wasn&amp;#39;t happy with the performance yet&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47swmr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039733,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n478y3n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n478461","score":1,"author_fullname":"t2_y1vyie97k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh, I didn't know there was big gap like this. My bad! I just tested the 30A3 and find it good, I should quickly go and check the 32B model","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n478y3n","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh, I didn&amp;#39;t know there was big gap like this. My bad! I just tested the 30A3 and find it good, I should quickly go and check the 32B model&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n478y3n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033614,"author_flair_text":null,"treatment_tags":[],"created_utc":1753033614,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48hlt3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47izud","score":1,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Besides the numbers, there is also training data and how it turned out. \\n\\nActive parameters and square root stuff relates to general intelligence and the whole \\"30b\\" portion is the knowledge it can hold. They're approximations.\\n\\nSo take something like hunyuan.. it can recall a lot of stuff but when I used it, it couldn't tell who said what in a chat.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n48hlt3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Besides the numbers, there is also training data and how it turned out. &lt;/p&gt;\\n\\n&lt;p&gt;Active parameters and square root stuff relates to general intelligence and the whole &amp;quot;30b&amp;quot; portion is the knowledge it can hold. They&amp;#39;re approximations.&lt;/p&gt;\\n\\n&lt;p&gt;So take something like hunyuan.. it can recall a lot of stuff but when I used it, it couldn&amp;#39;t tell who said what in a chat.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n48hlt3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753047457,"author_flair_text":null,"treatment_tags":[],"created_utc":1753047457,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48ou6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aggressive-Physics17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47izud","score":1,"author_fullname":"t2_1rboovfa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i recommend building a reasonably comprehensive benchmark based on your use cases.\\n\\ni have a private one with knowledge, reasoning and nuance categories. there are no options to choose from. i always do 0.7 temp for its queries (unless ai makers explicitly request a specific one, such as 0.3 for deepseek v3). in it,  \\nqwen3-32b scored 7/12, 15/15 and 7/9,  \\nqwen3-14b scored 4/12, 15/15 and 6/9,  \\nqwen3-30b-a3b scored 1/12, 10/15 and 3/9. since i made this benchmark around my preferences, it is actually a good heuristic for me. represents my experience with them.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n48ou6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i recommend building a reasonably comprehensive benchmark based on your use cases.&lt;/p&gt;\\n\\n&lt;p&gt;i have a private one with knowledge, reasoning and nuance categories. there are no options to choose from. i always do 0.7 temp for its queries (unless ai makers explicitly request a specific one, such as 0.3 for deepseek v3). in it,&lt;br/&gt;\\nqwen3-32b scored 7/12, 15/15 and 7/9,&lt;br/&gt;\\nqwen3-14b scored 4/12, 15/15 and 6/9,&lt;br/&gt;\\nqwen3-30b-a3b scored 1/12, 10/15 and 3/9. since i made this benchmark around my preferences, it is actually a good heuristic for me. represents my experience with them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n48ou6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753049855,"author_flair_text":null,"treatment_tags":[],"created_utc":1753049855,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47izud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n478461","score":1,"author_fullname":"t2_y1vyie97k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"hmm and quick question, so is qwen 3 14B better/smarter then the 30A3 with/without thinking enabled?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n47izud","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hmm and quick question, so is qwen 3 14B better/smarter then the 30A3 with/without thinking enabled?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47izud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036643,"author_flair_text":null,"treatment_tags":[],"created_utc":1753036643,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n478461","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aggressive-Physics17","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46zp9a","score":2,"author_fullname":"t2_1rboovfa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you're referring to Qwen3 A3B-30B, he's referring to Qwen3-32B\\n\\nthe 32B isn't MoE so all 32B are active per token  \\nA3B-30B isn't in the same class even though the number \\"30B\\" is similar to \\"32B\\"  \\n3 billion \\\\* 30 billion = 90 quintillion (or 90x10\\\\^18), so sqrt(90 x 10\\\\^18) = sqrt(90) √ó sqrt(10\\\\^18) = 9.487 x 10\\\\^9, so it should behave roughly like a 9.49B dense model and consequently nowhere near Qwen3-32B","edited":false,"author_flair_css_class":null,"name":"t1_n478461","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you&amp;#39;re referring to Qwen3 A3B-30B, he&amp;#39;s referring to Qwen3-32B&lt;/p&gt;\\n\\n&lt;p&gt;the 32B isn&amp;#39;t MoE so all 32B are active per token&lt;br/&gt;\\nA3B-30B isn&amp;#39;t in the same class even though the number &amp;quot;30B&amp;quot; is similar to &amp;quot;32B&amp;quot;&lt;br/&gt;\\n3 billion * 30 billion = 90 quintillion (or 90x10^18), so sqrt(90 x 10^18) = sqrt(90) √ó sqrt(10^18) = 9.487 x 10^9, so it should behave roughly like a 9.49B dense model and consequently nowhere near Qwen3-32B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n478461/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033375,"author_flair_text":null,"collapsed":false,"created_utc":1753033375,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n46zp9a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46z7a5","score":1,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah we can agree on that 32B being the king and since it has just 3B active params it's so fast as well","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46zp9a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah we can agree on that 32B being the king and since it has just 3B active params it&amp;#39;s so fast as well&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46zp9a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030918,"author_flair_text":null,"treatment_tags":[],"created_utc":1753030918,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48d29i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47gehi","score":1,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure.\\n\\n\\nCan I ask what job you're doing where you need fiction writing ability?\\n\\n\\nHard to imagine your typical 10,000 hours reading as a child, author, needing an LLM but who knows. We're all fundamentally lazy, right?","edited":false,"author_flair_css_class":null,"name":"t1_n48d29i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure.&lt;/p&gt;\\n\\n&lt;p&gt;Can I ask what job you&amp;#39;re doing where you need fiction writing ability?&lt;/p&gt;\\n\\n&lt;p&gt;Hard to imagine your typical 10,000 hours reading as a child, author, needing an LLM but who knows. We&amp;#39;re all fundamentally lazy, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4ta0f","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n48d29i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753046005,"author_flair_text":null,"collapsed":false,"created_utc":1753046005,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47gehi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46z7a5","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Qwen is the undisputed king of 32b, though.\\n\\nNot for fiction writing where Mistral Small 3.2, Gemma 3 27b and GLM-4 are much better.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47gehi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Qwen is the undisputed king of 32b, though.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Not for fiction writing where Mistral Small 3.2, Gemma 3 27b and GLM-4 are much better.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n47gehi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035845,"author_flair_text":null,"treatment_tags":[],"created_utc":1753035845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n46z7a5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46yhhc","score":0,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen is the undisputed king of 32b, though.\\n\\n\\nI threw the 235b in there as a taster for them.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46z7a5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen is the undisputed king of 32b, though.&lt;/p&gt;\\n\\n&lt;p&gt;I threw the 235b in there as a taster for them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46z7a5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030771,"author_flair_text":null,"treatment_tags":[],"created_utc":1753030771,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n46yhhc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ba2sYd","can_mod_post":false,"created_utc":1753030559,"send_replies":true,"parent_id":"t1_n46wwlb","score":2,"author_fullname":"t2_y1vyie97k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, many new models have been released, but DeepSeek is still incredibly good and I still find it better than most in many areas. That‚Äôs exactly why both I and many others are still excitedly waiting for R2. and about the qwen 235b, Well it's not bad but I I wouldn't tell it's the king, though it would be good if they could create small versions of their llms instead of distillation","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46yhhc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, many new models have been released, but DeepSeek is still incredibly good and I still find it better than most in many areas. That‚Äôs exactly why both I and many others are still excitedly waiting for R2. and about the qwen 235b, Well it&amp;#39;s not bad but I I wouldn&amp;#39;t tell it&amp;#39;s the king, though it would be good if they could create small versions of their llms instead of distillation&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46yhhc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030559,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46zb97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stoppableDissolution","can_mod_post":false,"created_utc":1753030804,"send_replies":true,"parent_id":"t1_n46wwlb","score":1,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wish deepseek made something scout-sized but actually good. Or 40-70b dense.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46zb97","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wish deepseek made something scout-sized but actually good. Or 40-70b dense.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4ta0f","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46zb97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030804,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n46wwlb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1753030092,"send_replies":true,"parent_id":"t3_1m4ta0f","score":2,"author_fullname":"t2_by77ogdhr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They don't really need to do anything, though, do they?\\n\\n\\nThey're still topping the frontier charts with the proprietary models, it seems.\\n\\n\\nIf they really wanna advertise their technical prowess, they should come down to 32b/235b and challenge the king.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46wwlb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They don&amp;#39;t really need to do anything, though, do they?&lt;/p&gt;\\n\\n&lt;p&gt;They&amp;#39;re still topping the frontier charts with the proprietary models, it seems.&lt;/p&gt;\\n\\n&lt;p&gt;If they really wanna advertise their technical prowess, they should come down to 32b/235b and challenge the king.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46wwlb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030092,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46xfhn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LagOps91","can_mod_post":false,"created_utc":1753030247,"send_replies":true,"parent_id":"t3_1m4ta0f","score":0,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's quite funny to me how open ai gets flack for doing too many announcements and hype posts, but when you don't constantly get a \\"we are working on it\\" from deepseek, then that somehow is odd? let's just have a bit of patience and let them cook. the last thing needed is more expectations and pressure.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46xfhn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s quite funny to me how open ai gets flack for doing too many announcements and hype posts, but when you don&amp;#39;t constantly get a &amp;quot;we are working on it&amp;quot; from deepseek, then that somehow is odd? let&amp;#39;s just have a bit of patience and let them cook. the last thing needed is more expectations and pressure.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4ta0f/where_is_deepsseek_r2/n46xfhn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030247,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4ta0f","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
