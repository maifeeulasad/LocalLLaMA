import{j as e}from"./index-BgwOAK4-.js";import{R as t}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"This is kind of just a \\"wishlist\\", but I'm looking for locally hosted alternatives to a variety of work tools like SciSpace/Notebook LM, Zapier, etc.\\n\\nRecently I've been building out a knowledge management system using Obsidian/Dataview to track and link research topics, events/conferences/journals/specific papers, other researchers in the field, etc. and I'm looking to tie it together with my email, calendar, to-do list, etc.\\n\\nThere are lots of domain-specific subtools, etc. but ideally I'm shooting for an integrated system that would, e.g. ingest an RSS feed of research papers (overnight if necessary), identify which papers are relevant to research topics in my notes, follow the links in the markdown files to identify related people and events, look through my emails/calendar to see if there are recent contacts from those people or upcoming events where I'd be in contact with them, and add a tentative \\"Ask XYZ person about result ABC from this paper\\" to my to-do list.\\n\\nIn other words, combine continual ingestion of new content, and manage updates to the knowledge base itself (inclusive of notes, emails, calendar, to-do's as part of the knowledge base). It seems that Zapier might be able to handle that with the right set of automations, but both the pricing and privacy concerns are pushing me towards a locally hosted solution.\\n\\nThus far I've really only played with basic tools like LM Studio and Anything LLM, with a bit of work using guidance directly with llama.cpp. It seems like LangGraph would be the baseline tool for stringing together a more complex set of agents like this, but I'm not sure if that's the best place to start or if there are more developed tools that would make this easier, or if others have already developed a framework for this kind of automation.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Has anyone set up a generalized work/research assistant?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lu7hd6","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.5,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_4ae9u","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751925833,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;This is kind of just a &amp;quot;wishlist&amp;quot;, but I&amp;#39;m looking for locally hosted alternatives to a variety of work tools like SciSpace/Notebook LM, Zapier, etc.&lt;/p&gt;\\n\\n&lt;p&gt;Recently I&amp;#39;ve been building out a knowledge management system using Obsidian/Dataview to track and link research topics, events/conferences/journals/specific papers, other researchers in the field, etc. and I&amp;#39;m looking to tie it together with my email, calendar, to-do list, etc.&lt;/p&gt;\\n\\n&lt;p&gt;There are lots of domain-specific subtools, etc. but ideally I&amp;#39;m shooting for an integrated system that would, e.g. ingest an RSS feed of research papers (overnight if necessary), identify which papers are relevant to research topics in my notes, follow the links in the markdown files to identify related people and events, look through my emails/calendar to see if there are recent contacts from those people or upcoming events where I&amp;#39;d be in contact with them, and add a tentative &amp;quot;Ask XYZ person about result ABC from this paper&amp;quot; to my to-do list.&lt;/p&gt;\\n\\n&lt;p&gt;In other words, combine continual ingestion of new content, and manage updates to the knowledge base itself (inclusive of notes, emails, calendar, to-do&amp;#39;s as part of the knowledge base). It seems that Zapier might be able to handle that with the right set of automations, but both the pricing and privacy concerns are pushing me towards a locally hosted solution.&lt;/p&gt;\\n\\n&lt;p&gt;Thus far I&amp;#39;ve really only played with basic tools like LM Studio and Anything LLM, with a bit of work using guidance directly with llama.cpp. It seems like LangGraph would be the baseline tool for stringing together a more complex set of agents like this, but I&amp;#39;m not sure if that&amp;#39;s the best place to start or if there are more developed tools that would make this easier, or if others have already developed a framework for this kind of automation.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lu7hd6","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"JanusTheDoorman","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lu7hd6/has_anyone_set_up_a_generalized_workresearch/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lu7hd6/has_anyone_set_up_a_generalized_workresearch/","subreddit_subscribers":496034,"created_utc":1751925833,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vs984","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ekaj","can_mod_post":false,"created_utc":1751926554,"send_replies":true,"parent_id":"t3_1lu7hd6","score":3,"author_fullname":"t2_3cajs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes. I've spent since last March building one. I first started with a gradio PoC, and then built a FastAPI instance which is on pause until I get the standalone client pubished to pypi. (next day or so, planning to make a post here about it)\\n\\nThe goal is to extend functionality to support exactly what you describe(re: ingestion of new/related/tracked content based on specifiers into a centralized DB with reporting and notification support). Placeholder is there, need to flesh it out. Depending on timelines, that functionality could exist in tldw\\\\_chatbook in a couple weeks.  \\nFirst iteration will just be tracking websites/videos/articles downloading/ingesting/analyzing them, then work on integrations to allow people to chain n8n or zapier to do whatever with stuff.\\n\\nServer portion is next, its been built out partially but paused due to RAG, wanted to feel out a proper API to be able to support OpenAIs RAG api along with others/figure out how best to allow for compatibility. Revisiting that soon.\\n\\n[https://github.com/rmusser01/tldw\\\\_server/](https://github.com/rmusser01/tldw_server/)\\n\\n[https://github.com/rmusser01/tldw\\\\_chatbook/tree/dev](https://github.com/rmusser01/tldw_chatbook/tree/dev)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vs984","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes. I&amp;#39;ve spent since last March building one. I first started with a gradio PoC, and then built a FastAPI instance which is on pause until I get the standalone client pubished to pypi. (next day or so, planning to make a post here about it)&lt;/p&gt;\\n\\n&lt;p&gt;The goal is to extend functionality to support exactly what you describe(re: ingestion of new/related/tracked content based on specifiers into a centralized DB with reporting and notification support). Placeholder is there, need to flesh it out. Depending on timelines, that functionality could exist in tldw_chatbook in a couple weeks.&lt;br/&gt;\\nFirst iteration will just be tracking websites/videos/articles downloading/ingesting/analyzing them, then work on integrations to allow people to chain n8n or zapier to do whatever with stuff.&lt;/p&gt;\\n\\n&lt;p&gt;Server portion is next, its been built out partially but paused due to RAG, wanted to feel out a proper API to be able to support OpenAIs RAG api along with others/figure out how best to allow for compatibility. Revisiting that soon.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/rmusser01/tldw_server/\\"&gt;https://github.com/rmusser01/tldw_server/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/rmusser01/tldw_chatbook/tree/dev\\"&gt;https://github.com/rmusser01/tldw_chatbook/tree/dev&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lu7hd6/has_anyone_set_up_a_generalized_workresearch/n1vs984/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751926554,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lu7hd6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wogzd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ii_social","can_mod_post":false,"created_utc":1751937200,"send_replies":true,"parent_id":"t3_1lu7hd6","score":1,"author_fullname":"t2_tohvxz80x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have but not using open source models, and using cursor as the agentic engine","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1wogzd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have but not using open source models, and using cursor as the agentic engine&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lu7hd6/has_anyone_set_up_a_generalized_workresearch/n1wogzd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751937200,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lu7hd6","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(t,{data:a});export{s as default};
