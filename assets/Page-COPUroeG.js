import{j as e}from"./index-Cs1fA_b_.js";import{R as l}from"./RedditPostRenderer-CcGVkzgc.js";import"./index-DCw-JEtz.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I benchmarked (almost) every model that can fit in 24GB VRAM (Qwens, R1 distils, Mistrals, even Llama 70b gguf)","link_flair_richtext":[{"e":"text","t":"Other"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":71,"top_awarded_type":null,"hide_score":false,"name":"t3_1i8tx5z","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.99,"author_flair_background_color":null,"ups":1847,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_slwqrxz3","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Other","can_mod_post":false,"score":1847,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/CNjA75t5Ou8MduM7jYGuSnAnkFL4nwV2NgZs8J1sYXs.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1737720530,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/es9l38ezmxee1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/es9l38ezmxee1.png?auto=webp&amp;s=a25e15632e756c69969090dabbc4bf7f27245b77","width":2749,"height":1403},"resolutions":[{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=66e7e134c4f79235e4138b789f3a62a01fde1438","width":108,"height":55},{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d36221230fd406e95cf20070d80780060c2ba898","width":216,"height":110},{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4895d643ba8833c38ad4fddfd2d251f61a3bc0cf","width":320,"height":163},{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a66f2c3fda0b03915eea1c0a72185b32e17e660","width":640,"height":326},{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=86bdcdea7c331628d38013523a1c9681fe761510","width":960,"height":489},{"url":"https://preview.redd.it/es9l38ezmxee1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c7f135455a822371e28861c31dd3ba0ed28bb53","width":1080,"height":551}],"variants":{},"id":"a71UVY3iZ22XqOuq7ISrZQJwH8TlP46mQwJ6xDTPy3s"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"7a7848d2-bf8e-11ed-8c2f-765d15199f78","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#94e044","id":"1i8tx5z","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"kyazoglu","discussion_type":null,"num_comments":212,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/","stickied":false,"url":"https://i.redd.it/es9l38ezmxee1.png","subreddit_subscribers":492230,"created_utc":1737720530,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wl55p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DrKedorkian","can_mod_post":false,"created_utc":1737724570,"send_replies":true,"parent_id":"t3_1i8tx5z","score":180,"author_fullname":"t2_3h35h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My 4090 and I thank you immensely","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wl55p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My 4090 and I thank you immensely&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wl55p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737724570,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":180}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ymx78","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_sqrkl","can_mod_post":false,"created_utc":1737746211,"send_replies":true,"parent_id":"t1_m8wbkq7","score":39,"author_fullname":"t2_pp9qh5t8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wonder how much these results are skewed by differences in how the models format answers, causing answer extraction failures on otherwise correct responses.\\n\\nSee:\\n\\nhttps://x.com/HKydlicek/status/1881734376696041659\\n\\nhttps://github.com/huggingface/Math-Verify\\n\\nThey noted these score jumps when using their method for answer extraction &amp; evaluation:\\n\\n-  Mistral-Large-Instruct-2411: 1.14 → 47.12 \\n-  Qwen2.5-32B-Instruct: 0 → 61.12\\n-  Meta-Llama-3.1-70B-Instruct: 2.91 → 37.52\\n-  phi-4: 10.96 → 48.92","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ymx78","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder how much these results are skewed by differences in how the models format answers, causing answer extraction failures on otherwise correct responses.&lt;/p&gt;\\n\\n&lt;p&gt;See:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://x.com/HKydlicek/status/1881734376696041659\\"&gt;https://x.com/HKydlicek/status/1881734376696041659&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/huggingface/Math-Verify\\"&gt;https://github.com/huggingface/Math-Verify&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;They noted these score jumps when using their method for answer extraction &amp;amp; evaluation:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt; Mistral-Large-Instruct-2411: 1.14 → 47.12 &lt;/li&gt;\\n&lt;li&gt; Qwen2.5-32B-Instruct: 0 → 61.12&lt;/li&gt;\\n&lt;li&gt; Meta-Llama-3.1-70B-Instruct: 2.91 → 37.52&lt;/li&gt;\\n&lt;li&gt; phi-4: 10.96 → 48.92&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ymx78/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737746211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mezf31f","id":"mezf31f","parent_id":"t1_m92h4vq","depth":7,"children":["mezf31f"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m92h4vq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealGentlefox","can_mod_post":false,"send_replies":true,"parent_id":"t1_m91q55e","score":4,"author_fullname":"t2_f471r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just for the record, I didn't mean the bigger models are less interesting just because they're bigger. Mistral / Llama just seem to care more about English/prose/creativity IMO. \\n\\nIf you mean why is everything 7/8B, then 12-14B, then 32B and 70B? I have no idea lol. But Google's models usually buck the trends. (9B and 27B)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_m92h4vq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just for the record, I didn&amp;#39;t mean the bigger models are less interesting just because they&amp;#39;re bigger. Mistral / Llama just seem to care more about English/prose/creativity IMO. &lt;/p&gt;\\n\\n&lt;p&gt;If you mean why is everything 7/8B, then 12-14B, then 32B and 70B? I have no idea lol. But Google&amp;#39;s models usually buck the trends. (9B and 27B)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92h4vq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737798867,"author_flair_text":null,"treatment_tags":[],"created_utc":1737798867,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92so5t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mart-McUH","can_mod_post":false,"send_replies":true,"parent_id":"t1_m91q55e","score":3,"author_fullname":"t2_q3eqbw2b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I would not say there are necessarily sweet-spots. It is mostly perceived like it because models are trained in some discrete sizes and GPU's come with certain VRAM configurations, which leads to kind of good fits.\\n\\nThat said, afaik you need certain model size for certain emergent abilities to appear, which does kind of create some boundaries/stepping stones (but it definitely is not some straight line like HERE and one parameter lower you fail). It seems like between 30B and 70B there is such noticeable step up, but you can't say it happens exactly at 40B, 50B, 60B etc.\\n\\nIf you are willing to offload to RAM (GGUF) then \\\\~40-50B would actually be nice sweetspot for 24GB VRAM (3090/4090), but there are just almost no models there. And so you either step down to 32B or suffer lower quants of 70B.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_m92so5t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would not say there are necessarily sweet-spots. It is mostly perceived like it because models are trained in some discrete sizes and GPU&amp;#39;s come with certain VRAM configurations, which leads to kind of good fits.&lt;/p&gt;\\n\\n&lt;p&gt;That said, afaik you need certain model size for certain emergent abilities to appear, which does kind of create some boundaries/stepping stones (but it definitely is not some straight line like HERE and one parameter lower you fail). It seems like between 30B and 70B there is such noticeable step up, but you can&amp;#39;t say it happens exactly at 40B, 50B, 60B etc.&lt;/p&gt;\\n\\n&lt;p&gt;If you are willing to offload to RAM (GGUF) then ~40-50B would actually be nice sweetspot for 24GB VRAM (3090/4090), but there are just almost no models there. And so you either step down to 32B or suffer lower quants of 70B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92so5t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737805938,"author_flair_text":null,"treatment_tags":[],"created_utc":1737805938,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m91q55e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kisk22","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8yx7em","score":3,"author_fullname":"t2_9c3m2","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Anyone hypothesize the reason why there’s sweet spots in parameter counts?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m91q55e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone hypothesize the reason why there’s sweet spots in parameter counts?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91q55e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737783071,"author_flair_text":null,"treatment_tags":[],"created_utc":1737783071,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m8yx7em","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealGentlefox","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wkdj3","score":9,"author_fullname":"t2_f471r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's kind of bizarre. Anything with a lower param count completely loses track of where things are, what people feel, etc. Anything else of a similar or higher param count &lt;30B is just really, really boring. \\n\\nI know Llama 3.1+ 13B would be KILLING it with fiction/RP if we had it, but nope, nothing between 8B and 70B =/","edited":false,"author_flair_css_class":null,"name":"t1_m8yx7em","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s kind of bizarre. Anything with a lower param count completely loses track of where things are, what people feel, etc. Anything else of a similar or higher param count &amp;lt;30B is just really, really boring. &lt;/p&gt;\\n\\n&lt;p&gt;I know Llama 3.1+ 13B would be KILLING it with fiction/RP if we had it, but nope, nothing between 8B and 70B =/&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yx7em/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737749126,"author_flair_text":null,"collapsed":false,"created_utc":1737749126,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"more","data":{"count":6,"name":"t1_m8y508j","id":"m8y508j","parent_id":"t1_m8wkdj3","depth":4,"children":["m8y508j","m92rihs"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wkdj3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wewp3","score":36,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Depends what it used it for. For anything fiction related, nothing between 8b and 22b compares for writing actual coherent stories, with actual human language, which I can read and enjoy. Qwen below 72b is absolute crap for storytelling; Phi is even worse.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wkdj3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends what it used it for. For anything fiction related, nothing between 8b and 22b compares for writing actual coherent stories, with actual human language, which I can read and enjoy. Qwen below 72b is absolute crap for storytelling; Phi is even worse.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wkdj3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737724281,"author_flair_text":null,"treatment_tags":[],"created_utc":1737724281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wn56v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Slomberer","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wfp1h","score":35,"author_fullname":"t2_6hgmn9ji","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"MN has been my top model for roleplay and personas ever since it released. I haven't found any better model that reached the same average performance, even at such \\"low\\" parameters.","edited":false,"author_flair_css_class":null,"name":"t1_m8wn56v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MN has been my top model for roleplay and personas ever since it released. I haven&amp;#39;t found any better model that reached the same average performance, even at such &amp;quot;low&amp;quot; parameters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wn56v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737725301,"author_flair_text":null,"collapsed":false,"created_utc":1737725301,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wfp1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stddealer","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wewp3","score":21,"author_fullname":"t2_5gk3j2hj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Feels better and is faster than Qwen 14B (both quantized to 4.5 bpw) in my subjective testing.","edited":1737727316,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wfp1h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Feels better and is faster than Qwen 14B (both quantized to 4.5 bpw) in my subjective testing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wfp1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722415,"author_flair_text":null,"treatment_tags":[],"created_utc":1737722415,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yldk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MusicTait","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wewp3","score":3,"author_fullname":"t2_16nig7t0sh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"im sorry for him","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yldk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;im sorry for him&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yldk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737745778,"author_flair_text":null,"treatment_tags":[],"created_utc":1737745778,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m8wwta5","id":"m8wwta5","parent_id":"t1_m8wewp3","depth":3,"children":["m8wwta5"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wewp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThaisaGuilford","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wcgnv","score":52,"author_fullname":"t2_gi5i1qe2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's really bad","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8wewp3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s really bad&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wewp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722079,"author_flair_text":null,"treatment_tags":[],"created_utc":1737722079,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":52}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wcgnv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stddealer","can_mod_post":false,"created_utc":1737720987,"send_replies":true,"parent_id":"t1_m8wbkq7","score":72,"author_fullname":"t2_5gk3j2hj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm a Mistral Nemo fan :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wcgnv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m a Mistral Nemo fan :(&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wcgnv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737720987,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":72}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wx3ty","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"daHaus","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wp59s","score":4,"author_fullname":"t2_966gk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it's using an \\"IQ\\" quant that will have tweaked the weights and may not be the best for generalizing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wx3ty","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s using an &amp;quot;IQ&amp;quot; quant that will have tweaked the weights and may not be the best for generalizing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wx3ty/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728710,"author_flair_text":null,"treatment_tags":[],"created_utc":1737728710,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8z2ugr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wp59s","score":2,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've had similarly bad results running 4KM back in the day, but I also just thought the quantization completely destroys it, interesting that fp16 is also messed up. The one on lmsys arena seems to work well though, not sure how they set it up.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8z2ugr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve had similarly bad results running 4KM back in the day, but I also just thought the quantization completely destroys it, interesting that fp16 is also messed up. The one on lmsys arena seems to work well though, not sure how they set it up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8z2ugr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737750748,"author_flair_text":null,"treatment_tags":[],"created_utc":1737750748,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wp59s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wmecl","score":12,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gguf from bartowski. fp16 directly from the google (google/gemma-2-27b-it)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8wp59s","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gguf from bartowski. fp16 directly from the google (google/gemma-2-27b-it)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wp59s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726013,"author_flair_text":null,"treatment_tags":[],"created_utc":1737726013,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m92vap4","id":"m92vap4","parent_id":"t1_m92ub7z","depth":3,"children":["m92vap4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m92ub7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mart-McUH","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wmecl","score":1,"author_fullname":"t2_q3eqbw2b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma2 has no system prompt which might potentially hamper it. That said 27B should be lot better than 9B so that is strange. For me, locally, 27B always performed better than 9B.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m92ub7z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma2 has no system prompt which might potentially hamper it. That said 27B should be lot better than 9B so that is strange. For me, locally, 27B always performed better than 9B.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92ub7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737806853,"author_flair_text":null,"treatment_tags":[],"created_utc":1737806853,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wmecl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brown2green","can_mod_post":false,"created_utc":1737725030,"send_replies":true,"parent_id":"t1_m8wbkq7","score":16,"author_fullname":"t2_f010l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Regarding Gemma-2-27b-it, I ran the benchmarks but was surprised to find it underperforming compared to the 9b version. Initially, I assumed this was due to using Q4_K_M GGUF, but even testing with the base model (FP16) yielded similarly poor results across several benchmarks. I may have overlooked something, but I excluded it from the results. Do you have any idea what could be the reason for it?\\n\\nWhere did you download it? Some of the older GGUF quantizations of Gemma-2-27B are defective; it took a while before Llama.cpp properly supported it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wmecl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Regarding Gemma-2-27b-it, I ran the benchmarks but was surprised to find it underperforming compared to the 9b version. Initially, I assumed this was due to using Q4_K_M GGUF, but even testing with the base model (FP16) yielded similarly poor results across several benchmarks. I may have overlooked something, but I excluded it from the results. Do you have any idea what could be the reason for it?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Where did you download it? Some of the older GGUF quantizations of Gemma-2-27B are defective; it took a while before Llama.cpp properly supported it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wmecl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737725030,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90m57o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8yjl6d","score":1,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I used to use Nemo all the time with Ollama.\\n\\n\\nIt was easily the best small model for me, at the time.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m90m57o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I used to use Nemo all the time with Ollama.&lt;/p&gt;\\n\\n&lt;p&gt;It was easily the best small model for me, at the time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90m57o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767655,"author_flair_text":null,"treatment_tags":[],"created_utc":1737767655,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_m9ff2mv","id":"m9ff2mv","parent_id":"t1_m8yjl6d","depth":2,"children":["m9ff2mv"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8yjl6d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Southern_Sun_2106","can_mod_post":false,"created_utc":1737745275,"send_replies":true,"parent_id":"t1_m8wbkq7","score":13,"author_fullname":"t2_ajuxt3cr4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mistral Nemo, for some reason, sucks with the template that comes with it from Ollama, when I run it in the app that I use. However, when I use a different template (specifically this one - TEMPLATE \\"\\"\\"\\\\[INST\\\\] {{ if .System }}{{ .System }} {{ end }}{{ .Prompt }} \\\\[/INST\\\\]\\"\\"\\") - Mistral Nemo becomes \\\\*\\\\*the only\\\\*\\\\* model out of the countless local models that I've tried that can actually superbly use long chains of thinking/tool use before giving an answer. It can literally chew through 50 pages of tool results and inner monologues without loosing coherence, when other models (including Qwen Preview) become blubbering fools. Would you mind re-running it with this template?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yjl6d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral Nemo, for some reason, sucks with the template that comes with it from Ollama, when I run it in the app that I use. However, when I use a different template (specifically this one - TEMPLATE &amp;quot;&amp;quot;&amp;quot;[INST] {{ if .System }}{{ .System }} {{ end }}{{ .Prompt }} [/INST]&amp;quot;&amp;quot;&amp;quot;) - Mistral Nemo becomes **the only** model out of the countless local models that I&amp;#39;ve tried that can actually superbly use long chains of thinking/tool use before giving an answer. It can literally chew through 50 pages of tool results and inner monologues without loosing coherence, when other models (including Qwen Preview) become blubbering fools. Would you mind re-running it with this template?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yjl6d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737745275,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m8wx66d","id":"m8wx66d","parent_id":"t1_m8wujji","depth":3,"children":["m8wx66d"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wujji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wridt","score":3,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"no, it's AWQ, not gguf.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8wujji","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, it&amp;#39;s AWQ, not gguf.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wujji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727868,"author_flair_text":null,"treatment_tags":[],"created_utc":1737727868,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wridt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"qado","can_mod_post":false,"created_utc":1737726836,"send_replies":true,"parent_id":"t1_m8wbkq7","score":7,"author_fullname":"t2_i4zxm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1 from bartowski ? then must set temp 0.5 and top-p 0.95. Some comments say Sloth ver is better.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wridt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 from bartowski ? then must set temp 0.5 and top-p 0.95. Some comments say Sloth ver is better.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wridt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726836,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m91ssqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kyazoglu","can_mod_post":false,"send_replies":true,"parent_id":"t1_m900pmx","score":2,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes. Take a look at the fp8 qwen14b vs awq qwen32b. It is almost same thing as q8 vs q4","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m91ssqu","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes. Take a look at the fp8 qwen14b vs awq qwen32b. It is almost same thing as q8 vs q4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91ssqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737784388,"author_flair_text":null,"treatment_tags":[],"created_utc":1737784388,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m900pmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cmndr_spanky","can_mod_post":false,"created_utc":1737760637,"send_replies":true,"parent_id":"t1_m8wbkq7","score":3,"author_fullname":"t2_r41b1kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Here's what I want to know.  I know you said  going lower than Q4 quantization, but do you think I'm better with a Q4 32b model than a Q6 or Q8 14b model of the same family ? I always wonder if performance prefers bigger models vs being able to run those smaller models at better precision.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m900pmx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here&amp;#39;s what I want to know.  I know you said  going lower than Q4 quantization, but do you think I&amp;#39;m better with a Q4 32b model than a Q6 or Q8 14b model of the same family ? I always wonder if performance prefers bigger models vs being able to run those smaller models at better precision.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m900pmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737760637,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9228lw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Acrolith","can_mod_post":false,"created_utc":1737789592,"send_replies":true,"parent_id":"t1_m8wbkq7","score":3,"author_fullname":"t2_882mz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Mistral Nemo turned out to be really bad, sorry for whoever is a fan of it.\\n\\nPeople only use this for RP and creative writing, which I don't think is measured by any of the benchmarks? Subjectively, I've found it to be pretty good at that, as long as you're willing to provide constant supervision, edit its responses etc.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9228lw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Mistral Nemo turned out to be really bad, sorry for whoever is a fan of it.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;People only use this for RP and creative writing, which I don&amp;#39;t think is measured by any of the benchmarks? Subjectively, I&amp;#39;ve found it to be pretty good at that, as long as you&amp;#39;re willing to provide constant supervision, edit its responses etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9228lw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737789592,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ys13r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BreezyChill","can_mod_post":false,"created_utc":1737747647,"send_replies":true,"parent_id":"t1_m8wbkq7","score":2,"author_fullname":"t2_215nppsl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My (person)! Thanks for the takeaways. Was bewildered looking at the chart.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ys13r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My (person)! Thanks for the takeaways. Was bewildered looking at the chart.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ys13r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737747647,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m902z7a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"open_human","can_mod_post":false,"created_utc":1737761362,"send_replies":true,"parent_id":"t1_m8wbkq7","score":2,"author_fullname":"t2_41jsopsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"u/kyazoglu Thanks for the conclusion, would you know which is the fastest decoder model. I had high expectations for Mamba architecture, but their inference speed is still really bad as compared to the transformer architecture. Deepseek Multiheaded latent attention solves kindof compression it but need to see which other models have faster decoder/ inferencing. Thoughts?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m902z7a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"/u/kyazoglu\\"&gt;u/kyazoglu&lt;/a&gt; Thanks for the conclusion, would you know which is the fastest decoder model. I had high expectations for Mamba architecture, but their inference speed is still really bad as compared to the transformer architecture. Deepseek Multiheaded latent attention solves kindof compression it but need to see which other models have faster decoder/ inferencing. Thoughts?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m902z7a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737761362,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mhxko8c","id":"mhxko8c","parent_id":"t1_m92ob9f","depth":2,"children":["mhxko8c"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m92ob9f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mart-McUH","can_mod_post":false,"created_utc":1737803357,"send_replies":true,"parent_id":"t1_m8wbkq7","score":2,"author_fullname":"t2_q3eqbw2b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"3bit quants of 70B, especially IQ3\\\\_S and above are still worth it. IQ2 are too low. For 123B even IQ2\\\\_M is good (IQ2\\\\_XXS is too low also for 123B).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92ob9f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3bit quants of 70B, especially IQ3_S and above are still worth it. IQ2 are too low. For 123B even IQ2_M is good (IQ2_XXS is too low also for 123B).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92ob9f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737803357,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90lig0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wf4no","score":1,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I keep saying it... 27b was awesome and then I repulled one day and it was dogshit.\\n\\n\\nIt's like it got nerfed or something.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m90lig0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I keep saying it... 27b was awesome and then I repulled one day and it was dogshit.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s like it got nerfed or something.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90lig0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767441,"author_flair_text":null,"treatment_tags":[],"created_utc":1737767441,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wf4no","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"----_____---------","can_mod_post":false,"created_utc":1737722175,"send_replies":true,"parent_id":"t1_m8wbkq7","score":3,"author_fullname":"t2_zyr2k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've had the same experience with Gemma-2-27b-it seeming almost worse than 9b back in the day, when they just came out and I was just vibe testing them on lmarena.\\nI don't even know how that's possible, but you may be onto something real.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wf4no","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve had the same experience with Gemma-2-27b-it seeming almost worse than 9b back in the day, when they just came out and I was just vibe testing them on lmarena.\\nI don&amp;#39;t even know how that&amp;#39;s possible, but you may be onto something real.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wf4no/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722175,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m92v0vn","id":"m92v0vn","parent_id":"t1_m90md2z","depth":3,"children":["m92v0vn"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m90md2z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wi7pj","score":2,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you tried them?\\n\\n\\nMore rambling, meandering, electricity burning shite, IME.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m90md2z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried them?&lt;/p&gt;\\n\\n&lt;p&gt;More rambling, meandering, electricity burning shite, IME.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90md2z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767729,"author_flair_text":null,"treatment_tags":[],"created_utc":1737767729,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wi7pj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Professional-Bear857","can_mod_post":false,"created_utc":1737723438,"send_replies":true,"parent_id":"t1_m8wbkq7","score":4,"author_fullname":"t2_yrl9ztfsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try Fuseo1-qwq-skyt1 and fuseo1-qwen-2.5-instruct variants please. I think they are the current SOTA at 24gb.","edited":1737727645,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wi7pj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try Fuseo1-qwq-skyt1 and fuseo1-qwen-2.5-instruct variants please. I think they are the current SOTA at 24gb.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wi7pj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737723438,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zo046","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"perk11","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8ypbi6","score":2,"author_fullname":"t2_ar5cq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That was a bug in llama.cpp initially I think. I've been using it for months now and it just works.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zo046","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That was a bug in llama.cpp initially I think. I&amp;#39;ve been using it for months now and it just works.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zo046/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737756760,"author_flair_text":null,"treatment_tags":[],"created_utc":1737756760,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_m8z8vz8","id":"m8z8vz8","parent_id":"t1_m8ypbi6","depth":3,"children":["m8z8vz8","m92tu8m"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8ypbi6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Alexey2017","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wu5mo","score":1,"author_fullname":"t2_15kyx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How did you manage to tame this model? Double spaces and a lot of markup garbage in the generated text made me abandon Gemma.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8ypbi6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you manage to tame this model? Double spaces and a lot of markup garbage in the generated text made me abandon Gemma.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ypbi6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737746883,"author_flair_text":null,"treatment_tags":[],"created_utc":1737746883,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wu5mo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llama-impersonator","can_mod_post":false,"created_utc":1737727739,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_14usv0hw3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i'm a huge fan of gemma-2-9b but the 27b model does not impress me. it feels worse in some ways and slightly better in others.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wu5mo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m a huge fan of gemma-2-9b but the 27b model does not impress me. it feels worse in some ways and slightly better in others.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wu5mo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727739,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8y0fhm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"latentmag","can_mod_post":false,"created_utc":1737739970,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_hkf0kkl5s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, extremely useful!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8y0fhm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, extremely useful!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y0fhm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737739970,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yeelw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"roller3d","can_mod_post":false,"created_utc":1737743840,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_6w79e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I thought you’re not supposed to use few shot with r1.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yeelw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought you’re not supposed to use few shot with r1.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yeelw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737743840,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ytzqz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LiteSoul","can_mod_post":false,"created_utc":1737748203,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_nbcy4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://www.perplexity.ai/search/what-s-awq-in-the-context-of-l-1yH1gr78Q.6PzCZww.kO7Q\\n\\nStill unsure if I should use AWQ or Q4/8 GGUF","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ytzqz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.perplexity.ai/search/what-s-awq-in-the-context-of-l-1yH1gr78Q.6PzCZww.kO7Q\\"&gt;https://www.perplexity.ai/search/what-s-awq-in-the-context-of-l-1yH1gr78Q.6PzCZww.kO7Q&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Still unsure if I should use AWQ or Q4/8 GGUF&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ytzqz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737748203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90unwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mycall","can_mod_post":false,"created_utc":1737770587,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_22rf5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; the Nemotron model because vLLM doesn’t support its architecture.\\n\\nDo you know if Nemotron is working with/on vLLM support?\\n\\n(&lt;Q4)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90unwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;the Nemotron model because vLLM doesn’t support its architecture.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Do you know if Nemotron is working with/on vLLM support?&lt;/p&gt;\\n\\n&lt;p&gt;(&amp;lt;Q4)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90unwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737770587,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m914ufj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"susne","can_mod_post":false,"created_utc":1737774236,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_cyavn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very cool. Thanks! Do you know of a similar study for 16gb VRAM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m914ufj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very cool. Thanks! Do you know of a similar study for 16gb VRAM?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m914ufj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737774236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9197wn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1737775859,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen2.5-32B and Qwen2.5-32B-Coder are two different models. Could you run the same tests using the coder model?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9197wn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen2.5-32B and Qwen2.5-32B-Coder are two different models. Could you run the same tests using the coder model?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9197wn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737775859,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m91far7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thrumpwart","can_mod_post":false,"created_utc":1737778259,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_iol3buybk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What about my homie GLM4-9B?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m91far7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about my homie GLM4-9B?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91far7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737778259,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9226ic","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DunderSunder","can_mod_post":false,"created_utc":1737789558,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_6l45tfvy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\`Running GGUF models with vLLM is a big pain\`\\n\\nyep I tested Qwen2.5 GGUF from bartowski and none of them worked, They all produce gibberish.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9226ic","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;code&gt;Running GGUF models with vLLM is a big pain&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;yep I tested Qwen2.5 GGUF from bartowski and none of them worked, They all produce gibberish.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9226ic/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737789558,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m994dz0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SuperChewbacca","can_mod_post":false,"send_replies":true,"parent_id":"t1_m92m47y","score":2,"author_fullname":"t2_8lufz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think ollama only supports GGUF and uses llama.cpp for its backend.\\n\\nTo run models with an AWQ quant you need something like vLLM.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m994dz0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think ollama only supports GGUF and uses llama.cpp for its backend.&lt;/p&gt;\\n\\n&lt;p&gt;To run models with an AWQ quant you need something like vLLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m994dz0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737892553,"author_flair_text":null,"treatment_tags":[],"created_utc":1737892553,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m92m47y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tommib","can_mod_post":false,"created_utc":1737802019,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_an8aj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"am I missing it or I can't see Qwen AWQ on ollama? I kinda got lost there looking for it. Im still not sure how to use hugging face","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92m47y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;am I missing it or I can&amp;#39;t see Qwen AWQ on ollama? I kinda got lost there looking for it. Im still not sure how to use hugging face&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92m47y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737802019,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m93tlzy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Statistician5032","can_mod_post":false,"created_utc":1737820364,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_d0l2ueka","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe quantization ruined the performance of deepseek-r1-distill-qwen-32b, otherwise it would be hard to explain why it does not perform well in ARC and math-related problems. I've never tried the unquantized version though, who knows.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m93tlzy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe quantization ruined the performance of deepseek-r1-distill-qwen-32b, otherwise it would be hard to explain why it does not perform well in ARC and math-related problems. I&amp;#39;ve never tried the unquantized version though, who knows.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m93tlzy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737820364,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9a4mo8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gchamon","can_mod_post":false,"created_utc":1737906535,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_i57bz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey there!\\n\\nFirst thanks for the hard work! This is invaluable.\\n\\nI'd like to give you more work though, sorry about that 🤣\\n\\nCould you also do a followup post with instructions to reproduce the benchmarks?\\n\\nIt'd be useful to identify eventual bottlenecks in my setup.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9a4mo8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey there!&lt;/p&gt;\\n\\n&lt;p&gt;First thanks for the hard work! This is invaluable.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d like to give you more work though, sorry about that 🤣&lt;/p&gt;\\n\\n&lt;p&gt;Could you also do a followup post with instructions to reproduce the benchmarks?&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;d be useful to identify eventual bottlenecks in my setup.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9a4mo8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737906535,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mak2gqq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mp3m4k3r","can_mod_post":false,"created_utc":1738506487,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_542ztvqj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey! Not sure if I missed it but what was the methodology used as I am in the market for doing similar tests, currently sinking time into a fork of SWE-Bench to test it against different configurations I have for hosting models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mak2gqq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey! Not sure if I missed it but what was the methodology used as I am in the market for doing similar tests, currently sinking time into a fork of SWE-Bench to test it against different configurations I have for hosting models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mak2gqq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738506487,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mhxjd5l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Cow1976","can_mod_post":false,"created_utc":1742051545,"send_replies":true,"parent_id":"t1_m8wbkq7","score":1,"author_fullname":"t2_3pwbsmdr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow, Phi-4 is so good! I find it great as well. But sometimes bigger models do better on math, slightly, I mean, reasoning, wording perfection.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mhxjd5l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, Phi-4 is so good! I find it great as well. But sometimes bigger models do better on math, slightly, I mean, reasoning, wording perfection.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mhxjd5l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742051545,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":3,"name":"t1_m8whr7i","id":"m8whr7i","parent_id":"t1_m8wbkq7","depth":1,"children":["m8whr7i"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wbkq7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"created_utc":1737720579,"send_replies":true,"parent_id":"t3_1i8tx5z","score":239,"author_fullname":"t2_slwqrxz3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi. I wanted to identify the best model that could fit in a card with 24 GB VRAM, so I conducted some benchmarks. Later, I thought it might be helpful to share the results with the community, so I extended the scope and included additional benchmarks, even those I didn't personally need. All tests were run on an H100 using vLLM as the inference engine (even for GGUF), and I used the lm\\\\_evaluation\\\\_harness repository for benchmarking. However, I found its documentation frustratingly poor. Some tasks triggered a \\"No such task\\" error despite being listed under \\"tasks\\" in the repository. Anyway, I'm not very satisfied but it gets the job done.\\n\\n**Notes:**\\n\\n* Coding benchmarks excluded: None of the benchmarks focus on coding. I think it's clear that Qwen2.5-32B-Coder is the king here that could fit in a 24GB card.\\n* Whole test took one and a half week despite the monster card H100. Benchmarks were running roughly half of that time.\\n* Format compatibility: I prioritized formats with better compatibility with vLLM, which is why I chose AWQ over Q4.\\n* I believe two models are missing here: Gemma-2-27b-it (4-bit) and Llama-3.1-nemotron-51b (which should fit with some 3-bit quantization). I couldn’t test the Nemotron model because vLLM doesn’t support its architecture.\\n* Regarding Gemma-2-27b-it, I ran the benchmarks but was surprised to find it underperforming compared to the 9b version. Initially, I assumed this was due to using Q4\\\\_K\\\\_M GGUF, but even testing with the base model (FP16) yielded similarly poor results across several benchmarks. I may have overlooked something, but I excluded it from the results. Do you have any idea what could be the reason for it?\\n* Running GGUF models with vLLM is a big pain. I knew this feature was recently introduced and labeled as underoptimized but I didn’t expect it to result in a 15x increase in runtime.\\n* Low scores: Some results are very low. In certain cases, they reflect genuinely poor model performance (such as LLaMA GGUF on GSM8K). However, others may indicate faulty measurements (e.g., IFEval of Phi-4). I'm unsure what caused these discrepancies; perhaps the community can provide insights.\\n* Qwen2.5-72b does not have a quant that can fit in 24 gb vram.\\n* TurkishMMLU: This may not matter to most, but the TurkishMMLU benchmark produced nine distinct values without providing an overall average. I manually averaged them.\\n\\n**Conclusion:**\\n\\n* For me the winner is Qwen2.5-32B-Instruct-AWQ although it performed poorly at BBH\\n* I'm kinda surprised to see slightly decreased performance of R1 distilled Qwen compared to normal qwen. This could be explained by the benchmarks I ran, i'm not sure.\\n* Do NOT use big models with extremely low quants (&lt;Q4)\\n* Phi-4 is a monster at Math\\n* There isn't a single best model. As evident from the table, the top-performing results (in green) are distributed across various models.\\n* Mistral Nemo turned out to be really bad, sorry for whoever is a fan of it.","edited":1737721327,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wbkq7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi. I wanted to identify the best model that could fit in a card with 24 GB VRAM, so I conducted some benchmarks. Later, I thought it might be helpful to share the results with the community, so I extended the scope and included additional benchmarks, even those I didn&amp;#39;t personally need. All tests were run on an H100 using vLLM as the inference engine (even for GGUF), and I used the lm_evaluation_harness repository for benchmarking. However, I found its documentation frustratingly poor. Some tasks triggered a &amp;quot;No such task&amp;quot; error despite being listed under &amp;quot;tasks&amp;quot; in the repository. Anyway, I&amp;#39;m not very satisfied but it gets the job done.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Coding benchmarks excluded: None of the benchmarks focus on coding. I think it&amp;#39;s clear that Qwen2.5-32B-Coder is the king here that could fit in a 24GB card.&lt;/li&gt;\\n&lt;li&gt;Whole test took one and a half week despite the monster card H100. Benchmarks were running roughly half of that time.&lt;/li&gt;\\n&lt;li&gt;Format compatibility: I prioritized formats with better compatibility with vLLM, which is why I chose AWQ over Q4.&lt;/li&gt;\\n&lt;li&gt;I believe two models are missing here: Gemma-2-27b-it (4-bit) and Llama-3.1-nemotron-51b (which should fit with some 3-bit quantization). I couldn’t test the Nemotron model because vLLM doesn’t support its architecture.&lt;/li&gt;\\n&lt;li&gt;Regarding Gemma-2-27b-it, I ran the benchmarks but was surprised to find it underperforming compared to the 9b version. Initially, I assumed this was due to using Q4_K_M GGUF, but even testing with the base model (FP16) yielded similarly poor results across several benchmarks. I may have overlooked something, but I excluded it from the results. Do you have any idea what could be the reason for it?&lt;/li&gt;\\n&lt;li&gt;Running GGUF models with vLLM is a big pain. I knew this feature was recently introduced and labeled as underoptimized but I didn’t expect it to result in a 15x increase in runtime.&lt;/li&gt;\\n&lt;li&gt;Low scores: Some results are very low. In certain cases, they reflect genuinely poor model performance (such as LLaMA GGUF on GSM8K). However, others may indicate faulty measurements (e.g., IFEval of Phi-4). I&amp;#39;m unsure what caused these discrepancies; perhaps the community can provide insights.&lt;/li&gt;\\n&lt;li&gt;Qwen2.5-72b does not have a quant that can fit in 24 gb vram.&lt;/li&gt;\\n&lt;li&gt;TurkishMMLU: This may not matter to most, but the TurkishMMLU benchmark produced nine distinct values without providing an overall average. I manually averaged them.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;For me the winner is Qwen2.5-32B-Instruct-AWQ although it performed poorly at BBH&lt;/li&gt;\\n&lt;li&gt;I&amp;#39;m kinda surprised to see slightly decreased performance of R1 distilled Qwen compared to normal qwen. This could be explained by the benchmarks I ran, i&amp;#39;m not sure.&lt;/li&gt;\\n&lt;li&gt;Do NOT use big models with extremely low quants (&amp;lt;Q4)&lt;/li&gt;\\n&lt;li&gt;Phi-4 is a monster at Math&lt;/li&gt;\\n&lt;li&gt;There isn&amp;#39;t a single best model. As evident from the table, the top-performing results (in green) are distributed across various models.&lt;/li&gt;\\n&lt;li&gt;Mistral Nemo turned out to be really bad, sorry for whoever is a fan of it.&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wbkq7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737720579,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":239}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xut72","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MmmmMorphine","can_mod_post":false,"created_utc":1737738414,"send_replies":true,"parent_id":"t1_m8x3h8q","score":17,"author_fullname":"t2_ea78a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does feel a bit misleading - I prefer things like this to be normalized and/or presented as percents of the top (or bottom) performer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xut72","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does feel a bit misleading - I prefer things like this to be normalized and/or presented as percents of the top (or bottom) performer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xut72/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737738414,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m8x3h8q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"30svich","can_mod_post":false,"created_utc":1737730712,"send_replies":true,"parent_id":"t3_1i8tx5z","score":29,"author_fullname":"t2_qfifao8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"0.77 is bad and 0.83 is excellent? Nah, one is slightly better. You should change coloring thresholds","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8x3h8q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;0.77 is bad and 0.83 is excellent? Nah, one is slightly better. You should change coloring thresholds&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x3h8q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737730712,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wk5kz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cosyless","can_mod_post":false,"created_utc":1737724195,"send_replies":true,"parent_id":"t3_1i8tx5z","score":81,"author_fullname":"t2_7uzm1a6f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great job!   \\nAs a side note, this kind of discrete color coding could mislead at first sight. I would like to see this data set in a scatter plot (or bar) format.   \\nEline saglik.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wk5kz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great job!&lt;br/&gt;\\nAs a side note, this kind of discrete color coding could mislead at first sight. I would like to see this data set in a scatter plot (or bar) format.&lt;br/&gt;\\nEline saglik.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wk5kz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737724195,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":81}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8x7ze4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MidAirRunner","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wvmbo","score":11,"author_fullname":"t2_qwhykwm6l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It should not make any difference though? The model is the same.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8x7ze4","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It should not make any difference though? The model is the same.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x7ze4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737732045,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1737732045,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wvmbo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"moldyjellybean","can_mod_post":false,"created_utc":1737728225,"send_replies":true,"parent_id":"t1_m8wdudq","score":4,"author_fullname":"t2_dxkhe2u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nice work, I know MacBooks use the ram differently has this test been down on MacBooks?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wvmbo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nice work, I know MacBooks use the ram differently has this test been down on MacBooks?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wvmbo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728225,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wdudq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1737721608,"send_replies":true,"parent_id":"t3_1i8tx5z","score":73,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"great work, there is much more value in these results than in \\"benchmarks\\" we usually see and can't reproduce later","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wdudq","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;great work, there is much more value in these results than in &amp;quot;benchmarks&amp;quot; we usually see and can&amp;#39;t reproduce later&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wdudq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721608,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":73}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wiogm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kyazoglu","can_mod_post":false,"created_utc":1737723621,"send_replies":true,"parent_id":"t1_m8wh14u","score":3,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're right, the Winogrande results are pretty close. I set it up that way because most models scored above 0.8, but a few were in the 0.77–0.78 range. Those weren’t bad, just worse compared to the all others, and that’s why I highlighted them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wiogm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re right, the Winogrande results are pretty close. I set it up that way because most models scored above 0.8, but a few were in the 0.77–0.78 range. Those weren’t bad, just worse compared to the all others, and that’s why I highlighted them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wiogm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737723621,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wh14u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Legumbrero","can_mod_post":false,"created_utc":1737722966,"send_replies":true,"parent_id":"t3_1i8tx5z","score":23,"author_fullname":"t2_146dhkvfhd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure if it's a color key error but in some cases there might be an overly high emphasis on statistically similar values.  For example, it seems like Winogrande performance depicts a larger gap than there really is, as it keys Mistral nemo as two tiers below as Qwen2.5 when the scores are within 1%ish of each other?  Seems less useful to emphasize those results than some of the ones where there really is a huge distinction (Arc or MMLU).  I'm not familiar with all the benchmarks, so I could be off in my thinking however.  Thank you for sharing this data in any case as it's great to have independent numbers!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wh14u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure if it&amp;#39;s a color key error but in some cases there might be an overly high emphasis on statistically similar values.  For example, it seems like Winogrande performance depicts a larger gap than there really is, as it keys Mistral nemo as two tiers below as Qwen2.5 when the scores are within 1%ish of each other?  Seems less useful to emphasize those results than some of the ones where there really is a huge distinction (Arc or MMLU).  I&amp;#39;m not familiar with all the benchmarks, so I could be off in my thinking however.  Thank you for sharing this data in any case as it&amp;#39;s great to have independent numbers!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wh14u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722966,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wxd9n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cof666","can_mod_post":false,"created_utc":1737728794,"send_replies":true,"parent_id":"t3_1i8tx5z","score":19,"author_fullname":"t2_crptw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi. Can you please do one for 12gb vram?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wxd9n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi. Can you please do one for 12gb vram?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wxd9n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728794,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":6,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8y65tw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8y55hf","score":11,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it's just a pet home project for LLM data visualization based on the OkLab gradients and the standard grid design layouts.","edited":1737744010,"author_flair_css_class":null,"name":"t1_m8y65tw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it&amp;#39;s just a pet home project for LLM data visualization based on the OkLab gradients and the standard grid design layouts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1i8tx5z","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y65tw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737741547,"author_flair_text":null,"collapsed":false,"created_utc":1737741547,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"m8y55hf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8xnoog","score":6,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1740085315,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y55hf/","num_reports":null,"locked":false,"name":"t1_m8y55hf","created":1737741270,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737741270,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m8xnoog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8xl77i","score":27,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks. I wrote a report generator from json based on the Meta LLM models performance reports.\\n\\nI found that absolute-based smooth colors gradation, model names in headers instead of column names (with attention to used quantization) and improved benchmark names with percent-based scores - gives better value to compare the u/kyazoglu results.","edited":1737736859,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8xnoog","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks. I wrote a report generator from json based on the Meta LLM models performance reports.&lt;/p&gt;\\n\\n&lt;p&gt;I found that absolute-based smooth colors gradation, model names in headers instead of column names (with attention to used quantization) and improved benchmark names with percent-based scores - gives better value to compare the &lt;a href=\\"/u/kyazoglu\\"&gt;u/kyazoglu&lt;/a&gt; results.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xnoog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737736447,"author_flair_text":null,"treatment_tags":[],"created_utc":1737736447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}}],"before":null}},"user_reports":[],"saved":false,"id":"m8xl77i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Navith","can_mod_post":false,"created_utc":1737735768,"send_replies":true,"parent_id":"t1_m8xdtgv","score":16,"author_fullname":"t2_5q4w1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How did you make this? It's beautiful","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xl77i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you make this? It&amp;#39;s beautiful&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xl77i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737735768,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8z4g1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Rae_1988","can_mod_post":false,"created_utc":1737751206,"send_replies":true,"parent_id":"t1_m8xdtgv","score":7,"author_fullname":"t2_4ql3eu2xa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"this is 1 million times better","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8z4g1c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this is 1 million times better&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8z4g1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737751206,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m927a6n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sergeant113","can_mod_post":false,"created_utc":1737792662,"send_replies":true,"parent_id":"t1_m8xdtgv","score":3,"author_fullname":"t2_t4knm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma 2 9B is killing it among the bigger-brain peers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m927a6n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 2 9B is killing it among the bigger-brain peers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m927a6n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737792662,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma4rsko","id":"ma4rsko","parent_id":"t1_ma4pt1c","depth":2,"children":["ma4rsko"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma4pt1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wviana","can_mod_post":false,"created_utc":1738291843,"send_replies":true,"parent_id":"t1_m8xdtgv","score":1,"author_fullname":"t2_dmqoc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sent this picture to DeepSeek R1 with the follow prompt \\n\\nread this table. take sum in each column. so we will have the sum for each model. than divide total points by its gb size and present to me descreasing the best performant by Gb. \\n\\nAfter a long thinking here is the answer. I didn't check the values. \\n\\nHere are the models ranked by performance per GB (points/GB), from highest to lowest:\\n\\n1. **Qwenz3-14B** - 103.14  \\n2. **Genma 2** - 95.23  \\n3. **Pia-2** - 77.29  \\n4. **Mistral Memo** - 73.67  \\n5. **DeepSeek-R1** - 67.92  \\n6. **QwG-33B-Preview** - 67.66  \\n7. **Qwenz5-32B** - 67.36  \\n8. **Mistral Small** - 65.00  \\n9. **Llama 33** - 57.18  \\n\\n---  \\n**Methodology**:  \\n- Summed all metric values for each model.  \\n- Divided total points by the model's GB size.  \\n- Sorted descending by points/GB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma4pt1c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sent this picture to DeepSeek R1 with the follow prompt &lt;/p&gt;\\n\\n&lt;p&gt;read this table. take sum in each column. so we will have the sum for each model. than divide total points by its gb size and present to me descreasing the best performant by Gb. &lt;/p&gt;\\n\\n&lt;p&gt;After a long thinking here is the answer. I didn&amp;#39;t check the values. &lt;/p&gt;\\n\\n&lt;p&gt;Here are the models ranked by performance per GB (points/GB), from highest to lowest:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Qwenz3-14B&lt;/strong&gt; - 103.14&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Genma 2&lt;/strong&gt; - 95.23&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Pia-2&lt;/strong&gt; - 77.29&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Mistral Memo&lt;/strong&gt; - 73.67&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;DeepSeek-R1&lt;/strong&gt; - 67.92&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;QwG-33B-Preview&lt;/strong&gt; - 67.66&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Qwenz5-32B&lt;/strong&gt; - 67.36&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Mistral Small&lt;/strong&gt; - 65.00&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Llama 33&lt;/strong&gt; - 57.18&lt;br/&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;:&lt;br/&gt;\\n- Summed all metric values for each model.&lt;br/&gt;\\n- Divided total points by the model&amp;#39;s GB size.&lt;br/&gt;\\n- Sorted descending by points/GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/ma4pt1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738291843,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8xdtgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"created_utc":1737733709,"send_replies":true,"parent_id":"t3_1i8tx5z","score":71,"author_fullname":"t2_1oih32c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/7tuz3g9hqyee1.png?width=3840&amp;format=png&amp;auto=webp&amp;s=a2052911d5cd49bf9ce7c92580d705550103f995","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xdtgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/7tuz3g9hqyee1.png?width=3840&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a2052911d5cd49bf9ce7c92580d705550103f995\\"&gt;https://preview.redd.it/7tuz3g9hqyee1.png?width=3840&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a2052911d5cd49bf9ce7c92580d705550103f995&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xdtgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737733709,"media_metadata":{"7tuz3g9hqyee1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":60,"x":108,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2796fc9f9f0cc83cee62deac7a3d2783d03688f"},{"y":121,"x":216,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3fc53ad6d69c1bdef99420b517b3c44e057803ce"},{"y":180,"x":320,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d222b76ecb9a1527c66f7145da30b5f703d484a"},{"y":360,"x":640,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=95967963caf1168938a15eec797806616e4e187f"},{"y":540,"x":960,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d967f185db6b8fdc48ded289063a2d4d5b44569"},{"y":607,"x":1080,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cf3a47ce40c825d7dbd7eda90135aa7438db5aeb"}],"s":{"y":2160,"x":3840,"u":"https://preview.redd.it/7tuz3g9hqyee1.png?width=3840&amp;format=png&amp;auto=webp&amp;s=a2052911d5cd49bf9ce7c92580d705550103f995"},"id":"7tuz3g9hqyee1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":71}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zxxvy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"subhayan2006","can_mod_post":false,"created_utc":1737759770,"send_replies":true,"parent_id":"t1_m8wi08i","score":4,"author_fullname":"t2_3jd7ktep","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Q3 quants might work better and would potentially fit in the 32gb vram of the 5090, with minimal offloading","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zxxvy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q3 quants might work better and would potentially fit in the 32gb vram of the 5090, with minimal offloading&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zxxvy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737759770,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wi08i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1737723355,"send_replies":true,"parent_id":"t3_1i8tx5z","score":13,"author_fullname":"t2_ogjj6ebj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Q2 quants killed llama 3.3 😅\\nIn theory would easily be the best .","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wi08i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q2 quants killed llama 3.3 😅\\nIn theory would easily be the best .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wi08i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737723355,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xz2aj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Akos-","can_mod_post":false,"created_utc":1737739590,"send_replies":true,"parent_id":"t1_m8xqbpj","score":8,"author_fullname":"t2_3xk4s4iv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\*Cries in GPU poor too\\\\*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xz2aj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;*Cries in GPU poor too*&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xz2aj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737739590,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mavxc4c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Malgamerz","can_mod_post":false,"created_utc":1738653556,"send_replies":true,"parent_id":"t1_m8xqbpj","score":1,"author_fullname":"t2_39y9c6cv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Indeed, here they always talks about using MacBook while me using some ol' GPU, even worse, AMD not Nvidia so no CUDA and it's only 8GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mavxc4c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Indeed, here they always talks about using MacBook while me using some ol&amp;#39; GPU, even worse, AMD not Nvidia so no CUDA and it&amp;#39;s only 8GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mavxc4c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738653556,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8xqbpj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreedyWorking1499","can_mod_post":false,"created_utc":1737737170,"send_replies":true,"parent_id":"t3_1i8tx5z","score":13,"author_fullname":"t2_sixftbze","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone do this with 8GB for the poor folk?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xqbpj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone do this with 8GB for the poor folk?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xqbpj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737737170,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wev3y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StandardLovers","can_mod_post":false,"created_utc":1737722060,"send_replies":true,"parent_id":"t3_1i8tx5z","score":26,"author_fullname":"t2_txchqn9yj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen2.5:32b was my go to model, glad to see it confirmed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wev3y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen2.5:32b was my go to model, glad to see it confirmed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wev3y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722060,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wthgl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThePixelHunter","can_mod_post":false,"created_utc":1737727510,"send_replies":true,"parent_id":"t3_1i8tx5z","score":46,"author_fullname":"t2_e62wz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for this.\\n\\nI asked Claude to recreate the table with the model names as column headers.\\n\\nColor coding was replaced with letter grades (A/B/C/D/F).\\n\\n| Benchmark | fp8-Qwen2.5-14B-Instruct | fp8-Mistral-Nemo-Instruct-2407 | fp8-Phi-4 | Mistral-Small-Instruct-2409-AWQ | gemma-2-9b-it | Qwen2.5-32B-Instruct-AWQ | QWQ-32B-Preview-AWQ | DeepSeek-R1-32B-AWQ | Llama-3.3-70B-Instruct-IQ2_XXS |\\n|-----------|-------------------------|------------------------------|------------|--------------------------------|---------------|------------------------|-------------------|-------------------|------------------------------|\\n| Hellaswag (5-shot acc) | 0.656 (C) | 0.6404 (C) | 0.651 (C) | 0.674 (C) | 0.6072 (C) | 0.6673 (C) | 0.6662 (C) | 0.6304 (C) | 0.6033 (C) |\\n| Hellaswag (5-shot acc_norm) | 0.8445 (A) | 0.8339 (A) | 0.8378 (A) | 0.8632 (A) | 0.8123 (A) | 0.8484 (A) | 0.8523 (A) | 0.8254 (A) | 0.7955 (B) |\\n| Winogrande (5-shot acc) | 0.7956 (B) | 0.8208 (A) | 0.8106 (A) | 0.8327 (A) | 0.7774 (B) | 0.8114 (A) | 0.8098 (A) | 0.7814 (B) | 0.8287 (A) |\\n| Race (0-shot acc) | 0.4526 (D) | 0.4411 (D) | 0.4057 (D) | 0.4651 (D) | 0.4699 (D) | 0.4785 (D) | 0.4517 (D) | 0.4555 (D) | 0.4488 (D) |\\n| TruthfulQA mc2 (0-shot acc) | 0.6844 (C) | 0.5472 (C) | 0.5951 (C) | 0.5646 (C) | 0.6019 (C) | 0.6638 (C) | 0.6004 (C) | 0.5775 (C) | 0.5473 (C) |\\n| BBH (3-shot exact_match) | 0.2169 (F) | 0.7151 (B) | 0.8367 (A) | 0.7478 (B) | 0.6964 (C) | 0.1052 (F) | 0.765 (B) | 0.7412 (B) | 0.7409 (B) |\\n| GPQA main(0-shot) | 0.3594 (F) | 0.3438 (F) | 0.3906 (F) | 0.3594 (F) | 0.3281 (F) | 0.4018 (D) | 0.3929 (F) | 0.4464 (D) | 0.4219 (D) |\\n| GPQA Diamond (0-shot) | 0.3586 (F) | 0.3484 (F) | 0.4091 (D) | 0.3383 (F) | 0.3737 (F) | 0.404 (D) | 0.4292 (D) | 0.399 (F) | 0.3838 (F) |\\n| minerva_math (3-shot) | 0.2316 (F) | 0.2986 (F) | 0.4746 (D) | 0.3694 (F) | 0.2702 (F) | 0.3752 (F) | 0.3434 (F) | 0.4024 (D) | 0.3312 (F) |\\n| Gsm8k (5 shot. Strict-match) | 0.8294 (A) | 0.721 (B) | 0.8984 (A) | 0.8188 (A) | 0.818 (A) | 0.8249 (A) | 0.8226 (A) | 0.8378 (A) | 0.2728 (F) |\\n| logiqa2 (5-shot acc) | 0.7233 (B) | 0.5356 (C) | 0.6584 (C) | 0.5757 (C) | 0.6081 (C) | 0.7564 (B) | 0.7646 (B) | 0.7093 (B) | 0.6088 (C) |\\n| MMLU (5 shot acc) | 0.7973 (B) | 0.6812 (C) | 0.8013 (A) | 0.7099 (B) | 0.7233 (B) | 0.8238 (A) | 0.8233 (A) | 0.8084 (A) | 0.7352 (B) |\\n| MMLU_PRO (5 shot exact_match) | 0.5123 (C) | 0.43 (D) | 0.591 (C) | 0.4638 (D) | 0.4889 (D) | 0.5657 (C) | 0.4461 (D) | 0.5816 (C) | 0.4751 (D) |\\n| ffeval (inst-level-loose-acc) | 0.7038 (B) | 0.4604 (D) | 0.0683 (F) | 0.7098 (B) | 0.7362 (B) | 0.7542 (B) | 0.4556 (D) | 0.5192 (C) | 0.6595 (C) |\\n| arc_easy (5-shot acc) | 0.9087 (A) | 0.8641 (A) | 0.8889 (A) | 0.8801 (A) | 0.8902 (A) | 0.9045 (A) | 0.8939 (A) | 0.8704 (A) | 0.633 (C) |\\n| arc_easy (5-shot acc_norm) | 0.912 (A) | 0.8779 (A) | 0.8948 (A) | 0.8906 (A) | 0.8986 (A) | 0.9108 (A) | 0.8994 (A) | 0.8712 (A) | 0.6347 (C) |\\n| arc_challenge (5-shot acc) | 0.6903 (C) | 0.6101 (C) | 0.6331 (C) | 0.6246 (C) | 0.6741 (C) | 0.7065 (B) | 0.6732 (C) | 0.6169 (C) | 0.3823 (F) |\\n| arc_challenge (5-shot acc_norm) | 0.7227 (B) | 0.6493 (C) | 0.6638 (C) | 0.6706 (C) | 0.7031 (B) | 0.7235 (B) | 0.6954 (C) | 0.6527 (C) | 0.4394 (D) |\\n| Turkishmmlu (5 shot) | 0.645 (C) | 0.465 (D) | 0.585 (C) | 0.451 (D) | 0.57 (C) | 0.693 (C) | 0.69 (C) | 0.635 (C) | 0.573 (C) |","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wthgl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this.&lt;/p&gt;\\n\\n&lt;p&gt;I asked Claude to recreate the table with the model names as column headers.&lt;/p&gt;\\n\\n&lt;p&gt;Color coding was replaced with letter grades (A/B/C/D/F).&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Benchmark&lt;/th&gt;\\n&lt;th&gt;fp8-Qwen2.5-14B-Instruct&lt;/th&gt;\\n&lt;th&gt;fp8-Mistral-Nemo-Instruct-2407&lt;/th&gt;\\n&lt;th&gt;fp8-Phi-4&lt;/th&gt;\\n&lt;th&gt;Mistral-Small-Instruct-2409-AWQ&lt;/th&gt;\\n&lt;th&gt;gemma-2-9b-it&lt;/th&gt;\\n&lt;th&gt;Qwen2.5-32B-Instruct-AWQ&lt;/th&gt;\\n&lt;th&gt;QWQ-32B-Preview-AWQ&lt;/th&gt;\\n&lt;th&gt;DeepSeek-R1-32B-AWQ&lt;/th&gt;\\n&lt;th&gt;Llama-3.3-70B-Instruct-IQ2_XXS&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Hellaswag (5-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.656 (C)&lt;/td&gt;\\n&lt;td&gt;0.6404 (C)&lt;/td&gt;\\n&lt;td&gt;0.651 (C)&lt;/td&gt;\\n&lt;td&gt;0.674 (C)&lt;/td&gt;\\n&lt;td&gt;0.6072 (C)&lt;/td&gt;\\n&lt;td&gt;0.6673 (C)&lt;/td&gt;\\n&lt;td&gt;0.6662 (C)&lt;/td&gt;\\n&lt;td&gt;0.6304 (C)&lt;/td&gt;\\n&lt;td&gt;0.6033 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Hellaswag (5-shot acc_norm)&lt;/td&gt;\\n&lt;td&gt;0.8445 (A)&lt;/td&gt;\\n&lt;td&gt;0.8339 (A)&lt;/td&gt;\\n&lt;td&gt;0.8378 (A)&lt;/td&gt;\\n&lt;td&gt;0.8632 (A)&lt;/td&gt;\\n&lt;td&gt;0.8123 (A)&lt;/td&gt;\\n&lt;td&gt;0.8484 (A)&lt;/td&gt;\\n&lt;td&gt;0.8523 (A)&lt;/td&gt;\\n&lt;td&gt;0.8254 (A)&lt;/td&gt;\\n&lt;td&gt;0.7955 (B)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Winogrande (5-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.7956 (B)&lt;/td&gt;\\n&lt;td&gt;0.8208 (A)&lt;/td&gt;\\n&lt;td&gt;0.8106 (A)&lt;/td&gt;\\n&lt;td&gt;0.8327 (A)&lt;/td&gt;\\n&lt;td&gt;0.7774 (B)&lt;/td&gt;\\n&lt;td&gt;0.8114 (A)&lt;/td&gt;\\n&lt;td&gt;0.8098 (A)&lt;/td&gt;\\n&lt;td&gt;0.7814 (B)&lt;/td&gt;\\n&lt;td&gt;0.8287 (A)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Race (0-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.4526 (D)&lt;/td&gt;\\n&lt;td&gt;0.4411 (D)&lt;/td&gt;\\n&lt;td&gt;0.4057 (D)&lt;/td&gt;\\n&lt;td&gt;0.4651 (D)&lt;/td&gt;\\n&lt;td&gt;0.4699 (D)&lt;/td&gt;\\n&lt;td&gt;0.4785 (D)&lt;/td&gt;\\n&lt;td&gt;0.4517 (D)&lt;/td&gt;\\n&lt;td&gt;0.4555 (D)&lt;/td&gt;\\n&lt;td&gt;0.4488 (D)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;TruthfulQA mc2 (0-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.6844 (C)&lt;/td&gt;\\n&lt;td&gt;0.5472 (C)&lt;/td&gt;\\n&lt;td&gt;0.5951 (C)&lt;/td&gt;\\n&lt;td&gt;0.5646 (C)&lt;/td&gt;\\n&lt;td&gt;0.6019 (C)&lt;/td&gt;\\n&lt;td&gt;0.6638 (C)&lt;/td&gt;\\n&lt;td&gt;0.6004 (C)&lt;/td&gt;\\n&lt;td&gt;0.5775 (C)&lt;/td&gt;\\n&lt;td&gt;0.5473 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;BBH (3-shot exact_match)&lt;/td&gt;\\n&lt;td&gt;0.2169 (F)&lt;/td&gt;\\n&lt;td&gt;0.7151 (B)&lt;/td&gt;\\n&lt;td&gt;0.8367 (A)&lt;/td&gt;\\n&lt;td&gt;0.7478 (B)&lt;/td&gt;\\n&lt;td&gt;0.6964 (C)&lt;/td&gt;\\n&lt;td&gt;0.1052 (F)&lt;/td&gt;\\n&lt;td&gt;0.765 (B)&lt;/td&gt;\\n&lt;td&gt;0.7412 (B)&lt;/td&gt;\\n&lt;td&gt;0.7409 (B)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;GPQA main(0-shot)&lt;/td&gt;\\n&lt;td&gt;0.3594 (F)&lt;/td&gt;\\n&lt;td&gt;0.3438 (F)&lt;/td&gt;\\n&lt;td&gt;0.3906 (F)&lt;/td&gt;\\n&lt;td&gt;0.3594 (F)&lt;/td&gt;\\n&lt;td&gt;0.3281 (F)&lt;/td&gt;\\n&lt;td&gt;0.4018 (D)&lt;/td&gt;\\n&lt;td&gt;0.3929 (F)&lt;/td&gt;\\n&lt;td&gt;0.4464 (D)&lt;/td&gt;\\n&lt;td&gt;0.4219 (D)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;GPQA Diamond (0-shot)&lt;/td&gt;\\n&lt;td&gt;0.3586 (F)&lt;/td&gt;\\n&lt;td&gt;0.3484 (F)&lt;/td&gt;\\n&lt;td&gt;0.4091 (D)&lt;/td&gt;\\n&lt;td&gt;0.3383 (F)&lt;/td&gt;\\n&lt;td&gt;0.3737 (F)&lt;/td&gt;\\n&lt;td&gt;0.404 (D)&lt;/td&gt;\\n&lt;td&gt;0.4292 (D)&lt;/td&gt;\\n&lt;td&gt;0.399 (F)&lt;/td&gt;\\n&lt;td&gt;0.3838 (F)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;minerva_math (3-shot)&lt;/td&gt;\\n&lt;td&gt;0.2316 (F)&lt;/td&gt;\\n&lt;td&gt;0.2986 (F)&lt;/td&gt;\\n&lt;td&gt;0.4746 (D)&lt;/td&gt;\\n&lt;td&gt;0.3694 (F)&lt;/td&gt;\\n&lt;td&gt;0.2702 (F)&lt;/td&gt;\\n&lt;td&gt;0.3752 (F)&lt;/td&gt;\\n&lt;td&gt;0.3434 (F)&lt;/td&gt;\\n&lt;td&gt;0.4024 (D)&lt;/td&gt;\\n&lt;td&gt;0.3312 (F)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Gsm8k (5 shot. Strict-match)&lt;/td&gt;\\n&lt;td&gt;0.8294 (A)&lt;/td&gt;\\n&lt;td&gt;0.721 (B)&lt;/td&gt;\\n&lt;td&gt;0.8984 (A)&lt;/td&gt;\\n&lt;td&gt;0.8188 (A)&lt;/td&gt;\\n&lt;td&gt;0.818 (A)&lt;/td&gt;\\n&lt;td&gt;0.8249 (A)&lt;/td&gt;\\n&lt;td&gt;0.8226 (A)&lt;/td&gt;\\n&lt;td&gt;0.8378 (A)&lt;/td&gt;\\n&lt;td&gt;0.2728 (F)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;logiqa2 (5-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.7233 (B)&lt;/td&gt;\\n&lt;td&gt;0.5356 (C)&lt;/td&gt;\\n&lt;td&gt;0.6584 (C)&lt;/td&gt;\\n&lt;td&gt;0.5757 (C)&lt;/td&gt;\\n&lt;td&gt;0.6081 (C)&lt;/td&gt;\\n&lt;td&gt;0.7564 (B)&lt;/td&gt;\\n&lt;td&gt;0.7646 (B)&lt;/td&gt;\\n&lt;td&gt;0.7093 (B)&lt;/td&gt;\\n&lt;td&gt;0.6088 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;MMLU (5 shot acc)&lt;/td&gt;\\n&lt;td&gt;0.7973 (B)&lt;/td&gt;\\n&lt;td&gt;0.6812 (C)&lt;/td&gt;\\n&lt;td&gt;0.8013 (A)&lt;/td&gt;\\n&lt;td&gt;0.7099 (B)&lt;/td&gt;\\n&lt;td&gt;0.7233 (B)&lt;/td&gt;\\n&lt;td&gt;0.8238 (A)&lt;/td&gt;\\n&lt;td&gt;0.8233 (A)&lt;/td&gt;\\n&lt;td&gt;0.8084 (A)&lt;/td&gt;\\n&lt;td&gt;0.7352 (B)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;MMLU_PRO (5 shot exact_match)&lt;/td&gt;\\n&lt;td&gt;0.5123 (C)&lt;/td&gt;\\n&lt;td&gt;0.43 (D)&lt;/td&gt;\\n&lt;td&gt;0.591 (C)&lt;/td&gt;\\n&lt;td&gt;0.4638 (D)&lt;/td&gt;\\n&lt;td&gt;0.4889 (D)&lt;/td&gt;\\n&lt;td&gt;0.5657 (C)&lt;/td&gt;\\n&lt;td&gt;0.4461 (D)&lt;/td&gt;\\n&lt;td&gt;0.5816 (C)&lt;/td&gt;\\n&lt;td&gt;0.4751 (D)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;ffeval (inst-level-loose-acc)&lt;/td&gt;\\n&lt;td&gt;0.7038 (B)&lt;/td&gt;\\n&lt;td&gt;0.4604 (D)&lt;/td&gt;\\n&lt;td&gt;0.0683 (F)&lt;/td&gt;\\n&lt;td&gt;0.7098 (B)&lt;/td&gt;\\n&lt;td&gt;0.7362 (B)&lt;/td&gt;\\n&lt;td&gt;0.7542 (B)&lt;/td&gt;\\n&lt;td&gt;0.4556 (D)&lt;/td&gt;\\n&lt;td&gt;0.5192 (C)&lt;/td&gt;\\n&lt;td&gt;0.6595 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;arc_easy (5-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.9087 (A)&lt;/td&gt;\\n&lt;td&gt;0.8641 (A)&lt;/td&gt;\\n&lt;td&gt;0.8889 (A)&lt;/td&gt;\\n&lt;td&gt;0.8801 (A)&lt;/td&gt;\\n&lt;td&gt;0.8902 (A)&lt;/td&gt;\\n&lt;td&gt;0.9045 (A)&lt;/td&gt;\\n&lt;td&gt;0.8939 (A)&lt;/td&gt;\\n&lt;td&gt;0.8704 (A)&lt;/td&gt;\\n&lt;td&gt;0.633 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;arc_easy (5-shot acc_norm)&lt;/td&gt;\\n&lt;td&gt;0.912 (A)&lt;/td&gt;\\n&lt;td&gt;0.8779 (A)&lt;/td&gt;\\n&lt;td&gt;0.8948 (A)&lt;/td&gt;\\n&lt;td&gt;0.8906 (A)&lt;/td&gt;\\n&lt;td&gt;0.8986 (A)&lt;/td&gt;\\n&lt;td&gt;0.9108 (A)&lt;/td&gt;\\n&lt;td&gt;0.8994 (A)&lt;/td&gt;\\n&lt;td&gt;0.8712 (A)&lt;/td&gt;\\n&lt;td&gt;0.6347 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;arc_challenge (5-shot acc)&lt;/td&gt;\\n&lt;td&gt;0.6903 (C)&lt;/td&gt;\\n&lt;td&gt;0.6101 (C)&lt;/td&gt;\\n&lt;td&gt;0.6331 (C)&lt;/td&gt;\\n&lt;td&gt;0.6246 (C)&lt;/td&gt;\\n&lt;td&gt;0.6741 (C)&lt;/td&gt;\\n&lt;td&gt;0.7065 (B)&lt;/td&gt;\\n&lt;td&gt;0.6732 (C)&lt;/td&gt;\\n&lt;td&gt;0.6169 (C)&lt;/td&gt;\\n&lt;td&gt;0.3823 (F)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;arc_challenge (5-shot acc_norm)&lt;/td&gt;\\n&lt;td&gt;0.7227 (B)&lt;/td&gt;\\n&lt;td&gt;0.6493 (C)&lt;/td&gt;\\n&lt;td&gt;0.6638 (C)&lt;/td&gt;\\n&lt;td&gt;0.6706 (C)&lt;/td&gt;\\n&lt;td&gt;0.7031 (B)&lt;/td&gt;\\n&lt;td&gt;0.7235 (B)&lt;/td&gt;\\n&lt;td&gt;0.6954 (C)&lt;/td&gt;\\n&lt;td&gt;0.6527 (C)&lt;/td&gt;\\n&lt;td&gt;0.4394 (D)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Turkishmmlu (5 shot)&lt;/td&gt;\\n&lt;td&gt;0.645 (C)&lt;/td&gt;\\n&lt;td&gt;0.465 (D)&lt;/td&gt;\\n&lt;td&gt;0.585 (C)&lt;/td&gt;\\n&lt;td&gt;0.451 (D)&lt;/td&gt;\\n&lt;td&gt;0.57 (C)&lt;/td&gt;\\n&lt;td&gt;0.693 (C)&lt;/td&gt;\\n&lt;td&gt;0.69 (C)&lt;/td&gt;\\n&lt;td&gt;0.635 (C)&lt;/td&gt;\\n&lt;td&gt;0.573 (C)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wthgl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727510,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wpke0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"created_utc":1737726160,"send_replies":true,"parent_id":"t1_m8wp2jk","score":8,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No need for reasoning? Then don't reason. Just spit it out.  \\nIn math which requires reasoning, R1 distil beat Qwen","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wpke0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No need for reasoning? Then don&amp;#39;t reason. Just spit it out.&lt;br/&gt;\\nIn math which requires reasoning, R1 distil beat Qwen&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wpke0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726160,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90dr07","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"boredcynicism","can_mod_post":false,"created_utc":1737764845,"send_replies":true,"parent_id":"t1_m8wp2jk","score":2,"author_fullname":"t2_gtyn8l5pn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sensitive to temperature, top-k, system prompt.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90dr07","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sensitive to temperature, top-k, system prompt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90dr07/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737764845,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wxljt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Professional-Bear857","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wparb","score":6,"author_fullname":"t2_yrl9ztfsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why not have both?\\n\\n  \\n[https://huggingface.co/sm54/FuseO1-DeepSeekR1-Qwen2.5-Coder-32B-Preview-Q4\\\\_K\\\\_M-GGUF](https://huggingface.co/sm54/FuseO1-DeepSeekR1-Qwen2.5-Coder-32B-Preview-Q4_K_M-GGUF)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8wxljt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not have both?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/sm54/FuseO1-DeepSeekR1-Qwen2.5-Coder-32B-Preview-Q4_K_M-GGUF\\"&gt;https://huggingface.co/sm54/FuseO1-DeepSeekR1-Qwen2.5-Coder-32B-Preview-Q4_K_M-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wxljt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728868,"author_flair_text":null,"treatment_tags":[],"created_utc":1737728868,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wparb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EternalOptimister","can_mod_post":false,"created_utc":1737726066,"send_replies":true,"parent_id":"t1_m8wp2jk","score":1,"author_fullname":"t2_1cfh8hg6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Would it also be worse than Qwen-2.5-Coder in coding?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wparb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would it also be worse than Qwen-2.5-Coder in coding?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wparb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726066,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m960tqb","id":"m960tqb","parent_id":"t1_m91vhqw","depth":3,"children":["m960tqb","m98951z"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m91vhqw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EternalOptimister","can_mod_post":false,"send_replies":true,"parent_id":"t1_m90ndwv","score":3,"author_fullname":"t2_1cfh8hg6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because DeepSeek (the main model) is making rounds as being a top model for everything. Thought the distilled versions would be similar!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m91vhqw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because DeepSeek (the main model) is making rounds as being a top model for everything. Thought the distilled versions would be similar!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91vhqw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737785796,"author_flair_text":null,"treatment_tags":[],"created_utc":1737785796,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m90ndwv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1737768081,"send_replies":true,"parent_id":"t1_m8wp2jk","score":1,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why are you very surprised?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90ndwv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why are you very surprised?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90ndwv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737768081,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m960com","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kyr0x0","can_mod_post":false,"created_utc":1737843592,"send_replies":true,"parent_id":"t1_m8wp2jk","score":1,"author_fullname":"t2_dv2ps98i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tested with temp outside 0.5..0.7 range? Because if so, the matter is clear.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m960com","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tested with temp outside 0.5..0.7 range? Because if so, the matter is clear.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m960com/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737843592,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wp2jk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EternalOptimister","can_mod_post":false,"created_utc":1737725986,"send_replies":true,"parent_id":"t3_1i8tx5z","score":9,"author_fullname":"t2_1cfh8hg6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very surprised to see DeepSeek-r1-32B distillation to perform so poorly compared to Qwen-2.5. Any explanation?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wp2jk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very surprised to see DeepSeek-r1-32B distillation to perform so poorly compared to Qwen-2.5. Any explanation?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wp2jk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737725986,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wcddq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Few_Painter_5588","can_mod_post":false,"created_utc":1737720946,"send_replies":true,"parent_id":"t3_1i8tx5z","score":17,"author_fullname":"t2_uvgafqnfy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think the most impressive part here, is the fact that Llama 3.3 has an ifeval score of 66% despite it being an IQ2 XXS quant. That shows how insane it's instruction following capabilities are.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wcddq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the most impressive part here, is the fact that Llama 3.3 has an ifeval score of 66% despite it being an IQ2 XXS quant. That shows how insane it&amp;#39;s instruction following capabilities are.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wcddq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737720946,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zh3tl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rinukkusu","can_mod_post":false,"created_utc":1737754788,"send_replies":true,"parent_id":"t1_m8wv4la","score":1,"author_fullname":"t2_h9n1i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I really like Gemma 2 9B over Llama 3.X 8B or Mistral.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zh3tl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I really like Gemma 2 9B over Llama 3.X 8B or Mistral.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zh3tl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737754788,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wv4la","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thecalmgreen","can_mod_post":false,"created_utc":1737728063,"send_replies":true,"parent_id":"t3_1i8tx5z","score":8,"author_fullname":"t2_17ktgtm91m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I believe that the Gemma 2 9B is one of the \\"oldest\\" models among those tested, and does better than a good number of models. This just makes me want a Gemma 3 even more, but it looks like Google decided to torture us a little. 😪","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wv4la","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I believe that the Gemma 2 9B is one of the &amp;quot;oldest&amp;quot; models among those tested, and does better than a good number of models. This just makes me want a Gemma 3 even more, but it looks like Google decided to torture us a little. 😪&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wv4la/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728063,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90vlza","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OmarBessa","can_mod_post":false,"created_utc":1737770921,"send_replies":true,"parent_id":"t3_1i8tx5z","score":8,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"|Model|Sum|\\n|:-|:-|\\n|QWQ-32B-Preview-AWQ|12.4750|\\n|Qwen2.5-32B-Instruct-AWQ|12.4189|\\n|DeepSeek-R1-32B-AWQ|12.3617|\\n|fp8-Phi-4|12.0942|\\n|gemma-2-9b-it|12.0476|\\n|fp8-Qwen2.5-14B-Instruct|12.0444|\\n|Mistral-Small-Instruct-2409-AWQ|12.0094|\\n|fp8-Mistral-Nemo-Instruct-2407|11.2839|\\n|Llama-3.3-70B-Instruct-IQ2\\\\_XXS|10.5152|","edited":1737771156,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90vlza","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Model&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Sum&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;QWQ-32B-Preview-AWQ&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.4750&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Qwen2.5-32B-Instruct-AWQ&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.4189&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;DeepSeek-R1-32B-AWQ&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.3617&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;fp8-Phi-4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.0942&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;gemma-2-9b-it&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.0476&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;fp8-Qwen2.5-14B-Instruct&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.0444&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Mistral-Small-Instruct-2409-AWQ&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;12.0094&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;fp8-Mistral-Nemo-Instruct-2407&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;11.2839&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Llama-3.3-70B-Instruct-IQ2_XXS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;10.5152&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90vlza/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737770921,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m95cirh","id":"m95cirh","parent_id":"t1_m8wx6fd","depth":3,"children":["m95cirh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wx6fd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Foreign-Beginning-49","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wesrx","score":4,"author_fullname":"t2_83u2l6o4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh certainly, try asking phi4 to not use asterisks. Most of the time my tts stt kokoro script will be saying asterisk asterisk....asterisk asterisk. We have gone so far these last few years and still have a sprint ahead but we are getting there fast!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8wx6fd","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh certainly, try asking phi4 to not use asterisks. Most of the time my tts stt kokoro script will be saying asterisk asterisk....asterisk asterisk. We have gone so far these last few years and still have a sprint ahead but we are getting there fast!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wx6fd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728733,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1737728733,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xp3m2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffeine_Monster","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wesrx","score":2,"author_fullname":"t2_hg9yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As is tradition.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8xp3m2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As is tradition.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xp3m2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737736836,"author_flair_text":null,"treatment_tags":[],"created_utc":1737736836,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wesrx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SoAp9035","can_mod_post":false,"created_utc":1737722031,"send_replies":true,"parent_id":"t1_m8wdeug","score":12,"author_fullname":"t2_78asa0m0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Phi-4 seems to be not good at instruction following. They mentioned in the paper.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wesrx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi-4 seems to be not good at instruction following. They mentioned in the paper.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wesrx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722031,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wdys3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kyazoglu","can_mod_post":false,"created_utc":1737721663,"send_replies":true,"parent_id":"t1_m8wdeug","score":2,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think so. I explained it in my notes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wdys3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think so. I explained it in my notes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wdys3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721663,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wdeug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Swimming6548","can_mod_post":false,"created_utc":1737721418,"send_replies":true,"parent_id":"t3_1i8tx5z","score":7,"author_fullname":"t2_t0tl0xgz4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is phi4 ifeval value correct?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wdeug","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is phi4 ifeval value correct?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wdeug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721418,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8x02g0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"created_utc":1737729662,"send_replies":true,"parent_id":"t1_m8wz3xg","score":8,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/EleutherAI/lm-evaluation-harness/tree/main](https://github.com/EleutherAI/lm-evaluation-harness/tree/main)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8x02g0","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/EleutherAI/lm-evaluation-harness/tree/main\\"&gt;https://github.com/EleutherAI/lm-evaluation-harness/tree/main&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x02g0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737729662,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wz3xg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pm2r_bis","can_mod_post":false,"created_utc":1737729354,"send_replies":true,"parent_id":"t3_1i8tx5z","score":7,"author_fullname":"t2_pnaetocj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you share with us the code used to rum these benchmark? I would like to reproduce","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wz3xg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you share with us the code used to rum these benchmark? I would like to reproduce&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wz3xg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737729354,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zv6aw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zugzwang_CYOA","can_mod_post":false,"created_utc":1737758922,"send_replies":true,"parent_id":"t3_1i8tx5z","score":8,"author_fullname":"t2_mzaab62c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you use a Q4 cache, you can fully load a IQ2\\\\_S quant of Llama 3.3 70b, and that will run circles around IQ2\\\\_XXS. I have found that when quants get into the Q2 range, things get so exponential that the difference between lower Q2 quants and higher Q2 quants is like night and day. Ex, this chart suggest that the difference between IQ2\\\\_M and IQ2\\\\_XXS is greater than the difference between IQ2\\\\_M and Q6\\\\_K in divergence.\\n\\nAnyway, I think you should test Llama 3.3 again, at IQ2\\\\_S.\\n\\nhttps://preview.redd.it/64drmtwds0fe1.png?width=1771&amp;format=png&amp;auto=webp&amp;s=e108761fefc760dc0800ff286cc78903df93ac82","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zv6aw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you use a Q4 cache, you can fully load a IQ2_S quant of Llama 3.3 70b, and that will run circles around IQ2_XXS. I have found that when quants get into the Q2 range, things get so exponential that the difference between lower Q2 quants and higher Q2 quants is like night and day. Ex, this chart suggest that the difference between IQ2_M and IQ2_XXS is greater than the difference between IQ2_M and Q6_K in divergence.&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, I think you should test Llama 3.3 again, at IQ2_S.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/64drmtwds0fe1.png?width=1771&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e108761fefc760dc0800ff286cc78903df93ac82\\"&gt;https://preview.redd.it/64drmtwds0fe1.png?width=1771&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e108761fefc760dc0800ff286cc78903df93ac82&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zv6aw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737758922,"media_metadata":{"64drmtwds0fe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":57,"x":108,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed9188ab74450311c57e660a70ff382eef0d8814"},{"y":115,"x":216,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b7b3304f24be55235c36483b8e0ab95942cbf43d"},{"y":170,"x":320,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=94c85658fe006d65cb2e689aaa733e9bc8af4f94"},{"y":341,"x":640,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=178a03496851e0ea1150fbec2aec6bd09a5a528a"},{"y":511,"x":960,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=212a75b5989d2af69fbb7de46f211493087fbad5"},{"y":575,"x":1080,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=709005877e81b4b3c768e4962eb139b713b21300"}],"s":{"y":944,"x":1771,"u":"https://preview.redd.it/64drmtwds0fe1.png?width=1771&amp;format=png&amp;auto=webp&amp;s=e108761fefc760dc0800ff286cc78903df93ac82"},"id":"64drmtwds0fe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wdmqn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"schizo_poster","can_mod_post":false,"created_utc":1737721515,"send_replies":true,"parent_id":"t3_1i8tx5z","score":4,"author_fullname":"t2_ix5dvt5p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thank you for your service","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wdmqn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you for your service&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wdmqn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721515,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yq9tc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pkz_swe","can_mod_post":false,"created_utc":1737747150,"send_replies":true,"parent_id":"t3_1i8tx5z","score":5,"author_fullname":"t2_o3wza","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is an excellent table! I wish we could have similar tables for various VRAM sizes together with tokens/sec to get an idea of the speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yq9tc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is an excellent table! I wish we could have similar tables for various VRAM sizes together with tokens/sec to get an idea of the speed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yq9tc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737747150,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8x1um0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Willing_Landscape_61","can_mod_post":false,"created_utc":1737730219,"send_replies":true,"parent_id":"t3_1i8tx5z","score":3,"author_fullname":"t2_8lvrytgw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It seems that a combo of Phi-4 and Qwen could be pretty good. Not sure if task could be easily classified and routed or if some ensemble learning is in order ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8x1um0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems that a combo of Phi-4 and Qwen could be pretty good. Not sure if task could be easily classified and routed or if some ensemble learning is in order &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x1um0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737730219,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m900prh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gofiend","can_mod_post":false,"created_utc":1737760638,"send_replies":true,"parent_id":"t3_1i8tx5z","score":3,"author_fullname":"t2_2roqrw5l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So a few standard issues with LLM benchmarking to keep an eye out for:\\n\\n* Temperature: If you are testing factual answers, multiple choice etc., you probably want the model set to a low temperature (perhaps even 0), otherwise you are forcing the model to occasionally make mistakes at a rate that is idiosyncratic to each model.\\n* Answer format: [https://github.com/huggingface/Math-Verify](https://github.com/huggingface/Math-Verify) showed that harness is really bad at parsing out correct answers with even minor format deviations\\n* Correct prompt format and tokenization: Almost every time a new model comes out the tokenization and system prompt for it is broken... if you don't get the fixed model and tokenization fixes, you'll get substantially worse output.\\n* ROPE: We've gotten better at this, but longer problems often suffer simply because ROPE isn't correctly handled for the model in VLLM or LLama.cpp (again typically fixed after a few weeks)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m900prh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So a few standard issues with LLM benchmarking to keep an eye out for:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Temperature: If you are testing factual answers, multiple choice etc., you probably want the model set to a low temperature (perhaps even 0), otherwise you are forcing the model to occasionally make mistakes at a rate that is idiosyncratic to each model.&lt;/li&gt;\\n&lt;li&gt;Answer format: &lt;a href=\\"https://github.com/huggingface/Math-Verify\\"&gt;https://github.com/huggingface/Math-Verify&lt;/a&gt; showed that harness is really bad at parsing out correct answers with even minor format deviations&lt;/li&gt;\\n&lt;li&gt;Correct prompt format and tokenization: Almost every time a new model comes out the tokenization and system prompt for it is broken... if you don&amp;#39;t get the fixed model and tokenization fixes, you&amp;#39;ll get substantially worse output.&lt;/li&gt;\\n&lt;li&gt;ROPE: We&amp;#39;ve gotten better at this, but longer problems often suffer simply because ROPE isn&amp;#39;t correctly handled for the model in VLLM or LLama.cpp (again typically fixed after a few weeks)&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m900prh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737760638,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92q48g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"netikas","can_mod_post":false,"created_utc":1737804446,"send_replies":true,"parent_id":"t3_1i8tx5z","score":3,"author_fullname":"t2_zby0osc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If only qwen didnt spew out Chinese tokens 10% of the time...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92q48g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If only qwen didnt spew out Chinese tokens 10% of the time...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92q48g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737804446,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wf2zf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1i8tx5z","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Çok güzel, very nice summary. This is the kind of data that is actually relevant to your 'average' hobbyist or amateur local llm user.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Çok güzel, very nice summary. This is the kind of data that is actually relevant to your &amp;#39;average&amp;#39; hobbyist or amateur local llm user.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wf2zf/","num_reports":null,"locked":false,"name":"t1_m8wf2zf","created":1737722154,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737722154,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wupf4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SuperChewbacca","can_mod_post":false,"created_utc":1737727923,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_8lufz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks OP.  Nice work.\\n\\nYou sort of confirmed what I saw with less scientific testing of QwQ vs the R1 Distill.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wupf4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks OP.  Nice work.&lt;/p&gt;\\n\\n&lt;p&gt;You sort of confirmed what I saw with less scientific testing of QwQ vs the R1 Distill.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wupf4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727923,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"body":"Me, who just got my 4090 rig setup and went straight for Qwen 2.5 32b:\\n\\n\\"OOOOhhhh YEAH! Sweet validation!\\"","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wz8gw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mekanimal","can_mod_post":false,"created_utc":1737729394,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_h5xqk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wz8gw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Me, who just got my 4090 rig setup and went straight for Qwen 2.5 32b:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;OOOOhhhh YEAH! Sweet validation!&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wz8gw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737729394,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m93j1g1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Busy_Category3784","can_mod_post":false,"created_utc":1737817043,"send_replies":true,"parent_id":"t1_m8x5ohf","score":2,"author_fullname":"t2_z82b3izot","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen32b-coder is the best programming model, you are so greedy. If you want to be comparable to 4o, you need 658b deepseek-v3.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m93j1g1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen32b-coder is the best programming model, you are so greedy. If you want to be comparable to 4o, you need 658b deepseek-v3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m93j1g1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737817043,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8x5ohf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x5ohf/","num_reports":null,"locked":false,"name":"t1_m8x5ohf","created":1737731371,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737731371,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90vjkk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1737770897,"send_replies":true,"parent_id":"t1_m90eqrw","score":2,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Strix Halo will be gangbusters with 96GB of VRAM.\\n\\nNo, it won't be. It's not VRAM. It's fastish for system RAM. Slow for VRAM. It's like RX580 speed RAM. Which for driving 96GB, is too slow. As people with Mac M Pros will tell you since the speed of that RAM is comparable. Even my M Max with faster RAM is on the slowish side driving only 32GB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90vjkk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Strix Halo will be gangbusters with 96GB of VRAM.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;No, it won&amp;#39;t be. It&amp;#39;s not VRAM. It&amp;#39;s fastish for system RAM. Slow for VRAM. It&amp;#39;s like RX580 speed RAM. Which for driving 96GB, is too slow. As people with Mac M Pros will tell you since the speed of that RAM is comparable. Even my M Max with faster RAM is on the slowish side driving only 32GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90vjkk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737770897,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m90eqrw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Strix Halo will be gangbusters with 96GB of VRAM.  Pretty crazy time we live in.  Plus, it appears we are not alone in the universe.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Strix Halo will be gangbusters with 96GB of VRAM.  Pretty crazy time we live in.  Plus, it appears we are not alone in the universe.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90eqrw/","num_reports":null,"locked":false,"name":"t1_m90eqrw","created":1737765176,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737765176,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m919sv7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jadefox02","can_mod_post":false,"created_utc":1737776082,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_biz3pzn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure if it's been asked... but for us colorblind people... can you use some more distinctive colors? Or more contrast? I'm struggling right now! 😭","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m919sv7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure if it&amp;#39;s been asked... but for us colorblind people... can you use some more distinctive colors? Or more contrast? I&amp;#39;m struggling right now! 😭&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m919sv7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737776082,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wfk8g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stddealer","can_mod_post":false,"created_utc":1737722359,"send_replies":true,"parent_id":"t3_1i8tx5z","score":5,"author_fullname":"t2_5gk3j2hj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No surprise, the models trained on benchmarks perform well on the benchmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wfk8g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No surprise, the models trained on benchmarks perform well on the benchmarks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wfk8g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722359,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m8wfo7p","id":"m8wfo7p","parent_id":"t1_m8wf5af","depth":2,"children":["m8wfo7p"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wf5af","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Autobahn97","can_mod_post":false,"created_utc":1737722182,"send_replies":true,"parent_id":"t1_m8wct93","score":3,"author_fullname":"t2_jl3sqld","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP mentioned above that Gemma2 27B was tested and underperformed the smaller model, presumably due to quantization.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wf5af","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP mentioned above that Gemma2 27B was tested and underperformed the smaller model, presumably due to quantization.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wf5af/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722182,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ygls7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Not_your_guy_buddy42","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wfuo8","score":2,"author_fullname":"t2_4m6vm3ghs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Has anyone tried the Queen audio 2 model\\n\\nI did but it always gives back  \\"Galileo figaro, magnifico\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8ygls7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Has anyone tried the Queen audio 2 model&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I did but it always gives back  &amp;quot;Galileo figaro, magnifico&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ygls7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737744450,"author_flair_text":null,"treatment_tags":[],"created_utc":1737744450,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wfuo8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redfairynotblue","can_mod_post":false,"created_utc":1737722480,"send_replies":true,"parent_id":"t1_m8wct93","score":2,"author_fullname":"t2_tyaybnhnw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Has anyone tried the Queen audio 2 model that can take in audio and describe the sound in the audio? It sounds interesting but I'm not a tech person so my old computer hardly has any VRam ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wfuo8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Has anyone tried the Queen audio 2 model that can take in audio and describe the sound in the audio? It sounds interesting but I&amp;#39;m not a tech person so my old computer hardly has any VRam &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wfuo8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722480,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wct93","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SoAp9035","can_mod_post":false,"created_utc":1737721145,"send_replies":true,"parent_id":"t3_1i8tx5z","score":3,"author_fullname":"t2_78asa0m0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen 2.5 all day! I thought Gemma 2 would be better at Turkish though. Can you benchmark Gemma 2 27B? Thanks for the benchmark btw.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wct93","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 2.5 all day! I thought Gemma 2 would be better at Turkish though. Can you benchmark Gemma 2 27B? Thanks for the benchmark btw.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wct93/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721145,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8whwsb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Professional-Bear857","can_mod_post":false,"created_utc":1737723318,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_yrl9ztfsa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try fuseo1 qwq and fuseo1 2.5 qwen instruct maybe? I'd be curious to see how they perform. They seem to be sota in 24gb from my testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8whwsb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try fuseo1 qwq and fuseo1 2.5 qwen instruct maybe? I&amp;#39;d be curious to see how they perform. They seem to be sota in 24gb from my testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8whwsb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737723318,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wk6ta","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"brown2green","can_mod_post":false,"created_utc":1737724208,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_f010l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think the color scale needs to be absolute rather than benchmark-relative.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wk6ta","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the color scale needs to be absolute rather than benchmark-relative.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wk6ta/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737724208,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wcl0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zoom3913","can_mod_post":false,"created_utc":1737721042,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_4kkpld2q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"very nice comparison. gut feeling was indeed that qwen-32b is the best, being close to llama70b in my testing. I wonder if QwQ would do better at 8bpw. Perhaps a 48gb test next ? :) ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wcl0j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;very nice comparison. gut feeling was indeed that qwen-32b is the best, being close to llama70b in my testing. I wonder if QwQ would do better at 8bpw. Perhaps a 48gb test next ? :) ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wcl0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737721042,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wfo9s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uxl","can_mod_post":false,"created_utc":1737722406,"send_replies":true,"parent_id":"t3_1i8tx5z","score":2,"author_fullname":"t2_7f7q9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is cool. It means you could get a top shelf gaming laptop (like the 2025 edition of the Razer Blade 16, with a 5090) and it would double as a localized/offline gen AI workstation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wfo9s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is cool. It means you could get a top shelf gaming laptop (like the 2025 edition of the Razer Blade 16, with a 5090) and it would double as a localized/offline gen AI workstation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wfo9s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722406,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8x07y4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MrTony_23","can_mod_post":false,"created_utc":1737729711,"send_replies":true,"parent_id":"t1_m8wf363","score":3,"author_fullname":"t2_13ufgz2i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It will differ a lot, I presume. Quantization below Q4 has significant drop in quality","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8x07y4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will differ a lot, I presume. Quantization below Q4 has significant drop in quality&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x07y4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737729711,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wf363","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dr_Me_123","can_mod_post":false,"created_utc":1737722157,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_59yau29b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How much the results will differ between 70B IQ2 and 70B IQ4 ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wf363","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much the results will differ between 70B IQ2 and 70B IQ4 ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wf363/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737722157,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wo1wn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"prabhic","can_mod_post":false,"created_utc":1737725628,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_429xldzo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very valuable info thank you","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wo1wn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very valuable info thank you&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wo1wn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737725628,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wpjef","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnswerFeeling460","can_mod_post":false,"created_utc":1737726150,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_1hbkvhe0w6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for you work! I was playing around with different ollama deepseek r1 destillates on my VPS with 32 GB. I am eager to learn what the beste LLM could be!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wpjef","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for you work! I was playing around with different ollama deepseek r1 destillates on my VPS with 32 GB. I am eager to learn what the beste LLM could be!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wpjef/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726150,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8wtxwd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llama-impersonator","can_mod_post":false,"created_utc":1737727666,"send_replies":true,"parent_id":"t1_m8wprpp","score":2,"author_fullname":"t2_14usv0hw3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"awq is a different quantization format than gguf.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wtxwd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;awq is a different quantization format than gguf.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wtxwd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727666,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wprpp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wprpp/","num_reports":null,"locked":false,"name":"t1_m8wprpp","created":1737726230,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737726230,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mhxltow","id":"mhxltow","parent_id":"t1_m8xox6v","depth":3,"children":["mhxltow"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m8xox6v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"unrulywind","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8wuwok","score":9,"author_fullname":"t2_hi1n3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's closer to Q3_K_M. AWQ 4bpw is 4bpw.\\n\\nGGUF is a bit misleading. Q3_K_M is ~3.9bpw. Q4_K_M is ~4.8bpw.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m8xox6v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s closer to Q3_K_M. AWQ 4bpw is 4bpw.&lt;/p&gt;\\n\\n&lt;p&gt;GGUF is a bit misleading. Q3_K_M is ~3.9bpw. Q4_K_M is ~4.8bpw.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xox6v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737736788,"author_flair_text":null,"treatment_tags":[],"created_utc":1737736788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wuwok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kyazoglu","can_mod_post":false,"created_utc":1737727989,"send_replies":true,"parent_id":"t1_m8wr29s","score":5,"author_fullname":"t2_slwqrxz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the best 4-bit quantization type for vLLM. So it's like Q4\\\\_K\\\\_M","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wuwok","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the best 4-bit quantization type for vLLM. So it&amp;#39;s like Q4_K_M&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wuwok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737727989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wr29s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Porespellar","can_mod_post":false,"created_utc":1737726684,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_y35oj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is AWQ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wr29s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is AWQ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wr29s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737726684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90lc09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mythril_Zombie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m8yhz3r","score":1,"author_fullname":"t2_8d4gn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I need you to write a book.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m90lc09","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I need you to write a book.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90lc09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767382,"author_flair_text":null,"treatment_tags":[],"created_utc":1737767382,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8yhz3r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loudmax","can_mod_post":false,"created_utc":1737744830,"send_replies":true,"parent_id":"t1_m8wxzmp","score":5,"author_fullname":"t2_61k60","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The tests were performed using vLLM rather than llama.cpp.\\n\\nThe main benefit of llama.cpp/GGUF for us LocalLLaMA enthusiasts is its flexibility.  It runs on Macs, or on Linux/Windows PCs, and you can split the model so part of it runs on a GPU and part of it runs on CPU.  vLLM/AWQ has better performance than llama.cpp, but it won't run on a Mac, and you have to fit the entire model on the GPU's VRAM.  If you have access to something with a lot of VRAM like H100, you're better off running vLLM.  If you want to run big models on consumer grade hardware, llama.cpp allows more options.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yhz3r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The tests were performed using vLLM rather than llama.cpp.&lt;/p&gt;\\n\\n&lt;p&gt;The main benefit of llama.cpp/GGUF for us LocalLLaMA enthusiasts is its flexibility.  It runs on Macs, or on Linux/Windows PCs, and you can split the model so part of it runs on a GPU and part of it runs on CPU.  vLLM/AWQ has better performance than llama.cpp, but it won&amp;#39;t run on a Mac, and you have to fit the entire model on the GPU&amp;#39;s VRAM.  If you have access to something with a lot of VRAM like H100, you&amp;#39;re better off running vLLM.  If you want to run big models on consumer grade hardware, llama.cpp allows more options.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yhz3r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737744830,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yct63","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Barafu","can_mod_post":false,"created_utc":1737743396,"send_replies":true,"parent_id":"t1_m8wxzmp","score":1,"author_fullname":"t2_gf6so","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP is using software that can not run GGUF well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yct63","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP is using software that can not run GGUF well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yct63/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737743396,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"m8wxzmp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aj_thenoob2","can_mod_post":false,"created_utc":1737728994,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_qa5sjku25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Newbie here, why AWQ vs GGUF for Qwen?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8wxzmp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Newbie here, why AWQ vs GGUF for Qwen?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8wxzmp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737728994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8x6axd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"omaru_kun","can_mod_post":false,"created_utc":1737731556,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_k3qx4hop","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"need this kinda result each month","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8x6axd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;need this kinda result each month&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8x6axd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737731556,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xir5n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maddogxsk","can_mod_post":false,"created_utc":1737735095,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_89xxvpkqp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like qwen2.5 would be a great fit for an agent","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xir5n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like qwen2.5 would be a great fit for an agent&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xir5n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737735095,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xwzcx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YearnMar10","can_mod_post":false,"created_utc":1737739016,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_zldrkfl0t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you try https://www.reddit.com/r/LocalLLaMA/s/PQxpUw4DUp please?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xwzcx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you try &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/s/PQxpUw4DUp\\"&gt;https://www.reddit.com/r/LocalLLaMA/s/PQxpUw4DUp&lt;/a&gt; please?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xwzcx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737739016,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8xyp7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shoddy-Tutor9563","can_mod_post":false,"created_utc":1737739490,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_56opwsoz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This exactly matches my own benchmark for agentic flow - qwen 2.5 32B is the king","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8xyp7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This exactly matches my own benchmark for agentic flow - qwen 2.5 32B is the king&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8xyp7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737739490,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8y1few","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"latentmag","can_mod_post":false,"created_utc":1737740249,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_hkf0kkl5s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The conclusion that different models excel at different tasks begs the luxurious question of the tools the community uses to properly get the forking right in order to get the right task to the right model. I mean aside from the possibilities given in gptresearcher where you can differentiate between strategic, fast etc. model, what do you guys use?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8y1few","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The conclusion that different models excel at different tasks begs the luxurious question of the tools the community uses to properly get the forking right in order to get the right task to the right model. I mean aside from the possibilities given in gptresearcher where you can differentiate between strategic, fast etc. model, what do you guys use?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y1few/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737740249,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8y6td5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Illhoon","can_mod_post":false,"created_utc":1737741728,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_1kc58ain","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow this is some great insight for me as I am always not sure what runs on what Hardware and how good. Dobyou know if perhaps a graph like this exists for the nvidia 4090 and 4080 Super series?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8y6td5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow this is some great insight for me as I am always not sure what runs on what Hardware and how good. Dobyou know if perhaps a graph like this exists for the nvidia 4090 and 4080 Super series?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y6td5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737741728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8y9yc5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"created_utc":1737742604,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_s4zzntp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From my tests Llama-3.1-nemotron-51b at Q3KS and Q4KS worth it, results are better or same to Qwen 32b Inst.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8y9yc5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From my tests Llama-3.1-nemotron-51b at Q3KS and Q4KS worth it, results are better or same to Qwen 32b Inst.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8y9yc5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737742604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ybapn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"estebansaa","can_mod_post":false,"created_utc":1737742979,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_m8971","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"great job.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ybapn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;great job.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ybapn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737742979,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yeg8q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"msRachels","can_mod_post":false,"created_utc":1737743852,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_axb9mwfgt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you share the code?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yeg8q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you share the code?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yeg8q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737743852,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yjluu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1737745280,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So, just use a Qwen model already. That's what I've been doing since they came out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yjluu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So, just use a Qwen model already. That&amp;#39;s what I&amp;#39;ve been doing since they came out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yjluu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737745280,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ylqxc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"blazkowicz8545","can_mod_post":false,"created_utc":1737745883,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_1bbrk8jln4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have 24gb ram and a ryzen 4 processor. Ran llma 3 4b locally and it went into infinite loop on writing a line of code when i told it to write a simple java program.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ylqxc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have 24gb ram and a ryzen 4 processor. Ran llma 3 4b locally and it went into infinite loop on writing a line of code when i told it to write a simple java program.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ylqxc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737745883,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ynqfl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ayeebe","can_mod_post":false,"created_utc":1737746439,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_pjy7utek","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you so much for this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ynqfl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you so much for this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ynqfl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737746439,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8yq98j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Critical_Water_3838","can_mod_post":false,"created_utc":1737747146,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_8j84ku4c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I need coding model 7B - 30B . Which is the best ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8yq98j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I need coding model 7B - 30B . Which is the best ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8yq98j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737747146,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8z41dh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rae_1988","can_mod_post":false,"created_utc":1737751090,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_4ql3eu2xa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"whats Qwen?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8z41dh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;whats Qwen?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8z41dh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737751090,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zb5sh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Putrid_Channel2095","can_mod_post":false,"created_utc":1737753109,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_amnu1ews","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh very interesting, can you share the doc? I'm interested in computing an average rank per model across the tests.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zb5sh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh very interesting, can you share the doc? I&amp;#39;m interested in computing an average rank per model across the tests.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zb5sh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737753109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8ze7yi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jarec707","can_mod_post":false,"created_utc":1737753972,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_mjsmz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Beautiful presentation, easy to grasp, and useful. Many thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8ze7yi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Beautiful presentation, easy to grasp, and useful. Many thanks!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8ze7yi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737753972,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zj9og","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bluepersona1752","can_mod_post":false,"created_utc":1737755396,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_oqdc0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks a ton for doing this. Which benchmarks are coding benchmarks?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zj9og","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks a ton for doing this. Which benchmarks are coding benchmarks?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zj9og/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737755396,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m8zm4p0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cut6976","can_mod_post":false,"created_utc":1737756208,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_9ydsrbqy6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how did you run these benchmarks? did you check the codes/dataset for each benchmark or is there a way/framework to test many of them in a single framework?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m8zm4p0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how did you run these benchmarks? did you check the codes/dataset for each benchmark or is there a way/framework to test many of them in a single framework?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m8zm4p0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737756208,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m900aaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmp22","can_mod_post":false,"created_utc":1737760502,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_gl0fr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would be interesting to have sota closed models scores included for reference purposes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m900aaf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would be interesting to have sota closed models scores included for reference purposes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m900aaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737760502,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m909gxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1737763448,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_s6sfw4yy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good work. Why not also test gemma-2-27b-it Q6\\\\_K and Llama-3\\\\_1-Nemotron-51B IQ3\\\\_M? If gemma-2-9b is decent, then 27b Q6\\\\_K should be near the top. As to the 51B model, we can see if IQ3\\\\_M is a useful quant or not.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m909gxk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good work. Why not also test gemma-2-27b-it Q6_K and Llama-3_1-Nemotron-51B IQ3_M? If gemma-2-9b is decent, then 27b Q6_K should be near the top. As to the 51B model, we can see if IQ3_M is a useful quant or not.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m909gxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737763448,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90e4gx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vegetable_Sun_9225","can_mod_post":false,"created_utc":1737764969,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_dsowj79s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you provide your benchmarking script? I have two GPUs and was planning on hitting some of the bigger ones but am struggle to get the benchmarks set up right","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90e4gx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you provide your benchmarking script? I have two GPUs and was planning on hitting some of the bigger ones but am struggle to get the benchmarks set up right&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90e4gx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737764969,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90hkaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mercyfulking","can_mod_post":false,"created_utc":1737766114,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_vf0tsmy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All this for ai waifus?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90hkaz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All this for ai waifus?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90hkaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737766114,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90ixot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fbocplr_01","can_mod_post":false,"created_utc":1737766573,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_pkdw4hul","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What about Ministral 8b 2410 and Llama 3.1 7B, i use these the most?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90ixot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about Ministral 8b 2410 and Llama 3.1 7B, i use these the most?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90ixot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737766573,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90ltb8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1737767543,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_by77ogdhr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen 32b native is king?\\n\\n\\nAbsolutely nobody is surprised by this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90ltb8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 32b native is king?&lt;/p&gt;\\n\\n&lt;p&gt;Absolutely nobody is surprised by this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90ltb8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767543,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m90lxia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thedudely1","can_mod_post":false,"created_utc":1737767583,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_i305y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh this is awesome. I love that you compared Llama 70b IQ2 XXS with fp8 smaller models like Phi-4 because that is the question I'm always asking myself!! Small less quantized model or large heavily quantized model...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m90lxia","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh this is awesome. I love that you compared Llama 70b IQ2 XXS with fp8 smaller models like Phi-4 because that is the question I&amp;#39;m always asking myself!! Small less quantized model or large heavily quantized model...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m90lxia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737767583,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m91dhgo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Flimsy-Tonight-6050","can_mod_post":false,"created_utc":1737777520,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_bcikvj8o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"16 gigs please?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m91dhgo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;16 gigs please?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91dhgo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737777520,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m91mwd6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Su1tz","can_mod_post":false,"created_utc":1737781543,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_tupznx19","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you check out that deepseek-t1-qwq-qwen 32b freakshow of a model against turkishmmlu?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m91mwd6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you check out that deepseek-t1-qwq-qwen 32b freakshow of a model against turkishmmlu?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91mwd6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737781543,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m91r96j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Repulsive-Parsnip509","can_mod_post":false,"created_utc":1737783614,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_1cz8s6vth3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this is why we shouldn't trust SV crowd","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m91r96j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this is why we shouldn&amp;#39;t trust SV crowd&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m91r96j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737783614,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92ddh3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oneonefivef","can_mod_post":false,"created_utc":1737796479,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_13ecea","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My 1 Tb SSD is angry at you. Very angry.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92ddh3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My 1 Tb SSD is angry at you. Very angry.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92ddh3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737796479,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92fr84","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MIKOLOZ","can_mod_post":false,"created_utc":1737797988,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_5amk1jsa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi. I have a question about benchmarking PLMs, it would be really kind of you to help me figure this out. I did some research upon the topic of evaluating of PLM’s before SFT. This is the problem: given the pretrained language models P1, P2…. Pn, which might be the best to fine tune on some Target task?\\nSo as far as i know, i can’t ask questions PLM, the only thing i can do is just write some prompt which has lets say X tokens, and the PLM will generate next Y tokens. So, i don’t quite get how are PLM’s are evaluated, which benchmark datasets are being used, how are they being used. If you have some papers or case studies on this topic, please give recommendations. Thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92fr84","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi. I have a question about benchmarking PLMs, it would be really kind of you to help me figure this out. I did some research upon the topic of evaluating of PLM’s before SFT. This is the problem: given the pretrained language models P1, P2…. Pn, which might be the best to fine tune on some Target task?\\nSo as far as i know, i can’t ask questions PLM, the only thing i can do is just write some prompt which has lets say X tokens, and the PLM will generate next Y tokens. So, i don’t quite get how are PLM’s are evaluated, which benchmark datasets are being used, how are they being used. If you have some papers or case studies on this topic, please give recommendations. Thank you!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92fr84/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737797988,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1i8tx5z","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92oxut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I wonder if the instruction following on the R1 32b distill affected its scores somehow. I tried that distill with some very difficult math problems and it could solve them. Phi4 is also pretty good, but nowhere even close to R1-32b on math.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if the instruction following on the R1 32b distill affected its scores somehow. I tried that distill with some very difficult math problems and it could solve them. Phi4 is also pretty good, but nowhere even close to R1-32b on math.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92oxut/","num_reports":null,"locked":false,"name":"t1_m92oxut","created":1737803740,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737803740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9330rg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bobabenz","can_mod_post":false,"created_utc":1737811003,"send_replies":true,"parent_id":"t1_m92pbtt","score":3,"author_fullname":"t2_rbmg7jk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A cheeky but also serious answer: they’re called Large language models, not Little language models.  It NEEDS a lot of data to be good.  Only difference between GPT-1 up to GPT-3 was the amount of data.  A lot of GPT-1’s talking to each other doesn’t do much.\\n\\nThe other surprising thing was that knowing all the things makes the model perform better than having it trained specifically on topics, due to being able to use more data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9330rg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A cheeky but also serious answer: they’re called Large language models, not Little language models.  It NEEDS a lot of data to be good.  Only difference between GPT-1 up to GPT-3 was the amount of data.  A lot of GPT-1’s talking to each other doesn’t do much.&lt;/p&gt;\\n\\n&lt;p&gt;The other surprising thing was that knowing all the things makes the model perform better than having it trained specifically on topics, due to being able to use more data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1i8tx5z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9330rg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737811003,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m92pbtt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Reno0vacio","can_mod_post":false,"created_utc":1737803975,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_4yaw09a6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't really understand this whole thing... if I want a specific model to do a thing, like writing a story, math, or coding... then if I want the best one I have to download it and use it..\\n\\nWhy can't you train little llm's for a specific thing and put them all together and just use a specific llm to do a specific task that it's good at?\\n\\nIsn't that the MOE anyway?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92pbtt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t really understand this whole thing... if I want a specific model to do a thing, like writing a story, math, or coding... then if I want the best one I have to download it and use it..&lt;/p&gt;\\n\\n&lt;p&gt;Why can&amp;#39;t you train little llm&amp;#39;s for a specific thing and put them all together and just use a specific llm to do a specific task that it&amp;#39;s good at?&lt;/p&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t that the MOE anyway?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92pbtt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737803975,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92q9d8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Beautiful-Still8168","can_mod_post":false,"created_utc":1737804530,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_deyplz2f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Time to unpack my new 3090! Interested to see more Deepseek R1 in fp8","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92q9d8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Time to unpack my new 3090! Interested to see more Deepseek R1 in fp8&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92q9d8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737804530,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92qow6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Banished_Privateer","can_mod_post":false,"created_utc":1737804787,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_1nwgfzyg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You should use the patched version of phi4 that improves benchmarks a lot.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92qow6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You should use the patched version of phi4 that improves benchmarks a lot.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92qow6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737804787,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92s539","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeathShot7777","can_mod_post":false,"created_utc":1737805636,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_3kng7y57","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone benchmark the distilled models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92s539","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone benchmark the distilled models&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92s539/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737805636,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m92s7kn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rolling_watermelon","can_mod_post":false,"created_utc":1737805676,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_3kycily4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great work! Eline sağlık","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m92s7kn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great work! Eline sağlık&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m92s7kn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737805676,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m935bt3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"labianconeri","can_mod_post":false,"created_utc":1737811973,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_25mds4k2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any idea how much VRAM these models need for fine-tuning/training ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m935bt3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any idea how much VRAM these models need for fine-tuning/training ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m935bt3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737811973,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m93w7f3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stereotypical_CS","can_mod_post":false,"created_utc":1737821122,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_107mod","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you have a github for this? Would be curious to see results for 64 GB models and maybe some system metrics for running on a MacBook 😅","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m93w7f3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have a github for this? Would be curious to see results for 64 GB models and maybe some system metrics for running on a MacBook 😅&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m93w7f3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737821122,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m93yis5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"time_traveller_x","can_mod_post":false,"created_utc":1737821800,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_5e6jyasl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thanks for this mate!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m93yis5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks for this mate!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m93yis5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737821800,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m949h5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SadWolverine24","can_mod_post":false,"created_utc":1737824928,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_7a1jtru1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm surprised QwQ outperforms R1.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m949h5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m surprised QwQ outperforms R1.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m949h5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737824928,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9600nt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kyr0x0","can_mod_post":false,"created_utc":1737843484,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_dv2ps98i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Was R1 tested with temp between 0.5 and 0.7? Otherwise it really su*** ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9600nt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Was R1 tested with temp between 0.5 and 0.7? Otherwise it really su*** ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9600nt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737843484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m99uv1z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jojobeansiscraycray","can_mod_post":false,"created_utc":1737903523,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_xa93z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"is it worth getting a 2nd 3090 and getting models in the 30 - 40 gb file sizes?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m99uv1z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;is it worth getting a 2nd 3090 and getting models in the 30 - 40 gb file sizes?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m99uv1z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737903523,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9glls1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Middle-Pipe-1149","can_mod_post":false,"created_utc":1737990094,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_12jr37rokt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey, I am pretty new so bear with me plz. \\n\\n\\n\\nWhen you run inference of the model, are you running a compiled version of the model? If so, what compiler were you using? Would it be Tensorrt / TRT-LLM, or torch.compile? Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9glls1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, I am pretty new so bear with me plz. &lt;/p&gt;\\n\\n&lt;p&gt;When you run inference of the model, are you running a compiled version of the model? If so, what compiler were you using? Would it be Tensorrt / TRT-LLM, or torch.compile? Thanks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9glls1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737990094,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9nmqfn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xqoe","can_mod_post":false,"created_utc":1738080717,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_5slsu5xg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Without surprises, the heaviest is the best","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9nmqfn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Without surprises, the heaviest is the best&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9nmqfn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738080717,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9vqtxh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dreamer_2142","can_mod_post":false,"created_utc":1738181001,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_138iip","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hi, where can I download the fp8-Qwen2.5-32B-Coder gguf you tested here? or did you convert it yourself?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9vqtxh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hi, where can I download the fp8-Qwen2.5-32B-Coder gguf you tested here? or did you convert it yourself?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9vqtxh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738181001,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9z1gkk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Triskite","can_mod_post":false,"created_utc":1738220735,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_4h9ql","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"exl2 and bnb dynamic 4b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9z1gkk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;exl2 and bnb dynamic 4b?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/m9z1gkk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738220735,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma2jcqm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tokenosopher","can_mod_post":false,"created_utc":1738267899,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_idd96asp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very cool, thanks for this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma2jcqm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very cool, thanks for this&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/ma2jcqm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738267899,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"ma4nv9r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cognitivetechniq","can_mod_post":false,"created_utc":1738291174,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_pdiwdmrzk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"looks like you'll have to run again for Mistral Small 3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma4nv9r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;looks like you&amp;#39;ll have to run again for Mistral Small 3&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/ma4nv9r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738291174,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mabl0ne","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Anonymous239013","can_mod_post":false,"created_utc":1738382134,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_exm19xgru","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can I ask what your parameters were when when running the command for Qwen2.5-32B-Instruct-AWQ (ie \\"vllm serve Qwen/Qwen2.5-32B-Instruct-AWQ --max-model-len 8192 --max-num-batched-tokens 8192 --max-num-seqs 4 --tensor-parallel-size 1 --gpu-memory-utilization 0.85\\")?","edited":1738385179,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mabl0ne","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can I ask what your parameters were when when running the command for Qwen2.5-32B-Instruct-AWQ (ie &amp;quot;vllm serve Qwen/Qwen2.5-32B-Instruct-AWQ --max-model-len 8192 --max-num-batched-tokens 8192 --max-num-seqs 4 --tensor-parallel-size 1 --gpu-memory-utilization 0.85&amp;quot;)?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mabl0ne/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738382134,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"makis8a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"guiltyguy_","can_mod_post":false,"created_utc":1738511692,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_7pyh8m2f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Now someone needs to add Deepseek-R1-32b to the mix and share the results","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_makis8a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now someone needs to add Deepseek-R1-32b to the mix and share the results&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/makis8a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738511692,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mbj37gj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"drifter_VR","can_mod_post":false,"created_utc":1738956356,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_b6ejc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The new Mistral Small 3 is probably the best model fitting 24GB right now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mbj37gj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The new Mistral Small 3 is probably the best model fitting 24GB right now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mbj37gj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738956356,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mbtsg1o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"4bjmc881","can_mod_post":false,"created_utc":1739104468,"send_replies":true,"parent_id":"t3_1i8tx5z","score":1,"author_fullname":"t2_u2lcu7fa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Really cool work! Can you do the same with 32GB of VRAM as limitation and 48GB? ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mbtsg1o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really cool work! Can you do the same with 32GB of VRAM as limitation and 48GB? &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1i8tx5z/i_benchmarked_almost_every_model_that_can_fit_in/mbtsg1o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739104468,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1i8tx5z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":6,"name":"t1_m8x8tfm","id":"m8x8tfm","parent_id":"t3_1i8tx5z","depth":0,"children":["m8x8tfm","m8wgnm7","m8wk03y"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
