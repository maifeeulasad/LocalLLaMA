import{j as e}from"./index-DQXiEb7D.js";import{R as t}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"We built an internal support agent using LangChain + OpenAI + some simple tool calls.\\n\\nGetting to a working prototype took 3 days with Cursor and just messing around. Great.\\n\\nBut actually trying to operate that agent across multiple teams was absolute chaos.\\n\\n– No structured logs of intermediate reasoning\\n\\n– No persistent memory or traceability\\n\\n– No access control (anyone could run/modify it)\\n\\n– No ability to validate outputs at scale\\n\\nIt’s like deploying a microservice with no logs, no auth, and no monitoring. The frameworks are designed for demos, not real workflows. And everyone I know is duct-taping together JSON dumps + Slack logs to stay afloat.\\n\\nSo, what does agent infra actually look like after the first prototype for you guys?\\n\\nWould love to hear real setups. Especially if you’ve gone past the LangChain happy path.\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"LangChain/Crew/AutoGen made it easy to build agents, but operating them is a joke","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltxiy4","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.73,"author_flair_background_color":null,"subreddit_type":"public","ups":10,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_12hlr7sk","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":10,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751902984,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;We built an internal support agent using LangChain + OpenAI + some simple tool calls.&lt;/p&gt;\\n\\n&lt;p&gt;Getting to a working prototype took 3 days with Cursor and just messing around. Great.&lt;/p&gt;\\n\\n&lt;p&gt;But actually trying to operate that agent across multiple teams was absolute chaos.&lt;/p&gt;\\n\\n&lt;p&gt;– No structured logs of intermediate reasoning&lt;/p&gt;\\n\\n&lt;p&gt;– No persistent memory or traceability&lt;/p&gt;\\n\\n&lt;p&gt;– No access control (anyone could run/modify it)&lt;/p&gt;\\n\\n&lt;p&gt;– No ability to validate outputs at scale&lt;/p&gt;\\n\\n&lt;p&gt;It’s like deploying a microservice with no logs, no auth, and no monitoring. The frameworks are designed for demos, not real workflows. And everyone I know is duct-taping together JSON dumps + Slack logs to stay afloat.&lt;/p&gt;\\n\\n&lt;p&gt;So, what does agent infra actually look like after the first prototype for you guys?&lt;/p&gt;\\n\\n&lt;p&gt;Would love to hear real setups. Especially if you’ve gone past the LangChain happy path.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ltxiy4","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ImmuneCoder","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/","subreddit_subscribers":496034,"created_utc":1751902984,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1uf0ac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GortKlaatu_","can_mod_post":false,"created_utc":1751910455,"send_replies":true,"parent_id":"t3_1ltxiy4","score":9,"author_fullname":"t2_ixeagk4w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lanchain has hooks for logging by default. If you set a langsmith key then it's automatically logging to the langsmith API. [https://docs.smith.langchain.com/](https://docs.smith.langchain.com/)\\n\\nYou don't have to use langsmith and can customize where it logs to such as with a local [langfuse](https://langfuse.com/docs/integrations/langchain/tracing), or any other tool.\\n\\nFrom your description, it sounds like you vibe coded an AI agent without considering a front end or monitoring.\\n\\n  \\nAt minimum, have your team do this: [https://academy.langchain.com/](https://academy.langchain.com/)","edited":1751910886,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uf0ac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lanchain has hooks for logging by default. If you set a langsmith key then it&amp;#39;s automatically logging to the langsmith API. &lt;a href=\\"https://docs.smith.langchain.com/\\"&gt;https://docs.smith.langchain.com/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;You don&amp;#39;t have to use langsmith and can customize where it logs to such as with a local &lt;a href=\\"https://langfuse.com/docs/integrations/langchain/tracing\\"&gt;langfuse&lt;/a&gt;, or any other tool.&lt;/p&gt;\\n\\n&lt;p&gt;From your description, it sounds like you vibe coded an AI agent without considering a front end or monitoring.&lt;/p&gt;\\n\\n&lt;p&gt;At minimum, have your team do this: &lt;a href=\\"https://academy.langchain.com/\\"&gt;https://academy.langchain.com/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1uf0ac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751910455,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1u8mnt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"indicava","can_mod_post":false,"created_utc":1751908569,"send_replies":true,"parent_id":"t3_1ltxiy4","score":15,"author_fullname":"t2_4dvff","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, when you write software that operates in a commercial setting using Cursor and “messing around” it isn’t surprising you’re not familiar with LangChain’s persistent state options, LangSmith for pretty good observability, or the fact that Auth and access control are out of scope for these frameworks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1u8mnt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, when you write software that operates in a commercial setting using Cursor and “messing around” it isn’t surprising you’re not familiar with LangChain’s persistent state options, LangSmith for pretty good observability, or the fact that Auth and access control are out of scope for these frameworks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1u8mnt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751908569,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wq1dk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1751937741,"send_replies":true,"parent_id":"t3_1ltxiy4","score":2,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Prototype vs production woes, as usual. Langchain is good for kicking off a project but woe be unto you if you use it in production. Visibility is nil; stuff just breaks and you're stuck with no idea what happened.\\n\\nI tried Semantic Kernel's agentic patterns and they're good, but Microsoft says they're still experimental and bound to change. My solution was to create my own simple framework wrapped around OpenAI calls with plenty of logging. For most simpler agentic projects, you're better off using the most basic primitives you can get away with.\\n\\nAs for evals, there are Microsoft frameworks (MS again!) for this but you're relying on an LLM to judge another LLM's output.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1wq1dk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Prototype vs production woes, as usual. Langchain is good for kicking off a project but woe be unto you if you use it in production. Visibility is nil; stuff just breaks and you&amp;#39;re stuck with no idea what happened.&lt;/p&gt;\\n\\n&lt;p&gt;I tried Semantic Kernel&amp;#39;s agentic patterns and they&amp;#39;re good, but Microsoft says they&amp;#39;re still experimental and bound to change. My solution was to create my own simple framework wrapped around OpenAI calls with plenty of logging. For most simpler agentic projects, you&amp;#39;re better off using the most basic primitives you can get away with.&lt;/p&gt;\\n\\n&lt;p&gt;As for evals, there are Microsoft frameworks (MS again!) for this but you&amp;#39;re relying on an LLM to judge another LLM&amp;#39;s output.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1wq1dk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751937741,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1u665d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Eugr","can_mod_post":false,"created_utc":1751907856,"send_replies":true,"parent_id":"t3_1ltxiy4","score":2,"author_fullname":"t2_f3l6q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can look at PydanticAI - much cleaner framework IMO with better logging/observability support. You still need to take care of auth outside of the framework, but I like it so far.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1u665d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can look at PydanticAI - much cleaner framework IMO with better logging/observability support. You still need to take care of auth outside of the framework, but I like it so far.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1u665d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751907856,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1v1fll","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"secopsml","can_mod_post":false,"created_utc":1751917707,"send_replies":true,"parent_id":"t3_1ltxiy4","score":1,"author_fullname":"t2_pmniwf57y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Observability for lang chain with laminar lmnr.ai.\\n\\n\\nWorks flawlessly as simple decorator. With evaluation suite.\\n\\n\\nI use plain http requests or openai sdk as 3rd party libraries usually are so late to implement new features that it is easier to just fetch/requests/httpx etc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v1fll","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Observability for lang chain with laminar lmnr.ai.&lt;/p&gt;\\n\\n&lt;p&gt;Works flawlessly as simple decorator. With evaluation suite.&lt;/p&gt;\\n\\n&lt;p&gt;I use plain http requests or openai sdk as 3rd party libraries usually are so late to implement new features that it is easier to just fetch/requests/httpx etc&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1v1fll/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751917707,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vrvny","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thatphotoguy89","can_mod_post":false,"created_utc":1751926436,"send_replies":true,"parent_id":"t3_1ltxiy4","score":1,"author_fullname":"t2_nmj51","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Log with MLFlow. If you want evals as well, look into InspectAI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vrvny","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Log with MLFlow. If you want evals as well, look into InspectAI&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1vrvny/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751926436,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xyur9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArtfulGenie69","can_mod_post":false,"created_utc":1751956480,"send_replies":true,"parent_id":"t3_1ltxiy4","score":1,"author_fullname":"t2_1d6ghm3sq0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, I'm on cursor with no team and even I got agent persistent memory working on my crewai app, hehe. Making me feel good! Are you not having the langchain agents do validation? Is their validating just crummy?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xyur9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, I&amp;#39;m on cursor with no team and even I got agent persistent memory working on my crewai app, hehe. Making me feel good! Are you not having the langchain agents do validation? Is their validating just crummy?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxiy4/langchaincrewautogen_made_it_easy_to_build_agents/n1xyur9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751956480,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxiy4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:a});export{r as default};
