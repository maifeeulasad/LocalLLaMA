import{j as e}from"./index-Ce60G8KS.js";import{R as l}from"./RedditPostRenderer-Dxoi04TZ.js";import"./index-D3PeynhN.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"source from his instagram page","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Mark presenting four Llama 4 models, even a 2 trillion parameters model!!!","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1jsampe","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.85,"author_flair_background_color":null,"ups":2626,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_d2iqn","secure_media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/7bgnzhtxb2te1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1920,"width":1080,"scrubber_media_url":"https://v.redd.it/7bgnzhtxb2te1/DASH_96.mp4","dash_url":"https://v.redd.it/7bgnzhtxb2te1/DASHPlaylist.mpd?a=1753717838%2CNzlkOTYwZGYxYmVjZTljNmEyZGRiYjI0MzU5OTU4NGQyNDUzMzY2Zjk5YzQzMjc1ZmFiMWYyNTM3M2I5ZDYwNw%3D%3D&amp;v=1&amp;f=sd","duration":138,"hls_url":"https://v.redd.it/7bgnzhtxb2te1/HLSPlaylist.m3u8?a=1753717838%2CNzVkMWIzZWQ3MGQ4ZGNhYTJlZTllY2Y2NzJmOTM4MTQyMDAzOWZjZTljZTdjZGNiNDhmYmY1Yzk4N2JjZDk4Mw%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":2626,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=30a64a5194832e9a0910f0c41bdb486fe7042148","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1743879128,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;source from his instagram page&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/7bgnzhtxb2te1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?format=pjpg&amp;auto=webp&amp;s=199f7992a940419d0c0850f9fb12e1fcf3f4c92c","width":977,"height":1737},"resolutions":[{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b7cffa556cbce0f424929424c553b581a2646032","width":108,"height":192},{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5ee9b622a77b6ed8d8699a567dd73ba44ff7aae2","width":216,"height":384},{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ee28e8c79fd4316fe251e015ac11ef32f0116933","width":320,"height":568},{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=92dea81cd31b590804421b543526cb96395e5c2f","width":640,"height":1137},{"url":"https://external-preview.redd.it/Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e80c2044f6c63fad9e7396b048f349706441e681","width":960,"height":1706}],"variants":{},"id":"Z3p2aHZudXhiMnRlMYW4H8xHgtzR3pjuficV95KktJ2KVETiew0YUMQL020k"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1jsampe","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"LarDark","discussion_type":null,"num_comments":592,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/7bgnzhtxb2te1/DASH_1080.mp4?source=fallback","has_audio":true,"height":1920,"width":1080,"scrubber_media_url":"https://v.redd.it/7bgnzhtxb2te1/DASH_96.mp4","dash_url":"https://v.redd.it/7bgnzhtxb2te1/DASHPlaylist.mpd?a=1753717838%2CNzlkOTYwZGYxYmVjZTljNmEyZGRiYjI0MzU5OTU4NGQyNDUzMzY2Zjk5YzQzMjc1ZmFiMWYyNTM3M2I5ZDYwNw%3D%3D&amp;v=1&amp;f=sd","duration":138,"hls_url":"https://v.redd.it/7bgnzhtxb2te1/HLSPlaylist.m3u8?a=1753717838%2CNzVkMWIzZWQ3MGQ4ZGNhYTJlZTllY2Y2NzJmOTM4MTQyMDAzOWZjZTljZTdjZGNiNDhmYmY1Yzk4N2JjZDk4Mw%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/","stickied":false,"url":"https://v.redd.it/7bgnzhtxb2te1","subreddit_subscribers":492313,"created_utc":1743879128,"num_crossposts":2,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlmewft","id":"mlmewft","parent_id":"t1_mllj1j0","depth":4,"children":["mlmewft"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllj1j0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Careless-Age-4290","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll8sw6","score":7,"author_fullname":"t2_dktbk6jim","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I went to lizard people first","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllj1j0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I went to lizard people first&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllj1j0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743886360,"author_flair_text":null,"treatment_tags":[],"created_utc":1743886360,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mll8sw6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pkotov","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll2e2b","score":31,"author_fullname":"t2_fxfz6hmx7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Everybody knew it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll8sw6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everybody knew it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8sw6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882928,"author_flair_text":null,"treatment_tags":[],"created_utc":1743882928,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}}],"before":null}},"user_reports":[],"saved":false,"id":"mll2e2b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"justGuy007","can_mod_post":false,"created_utc":1743880708,"send_replies":true,"parent_id":"t1_mll04dd","score":298,"author_fullname":"t2_n60qn3ib","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Zuk was the first AI, we just didn't know it 😅\\n\\nEdit: Also, the bent nose happened this year when Deepseek released r1 👀😅","edited":1743884266,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll2e2b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Zuk was the first AI, we just didn&amp;#39;t know it 😅&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Also, the bent nose happened this year when Deepseek released r1 👀😅&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll2e2b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880708,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":298}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlmzpud","id":"mlmzpud","parent_id":"t1_mll6xu3","depth":2,"children":["mlmzpud"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll6xu3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"maraudingguard","can_mod_post":false,"created_utc":1743882288,"send_replies":true,"parent_id":"t1_mll04dd","score":21,"author_fullname":"t2_ooq6r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Android creating AGI, it's called Meta for a reason","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll6xu3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Android creating AGI, it&amp;#39;s called Meta for a reason&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll6xu3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882288,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_mllhy8o","id":"mllhy8o","parent_id":"t1_mll46iz","depth":3,"children":["mllhy8o","mloom90","mm2m5gj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll46iz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ebrbrbr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll19sc","score":26,"author_fullname":"t2_1cws6fp9ts","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's just a slight audio delay. It's consistent.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll46iz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s just a slight audio delay. It&amp;#39;s consistent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll46iz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881326,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881326,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"more","data":{"count":6,"name":"t1_mll3vxe","id":"mll3vxe","parent_id":"t1_mll19sc","depth":2,"children":["mll3vxe","mll3ivl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll19sc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pleasant-PolarBear","can_mod_post":false,"created_utc":1743880326,"send_replies":true,"parent_id":"t1_mll04dd","score":63,"author_fullname":"t2_fq884x8a2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was thinking the same thing, why does his mouth not sync with his voice? Once a lizard always a lizard.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll19sc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was thinking the same thing, why does his mouth not sync with his voice? Once a lizard always a lizard.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll19sc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880326,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":63}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_mlv6m5v","id":"mlv6m5v","parent_id":"t1_mlo9aa2","depth":5,"children":["mlv6m5v"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlo9aa2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tecedu","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnvqlf","score":8,"author_fullname":"t2_ozjx0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah cool now, get us those systems working with all major ML framworks, get them working with major resellers like CDW with atleast 5 years support and 4 hours response.","edited":false,"author_flair_css_class":null,"name":"t1_mlo9aa2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah cool now, get us those systems working with all major ML framworks, get them working with major resellers like CDW with atleast 5 years support and 4 hours response.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo9aa2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743930253,"author_flair_text":null,"collapsed":false,"created_utc":1743930253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mlv6nmg","id":"mlv6nmg","parent_id":"t1_mlp7dep","depth":5,"children":["mlv6nmg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp7dep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"trahloc","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnvqlf","score":3,"author_fullname":"t2_42ln1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tell me when they've made a thousand units available for sale to a 3rd party.","edited":false,"author_flair_css_class":null,"name":"t1_mlp7dep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tell me when they&amp;#39;ve made a thousand units available for sale to a 3rd party.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlp7dep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947898,"author_flair_text":null,"collapsed":false,"created_utc":1743947898,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnvqlf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"uhuge","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnibsp","score":4,"author_fullname":"t2_742ne6tg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They get crushed on the inference front by SambaNova, Cerebrus and others though..?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlnvqlf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They get crushed on the inference front by SambaNova, Cerebrus and others though..?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnvqlf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743921803,"author_flair_text":null,"treatment_tags":[],"created_utc":1743921803,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnibsp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CryptoMines","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmlnu3","score":18,"author_fullname":"t2_3d05uie","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nvidia don’t need any training to happen on any of their chips and they still won’t be able to keep up with demand for the next 10 years. Inference and usage are what’s going to gobble up the GPUs, not training.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlnibsp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nvidia don’t need any training to happen on any of their chips and they still won’t be able to keep up with demand for the next 10 years. Inference and usage are what’s going to gobble up the GPUs, not training.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnibsp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743914574,"author_flair_text":null,"treatment_tags":[],"created_utc":1743914574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlosyz4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"darkpigvirus","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmlnu3","score":5,"author_fullname":"t2_91pguotp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"more compute power + GREAT AI SCIENCE = google ai like gemma\\n\\nmore compute power + good ai science + max community contribution = llama 4","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlosyz4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;more compute power + GREAT AI SCIENCE = google ai like gemma&lt;/p&gt;\\n\\n&lt;p&gt;more compute power + good ai science + max community contribution = llama 4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlosyz4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941925,"author_flair_text":null,"treatment_tags":[],"created_utc":1743941925,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":17,"name":"t1_mlob61o","id":"mlob61o","parent_id":"t1_mlmlnu3","depth":2,"children":["mlob61o","mlmow9k","mlmoedn","mlnnbwj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmlnu3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1743900606,"send_replies":true,"parent_id":"t1_mll04dd","score":42,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Plot twist, Zuck figured out Llama 4 was dead on arrival when DeepSeek dropped their model, so he took a massive short position on Nvidia stock, put all their effort into turning the Llama 4 that they were working on into a much much larger model to demonstrate that just throwing more compute at training has hit a brick wall and that American companies can't compete with the Chinese. As soon as the market realizes what this absolute failure means for Nvidia data center GPU sales, that can't be sold to China, their stock will plunge and Zuck can sell the shorts to recoup much of what they wasted training llama 4. \\n\\n\\nThe potential upside is that Nvidia might be forced to rely more on consumer cards again, which means they'll increase production and try sell as many as possible, requiring them to lower prices as well. Perhaps that's what Zuckerberg was up to all along and he just gave the open source community the best present we could ask for.","edited":1743901324,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmlnu3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Plot twist, Zuck figured out Llama 4 was dead on arrival when DeepSeek dropped their model, so he took a massive short position on Nvidia stock, put all their effort into turning the Llama 4 that they were working on into a much much larger model to demonstrate that just throwing more compute at training has hit a brick wall and that American companies can&amp;#39;t compete with the Chinese. As soon as the market realizes what this absolute failure means for Nvidia data center GPU sales, that can&amp;#39;t be sold to China, their stock will plunge and Zuck can sell the shorts to recoup much of what they wasted training llama 4. &lt;/p&gt;\\n\\n&lt;p&gt;The potential upside is that Nvidia might be forced to rely more on consumer cards again, which means they&amp;#39;ll increase production and try sell as many as possible, requiring them to lower prices as well. Perhaps that&amp;#39;s what Zuckerberg was up to all along and he just gave the open source community the best present we could ask for.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmlnu3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743900606,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllagvs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kirath99","can_mod_post":false,"created_utc":1743883490,"send_replies":true,"parent_id":"t1_mll04dd","score":3,"author_fullname":"t2_59oifw7f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah this is something the AI would do, you know to taunt us humans","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllagvs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah this is something the AI would do, you know to taunt us humans&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllagvs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883490,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":10,"name":"t1_mll1fdl","id":"mll1fdl","parent_id":"t1_mll04dd","depth":1,"children":["mll1fdl","mll4qwn","mlmiwag","mlmmnvr","mln58z0","mlogk2y","mlzm7k0","mln0hcv","mlnwoas"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll04dd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1743879933,"send_replies":true,"parent_id":"t3_1jsampe","score":877,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"At this point I do not know if it real or AI generated /s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll04dd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At this point I do not know if it real or AI generated /s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll04dd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743879933,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":877}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlolasw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Snoo_28140","can_mod_post":false,"send_replies":true,"parent_id":"t1_mln97en","score":6,"author_fullname":"t2_6ms1kza7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So true 😅","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlolasw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So true 😅&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlolasw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743937865,"author_flair_text":null,"treatment_tags":[],"created_utc":1743937865,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mln97en","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mreggman6000","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllb86m","score":42,"author_fullname":"t2_8hl3oxwi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Waiting for 4.2 3b models 🤣","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mln97en","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Waiting for 4.2 3b models 🤣&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln97en/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743910373,"author_flair_text":null,"treatment_tags":[],"created_utc":1743910373,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mls2cjy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DangerousBrat","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllb86m","score":2,"author_fullname":"t2_1gmik7kinq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do they prune a model? How do they decide which parameters to  cut?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mls2cjy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do they prune a model? How do they decide which parameters to  cut?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mls2cjy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743981884,"author_flair_text":null,"treatment_tags":[],"created_utc":1743981884,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mllb86m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chilidawg","can_mod_post":false,"created_utc":1743883743,"send_replies":true,"parent_id":"t1_mll3db5","score":73,"author_fullname":"t2_66rg9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Here's hoping for 4.1 pruned options","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllb86m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Here&amp;#39;s hoping for 4.1 pruned options&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllb86m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883743,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":73}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_mlnzh3f","id":"mlnzh3f","parent_id":"t1_mlnfddt","depth":3,"children":["mlnzh3f"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnfddt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Calm-Ad-2155","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllhjhm","score":10,"author_fullname":"t2_sktpdgir","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I get good runs with those models on a 9070XT too, straight Vulkan and PyTorch also works with it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlnfddt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I get good runs with those models on a 9070XT too, straight Vulkan and PyTorch also works with it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnfddt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743913137,"author_flair_text":null,"treatment_tags":[],"created_utc":1743913137,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"more","data":{"count":5,"name":"t1_mlqmi1g","id":"mlqmi1g","parent_id":"t1_mllhjhm","depth":2,"children":["mlqmi1g","mlqocu9","mlqmwxr","mlo4qec"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllhjhm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ill_Yam_9994","can_mod_post":false,"created_utc":1743885859,"send_replies":true,"parent_id":"t1_mll3db5","score":39,"author_fullname":"t2_viqqk6www","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The scout might run okay on consumer PCs being MoE. 3090/4090/5090 + 64GB of RAM can probably load and run Q4?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllhjhm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The scout might run okay on consumer PCs being MoE. 3090/4090/5090 + 64GB of RAM can probably load and run Q4?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllhjhm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885859,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln6p9g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"phazei","can_mod_post":false,"created_utc":1743909255,"send_replies":true,"parent_id":"t1_mll3db5","score":4,"author_fullname":"t2_4aen8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We still get another chance next week with the Qwens!  Sure hope v3 has a 32b avail... otherwise.... super disappoint","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln6p9g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We still get another chance next week with the Qwens!  Sure hope v3 has a 32b avail... otherwise.... super disappoint&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln6p9g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909255,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":20,"name":"t1_mlmujq5","id":"mlmujq5","parent_id":"t1_mll3db5","depth":1,"children":["mlmujq5","mlpex42","mlo5ilw","mlp6iac","mlmtrzf","mlmuvw2","mlnbzp6","mlnf91u"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll3db5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LarDark","can_mod_post":false,"created_utc":1743881044,"send_replies":true,"parent_id":"t3_1jsampe","score":281,"author_fullname":"t2_d2iqn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Still I wanted a 32b or less model :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll3db5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still I wanted a 32b or less model :(&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll3db5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881044,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":281}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlngp5b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the__storm","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmxpro","score":4,"author_fullname":"t2_gx0bv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"256k pre-training is a good sign, but yeah I want to see how it holds up.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlngp5b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;256k pre-training is a good sign, but yeah I want to see how it holds up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlngp5b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743913772,"author_flair_text":null,"treatment_tags":[],"created_utc":1743913772,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmxpro","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ramzeez88","can_mod_post":false,"created_utc":1743905444,"send_replies":true,"parent_id":"t1_mll9tzm","score":29,"author_fullname":"t2_usy2s7an","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it stays coherent at such size. Even if it was 500k ,it would still be awesome and easier on RAM requirements.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmxpro","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it stays coherent at such size. Even if it was 500k ,it would still be awesome and easier on RAM requirements.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmxpro/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743905444,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"more","data":{"count":1,"name":"t1_mlputck","id":"mlputck","parent_id":"t1_mll9tzm","depth":1,"children":["mlputck"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9tzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ChatGPTit","can_mod_post":false,"created_utc":1743883275,"send_replies":true,"parent_id":"t3_1jsampe","score":64,"author_fullname":"t2_k47hnsqi5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"10M input token is wild","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9tzm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;10M input token is wild&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9tzm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883275,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":64}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":46,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":39,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":33,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":43,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mlnl3bc","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnl3bc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnjxik","score":43,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Llama 13, multiverse","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 13, multiverse&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnl3bc/","num_reports":null,"locked":false,"name":"t1_mlnl3bc","created":1743915956,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743915956,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnjxik","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Exact_League_5","can_mod_post":false,"created_utc":1743915368,"send_replies":true,"parent_id":"t1_mlnjijq","score":36,"author_fullname":"t2_7dzb230pa","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama 12 Observable universe","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlnjxik","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 12 Observable universe&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnjxik/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743915368,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnjijq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnjhaa","score":33,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnjijq/","num_reports":null,"locked":false,"name":"t1_mlnjijq","created":1743915162,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743915162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnjhaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlncxvf","score":39,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnjhaa/","num_reports":null,"locked":false,"name":"t1_mlnjhaa","created":1743915145,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743915145,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mlncxvf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nullnuller","can_mod_post":false,"send_replies":true,"parent_id":"t1_mln1t8y","score":42,"author_fullname":"t2_tfi3do4i","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama 9 solar system","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlncxvf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 9 solar system&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlncxvf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743912027,"author_flair_text":null,"treatment_tags":[],"created_utc":1743912027,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}}],"before":null}},"user_reports":[],"saved":false,"id":"mln1t8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmgtu1","score":46,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln1t8y/","num_reports":null,"locked":false,"name":"t1_mln1t8y","created":1743907143,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743907143,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmgtu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"0xFatWhiteMan","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllnzyr","score":53,"author_fullname":"t2_pz2dkuedp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama 7 one per country","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmgtu1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama 7 one per country&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmgtu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743898738,"author_flair_text":null,"treatment_tags":[],"created_utc":1743898738,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}}],"before":null}},"user_reports":[],"saved":false,"id":"mllnzyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yehiaserag","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllhaj9","score":69,"author_fullname":"t2_xfnx16t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama6 on a single city","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllnzyr","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama6 on a single city&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllnzyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743888081,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1743888081,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo7tbg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ain92ru","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllhaj9","score":2,"author_fullname":"t2_fzavzbid","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"These are just scaling laws, like it or not but larger models will always be better than the smaller ones distilled from them","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlo7tbg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These are just scaling laws, like it or not but larger models will always be better than the smaller ones distilled from them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo7tbg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743929285,"author_flair_text":null,"treatment_tags":[],"created_utc":1743929285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":1,"name":"t1_mlqwsdq","id":"mlqwsdq","parent_id":"t1_mllhaj9","depth":2,"children":["mlqwsdq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllhaj9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Rich_Artist_8327","can_mod_post":false,"created_utc":1743885775,"send_replies":true,"parent_id":"t1_mll9l6f","score":164,"author_fullname":"t2_1jk2ep8a52","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Lllama5 will work in a single datacenter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllhaj9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lllama5 will work in a single datacenter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllhaj9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885775,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":164}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlou96h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielv123","can_mod_post":false,"created_utc":1743942539,"send_replies":true,"parent_id":"t1_mll9l6f","score":15,"author_fullname":"t2_hllk9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not a joke, the single GPU they are quoting is an H100 with int4 quant.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlou96h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not a joke, the single GPU they are quoting is an H100 with int4 quant.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlou96h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743942539,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mm4wy1o","id":"mm4wy1o","parent_id":"t1_mlonmdk","depth":2,"children":["mm4wy1o"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlonmdk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sassydodo","can_mod_post":false,"created_utc":1743939186,"send_replies":true,"parent_id":"t1_mll9l6f","score":8,"author_fullname":"t2_qds2a3i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"single gpu isn't your 5080/5090 lol, its data center gpu, with 80gb of vram","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlonmdk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;single gpu isn&amp;#39;t your 5080/5090 lol, its data center gpu, with 80gb of vram&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlonmdk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743939186,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9l6f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Delicious_Draft_8907","can_mod_post":false,"created_utc":1743883194,"send_replies":true,"parent_id":"t3_1jsampe","score":250,"author_fullname":"t2_1bmxbv0yzl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks to Meta for continuing to stick with open weights. Also great to hear they are targeting single GPU and single systems, looking forward to try it out!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9l6f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks to Meta for continuing to stick with open weights. Also great to hear they are targeting single GPU and single systems, looking forward to try it out!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9l6f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883194,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":250}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlourov","id":"mlourov","parent_id":"t1_mll0ynj","depth":2,"children":["mlourov"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll0ynj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dogeboja","can_mod_post":false,"created_utc":1743880220,"send_replies":true,"parent_id":"t1_mll0l0o","score":139,"author_fullname":"t2_eurkn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Deepseek V3 has 37 billion active parameters and 256 experts. But it's a 671B model. You can read the paper how this works, the \\"experts\\" are not full smaller 37B models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll0ynj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek V3 has 37 billion active parameters and 256 experts. But it&amp;#39;s a 671B model. You can read the paper how this works, the &amp;quot;experts&amp;quot; are not full smaller 37B models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll0ynj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":139}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":20,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqyb2y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kovnev","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllf74a","score":3,"author_fullname":"t2_hhw87t7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So when he says single GPU he is clearly talking about commercial data center GPU's? That's more than a little misleading...","edited":false,"author_flair_css_class":null,"name":"t1_mlqyb2y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So when he says single GPU he is clearly talking about commercial data center GPU&amp;#39;s? That&amp;#39;s more than a little misleading...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlqyb2y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743968334,"author_flair_text":null,"collapsed":false,"created_utc":1743968334,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":6,"name":"t1_mllg16h","id":"mllg16h","parent_id":"t1_mllf74a","depth":4,"children":["mllg16h","mlm4pyw","mlom4vi"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllf74a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlld0jy","score":95,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Why dont they include the size of the model? How do I know if it will fit my vram without actual numbers?\\n\\nThe rule is simple:\\n\\n* **FP16** (2 bytes per parameter): VRAM ≈ (B + C × D) × 2\\n* **FP8** (1 byte per parameter): VRAM ≈ B + C × D\\n* **INT4** (0.5 bytes per parameter): VRAM ≈ (B + C × D) / 2\\n\\nWhere B - billions of parameters, C - context size (10M for example), D - model dimensions or \`hidden_size\` (e.g. [5120](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-unsloth-bnb-4bit/blob/main/config.json) for Llama 4 Scout).\\n\\nSome examples for Llama 4 Scout (109B) and full (10M) context window:\\n\\n* FP8: \`(109E9 + 10E6 * 5120) / (1024 * 1024 * 1024)\` \\\\~150 GB VRAM\\n* INT4: \`(109E9 + 10E6 * 5120) / 2 / (1024 * 1024 * 1024)\` \\\\~75 GB VRAM\\n\\n150GB is a single B200 (180GB) (\\\\~$8 per hour)\\n\\n75GB is a single H100 (80GB) (\\\\~$2.4 per hour)\\n\\nFor 1M context window the Llama 4 Scout requires only 106GB (FP8) or 53GB (INT4 on couple of 5090) of VRAM.\\n\\nSmall quants and 8K context window will give you:\\n\\n* INT3 (\\\\~37.5%) : 38 GB (most of 48 layers are on 5090 GPU)\\n* INT2 (\\\\~25%): 25 GB (almost all 48 layers are on 4090 GPU)\\n* INT1/Binary (\\\\~12.5%): 13 GB (no sure about model capabilities :)","edited":1744049525,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllf74a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Why dont they include the size of the model? How do I know if it will fit my vram without actual numbers?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The rule is simple:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;FP16&lt;/strong&gt; (2 bytes per parameter): VRAM ≈ (B + C × D) × 2&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;FP8&lt;/strong&gt; (1 byte per parameter): VRAM ≈ B + C × D&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;INT4&lt;/strong&gt; (0.5 bytes per parameter): VRAM ≈ (B + C × D) / 2&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Where B - billions of parameters, C - context size (10M for example), D - model dimensions or &lt;code&gt;hidden_size&lt;/code&gt; (e.g. &lt;a href=\\"https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-unsloth-bnb-4bit/blob/main/config.json\\"&gt;5120&lt;/a&gt; for Llama 4 Scout).&lt;/p&gt;\\n\\n&lt;p&gt;Some examples for Llama 4 Scout (109B) and full (10M) context window:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;FP8: &lt;code&gt;(109E9 + 10E6 * 5120) / (1024 * 1024 * 1024)&lt;/code&gt; ~150 GB VRAM&lt;/li&gt;\\n&lt;li&gt;INT4: &lt;code&gt;(109E9 + 10E6 * 5120) / 2 / (1024 * 1024 * 1024)&lt;/code&gt; ~75 GB VRAM&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;150GB is a single B200 (180GB) (~$8 per hour)&lt;/p&gt;\\n\\n&lt;p&gt;75GB is a single H100 (80GB) (~$2.4 per hour)&lt;/p&gt;\\n\\n&lt;p&gt;For 1M context window the Llama 4 Scout requires only 106GB (FP8) or 53GB (INT4 on couple of 5090) of VRAM.&lt;/p&gt;\\n\\n&lt;p&gt;Small quants and 8K context window will give you:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;INT3 (~37.5%) : 38 GB (most of 48 layers are on 5090 GPU)&lt;/li&gt;\\n&lt;li&gt;INT2 (~25%): 25 GB (almost all 48 layers are on 4090 GPU)&lt;/li&gt;\\n&lt;li&gt;INT1/Binary (~12.5%): 13 GB (no sure about model capabilities :)&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllf74a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885078,"author_flair_text":null,"treatment_tags":[],"created_utc":1743885078,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":95}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mlnk04t","id":"mlnk04t","parent_id":"t1_mlmyr44","depth":4,"children":["mlnk04t","mlo122k"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmyr44","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"InterstitialLove","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlld0jy","score":11,"author_fullname":"t2_b42k1qb3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nobody runs unquantized models anyways, so how big it ends up depends on the specifics of what format you use to quantize it\\n\\nI mean, you're presumably not downloading models from meta directly. They come from randos on huggingface who fine tune the model and then release it in various formats and quantization levels. How is Zuck supposed to know what those guys are gonna do before you download it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmyr44","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nobody runs unquantized models anyways, so how big it ends up depends on the specifics of what format you use to quantize it&lt;/p&gt;\\n\\n&lt;p&gt;I mean, you&amp;#39;re presumably not downloading models from meta directly. They come from randos on huggingface who fine tune the model and then release it in various formats and quantization levels. How is Zuck supposed to know what those guys are gonna do before you download it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmyr44/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743905866,"author_flair_text":null,"treatment_tags":[],"created_utc":1743905866,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":3,"name":"t1_mln8oa4","id":"mln8oa4","parent_id":"t1_mlld0jy","depth":3,"children":["mln8oa4","mlnyq7y"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlld0jy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1743884346,"send_replies":true,"parent_id":"t1_mll8h90","score":20,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlld0jy/","num_reports":null,"locked":false,"name":"t1_mlld0jy","created":1743884346,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":12,"name":"t1_mllf4z0","id":"mllf4z0","parent_id":"t1_mll8h90","depth":2,"children":["mllf4z0","mlo902e"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll8h90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"created_utc":1743882818,"send_replies":true,"parent_id":"t1_mll0l0o","score":67,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"From [here](https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/):\\n\\nhttps://preview.redd.it/kf6pyarum2te1.png?width=1922&amp;format=png&amp;auto=webp&amp;s=556d93e1bbb197663225ffa0ebd8dd61ecb5a9af","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8h90","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From &lt;a href=\\"https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/\\"&gt;here&lt;/a&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/kf6pyarum2te1.png?width=1922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=556d93e1bbb197663225ffa0ebd8dd61ecb5a9af\\"&gt;https://preview.redd.it/kf6pyarum2te1.png?width=1922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=556d93e1bbb197663225ffa0ebd8dd61ecb5a9af&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8h90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882818,"media_metadata":{"kf6pyarum2te1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":62,"x":108,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e359c20b2ec51ec794397939818c7f5dfcd8f9d"},{"y":124,"x":216,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1bdbaa74892f1368b97e1a8d54f8529e99a1f9b"},{"y":184,"x":320,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5eab20f3632a6fa395af29a55f157a32533892dd"},{"y":369,"x":640,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=09b44adcecd6722878fb090cb2f28d2239b6de0c"},{"y":554,"x":960,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c03745ac31f98c66e7d9a3989c67eb41058d50d"},{"y":623,"x":1080,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=26db258cec8bddb56c68bca5d8098df3ed910fc5"}],"s":{"y":1110,"x":1922,"u":"https://preview.redd.it/kf6pyarum2te1.png?width=1922&amp;format=png&amp;auto=webp&amp;s=556d93e1bbb197663225ffa0ebd8dd61ecb5a9af"},"id":"kf6pyarum2te1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":67}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll8sut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xandrmoro","can_mod_post":false,"created_utc":1743882927,"send_replies":true,"parent_id":"t1_mll0l0o","score":29,"author_fullname":"t2_i13ds","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In short, experts share portion of their weights, they are not fully isolated","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8sut","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In short, experts share portion of their weights, they are not fully isolated&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8sut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882927,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mn975cy","id":"mn975cy","parent_id":"t1_mme0xgv","depth":3,"children":["mn975cy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mme0xgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zkstx","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlvkj3x","score":3,"author_fullname":"t2_ngj5tm8x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is interesting! Do you know of any way to keep and inference the shared portion specifically on GPU while keeping the routed portion in RAM for CPU inference (would still require communicating the activations after each layer but I could imagine it would be faster than cycling the weights)? As of now llamacpp offloads full layers by default, I believe","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mme0xgv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is interesting! Do you know of any way to keep and inference the shared portion specifically on GPU while keeping the routed portion in RAM for CPU inference (would still require communicating the activations after each layer but I could imagine it would be faster than cycling the weights)? As of now llamacpp offloads full layers by default, I believe&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mme0xgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744293588,"author_flair_text":null,"treatment_tags":[],"created_utc":1744293588,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":5,"name":"t1_mmgwf5p","id":"mmgwf5p","parent_id":"t1_mlvkj3x","depth":2,"children":["mmgwf5p"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlvkj3x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jpydych","can_mod_post":false,"created_utc":1744039463,"send_replies":true,"parent_id":"t1_mll0l0o","score":7,"author_fullname":"t2_18z3gi173f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In case of Maverick, one routed expert is hidden\\\\_size \\\\* intermediate\\\\_size \\\\* 3 = 125 829 120 parameters per layer. A MoE sublayer is placed every second layer, and one routed expert is active per token per layer, resulting in 125 829 120 \\\\* num\\\\_hidden\\\\_layers / interleave\\\\_moe\\\\_layer\\\\_step = 3 019 898 880 parameters activated per token in MoE sublayers.   \\n  \\nAdditionally, they placed so called \\"shared expert\\" in each layer, which has hidden\\\\_size \\\\* intermediate\\\\_size\\\\_mlp \\\\* 3 = 251 658 240 parameters per layer, so 12 079 595 520 parameters are activated per token in all \\"shared expert\\" sublayers.\\n\\nThe model has also attention sublayers (obviously), which use hidden\\\\_size \\\\* num\\\\_key\\\\_value\\\\_heads \\\\* head\\\\_dim \\\\* 2 + hidden\\\\_size \\\\* num\\\\_attention\\\\_heads \\\\* head\\\\_dim = 36 700 160 per layer, so 1 761 607 680 in total.\\n\\nThis gives 3 019 898 880 + 12 079 595 520 + 1 761 607 680 = 16 861 102 080 activated parameters per token, and 3 019 898 880 \\\\* 128 + 12 079 595 520 + 1 761 607 680 = 400 388 259 840 total parameters, which checks out.\\n\\nYou can find those numbers in the \\"config.json\\" file, in the \\"text\\\\_config\\" section:  \\n[https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-FP8/blob/main/config.json](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-FP8/blob/main/config.json)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlvkj3x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In case of Maverick, one routed expert is hidden_size * intermediate_size * 3 = 125 829 120 parameters per layer. A MoE sublayer is placed every second layer, and one routed expert is active per token per layer, resulting in 125 829 120 * num_hidden_layers / interleave_moe_layer_step = 3 019 898 880 parameters activated per token in MoE sublayers.   &lt;/p&gt;\\n\\n&lt;p&gt;Additionally, they placed so called &amp;quot;shared expert&amp;quot; in each layer, which has hidden_size * intermediate_size_mlp * 3 = 251 658 240 parameters per layer, so 12 079 595 520 parameters are activated per token in all &amp;quot;shared expert&amp;quot; sublayers.&lt;/p&gt;\\n\\n&lt;p&gt;The model has also attention sublayers (obviously), which use hidden_size * num_key_value_heads * head_dim * 2 + hidden_size * num_attention_heads * head_dim = 36 700 160 per layer, so 1 761 607 680 in total.&lt;/p&gt;\\n\\n&lt;p&gt;This gives 3 019 898 880 + 12 079 595 520 + 1 761 607 680 = 16 861 102 080 activated parameters per token, and 3 019 898 880 * 128 + 12 079 595 520 + 1 761 607 680 = 400 388 259 840 total parameters, which checks out.&lt;/p&gt;\\n\\n&lt;p&gt;You can find those numbers in the &amp;quot;config.json&amp;quot; file, in the &amp;quot;text_config&amp;quot; section:&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-FP8/blob/main/config.json\\"&gt;https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-FP8/blob/main/config.json&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlvkj3x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744039463,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlvmgtu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jpydych","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll9jaf","score":3,"author_fullname":"t2_18z3gi173f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In fact, Maverick uses only 1 routed expert per two layers (which makes 3 019 898 880 parameters activated in MoE sublayer per token), one shared expert in each layer (which makes 12 079 595 520 activated per token), and GQA attention (which makes 1 761 607 680 activated per token).\\n\\nYou can find my exact calculations here: [https://www.reddit.com/r/LocalLLaMA/comments/1jsampe/comment/mlvkj3x/](https://www.reddit.com/r/LocalLLaMA/comments/1jsampe/comment/mlvkj3x/)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlvmgtu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In fact, Maverick uses only 1 routed expert per two layers (which makes 3 019 898 880 parameters activated in MoE sublayer per token), one shared expert in each layer (which makes 12 079 595 520 activated per token), and GQA attention (which makes 1 761 607 680 activated per token).&lt;/p&gt;\\n\\n&lt;p&gt;You can find my exact calculations here: &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1jsampe/comment/mlvkj3x/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jsampe/comment/mlvkj3x/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlvmgtu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744040062,"author_flair_text":null,"treatment_tags":[],"created_utc":1744040062,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlojw30","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TechnoByte_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll9jaf","score":2,"author_fullname":"t2_4w91lkml","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it's 109B total, 17B active","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlojw30","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it&amp;#39;s 109B total, 17B active&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlojw30/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743937032,"author_flair_text":null,"treatment_tags":[],"created_utc":1743937032,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9jaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Brainlag","can_mod_post":false,"created_utc":1743883176,"send_replies":true,"parent_id":"t1_mll0l0o","score":9,"author_fullname":"t2_4oasu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Expert size is not 17B but more like ~2.8B and then you have 6 active experts for 17B active parameters.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9jaf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Expert size is not 17B but more like ~2.8B and then you have 6 active experts for 17B active parameters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9jaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883176,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mlmpj79","id":"mlmpj79","parent_id":"t1_mll1fy6","depth":2,"children":["mlmpj79"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll1fy6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RealSataan","can_mod_post":false,"created_utc":1743880384,"send_replies":true,"parent_id":"t1_mll0l0o","score":12,"author_fullname":"t2_9iiw5xxe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Out of those experts only a few are activated. \\n\\nIt's a sparsely activated model class called mixture of experts. In models without the experts only one expert is there and it's activated for every token. But in models like these you have a bunch of experts and only a certain number of them are activated for every token. So you are using only a fraction of the total parameters, but still you need to keep all of the model in memory","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll1fy6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Out of those experts only a few are activated. &lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a sparsely activated model class called mixture of experts. In models without the experts only one expert is there and it&amp;#39;s activated for every token. But in models like these you have a bunch of experts and only a certain number of them are activated for every token. So you are using only a fraction of the total parameters, but still you need to keep all of the model in memory&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll1fy6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880384,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":7,"name":"t1_mlvkxds","id":"mlvkxds","parent_id":"t1_mll9yn3","depth":2,"children":["mlvkxds","mlmv85r"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9yn3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aurelivm","can_mod_post":false,"created_utc":1743883319,"send_replies":true,"parent_id":"t1_mll0l0o","score":5,"author_fullname":"t2_zg7via4p7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"17B parameters is several experts activated at once. MoEs generally do not activate only one expert at a time.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9yn3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;17B parameters is several experts activated at once. MoEs generally do not activate only one expert at a time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9yn3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883319,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlnykq2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CasulaScience","can_mod_post":false,"created_utc":1743923397,"send_replies":true,"parent_id":"t1_mll0l0o","score":2,"author_fullname":"t2_moyz0mhl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's active params, not all params are in the experts. It's impossible to say exactly how many params the model is just knowing the number of experts per layer and the active param count (e.g. 17B and 128). Things like number of layers, number of active experts per layer, FFN size, attention hidden dimension, whether they use latent attention, etc... all come into play.\\n\\nLlama 4 Scout is ~ 100B total params, and Llama 4 Maverick is ~ 400B total params","edited":1743924404,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlnykq2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s active params, not all params are in the experts. It&amp;#39;s impossible to say exactly how many params the model is just knowing the number of experts per layer and the active param count (e.g. 17B and 128). Things like number of layers, number of active experts per layer, FFN size, attention hidden dimension, whether they use latent attention, etc... all come into play.&lt;/p&gt;\\n\\n&lt;p&gt;Llama 4 Scout is ~ 100B total params, and Llama 4 Maverick is ~ 400B total params&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnykq2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743923397,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo6o2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iperson4213","can_mod_post":false,"created_utc":1743928538,"send_replies":true,"parent_id":"t1_mll0l0o","score":2,"author_fullname":"t2_j55lvyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"MoE is applied to the FFN only, other weights like attentions and embedding only have one. \\n\\nThe specific MoE uses 1 shared expert that is always on 128 routed experts, of which 1 is turned on by the router. \\n\\nIn addition, Interleaved MoE is used, meaning only every other layer has the 128 routed experts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo6o2q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MoE is applied to the FFN only, other weights like attentions and embedding only have one. &lt;/p&gt;\\n\\n&lt;p&gt;The specific MoE uses 1 shared expert that is always on 128 routed experts, of which 1 is turned on by the router. &lt;/p&gt;\\n\\n&lt;p&gt;In addition, Interleaved MoE is used, meaning only every other layer has the 128 routed experts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo6o2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743928538,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":4,"name":"t1_mll13kn","id":"mll13kn","parent_id":"t1_mll0l0o","depth":1,"children":["mll13kn","mll9zb1","mln4vz3","mlm8r6x"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll0l0o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MikeRoz","can_mod_post":false,"created_utc":1743880090,"send_replies":true,"parent_id":"t3_1jsampe","score":137,"author_fullname":"t2_ht2fg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone help me with the math on \\"Maverick\\"? 17B parameters x 128 experts - if you multiply those numbers, you get 2,176B, or 2.176T. But then a few moments later he touts \\"Behemoth\\" as having 2T parameters, which is presumably not as impressive if Maverick is 2.18T.\\n\\nEDIT: Looks like the model is ~702.8 GB at FP16...","edited":1743880609,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll0l0o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone help me with the math on &amp;quot;Maverick&amp;quot;? 17B parameters x 128 experts - if you multiply those numbers, you get 2,176B, or 2.176T. But then a few moments later he touts &amp;quot;Behemoth&amp;quot; as having 2T parameters, which is presumably not as impressive if Maverick is 2.18T.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Looks like the model is ~702.8 GB at FP16...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll0l0o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880090,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":137}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmlpvb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sheepcloudy","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll9t0n","score":18,"author_fullname":"t2_v7ifqqt62","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It has to pass the vibe-check test of fireship.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmlpvb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It has to pass the vibe-check test of fireship.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmlpvb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743900628,"author_flair_text":null,"treatment_tags":[],"created_utc":1743900628,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9t0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xandrmoro","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll8j9v","score":37,"author_fullname":"t2_i13ds","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thats actually good, given that R1 is like 60% bigger.\\n\\nBut real-world performance remains to be seen.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll9t0n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thats actually good, given that R1 is like 60% bigger.&lt;/p&gt;\\n\\n&lt;p&gt;But real-world performance remains to be seen.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9t0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883266,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883266,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}}],"before":null}},"user_reports":[],"saved":false,"id":"mll8j9v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RipleyVanDalen","can_mod_post":false,"created_utc":1743882837,"send_replies":false,"parent_id":"t1_mll5vu9","score":75,"author_fullname":"t2_vg6askym8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tied with R1 once you factor in style control. That's not too bad, especially considering Maverick isn't supposed to be a bigger model like Reasoning / Behemoth","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8j9v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tied with R1 once you factor in style control. That&amp;#39;s not too bad, especially considering Maverick isn&amp;#39;t supposed to be a bigger model like Reasoning / Behemoth&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8j9v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882837,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":75}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo4aq6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_sqrkl","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlnwyis","score":9,"author_fullname":"t2_pp9qh5t8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unadulterated slop (imo). Compare the outputs to gemini's to get a comparative sense of what frontier llms are capable of.","edited":1743928547,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo4aq6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unadulterated slop (imo). Compare the outputs to gemini&amp;#39;s to get a comparative sense of what frontier llms are capable of.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo4aq6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743926988,"author_flair_text":null,"treatment_tags":[],"created_utc":1743926988,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mlnwyis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"uhuge","can_mod_post":false,"send_replies":true,"parent_id":"t1_mln64fk","score":6,"author_fullname":"t2_742ne6tg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's wrong with the samples? I've tried reading some but only critique I might have was a bit dry style..?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlnwyis","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s wrong with the samples? I&amp;#39;ve tried reading some but only critique I might have was a bit dry style..?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnwyis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743922482,"author_flair_text":null,"treatment_tags":[],"created_utc":1743922482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":2,"name":"t1_mlori8m","id":"mlori8m","parent_id":"t1_mln64fk","depth":2,"children":["mlori8m"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mln64fk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_sqrkl","can_mod_post":false,"created_utc":1743909000,"send_replies":true,"parent_id":"t1_mll5vu9","score":28,"author_fullname":"t2_pp9qh5t8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My writing benchmarks disagree with this pretty hard.\\n\\n[Longform writing](https://eqbench.com/creative_writing_longform.html)\\n\\n[Creative writing v3](https://eqbench.com/creative_writing.html)\\n\\nNot sure if they are LMSYS-maxxing or if there's an implementation issue or what.\\n\\nI skimmed some of the [outputs](https://eqbench.com/results/creative-writing-longform/meta-llama__Llama-4-Maverick-17B-128E-Instruct_longform_report.html) and they are genuinely bad.\\n\\nIt's not uncommon for benchmarks to disagree but this amount of discrepancy needs some explaining.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln64fk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My writing benchmarks disagree with this pretty hard.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://eqbench.com/creative_writing_longform.html\\"&gt;Longform writing&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://eqbench.com/creative_writing.html\\"&gt;Creative writing v3&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Not sure if they are LMSYS-maxxing or if there&amp;#39;s an implementation issue or what.&lt;/p&gt;\\n\\n&lt;p&gt;I skimmed some of the &lt;a href=\\"https://eqbench.com/results/creative-writing-longform/meta-llama__Llama-4-Maverick-17B-128E-Instruct_longform_report.html\\"&gt;outputs&lt;/a&gt; and they are genuinely bad.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s not uncommon for benchmarks to disagree but this amount of discrepancy needs some explaining.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln64fk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909000,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mll7p5z","id":"mll7p5z","parent_id":"t1_mll7bsi","depth":2,"children":["mll7p5z"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll7bsi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CheekyBastard55","can_mod_post":false,"created_utc":1743882422,"send_replies":true,"parent_id":"t1_mll5vu9","score":8,"author_fullname":"t2_3yspdpju","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Now check with style control and see it humbled.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7bsi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now check with style control and see it humbled.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7bsi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882422,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":5,"name":"t1_mll81nn","id":"mll81nn","parent_id":"t1_mll5vu9","depth":1,"children":["mll81nn","mln7n57","mloa63t","mlnnl4r"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll5vu9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"alew3","can_mod_post":false,"created_utc":1743881919,"send_replies":true,"parent_id":"t3_1jsampe","score":154,"author_fullname":"t2_8bwjj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/2fy8orf7k2te1.png?width=1458&amp;format=png&amp;auto=webp&amp;s=4d030d1e8fea34167b876f4cced248a7de862931\\n\\n2nd place on LMArena","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll5vu9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/2fy8orf7k2te1.png?width=1458&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d030d1e8fea34167b876f4cced248a7de862931\\"&gt;https://preview.redd.it/2fy8orf7k2te1.png?width=1458&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d030d1e8fea34167b876f4cced248a7de862931&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;2nd place on LMArena&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll5vu9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881919,"media_metadata":{"2fy8orf7k2te1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":44,"x":108,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a194066d3e859c1709d93b1a14d28ff6e2d6ac3"},{"y":89,"x":216,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f64e88d5b1e99685c8eecf9b051db0f669553689"},{"y":132,"x":320,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ea92eb6b4b838831aab6a882f597737ff120fea"},{"y":265,"x":640,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d49cd6dda98bea45303dd45ba320789e8ecf51b3"},{"y":398,"x":960,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e4c8cb050a596ff690aeb35a49a38ee9df6a8ab6"},{"y":448,"x":1080,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=345607032f194fafdd79bb48afd9d95d8ad8a43f"}],"s":{"y":605,"x":1458,"u":"https://preview.redd.it/2fy8orf7k2te1.png?width=1458&amp;format=png&amp;auto=webp&amp;s=4d030d1e8fea34167b876f4cced248a7de862931"},"id":"2fy8orf7k2te1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":154}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllarur","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll6u2k","score":29,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fuck it. I'm kidnapping Jensen's leather jackets and holding them for ransom.","edited":false,"author_flair_css_class":null,"name":"t1_mllarur","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuck it. I&amp;#39;m kidnapping Jensen&amp;#39;s leather jackets and holding them for ransom.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllarur/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883594,"author_flair_text":null,"collapsed":false,"created_utc":1743883594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}}],"before":null}},"user_reports":[],"saved":false,"id":"mll6u2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheSn00pster","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3zag","score":15,"author_fullname":"t2_uozbh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Or else…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll6u2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or else…&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll6u2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882251,"author_flair_text":null,"treatment_tags":[],"created_utc":1743882251,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"more","data":{"count":1,"name":"t1_mma17k0","id":"mma17k0","parent_id":"t1_mll3zag","depth":3,"children":["mma17k0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll3zag","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3876","score":108,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just stop being poor, right?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll3zag","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just stop being poor, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll3zag/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881255,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881255,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":108}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllb1st","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pleasemakesense","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3876","score":10,"author_fullname":"t2_3hx3wwuc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Only 20k for now*","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllb1st","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Only 20k for now*&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllb1st/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883685,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":6,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlovjr2","id":"mlovjr2","parent_id":"t1_mll9dxp","depth":4,"children":["mlovjr2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9dxp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gthing","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll7qmd","score":9,"author_fullname":"t2_1mksj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yea Meta says it's designed to run on a single H100, but it doesn't explain exactly how that works.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9dxp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea Meta says it&amp;#39;s designed to run on a single H100, but it doesn&amp;#39;t explain exactly how that works.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9dxp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883126,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883126,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mll7qmd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1743882564,"send_replies":true,"parent_id":"t1_mll3876","score":6,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746985902,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7qmd/","num_reports":null,"locked":false,"name":"t1_mll7qmd","created":1743882564,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllcfyn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Rich_Artist_8327","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3876","score":15,"author_fullname":"t2_1jk2ep8a52","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Plus Tariffs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllcfyn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Plus Tariffs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcfyn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884152,"author_flair_text":null,"treatment_tags":[],"created_utc":1743884152,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllhh4t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"floridianfisher","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3876","score":3,"author_fullname":"t2_5ac5a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"At 4bit","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllhh4t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At 4bit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllhh4t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885836,"author_flair_text":null,"treatment_tags":[],"created_utc":1743885836,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":2,"name":"t1_mln5pkq","id":"mln5pkq","parent_id":"t1_mll3876","depth":2,"children":["mln5pkq","mllweop"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll3876","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gthing","can_mod_post":false,"created_utc":1743880994,"send_replies":true,"parent_id":"t1_mll1lgd","score":146,"author_fullname":"t2_1mksj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can if you have an H100. It's only like 20k bro whats the problem.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll3876","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can if you have an H100. It&amp;#39;s only like 20k bro whats the problem.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll3876/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880994,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":146}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":6,"name":"t1_mllgg8j","id":"mllgg8j","parent_id":"t1_mllcwnh","depth":6,"children":["mllgg8j"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllcwnh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baader-Meinhof","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllaftd","score":20,"author_fullname":"t2_3ngj9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"And Deepseek r1 only has 37B active but is SOTA.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mllcwnh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And Deepseek r1 only has 37B active but is SOTA.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcwnh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884309,"author_flair_text":null,"treatment_tags":[],"created_utc":1743884309,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"mllaftd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll4ntr","score":10,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But also.. only 17b parameters are active.","edited":false,"author_flair_css_class":null,"name":"t1_mllaftd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But also.. only 17b parameters are active.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllaftd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883480,"author_flair_text":null,"collapsed":false,"created_utc":1743883480,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4ntr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Baader-Meinhof","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3mru","score":30,"author_fullname":"t2_3ngj9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It will run dramatically faster as only 17B parameters are active. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll4ntr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will run dramatically faster as only 17B parameters are active. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4ntr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881489,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881489,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":6,"name":"t1_mll4vhc","id":"mll4vhc","parent_id":"t1_mll4ikz","depth":5,"children":["mll4vhc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4ikz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll4933","score":7,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's the new one they just released to replace R+.","edited":false,"author_flair_css_class":null,"name":"t1_mll4ikz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s the new one they just released to replace R+.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4ikz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881440,"author_flair_text":null,"collapsed":false,"created_utc":1743881440,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4933","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlanCarrOnline","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll3mru","score":6,"author_fullname":"t2_ry6xs35o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Command-a? \\n\\nI have command-R and Command-R+ but I dunno what Command-a is. You're embarrassing me now. Stopit.\\n\\n:P","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll4933","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Command-a? &lt;/p&gt;\\n\\n&lt;p&gt;I have command-R and Command-R+ but I dunno what Command-a is. You&amp;#39;re embarrassing me now. Stopit.&lt;/p&gt;\\n\\n&lt;p&gt;:P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4933/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881349,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":3,"name":"t1_mlodern","id":"mlodern","parent_id":"t1_mll3mru","depth":3,"children":["mlodern"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll3mru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll39xn","score":15,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I just watched him yapping and did 17x16. 109b ain't that bad but what's the benefit over mistral-large or command-a?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll3mru","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just watched him yapping and did 17x16. 109b ain&amp;#39;t that bad but what&amp;#39;s the benefit over mistral-large or command-a?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll3mru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881135,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881135,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mll39xn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlanCarrOnline","can_mod_post":false,"created_utc":1743881011,"send_replies":true,"parent_id":"t1_mll1lgd","score":39,"author_fullname":"t2_ry6xs35o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On their site it says:\\n\\n**17B active params x 16 experts, 109B total params**\\n\\nWell my 3090 can run 123B models, so... maybe? \\n\\nSlowly, with limited context, but maybe.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll39xn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On their site it says:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;17B active params x 16 experts, 109B total params&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Well my 3090 can run 123B models, so... maybe? &lt;/p&gt;\\n\\n&lt;p&gt;Slowly, with limited context, but maybe.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll39xn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881011,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"more","data":{"count":6,"name":"t1_mlnk205","id":"mlnk205","parent_id":"t1_mll1lgd","depth":1,"children":["mlnk205","mlmwobq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll1lgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1743880437,"send_replies":true,"parent_id":"t3_1jsampe","score":174,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So basically we can't run any of these? 17x16 is 272b.\\n\\nAnd 4xA6000 guy was complaining he overbought....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll1lgd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So basically we can&amp;#39;t run any of these? 17x16 is 272b.&lt;/p&gt;\\n\\n&lt;p&gt;And 4xA6000 guy was complaining he overbought....&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll1lgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880437,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":174}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo2whf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"berni8k","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlllhjk","score":3,"author_fullname":"t2_hfyjp","approved_by":null,"mod_note":null,"all_awardings":[],"body":"To be fair they never said \\"single consumer GPU\\" but yeah i also first understood it as \\"It will run on a single RTX 5090\\"\\n\\nActual size is 109B parameters. I can run that on my 4x RTX3090 rig but it will be quantized down to hell (especially if i want that big context window) and the tokens/s are likely not going to be huge (It gets \\\\~3 tok/s on this big models and large context). Tho this is a sparse MOE model so perhaps it can hit 10 tok/s on such a rig.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlo2whf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be fair they never said &amp;quot;single consumer GPU&amp;quot; but yeah i also first understood it as &amp;quot;It will run on a single RTX 5090&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Actual size is 109B parameters. I can run that on my 4x RTX3090 rig but it will be quantized down to hell (especially if i want that big context window) and the tokens/s are likely not going to be huge (It gets ~3 tok/s on this big models and large context). Tho this is a sparse MOE model so perhaps it can hit 10 tok/s on such a rig.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo2whf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743926107,"author_flair_text":null,"treatment_tags":[],"created_utc":1743926107,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_mlmq80j","id":"mlmq80j","parent_id":"t1_mlllhjk","depth":5,"children":["mlmq80j"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlllhjk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Severin_Suveren","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllc5cm","score":9,"author_fullname":"t2_vfpsd1c8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My two RTX 3090s are still holding up hope this is still possible somehow, someway!","edited":false,"author_flair_css_class":null,"name":"t1_mlllhjk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My two RTX 3090s are still holding up hope this is still possible somehow, someway!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlllhjk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743887195,"author_flair_text":null,"collapsed":false,"created_utc":1743887195,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mllc5cm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllay06","score":30,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;I thought this comment was joking at first glance\\n\\n[Let's see](https://www.runpod.io/pricing): $2.59 per hour \\\\* 8 hours per working day \\\\* 20 working days per month = $415 per month. Could be affordable if this model let you earn more than $415 per month.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllc5cm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I thought this comment was joking at first glance&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.runpod.io/pricing\\"&gt;Let&amp;#39;s see&lt;/a&gt;: $2.59 per hour * 8 hours per working day * 20 working days per month = $415 per month. Could be affordable if this model let you earn more than $415 per month.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllc5cm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884052,"author_flair_text":null,"treatment_tags":[],"created_utc":1743884052,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}}],"before":null}},"user_reports":[],"saved":false,"id":"mllay06","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OnurCetinkaya","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll89ho","score":69,"author_fullname":"t2_n3tl8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I thought this comment was joking at first glance, then click on the link and yeah, that was not a joke lol.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllay06","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought this comment was joking at first glance, then click on the link and yeah, that was not a joke lol.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllay06/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883650,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883650,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlo1lez","id":"mlo1lez","parent_id":"t1_mllfba9","depth":3,"children":["mlo1lez"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllfba9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nmkd","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll89ho","score":11,"author_fullname":"t2_rg6rx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"IQ2_XXS it is...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllfba9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IQ2_XXS it is...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllfba9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885116,"author_flair_text":null,"treatment_tags":[],"created_utc":1743885116,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln9klz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"send_replies":true,"parent_id":"t1_mln86ks","score":4,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Hopefully they've got a good deal on hourly rates to train it...\\n\\nhttps://preview.redd.it/6sbi48dmw4te1.png?width=318&amp;format=png&amp;auto=webp&amp;s=cc15566b186fd4ef951ce2539938e5733cc11e37\\n\\nThe main challenge isn't just training the model, it's making absolutely sure someone flips the 'off' switch when it's done, especially before a long weekend. Otherwise, that's one hell of an electric bill for an idle datacenter.","edited":1743911210,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln9klz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Hopefully they&amp;#39;ve got a good deal on hourly rates to train it...&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/6sbi48dmw4te1.png?width=318&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc15566b186fd4ef951ce2539938e5733cc11e37\\"&gt;https://preview.redd.it/6sbi48dmw4te1.png?width=318&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc15566b186fd4ef951ce2539938e5733cc11e37&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The main challenge isn&amp;#39;t just training the model, it&amp;#39;s making absolutely sure someone flips the &amp;#39;off&amp;#39; switch when it&amp;#39;s done, especially before a long weekend. Otherwise, that&amp;#39;s one hell of an electric bill for an idle datacenter.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln9klz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743910539,"media_metadata":{"6sbi48dmw4te1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":54,"x":108,"u":"https://preview.redd.it/6sbi48dmw4te1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=79df1c5808471777abc47ac01e0bc47d1aff062e"},{"y":108,"x":216,"u":"https://preview.redd.it/6sbi48dmw4te1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=647ab696f3fcba2ea6621330014e3f8c4b70a403"}],"s":{"y":159,"x":318,"u":"https://preview.redd.it/6sbi48dmw4te1.png?width=318&amp;format=png&amp;auto=webp&amp;s=cc15566b186fd4ef951ce2539938e5733cc11e37"},"id":"6sbi48dmw4te1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1743910539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mln86ks","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"renrutal","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll89ho","score":5,"author_fullname":"t2_6nt9z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md#hardware-and-software\\n\\n&gt; Training Energy Use: Model pre-training utilized a cumulative of 7.38M GPU hours of computation on H100-80GB (TDP of 700W) type hardware\\n\\n5M GPU hours spent training Llama 4 Scout, 2.38M on Llama 4 Maverick.\\n\\nHopefully they've got a good deal on hourly rates to train it...\\n\\n\\n(edit: I meant to reply something else. Oh well, the data is there.)","edited":1743910533,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mln86ks","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md#hardware-and-software\\"&gt;https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md#hardware-and-software&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Training Energy Use: Model pre-training utilized a cumulative of 7.38M GPU hours of computation on H100-80GB (TDP of 700W) type hardware&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;5M GPU hours spent training Llama 4 Scout, 2.38M on Llama 4 Maverick.&lt;/p&gt;\\n\\n&lt;p&gt;Hopefully they&amp;#39;ve got a good deal on hourly rates to train it...&lt;/p&gt;\\n\\n&lt;p&gt;(edit: I meant to reply something else. Oh well, the data is there.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln86ks/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909914,"author_flair_text":null,"treatment_tags":[],"created_utc":1743909914,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_mlmz07x","id":"mlmz07x","parent_id":"t1_mll89ho","depth":2,"children":["mlmz07x"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll89ho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evolution31415","can_mod_post":false,"created_utc":1743882744,"send_replies":true,"parent_id":"t1_mll36ci","score":133,"author_fullname":"t2_1oih32c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;On a single GPU?\\n\\n[Yes](https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/): *\\\\*\\\\*Single GPU inference using an INT4-quantized version of Llama 4 Scout on 1xH100 GPU*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll89ho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;On a single GPU?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.llama.com/docs/model-cards-and-prompt-formats/llama4_omni/\\"&gt;Yes&lt;/a&gt;: &lt;em&gt;\\\\&lt;/em&gt;*Single GPU inference using an INT4-quantized version of Llama 4 Scout on 1xH100 GPU*&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll89ho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882744,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":133}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":108,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllf520","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Recoil42","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll4yo5","score":23,"author_fullname":"t2_2kndo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Dang, I was hoping to run this on my Voodoo 3DFX.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllf520","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dang, I was hoping to run this on my Voodoo 3DFX.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllf520/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885058,"author_flair_text":null,"treatment_tags":[],"created_utc":1743885058,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4yo5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll36ci","score":108,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746982167,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4yo5/","num_reports":null,"locked":false,"name":"t1_mll4yo5","created":1743881594,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743881594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":8,"name":"t1_mlouwsy","id":"mlouwsy","parent_id":"t1_mll96f4","depth":3,"children":["mlouwsy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll96f4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xandrmoro","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll7jaf","score":9,"author_fullname":"t2_i13ds","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which is not that horrible, actually. It should allow you like 13-14 t/s at q8 of ~45B model performance.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll96f4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which is not that horrible, actually. It should allow you like 13-14 t/s at q8 of ~45B model performance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll96f4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883056,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mll7jaf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dax580","can_mod_post":false,"created_utc":1743882494,"send_replies":true,"parent_id":"t1_mll36ci","score":16,"author_fullname":"t2_4xhzc5ek","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean, it kinda is the case, the Radeon RX 8060S is around an RTX 3060 in performance, and you can have it with 128GB of “VRAM” if you don’t know what I’m talking about, the GPU (integrated) of the “insert stupid AMD AI name” HX 395+, the cheapest and IMO best way to get one is the Framework Desktop, around $2K with case $1600 just motherboard with SoC and RAM.\\n\\nI know it uses standard RAM (unfortunately the SoC made a must it being soldered), but being very fast and a Quad Channel config it has 256GB/s of bandwidth to work with.\\n\\nI mean the guy said it can run on one GPU, didn’t say in every one GPU xd\\n\\nKinda unfortunate we don’t have cheap ways to have a lot of high speed enough memory.\\nI think running LLMs will became much more easier with DDR6, even if we are still trapped in consumer platforms in Dual Channel, would be possible to get them in  16,000mhz modules which would give 256GB over just 128 bit bus, BUT it seems DDR6 will have more bits per channel so Dual Channel could become 192 or 256 bit bus","edited":1743883344,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7jaf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, it kinda is the case, the Radeon RX 8060S is around an RTX 3060 in performance, and you can have it with 128GB of “VRAM” if you don’t know what I’m talking about, the GPU (integrated) of the “insert stupid AMD AI name” HX 395+, the cheapest and IMO best way to get one is the Framework Desktop, around $2K with case $1600 just motherboard with SoC and RAM.&lt;/p&gt;\\n\\n&lt;p&gt;I know it uses standard RAM (unfortunately the SoC made a must it being soldered), but being very fast and a Quad Channel config it has 256GB/s of bandwidth to work with.&lt;/p&gt;\\n\\n&lt;p&gt;I mean the guy said it can run on one GPU, didn’t say in every one GPU xd&lt;/p&gt;\\n\\n&lt;p&gt;Kinda unfortunate we don’t have cheap ways to have a lot of high speed enough memory.\\nI think running LLMs will became much more easier with DDR6, even if we are still trapped in consumer platforms in Dual Channel, would be possible to get them in  16,000mhz modules which would give 256GB over just 128 bit bus, BUT it seems DDR6 will have more bits per channel so Dual Channel could become 192 or 256 bit bus&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7jaf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882494,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll51im","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"joninco","can_mod_post":false,"created_utc":1743881622,"send_replies":true,"parent_id":"t1_mll36ci","score":22,"author_fullname":"t2_8e8y0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On a single gpu.... used to login to your massive cluster.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll51im","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On a single gpu.... used to login to your massive cluster.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll51im/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881622,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll7nx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Charuru","can_mod_post":false,"created_utc":1743882538,"send_replies":true,"parent_id":"t1_mll36ci","score":5,"author_fullname":"t2_4kcht","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fits on a B300 I guess.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7nx4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fits on a B300 I guess.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7nx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882538,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllblti","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"knoodrake","can_mod_post":false,"created_utc":1743883870,"send_replies":true,"parent_id":"t1_mll36ci","score":2,"author_fullname":"t2_ib0a6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"on a single gpu\\" ( with 100% of layers and whatnot offloaded )","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllblti","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;on a single gpu&amp;quot; ( with 100% of layers and whatnot offloaded )&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllblti/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883870,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":7,"name":"t1_mllcwxj","id":"mllcwxj","parent_id":"t1_mll36ci","depth":1,"children":["mllcwxj","mlmrx18","mlo1k98"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll36ci","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1743880976,"send_replies":true,"parent_id":"t3_1jsampe","score":196,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"On  a single gpu\\"? On a single GPU means on on a single 3060, not on a single Cerebras slate.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll36ci","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;On  a single gpu&amp;quot;? On a single GPU means on on a single 3060, not on a single Cerebras slate.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll36ci/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880976,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":196}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll8r09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mpasila","can_mod_post":false,"created_utc":1743882910,"send_replies":true,"parent_id":"t3_1jsampe","score":18,"author_fullname":"t2_lhhagpdw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"welp I hope Mistral will finally make an update to Nemo a model I can actually run on a single GPU.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8r09","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;welp I hope Mistral will finally make an update to Nemo a model I can actually run on a single GPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8r09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882910,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":112,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlnv7dc","id":"mlnv7dc","parent_id":"t1_mlms85r","depth":3,"children":["mlnv7dc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlms85r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zyansheep","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlld7kb","score":14,"author_fullname":"t2_e757sg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"1-bit quant when...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlms85r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1-bit quant when...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlms85r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743903234,"author_flair_text":null,"treatment_tags":[],"created_utc":1743903234,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"mlld7kb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"power97992","can_mod_post":false,"created_utc":1743884411,"send_replies":true,"parent_id":"t1_mll1vxg","score":26,"author_fullname":"t2_64yf00b9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We need 4  and 5 bit quants lol.  Even the 109b scout model is too big, we need a 16b and 32 b model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlld7kb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need 4  and 5 bit quants lol.  Even the 109b scout model is too big, we need a 16b and 32 b model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlld7kb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884411,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":8,"name":"t1_mlo1why","id":"mlo1why","parent_id":"t1_mln4xac","depth":4,"children":["mlo1why","mln6cnw"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mln4xac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"altoidsjedi","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmnkk1","score":19,"author_fullname":"t2_6f7v3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"**The short(ish) version is this:**\\nIf a MoE model has **N** number of total parameters, of which only **K** are active per each forward pass (each token prediction), then:\\n- The model needs to enough memory to store all N parameters in memory, meaning you likely need more RAM than you would for a typical dense model. \\n- The model only needs to send data worth K number of parameters from the memory to CPU and back per each forward pass. \\n\\nSo if I fit something like Mistral Large (123 billion parameters) in INT-4 on my CPU RAM, and run it on CPU, it will have the potential knowledge/intelligence of a 123B parameter model, but it will run as SLOW as a 123b parameter model does on CPU, becuase of the extreme amount of data that needs to transfer between the (relatively narrow) data lanes between the CPU RAM and the CPU. \\n\\nBut for a model like Llama 4 Scout, where there are 109B total parameters, the model has the potential to be able to be as knowledge an intelligent as any other model within the 100B parameter size (assuming good training data and training practices).\\n\\nBUT, since it only uses 17B parameters per each forward pass, it can roughly run as fast as any dense 15-20B parameter LLM. And frankly with a decent CPU with AVX-512 support and DDR5 memory, you can get pretty decent performance as 17B parameter is relatively easy for a modern CPU with decent memory bandwidth to handle. \\n\\n--- \\n---\\n\\n**The long version (which im copying from another comment I made elsewhere) is:**\\nWith your typical transformer language model, a very simplified sketch is that the model is divided into layers/blocks, where each layer/block is comprised of some configuration of attention mechanisms, normalization, and a Feed Forward Neural Network (FFNN).\\n\\nLet’s say a simple “dense” model, like your typical 70B parameter model, has around 80–100 layers (I’m pulling that number out of my ass — I don’t recall the exact number, but it’s ballpark). In each of those layers, you’ll have the intermediate vector representations of your token context window processed by that layer, and the newly processed representation will get passed along to the next layer. So it’s (Attention -&gt; Normalization -&gt; FFNN) x N layers, until the final layer produces the output logits for token generation.\\n\\nNow the key difference in a MoE model is usually in the FFNN portion of each layer. Rather than having one FFNN per transformer block, it has **n** FFNNs — where **n** is the number of “experts.” These experts are fully separate sets of weights (i.e. separate parameter matrices), not just different activations.\\n\\nLet’s say there are 16 experts per layer. What happens is: before the FFNN is applied, a routing mechanism (like a learned gating function) looks at the token representation and decides which one (or two) of the 16 experts to use. So in practice, only a small subset of the available experts are active in any given forward pass — often just one or two — **but all 16 experts still live in memory**.\\n\\nSo no, you don’t scale up your model parameters as simply as 70B × 16. Instead, it’s something like:  \\n**(total params in non-FFNN parts) + (FFNN params × num_experts).**\\nAnd that total gives you something like 400B+ total parameters, even if only ~17B of them are active on any given token.\\n\\nThe upside of this architecture is that you can scale total capacity without scaling inference-time compute as much. The model can learn and represent more patterns, knowledge, and abstractions, which leads to better generalization and emergent abilities. The downside is that **you still need enough RAM/VRAM to hold all those experts in memory**, even the ones not being used during any specific forward pass.\\n\\nBut then the *other* upside is that because only a small number of experts are active per token (e.g., 1 or 2 per layer), the actual number of parameters involved in compute per forward pass is much lower — again, around 17B. That makes for a lower memory bandwidth requirement between RAM/VRAM and CPU/GPU — which is often the bottleneck in inference, especially on CPUs.\\n\\nSo you get more intelligence, and you get it to generate faster — but you need enough memory to hold the whole model. That makes MoE models a good fit for setups with **lots of RAM** but limited bandwidth or VRAM — like high-end CPU inference.\\n\\nFor example, I’m planning to run LLaMA 4 Scout on my desktop — Ryzen 9600X, 96GB of DDR5-6400 RAM — using an int4 quantized model that takes up somewhere between 55–60GB of RAM (not counting whatever’s needed for the context window). But instead of running as slow as a dense model with a similar total parameter count — like Mistral Large 2411 — it should run roughly as fast as a dense ~17B model.","edited":1743910830,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln4xac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;The short(ish) version is this:&lt;/strong&gt;\\nIf a MoE model has &lt;strong&gt;N&lt;/strong&gt; number of total parameters, of which only &lt;strong&gt;K&lt;/strong&gt; are active per each forward pass (each token prediction), then:\\n- The model needs to enough memory to store all N parameters in memory, meaning you likely need more RAM than you would for a typical dense model. \\n- The model only needs to send data worth K number of parameters from the memory to CPU and back per each forward pass. &lt;/p&gt;\\n\\n&lt;p&gt;So if I fit something like Mistral Large (123 billion parameters) in INT-4 on my CPU RAM, and run it on CPU, it will have the potential knowledge/intelligence of a 123B parameter model, but it will run as SLOW as a 123b parameter model does on CPU, becuase of the extreme amount of data that needs to transfer between the (relatively narrow) data lanes between the CPU RAM and the CPU. &lt;/p&gt;\\n\\n&lt;p&gt;But for a model like Llama 4 Scout, where there are 109B total parameters, the model has the potential to be able to be as knowledge an intelligent as any other model within the 100B parameter size (assuming good training data and training practices).&lt;/p&gt;\\n\\n&lt;p&gt;BUT, since it only uses 17B parameters per each forward pass, it can roughly run as fast as any dense 15-20B parameter LLM. And frankly with a decent CPU with AVX-512 support and DDR5 memory, you can get pretty decent performance as 17B parameter is relatively easy for a modern CPU with decent memory bandwidth to handle. &lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;&lt;strong&gt;The long version (which im copying from another comment I made elsewhere) is:&lt;/strong&gt;\\nWith your typical transformer language model, a very simplified sketch is that the model is divided into layers/blocks, where each layer/block is comprised of some configuration of attention mechanisms, normalization, and a Feed Forward Neural Network (FFNN).&lt;/p&gt;\\n\\n&lt;p&gt;Let’s say a simple “dense” model, like your typical 70B parameter model, has around 80–100 layers (I’m pulling that number out of my ass — I don’t recall the exact number, but it’s ballpark). In each of those layers, you’ll have the intermediate vector representations of your token context window processed by that layer, and the newly processed representation will get passed along to the next layer. So it’s (Attention -&amp;gt; Normalization -&amp;gt; FFNN) x N layers, until the final layer produces the output logits for token generation.&lt;/p&gt;\\n\\n&lt;p&gt;Now the key difference in a MoE model is usually in the FFNN portion of each layer. Rather than having one FFNN per transformer block, it has &lt;strong&gt;n&lt;/strong&gt; FFNNs — where &lt;strong&gt;n&lt;/strong&gt; is the number of “experts.” These experts are fully separate sets of weights (i.e. separate parameter matrices), not just different activations.&lt;/p&gt;\\n\\n&lt;p&gt;Let’s say there are 16 experts per layer. What happens is: before the FFNN is applied, a routing mechanism (like a learned gating function) looks at the token representation and decides which one (or two) of the 16 experts to use. So in practice, only a small subset of the available experts are active in any given forward pass — often just one or two — &lt;strong&gt;but all 16 experts still live in memory&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;So no, you don’t scale up your model parameters as simply as 70B × 16. Instead, it’s something like:  \\n&lt;strong&gt;(total params in non-FFNN parts) + (FFNN params × num_experts).&lt;/strong&gt;\\nAnd that total gives you something like 400B+ total parameters, even if only ~17B of them are active on any given token.&lt;/p&gt;\\n\\n&lt;p&gt;The upside of this architecture is that you can scale total capacity without scaling inference-time compute as much. The model can learn and represent more patterns, knowledge, and abstractions, which leads to better generalization and emergent abilities. The downside is that &lt;strong&gt;you still need enough RAM/VRAM to hold all those experts in memory&lt;/strong&gt;, even the ones not being used during any specific forward pass.&lt;/p&gt;\\n\\n&lt;p&gt;But then the &lt;em&gt;other&lt;/em&gt; upside is that because only a small number of experts are active per token (e.g., 1 or 2 per layer), the actual number of parameters involved in compute per forward pass is much lower — again, around 17B. That makes for a lower memory bandwidth requirement between RAM/VRAM and CPU/GPU — which is often the bottleneck in inference, especially on CPUs.&lt;/p&gt;\\n\\n&lt;p&gt;So you get more intelligence, and you get it to generate faster — but you need enough memory to hold the whole model. That makes MoE models a good fit for setups with &lt;strong&gt;lots of RAM&lt;/strong&gt; but limited bandwidth or VRAM — like high-end CPU inference.&lt;/p&gt;\\n\\n&lt;p&gt;For example, I’m planning to run LLaMA 4 Scout on my desktop — Ryzen 9600X, 96GB of DDR5-6400 RAM — using an int4 quantized model that takes up somewhere between 55–60GB of RAM (not counting whatever’s needed for the context window). But instead of running as slow as a dense model with a similar total parameter count — like Mistral Large 2411 — it should run roughly as fast as a dense ~17B model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln4xac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743908477,"author_flair_text":null,"treatment_tags":[],"created_utc":1743908477,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmnkk1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CesarBR_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmhduc","score":4,"author_fullname":"t2_w8myga52l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you elaborate a bit more?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlmnkk1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you elaborate a bit more?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmnkk1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743901358,"author_flair_text":null,"treatment_tags":[],"created_utc":1743901358,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmhduc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"altoidsjedi","can_mod_post":false,"created_utc":1743898953,"send_replies":true,"parent_id":"t1_mll1vxg","score":18,"author_fullname":"t2_6f7v3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On the contrary, I would absolutely like a INT4 GGUF of Scout! \\n\\nBetween my 3x 3070's (24gb VRAM total), 96GB of DDR5-6400, and an entry level 9600x Zen5 CPU with AVX-enabled llama.cpp, I'm pretty sure I've got enough to run a 4-bit quant just fine. \\n\\nThe great thing about MoE's is that if you have enough CPU RAM (which is relatively cheap compare to GPU VRAM), the small number of active parameters can be handled by a rig with decent enough CPU and RAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmhduc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On the contrary, I would absolutely like a INT4 GGUF of Scout! &lt;/p&gt;\\n\\n&lt;p&gt;Between my 3x 3070&amp;#39;s (24gb VRAM total), 96GB of DDR5-6400, and an entry level 9600x Zen5 CPU with AVX-enabled llama.cpp, I&amp;#39;m pretty sure I&amp;#39;ve got enough to run a 4-bit quant just fine. &lt;/p&gt;\\n\\n&lt;p&gt;The great thing about MoE&amp;#39;s is that if you have enough CPU RAM (which is relatively cheap compare to GPU VRAM), the small number of active parameters can be handled by a rig with decent enough CPU and RAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmhduc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743898953,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmus2g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BumbleSlob","can_mod_post":false,"created_utc":1743904259,"send_replies":true,"parent_id":"t1_mll1vxg","score":7,"author_fullname":"t2_1j7fhlcqkp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"“I’m tired, boss.”","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmus2g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;“I’m tired, boss.”&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmus2g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743904259,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":2,"name":"t1_mlpelc0","id":"mlpelc0","parent_id":"t1_mll1vxg","depth":1,"children":["mlpelc0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll1vxg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jsampe","score":112,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll1vxg/","num_reports":null,"locked":false,"name":"t1_mll1vxg","created":1743880535,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743880535,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mlol8dk","id":"mlol8dk","parent_id":"t1_mllx93k","depth":2,"children":["mlol8dk"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllx93k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dax580","can_mod_post":false,"created_utc":1743891423,"send_replies":true,"parent_id":"t1_mll9nle","score":7,"author_fullname":"t2_4xhzc5ek","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or your $2K 8060S device like the Framework Desktop","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllx93k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or your $2K 8060S device like the Framework Desktop&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllx93k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743891423,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9nle","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mobile_Tart_1016","can_mod_post":false,"created_utc":1743883215,"send_replies":true,"parent_id":"t3_1jsampe","score":18,"author_fullname":"t2_9pnhbbia3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"On your single B200*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9nle","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On your single B200*&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9nle/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883215,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln68lv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Relevant-Ad9432","can_mod_post":false,"send_replies":true,"parent_id":"t1_mln1j3w","score":6,"author_fullname":"t2_m3psgpkb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"quite a slow learner tbh /s","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mln68lv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;quite a slow learner tbh /s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln68lv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909051,"author_flair_text":null,"treatment_tags":[],"created_utc":1743909051,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mln1j3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"some_user_2021","can_mod_post":false,"created_utc":1743907025,"send_replies":true,"parent_id":"t1_mll2pri","score":23,"author_fullname":"t2_cmfeo4yq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The more of your data he gathered. The more he understood what it meant to be human.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln1j3w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The more of your data he gathered. The more he understood what it meant to be human.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln1j3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743907025,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"more","data":{"count":1,"name":"t1_mll8w2w","id":"mll8w2w","parent_id":"t1_mll2pri","depth":1,"children":["mll8w2w"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll2pri","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"garnered_wisdom","can_mod_post":false,"created_utc":1743880819,"send_replies":true,"parent_id":"t3_1jsampe","score":71,"author_fullname":"t2_d5s08xmj4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Damn, advancements in AI have got Zuck sounding more human than ever.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll2pri","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn, advancements in AI have got Zuck sounding more human than ever.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll2pri/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880819,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":71}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mln00lh","id":"mln00lh","parent_id":"t1_mlmgskd","depth":1,"children":["mln00lh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmgskd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cnydox","can_mod_post":false,"created_utc":1743898725,"send_replies":true,"parent_id":"t3_1jsampe","score":14,"author_fullname":"t2_i8cfjvg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama 5 will need 2 data centers to run it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmgskd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 5 will need 2 data centers to run it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmgskd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743898725,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll9ua0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_raydeStar","can_mod_post":false,"created_utc":1743883278,"send_replies":true,"parent_id":"t1_mll41i5","score":27,"author_fullname":"t2_7g79z1vy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, not even one.  way to nip my excitement in the bud","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9ua0","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, not even one.  way to nip my excitement in the bud&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9ua0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883278,"author_flair_text":"Llama 3.1","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_mlp1t6o","id":"mlp1t6o","parent_id":"t1_mlmj48w","depth":4,"children":["mlp1t6o","mlnxzrm","mlp1dia"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmj48w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"altoidsjedi","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlli7ko","score":18,"author_fullname":"t2_6f7v3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've run Mistral Large (128b dense model) on 96gb of DDR5-6400, CPU only, at roughly 1-2tokens per second. \\n\\nLlama 4 Maverick has fever parameters and is sparse / MoE. 17B active parameters makes it actually QUITE viable to run on an enthusiast CPU-based system. \\n\\nWill report back on how it's running on my system when there are INT-4 quants available. Predicting something around the 4 to 8 tokens per second range. \\n\\nSpecs are: \\n-Ryzen 9600x \\n- 2x 48GB DDR5-6400\\n- 3x RTX 3070 8gb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmj48w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve run Mistral Large (128b dense model) on 96gb of DDR5-6400, CPU only, at roughly 1-2tokens per second. &lt;/p&gt;\\n\\n&lt;p&gt;Llama 4 Maverick has fever parameters and is sparse / MoE. 17B active parameters makes it actually QUITE viable to run on an enthusiast CPU-based system. &lt;/p&gt;\\n\\n&lt;p&gt;Will report back on how it&amp;#39;s running on my system when there are INT-4 quants available. Predicting something around the 4 to 8 tokens per second range. &lt;/p&gt;\\n\\n&lt;p&gt;Specs are: \\n-Ryzen 9600x \\n- 2x 48GB DDR5-6400\\n- 3x RTX 3070 8gb&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmj48w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743899625,"author_flair_text":null,"treatment_tags":[],"created_utc":1743899625,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mln7w57","id":"mln7w57","parent_id":"t1_mlmwlgj","depth":5,"children":["mln7w57","mlna18f"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmwlgj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PavelPivovarov","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlmn7b8","score":4,"author_fullname":"t2_7ea11vu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I still wish they wouldn't abandon small LLMs (&lt;14b) altogether. That's a sad move and I really hope Qwen3 will get us GPU-poor folks covered.","edited":false,"author_flair_css_class":null,"name":"t1_mlmwlgj","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I still wish they wouldn&amp;#39;t abandon small LLMs (&amp;lt;14b) altogether. That&amp;#39;s a sad move and I really hope Qwen3 will get us GPU-poor folks covered.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsampe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmwlgj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743904985,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1743904985,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmn7b8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noiserr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlli7ko","score":6,"author_fullname":"t2_2khn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's MoE though so you could run it on CPU/Mac/Strix Halo.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmn7b8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s MoE though so you could run it on CPU/Mac/Strix Halo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmn7b8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743901211,"author_flair_text":null,"treatment_tags":[],"created_utc":1743901211,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_mllp4rq","id":"mllp4rq","parent_id":"t1_mlli7ko","depth":3,"children":["mllp4rq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlli7ko","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PavelPivovarov","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlldb5x","score":19,"author_fullname":"t2_7ea11vu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Scout is 109b model. As per llama site require 1xH100 at Q4. So no, nothing enthusiasts grade this time.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlli7ko","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Scout is 109b model. As per llama site require 1xH100 at Q4. So no, nothing enthusiasts grade this time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlli7ko/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743886082,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1743886082,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}}],"before":null}},"user_reports":[],"saved":false,"id":"mlldb5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1743884445,"send_replies":true,"parent_id":"t1_mll41i5","score":15,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Scout yes, the rest probably not without crawling or tripping the circuit breaker.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlldb5x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Scout yes, the rest probably not without crawling or tripping the circuit breaker.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlldb5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884445,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"more","data":{"count":3,"name":"t1_mlrrkk0","id":"mlrrkk0","parent_id":"t1_mll41i5","depth":1,"children":["mlrrkk0","mlljiqp","mlplcbv"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll41i5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Naitsirc98C","can_mod_post":false,"created_utc":1743881277,"send_replies":true,"parent_id":"t3_1jsampe","score":69,"author_fullname":"t2_1xtxv79m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So no chance to run this with consumer GPU right? Dissapointed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll41i5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So no chance to run this with consumer GPU right? Dissapointed.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll41i5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881277,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mlqls4i","id":"mlqls4i","parent_id":"t1_mlqju43","depth":2,"children":["mlqls4i"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqju43","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ElementNumber6","can_mod_post":false,"created_utc":1743963650,"send_replies":true,"parent_id":"t1_mll8nog","score":5,"author_fullname":"t2_qzoa22cr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"These sorts of advancements are the life blood of enthusiast communities.  If they didn't happen we wouldn't see hardware and software race to keep up.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqju43","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These sorts of advancements are the life blood of enthusiast communities.  If they didn&amp;#39;t happen we wouldn&amp;#39;t see hardware and software race to keep up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlqju43/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963650,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mll8nog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttbap","can_mod_post":false,"created_utc":1743882879,"send_replies":true,"parent_id":"t3_1jsampe","score":33,"author_fullname":"t2_tly4brec","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wtf, Is NVIDIA paying him create big ass models so they can sell even more for inference ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8nog","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wtf, Is NVIDIA paying him create big ass models so they can sell even more for inference ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8nog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882879,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll231c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thetaFAANG","can_mod_post":false,"created_utc":1743880604,"send_replies":true,"parent_id":"t3_1jsampe","score":27,"author_fullname":"t2_da5i8ajs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this aint a scene, its a god damn arms race 🎵","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll231c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this aint a scene, its a god damn arms race 🎵&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll231c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll7tco","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"power97992","can_mod_post":false,"created_utc":1743882590,"send_replies":true,"parent_id":"t3_1jsampe","score":9,"author_fullname":"t2_64yf00b9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m waiting to See the reasoning model!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7tco","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m waiting to See the reasoning model!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7tco/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882590,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll8kd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"alew3","can_mod_post":false,"created_utc":1743882848,"send_replies":true,"parent_id":"t3_1jsampe","score":7,"author_fullname":"t2_8bwjj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's already available on  Hugging Face, Databricks, Together AI, Ollama, and Snowflake","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8kd3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s already available on  Hugging Face, Databricks, Together AI, Ollama, and Snowflake&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8kd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882848,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo51fc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vinnifit","can_mod_post":false,"created_utc":1743927465,"send_replies":true,"parent_id":"t3_1jsampe","score":8,"author_fullname":"t2_ymb5k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://ai.meta.com/blog/llama-4-multimodal-intelligence/ :\\n\\n\\"It’s well-known that all leading LLMs have had issues with bias—specifically, they historically have leaned left when it comes to debated political and social topics. This is due to the types of training data available on the internet.\\"\\n\\nThis reminds me of that Colbert joke: \\"It's well known reality has a liberal bias.\\" :'-)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo51fc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://ai.meta.com/blog/llama-4-multimodal-intelligence/\\"&gt;https://ai.meta.com/blog/llama-4-multimodal-intelligence/&lt;/a&gt; :&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;It’s well-known that all leading LLMs have had issues with bias—specifically, they historically have leaned left when it comes to debated political and social topics. This is due to the types of training data available on the internet.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;This reminds me of that Colbert joke: &amp;quot;It&amp;#39;s well known reality has a liberal bias.&amp;quot; :&amp;#39;-)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo51fc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743927465,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mll8216","id":"mll8216","parent_id":"t1_mll28vh","depth":2,"children":["mll8216"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll28vh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mr-Barack-Obama","can_mod_post":false,"created_utc":1743880658,"send_replies":true,"parent_id":"t1_mll0o2u","score":40,"author_fullname":"t2_igdar","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"he said it’s not done training yet would they really put it on llmarena?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll28vh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;he said it’s not done training yet would they really put it on llmarena?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll28vh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880658,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mllkq3d","id":"mllkq3d","parent_id":"t1_mllj1w9","depth":2,"children":["mllkq3d"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllj1w9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Apprehensive-Ant7955","can_mod_post":false,"created_utc":1743886363,"send_replies":true,"parent_id":"t1_mll0o2u","score":11,"author_fullname":"t2_fkghk5075","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maverick is on llmarena, not behemoth","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllj1w9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maverick is on llmarena, not behemoth&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllj1w9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743886363,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mll0o2u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gzzhongqi","can_mod_post":false,"created_utc":1743880119,"send_replies":true,"parent_id":"t3_1jsampe","score":24,"author_fullname":"t2_jldf8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"2 trillion..... That is why that model is so slow in llmarena i guess","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll0o2u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2 trillion..... That is why that model is so slow in llmarena i guess&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll0o2u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880119,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll827a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Innomen","can_mod_post":false,"created_utc":1743882676,"send_replies":true,"parent_id":"t3_1jsampe","score":5,"author_fullname":"t2_36j0c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If this isn't bullshit... Man. I might have to push my timeline.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll827a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If this isn&amp;#39;t bullshit... Man. I might have to push my timeline.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll827a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882676,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":23,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mll75ze","id":"mll75ze","parent_id":"t1_mll5o6s","depth":4,"children":["mll75ze"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll5o6s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HauntingAd8395","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll4jfp","score":6,"author_fullname":"t2_17khmwh2r0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"oh, you are right;  \\nthe mixture of experts are the FFN, which are 2 linear transformations.\\n\\nthere are 3 linear transformation for qkv and 1 linear transformation to mix the embedding from concatenated heads;\\n\\nso that should be 10b left?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll5o6s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh, you are right;&lt;br/&gt;\\nthe mixture of experts are the FFN, which are 2 linear transformations.&lt;/p&gt;\\n\\n&lt;p&gt;there are 3 linear transformation for qkv and 1 linear transformation to mix the embedding from concatenated heads;&lt;/p&gt;\\n\\n&lt;p&gt;so that should be 10b left?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll5o6s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881844,"author_flair_text":null,"treatment_tags":[],"created_utc":1743881844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4jfp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1743881448,"send_replies":true,"parent_id":"t1_mll3a7f","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1743881796,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4jfp/","num_reports":null,"locked":false,"name":"t1_mll4jfp","created":1743881448,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mll3a7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HauntingAd8395","can_mod_post":false,"created_utc":1743881014,"send_replies":true,"parent_id":"t1_mll264h","score":11,"author_fullname":"t2_17khmwh2r0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It says 109B total params (sources: [Download Llama](https://www.llama.com/llama-downloads/))\\n\\nDoes this imply that some of their experts share parameters?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll3a7f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It says 109B total params (sources: &lt;a href=\\"https://www.llama.com/llama-downloads/\\"&gt;Download Llama&lt;/a&gt;)&lt;/p&gt;\\n\\n&lt;p&gt;Does this imply that some of their experts share parameters?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll3a7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881014,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllmz5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nixellion","can_mod_post":false,"send_replies":true,"parent_id":"t1_mllk369","score":3,"author_fullname":"t2_12fajr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That is not the kind of speed thats practical for any kind of work with llms. For testing and playing around maybe, but not for any work and definitely not for serving even on a small scale","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllmz5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That is not the kind of speed thats practical for any kind of work with llms. For testing and playing around maybe, but not for any work and definitely not for serving even on a small scale&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllmz5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743887719,"author_flair_text":null,"treatment_tags":[],"created_utc":1743887719,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mllk369","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlla5pg","score":5,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"With only 17B active, it should run on DDR5 even without GPU if you have the patience for 3-5 tok/sek. The more you offload, the better of course and prompt processing will be very slow.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllk369","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With only 17B active, it should run on DDR5 even without GPU if you have the patience for 3-5 tok/sek. The more you offload, the better of course and prompt processing will be very slow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllk369/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743886713,"author_flair_text":null,"treatment_tags":[],"created_utc":1743886713,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlla5pg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nixellion","can_mod_post":false,"created_utc":1743883385,"send_replies":true,"parent_id":"t1_mll264h","score":6,"author_fullname":"t2_12fajr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can probably run it on 2x24GB GPUs. Which is... doable, but like you have to be serious about using LLMs at home.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlla5pg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can probably run it on 2x24GB GPUs. Which is... doable, but like you have to be serious about using LLMs at home.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlla5pg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883385,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_mloem7x","id":"mloem7x","parent_id":"t1_mll264h","depth":1,"children":["mloem7x"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll264h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jsampe","score":23,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1743881996,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll264h/","num_reports":null,"locked":false,"name":"t1_mll264h","created":1743880632,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743880632,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"a8acc9bc-4792-11ee-b77d-c61a47557e59","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mln6kud","id":"mln6kud","parent_id":"t1_mlmhoq5","depth":2,"children":["mln6kud","mlo20v7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmhoq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"InsideYork","can_mod_post":false,"created_utc":1743899071,"send_replies":true,"parent_id":"t1_mllbbww","score":12,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why is it a problem? You can distill a small model but you can’t enlarge a small one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmhoq5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why is it a problem? You can distill a small model but you can’t enlarge a small one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmhoq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743899071,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"mllbbww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"henk717","can_mod_post":false,"created_utc":1743883778,"send_replies":true,"parent_id":"t3_1jsampe","score":26,"author_fullname":"t2_bx8b9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope this does not become a trend where small models are left out, had an issue with deepseek-r1 this week (it began requiring 350GB of vram extra but got reported as a speed regression) and debugging it cost $80 in compute rentals because no small variant was available with the same architecture. Llama4 isn't just out of reach for reasonable local LLM usage, its also going to make it expensive to properly support in all the hobby driven projects.\\n\\nIt doesn't have to be better than other smaller models if the architecture isn't optimized for that, but at least release something around the 12B size for developers to test support. There is no way you can do things like automatic CI testing or at home development if they are this heavy and have an odd performance downgrade.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllbbww","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"KoboldAI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope this does not become a trend where small models are left out, had an issue with deepseek-r1 this week (it began requiring 350GB of vram extra but got reported as a speed regression) and debugging it cost $80 in compute rentals because no small variant was available with the same architecture. Llama4 isn&amp;#39;t just out of reach for reasonable local LLM usage, its also going to make it expensive to properly support in all the hobby driven projects.&lt;/p&gt;\\n\\n&lt;p&gt;It doesn&amp;#39;t have to be better than other smaller models if the architecture isn&amp;#39;t optimized for that, but at least release something around the 12B size for developers to test support. There is no way you can do things like automatic CI testing or at home development if they are this heavy and have an odd performance downgrade.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllbbww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883778,"author_flair_text":"KoboldAI","treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#5a74cc","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mllerct","id":"mllerct","parent_id":"t1_mllcr7x","depth":3,"children":["mllerct"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllcr7x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"THE--GRINCH","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll8ltn","score":8,"author_fullname":"t2_jn1vgq5vl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hopefully it's as good as its size, the original gpt4 was also 2T~ and it propelled the next generation of models for a while.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mllcr7x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hopefully it&amp;#39;s as good as its size, the original gpt4 was also 2T~ and it propelled the next generation of models for a while.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcr7x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884258,"author_flair_text":null,"treatment_tags":[],"created_utc":1743884258,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":1,"name":"t1_mlmnn13","id":"mlmnn13","parent_id":"t1_mll8ltn","depth":2,"children":["mlmnn13"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll8ltn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"power97992","can_mod_post":false,"created_utc":1743882861,"send_replies":true,"parent_id":"t1_mll40vu","score":9,"author_fullname":"t2_64yf00b9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It will be super expensive to run, it is massive lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8ltn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will be super expensive to run, it is massive lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8ltn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882861,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mll40vu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cosmic__Guy","can_mod_post":false,"created_utc":1743881271,"send_replies":true,"parent_id":"t3_1jsampe","score":14,"author_fullname":"t2_7jwrh6amp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am more excited about llama4 Behemoth, I hope it doesn't turn out like GPT 4.5, it was also a massive model, But when comparing efficiency with respect to compute/price, it disappointed us all","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll40vu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am more excited about llama4 Behemoth, I hope it doesn&amp;#39;t turn out like GPT 4.5, it was also a massive model, But when comparing efficiency with respect to compute/price, it disappointed us all&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll40vu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743881271,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mlngzdo","id":"mlngzdo","parent_id":"t1_mlldbe8","depth":1,"children":["mlngzdo"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlldbe8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1743884447,"send_replies":true,"parent_id":"t3_1jsampe","score":9,"author_fullname":"t2_qhlcbiy3k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With 64GB RAM + 16GB VRAM, I can probably fit their smallest version, the 109b MoE, at Q4 quant. With only 17b parameters active, it should be pretty fast. If llama.cpp ever gets support that is, since this is multimodal.\\n\\nI do wish they had released smaller models though, between the 20b - 70b range.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlldbe8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With 64GB RAM + 16GB VRAM, I can probably fit their smallest version, the 109b MoE, at Q4 quant. With only 17b parameters active, it should be pretty fast. If llama.cpp ever gets support that is, since this is multimodal.&lt;/p&gt;\\n\\n&lt;p&gt;I do wish they had released smaller models though, between the 20b - 70b range.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlldbe8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884447,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mln9rc2","id":"mln9rc2","parent_id":"t1_mllakj1","depth":1,"children":["mln9rc2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllakj1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jsampe","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllakj1/","num_reports":null,"locked":false,"name":"t1_mllakj1","created":1743883525,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743883525,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllccgb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"THE--GRINCH","can_mod_post":false,"created_utc":1743884119,"send_replies":true,"parent_id":"t3_1jsampe","score":4,"author_fullname":"t2_jn1vgq5vl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"10M CONTEXT WINDOW?!?!??!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllccgb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;10M CONTEXT WINDOW?!?!??!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllccgb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884119,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll0n9m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"deathtoallparasites","can_mod_post":false,"created_utc":1743880111,"send_replies":true,"parent_id":"t1_mll00es","score":37,"author_fullname":"t2_kp99g3st","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"its open weights my guy!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll0n9m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;its open weights my guy!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll0n9m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880111,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln86jh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"joshred","can_mod_post":false,"created_utc":1743909914,"send_replies":true,"parent_id":"t1_mll00es","score":2,"author_fullname":"t2_3puwn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Open weights is not open source.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln86jh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Open weights is not open source.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln86jh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909914,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mll00es","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"neoneye2","can_mod_post":false,"created_utc":1743879895,"send_replies":true,"parent_id":"t3_1jsampe","score":24,"author_fullname":"t2_zijetf2n5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"These are big numbers. Thank you for making this open source.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll00es","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These are big numbers. Thank you for making this open source.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll00es/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743879895,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmmaep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mechanical_Number","can_mod_post":false,"created_utc":1743900851,"send_replies":true,"parent_id":"t3_1jsampe","score":7,"author_fullname":"t2_dz0pogql","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am sure that Zuckerberg knows the difference between open-source and open-weights, so I find his use of \\"open-source\\" here a bit disingenuous. A model like OLMo is open-source. A model like Llama is open-weights. Better than not-even-weights of course. :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmmaep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am sure that Zuckerberg knows the difference between open-source and open-weights, so I find his use of &amp;quot;open-source&amp;quot; here a bit disingenuous. A model like OLMo is open-source. A model like Llama is open-weights. Better than not-even-weights of course. :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmmaep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743900851,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mln5ho4","id":"mln5ho4","parent_id":"t1_mll7acg","depth":1,"children":["mln5ho4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll7acg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"created_utc":1743882407,"send_replies":true,"parent_id":"t3_1jsampe","score":8,"author_fullname":"t2_eerln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Somebody distill it down to 8x16? Please?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7acg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Somebody distill it down to 8x16? Please?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7acg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882407,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":8,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mll4f8l","id":"mll4f8l","parent_id":"t1_mll4ayy","depth":2,"children":["mll4f8l"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll4ayy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll2vrt","score":8,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746985105,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll4ayy/","num_reports":null,"locked":false,"name":"t1_mll4ayy","created":1743881367,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743881367,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mll2vrt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AlanCarrOnline","can_mod_post":false,"created_utc":1743880875,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_ry6xs35o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone math this for me? He says the smallest one runs on a single GPU. Is that one of them A40,000 things or whatever, or can an actual normal GPU ran any of this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll2vrt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone math this for me? He says the smallest one runs on a single GPU. Is that one of them A40,000 things or whatever, or can an actual normal GPU ran any of this?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll2vrt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880875,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll8vp2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ggone20","can_mod_post":false,"created_utc":1743882954,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_nxled","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Stay good out there!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll8vp2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Stay good out there!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll8vp2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882954,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllcppp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnticitizenPrime","can_mod_post":false,"created_utc":1743884244,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_66km3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dang, it's already up on OpenRouter.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllcppp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dang, it&amp;#39;s already up on OpenRouter.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcppp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884244,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllcxmm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cr0wburn","can_mod_post":false,"created_utc":1743884318,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_a2jrm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sounds good!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllcxmm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sounds good!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcxmm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884318,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllg0uh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Moravec_Paradox","can_mod_post":false,"created_utc":1743885352,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_rowuy64vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Scout is 17B x16 MoE for 109B total. \\n\\nIt can be run locally on some systems but it's not Llama 3.1 8B material. That model I like running locally even on my laptop and I am hoping they drop a small model that size after some of the bigger ones are released.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllg0uh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Scout is 17B x16 MoE for 109B total. &lt;/p&gt;\\n\\n&lt;p&gt;It can be run locally on some systems but it&amp;#39;s not Llama 3.1 8B material. That model I like running locally even on my laptop and I am hoping they drop a small model that size after some of the bigger ones are released.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllg0uh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743885352,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmwnn6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"levanovik_2002","can_mod_post":false,"created_utc":1743905010,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_xlr2rnsqz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"they went from user-based to enterprise-based","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmwnn6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they went from user-based to enterprise-based&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmwnn6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743905010,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln1hqh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"created_utc":1743907009,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_a2uzegb8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really, really, wish he would have released a 0.5B model as well to make that old joke from the missing 30b llama 2 models a reality.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln1hqh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really, really, wish he would have released a 0.5B model as well to make that old joke from the missing 30b llama 2 models a reality.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln1hqh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743907009,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo0lpg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anxcaptain","can_mod_post":false,"created_utc":1743924655,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_4ieo5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for the new model, lizard","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo0lpg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the new model, lizard&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo0lpg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743924655,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo17qd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hungry-Wealth-6132","can_mod_post":false,"created_utc":1743925045,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_rc3y9qnx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"He is one of the worst living people","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo17qd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He is one of the worst living people&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo17qd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743925045,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mloi0nv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpaceDynamite1","can_mod_post":false,"created_utc":1743935891,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_1eh2s1ue9n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"He tries so hard to be a totally genuine and authentic personality. \\n\\nTry harder, Mark. The more you try, the more unlikeable you become.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mloi0nv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He tries so hard to be a totally genuine and authentic personality. &lt;/p&gt;\\n\\n&lt;p&gt;Try harder, Mark. The more you try, the more unlikeable you become.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mloi0nv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743935891,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlorwx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MyMedsAreOOS","can_mod_post":false,"created_utc":1743941404,"send_replies":true,"parent_id":"t3_1jsampe","score":3,"author_fullname":"t2_qnfjlm1wh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's days like this I wish Filthy Frank was still around.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlorwx4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s days like this I wish Filthy Frank was still around.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlorwx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941404,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":8,"removal_reason":null,"link_id":"t3_1jsampe","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll2tyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jsampe","score":8,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Zuck trolling us with AGI","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Zuck trolling us with AGI&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll2tyk/","num_reports":null,"locked":false,"name":"t1_mll2tyk","created":1743880858,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743880858,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mllg8ei","id":"mllg8ei","parent_id":"t1_mlleuix","depth":1,"children":["mllg8ei"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlleuix","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NectarineDifferent67","can_mod_post":false,"created_utc":1743884961,"send_replies":true,"parent_id":"t3_1jsampe","score":6,"author_fullname":"t2_upiu4n71","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried Maverick, and it fails to remember (or ignore) something in the second chat. So.... I will go back to Claude.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlleuix","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried Maverick, and it fails to remember (or ignore) something in the second chat. So.... I will go back to Claude.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlleuix/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884961,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mllknr2","id":"mllknr2","parent_id":"t1_mllb48s","depth":1,"children":["mllknr2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mllb48s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Alkeryn","can_mod_post":false,"created_utc":1743883707,"send_replies":true,"parent_id":"t3_1jsampe","score":4,"author_fullname":"t2_xbcpo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Kek not multimodal","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllb48s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kek not multimodal&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllb48s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883707,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrryux","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PlateLive8645","can_mod_post":false,"created_utc":1743978147,"send_replies":true,"parent_id":"t1_mlldb61","score":2,"author_fullname":"t2_1734a7haui","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's most likely going to benefit researchers that will distill/fine tune it for them and make commercially viable products.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlrryux","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s most likely going to benefit researchers that will distill/fine tune it for them and make commercially viable products.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlrryux/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743978147,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlldb61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Roidberg69","can_mod_post":false,"created_utc":1743884445,"send_replies":true,"parent_id":"t3_1jsampe","score":4,"author_fullname":"t2_8dw7czso","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Damn, sounds like zuck is about to give away a 2 trillion parameter reasoning model away for free in 1-2 months. Wonder what thats going to do to the AI space. Im guessing you will need around 4-6 TB for that so 80-120k in 512gb mac studios would probably do the job right? Cant really use the cloud either because 40 -50 h100s will cost you 2k per day or half that for 4bit","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlldb61","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Damn, sounds like zuck is about to give away a 2 trillion parameter reasoning model away for free in 1-2 months. Wonder what thats going to do to the AI space. Im guessing you will need around 4-6 TB for that so 80-120k in 512gb mac studios would probably do the job right? Cant really use the cloud either because 40 -50 h100s will cost you 2k per day or half that for 4bit&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlldb61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884445,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmrmio","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Elite_Crew","can_mod_post":false,"created_utc":1743902994,"send_replies":true,"parent_id":"t3_1jsampe","score":4,"author_fullname":"t2_6z6tc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This version of Mark is the most human yet!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmrmio","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This version of Mark is the most human yet!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmrmio/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743902994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mllehfg","id":"mllehfg","parent_id":"t1_mlld2x8","depth":3,"children":["mllehfg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlld2x8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"noage","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll9o58","score":3,"author_fullname":"t2_5ao30","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There was some stuff about a 1.58bit quant of deepseek r1 being usable. This also being a MOE seems like there might be tricks out there for lower quants to be serviceable. Whether they would compare to just running gemma 3 27b at much higher quants... i have doubts since the benchmarks don't show they are starting off much higher.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlld2x8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There was some stuff about a 1.58bit quant of deepseek r1 being usable. This also being a MOE seems like there might be tricks out there for lower quants to be serviceable. Whether they would compare to just running gemma 3 27b at much higher quants... i have doubts since the benchmarks don&amp;#39;t show they are starting off much higher.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlld2x8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884368,"author_flair_text":null,"treatment_tags":[],"created_utc":1743884368,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":4,"name":"t1_mll9wjj","id":"mll9wjj","parent_id":"t1_mll9o58","depth":2,"children":["mll9wjj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9o58","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nixellion","can_mod_post":false,"created_utc":1743883220,"send_replies":true,"parent_id":"t1_mll6pie","score":8,"author_fullname":"t2_12fajr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sadly that's not entirely how that works. Llama 4 Scout is totalling at 109B parameters, so that's gonna be way more than 17GB RAM.\\n\\nIt will fit into 24GB at around 2-3 bit quant. You will need 2 24GB GPUs to run it at 4bit. Which is not terrible, but not a single consumer GPU for sure.\\n\\nEDIT: Correcton, 2-3 bit quants fit 70B models into 24GB. For 109 you'll have to use at least 48GB VRAM","edited":1743883435,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll9o58","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sadly that&amp;#39;s not entirely how that works. Llama 4 Scout is totalling at 109B parameters, so that&amp;#39;s gonna be way more than 17GB RAM.&lt;/p&gt;\\n\\n&lt;p&gt;It will fit into 24GB at around 2-3 bit quant. You will need 2 24GB GPUs to run it at 4bit. Which is not terrible, but not a single consumer GPU for sure.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Correcton, 2-3 bit quants fit 70B models into 24GB. For 109 you&amp;#39;ll have to use at least 48GB VRAM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9o58/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mllb8d4","id":"mllb8d4","parent_id":"t1_mlla263","depth":2,"children":["mllb8d4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlla263","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Xandrmoro","can_mod_post":false,"created_utc":1743883352,"send_replies":true,"parent_id":"t1_mll6pie","score":2,"author_fullname":"t2_i13ds","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is 109B, 17B per activation","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlla263","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is 109B, 17B per activation&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlla263/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883352,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_mllagx8","id":"mllagx8","parent_id":"t1_mll6pie","depth":1,"children":["mllagx8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll6pie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Proud_Fox_684","can_mod_post":false,"created_utc":1743882207,"send_replies":true,"parent_id":"t3_1jsampe","score":8,"author_fullname":"t2_4sn0z2l0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow! Really looking forward to this. More MoE models.\\n\\nLet's break it down:\\n\\n* **~~Llama 4 Scout~~**~~: 17 Billion parameters x 16 experts. At 8-bit precision 17 Billion parameters = 17 GB RAM. At 4-bit quantization ==&gt; 8,5 GB RAM. You could push it down further depending on the quantization type, such as GPTQ/AWQ. This is just for a rough calculation.~~\\n\\n**EDIT :::  It's 109B parameters total, but 17B parameters active per token. 16 experts.** \\n\\n**That means if you load the entire model onto your GPU at 4-bit, it's roughly 55 GB VRAM. Not considering intermediate activations which depend on context window, among other things. I suppose you could fit it on a H100. That's what he means by a single GPU?**","edited":1743884265,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll6pie","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow! Really looking forward to this. More MoE models.&lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s break it down:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;&lt;del&gt;Llama 4 Scout&lt;/del&gt;&lt;/strong&gt;&lt;del&gt;: 17 Billion parameters x 16 experts. At 8-bit precision 17 Billion parameters = 17 GB RAM. At 4-bit quantization ==&amp;gt; 8,5 GB RAM. You could push it down further depending on the quantization type, such as GPTQ/AWQ. This is just for a rough calculation.&lt;/del&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;EDIT :::  It&amp;#39;s 109B parameters total, but 17B parameters active per token. 16 experts.&lt;/strong&gt; &lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;That means if you load the entire model onto your GPU at 4-bit, it&amp;#39;s roughly 55 GB VRAM. Not considering intermediate activations which depend on context window, among other things. I suppose you could fit it on a H100. That&amp;#39;s what he means by a single GPU?&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll6pie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882207,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mlp80pf","id":"mlp80pf","parent_id":"t1_mlmq64p","depth":2,"children":["mlp80pf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlmq64p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Due-Memory-6957","can_mod_post":false,"created_utc":1743902405,"send_replies":true,"parent_id":"t1_mll12lw","score":20,"author_fullname":"t2_k8tos496","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The year 2025 of our lord Jesus Christ and people still think asking the models about themselves is a valid way to acquire knowledge?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmq64p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The year 2025 of our lord Jesus Christ and people still think asking the models about themselves is a valid way to acquire knowledge?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmq64p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743902405,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll7n4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"reza2kn","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll71qu","score":3,"author_fullname":"t2_3mgqd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that is how Meta researchers have been studying and publishing papers on","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll7n4a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that is how Meta researchers have been studying and publishing papers on&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7n4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882530,"author_flair_text":null,"treatment_tags":[],"created_utc":1743882530,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mllcfsy","id":"mllcfsy","parent_id":"t1_mll9l2c","depth":3,"children":["mllcfsy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll9l2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_mll71qu","score":2,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mll9l2c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/\\"&gt;https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll9l2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743883192,"author_flair_text":null,"treatment_tags":[],"created_utc":1743883192,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mll71qu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Recoil42","can_mod_post":false,"created_utc":1743882325,"send_replies":true,"parent_id":"t1_mll12lw","score":9,"author_fullname":"t2_2kndo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait, someone fill me in. How would you *use* latent spaces instead of tokenizing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll71qu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait, someone fill me in. How would you &lt;em&gt;use&lt;/em&gt; latent spaces instead of tokenizing?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll71qu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882325,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"more","data":{"count":8,"name":"t1_mlmx79g","id":"mlmx79g","parent_id":"t1_mll12lw","depth":1,"children":["mlmx79g","mll8rm4","mln6njh","mllibst"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mll12lw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"InsideYork","can_mod_post":false,"created_utc":1743880257,"send_replies":true,"parent_id":"t3_1jsampe","score":12,"author_fullname":"t2_12s3hn4y0b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it using byte latent transformer instead of thinking by tokenizing yet?\\n\\nI asked it\\n\\n&gt;\\tYou're really digging into the specifics. Yes, my architecture is based on a variant of the Byte-Level Latent Transformer, also known as a Byte-Pair Encoding (BPE) transformer.\\nByte-Level Latent Transformers are a type of transformer model that operates directly on raw bytes, rather than relying on pre-tokenized input. This approach allows for more flexible and efficient processing of text data, especially when dealing with out-of-vocabulary words or non-standard language.\\nThe Byte-Pair Encoding (BPE) algorithm is used to convert the input text into a sequence of subwords, which are then fed into the transformer model. This approach enables the model to capture complex patterns and relationships in language, even at the subword level.\\nSo, to answer your question, my architecture does indeed incorporate elements of Byte-Level Latent Transformers and BPE, which helps me to better understand and generate text.","edited":1743884481,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll12lw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it using byte latent transformer instead of thinking by tokenizing yet?&lt;/p&gt;\\n\\n&lt;p&gt;I asked it&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;You&amp;#39;re really digging into the specifics. Yes, my architecture is based on a variant of the Byte-Level Latent Transformer, also known as a Byte-Pair Encoding (BPE) transformer.\\nByte-Level Latent Transformers are a type of transformer model that operates directly on raw bytes, rather than relying on pre-tokenized input. This approach allows for more flexible and efficient processing of text data, especially when dealing with out-of-vocabulary words or non-standard language.\\nThe Byte-Pair Encoding (BPE) algorithm is used to convert the input text into a sequence of subwords, which are then fed into the transformer model. This approach enables the model to capture complex patterns and relationships in language, even at the subword level.\\nSo, to answer your question, my architecture does indeed incorporate elements of Byte-Level Latent Transformers and BPE, which helps me to better understand and generate text.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll12lw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743880257,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mll7o6i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_raydeStar","can_mod_post":false,"created_utc":1743882541,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_7g79z1vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Holy crap I was not expecting this.\\n\\naahhhhhhhhhh!!!!!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mll7o6i","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Holy crap I was not expecting this.&lt;/p&gt;\\n\\n&lt;p&gt;aahhhhhhhhhh!!!!!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mll7o6i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743882541,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmo65s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"noiserr","can_mod_post":false,"created_utc":1743901598,"send_replies":true,"parent_id":"t1_mllcryz","score":2,"author_fullname":"t2_2khn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The AI Max 395 128GB should be able to run the Scout model fine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmo65s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The AI Max 395 128GB should be able to run the Scout model fine.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsampe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmo65s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743901598,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mllcryz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rich_Artist_8327","can_mod_post":false,"created_utc":1743884265,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_1jk2ep8a52","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Could 128GB AMD Ryzen AI MAX 395 plus something like 7900 XTX 24GB run some of these new models fine? if the 7900 xtx would be connected with oculink or pcie 16x?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllcryz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could 128GB AMD Ryzen AI MAX 395 plus something like 7900 XTX 24GB run some of these new models fine? if the 7900 xtx would be connected with oculink or pcie 16x?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllcryz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743884265,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mllj8bw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grigio","can_mod_post":false,"created_utc":1743886423,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_37dhn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Good, but Maverick do not beat 4o to my tests","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mllj8bw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good, but Maverick do not beat 4o to my tests&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mllj8bw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743886423,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlmu76h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mooman555","can_mod_post":false,"created_utc":1743904027,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_g036y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just in time for stock market crash, how convenient","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlmu76h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just in time for stock market crash, how convenient&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlmu76h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743904027,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln1v1c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gubzs","can_mod_post":false,"created_utc":1743907163,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_u0jcd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"H-how many terabytes of RAM do you need to run a 2 trillion parameter model 😅\\n\\nI mean they can distill it but I can't see that being immediately useful for anything else","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln1v1c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;H-how many terabytes of RAM do you need to run a 2 trillion parameter model 😅&lt;/p&gt;\\n\\n&lt;p&gt;I mean they can distill it but I can&amp;#39;t see that being immediately useful for anything else&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln1v1c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743907163,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln3l9w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Socks797","can_mod_post":false,"created_utc":1743907907,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_qxc3er42","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow the new model looks lifelike","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln3l9w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow the new model looks lifelike&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln3l9w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743907907,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mln6jez","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sirdrewpalot","can_mod_post":false,"created_utc":1743909182,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_e2tv5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you believe you're open source and keep saying it, one day it might come true.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mln6jez","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you believe you&amp;#39;re open source and keep saying it, one day it might come true.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mln6jez/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743909182,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlnt2og","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JumpingJack79","can_mod_post":false,"created_utc":1743920305,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_a0qbr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What model is he getting fashion tips from? Definitely avoid that one like the plague due to catastrophic alignment issues.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlnt2og","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What model is he getting fashion tips from? Definitely avoid that one like the plague due to catastrophic alignment issues.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnt2og/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743920305,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlnwa43","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nomorecookiein2025","can_mod_post":false,"created_utc":1743922117,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_1g5mq9w9fe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this April again?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlnwa43","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this April again?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlnwa43/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743922117,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo336v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zyj","can_mod_post":false,"created_utc":1743926225,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_9dnfa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"He keeps saying „open source“ despite not providing what‘s needed to rebuild the model: The training data.\\nIt‘s open weights, not open source.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo336v","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He keeps saying „open source“ despite not providing what‘s needed to rebuild the model: The training data.\\nIt‘s open weights, not open source.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo336v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743926225,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo44ax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ZucchiniMidnight","can_mod_post":false,"created_utc":1743926874,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_b17tri68","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Reading from a script, love it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo44ax","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Reading from a script, love it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo44ax/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743926874,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo4uif","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xp5uhagu","can_mod_post":false,"created_utc":1743927340,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_65oxs7zp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AI gen zuk should use apache or MIT license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo4uif","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AI gen zuk should use apache or MIT license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo4uif/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743927340,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo858i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Eraser1926","can_mod_post":false,"created_utc":1743929501,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_tvdtyqtl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it the Lizard guy or AI?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo858i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it the Lizard guy or AI?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo858i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743929501,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlo9rwr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tmvr","can_mod_post":false,"created_utc":1743930575,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_11qlhv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama 4 Scout \\"*runs on a single GPU*\\" as long as that GPU is the 192GB GB200 and you are OK with Q4 :))\\n\\nEDIT: I see now that Scout is 109B so good news, you can run it already on an 80GB H100 with some context if you are fine with Q4...","edited":1743935308,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlo9rwr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 4 Scout &amp;quot;&lt;em&gt;runs on a single GPU&lt;/em&gt;&amp;quot; as long as that GPU is the 192GB GB200 and you are OK with Q4 :))&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: I see now that Scout is 109B so good news, you can run it already on an 80GB H100 with some context if you are fine with Q4...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlo9rwr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743930575,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mloawup","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nothingexceptfor","can_mod_post":false,"created_utc":1743931316,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_jzrki","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This humanoid gives me the creeps 😖, I would prefer just reading about it than hearing him trying to pass as a human being","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mloawup","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This humanoid gives me the creeps 😖, I would prefer just reading about it than hearing him trying to pass as a human being&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mloawup/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743931316,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlog1b9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BoQsc","can_mod_post":false,"created_utc":1743934629,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_hkuy7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/5uzuicriw6te1.png?width=718&amp;format=png&amp;auto=webp&amp;s=17c6144ee228eae8f792674d9d382684c3d8cfee\\n\\nSure, whatever you say Zuck, best model, /s  \\nllama4 maveric performs like 2023 llama2 or llama3.  \\nI tried the llama4 scout and it's the same and no better.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlog1b9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5uzuicriw6te1.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17c6144ee228eae8f792674d9d382684c3d8cfee\\"&gt;https://preview.redd.it/5uzuicriw6te1.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=17c6144ee228eae8f792674d9d382684c3d8cfee&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Sure, whatever you say Zuck, best model, /s&lt;br/&gt;\\nllama4 maveric performs like 2023 llama2 or llama3.&lt;br/&gt;\\nI tried the llama4 scout and it&amp;#39;s the same and no better.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlog1b9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743934629,"media_metadata":{"5uzuicriw6te1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":78,"x":108,"u":"https://preview.redd.it/5uzuicriw6te1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3c8b19f8d307287810bb4a0c900b23a6a2c0d94"},{"y":157,"x":216,"u":"https://preview.redd.it/5uzuicriw6te1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8b255c5d184b79c0107122353199c2f916a9c9b"},{"y":233,"x":320,"u":"https://preview.redd.it/5uzuicriw6te1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4739737b76be7ddec1b1a743c55703b1e558c07e"},{"y":467,"x":640,"u":"https://preview.redd.it/5uzuicriw6te1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d7ac02538d17ec1e595165c88f275303987e9bbf"}],"s":{"y":525,"x":718,"u":"https://preview.redd.it/5uzuicriw6te1.png?width=718&amp;format=png&amp;auto=webp&amp;s=17c6144ee228eae8f792674d9d382684c3d8cfee"},"id":"5uzuicriw6te1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"body":"It's now funny how a 109B model is considered small/mid-sized 😭","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mltvzd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"External-Soft-6286","can_mod_post":false,"created_utc":1744012075,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_czckr3ke","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mltvzd3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s now funny how a 109B model is considered small/mid-sized 😭&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mltvzd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744012075,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mluslav","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NathanPark","can_mod_post":false,"created_utc":1744030124,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_qpzwe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Respect","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mluslav","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Respect&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mluslav/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744030124,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlvvojo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"must_hustle","can_mod_post":false,"created_utc":1744042908,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_1f9fo2ppbd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Some pretty interesting stuff but overall not impressed, wrote quite a bit about it for a general audience in my newsletter: [https://mail.artificiallyboosted.com/p/dear-zuckerberg-size-doesn-t-matter-d721a2264bbd765b](https://mail.artificiallyboosted.com/p/dear-zuckerberg-size-doesn-t-matter-d721a2264bbd765b)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlvvojo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Some pretty interesting stuff but overall not impressed, wrote quite a bit about it for a general audience in my newsletter: &lt;a href=\\"https://mail.artificiallyboosted.com/p/dear-zuckerberg-size-doesn-t-matter-d721a2264bbd765b\\"&gt;https://mail.artificiallyboosted.com/p/dear-zuckerberg-size-doesn-t-matter-d721a2264bbd765b&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mlvvojo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744042908,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mly8jvr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BigMagnut","can_mod_post":false,"created_utc":1744069907,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_kmbhlwmn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Parameters are becoming like the bit wars of video game consoles.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mly8jvr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Parameters are becoming like the bit wars of video game consoles.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mly8jvr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744069907,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmajwf6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EricTheRed123","can_mod_post":false,"created_utc":1744238029,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_h9d8sk7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just got the unsloth version from Huggingface.  It's the Maverick version quantized to 3bit.  It's currently running at about 41 tokens/sec with the full 128 experts loaded.  This is on an M3 Ultra Mac Studio with 80 GPU cores and 256Gb ram.  I hope this helps someone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmajwf6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just got the unsloth version from Huggingface.  It&amp;#39;s the Maverick version quantized to 3bit.  It&amp;#39;s currently running at about 41 tokens/sec with the full 128 experts loaded.  This is on an M3 Ultra Mac Studio with 80 GPU cores and 256Gb ram.  I hope this helps someone.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mmajwf6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744238029,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmcgb0c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ignorantpisswalker","can_mod_post":false,"created_utc":1744265175,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_13hlwc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder how much of the new tokens are useless, see for example: [https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors](https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors)\\n\\nI don't want larger models, I want smaller modes. I cannot run this on my machine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmcgb0c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder how much of the new tokens are useless, see for example: &lt;a href=\\"https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors\\"&gt;https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t want larger models, I want smaller modes. I cannot run this on my machine.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mmcgb0c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744265175,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmj4e6d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kukalikuk","can_mod_post":false,"created_utc":1744360093,"send_replies":true,"parent_id":"t3_1jsampe","score":2,"author_fullname":"t2_23e97j9u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems like omnihuman demo video, it's too long to read without a prompter in a selfie pose 😁","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmj4e6d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems like omnihuman demo video, it&amp;#39;s too long to read without a prompter in a selfie pose 😁&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsampe/mark_presenting_four_llama_4_models_even_a_2/mmj4e6d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744360093,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsampe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":186,"name":"t1_mll5r4u","id":"mll5r4u","parent_id":"t3_1jsampe","depth":0,"children":["mll5r4u","mll2o4j","mllan68","mlkyzol","mlo5duv","mlle192","mll7cfs","mll11j0","mllcjjt","mll8gil","mloojdh","mlljcpx","mllao85","mlmu871","mlmmnq7","mllhxoo","mll4jdj","mls45y7","mlmfz4m","mln67as","mlrx6je","mln09w8","mllkbky","mlnq0yx","mlmxcjb","mlngxwi","mllcahh","mln3h8i","mlq2521","mlnxy5z","mllg0vn","mlmkfd4","mloker9","mlpwk6h","mlom0xi","mlmqol0","mlmx3i0","mlkzeob","mlnle87","mlnuf5j","mlvs4yf","mllgu5y","mlnjvi3","mlncxiv","mll0lxo","mlu72vg","mllij5p","mlx840f","mlthgrk","mln504p","mlvnwz0","mlouy6m","mlw1w0r","mlo6hz5","mlnljow","mlptgdd","mlo8n51","mlsf4nc","mlnex2n","mlpj6s5","mlpd8pw","mlnytfc","mllix3q","mm5jwd1","mlnadrf","mlqintc","mlqikdo","mm35yet","mwxhxrz","mlrbs4b","mllizd3","mlljw0d","mm81zhs","mlntgzx","mlrpchw","mlrbweu","mlqumsy","mlsxr38","mlsyk5i","mlwguwy","mlldie3","mlng51v","mln5b4z","mln9ojp","mlr1e2m","mnhd27y","mlo148y","mlot7rj","mlqvngh","mln7obk","mlxp9n4","mluycdv","mmafi84","mll613g","mlpbegz","mlmrwbt","mllemb8","mlmk69k","mlrc808","mll2l1z","mlmrtb9","mllj4s5","mlukmxk","mll9ge0","mlli1kh","mmcjl5c","mllc742","mllflcx","mll5nfj","mlmwibo","mln82no","mlroa51","mlsivfm","mlo4b2k","mlsrzv5","mln5yq2","mlrx69o","mlsautv","mlnt403","mll6dl6","mls8yt6","mllhf79","mlms39a","mlljjd9","mlooso8","mlmjw2v","mll0sbr","mlkzrcu","mlornc0","mlld1dg","mll7i5b","mln1m1i","mll4lni","mlkzag4","mlmr3n8","mllh0cd","mlla2ya","mllgc07","mll5wxc","mll2yrt","mlmsald","mll0e1u","mlncx2z"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
