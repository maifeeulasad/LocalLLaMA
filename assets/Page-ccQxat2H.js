import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"so ive hosted ollama locally on my system onÂ [http://localhost:11434/api/generate](http://localhost:11434/api/generate)Â and was testing it out a bit and it seems that between separate fetch calls, ollama seems to be retaining some memory.\\n\\ni don't understand why this would happen because as much as i have seen modern llms, they don't change their weights during inference.\\n\\nScenario:\\n\\n1. makes a query to ollama for topic 1 with a very specific keyword that i have created\\n2. makes another query to ollama for a topic that is similar to topic 1 but has a new keyword.\\n\\nTurns out that the first keyword shows up in the second response aswell. Not always, but this shouldn't happen at all as much as i know\\n\\nIs there something that i am missing?  \\nI checked the ollama/history file and it only contained prompts that i have made from the terminal using ollama run &lt;model\\\\_name&gt;","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Ollama retaining history?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzjlvi","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.6,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_c40awigh","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752491545,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;so ive hosted ollama locally on my system onÂ &lt;a href=\\"http://localhost:11434/api/generate\\"&gt;http://localhost:11434/api/generate&lt;/a&gt;Â and was testing it out a bit and it seems that between separate fetch calls, ollama seems to be retaining some memory.&lt;/p&gt;\\n\\n&lt;p&gt;i don&amp;#39;t understand why this would happen because as much as i have seen modern llms, they don&amp;#39;t change their weights during inference.&lt;/p&gt;\\n\\n&lt;p&gt;Scenario:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;makes a query to ollama for topic 1 with a very specific keyword that i have created&lt;/li&gt;\\n&lt;li&gt;makes another query to ollama for a topic that is similar to topic 1 but has a new keyword.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Turns out that the first keyword shows up in the second response aswell. Not always, but this shouldn&amp;#39;t happen at all as much as i know&lt;/p&gt;\\n\\n&lt;p&gt;Is there something that i am missing?&lt;br/&gt;\\nI checked the ollama/history file and it only contained prompts that i have made from the terminal using ollama run &amp;lt;model\\\\_name&amp;gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lzjlvi","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"DimensionEnergy","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/","subreddit_subscribers":499296,"created_utc":1752491545,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n355n2h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_n34158u","score":1,"author_fullname":"t2_8eneodlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Donâ€™t over think this , ollama can be buggy. If you have too many issues use LLM studio.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n355n2h","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Donâ€™t over think this , ollama can be buggy. If you have too many issues use LLM studio.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzjlvi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n355n2h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752525739,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752525739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n34158u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DimensionEnergy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3409o8","score":1,"author_fullname":"t2_c40awigh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"good point, but still i dont think the words I'm working with are so common that an llm would just chuck one in for good measure just because it felt right. especially when it could have added any of the other 20-30 words","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n34158u","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;good point, but still i dont think the words I&amp;#39;m working with are so common that an llm would just chuck one in for good measure just because it felt right. especially when it could have added any of the other 20-30 words&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lzjlvi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n34158u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752514317,"author_flair_text":null,"treatment_tags":[],"created_utc":1752514317,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3409o8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n33s1u5","score":2,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LLM's are just that repetitive.  They have a strong inclination to say certain things.  It's part of the reason GPT'isms are so bad.\\n\\nOne thing you might change is the temp setting.  A setting too low is more likely to cause the LLM to produce repetitive results.","edited":false,"author_flair_css_class":null,"name":"t1_n3409o8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LLM&amp;#39;s are just that repetitive.  They have a strong inclination to say certain things.  It&amp;#39;s part of the reason GPT&amp;#39;isms are so bad.&lt;/p&gt;\\n\\n&lt;p&gt;One thing you might change is the temp setting.  A setting too low is more likely to cause the LLM to produce repetitive results.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lzjlvi","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n3409o8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752514086,"author_flair_text":null,"collapsed":false,"created_utc":1752514086,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n33s1u5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DimensionEnergy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n33jtsv","score":1,"author_fullname":"t2_c40awigh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"exactly what im saying!!! i experienced this a lot before, but this time was concrete evidence that it had some memory.   \\nI really dont understand why its doing that tho. \\n\\nthing is around a few months ago when i was messing around with the chatgpt API endpoint. i had a similar experience, but dismissed it. \\n\\nso maybe its something about the general llm architecture?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n33s1u5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;exactly what im saying!!! i experienced this a lot before, but this time was concrete evidence that it had some memory.&lt;br/&gt;\\nI really dont understand why its doing that tho. &lt;/p&gt;\\n\\n&lt;p&gt;thing is around a few months ago when i was messing around with the chatgpt API endpoint. i had a similar experience, but dismissed it. &lt;/p&gt;\\n\\n&lt;p&gt;so maybe its something about the general llm architecture?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n33s1u5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752511838,"author_flair_text":null,"treatment_tags":[],"created_utc":1752511838,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n33jtsv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32ngn2","score":2,"author_fullname":"t2_8eelmfjg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's kind of a weird experience.  It thinks way more alike between sessions than you'd think.  I would have it write stories and it would use the same names over and over and it would get a bit unsettling.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n33jtsv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s kind of a weird experience.  It thinks way more alike between sessions than you&amp;#39;d think.  I would have it write stories and it would use the same names over and over and it would get a bit unsettling.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n33jtsv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752509528,"author_flair_text":null,"treatment_tags":[],"created_utc":1752509528,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n34cclu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DimensionEnergy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n341fqs","score":1,"author_fullname":"t2_c40awigh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"simple fetch call\\n\\n    OLLAMA_ENDPOINT = \\"http://localhost:11434/api/generate\\"\\n    def query_ollama(prompt):\\n        payload = {\\n            \\"model\\": MODEL_NAME,\\n            \\"prompt\\": prompt,\\n            \\"system\\": SYSTEM_PROMPT,\\n            \\"stream\\": False\\n        }\\n        response = requests.post(OLLAMA_ENDPOINT, json=payload)\\n        if response.status_code == 200:\\n            print(response.json()[\\"response\\"])\\n            return response.json()[\\"response\\"]\\n        else:\\n            raise Exception(f\\"Ollama query failed with status {response.status_code}: {response.text}\\")","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n34cclu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;simple fetch call&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;OLLAMA_ENDPOINT = &amp;quot;http://localhost:11434/api/generate&amp;quot;\\ndef query_ollama(prompt):\\n    payload = {\\n        &amp;quot;model&amp;quot;: MODEL_NAME,\\n        &amp;quot;prompt&amp;quot;: prompt,\\n        &amp;quot;system&amp;quot;: SYSTEM_PROMPT,\\n        &amp;quot;stream&amp;quot;: False\\n    }\\n    response = requests.post(OLLAMA_ENDPOINT, json=payload)\\n    if response.status_code == 200:\\n        print(response.json()[&amp;quot;response&amp;quot;])\\n        return response.json()[&amp;quot;response&amp;quot;]\\n    else:\\n        raise Exception(f&amp;quot;Ollama query failed with status {response.status_code}: {response.text}&amp;quot;)\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n34cclu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752517373,"author_flair_text":null,"treatment_tags":[],"created_utc":1752517373,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n341fqs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n32ngn2","score":2,"author_fullname":"t2_e9jh97s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are you accessing the API? Are you using Ollama/OpenAI library?\\n\\nUnless you're accidentaly including old context, it can't remember anything. I assure you, it's not possible.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n341fqs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are you accessing the API? Are you using Ollama/OpenAI library?&lt;/p&gt;\\n\\n&lt;p&gt;Unless you&amp;#39;re accidentaly including old context, it can&amp;#39;t remember anything. I assure you, it&amp;#39;s not possible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n341fqs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752514394,"author_flair_text":null,"treatment_tags":[],"created_utc":1752514394,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n32ngn2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DimensionEnergy","can_mod_post":false,"created_utc":1752499984,"send_replies":true,"parent_id":"t1_n32ansd","score":2,"author_fullname":"t2_c40awigh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thats why i wanted to ask. \\n\\nunderstand that the keywords I'm referring to here are acronyms that are deeply specific. And even though that makes it even more probable that they show up together, there are at least 20-30 that are correlated in this way. why did the only one show up that i passed in just before in the previous prompt?\\n\\non top of this in the second prompt i only mentioned the general topic. yet it mentioned and generated a gibberish response with words from the first prompt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32ngn2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thats why i wanted to ask. &lt;/p&gt;\\n\\n&lt;p&gt;understand that the keywords I&amp;#39;m referring to here are acronyms that are deeply specific. And even though that makes it even more probable that they show up together, there are at least 20-30 that are correlated in this way. why did the only one show up that i passed in just before in the previous prompt?&lt;/p&gt;\\n\\n&lt;p&gt;on top of this in the second prompt i only mentioned the general topic. yet it mentioned and generated a gibberish response with words from the first prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n32ngn2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752499984,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n32njm7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DimensionEnergy","can_mod_post":false,"created_utc":1752500011,"send_replies":true,"parent_id":"t1_n32ansd","score":1,"author_fullname":"t2_c40awigh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i can assure you that the client isn't storing any history","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32njm7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i can assure you that the client isn&amp;#39;t storing any history&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzjlvi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n32njm7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752500011,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n32ansd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chibop1","can_mod_post":false,"created_utc":1752495441,"send_replies":true,"parent_id":"t3_1lzjlvi","score":2,"author_fullname":"t2_e9jh97s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It doesn't. Tell your name ask what your name is in the same context. It should tell your name. Then in another session with fresh context, ask your name. It shouldn't be able to tell your name. If it does, client is managing some weird history context.\\n\\nAs a large language model, I have no memory of past conversations and don't know who you are. You haven't told me your name! ðŸ˜Š \\n\\nYou can tell me your name if you'd like, but I won't remember it for future interactions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n32ansd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t. Tell your name ask what your name is in the same context. It should tell your name. Then in another session with fresh context, ask your name. It shouldn&amp;#39;t be able to tell your name. If it does, client is managing some weird history context.&lt;/p&gt;\\n\\n&lt;p&gt;As a large language model, I have no memory of past conversations and don&amp;#39;t know who you are. You haven&amp;#39;t told me your name! ðŸ˜Š &lt;/p&gt;\\n\\n&lt;p&gt;You can tell me your name if you&amp;#39;d like, but I won&amp;#39;t remember it for future interactions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n32ansd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752495441,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzjlvi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n36jbpr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HistorianPotential48","can_mod_post":false,"created_utc":1752541485,"send_replies":true,"parent_id":"t3_1lzjlvi","score":1,"author_fullname":"t2_4dzthia7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"please post least reproducible example. what topic? what keyword? this is not a ouija board.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n36jbpr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;please post least reproducible example. what topic? what keyword? this is not a ouija board.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzjlvi/ollama_retaining_history/n36jbpr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752541485,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzjlvi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
