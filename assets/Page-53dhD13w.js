import{j as t}from"./index-CWmJdUH_.js";import{R as e}from"./RedditPostRenderer-D2iunoQ9.js";import"./index-BCg9RP6g.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey r/LocalLLaMA,\\n\\nI just published research on \\"thought anchors\\" - a method to analyze which specific reasoning steps matter most for task success in locally-runnable models. Thought this community would find the results interesting since it directly compares two popular local models.\\n\\n**TL;DR: Qwen3-0.6B and DeepSeek-R1-Distill-1.5B have fundamentally different reasoning architectures, not just different performance levels.**\\n\\n# What are Thought Anchors?\\n\\nBuilding on work by Bogdan et al., thought anchors identify critical sentences in a model's chain-of-thought reasoning that significantly impact whether it gets the right answer. Instead of looking at individual tokens, we analyze complete reasoning steps.\\n\\n# Key Findings on GSM8K Math Problems:\\n\\n**DeepSeek-R1-Distill (1.5B):**\\n\\n* Concentrated reasoning: fewer steps, higher impact per step (0.408 avg)\\n* 82.7% positive reasoning steps - very consistent\\n* Single primary failure mode (logical errors)\\n* Optimized for reliability over exploration\\n\\n**Qwen3 (0.6B):**\\n\\n* Distributed reasoning: more steps, spread impact (0.278 avg)\\n* 71.6% positive steps but higher variance\\n* Multiple failure modes (logical, computational, missing steps)\\n* More experimental approach with higher risk/reward\\n\\n# Practical Implications for Local Users:\\n\\nIf you're choosing between these models:\\n\\n* **Need consistent, reliable outputs?** → DeepSeek-R1's concentrated approach\\n* **Want more creative/exploratory reasoning?** → Qwen3's distributed approach\\n* **Resource constraints?** → Qwen3 at 0.6B vs DeepSeek at 1.5B\\n\\nThis isn't about one being \\"better\\" - they're optimized for different reasoning strategies.\\n\\n# Open Source Everything:\\n\\n* **PTS Library**: [https://github.com/codelion/pts](https://github.com/codelion/pts) (tool for generating thought anchors)\\n* **Datasets**: Available on HuggingFace for both models\\n* **Analysis Code**: Full reproducibility\\n* **Article**: [https://huggingface.co/blog/codelion/understanding-model-reasoning-thought-anchors](https://huggingface.co/blog/codelion/understanding-model-reasoning-thought-anchors)\\n\\nThe PTS library works with any local model that supports structured output, so you can analyze your own models' reasoning patterns.\\n\\n# Questions for the Community:\\n\\n1. Has anyone noticed similar reasoning pattern differences in their local setups?\\n2. Which reasoning approach works better for your specific use cases?\\n3. Any interest in extending this analysis to other popular local models (Llama, Mistral, etc.)?\\n\\nWould love to hear your experiences and thoughts on model reasoning approaches!\\n\\n**Edit**: Original thought anchors concept credit goes to Paul Bogdan's team - this research extends their methodology to compare local model architectures.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"[Research] Thought Anchors: Understanding How Qwen3-0.6B vs DeepSeek-R1-Distill-1.5B Actually Reason - Different Cognitive Architectures Revealed","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6zce0","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.87,"author_flair_background_color":"#93b1ba","subreddit_type":"public","ups":18,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","is_original_content":false,"author_fullname":"t2_e0bph","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":18,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1753243256,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey &lt;a href=\\"/r/LocalLLaMA\\"&gt;r/LocalLLaMA&lt;/a&gt;,&lt;/p&gt;\\n\\n&lt;p&gt;I just published research on &amp;quot;thought anchors&amp;quot; - a method to analyze which specific reasoning steps matter most for task success in locally-runnable models. Thought this community would find the results interesting since it directly compares two popular local models.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;TL;DR: Qwen3-0.6B and DeepSeek-R1-Distill-1.5B have fundamentally different reasoning architectures, not just different performance levels.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;h1&gt;What are Thought Anchors?&lt;/h1&gt;\\n\\n&lt;p&gt;Building on work by Bogdan et al., thought anchors identify critical sentences in a model&amp;#39;s chain-of-thought reasoning that significantly impact whether it gets the right answer. Instead of looking at individual tokens, we analyze complete reasoning steps.&lt;/p&gt;\\n\\n&lt;h1&gt;Key Findings on GSM8K Math Problems:&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;strong&gt;DeepSeek-R1-Distill (1.5B):&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Concentrated reasoning: fewer steps, higher impact per step (0.408 avg)&lt;/li&gt;\\n&lt;li&gt;82.7% positive reasoning steps - very consistent&lt;/li&gt;\\n&lt;li&gt;Single primary failure mode (logical errors)&lt;/li&gt;\\n&lt;li&gt;Optimized for reliability over exploration&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Qwen3 (0.6B):&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Distributed reasoning: more steps, spread impact (0.278 avg)&lt;/li&gt;\\n&lt;li&gt;71.6% positive steps but higher variance&lt;/li&gt;\\n&lt;li&gt;Multiple failure modes (logical, computational, missing steps)&lt;/li&gt;\\n&lt;li&gt;More experimental approach with higher risk/reward&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;Practical Implications for Local Users:&lt;/h1&gt;\\n\\n&lt;p&gt;If you&amp;#39;re choosing between these models:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Need consistent, reliable outputs?&lt;/strong&gt; → DeepSeek-R1&amp;#39;s concentrated approach&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Want more creative/exploratory reasoning?&lt;/strong&gt; → Qwen3&amp;#39;s distributed approach&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Resource constraints?&lt;/strong&gt; → Qwen3 at 0.6B vs DeepSeek at 1.5B&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;This isn&amp;#39;t about one being &amp;quot;better&amp;quot; - they&amp;#39;re optimized for different reasoning strategies.&lt;/p&gt;\\n\\n&lt;h1&gt;Open Source Everything:&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;PTS Library&lt;/strong&gt;: &lt;a href=\\"https://github.com/codelion/pts\\"&gt;https://github.com/codelion/pts&lt;/a&gt; (tool for generating thought anchors)&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Datasets&lt;/strong&gt;: Available on HuggingFace for both models&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Analysis Code&lt;/strong&gt;: Full reproducibility&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Article&lt;/strong&gt;: &lt;a href=\\"https://huggingface.co/blog/codelion/understanding-model-reasoning-thought-anchors\\"&gt;https://huggingface.co/blog/codelion/understanding-model-reasoning-thought-anchors&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The PTS library works with any local model that supports structured output, so you can analyze your own models&amp;#39; reasoning patterns.&lt;/p&gt;\\n\\n&lt;h1&gt;Questions for the Community:&lt;/h1&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Has anyone noticed similar reasoning pattern differences in their local setups?&lt;/li&gt;\\n&lt;li&gt;Which reasoning approach works better for your specific use cases?&lt;/li&gt;\\n&lt;li&gt;Any interest in extending this analysis to other popular local models (Llama, Mistral, etc.)?&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Would love to hear your experiences and thoughts on model reasoning approaches!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt;: Original thought anchors concept credit goes to Paul Bogdan&amp;#39;s team - this research extends their methodology to compare local model architectures.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?auto=webp&amp;s=187504b6a6cdaab3b5025c91a3798e0b46bcb9f0","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=76a98416b90c3288a04cac47b99811464ff316e5","width":108,"height":54},{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9389c4b2ca46a4b05928b5941369ea699ccec4e6","width":216,"height":108},{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5964cc2bf092a1202a804fdcec163a7e14497c35","width":320,"height":160},{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1a192ca72cfe990c9ccd3456b264cd2914962c19","width":640,"height":320},{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=67133c9db0890c820ce5cdc0549dcaeb9f9e95de","width":960,"height":480},{"url":"https://external-preview.redd.it/LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=978ef4cf2867cf2f582d6936f382955179b16eba","width":1080,"height":540}],"variants":{},"id":"LUwOzF1qaWXXZdKFKtNyq98eHv6n8KWbzzx3ALLxitY"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Llama 3.1","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m6zce0","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"asankhs","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1m6zce0/research_thought_anchors_understanding_how/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6zce0/research_thought_anchors_understanding_how/","subreddit_subscribers":503255,"created_utc":1753243256,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4nsdnr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jack9761","can_mod_post":false,"created_utc":1753246972,"send_replies":true,"parent_id":"t3_1m6zce0","score":1,"author_fullname":"t2_13gw4o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you done limited tests on larger models in each series (Qwen 4b, 8b, Qwen 8b-deepseek) to see if the pattern still holds?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4nsdnr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you done limited tests on larger models in each series (Qwen 4b, 8b, Qwen 8b-deepseek) to see if the pattern still holds?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6zce0/research_thought_anchors_understanding_how/n4nsdnr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753246972,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6zce0","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>t.jsx(e,{data:l});export{o as default};
