import{j as e}from"./index-BpC9hjVs.js";import{R as l}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"The 1T Kimi K2 model is using DeepSeek V3 architecture","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxb0eo","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":"#bbbdbf","ups":156,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_4gc7hf3m","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":156,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://a.thumbs.redditmedia.com/GLWo99y2VXsciDgoAKyzE3GZociHN4n_7g_ihtVi9I0.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752250411,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/l3gpvb5or9cf1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?auto=webp&amp;s=40d8a85b1d07e964b63a7e5184f9a5d5809b715f","width":1080,"height":1907},"resolutions":[{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff23740ffcaa59c97aa66e63a434e727e8b2ad4a","width":108,"height":190},{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bce6fa94a7bb620076dc98255430dc1b47e1e0a7","width":216,"height":381},{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8aea3ce7d05f335e3aa2e57966b68ef819eeeea9","width":320,"height":565},{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ed19f0e0b0c28fcc15556f566717d11201a68611","width":640,"height":1130},{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e13852845fea6f89d5766368474e1f7307fd4b0","width":960,"height":1695},{"url":"https://preview.redd.it/l3gpvb5or9cf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18f660077733393b7b3433b426f75cb65bfef0e5","width":1080,"height":1907}],"variants":{},"id":"Q200XGQK2QDqTgopEJURrQJKELVtC6jLu8BfpN-NSrQ"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lxb0eo","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"AaronFeng47","discussion_type":null,"num_comments":30,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/","stickied":false,"url":"https://i.redd.it/l3gpvb5or9cf1.png","subreddit_subscribers":498346,"created_utc":1752250411,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kvq9n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752252989,"send_replies":true,"parent_id":"t3_1lxb0eo","score":91,"author_fullname":"t2_4amlo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Given that Deepseek's architecture has been proven to work well, and be quite economical compared to what the industry norm was at the time, why wouldn't they? \\n\\nAlso most models recently have used architecture  that were clearly inspired by Deepseek, though modified just enough to be incompatible with existing solutions. Officially using the same architecture is actually a good thing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kvq9n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Given that Deepseek&amp;#39;s architecture has been proven to work well, and be quite economical compared to what the industry norm was at the time, why wouldn&amp;#39;t they? &lt;/p&gt;\\n\\n&lt;p&gt;Also most models recently have used architecture  that were clearly inspired by Deepseek, though modified just enough to be incompatible with existing solutions. Officially using the same architecture is actually a good thing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2kvq9n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752252989,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":91}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kto6q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Theio666","can_mod_post":false,"created_utc":1752252420,"send_replies":true,"parent_id":"t3_1lxb0eo","score":115,"author_fullname":"t2_ikhuo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why not, no need to reinvent/reimplement MLA and other tricks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kto6q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not, no need to reinvent/reimplement MLA and other tricks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2kto6q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752252420,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":115}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2kuyit","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NoobMLDude","can_mod_post":false,"created_utc":1752252777,"send_replies":true,"parent_id":"t3_1lxb0eo","score":26,"author_fullname":"t2_t0syffr8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Teams working on the same architecture is actually not bad. \\nSo novel enhancements can stack on top of each other when multiple teams work on same architecture.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kuyit","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Teams working on the same architecture is actually not bad. \\nSo novel enhancements can stack on top of each other when multiple teams work on same architecture.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2kuyit/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752252777,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"609bf7d4-01f3-11f0-9760-5611c8333bee","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"609bf7d4-01f3-11f0-9760-5611c8333bee","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mawnf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"You_Wen_AzzHu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ld2v0","score":4,"author_fullname":"t2_p4oxcufl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Run unsloth gguf q4 version with llamacpp or ik_llama.  8 tkps.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mawnf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"exllama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Run unsloth gguf q4 version with llamacpp or ik_llama.  8 tkps.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2mawnf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267800,"author_flair_text":"exllama","treatment_tags":[],"created_utc":1752267800,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lgimt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lfmv7","score":2,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I donâ€™t have it, I blew it away after Qwen3 235B out-performed Dots, which isnâ€™t surprising given the size difference.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2lgimt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I donâ€™t have it, I blew it away after Qwen3 235B out-performed Dots, which isnâ€™t surprising given the size difference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lgimt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752258806,"author_flair_text":null,"treatment_tags":[],"created_utc":1752258806,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2lfmv7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Physical-Citron5153","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ldd3a","score":2,"author_fullname":"t2_clhgguip","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you also share your config and estimate tok/s","edited":false,"author_flair_css_class":null,"name":"t1_n2lfmv7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you also share your config and estimate tok/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lfmv7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752258548,"author_flair_text":null,"collapsed":false,"created_utc":1752258548,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ldd3a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__JockY__","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ld2v0","score":3,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"vLLM with the FP8 quant https://huggingface.co/rednote-hilab/dots.llm1.inst-FP8-dynamic","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ldd3a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;vLLM with the FP8 quant &lt;a href=\\"https://huggingface.co/rednote-hilab/dots.llm1.inst-FP8-dynamic\\"&gt;https://huggingface.co/rednote-hilab/dots.llm1.inst-FP8-dynamic&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2ldd3a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752257889,"author_flair_text":null,"treatment_tags":[],"created_utc":1752257889,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ld2v0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2l9tfg","score":2,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I canâ€™t get it running. What front end, and what quantization model have you used?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ld2v0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I canâ€™t get it running. What front end, and what quantization model have you used?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2ld2v0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752257806,"author_flair_text":null,"treatment_tags":[],"created_utc":1752257806,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2l9tfg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1752256865,"send_replies":true,"parent_id":"t1_n2l2ydc","score":11,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Dots is close at 142B A14B: https://huggingface.co/rednote-hilab/dots.llm1.inst\\n\\nIt performed quite well in my limited code-based testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2l9tfg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dots is close at 142B A14B: &lt;a href=\\"https://huggingface.co/rednote-hilab/dots.llm1.inst\\"&gt;https://huggingface.co/rednote-hilab/dots.llm1.inst&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It performed quite well in my limited code-based testing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2l9tfg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752256865,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n2l2ydc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"You_Wen_AzzHu","can_mod_post":false,"created_utc":1752254974,"send_replies":true,"parent_id":"t3_1lxb0eo","score":21,"author_fullname":"t2_p4oxcufl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We need a 100b a10 Deepseek architecture model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2l2ydc","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"exllama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need a 100b a10 Deepseek architecture model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2l2ydc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752254974,"author_flair_text":"exllama","treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2m0o1b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poli-cya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lzj2k","score":3,"author_fullname":"t2_q8g93lhv4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the info, I'm a bit ignorant on this stuff. I wasn't saying kimi is a rework of a deepseek model, just that I believe it's possible to change vocab and whatnot. Now to decide if I want to clear off an SSD and wait a day to download and see how many tok/s I can get on this monster.","edited":false,"author_flair_css_class":null,"name":"t1_n2m0o1b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the info, I&amp;#39;m a bit ignorant on this stuff. I wasn&amp;#39;t saying kimi is a rework of a deepseek model, just that I believe it&amp;#39;s possible to change vocab and whatnot. Now to decide if I want to clear off an SSD and wait a day to download and see how many tok/s I can get on this monster.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2m0o1b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752264788,"author_flair_text":null,"collapsed":false,"created_utc":1752264788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mxz45","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mnxn5","score":1,"author_fullname":"t2_4hfmiefj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Will do. Feels silly in retrospect not looking at the existing metadata; [Happy to reply with a fun paper too thatâ€™s fun/relevant](https://arxiv.org/pdf/2507.07955)\\n\\n[Gonna see if I can add H-Net Layers to existing models ](https://github.com/codelion/adaptive-classifier)and optimize for corpus-specific rewards generated across a more stable gradient update","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2mxz45","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will do. Feels silly in retrospect not looking at the existing metadata; &lt;a href=\\"https://arxiv.org/pdf/2507.07955\\"&gt;Happy to reply with a fun paper too thatâ€™s fun/relevant&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/codelion/adaptive-classifier\\"&gt;Gonna see if I can add H-Net Layers to existing models &lt;/a&gt;and optimize for corpus-specific rewards generated across a more stable gradient update&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2mxz45/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752275312,"author_flair_text":null,"treatment_tags":[],"created_utc":1752275312,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mnxn5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mkoa6","score":2,"author_fullname":"t2_1opxde6hyq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nope. Differences are identifiable if you just dig through the model info as published.  config.json, the readme, and the layer info buttons in the HF file listings (second icon right of the filename, two stacked squares and the arrow pointing up and right).  \\nDig, read, enjoy.\\n\\nAnd best of luck on that idea.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2mnxn5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope. Differences are identifiable if you just dig through the model info as published.  config.json, the readme, and the layer info buttons in the HF file listings (second icon right of the filename, two stacked squares and the arrow pointing up and right).&lt;br/&gt;\\nDig, read, enjoy.&lt;/p&gt;\\n\\n&lt;p&gt;And best of luck on that idea.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2mnxn5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752271899,"author_flair_text":null,"treatment_tags":[],"created_utc":1752271899,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mkoa6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lzj2k","score":1,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you have software you like for visualizing and quantifying those distinctions? ðŸ“Š \\n\\ne.g. weight watchers for per-layer alpha ðŸ“‰ \\n\\nWanting to instrument model checkpoints for CI/CD &amp; allow evolutionary approaches to domain specific tasks ðŸŽ¯","edited":false,"author_flair_css_class":null,"name":"t1_n2mkoa6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have software you like for visualizing and quantifying those distinctions? ðŸ“Š &lt;/p&gt;\\n\\n&lt;p&gt;e.g. weight watchers for per-layer alpha ðŸ“‰ &lt;/p&gt;\\n\\n&lt;p&gt;Wanting to instrument model checkpoints for CI/CD &amp;amp; allow evolutionary approaches to domain specific tasks ðŸŽ¯&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxb0eo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2mkoa6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270845,"author_flair_text":null,"collapsed":false,"created_utc":1752270845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2lzj2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Entubulated","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lp6ob","score":10,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Apparently you can, but from what I understand, it's not just plug and play changing the vocab, as the model's internal data representation is based around what tokenizer scheme it was trained on. You can also expand model size by playing games with layer repetition, or adding layers from similar models. The Chimera model is an example of mixing layers from similar models (DeepSeek V3 and R1), though final size remains the same there.\\n\\nBut the part where some some tensor shapes don't match is a bigger tell.\\n\\nThere's more differences if you go digging deeper, including Kimi K2 only having one dense base layer compared to the regular DSR1/DSV3 having three and the experts setups being different.\\n\\nI suppose it's \\\\*theoretically\\\\* possible this is a slice and dice and not from scratch, but I wouldn't bet on it without more info.\\n\\nEdit:  Also, on the speculative decoding models, my understanding is that you want to use a smaller model from the same series with the same tokenizer.Otherwise, your 'miss' rate can go up drastically and you don't see any speed benefit.","edited":1752265370,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lzj2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apparently you can, but from what I understand, it&amp;#39;s not just plug and play changing the vocab, as the model&amp;#39;s internal data representation is based around what tokenizer scheme it was trained on. You can also expand model size by playing games with layer repetition, or adding layers from similar models. The Chimera model is an example of mixing layers from similar models (DeepSeek V3 and R1), though final size remains the same there.&lt;/p&gt;\\n\\n&lt;p&gt;But the part where some some tensor shapes don&amp;#39;t match is a bigger tell.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s more differences if you go digging deeper, including Kimi K2 only having one dense base layer compared to the regular DSR1/DSV3 having three and the experts setups being different.&lt;/p&gt;\\n\\n&lt;p&gt;I suppose it&amp;#39;s *theoretically* possible this is a slice and dice and not from scratch, but I wouldn&amp;#39;t bet on it without more info.&lt;/p&gt;\\n\\n&lt;p&gt;Edit:  Also, on the speculative decoding models, my understanding is that you want to use a smaller model from the same series with the same tokenizer.Otherwise, your &amp;#39;miss&amp;#39; rate can go up drastically and you don&amp;#39;t see any speed benefit.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lzj2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752264447,"author_flair_text":null,"treatment_tags":[],"created_utc":1752264447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lv4b6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"zxytim","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lp6ob","score":4,"author_fullname":"t2_y2ugj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Kimi K2 is trained from scratch for sure.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lv4b6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Kimi K2 is trained from scratch for sure.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lv4b6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752263123,"author_flair_text":null,"treatment_tags":[],"created_utc":1752263123,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2lp6ob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poli-cya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2l7jhp","score":1,"author_fullname":"t2_q8g93lhv4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can change token embedding and vocab size though, right? Isn't that how people make those speculative decoding models? And you can expand a model from one size to larger, I know I've seen custom-made models that increase the size of the original.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2lp6ob","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can change token embedding and vocab size though, right? Isn&amp;#39;t that how people make those speculative decoding models? And you can expand a model from one size to larger, I know I&amp;#39;ve seen custom-made models that increase the size of the original.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lp6ob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752261336,"author_flair_text":null,"treatment_tags":[],"created_utc":1752261336,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2l7jhp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Entubulated","can_mod_post":false,"created_utc":1752256235,"send_replies":true,"parent_id":"t1_n2ko5ff","score":26,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"DSV3 / DSR1 are 671B param models, not 1T param models. At first glance, this does look like trained from scratch, as token embedding layer and vocab size are different. Some tensor shapes match while others don't.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2l7jhp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DSV3 / DSR1 are 671B param models, not 1T param models. At first glance, this does look like trained from scratch, as token embedding layer and vocab size are different. Some tensor shapes match while others don&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2l7jhp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752256235,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ko5ff","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LA_rent_Aficionado","can_mod_post":false,"created_utc":1752250843,"send_replies":true,"parent_id":"t3_1lxb0eo","score":23,"author_fullname":"t2_t8zbiflk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not sure if these are fine times or from scratch, the promised Kimi dev paper is still outstanding...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ko5ff","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure if these are fine times or from scratch, the promised Kimi dev paper is still outstanding...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2ko5ff/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752250843,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2phq2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1752317337,"send_replies":true,"parent_id":"t1_n2kypse","score":4,"author_fullname":"t2_4gc7hf3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe they don't have enough compute? Mistral large haven't receive any updates for a long timeÂ ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2phq2t","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe they don&amp;#39;t have enough compute? Mistral large haven&amp;#39;t receive any updates for a long timeÂ &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2phq2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752317337,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2kypse","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thereisonlythedance","can_mod_post":false,"created_utc":1752253811,"send_replies":true,"parent_id":"t3_1lxb0eo","score":20,"author_fullname":"t2_u4wkj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Iâ€™m surprised Mistral hasnâ€™t done this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2kypse","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Iâ€™m surprised Mistral hasnâ€™t done this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2kypse/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752253811,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ofb51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2nwcdo","score":1,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for link, pretty sure I'd tried from there and hit some snag, but memory is a bit fuzzy.  I'll add that to the stack to get back to...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ofb51","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for link, pretty sure I&amp;#39;d tried from there and hit some snag, but memory is a bit fuzzy.  I&amp;#39;ll add that to the stack to get back to...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2ofb51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752295650,"author_flair_text":null,"treatment_tags":[],"created_utc":1752295650,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2nwcdo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2lia4m","score":2,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Someone lined me [this](https://huggingface.co/daydream-org/DeepSeek-R1-GGUF-11446/discussions/1#67a327570051a98a96ded9e6) which uses triton-cpu for handle the FP8 natively in \`convert_hf_to_gguf.py\`.  Deepseek's conversion code requires a GPU with FP8 support and a couple tweaks to avoid OOMs on most GPUs","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2nwcdo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Someone lined me &lt;a href=\\"https://huggingface.co/daydream-org/DeepSeek-R1-GGUF-11446/discussions/1#67a327570051a98a96ded9e6\\"&gt;this&lt;/a&gt; which uses triton-cpu for handle the FP8 natively in &lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt;.  Deepseek&amp;#39;s conversion code requires a GPU with FP8 support and a couple tweaks to avoid OOMs on most GPUs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2nwcdo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752287725,"author_flair_text":null,"treatment_tags":[],"created_utc":1752287725,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2lia4m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"created_utc":1752259318,"send_replies":true,"parent_id":"t1_n2larzm","score":1,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In theory, yeah, it should convert and run with no issues.  \\nI'll wait for the usual suspects to try it, as last time I poked at published code to take the DeepSeek original FP8 models and try to convert them myself, it just kept throwing errors.  If it hasn't happened yet, would be nice if code to allow that conversion could be merged directly in to convert\\\\_hf\\\\_to\\\\_gguf.py","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lia4m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In theory, yeah, it should convert and run with no issues.&lt;br/&gt;\\nI&amp;#39;ll wait for the usual suspects to try it, as last time I poked at published code to take the DeepSeek original FP8 models and try to convert them myself, it just kept throwing errors.  If it hasn&amp;#39;t happened yet, would be nice if code to allow that conversion could be merged directly in to convert_hf_to_gguf.py&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lia4m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752259318,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2nvzi2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"created_utc":1752287588,"send_replies":true,"parent_id":"t1_n2larzm","score":1,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In principle, yeah.  However, it's not quite clear to me since they have changed the tokenizer AFAICT so the model won't GGUF with current llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nvzi2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In principle, yeah.  However, it&amp;#39;s not quite clear to me since they have changed the tokenizer AFAICT so the model won&amp;#39;t GGUF with current llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxb0eo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2nvzi2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752287588,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2larzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lissanro","can_mod_post":false,"created_utc":1752257139,"send_replies":true,"parent_id":"t3_1lxb0eo","score":4,"author_fullname":"t2_fpfao9g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting! So since it is using V3 arch, maybe its GGUF quants will work with ik\\\\_llama.cpp out of the box? There are currently no GGUF quants to try though, so I guess I have to wait a bit.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2larzm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting! So since it is using V3 arch, maybe its GGUF quants will work with ik_llama.cpp out of the box? There are currently no GGUF quants to try though, so I guess I have to wait a bit.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2larzm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752257139,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oo1wd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Su1tz","can_mod_post":false,"created_utc":1752300067,"send_replies":true,"parent_id":"t3_1lxb0eo","score":3,"author_fullname":"t2_tupznx19","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Free llama.cpp support","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2oo1wd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Free llama.cpp support&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2oo1wd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752300067,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2lc7er","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752257553,"send_replies":true,"parent_id":"t3_1lxb0eo","score":2,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We can run it at 1/2 bit.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2lc7er","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We can run it at 1/2 bit.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2lc7er/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752257553,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qp5fw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emotional-Metal4879","can_mod_post":false,"created_utc":1752334020,"send_replies":true,"parent_id":"t3_1lxb0eo","score":1,"author_fullname":"t2_psquw0767","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wow, scaling","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qp5fw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wow, scaling&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2qp5fw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752334020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vfwgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"getpodapp","can_mod_post":false,"created_utc":1752400106,"send_replies":true,"parent_id":"t3_1lxb0eo","score":2,"author_fullname":"t2_v2x4wxet","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Doesn't this mean whoever is serving v3 can just swap in kimi k2? this will help with adoption and is a great idea.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vfwgv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Doesn&amp;#39;t this mean whoever is serving v3 can just swap in kimi k2? this will help with adoption and is a great idea.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxb0eo/the_1t_kimi_k2_model_is_using_deepseek_v3/n2vfwgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752400106,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxb0eo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
