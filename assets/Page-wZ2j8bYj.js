import{j as e}from"./index-DQXiEb7D.js";import{R as t}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Medical triage means determining whether symptoms require emergency care, urgent care, or can be managed with self-care. This matters because LLMs are increasingly becoming the \\"digital front door\\" for health concerns—replacing the instinct to just Google it.\\n\\nGetting triage wrong can be dangerous (missed emergencies) or costly (unnecessary ER visits).\\n\\nWe've open-sourced **TriageBench**, a reproducible framework for evaluating LLM triage accuracy. It includes:\\n\\n* Standard clinical dataset (Semigran vignettes)\\n* Paired McNemar's test to detect model performance differences on small datasets\\n* Full methodology and evaluation code\\n\\nGitHub: [https://github.com/medaks/medask-benchmark](https://github.com/medaks/medask-benchmark)\\n\\nAs a demonstration, we benchmarked our own model (MedAsk) against several OpenAI models:\\n\\n* MedAsk: **87.6% accuracy**\\n* o3: **75.6%**\\n* GPT‑4.5: **68.9%**\\n\\nThe main limitation is dataset size (45 vignettes). We're looking for collaborators to help expand this—the field needs larger, more diverse clinical datasets.\\n\\nBlog post with full results: [https://medask.tech/blogs/medical-ai-triage-accuracy-2025-medask-beats-openais-o3-gpt-4-5/](https://medask.tech/blogs/medical-ai-triage-accuracy-2025-medask-beats-openais-o3-gpt-4-5/)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"We built an open-source medical triage benchmark","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxw3zz","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":116,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lp2ivten","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":116,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752311546,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Medical triage means determining whether symptoms require emergency care, urgent care, or can be managed with self-care. This matters because LLMs are increasingly becoming the &amp;quot;digital front door&amp;quot; for health concerns—replacing the instinct to just Google it.&lt;/p&gt;\\n\\n&lt;p&gt;Getting triage wrong can be dangerous (missed emergencies) or costly (unnecessary ER visits).&lt;/p&gt;\\n\\n&lt;p&gt;We&amp;#39;ve open-sourced &lt;strong&gt;TriageBench&lt;/strong&gt;, a reproducible framework for evaluating LLM triage accuracy. It includes:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Standard clinical dataset (Semigran vignettes)&lt;/li&gt;\\n&lt;li&gt;Paired McNemar&amp;#39;s test to detect model performance differences on small datasets&lt;/li&gt;\\n&lt;li&gt;Full methodology and evaluation code&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;GitHub: &lt;a href=\\"https://github.com/medaks/medask-benchmark\\"&gt;https://github.com/medaks/medask-benchmark&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;As a demonstration, we benchmarked our own model (MedAsk) against several OpenAI models:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;MedAsk: &lt;strong&gt;87.6% accuracy&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;o3: &lt;strong&gt;75.6%&lt;/strong&gt;&lt;/li&gt;\\n&lt;li&gt;GPT‑4.5: &lt;strong&gt;68.9%&lt;/strong&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The main limitation is dataset size (45 vignettes). We&amp;#39;re looking for collaborators to help expand this—the field needs larger, more diverse clinical datasets.&lt;/p&gt;\\n\\n&lt;p&gt;Blog post with full results: &lt;a href=\\"https://medask.tech/blogs/medical-ai-triage-accuracy-2025-medask-beats-openais-o3-gpt-4-5/\\"&gt;https://medask.tech/blogs/medical-ai-triage-accuracy-2025-medask-beats-openais-o3-gpt-4-5/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?auto=webp&amp;s=41ebf4298905eb26f4cef7c264a930eaa2aa2c5c","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9c7e10a1a4f6aeffdd4ad9ec00fba71b13e9850","width":108,"height":54},{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=12ae853d79e9684e4fdd32bea3af05e334b73b38","width":216,"height":108},{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b194f182a8f6d7fa069cdedc5685ff5d9aecc59","width":320,"height":160},{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=861e796a8d8ac8b7c2b73c785d2751b59de40d1c","width":640,"height":320},{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f068abe4f3993070d3e9aefaedd824a71bb88c7","width":960,"height":480},{"url":"https://external-preview.redd.it/YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39b1861c4e75006d81e7f80388e64198bfc249fa","width":1080,"height":540}],"variants":{},"id":"YGRuXIPLJmfx-HMMUWxIo3PT1Eu1Kllj_TeA0JBYYtI"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lxw3zz","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"Significant-Pair-275","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxw3zz/we_built_an_opensource_medical_triage_benchmark/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxw3zz/we_built_an_opensource_medical_triage_benchmark/","subreddit_subscribers":498346,"created_utc":1752311546,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2paa57","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Psionikus","can_mod_post":false,"created_utc":1752313019,"send_replies":true,"parent_id":"t3_1lxw3zz","score":5,"author_fullname":"t2_8vhsch4i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is awesome.  \\n\\nMy fear about this kind of work is that we will re-invent tons and tons and tons of \\"fine-tuned for X\\" models.  This is a symptom of situations where open source can have a big impact.  If we're all fine-tuning on top of X+1 and a lot of these fine-tunes are released, the overall pace of progress on the tech and what it enables can go faster.  Might as well self-promote since I'm thinking about this kind of stuff because it's exactly what I'm building.  r/prizeforge","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2paa57","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is awesome.  &lt;/p&gt;\\n\\n&lt;p&gt;My fear about this kind of work is that we will re-invent tons and tons and tons of &amp;quot;fine-tuned for X&amp;quot; models.  This is a symptom of situations where open source can have a big impact.  If we&amp;#39;re all fine-tuning on top of X+1 and a lot of these fine-tunes are released, the overall pace of progress on the tech and what it enables can go faster.  Might as well self-promote since I&amp;#39;m thinking about this kind of stuff because it&amp;#39;s exactly what I&amp;#39;m building.  &lt;a href=\\"/r/prizeforge\\"&gt;r/prizeforge&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxw3zz/we_built_an_opensource_medical_triage_benchmark/n2paa57/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752313019,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxw3zz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2v9hd7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Significant-Pair-275","can_mod_post":false,"created_utc":1752396304,"send_replies":true,"parent_id":"t1_n2r1l5z","score":2,"author_fullname":"t2_lp2ivten","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fair enough. We will add MedGemma as well as Deepseek to our benchmark suite.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v9hd7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fair enough. We will add MedGemma as well as Deepseek to our benchmark suite.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxw3zz","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxw3zz/we_built_an_opensource_medical_triage_benchmark/n2v9hd7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752396304,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2r1l5z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"this-just_in","can_mod_post":false,"created_utc":1752337884,"send_replies":true,"parent_id":"t3_1lxw3zz","score":5,"author_fullname":"t2_kdmu4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I understand that the purpose of this post is to introduce the MedAsk product but would have been interesting to see it compared to say MedGemma 27B too, to at least attempt to thread the needle with r/localllama.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2r1l5z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I understand that the purpose of this post is to introduce the MedAsk product but would have been interesting to see it compared to say MedGemma 27B too, to at least attempt to thread the needle with &lt;a href=\\"/r/localllama\\"&gt;r/localllama&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxw3zz/we_built_an_opensource_medical_triage_benchmark/n2r1l5z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752337884,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxw3zz","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}}]`),n=()=>e.jsx(t,{data:a});export{n as default};
