import{j as e}from"./index-CqAPCjw5.js";import{R as l}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I’m experimenting with lightweight finetuning of phi-4-mini to alter its speaking style for a project — think tonal adjustments like high-energy, friendly, getting rid of that “I am a artificial intelligence assistant…” stuff, etc. I still want to preserve all tool calling functions (Python, web search, image generation, etc.) and not break its multi-turn conversation.\\n\\nKey needs:\\n\\n– Non-destructive to function calling behavior\\n\\n– Has to be runnable on Colab (no GPU locally)\\n\\n\\\\- 0 Budget: No MonsterAPI or paid stuff\\n\\n\\\\- Keep it small: Under 5GB (After being quantized to GGUF)\\n\\n\\\\- Be able to be exported, converted to gguf, and run with ollama\\n\\nI’m not doing instruction tuning from scratch, just style injection over chat data.\\n\\nAny recommendations on a colab that can help me keep auxiliary functionality intact while customizing tone? I want to do basically what Just Rayan (On youtube) did, but with Phi4-Mini, and keeping tool calling functions.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Help with Finetuning Phi4-Mini","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m563lh","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.33,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_afskfa1c","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753061780,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m experimenting with lightweight finetuning of phi-4-mini to alter its speaking style for a project — think tonal adjustments like high-energy, friendly, getting rid of that “I am a artificial intelligence assistant…” stuff, etc. I still want to preserve all tool calling functions (Python, web search, image generation, etc.) and not break its multi-turn conversation.&lt;/p&gt;\\n\\n&lt;p&gt;Key needs:&lt;/p&gt;\\n\\n&lt;p&gt;– Non-destructive to function calling behavior&lt;/p&gt;\\n\\n&lt;p&gt;– Has to be runnable on Colab (no GPU locally)&lt;/p&gt;\\n\\n&lt;p&gt;- 0 Budget: No MonsterAPI or paid stuff&lt;/p&gt;\\n\\n&lt;p&gt;- Keep it small: Under 5GB (After being quantized to GGUF)&lt;/p&gt;\\n\\n&lt;p&gt;- Be able to be exported, converted to gguf, and run with ollama&lt;/p&gt;\\n\\n&lt;p&gt;I’m not doing instruction tuning from scratch, just style injection over chat data.&lt;/p&gt;\\n\\n&lt;p&gt;Any recommendations on a colab that can help me keep auxiliary functionality intact while customizing tone? I want to do basically what Just Rayan (On youtube) did, but with Phi4-Mini, and keeping tool calling functions.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m563lh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Witty_Mycologist_995","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/","subreddit_subscribers":502516,"created_utc":1753061780,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ddq6f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rnosov","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d25yl","score":1,"author_fullname":"t2_18x6fa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Model name - just change it to mini. Designing good reward function is not a trivial task. You can use your LLM of choice for help with coding but you'd likely still need to debug it. Could take a few days to find and test good classifier then plug it in to reward function. This is how big AI labs steer their models.","edited":false,"author_flair_css_class":null,"name":"t1_n4ddq6f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Model name - just change it to mini. Designing good reward function is not a trivial task. You can use your LLM of choice for help with coding but you&amp;#39;d likely still need to debug it. Could take a few days to find and test good classifier then plug it in to reward function. This is how big AI labs steer their models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m563lh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/n4ddq6f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753117299,"author_flair_text":null,"collapsed":false,"created_utc":1753117299,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d25yl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Witty_Mycologist_995","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4acysd","score":1,"author_fullname":"t2_afskfa1c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"oh alr. but still, you gave me phi4 notebook instead of phi4-mini notebook what do i do. also how do i set up a reward function for style?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4d25yl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh alr. but still, you gave me phi4 notebook instead of phi4-mini notebook what do i do. also how do i set up a reward function for style?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m563lh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/n4d25yl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753114072,"author_flair_text":null,"treatment_tags":[],"created_utc":1753114072,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4acysd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rnosov","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4a6o0a","score":1,"author_fullname":"t2_18x6fa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can use regular unsloth SFT notebook but it will slowly damage the model unless you're extremely careful. Most \\"creative\\" fine-tunes are normally quite dumb. You'd need to add examples of behaviour you want to preserve like function calling, math etc maybe do healmerge afterwards. GRPO or RL in general can change style without affecting underlying model capabilities.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4acysd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can use regular unsloth SFT notebook but it will slowly damage the model unless you&amp;#39;re extremely careful. Most &amp;quot;creative&amp;quot; fine-tunes are normally quite dumb. You&amp;#39;d need to add examples of behaviour you want to preserve like function calling, math etc maybe do healmerge afterwards. GRPO or RL in general can change style without affecting underlying model capabilities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m563lh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/n4acysd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753072651,"author_flair_text":null,"treatment_tags":[],"created_utc":1753072651,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4a6o0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Witty_Mycologist_995","can_mod_post":false,"created_utc":1753069850,"send_replies":true,"parent_id":"t1_n49xo1g","score":1,"author_fullname":"t2_afskfa1c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"no i mean something similar to what justrayan did: i have a set of user, assistant response pairs. how to finetune my model with that, without causing the model to forget how to use tools. also, the notebook you sent me is for phi4, not phi4-mini.","edited":1753072008,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a6o0a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no i mean something similar to what justrayan did: i have a set of user, assistant response pairs. how to finetune my model with that, without causing the model to forget how to use tools. also, the notebook you sent me is for phi4, not phi4-mini.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m563lh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/n4a6o0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753069850,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49xo1g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rnosov","can_mod_post":false,"created_utc":1753066174,"send_replies":true,"parent_id":"t3_1m563lh","score":1,"author_fullname":"t2_18x6fa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Add your model in this [GRPO notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb) and change the reward function to run a classifier that can detect tone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49xo1g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Add your model in this &lt;a href=\\"https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B\\"&gt;GRPO notebook&lt;/a&gt;-GRPO.ipynb) and change the reward function to run a classifier that can detect tone.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m563lh/help_with_finetuning_phi4mini/n49xo1g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066174,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m563lh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),i=()=>e.jsx(l,{data:t});export{i as default};
