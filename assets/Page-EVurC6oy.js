import{j as e}from"./index-BpC9hjVs.js";import{R as t}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"*^(#I'm starting a new series of explaining intriguing new AI papers)*\\n\\nLLMs learn from text and lack an inherent understanding of the physical world. Their \\"knowledge\\" is **mostly** limited to what's been described in the text they were trained on. This means they mostly struggle with concepts that are not easily described in words, like how objects move, interact, and deform over time. This is a form of \\"common sense\\" that is impossible to acquire from text alone.\\n\\nDuring training, the goal of LLM is to predict the following word in a sentence, given the preceding words. By learning to generate the appropriate next word, grammar knowledge and semantics emerge in the model, as those abilities are necessary for understanding which word will follow in a sentence. \\n\\nWhy not to apply this self-supervised approach for teaching AI how life works via videos? \\n\\nTake all the videos on the internet, randomly mask video-frames, and challenge the generating model to learn to accurately recover(reconstruct) the masked parts of the video-frames, so during training, the need of learning to predict what is happening in the masked parts of the videos, will develop the intuitive understanding of physics and in general how the world works. \\n\\nBut, for example, if in a video, a cup turns over, and we challenge the model to recover the masked part,  the model should predict the precise location of each falling droplet, as the generative objective expects pixel-level precision.  And because we are challenging the model to do the impossible, the learning process will just collapse.\\n\\nLet's see how Meta approaches this issue [https://arxiv.org/pdf/2506.09985](https://arxiv.org/pdf/2506.09985)\\n\\nTheir new architecture, called V-JEPA 2, consists of an encoder and a predictor.\\n\\n**encoder** takes in raw video-frames and outputs embeddings that capture useful semantic information about the state of the observed world.\\n\\nIn other words, it learns to extract the predictable aspects of a scene, for example, the approximate trajectory of the falling water, and does not get bogged down into the unpredictable, tiny details of every single pixel.  So that the predictor learns to predict the high-level process that happens in the masked region of the video. *(see until 0:07 in the video)*\\n\\nThis helps the model to underpin a high-level understanding of how life works, which opens the possibility to finally train truly generally intelligent robots that don’t do impressive actions just for show in specific cases. So, in the post-training stage, they train on videos that show a robotic arm’s interaction.\\n\\nThis time, they encode part of a video and also give information about robot’s intended action in the last video-frame and train the model to predict what will happen at high-level in the following video-frames. *(see 0:08 to 0:16 in the video)*\\n\\nSo, by predicting what will happen next, given the intended action, it learns to predict the consequences of actions.\\n\\nAfter training, the robot, powered by this model,  in the latent space can imagine the consequence of various chain-of-action scenarios to find a sequence of actions whose predicted outcome matches the desired outcome.\\n\\nAnd for tasks requiring planning across multiple time scales, it needs to learn how to break down a high-level task into smaller steps, such as making food or loading a dishwasher. For that, the Meta team wants to train a hierarchical JEPA model that is capable of learning, reasoning, and planning across multiple temporal and spatial scales.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Next big thing after LLMs - World Model [explained on the example of V-JEPA2]","link_flair_richtext":[{"e":"text","t":"Tutorial | Guide"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":65,"top_awarded_type":null,"hide_score":false,"name":"t3_1m4mfs8","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.93,"author_flair_background_color":null,"ups":192,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_xvwcc","secure_media":{"reddit_video":{"bitrate_kbps":2400,"fallback_url":"https://v.redd.it/h0ivgtibj0ef1/DASH_720.mp4?source=fallback","has_audio":true,"height":600,"width":1280,"scrubber_media_url":"https://v.redd.it/h0ivgtibj0ef1/DASH_96.mp4","dash_url":"https://v.redd.it/h0ivgtibj0ef1/DASHPlaylist.mpd?a=1755738919%2COTdmZjYwM2QyZjg3OTFmZjNhNjM4ODQ5NWU2M2ViYjI4N2UyYmYxNTM5MTk5Y2E1NzdmMGM5ODc3MjZhZTJhMQ%3D%3D&amp;v=1&amp;f=sd","duration":21,"hls_url":"https://v.redd.it/h0ivgtibj0ef1/HLSPlaylist.m3u8?a=1755738919%2CM2Y0ZWViNzY0MjE2OWJiMzFmOWQzZDE2OWExMDYxNmM0YmZhMWRjYWZkNDgxZTNiZjY5Mjc5OTVmZTRmZjhmYQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Tutorial | Guide","can_mod_post":false,"score":192,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=140&amp;height=65&amp;crop=140:65,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=4a64686273ed8c2776f8df926696df24c9ce4cf6","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753010231,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;em&gt;&lt;sup&gt;#I&amp;#39;m starting a new series of explaining intriguing new AI papers&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;LLMs learn from text and lack an inherent understanding of the physical world. Their &amp;quot;knowledge&amp;quot; is &lt;strong&gt;mostly&lt;/strong&gt; limited to what&amp;#39;s been described in the text they were trained on. This means they mostly struggle with concepts that are not easily described in words, like how objects move, interact, and deform over time. This is a form of &amp;quot;common sense&amp;quot; that is impossible to acquire from text alone.&lt;/p&gt;\\n\\n&lt;p&gt;During training, the goal of LLM is to predict the following word in a sentence, given the preceding words. By learning to generate the appropriate next word, grammar knowledge and semantics emerge in the model, as those abilities are necessary for understanding which word will follow in a sentence. &lt;/p&gt;\\n\\n&lt;p&gt;Why not to apply this self-supervised approach for teaching AI how life works via videos? &lt;/p&gt;\\n\\n&lt;p&gt;Take all the videos on the internet, randomly mask video-frames, and challenge the generating model to learn to accurately recover(reconstruct) the masked parts of the video-frames, so during training, the need of learning to predict what is happening in the masked parts of the videos, will develop the intuitive understanding of physics and in general how the world works. &lt;/p&gt;\\n\\n&lt;p&gt;But, for example, if in a video, a cup turns over, and we challenge the model to recover the masked part,  the model should predict the precise location of each falling droplet, as the generative objective expects pixel-level precision.  And because we are challenging the model to do the impossible, the learning process will just collapse.&lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s see how Meta approaches this issue &lt;a href=\\"https://arxiv.org/pdf/2506.09985\\"&gt;https://arxiv.org/pdf/2506.09985&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Their new architecture, called V-JEPA 2, consists of an encoder and a predictor.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;encoder&lt;/strong&gt; takes in raw video-frames and outputs embeddings that capture useful semantic information about the state of the observed world.&lt;/p&gt;\\n\\n&lt;p&gt;In other words, it learns to extract the predictable aspects of a scene, for example, the approximate trajectory of the falling water, and does not get bogged down into the unpredictable, tiny details of every single pixel.  So that the predictor learns to predict the high-level process that happens in the masked region of the video. &lt;em&gt;(see until 0:07 in the video)&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This helps the model to underpin a high-level understanding of how life works, which opens the possibility to finally train truly generally intelligent robots that don’t do impressive actions just for show in specific cases. So, in the post-training stage, they train on videos that show a robotic arm’s interaction.&lt;/p&gt;\\n\\n&lt;p&gt;This time, they encode part of a video and also give information about robot’s intended action in the last video-frame and train the model to predict what will happen at high-level in the following video-frames. &lt;em&gt;(see 0:08 to 0:16 in the video)&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;So, by predicting what will happen next, given the intended action, it learns to predict the consequences of actions.&lt;/p&gt;\\n\\n&lt;p&gt;After training, the robot, powered by this model,  in the latent space can imagine the consequence of various chain-of-action scenarios to find a sequence of actions whose predicted outcome matches the desired outcome.&lt;/p&gt;\\n\\n&lt;p&gt;And for tasks requiring planning across multiple time scales, it needs to learn how to break down a high-level task into smaller steps, such as making food or loading a dishwasher. For that, the Meta team wants to train a hierarchical JEPA model that is capable of learning, reasoning, and planning across multiple temporal and spatial scales.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/h0ivgtibj0ef1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?format=pjpg&amp;auto=webp&amp;s=6a8ec9b4980d9a40f31e6b1a7c7113057d70d42c","width":1920,"height":900},"resolutions":[{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=bd457375042fde995b2dbbbc85910bf0ffe7d88b","width":108,"height":50},{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=506b500241f56e40e0a1feebc362f80c5440bc81","width":216,"height":101},{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7f2f1446c77d923e99ffd8c175c55641539c9bb9","width":320,"height":150},{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=60a24c15686917cbed627c6f9aa1cd0d68bc6c1d","width":640,"height":300},{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4a674fb74efa796fcaa16cc6a4f6d5158ed3c8ab","width":960,"height":450},{"url":"https://external-preview.redd.it/bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e547aa9ee3bf8f5210ba9ff0685c84ce1099e4d7","width":1080,"height":506}],"variants":{},"id":"bzd6M2RyaWJqMGVmMazIDtYX-m4G2qSnSaRS5wvuc50lS7cqMTyw9S71POit"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"449b05a6-bf8e-11ed-b4bd-66961e47bd50","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#0079d3","id":"1m4mfs8","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"VR-Person","discussion_type":null,"num_comments":31,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":2400,"fallback_url":"https://v.redd.it/h0ivgtibj0ef1/DASH_720.mp4?source=fallback","has_audio":true,"height":600,"width":1280,"scrubber_media_url":"https://v.redd.it/h0ivgtibj0ef1/DASH_96.mp4","dash_url":"https://v.redd.it/h0ivgtibj0ef1/DASHPlaylist.mpd?a=1755738919%2COTdmZjYwM2QyZjg3OTFmZjNhNjM4ODQ5NWU2M2ViYjI4N2UyYmYxNTM5MTk5Y2E1NzdmMGM5ODc3MjZhZTJhMQ%3D%3D&amp;v=1&amp;f=sd","duration":21,"hls_url":"https://v.redd.it/h0ivgtibj0ef1/HLSPlaylist.m3u8?a=1755738919%2CM2Y0ZWViNzY0MjE2OWJiMzFmOWQzZDE2OWExMDYxNmM0YmZhMWRjYWZkNDgxZTNiZjY5Mjc5OTVmZTRmZjhmYQ%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/","stickied":false,"url":"https://v.redd.it/h0ivgtibj0ef1","subreddit_subscribers":502516,"created_utc":1753010231,"num_crossposts":0,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n487qve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n485ssi","score":3,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, I am not 100% of what they minimize, it is necessarily an error function, but it is probably incorrect to call it a loss.","edited":false,"author_flair_css_class":null,"name":"t1_n487qve","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, I am not 100% of what they minimize, it is necessarily an error function, but it is probably incorrect to call it a loss.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4mfs8","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n487qve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753044352,"author_flair_text":null,"collapsed":false,"created_utc":1753044352,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n485ssi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"moneyfake","can_mod_post":false,"send_replies":true,"parent_id":"t1_n484tfo","score":3,"author_fullname":"t2_4rbf5ddti","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I see but in gradient descent, the thing you are descenting on is a loss function, a concept strictly used in training so I was confused about that. I probably should just read the article, thanks though","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n485ssi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see but in gradient descent, the thing you are descenting on is a loss function, a concept strictly used in training so I was confused about that. I probably should just read the article, thanks though&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n485ssi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043753,"author_flair_text":null,"treatment_tags":[],"created_utc":1753043753,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n484tfo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n48422x","score":1,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If I get it right (50% chance honestly) you would find these parameters thanks to the inputs (in a LLM it would e.g. tell you the language and tone to use, in an image the likely color palette) and then use them during the generation. As I understand it would be a single pass to find them and then use them at generation.\\n\\nI have no idea how you are supposed to train such a thing however.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n484tfo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I get it right (50% chance honestly) you would find these parameters thanks to the inputs (in a LLM it would e.g. tell you the language and tone to use, in an image the likely color palette) and then use them during the generation. As I understand it would be a single pass to find them and then use them at generation.&lt;/p&gt;\\n\\n&lt;p&gt;I have no idea how you are supposed to train such a thing however.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n484tfo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043452,"author_flair_text":null,"treatment_tags":[],"created_utc":1753043452,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n48422x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"moneyfake","can_mod_post":false,"created_utc":1753043220,"send_replies":true,"parent_id":"t1_n462fa4","score":2,"author_fullname":"t2_4rbf5ddti","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; During inference, the parameters of the world **are found through gradient descent**.\\n\\nGradient descent during inference? How does that work, are there parameters being updated during inference (meaning constantly)?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48422x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;During inference, the parameters of the world &lt;strong&gt;are found through gradient descent&lt;/strong&gt;.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Gradient descent during inference? How does that work, are there parameters being updated during inference (meaning constantly)?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n48422x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043220,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48477w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ObjectSmooth8899","can_mod_post":false,"send_replies":true,"parent_id":"t1_n471c5v","score":3,"author_fullname":"t2_1hzvi4fxua","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Scaling the current models, whether in parameters, test time compute, or whatever, only prevents us from realizing their inherent limitations. Models don't really think, they don't really reason. They just seem to work, until they fail because they only predict text. The method is wrong, We need something better than an LLM or something complementary to an LLM that actually reasons.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48477w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Scaling the current models, whether in parameters, test time compute, or whatever, only prevents us from realizing their inherent limitations. Models don&amp;#39;t really think, they don&amp;#39;t really reason. They just seem to work, until they fail because they only predict text. The method is wrong, We need something better than an LLM or something complementary to an LLM that actually reasons.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n48477w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043264,"author_flair_text":null,"treatment_tags":[],"created_utc":1753043264,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cud7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ilovekittens345","can_mod_post":false,"send_replies":true,"parent_id":"t1_n471c5v","score":1,"author_fullname":"t2_i6wlmca3l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's all good and well but there is currently no mechanism active in LLM's to give them any agency and they are inherently not able to differentiate between their own thoughts, owner's thoughts and users thoughts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cud7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s all good and well but there is currently no mechanism active in LLM&amp;#39;s to give them any agency and they are inherently not able to differentiate between their own thoughts, owner&amp;#39;s thoughts and users thoughts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n4cud7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753111864,"author_flair_text":null,"treatment_tags":[],"created_utc":1753111864,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n471c5v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"keepthepace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46kc5r","score":5,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep. Looks cool on paper, but proposing a new architecture in the current climate is going to be a hard sale with all the progress regular transformers have received.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n471c5v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep. Looks cool on paper, but proposing a new architecture in the current climate is going to be a hard sale with all the progress regular transformers have received.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n471c5v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031399,"author_flair_text":null,"treatment_tags":[],"created_utc":1753031399,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n46kc5r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AmazinglyObliviouse","can_mod_post":false,"created_utc":1753026281,"send_replies":true,"parent_id":"t1_n462fa4","score":5,"author_fullname":"t2_c1qzfso6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The theory behind it sounds cool and all, but the benchmarks show such small improvements that it feels like it doesn't really matter. Additionally, meta has skillfully avoided using any jepa models for their vlms, which is kinda weird too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46kc5r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The theory behind it sounds cool and all, but the benchmarks show such small improvements that it feels like it doesn&amp;#39;t really matter. Additionally, meta has skillfully avoided using any jepa models for their vlms, which is kinda weird too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46kc5r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753026281,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n462fa4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"keepthepace","can_mod_post":false,"created_utc":1753020598,"send_replies":true,"parent_id":"t3_1m4mfs8","score":22,"author_fullname":"t2_63vtw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"These images and text fail to convey what I personally find the most interesting in these models. I'll try with my own words but I don't feel 100% that I am being accurate:\\n\\nThe goal of JEPA is to train a model that manages to makes the difference between the invariants of the world (e.g. \\"if the room is dark, all the parts of the image are likely to have lower brightness and contrast\\") and parameters of the world (e.g. \\"the room is dark\\")\\n\\nDuring inference, the parameters of the world **are found through gradient descent**. I feel this is what makes this architecture fundamentally different. During training, parameters are allowed to \\"float\\" to focus on the hard constraints of the world.\\n\\nThe goal is, for instance in a LLM, if you are training \\"The capital of France is &lt;Paris&gt;\\" to not penalize answers like \\"the city of Paris\\" and recognize that they are the same answer at different levels of verbosity.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n462fa4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These images and text fail to convey what I personally find the most interesting in these models. I&amp;#39;ll try with my own words but I don&amp;#39;t feel 100% that I am being accurate:&lt;/p&gt;\\n\\n&lt;p&gt;The goal of JEPA is to train a model that manages to makes the difference between the invariants of the world (e.g. &amp;quot;if the room is dark, all the parts of the image are likely to have lower brightness and contrast&amp;quot;) and parameters of the world (e.g. &amp;quot;the room is dark&amp;quot;)&lt;/p&gt;\\n\\n&lt;p&gt;During inference, the parameters of the world &lt;strong&gt;are found through gradient descent&lt;/strong&gt;. I feel this is what makes this architecture fundamentally different. During training, parameters are allowed to &amp;quot;float&amp;quot; to focus on the hard constraints of the world.&lt;/p&gt;\\n\\n&lt;p&gt;The goal is, for instance in a LLM, if you are training &amp;quot;The capital of France is &amp;lt;Paris&amp;gt;&amp;quot; to not penalize answers like &amp;quot;the city of Paris&amp;quot; and recognize that they are the same answer at different levels of verbosity.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n462fa4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753020598,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45d99p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VR-Person","can_mod_post":false,"created_utc":1753010532,"send_replies":true,"parent_id":"t3_1m4mfs8","score":10,"author_fullname":"t2_xvwcc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/abe0ysjbk0ef1.png?width=1252&amp;format=png&amp;auto=webp&amp;s=eac7e1d1e372e9cc00f173bc19e65a8a255a2dcb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45d99p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/abe0ysjbk0ef1.png?width=1252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eac7e1d1e372e9cc00f173bc19e65a8a255a2dcb\\"&gt;https://preview.redd.it/abe0ysjbk0ef1.png?width=1252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eac7e1d1e372e9cc00f173bc19e65a8a255a2dcb&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45d99p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753010532,"media_metadata":{"abe0ysjbk0ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":51,"x":108,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=506f8d2823cdba1855ae1d85024fdbd15ad317a1"},{"y":102,"x":216,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a9f5b24d55d4c3c8d206a7401e52bfb4ec89fad"},{"y":152,"x":320,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7b82be9c2b372dde2653f35209bbbdf8b7ac55b"},{"y":304,"x":640,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f319098669cbb68be13d2f11838102c7226a7d8"},{"y":456,"x":960,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=70c51a9e093e23010f4796779d66843a4aa1b017"},{"y":513,"x":1080,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=33cf29e8eed41b4ebe9e55737072950ed91f3681"}],"s":{"y":595,"x":1252,"u":"https://preview.redd.it/abe0ysjbk0ef1.png?width=1252&amp;format=png&amp;auto=webp&amp;s=eac7e1d1e372e9cc00f173bc19e65a8a255a2dcb"},"id":"abe0ysjbk0ef1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47bt8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"created_utc":1753034450,"send_replies":true,"parent_id":"t1_n45eojd","score":3,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cant blame him for trying new things.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47bt8k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cant blame him for trying new things.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n47bt8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753034450,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n45eojd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"swaglord1k","can_mod_post":false,"created_utc":1753011246,"send_replies":true,"parent_id":"t3_1m4mfs8","score":25,"author_fullname":"t2_jn77d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"go to bed yann","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45eojd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;go to bed yann&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45eojd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753011246,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45gpnu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wooden-guy","can_mod_post":false,"created_utc":1753012217,"send_replies":true,"parent_id":"t3_1m4mfs8","score":8,"author_fullname":"t2_16to413y2o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah man thank god that shit sucks now cause I'm still fucked till now from veo 3.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45gpnu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah man thank god that shit sucks now cause I&amp;#39;m still fucked till now from veo 3.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45gpnu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753012217,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n467ljp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"custodiam99","can_mod_post":false,"created_utc":1753022308,"send_replies":true,"parent_id":"t3_1m4mfs8","score":3,"author_fullname":"t2_nqnhgqqf5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Converting real world visual and spatio-temporal experiences into structured text - that would be nice.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n467ljp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Converting real world visual and spatio-temporal experiences into structured text - that would be nice.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n467ljp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753022308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45dl3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VR-Person","can_mod_post":false,"created_utc":1753010697,"send_replies":true,"parent_id":"t3_1m4mfs8","score":9,"author_fullname":"t2_xvwcc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/cz5cws8mk0ef1.png?width=1213&amp;format=png&amp;auto=webp&amp;s=333dd28336865a69e73cc935e2e6009d4f77b1c8\\n\\nRobots 0-shot benchmark: does not look impressive, but promising direction for building robots with general knowledge, instead of training robots to do specific actions in specific environments","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45dl3z","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/cz5cws8mk0ef1.png?width=1213&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=333dd28336865a69e73cc935e2e6009d4f77b1c8\\"&gt;https://preview.redd.it/cz5cws8mk0ef1.png?width=1213&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=333dd28336865a69e73cc935e2e6009d4f77b1c8&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Robots 0-shot benchmark: does not look impressive, but promising direction for building robots with general knowledge, instead of training robots to do specific actions in specific environments&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45dl3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753010697,"media_metadata":{"cz5cws8mk0ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":25,"x":108,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5402bd3a8372dcf60bb88b6429626a2581d711fb"},{"y":51,"x":216,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e18c09331de1c9d1f4c3ae4940a7d4afcf66862c"},{"y":77,"x":320,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd712c8660a94975c0be22e8683939e7f4b83234"},{"y":154,"x":640,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8963db30308c5199c504afd1ddd2398e4a059685"},{"y":231,"x":960,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a93b0c02017ef03e13d989b0ba80c515a38c16e1"},{"y":259,"x":1080,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=84f1e62ea9f94cf7e9ced52de06d87ca2be4d292"}],"s":{"y":292,"x":1213,"u":"https://preview.redd.it/cz5cws8mk0ef1.png?width=1213&amp;format=png&amp;auto=webp&amp;s=333dd28336865a69e73cc935e2e6009d4f77b1c8"},"id":"cz5cws8mk0ef1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n465kfc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n464oq8","score":1,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unless I am mistaken, the training procedure is very different isn't it?","edited":false,"author_flair_css_class":null,"name":"t1_n465kfc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless I am mistaken, the training procedure is very different isn&amp;#39;t it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4mfs8","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n465kfc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021644,"author_flair_text":null,"collapsed":false,"created_utc":1753021644,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n464oq8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VR-Person","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4608xm","score":2,"author_fullname":"t2_xvwcc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They still use transformers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n464oq8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They still use transformers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n464oq8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021353,"author_flair_text":null,"treatment_tags":[],"created_utc":1753021353,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4608xm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"keepthepace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45uqom","score":1,"author_fullname":"t2_63vtw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a bit too small to make people switch from transformers.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4608xm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a bit too small to make people switch from transformers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n4608xm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019854,"author_flair_text":null,"treatment_tags":[],"created_utc":1753019854,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n45uqom","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VR-Person","can_mod_post":false,"created_utc":1753017892,"send_replies":true,"parent_id":"t1_n45t5ur","score":2,"author_fullname":"t2_xvwcc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/uza1wbsj51ef1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=fe2760110e0693dd46df8a087c3d3fc5523b7567\\n\\nScaling the model size from 300M to 1B parameters yields a +1.7 point average improvement","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45uqom","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/uza1wbsj51ef1.png?width=1250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fe2760110e0693dd46df8a087c3d3fc5523b7567\\"&gt;https://preview.redd.it/uza1wbsj51ef1.png?width=1250&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fe2760110e0693dd46df8a087c3d3fc5523b7567&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Scaling the model size from 300M to 1B parameters yields a +1.7 point average improvement&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45uqom/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753017892,"media_metadata":{"uza1wbsj51ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":36,"x":108,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c74be6089355b5fd953ab8801f25b4f1ef120386"},{"y":72,"x":216,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=471859315d5473d26410e3342f8a53a46c08f3d7"},{"y":107,"x":320,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c2f904280a8e8b20b08b881bc2a00a86a09834d"},{"y":215,"x":640,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd6e11a90d5f3c4ef649e360d83f10221aaadc32"},{"y":323,"x":960,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=43985fc949f65c11fd3ed6ddb7970fa9352673b9"},{"y":363,"x":1080,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c2cfec13a4aa737a7fe556a6b8bbf13d0b42ddb"}],"s":{"y":421,"x":1250,"u":"https://preview.redd.it/uza1wbsj51ef1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=fe2760110e0693dd46df8a087c3d3fc5523b7567"},"id":"uza1wbsj51ef1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n45t5ur","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"30299578815310","can_mod_post":false,"created_utc":1753017309,"send_replies":true,"parent_id":"t3_1m4mfs8","score":4,"author_fullname":"t2_6pkxsu2c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They've been publishing stuff about Jepa for a while but no frontier models seem to use it, including meta's own models, which makes me wonder if it actually scales","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45t5ur","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;ve been publishing stuff about Jepa for a while but no frontier models seem to use it, including meta&amp;#39;s own models, which makes me wonder if it actually scales&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45t5ur/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753017309,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45dqgp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VR-Person","can_mod_post":false,"created_utc":1753010771,"send_replies":true,"parent_id":"t3_1m4mfs8","score":6,"author_fullname":"t2_xvwcc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/vf09d3j1l0ef1.png?width=1242&amp;format=png&amp;auto=webp&amp;s=2047a5c22b1b27daee8cc791a007999b9215ea29","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45dqgp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/vf09d3j1l0ef1.png?width=1242&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2047a5c22b1b27daee8cc791a007999b9215ea29\\"&gt;https://preview.redd.it/vf09d3j1l0ef1.png?width=1242&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2047a5c22b1b27daee8cc791a007999b9215ea29&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45dqgp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753010771,"media_metadata":{"vf09d3j1l0ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":14,"x":108,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c67bb81e19bb7a6a542be0f42ad5a574ea1fbe9"},{"y":29,"x":216,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=54b50cf8d4a62a7853788bf258b4d976cde11982"},{"y":43,"x":320,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d43abe3db493d4507245a79597d1f717b25b20e3"},{"y":86,"x":640,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a160908e608364fa356dd532ebb7be31b9768a36"},{"y":129,"x":960,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=13b97e07d838c06335cc3dab28a5bcf89d03933c"},{"y":146,"x":1080,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32decc89a1b56bf06b38e28fda240ac058bcda50"}],"s":{"y":168,"x":1242,"u":"https://preview.redd.it/vf09d3j1l0ef1.png?width=1242&amp;format=png&amp;auto=webp&amp;s=2047a5c22b1b27daee8cc791a007999b9215ea29"},"id":"vf09d3j1l0ef1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46e9dp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"custodiam99","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46do3d","score":5,"author_fullname":"t2_nqnhgqqf5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No, we did not encode it. They cannot create spatio-temporally realistic new information during inferencing, so they are just creating a very probable general verbal sequence. We need the spatio-temporal causal network of that created information, but it can be provided only by a non-LLM AI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46e9dp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, we did not encode it. They cannot create spatio-temporally realistic new information during inferencing, so they are just creating a very probable general verbal sequence. We need the spatio-temporal causal network of that created information, but it can be provided only by a non-LLM AI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46e9dp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753024430,"author_flair_text":null,"treatment_tags":[],"created_utc":1753024430,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n46do3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ParaboloidalCrest","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46c4iv","score":2,"author_fullname":"t2_nc2u4f7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And maybe LLMs don't even need to have it. We've already encoded physics into text and LLMs can just take advantage of that without the background work.\\n\\nBesides, not all physics can be visualized. post-Newton physics theories are hard to imagine/visualize by most people","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46do3d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And maybe LLMs don&amp;#39;t even need to have it. We&amp;#39;ve already encoded physics into text and LLMs can just take advantage of that without the background work.&lt;/p&gt;\\n\\n&lt;p&gt;Besides, not all physics can be visualized. post-Newton physics theories are hard to imagine/visualize by most people&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46do3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753024245,"author_flair_text":null,"treatment_tags":[],"created_utc":1753024245,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n46c4iv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"custodiam99","can_mod_post":false,"created_utc":1753023760,"send_replies":true,"parent_id":"t1_n46a6i4","score":8,"author_fullname":"t2_nqnhgqqf5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because you have non-verbal spatio-temporal mental relations and imagery in the background. LLMs don't have that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46c4iv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because you have non-verbal spatio-temporal mental relations and imagery in the background. LLMs don&amp;#39;t have that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46c4iv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753023760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n46a6i4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ParaboloidalCrest","can_mod_post":false,"created_utc":1753023139,"send_replies":true,"parent_id":"t3_1m4mfs8","score":2,"author_fullname":"t2_nc2u4f7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm kind of skeptical, given that Physics \\"text\\"books are the fattest out there. We learn physics via text and practice it, primarily, by solving text problems. You don't need a physics simulator to \\"see\\" how fast a hammer falls out of a window, you can just calculate it.\\n\\nA pretty awkward wheel is being re-invented here.","edited":1753023603,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46a6i4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m kind of skeptical, given that Physics &amp;quot;text&amp;quot;books are the fattest out there. We learn physics via text and practice it, primarily, by solving text problems. You don&amp;#39;t need a physics simulator to &amp;quot;see&amp;quot; how fast a hammer falls out of a window, you can just calculate it.&lt;/p&gt;\\n\\n&lt;p&gt;A pretty awkward wheel is being re-invented here.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46a6i4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753023139,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45wqnm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VR-Person","can_mod_post":false,"created_utc":1753018622,"send_replies":true,"parent_id":"t1_n45vl38","score":3,"author_fullname":"t2_xvwcc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"V-JEPA2 is just the first step for robotics yet. They did not even build an action model, and the model predicts the consequence of randomly chosen sets of actions.\\n\\nThis solution is not practical for robotics, but it is a promising direction","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45wqnm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;V-JEPA2 is just the first step for robotics yet. They did not even build an action model, and the model predicts the consequence of randomly chosen sets of actions.&lt;/p&gt;\\n\\n&lt;p&gt;This solution is not practical for robotics, but it is a promising direction&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4mfs8","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45wqnm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018622,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n45vl38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Needleworker_5247","can_mod_post":false,"created_utc":1753018202,"send_replies":true,"parent_id":"t3_1m4mfs8","score":2,"author_fullname":"t2_1gmprv51a1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This concept of using world models could revolutionize robotics, but the challenge remains in achieving nuanced prediction and action. What's crucial is how these models adapt in real-world settings with complex, unexpected variables. Can V-JEPA 2 handle such unpredictability without vast computational resources? It's promising, but real-world applications will test its limits. Interested in how it'll evolve and integrate with existing AI systems.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45vl38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This concept of using world models could revolutionize robotics, but the challenge remains in achieving nuanced prediction and action. What&amp;#39;s crucial is how these models adapt in real-world settings with complex, unexpected variables. Can V-JEPA 2 handle such unpredictability without vast computational resources? It&amp;#39;s promising, but real-world applications will test its limits. Interested in how it&amp;#39;ll evolve and integrate with existing AI systems.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45vl38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018202,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n467cz5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bladestorm91","can_mod_post":false,"created_utc":1753022230,"send_replies":true,"parent_id":"t3_1m4mfs8","score":2,"author_fullname":"t2_fg234","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really wish they would release LANG-JEPA soon-ish, the video and image JEPA models are cool and all, but that is primarily useful for robotics, not us regular people.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n467cz5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really wish they would release LANG-JEPA soon-ish, the video and image JEPA models are cool and all, but that is primarily useful for robotics, not us regular people.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n467cz5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753022230,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46vljp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celzo1776","can_mod_post":false,"created_utc":1753029701,"send_replies":true,"parent_id":"t3_1m4mfs8","score":-1,"author_fullname":"t2_u4u06q8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://ai-2027.com/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46vljp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://ai-2027.com/\\"&gt;https://ai-2027.com/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n46vljp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029701,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n478u4r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Comrade_Vodkin","can_mod_post":false,"created_utc":1753033582,"send_replies":true,"parent_id":"t3_1m4mfs8","score":0,"author_fullname":"t2_wa8ul","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ЖЕПА (sorry)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n478u4r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ЖЕПА (sorry)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n478u4r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033582,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45js7g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1753013583,"send_replies":true,"parent_id":"t3_1m4mfs8","score":-11,"author_fullname":"t2_1by73qs5e5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"I've heard of world models before. The name is too stupid to take it seriously. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45js7g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve heard of world models before. The name is too stupid to take it seriously. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4mfs8/next_big_thing_after_llms_world_model_explained/n45js7g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753013583,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4mfs8","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-11}}],"before":null}}]`),o=()=>e.jsx(t,{data:a});export{o as default};
