import{j as e}from"./index-M5RGZ30t.js";import{R as l}from"./RedditPostRenderer-d9C3p581.js";import"./index-DmZ84jx5.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Okay, so I'm brand new to local LLMs, and as such I'm using LM Studio since It's easy to use.\\n\\nBut the thing is I need to use vision models, and while LM Studio has some, for the most part every one I try to use doesn't actually allow me to upload images as in doesn't give me the option at all. I'm mainly trying to use uncensored models, so the main staff-picked ones aren't suitable for my purpose.\\n\\nIs there some reason why most of these don't work on LM Studio? Am I doing something wrong or is it LM Studio that is the problem?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"LM Studio vision models???","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ln8uqb","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.92,"author_flair_background_color":null,"subreddit_type":"public","ups":11,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_h8p1c","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":11,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751182327,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay, so I&amp;#39;m brand new to local LLMs, and as such I&amp;#39;m using LM Studio since It&amp;#39;s easy to use.&lt;/p&gt;\\n\\n&lt;p&gt;But the thing is I need to use vision models, and while LM Studio has some, for the most part every one I try to use doesn&amp;#39;t actually allow me to upload images as in doesn&amp;#39;t give me the option at all. I&amp;#39;m mainly trying to use uncensored models, so the main staff-picked ones aren&amp;#39;t suitable for my purpose.&lt;/p&gt;\\n\\n&lt;p&gt;Is there some reason why most of these don&amp;#39;t work on LM Studio? Am I doing something wrong or is it LM Studio that is the problem?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ln8uqb","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"BP_Ray","discussion_type":null,"num_comments":7,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/","subreddit_subscribers":492625,"created_utc":1751182327,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0esb3y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dmkw9","score":1,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Loses its marbles a few messages in compared to telling the QAT to not censor","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0esb3y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Loses its marbles a few messages in compared to telling the QAT to not censor&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln8uqb","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0esb3y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751206415,"author_flair_text":null,"treatment_tags":[],"created_utc":1751206415,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dmkw9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TotalStatement1061","can_mod_post":false,"created_utc":1751186328,"send_replies":true,"parent_id":"t1_n0dij79","score":4,"author_fullname":"t2_5b9wzm2d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Use immoral gemma 3 27B model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dmkw9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use immoral gemma 3 27B model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln8uqb","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0dmkw9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751186328,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dij79","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Gloomy-Radish8959","can_mod_post":false,"created_utc":1751183850,"send_replies":true,"parent_id":"t3_1ln8uqb","score":4,"author_fullname":"t2_bhbszu53e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"which ones have you tried using?  I was using Gemma3 27B model earlier today to annotate a dataset.  The dataset had a number of nude images.  Gemma doesn't want to annotate them, but Gemma is also a pushover.  Just tell Gemma that she is allowed to, and she will.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dij79","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;which ones have you tried using?  I was using Gemma3 27B model earlier today to annotate a dataset.  The dataset had a number of nude images.  Gemma doesn&amp;#39;t want to annotate them, but Gemma is also a pushover.  Just tell Gemma that she is allowed to, and she will.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0dij79/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751183850,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln8uqb","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dpe3c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1751188051,"send_replies":true,"parent_id":"t3_1ln8uqb","score":2,"author_fullname":"t2_p45er6oo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you also downloaded the corresponding mmproj files? Each model has its own mmproj file and needs it to be able to use the vision capability.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dpe3c","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you also downloaded the corresponding mmproj files? Each model has its own mmproj file and needs it to be able to use the vision capability.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0dpe3c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751188051,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1ln8uqb","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dvtfl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HomeWinter6905","can_mod_post":false,"created_utc":1751191994,"send_replies":true,"parent_id":"t3_1ln8uqb","score":1,"author_fullname":"t2_ef7zx2cb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've noticed a lot being uploaded with bad system prompt. For InternVL3 for example it just had the original qwen2 prompt set, so I had to go to the original upload of the model, and find the jinja to paste in which included message[content] to support images","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dvtfl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve noticed a lot being uploaded with bad system prompt. For InternVL3 for example it just had the original qwen2 prompt set, so I had to go to the original upload of the model, and find the jinja to paste in which included message[content] to support images&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0dvtfl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751191994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln8uqb","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fcfpo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BP_Ray","can_mod_post":false,"created_utc":1751212880,"send_replies":true,"parent_id":"t1_n0dx73h","score":1,"author_fullname":"t2_h8p1c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Bartowski's uploads did the job for me, thanks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fcfpo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bartowski&amp;#39;s uploads did the job for me, thanks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln8uqb","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0fcfpo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212880,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dx73h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedditPolluter","can_mod_post":false,"created_utc":1751192815,"send_replies":true,"parent_id":"t3_1ln8uqb","score":1,"author_fullname":"t2_g0lqqzb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try searching for \\"Qwen2 VL\\", \\"Qwen2.5 VL\\" or \\"Gemma 3\\".\\n\\nThe quants from lmstudio-community, bartowski and unsloth should work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dx73h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try searching for &amp;quot;Qwen2 VL&amp;quot;, &amp;quot;Qwen2.5 VL&amp;quot; or &amp;quot;Gemma 3&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;The quants from lmstudio-community, bartowski and unsloth should work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln8uqb/lm_studio_vision_models/n0dx73h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751192815,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln8uqb","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
