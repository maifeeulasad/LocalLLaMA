import{j as l}from"./index-BgwOAK4-.js";import{R as e}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Based on past threads from this sub, I see that below coding models are coming.\\n\\n1. Qwen3 Coder - [Recent thread](https://www.reddit.com/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/)\\n2. Deep Cogito - Preview models there\\n3. Polaris - Preview models there\\n4. Granite releasing any new coding models? Preview (General) models there for upcoming Version 4. How good is their existing coding models.\\n\\nWhat other coding models coming apart from above ones?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Upcoming Coding Models?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lobyx5","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.91,"author_flair_background_color":null,"subreddit_type":"public","ups":43,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1deiadfhb1","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":43,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751306279,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751300745,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Based on past threads from this sub, I see that below coding models are coming.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Qwen3 Coder - &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/\\"&gt;Recent thread&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Deep Cogito - Preview models there&lt;/li&gt;\\n&lt;li&gt;Polaris - Preview models there&lt;/li&gt;\\n&lt;li&gt;Granite releasing any new coding models? Preview (General) models there for upcoming Version 4. How good is their existing coding models.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;What other coding models coming apart from above ones?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lobyx5","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"pmttyji","discussion_type":null,"num_comments":13,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/","subreddit_subscribers":493242,"created_utc":1751300745,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pi0tx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dentuam","can_mod_post":false,"created_utc":1751345932,"send_replies":true,"parent_id":"t1_n0nrqu9","score":4,"author_fullname":"t2_znctr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"we all should have dreams. ðŸ˜‚","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pi0tx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;we all should have dreams. ðŸ˜‚&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lobyx5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0pi0tx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751345932,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pm010","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Namra_7","can_mod_post":false,"created_utc":1751347919,"send_replies":true,"parent_id":"t1_n0nrqu9","score":2,"author_fullname":"t2_1jzzgqlwn2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ðŸ˜‚ðŸ˜­","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pm010","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ðŸ˜‚ðŸ˜­&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lobyx5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0pm010/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347919,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nrqu9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jedisct1","can_mod_post":false,"created_utc":1751322936,"send_replies":true,"parent_id":"t3_1lobyx5","score":27,"author_fullname":"t2_7p6tw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We're all dreaming of an open model that could replace a Claude subscription.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nrqu9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;re all dreaming of an open model that could replace a Claude subscription.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0nrqu9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751322936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0n3v8n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cantgetthistowork","can_mod_post":false,"created_utc":1751315647,"send_replies":true,"parent_id":"t3_1lobyx5","score":5,"author_fullname":"t2_j1i0o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Devstral large\\n\\nR2","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0n3v8n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Devstral large&lt;/p&gt;\\n\\n&lt;p&gt;R2&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0n3v8n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751315647,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m66u6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Steuern_Runter","can_mod_post":false,"created_utc":1751305873,"send_replies":true,"parent_id":"t1_n0m3ciy","score":14,"author_fullname":"t2_w8pggsa4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Those are not coding models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m66u6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Those are not coding models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lobyx5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0m66u6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751305873,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m710v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pmttyji","can_mod_post":false,"created_utc":1751306103,"send_replies":true,"parent_id":"t1_n0m3ciy","score":1,"author_fullname":"t2_1deiadfhb1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So far no small size models from them. 0.3B .... then 21B .... and so on","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m710v","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So far no small size models from them. 0.3B .... then 21B .... and so on&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lobyx5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0m710v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306103,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0m3ciy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ProfessionUpbeat4500","can_mod_post":false,"created_utc":1751305102,"send_replies":true,"parent_id":"t3_1lobyx5","score":8,"author_fullname":"t2_h79wu0k74","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Baidu just released something...\\n\\nI just follow huggingface and the ceo on LinkedIn..easy to keep track of all the big news..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m3ciy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Baidu just released something...&lt;/p&gt;\\n\\n&lt;p&gt;I just follow huggingface and the ceo on LinkedIn..easy to keep track of all the big news..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0m3ciy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751305102,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0mv990","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ordinary_Mud7430","can_mod_post":false,"created_utc":1751313128,"send_replies":true,"parent_id":"t3_1lobyx5","score":5,"author_fullname":"t2_dmji1c74","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"CodeGemma?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0mv990","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;CodeGemma?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0mv990/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751313128,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0om8ys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jupiterbjy","can_mod_post":false,"created_utc":1751333355,"send_replies":true,"parent_id":"t1_n0m9vtw","score":3,"author_fullname":"t2_7ytuk99","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"didnt even know they made it, lemme leave a link and save others a search:\\n\\nhttps://huggingface.co/JetBrains/Mellum-4b-base","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0om8ys","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;didnt even know they made it, lemme leave a link and save others a search:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/JetBrains/Mellum-4b-base\\"&gt;https://huggingface.co/JetBrains/Mellum-4b-base&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lobyx5","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0om8ys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751333355,"author_flair_text":"Llama 3.1","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0m9vtw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emprahsFury","can_mod_post":false,"created_utc":1751306899,"send_replies":false,"parent_id":"t3_1lobyx5","score":6,"author_fullname":"t2_177r8n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jetbrains released their llm Mellum, onto HF. Its a 4b fim","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m9vtw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jetbrains released their llm Mellum, onto HF. Its a 4b fim&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0m9vtw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306899,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0m8kyh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fancyrocket","can_mod_post":false,"created_utc":1751306531,"send_replies":true,"parent_id":"t3_1lobyx5","score":2,"author_fullname":"t2_ghv87","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I too want to know this","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0m8kyh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I too want to know this&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0m8kyh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751306531,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0p3tkn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RobotRobotWhatDoUSee","can_mod_post":false,"created_utc":1751339800,"send_replies":true,"parent_id":"t3_1lobyx5","score":2,"author_fullname":"t2_m78cdz1nv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've been thinking a lot about this lately, this is maybe 1/3 of my motivation for my [earlier post](https://old.reddit.com/r/LocalLLaMA/comments/1l5zkdw/why_dont_we_see_more_technicallyoriented_clowncar/) about DIY MoE models. \\n\\nI've been doing a lot of reading since that post and at least conceptully feel like I've made a lot of progress. \\n\\nLife has been extremely busy lately and \\"implementation progress\\" has been slow, but I'd there is enough interest I'll post an update on that I've learned in the meanwhile.  \\n\\nMy first practical step will probably be to train up a small 3B or 4B coding model, which funny enough I see was also [asked about](https://old.reddit.com/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/) on the front page (of /r/localllama) today.\\n\\nOne other model you might add to your list: NVIDIA's [Llama 3.1 Nemotron Nano 4B](https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1)\\n\\n**Edit:** Well, actually, it looks like this one is probably not post-trained for coding so probably not intended for programming:\\n\\n&gt; Llama-3.1-Nemotron-Nano-4B-v1.1 is a large language model (LLM) which is a derivative of nvidia/Llama-3.1-Minitron-4B-Width-Base, which is created from Llama 3.1 8B using our LLM compression technique and offers improvements in model accuracy and efficiency. It is a reasoning model that is post trained for reasoning, human chat preferences, and tasks, such as RAG and tool calling.","edited":1751340009,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0p3tkn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve been thinking a lot about this lately, this is maybe 1/3 of my motivation for my &lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1l5zkdw/why_dont_we_see_more_technicallyoriented_clowncar/\\"&gt;earlier post&lt;/a&gt; about DIY MoE models. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been doing a lot of reading since that post and at least conceptully feel like I&amp;#39;ve made a lot of progress. &lt;/p&gt;\\n\\n&lt;p&gt;Life has been extremely busy lately and &amp;quot;implementation progress&amp;quot; has been slow, but I&amp;#39;d there is enough interest I&amp;#39;ll post an update on that I&amp;#39;ve learned in the meanwhile.  &lt;/p&gt;\\n\\n&lt;p&gt;My first practical step will probably be to train up a small 3B or 4B coding model, which funny enough I see was also &lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1lo5vnf/what_is_the_current_best_local_coding_model_with/\\"&gt;asked about&lt;/a&gt; on the front page (of &lt;a href=\\"/r/localllama\\"&gt;/r/localllama&lt;/a&gt;) today.&lt;/p&gt;\\n\\n&lt;p&gt;One other model you might add to your list: NVIDIA&amp;#39;s &lt;a href=\\"https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1\\"&gt;Llama 3.1 Nemotron Nano 4B&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; Well, actually, it looks like this one is probably not post-trained for coding so probably not intended for programming:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Llama-3.1-Nemotron-Nano-4B-v1.1 is a large language model (LLM) which is a derivative of nvidia/Llama-3.1-Minitron-4B-Width-Base, which is created from Llama 3.1 8B using our LLM compression technique and offers improvements in model accuracy and efficiency. It is a reasoning model that is post trained for reasoning, human chat preferences, and tasks, such as RAG and tool calling.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0p3tkn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751339800,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qlnxf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tempetemplar","can_mod_post":false,"created_utc":1751368132,"send_replies":true,"parent_id":"t3_1lobyx5","score":1,"author_fullname":"t2_atvw2aj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very excited with qwen 3 coder!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qlnxf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very excited with qwen 3 coder!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lobyx5/upcoming_coding_models/n0qlnxf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751368132,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lobyx5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>l.jsx(e,{data:a});export{n as default};
