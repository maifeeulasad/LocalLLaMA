import{j as e}from"./index-F0NXdzZX.js";import{R as t}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[https://github.com/Rivridis/Assistant-Client](https://github.com/Rivridis/Assistant-Client)\\n\\nOver the past few years, I have been developing a AI function calling agent, that can perfectly call functions with models as small as 3B or 7B parameters. Most of the frameworks I found while researching this topic just did not work with smaller, and non finetuned models. I tried llama-cpp openai, langchain and ollama but the function call success rate was disappointing for these small models.\\n\\nThe app can work with any LLM, no specific function calling finetunes needed. I took the suggestions from all the comments, and ported the UI to pyside from gradio. The app now comes in a desktop app format, and supports OpenAI API, so any models can be used. The models can be served from KoboldCPP or similar endpoints.\\n\\nThe current functions that it supports are search, music as well as weather. I tried to make it as easy to extend as possible, so feel free to add functions on top of it for your own use cases.\\n\\nIt also has a basic PDF query mode, as well as a code editor mode. \\n\\nThanks for all the support! If anyone has further ideas or improvements, please let me know. If anyone wants a tutorial or a guide, I shall provide that too.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"AI Assistant Agent with function calling - Update 2","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m0drwa","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.82,"author_flair_background_color":null,"subreddit_type":"public","ups":7,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_gs1v5r62","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":7,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752573750,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/Rivridis/Assistant-Client\\"&gt;https://github.com/Rivridis/Assistant-Client&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Over the past few years, I have been developing a AI function calling agent, that can perfectly call functions with models as small as 3B or 7B parameters. Most of the frameworks I found while researching this topic just did not work with smaller, and non finetuned models. I tried llama-cpp openai, langchain and ollama but the function call success rate was disappointing for these small models.&lt;/p&gt;\\n\\n&lt;p&gt;The app can work with any LLM, no specific function calling finetunes needed. I took the suggestions from all the comments, and ported the UI to pyside from gradio. The app now comes in a desktop app format, and supports OpenAI API, so any models can be used. The models can be served from KoboldCPP or similar endpoints.&lt;/p&gt;\\n\\n&lt;p&gt;The current functions that it supports are search, music as well as weather. I tried to make it as easy to extend as possible, so feel free to add functions on top of it for your own use cases.&lt;/p&gt;\\n\\n&lt;p&gt;It also has a basic PDF query mode, as well as a code editor mode. &lt;/p&gt;\\n\\n&lt;p&gt;Thanks for all the support! If anyone has further ideas or improvements, please let me know. If anyone wants a tutorial or a guide, I shall provide that too.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m0drwa","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Rivridis","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m0drwa/ai_assistant_agent_with_function_calling_update_2/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m0drwa/ai_assistant_agent_with_function_calling_update_2/","subreddit_subscribers":499774,"created_utc":1752573750,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3bfy51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Annual_Role_5066","can_mod_post":false,"created_utc":1752607901,"send_replies":true,"parent_id":"t3_1m0drwa","score":2,"author_fullname":"t2_7lqud3g7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've had similar frustrations with langchain - works great with GPT-4 but completely falls apart with local models. How's the reliabilty compared to just doing structured prompting? I've been manually parsing outputs lol\\n\\nThe PDF query + code editor combo is pretty cool, are you thinking of this more as a general productivity tool or specialized for certain workflows?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3bfy51","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve had similar frustrations with langchain - works great with GPT-4 but completely falls apart with local models. How&amp;#39;s the reliabilty compared to just doing structured prompting? I&amp;#39;ve been manually parsing outputs lol&lt;/p&gt;\\n\\n&lt;p&gt;The PDF query + code editor combo is pretty cool, are you thinking of this more as a general productivity tool or specialized for certain workflows?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m0drwa/ai_assistant_agent_with_function_calling_update_2/n3bfy51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752607901,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m0drwa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(t,{data:a});export{n as default};
