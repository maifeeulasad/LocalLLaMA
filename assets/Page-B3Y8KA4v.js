import{j as e}from"./index-Cd3v0jxz.js";import{R as l}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"\\\\*\\\\*TL;DR\\\\*\\\\* Thinking about building an LLM rig with 5 used AMD MI50 32GB GPUs to run Qwen 3 32b and 235b. Estimated token speeds look promising for the price (\\\\~$1125 total). Biggest hurdles are PCIe lane bandwidth &amp; power, which I'm attempting to solve with bifurcation cards and a new PSU.  Looking for feedback!\\n\\nHi everyone,\\n\\nLately I've been thinking about treating myself to a 3090 and a ram upgrade to run Qwen 3 32b and 235b, but the MI50 posts got me napkin mathing that rabbit hole. The numbers I'm seeing are 19 tok/s in 235b(I get 3 tok/s running q2), and 60 tok/s with 4x tensor parallel with 32b(I usually get 10-15 tok/s), which seems great for the price. To me that would be worth it to convert my desktop into a dedicated server. Other than slower prompt processing, is there a catch?\\n\\n  \\nIf its as good as some posts claim, then I'd be limited by cost and my existing hardware. The biggest problem is PCIe lanes, or lack thereof as low bandwidth will tank performance when running models in tensor parallel. To make the problem less bad, I'm going to try and keep everything PCIe gen 4. My motherboard supports bifurcation of the gen4 16x slot, which can be broken out by PCIe 4.0 bifurcation cards. The only gen 4 card I could find splits lanes, so that's why theres 3 of them. Another problem would be power, as the cards will need to be power limited slightly even with a 1600w PSU.\\n\\nCurrent system:  \\n\\\\*   \\\\*\\\\*CPU:\\\\*\\\\* Ryzen 5 7600  \\n\\\\*   \\\\*\\\\*RAM:\\\\*\\\\* 48GB DDR5 5200MHz  \\n\\\\*   \\\\*\\\\*Motherboard:\\\\*\\\\* MSI Mortar AM5  \\n\\\\*   \\\\*\\\\*SSD (Primary):\\\\*\\\\* 1TB SSD  \\n\\\\*   \\\\*\\\\*SSD (Secondary):\\\\*\\\\* 2TB SSD  \\n\\\\*   \\\\*\\\\*PSU:\\\\*\\\\* 850W  \\n\\\\*   \\\\*\\\\*GPU(s):\\\\*\\\\* 2x AMD RX6800 \\n\\n  \\nProspective system:  \\n\\\\*   \\\\*\\\\*CPU:\\\\*\\\\* Ryzen 5 7600  \\n\\\\*   \\\\*\\\\*RAM:\\\\*\\\\* 48GB DDR5 5200MHz  \\n\\\\*   \\\\*\\\\*Motherboard:\\\\*\\\\* MSI Mortar AM5(with bifurcation enabled)  \\n\\\\*   \\\\*\\\\*SSD (Primary):\\\\*\\\\* 1TB SSD  \\n\\\\*   \\\\*\\\\*SSD (Secondary):\\\\*\\\\* 2TB SSD  \\n\\\\*   \\\\*\\\\*GPUs (New):\\\\*\\\\* 5 x MI50 32GB ($130 each + $100 shipping = $750 total)  \\n\\\\*   \\\\*\\\\*PSU (New):\\\\*\\\\* 1600W PSU - $200  \\n\\\\*   \\\\*\\\\*Bifurcation Cards:\\\\*\\\\* Three PCIe 4.0 Bifurcation Cards - $75 ($25 each)  \\n\\\\*   \\\\*\\\\*Riser Cables:\\\\*\\\\* Four PCIe 4.0 8x Cables - $100 ($25 each)  \\n\\\\*   \\\\*\\\\*Cooling Shrouds:\\\\*\\\\* DIY MI50 GPU Cooling Shrouds (DIY)\\n\\n\\\\*   \\\\*\\\\*Total Cost of New Hardware:\\\\*\\\\* $1,125\\n\\nWhich doesn't seem too bad. The rx6800 gpus could be sold off too. Honestly the biggest loss would be not having a desktop, but I've been wanting a LLM focused homelab for a while now anyway. Maybe I could game on a VM in the server and stream it? Would love some feedback before I make an expensive mistake!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Considering 5xMI50 for Qwen 3 235b","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6eggp","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.89,"author_flair_background_color":"#bbbdbf","subreddit_type":"public","ups":13,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","is_original_content":false,"author_fullname":"t2_3f9vjjno","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":13,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753191801,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;**TL;DR** Thinking about building an LLM rig with 5 used AMD MI50 32GB GPUs to run Qwen 3 32b and 235b. Estimated token speeds look promising for the price (~$1125 total). Biggest hurdles are PCIe lane bandwidth &amp;amp; power, which I&amp;#39;m attempting to solve with bifurcation cards and a new PSU.  Looking for feedback!&lt;/p&gt;\\n\\n&lt;p&gt;Hi everyone,&lt;/p&gt;\\n\\n&lt;p&gt;Lately I&amp;#39;ve been thinking about treating myself to a 3090 and a ram upgrade to run Qwen 3 32b and 235b, but the MI50 posts got me napkin mathing that rabbit hole. The numbers I&amp;#39;m seeing are 19 tok/s in 235b(I get 3 tok/s running q2), and 60 tok/s with 4x tensor parallel with 32b(I usually get 10-15 tok/s), which seems great for the price. To me that would be worth it to convert my desktop into a dedicated server. Other than slower prompt processing, is there a catch?&lt;/p&gt;\\n\\n&lt;p&gt;If its as good as some posts claim, then I&amp;#39;d be limited by cost and my existing hardware. The biggest problem is PCIe lanes, or lack thereof as low bandwidth will tank performance when running models in tensor parallel. To make the problem less bad, I&amp;#39;m going to try and keep everything PCIe gen 4. My motherboard supports bifurcation of the gen4 16x slot, which can be broken out by PCIe 4.0 bifurcation cards. The only gen 4 card I could find splits lanes, so that&amp;#39;s why theres 3 of them. Another problem would be power, as the cards will need to be power limited slightly even with a 1600w PSU.&lt;/p&gt;\\n\\n&lt;p&gt;Current system:&lt;br/&gt;\\n*   **CPU:** Ryzen 5 7600&lt;br/&gt;\\n*   **RAM:** 48GB DDR5 5200MHz&lt;br/&gt;\\n*   **Motherboard:** MSI Mortar AM5&lt;br/&gt;\\n*   **SSD (Primary):** 1TB SSD&lt;br/&gt;\\n*   **SSD (Secondary):** 2TB SSD&lt;br/&gt;\\n*   **PSU:** 850W&lt;br/&gt;\\n*   **GPU(s):** 2x AMD RX6800 &lt;/p&gt;\\n\\n&lt;p&gt;Prospective system:&lt;br/&gt;\\n*   **CPU:** Ryzen 5 7600&lt;br/&gt;\\n*   **RAM:** 48GB DDR5 5200MHz&lt;br/&gt;\\n*   **Motherboard:** MSI Mortar AM5(with bifurcation enabled)&lt;br/&gt;\\n*   **SSD (Primary):** 1TB SSD&lt;br/&gt;\\n*   **SSD (Secondary):** 2TB SSD&lt;br/&gt;\\n*   **GPUs (New):** 5 x MI50 32GB ($130 each + $100 shipping = $750 total)&lt;br/&gt;\\n*   **PSU (New):** 1600W PSU - $200&lt;br/&gt;\\n*   **Bifurcation Cards:** Three PCIe 4.0 Bifurcation Cards - $75 ($25 each)&lt;br/&gt;\\n*   **Riser Cables:** Four PCIe 4.0 8x Cables - $100 ($25 each)&lt;br/&gt;\\n*   **Cooling Shrouds:** DIY MI50 GPU Cooling Shrouds (DIY)&lt;/p&gt;\\n\\n&lt;p&gt;*   **Total Cost of New Hardware:** $1,125&lt;/p&gt;\\n\\n&lt;p&gt;Which doesn&amp;#39;t seem too bad. The rx6800 gpus could be sold off too. Honestly the biggest loss would be not having a desktop, but I&amp;#39;ve been wanting a LLM focused homelab for a while now anyway. Maybe I could game on a VM in the server and stream it? Would love some feedback before I make an expensive mistake!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Llama 70B","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m6eggp","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"PraxisOG","discussion_type":null,"num_comments":29,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/","subreddit_subscribers":503254,"created_utc":1753191801,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lzfuw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"un_passant","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lbohn","score":2,"author_fullname":"t2_7rqtc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not sure but even DDR4 with 8 channels would be as good as expensive DDR5 on 4 channels, plus RAM would be even cheaper because you'd need less density (8 sticks vs 4).\\n\\nSo you can consider Epyc Gen 4 with 12 channels for DDR5 but it will be pricey (don't get the cheapest CPUs because they might not deliver all the memory bandwidth) or a good old Epyc Gen 2 with 8 DDR4 at 3200. \\n\\nYou could try to get something like [https://www.reddit.com/r/homelabsales/comments/1lsnivz/fs\\\\_usaaz\\\\_pair\\\\_of\\\\_supermicro\\\\_epyc\\\\_7502p\\\\_servers/](https://www.reddit.com/r/homelabsales/comments/1lsnivz/fs_usaaz_pair_of_supermicro_epyc_7502p_servers/)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lzfuw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure but even DDR4 with 8 channels would be as good as expensive DDR5 on 4 channels, plus RAM would be even cheaper because you&amp;#39;d need less density (8 sticks vs 4).&lt;/p&gt;\\n\\n&lt;p&gt;So you can consider Epyc Gen 4 with 12 channels for DDR5 but it will be pricey (don&amp;#39;t get the cheapest CPUs because they might not deliver all the memory bandwidth) or a good old Epyc Gen 2 with 8 DDR4 at 3200. &lt;/p&gt;\\n\\n&lt;p&gt;You could try to get something like &lt;a href=\\"https://www.reddit.com/r/homelabsales/comments/1lsnivz/fs_usaaz_pair_of_supermicro_epyc_7502p_servers/\\"&gt;https://www.reddit.com/r/homelabsales/comments/1lsnivz/fs_usaaz_pair_of_supermicro_epyc_7502p_servers/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4lzfuw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753223458,"author_flair_text":null,"treatment_tags":[],"created_utc":1753223458,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lbohn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmPips","can_mod_post":false,"created_utc":1753216432,"send_replies":true,"parent_id":"t1_n4j86il","score":1,"author_fullname":"t2_w2gxqd6i2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What's the cheapest [greater than dual]-channel DDR5 motherboard+CPU that one can acquire?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4lbohn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What&amp;#39;s the cheapest [greater than dual]-channel DDR5 motherboard+CPU that one can acquire?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4lbohn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753216432,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j86il","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"un_passant","can_mod_post":false,"created_utc":1753195457,"send_replies":true,"parent_id":"t3_1m6eggp","score":11,"author_fullname":"t2_7rqtc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Epyc CPU and mobo. DDR5 is useless with few memory channels. PCIe lanes could be ×16.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j86il","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Epyc CPU and mobo. DDR5 is useless with few memory channels. PCIe lanes could be ×16.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j86il/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195457,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"body":"Note that you will get 40t/s for Qwen3 32b gptq 4bit with 4x tensor parallelism. Qwen3 235B Q4_1 will work with llama.cpp and 5xMI50 at 19t/s initially. But expect that around 10k tokens you will see 5t/s. If we figure out support for that model in vLLM, we should see around 10t/s at 32k context. By the way, if you need a large context, I recommend you to get at least 6xMI50 and server motherboard. \\nI just ran 2 cards directly from my motherboard's PCIE slots, pcie4.0 at 8x and I saw PP to double. E.g. Qwen3-32B PP went from 230t/s to 470t/s.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j8ipq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MLDataScientist","can_mod_post":false,"created_utc":1753195552,"send_replies":true,"parent_id":"t3_1m6eggp","score":9,"author_fullname":"t2_3zy7pnf1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j8ipq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Note that you will get 40t/s for Qwen3 32b gptq 4bit with 4x tensor parallelism. Qwen3 235B Q4_1 will work with llama.cpp and 5xMI50 at 19t/s initially. But expect that around 10k tokens you will see 5t/s. If we figure out support for that model in vLLM, we should see around 10t/s at 32k context. By the way, if you need a large context, I recommend you to get at least 6xMI50 and server motherboard. \\nI just ran 2 cards directly from my motherboard&amp;#39;s PCIE slots, pcie4.0 at 8x and I saw PP to double. E.g. Qwen3-32B PP went from 230t/s to 470t/s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j8ipq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195552,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lmlzk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"UsualResult","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4jn9v5","score":7,"author_fullname":"t2_10iarzku","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is! The latest version of ROCm already has some problems with MI50. This is one reason why AMD gets beat up by NVidia. Their hardware is OK but their software support is a joke.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4lmlzk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is! The latest version of ROCm already has some problems with MI50. This is one reason why AMD gets beat up by NVidia. Their hardware is OK but their software support is a joke.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4lmlzk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219519,"author_flair_text":null,"treatment_tags":[],"created_utc":1753219519,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n4jn9v5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Direspark","can_mod_post":false,"created_utc":1753199636,"send_replies":true,"parent_id":"t1_n4ja1pm","score":8,"author_fullname":"t2_675qc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is wild to me. Doesn't ROCm also still not have support for some of their newer gpus? And they're dropping support for cards that are 5 years old? Sounds like a nightmare.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jn9v5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is wild to me. Doesn&amp;#39;t ROCm also still not have support for some of their newer gpus? And they&amp;#39;re dropping support for cards that are 5 years old? Sounds like a nightmare.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4jn9v5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753199636,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ja1pm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"disillusioned_okapi","can_mod_post":false,"created_utc":1753195977,"send_replies":true,"parent_id":"t3_1m6eggp","score":7,"author_fullname":"t2_wy3w8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just FYI: ROCm hasn't supported MI50 for almost 2 years https://github.com/ROCm/ROCm/issues/2308","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ja1pm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just FYI: ROCm hasn&amp;#39;t supported MI50 for almost 2 years &lt;a href=\\"https://github.com/ROCm/ROCm/issues/2308\\"&gt;https://github.com/ROCm/ROCm/issues/2308&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4ja1pm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195977,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"I agree here. I managed to add 6x MI50 to my Asus rog motherboard with 5950x CPU and 96gb ddr4. It is not stable. The system freezes sometimes. I had pcie4.0 to 4x4 bifurcation card. That also did not help much. I needed to set it to pcie3.0 4x4 so that I could use 4 cards. If I knew, I would just use a server motherboard.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j6jvq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MLDataScientist","can_mod_post":false,"created_utc":1753194999,"send_replies":true,"parent_id":"t1_n4j1w4e","score":5,"author_fullname":"t2_3zy7pnf1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j6jvq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree here. I managed to add 6x MI50 to my Asus rog motherboard with 5950x CPU and 96gb ddr4. It is not stable. The system freezes sometimes. I had pcie4.0 to 4x4 bifurcation card. That also did not help much. I needed to set it to pcie3.0 4x4 so that I could use 4 cards. If I knew, I would just use a server motherboard.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j6jvq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753194999,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j1w4e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nepherpitu","can_mod_post":false,"created_utc":1753193658,"send_replies":true,"parent_id":"t3_1m6eggp","score":9,"author_fullname":"t2_plp1w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do not try to push 5xGPU into consumer board. It doesn't worth the effort. Take a loot at used server system with a lot of PCIe lines and 8 channel DDR4 memory. I'm tried, results aren't promising - you either make a server of consumer grade PC and will not be able to use it as workstation, or you will waste major fraction of performance. If you want to lose performance - why bother with all this in first place? And if you are fine with server, then... buy server and maybe sell your workstation. This will be simplier and more useful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j1w4e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do not try to push 5xGPU into consumer board. It doesn&amp;#39;t worth the effort. Take a loot at used server system with a lot of PCIe lines and 8 channel DDR4 memory. I&amp;#39;m tried, results aren&amp;#39;t promising - you either make a server of consumer grade PC and will not be able to use it as workstation, or you will waste major fraction of performance. If you want to lose performance - why bother with all this in first place? And if you are fine with server, then... buy server and maybe sell your workstation. This will be simplier and more useful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j1w4e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753193658,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j6mb1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4j5ch1","score":7,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't look at X99 and get a proper server board from a reputable and known vendor if you want to avoid headaches.\\n\\nI have a few Epyc systems myself and love them, but they're much more expensive than something like X10 for practically no real benefit if you don't plan to do CPU inference. Broadwell is really the best bang for the buck for such a system. I have a dual Broadwell build on a X10DRX with four P40s, and four more P40s waiting on a few parts to upgrade to an octa setup (all watercooled, no risers).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4j6mb1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t look at X99 and get a proper server board from a reputable and known vendor if you want to avoid headaches.&lt;/p&gt;\\n\\n&lt;p&gt;I have a few Epyc systems myself and love them, but they&amp;#39;re much more expensive than something like X10 for practically no real benefit if you don&amp;#39;t plan to do CPU inference. Broadwell is really the best bang for the buck for such a system. I have a dual Broadwell build on a X10DRX with four P40s, and four more P40s waiting on a few parts to upgrade to an octa setup (all watercooled, no risers).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j6mb1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753195017,"author_flair_text":null,"treatment_tags":[],"created_utc":1753195017,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jjfn5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4j5ch1","score":1,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Depends what you're planning really. If the goal is all in VRAM running, then x99 is golden for you. You can have an X99 with 128 pcie3 lanes up and going for pennies compared to getting one of the two epyc 7002 boards that don't entirely suck. And the trick is actually only one of them doesn't suck, so you're going to be paying $650-$1000 for a ROMED8-2T or rolling the dice on the Chinese one maybe.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4jjfn5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends what you&amp;#39;re planning really. If the goal is all in VRAM running, then x99 is golden for you. You can have an X99 with 128 pcie3 lanes up and going for pennies compared to getting one of the two epyc 7002 boards that don&amp;#39;t entirely suck. And the trick is actually only one of them doesn&amp;#39;t suck, so you&amp;#39;re going to be paying $650-$1000 for a ROMED8-2T or rolling the dice on the Chinese one maybe.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4jjfn5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753198578,"author_flair_text":null,"treatment_tags":[],"created_utc":1753198578,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j5ch1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1753194653,"send_replies":true,"parent_id":"t1_n4j44ud","score":0,"author_fullname":"t2_3f9vjjno","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was looking at x99 as an attractive platform, though I'd rather get a 2nd gen epyc if I'm building out a server like that","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j5ch1","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was looking at x99 as an attractive platform, though I&amp;#39;d rather get a 2nd gen epyc if I&amp;#39;m building out a server like that&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j5ch1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753194653,"author_flair_text":"Llama 70B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4j44ud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1753194311,"send_replies":true,"parent_id":"t3_1m6eggp","score":3,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Look at Broadwell Xeons and something like a supermicro X10SRL. Both are pretty cheap. Broadwell has 40 Gen 3 lanes. You also get quad channel DDR4-2400, which is pretty cheap. You can put 256GB for around 130. Most Broadwell boards don't have a M.2 slot but they support NVMe SSDs nonetheless. Just grab yourself a HHHL PCIe NVMe SSD and you're gold (they're cheaper than M.2, and models like the PM1725 have an X8 interface and ~6GB/s read speed).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j44ud","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Look at Broadwell Xeons and something like a supermicro X10SRL. Both are pretty cheap. Broadwell has 40 Gen 3 lanes. You also get quad channel DDR4-2400, which is pretty cheap. You can put 256GB for around 130. Most Broadwell boards don&amp;#39;t have a M.2 slot but they support NVMe SSDs nonetheless. Just grab yourself a HHHL PCIe NVMe SSD and you&amp;#39;re gold (they&amp;#39;re cheaper than M.2, and models like the PM1725 have an X8 interface and ~6GB/s read speed).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j44ud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753194311,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ixjod","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Agreeable-Prompt-666","can_mod_post":false,"created_utc":1753192356,"send_replies":true,"parent_id":"t1_n4iwr9l","score":8,"author_fullname":"t2_1l3z4stvkq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Money is a bitch of a constraint","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ixjod","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Money is a bitch of a constraint&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4ixjod/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192356,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n4iwr9l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"created_utc":1753192115,"send_replies":true,"parent_id":"t3_1m6eggp","score":4,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Token speed is going to be about 10tk/sec.  Keep your desktop and build your LLM machine, get another job and earn some money to do it.   Stop over thinking it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4iwr9l","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Token speed is going to be about 10tk/sec.  Keep your desktop and build your LLM machine, get another job and earn some money to do it.   Stop over thinking it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4iwr9l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192115,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4k1yzr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LA_rent_Aficionado","can_mod_post":false,"created_utc":1753203719,"send_replies":true,"parent_id":"t3_1m6eggp","score":2,"author_fullname":"t2_t8zbiflk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Server/workstation platform or bust.  \\n\\nIt will be a nightmare to get everything to fit, get decent performance and be stable on a consumer board.  You can get it to work but your PCI bandwidth will be so bottlenecked that you won't have any future upgradability to faster cards and you're going to be doing all types of gymnastics getting cards recognized, maximizing bandwidth, etc.  Furthermore, without adequate memory channels, if you ever want to use any models that exceed VRAM you'll have far worse performance on the model layers on CPU/RAM due to the memory channels.\\n\\nLook at facebook marketplace, there are some steals on DDR4 servers that pop up every now and then, that or save up for an Epyc/Xeon/TR setup over time.  You can always buy the cards now while they are available and upgrade incrementally if money is an issue.  Unfortuantely there is no magic button to get cheap local support at any decent speed for some of the largest models out there. Even with the greatest deal on these cheap cards, they're support has sunsetted and eventually architecture changes will make them more obselete - thats just the nature of computer hardware though.  \\n\\nIt took me far more than I care to admit (especially to my GF) to get 54 t/s on Qwen 3 Q3\\\\_S with a TR and quad 5090 setup - the economics are that its simply cheaper to pay API costs unless you have a business need for a robust local setup.  That said, its hard to put a price on doing something yourself if you are a independent tinkerer by nature.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4k1yzr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Server/workstation platform or bust.  &lt;/p&gt;\\n\\n&lt;p&gt;It will be a nightmare to get everything to fit, get decent performance and be stable on a consumer board.  You can get it to work but your PCI bandwidth will be so bottlenecked that you won&amp;#39;t have any future upgradability to faster cards and you&amp;#39;re going to be doing all types of gymnastics getting cards recognized, maximizing bandwidth, etc.  Furthermore, without adequate memory channels, if you ever want to use any models that exceed VRAM you&amp;#39;ll have far worse performance on the model layers on CPU/RAM due to the memory channels.&lt;/p&gt;\\n\\n&lt;p&gt;Look at facebook marketplace, there are some steals on DDR4 servers that pop up every now and then, that or save up for an Epyc/Xeon/TR setup over time.  You can always buy the cards now while they are available and upgrade incrementally if money is an issue.  Unfortuantely there is no magic button to get cheap local support at any decent speed for some of the largest models out there. Even with the greatest deal on these cheap cards, they&amp;#39;re support has sunsetted and eventually architecture changes will make them more obselete - thats just the nature of computer hardware though.  &lt;/p&gt;\\n\\n&lt;p&gt;It took me far more than I care to admit (especially to my GF) to get 54 t/s on Qwen 3 Q3_S with a TR and quad 5090 setup - the economics are that its simply cheaper to pay API costs unless you have a business need for a robust local setup.  That said, its hard to put a price on doing something yourself if you are a independent tinkerer by nature.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4k1yzr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753203719,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4mtwth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EugenePopcorn","can_mod_post":false,"created_utc":1753233567,"send_replies":true,"parent_id":"t1_n4ln19c","score":1,"author_fullname":"t2_g6hpxxgss","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They're almost as fast in vulkan. That support is going nowhere. Other GPUs are definitely better at pre-fill, but they don't have cheap HBM2.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4mtwth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They&amp;#39;re almost as fast in vulkan. That support is going nowhere. Other GPUs are definitely better at pre-fill, but they don&amp;#39;t have cheap HBM2.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4mtwth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753233567,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ln19c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UsualResult","can_mod_post":false,"created_utc":1753219644,"send_replies":true,"parent_id":"t3_1m6eggp","score":2,"author_fullname":"t2_10iarzku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a 2x MI50 system. It's been OK for running ~30B models, but the prompt processing speed is SLOW. Like other posters have said, the ROCm support is quickly going away. Things still work now with ROCm 6.2... but all it would take is for llama.cpp to drop support and then the choice is either:\\n\\na) you have paperweights\\n\\nb) forever run an old version of llama.cpp\\n\\nNot great...\\n\\nThat being said, in the mean time, it has been fun to play with 2x MI50.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ln19c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a 2x MI50 system. It&amp;#39;s been OK for running ~30B models, but the prompt processing speed is SLOW. Like other posters have said, the ROCm support is quickly going away. Things still work now with ROCm 6.2... but all it would take is for llama.cpp to drop support and then the choice is either:&lt;/p&gt;\\n\\n&lt;p&gt;a) you have paperweights&lt;/p&gt;\\n\\n&lt;p&gt;b) forever run an old version of llama.cpp&lt;/p&gt;\\n\\n&lt;p&gt;Not great...&lt;/p&gt;\\n\\n&lt;p&gt;That being said, in the mean time, it has been fun to play with 2x MI50.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4ln19c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753219644,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jd9c2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Clear-Ad-9312","can_mod_post":false,"created_utc":1753196866,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_13gn4f8kdq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yeah consumer motherboards will not be sensible at all. On the other hand, instead of putting this much cash/time/effort on this setup, you can just get the framework desktop and get an oculink+4090(or an amd card to make it easier to handle drivers) down the road. this will get you good performance, and last you a lot longer in terms of support and capabilities. especially as someone else mentioned, MI50 support for rocm is non-existent. MI50 is likely going to get worse and you will eventually need to upgrade.\\n\\nAlso, down the line, if you do go from the framework desktop to a fully multi-GPU setup then that would work out too because you can repurpose the framework desktop as it is a beast and last a long af time.","edited":1753198053,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jd9c2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah consumer motherboards will not be sensible at all. On the other hand, instead of putting this much cash/time/effort on this setup, you can just get the framework desktop and get an oculink+4090(or an amd card to make it easier to handle drivers) down the road. this will get you good performance, and last you a lot longer in terms of support and capabilities. especially as someone else mentioned, MI50 support for rocm is non-existent. MI50 is likely going to get worse and you will eventually need to upgrade.&lt;/p&gt;\\n\\n&lt;p&gt;Also, down the line, if you do go from the framework desktop to a fully multi-GPU setup then that would work out too because you can repurpose the framework desktop as it is a beast and last a long af time.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4jd9c2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753196866,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jo9oa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"created_utc":1753199916,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_559a1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Don't replace your desktop with an LLM server, build out a separate machine for LLM if you're going MI50 IMO. If you want to stick it all in a desktop, stacking 3090s makes more sense but obviously way less vram per dollar.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jo9oa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t replace your desktop with an LLM server, build out a separate machine for LLM if you&amp;#39;re going MI50 IMO. If you want to stick it all in a desktop, stacking 3090s makes more sense but obviously way less vram per dollar.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4jo9oa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753199916,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4l59i9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1753214651,"send_replies":true,"parent_id":"t1_n4jv9s6","score":2,"author_fullname":"t2_3f9vjjno","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Alibaba","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4l59i9","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Alibaba&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4l59i9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753214651,"author_flair_text":"Llama 70B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4jv9s6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adwhh","can_mod_post":false,"created_utc":1753201879,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_ji6ooisdo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Where are you getting 130$ 32gb mi50s from?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jv9s6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where are you getting 130$ 32gb mi50s from?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4jv9s6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753201879,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4kl4pe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nabushika","can_mod_post":false,"created_utc":1753208931,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_1lrj5qoj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey! I'm looking to do similar, except on a larger scale (16x MI50 32gb for deepseek/kimi) - lmk if you want to collaborate on figuring out parts/sellers or maybe making a guide for people who want to do the same?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4kl4pe","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey! I&amp;#39;m looking to do similar, except on a larger scale (16x MI50 32gb for deepseek/kimi) - lmk if you want to collaborate on figuring out parts/sellers or maybe making a guide for people who want to do the same?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4kl4pe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753208931,"author_flair_text":"Llama 70B","treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j2l6p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1753193863,"send_replies":true,"parent_id":"t1_n4ix54k","score":1,"author_fullname":"t2_3f9vjjno","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Honestly fair enough. I'll do more extensive research into software support","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j2l6p","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly fair enough. I&amp;#39;ll do more extensive research into software support&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j2l6p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753193863,"author_flair_text":"Llama 70B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ix54k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"created_utc":1753192233,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_1l3z4stvkq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not a bad idea to save $, I was looking at similar solution. Doing some reading software support will be very flakey so once you get it running, make sure you document all versions of software and hacks required for those cards. At the time I  did not want to take the plunge and learn(or have the time) how to support mi50","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ix54k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not a bad idea to save $, I was looking at similar solution. Doing some reading software support will be very flakey so once you get it running, make sure you document all versions of software and hacks required for those cards. At the time I  did not want to take the plunge and learn(or have the time) how to support mi50&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4ix54k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192233,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4j1926","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1753193469,"send_replies":true,"parent_id":"t1_n4iym5e","score":1,"author_fullname":"t2_3f9vjjno","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ayy, I've only seen a couple others so this is probably half of us lol. The quantization of 235b I'm using squishes everything else down to 2.5gb, and windows 11 ain't a contortionist so I suspect there's some memory paging going on. Plan A was a simple ram upgrade, and it's reassuring to hear there's still some performance on the table.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4j1926","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ayy, I&amp;#39;ve only seen a couple others so this is probably half of us lol. The quantization of 235b I&amp;#39;m using squishes everything else down to 2.5gb, and windows 11 ain&amp;#39;t a contortionist so I suspect there&amp;#39;s some memory paging going on. Plan A was a simple ram upgrade, and it&amp;#39;s reassuring to hear there&amp;#39;s still some performance on the table.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6eggp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4j1926/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753193469,"author_flair_text":"Llama 70B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4iym5e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmPips","can_mod_post":false,"created_utc":1753192677,"send_replies":true,"parent_id":"t3_1m6eggp","score":1,"author_fullname":"t2_w2gxqd6i2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I did not expect to meet another dual Rx 6800 owner here. Howdy friend! 👋 \\n\\nI'm running Q2 on a VERY slow DDR4 board and getting ~5 tokens/second setting context size to like 10k. My bottleneck is entirely system memory speed, so your dual channel DDR5 board on your current system should in theory get twice my performance unless you're using a boatload of context if you can fit it all into memory.\\n\\nBefore delving into buying Instinct cards I'd recommend you try buying more RAM first! Cheaper, easier to install, easier to flip.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4iym5e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did not expect to meet another dual Rx 6800 owner here. Howdy friend! 👋 &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m running Q2 on a VERY slow DDR4 board and getting ~5 tokens/second setting context size to like 10k. My bottleneck is entirely system memory speed, so your dual channel DDR5 board on your current system should in theory get twice my performance unless you&amp;#39;re using a boatload of context if you can fit it all into memory.&lt;/p&gt;\\n\\n&lt;p&gt;Before delving into buying Instinct cards I&amp;#39;d recommend you try buying more RAM first! Cheaper, easier to install, easier to flip.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6eggp/considering_5xmi50_for_qwen_3_235b/n4iym5e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192677,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6eggp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
