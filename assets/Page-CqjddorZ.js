import{j as e}from"./index-DLSqWzaI.js";import{R as l}from"./RedditPostRenderer-CysRo2D_.js";import"./index-COXiL3Lo.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"AI21 has just made Jamba 1.7 available on Kaggle:\\n\\n[https://www.kaggle.com/models/ai21labs/ai21-jamba-1.7](https://www.kaggle.com/models/ai21labs/ai21-jamba-1.7) \\n\\n* You can run and test the model without needing to install it locally\\n* No need to harness setup, hardware and engineering knowledge via Hugging Face anymore\\n* Now you can run sample tasks, benchmark against other models and share public notebooks with results\\n\\nPretty significant as the model is now available for non technical users. Here is what we know about 1.7 and Jamba in general:\\n\\n* Combination of Transformer architecture and Mamba, making it more efficient at handling long sequences\\n* 256k context window - well-suited for long document summarization and memory-heavy chat agents\\n* Improved capabilities in understanding and following user instructions, and generating more factual, relevant outputs\\n\\nWho is going to try it out? What use cases do you have in mind?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Jamba 1.7 is now available on Kaggle","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6dco7","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.81,"author_flair_background_color":null,"subreddit_type":"public","ups":13,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1kwk178bd9","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":13,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1753202307,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753188954,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;AI21 has just made Jamba 1.7 available on Kaggle:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.kaggle.com/models/ai21labs/ai21-jamba-1.7\\"&gt;https://www.kaggle.com/models/ai21labs/ai21-jamba-1.7&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;You can run and test the model without needing to install it locally&lt;/li&gt;\\n&lt;li&gt;No need to harness setup, hardware and engineering knowledge via Hugging Face anymore&lt;/li&gt;\\n&lt;li&gt;Now you can run sample tasks, benchmark against other models and share public notebooks with results&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Pretty significant as the model is now available for non technical users. Here is what we know about 1.7 and Jamba in general:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Combination of Transformer architecture and Mamba, making it more efficient at handling long sequences&lt;/li&gt;\\n&lt;li&gt;256k context window - well-suited for long document summarization and memory-heavy chat agents&lt;/li&gt;\\n&lt;li&gt;Improved capabilities in understanding and following user instructions, and generating more factual, relevant outputs&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Who is going to try it out? What use cases do you have in mind?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m6dco7","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"NullPointerJack","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/","subreddit_subscribers":502981,"created_utc":1753188954,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lja8x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4kafz5","score":1,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This page is completely inaccurate and unreliable. For example, at the very beginning it says: „Jamba 1.7 Large has a smaller context windows than average, with a context window of 260k tokens.“","edited":false,"author_flair_css_class":null,"name":"t1_n4lja8x","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This page is completely inaccurate and unreliable. For example, at the very beginning it says: „Jamba 1.7 Large has a smaller context windows than average, with a context window of 260k tokens.“&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6dco7","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4lja8x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753218546,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1753218546,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4kb496","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4kafz5","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mistral Nemo is awful if you judge by benchmarks, yet still in use, as it is excellent chatbot.","edited":false,"author_flair_css_class":null,"name":"t1_n4kb496","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral Nemo is awful if you judge by benchmarks, yet still in use, as it is excellent chatbot.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6dco7","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4kb496/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753206174,"author_flair_text":null,"collapsed":false,"created_utc":1753206174,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4kafz5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kevin_1994","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4jvgkf","score":1,"author_fullname":"t2_o015g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The website is pretty meh in terms of accuracy but look at the individual benches of jamba 1.7 large:  \\n- MMLU-Pro -&gt; terrible  \\n- GPQA -&gt; terrible  \\n- HLE -&gt; bad  \\n- LiveCodeBench -&gt; one of the worst I've seen from post 2024 model  \\n- Math -&gt; one of the worst I've seen from post 2024 model \\n\\nQwen3 4B Reasoning (or 8B for benches that don't have 4B) beats it all of the above benchmarks lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4kafz5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The website is pretty meh in terms of accuracy but look at the individual benches of jamba 1.7 large:&lt;br/&gt;\\n- MMLU-Pro -&amp;gt; terrible&lt;br/&gt;\\n- GPQA -&amp;gt; terrible&lt;br/&gt;\\n- HLE -&amp;gt; bad&lt;br/&gt;\\n- LiveCodeBench -&amp;gt; one of the worst I&amp;#39;ve seen from post 2024 model&lt;br/&gt;\\n- Math -&amp;gt; one of the worst I&amp;#39;ve seen from post 2024 model &lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 4B Reasoning (or 8B for benches that don&amp;#39;t have 4B) beats it all of the above benchmarks lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4kafz5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753205993,"author_flair_text":null,"treatment_tags":[],"created_utc":1753205993,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4jvgkf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ixwyz","score":4,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That benchmark is a steaming piece of shit. It puts Gemma 3 27b way above mistral large 2411. Whoever used both models knows that this is simply not true.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4jvgkf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That benchmark is a steaming piece of shit. It puts Gemma 3 27b way above mistral large 2411. Whoever used both models knows that this is simply not true.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4jvgkf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753201932,"author_flair_text":null,"treatment_tags":[],"created_utc":1753201932,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ljgax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ixwyz","score":1,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This page is completely inaccurate and unreliable. For example, at the very beginning it says: „Jamba 1.7 Large has a smaller context windows than average, with a context window of 260k tokens.“","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ljgax","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This page is completely inaccurate and unreliable. For example, at the very beginning it says: „Jamba 1.7 Large has a smaller context windows than average, with a context window of 260k tokens.“&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4ljgax/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753218594,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753218594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jju53","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ixwyz","score":0,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"good to know. Thanks","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4jju53","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;good to know. Thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4jju53/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753198690,"author_flair_text":null,"treatment_tags":[],"created_utc":1753198690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ixwyz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kevin_1994","can_mod_post":false,"created_utc":1753192468,"send_replies":true,"parent_id":"t1_n4iruxe","score":1,"author_fullname":"t2_o015g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It sucks https://artificialanalysis.ai/models/jamba-1-7-large","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ixwyz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It sucks &lt;a href=\\"https://artificialanalysis.ai/models/jamba-1-7-large\\"&gt;https://artificialanalysis.ai/models/jamba-1-7-large&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4ixwyz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192468,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4iruxe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Silver-Champion-4846","can_mod_post":false,"created_utc":1753190547,"send_replies":true,"parent_id":"t3_1m6dco7","score":5,"author_fullname":"t2_9xer9y5w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm interested in knowing what people think of this model, how good is it compared to other models of the same size?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4iruxe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m interested in knowing what people think of this model, how good is it compared to other models of the same size?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4iruxe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753190547,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6dco7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4izbq0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celsowm","can_mod_post":false,"created_utc":1753192890,"send_replies":true,"parent_id":"t3_1m6dco7","score":1,"author_fullname":"t2_dyvrh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Openrouter needs to update 1.6 to 1.7","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4izbq0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Openrouter needs to update 1.6 to 1.7&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4izbq0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192890,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6dco7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1m6dco7","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jwur7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NullPointerJack","can_mod_post":false,"created_utc":1753202326,"send_replies":true,"parent_id":"t1_n4jlxj8","score":1,"author_fullname":"t2_1kwk178bd9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My bad, typo. It's meant to say 256k. Fixed now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jwur7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My bad, typo. It&amp;#39;s meant to say 256k. Fixed now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6dco7","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4jwur7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753202326,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4jlxj8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1m6dco7","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4jlxj8/","num_reports":null,"locked":false,"name":"t1_n4jlxj8","created":1753199264,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1753199264,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4jm45m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"404NotAFish","can_mod_post":false,"created_utc":1753199314,"send_replies":true,"parent_id":"t3_1m6dco7","score":1,"author_fullname":"t2_1jhbvmdfa6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Super excited to see this on Kaggle! I'm not a developer, but I’ve been following Jamba since the early releases and always felt a bit shut out when everything required Hugging Face or local setup.going to look into testing it with summarising long documents later.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4jm45m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Super excited to see this on Kaggle! I&amp;#39;m not a developer, but I’ve been following Jamba since the early releases and always felt a bit shut out when everything required Hugging Face or local setup.going to look into testing it with summarising long documents later.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6dco7/jamba_17_is_now_available_on_kaggle/n4jm45m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753199314,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6dco7","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:a});export{r as default};
