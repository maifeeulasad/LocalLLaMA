import{j as e}from"./index-BgwOAK4-.js";import{R as l}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm usually around here enjoying the discussions, and I've put together a short, 5-7 minute survey to better understand how all of you are using Large Language Models locally. I'm really curious about your setups, the tools and agents you're using, and what your day-to-day experience is like on the ground.\\n\\n\\n\\nBefore I jump in, I want to give a huge shout-out and thank you to the awesome people who helped me put this survey together! Their contributions were invaluable, and while they prefer to stay anonymous, know that their insights were super helpful in making this survey what it is.\\n\\n\\n\\nIf you're running LLMs on your own hardware, please consider taking a few minutes to share your insights.\\n\\n[https://qazwsx.aidaform.com/the-local-llm-landscape](https://qazwsx.aidaform.com/the-local-llm-landscape)\\n\\nAnd if you know other folks or communities who might fit the bill, it would be awesome if you could share it with them too! The more perspectives, the clearer the picture we get!\\n\\n\\n\\nThanks a ton for helping out!\\n\\nLink: [https://qazwsx.aidaform.com/the-local-llm-landscape](https://qazwsx.aidaform.com/the-local-llm-landscape)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"How Are YOU Using LLMs? (A Quick Survey)","link_flair_richtext":[{"e":"text","t":"Other"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ly256a","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.43,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dtzmsoy3","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Other","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752331453,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m usually around here enjoying the discussions, and I&amp;#39;ve put together a short, 5-7 minute survey to better understand how all of you are using Large Language Models locally. I&amp;#39;m really curious about your setups, the tools and agents you&amp;#39;re using, and what your day-to-day experience is like on the ground.&lt;/p&gt;\\n\\n&lt;p&gt;Before I jump in, I want to give a huge shout-out and thank you to the awesome people who helped me put this survey together! Their contributions were invaluable, and while they prefer to stay anonymous, know that their insights were super helpful in making this survey what it is.&lt;/p&gt;\\n\\n&lt;p&gt;If you&amp;#39;re running LLMs on your own hardware, please consider taking a few minutes to share your insights.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://qazwsx.aidaform.com/the-local-llm-landscape\\"&gt;https://qazwsx.aidaform.com/the-local-llm-landscape&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;And if you know other folks or communities who might fit the bill, it would be awesome if you could share it with them too! The more perspectives, the clearer the picture we get!&lt;/p&gt;\\n\\n&lt;p&gt;Thanks a ton for helping out!&lt;/p&gt;\\n\\n&lt;p&gt;Link: &lt;a href=\\"https://qazwsx.aidaform.com/the-local-llm-landscape\\"&gt;https://qazwsx.aidaform.com/the-local-llm-landscape&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"7a7848d2-bf8e-11ed-8c2f-765d15199f78","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#94e044","id":"1ly256a","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"kidupstart","discussion_type":null,"num_comments":9,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/","subreddit_subscribers":498345,"created_utc":1752331453,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qjgs8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kidupstart","can_mod_post":false,"created_utc":1752332227,"send_replies":true,"parent_id":"t1_n2qimx0","score":6,"author_fullname":"t2_dtzmsoy3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The name field is totally **optional**, just helps me prevent duplicate entries.   \\n  \\nA nickname is perfectly fine! Thanks for asking, and for considering the survey!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qjgs8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The name field is totally &lt;strong&gt;optional&lt;/strong&gt;, just helps me prevent duplicate entries.   &lt;/p&gt;\\n\\n&lt;p&gt;A nickname is perfectly fine! Thanks for asking, and for considering the survey!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly256a","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qjgs8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752332227,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2qimx0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"General_Service_8209","can_mod_post":false,"created_utc":1752331965,"send_replies":true,"parent_id":"t3_1ly256a","score":7,"author_fullname":"t2_jkfuj8nc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why do you need full names for this survey?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qimx0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why do you need full names for this survey?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qimx0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752331965,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qjs20","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SillyLilBear","can_mod_post":false,"created_utc":1752332327,"send_replies":true,"parent_id":"t1_n2qim8v","score":5,"author_fullname":"t2_wjjtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Rule 34","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qjs20","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Rule 34&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly256a","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qjs20/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752332327,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qjurm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kidupstart","can_mod_post":false,"created_utc":1752332351,"send_replies":true,"parent_id":"t1_n2qim8v","score":1,"author_fullname":"t2_dtzmsoy3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We'll be sharing the results right here! Our goal is to get a clearer picture of the **de facto tools and methods** folks are using for local LLMs, which will be super valuable for everyone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qjurm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We&amp;#39;ll be sharing the results right here! Our goal is to get a clearer picture of the &lt;strong&gt;de facto tools and methods&lt;/strong&gt; folks are using for local LLMs, which will be super valuable for everyone.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly256a","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qjurm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752332351,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2qim8v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"in-the-widening-gyre","can_mod_post":false,"created_utc":1752331959,"send_replies":true,"parent_id":"t3_1ly256a","score":2,"author_fullname":"t2_ynpybwz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What will you be using the info you collect for?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qim8v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What will you be using the info you collect for?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qim8v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752331959,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qotfb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"buildmine10","can_mod_post":false,"created_utc":1752333917,"send_replies":true,"parent_id":"t3_1ly256a","score":2,"author_fullname":"t2_9zuu2802","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mostly for deep delves into specific aspects of quantum mechanics or relativity. It's usually as an insanity check. Sometimes the LLM says something in disagreement with my conclusions which prompts me to figure out if I or the LLM is wrong. Usually I'm wrong, but it takes a long time to actually figure out if the LLM is being logically consistent with the things it says and how those things lead to a different conclusion and where the issue with my conclusion was. You do have to go through this process of determining who is correct because logical inconsistency with prior statements is quite common for LLMs. Sycophantic LLMs are bad for this, because they capitulate immediately upon challenging their conclusion.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qotfb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mostly for deep delves into specific aspects of quantum mechanics or relativity. It&amp;#39;s usually as an insanity check. Sometimes the LLM says something in disagreement with my conclusions which prompts me to figure out if I or the LLM is wrong. Usually I&amp;#39;m wrong, but it takes a long time to actually figure out if the LLM is being logically consistent with the things it says and how those things lead to a different conclusion and where the issue with my conclusion was. You do have to go through this process of determining who is correct because logical inconsistency with prior statements is quite common for LLMs. Sycophantic LLMs are bad for this, because they capitulate immediately upon challenging their conclusion.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qotfb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752333917,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2qyh11","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Longjumpingfish0403","can_mod_post":false,"created_utc":1752336903,"send_replies":true,"parent_id":"t3_1ly256a","score":1,"author_fullname":"t2_jarttha4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you're into exploring how different tools handle LLM inconsistencies, you might like [this article](https://linktothearticle.com) on evaluating LLM performance with complex problems. It's key to figuring out if the model's logic or your own needs a tweak. Might be interesting if you're running local models for deep dives!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2qyh11","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re into exploring how different tools handle LLM inconsistencies, you might like &lt;a href=\\"https://linktothearticle.com\\"&gt;this article&lt;/a&gt; on evaluating LLM performance with complex problems. It&amp;#39;s key to figuring out if the model&amp;#39;s logic or your own needs a tweak. Might be interesting if you&amp;#39;re running local models for deep dives!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2qyh11/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752336903,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2r3gn3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ii_social","can_mod_post":false,"created_utc":1752338476,"send_replies":true,"parent_id":"t3_1ly256a","score":1,"author_fullname":"t2_tohvxz80x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Searching, Coding, thinking, talking, everything!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2r3gn3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Searching, Coding, thinking, talking, everything!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2r3gn3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752338476,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2r5hja","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Toooooool","can_mod_post":false,"created_utc":1752339107,"send_replies":true,"parent_id":"t3_1ly256a","score":2,"author_fullname":"t2_8llornh4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sorry but I answered about 20 questions before giving up, this is wayy too many questions in one batch for me to do.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2r5hja","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry but I answered about 20 questions before giving up, this is wayy too many questions in one batch for me to do.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly256a/how_are_you_using_llms_a_quick_survey/n2r5hja/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752339107,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly256a","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
