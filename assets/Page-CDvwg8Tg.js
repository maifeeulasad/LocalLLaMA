import{j as e}from"./index-CNyNkRpk.js";import{R as l}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I come across many v100 32g gpus, ecc all intact for $360 on chinese second hand market (I live in China) and can easily get stuff like bifurcated 300G nvlink sxm2 to pcie adapters etc. for no more than $40. \\n\\nAlso, if I get the 16gb version of the v100, it only costs $80 per card. \\n\\nWouldn't this be a better deal than something like a 4060ti or even 3090s (if I get 3 32gb v100s) for LLMs?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"32g SXM2 V100s for $360, Good Deal for LLMs?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lyiyvq","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":6,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1cqq3fards","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":6,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752377595,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I come across many v100 32g gpus, ecc all intact for $360 on chinese second hand market (I live in China) and can easily get stuff like bifurcated 300G nvlink sxm2 to pcie adapters etc. for no more than $40. &lt;/p&gt;\\n\\n&lt;p&gt;Also, if I get the 16gb version of the v100, it only costs $80 per card. &lt;/p&gt;\\n\\n&lt;p&gt;Wouldn&amp;#39;t this be a better deal than something like a 4060ti or even 3090s (if I get 3 32gb v100s) for LLMs?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lyiyvq","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"starikari","discussion_type":null,"num_comments":24,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/","subreddit_subscribers":498344,"created_utc":1752377595,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ut8dc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starikari","can_mod_post":false,"created_utc":1752387016,"send_replies":true,"parent_id":"t1_n2uj0cw","score":1,"author_fullname":"t2_1cqq3fards","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah I see, thank you so much!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ut8dc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah I see, thank you so much!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2ut8dc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387016,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2uvrdi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starikari","can_mod_post":false,"created_utc":1752388386,"send_replies":true,"parent_id":"t1_n2uj0cw","score":1,"author_fullname":"t2_1cqq3fards","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh yea, do you think I could mix it in my server along with newer gen cards to kinda offset that poor model compatibility, and still have their vram available for larger models? I'm talking a single 4090 48g etc., at least for inference","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uvrdi","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yea, do you think I could mix it in my server along with newer gen cards to kinda offset that poor model compatibility, and still have their vram available for larger models? I&amp;#39;m talking a single 4090 48g etc., at least for inference&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2uvrdi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752388386,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vu3i6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vt6r1","score":0,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yea, he seems to only want to support newest hardware. Even ampere isn't safe in the long run. Only way it will happen is with a fork. \\n\\nYou can always cast to FP32 as well. Got some vram headroom. FA/int8 stuff is yuge by comparison.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vu3i6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, he seems to only want to support newest hardware. Even ampere isn&amp;#39;t safe in the long run. Only way it will happen is with a fork. &lt;/p&gt;\\n\\n&lt;p&gt;You can always cast to FP32 as well. Got some vram headroom. FA/int8 stuff is yuge by comparison.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vu3i6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752407655,"author_flair_text":null,"treatment_tags":[],"created_utc":1752407655,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vt6r1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lly0571","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vmwit","score":2,"author_fullname":"t2_70vzcleel","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/huggingface/transformers/pull/36832](https://github.com/huggingface/transformers/pull/36832) . Gemma3 in FP16 is broken due to overflow I think.\\n\\nTuring could support FA2 in FP16 as there are third party implementations, but I don't think Tridao would still actively working on Turing.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2vt6r1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/huggingface/transformers/pull/36832\\"&gt;https://github.com/huggingface/transformers/pull/36832&lt;/a&gt; . Gemma3 in FP16 is broken due to overflow I think.&lt;/p&gt;\\n\\n&lt;p&gt;Turing could support FA2 in FP16 as there are third party implementations, but I don&amp;#39;t think Tridao would still actively working on Turing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vt6r1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752407236,"author_flair_text":null,"treatment_tags":[],"created_utc":1752407236,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vmwit","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1752404079,"send_replies":true,"parent_id":"t1_n2uj0cw","score":1,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"2080ti has a chance at native flash attention if someone does the do.. V100 will never.\\n\\n&gt;HF implementations of Gemma3 which require BF16)\\n\\nThe vision portion is listed in the config as BF16, can probably change that after converting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2vmwit","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2080ti has a chance at native flash attention if someone does the do.. V100 will never.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;HF implementations of Gemma3 which require BF16)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The vision portion is listed in the config as BF16, can probably change that after converting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vmwit/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404079,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uj0cw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lly0571","can_mod_post":false,"created_utc":1752381868,"send_replies":true,"parent_id":"t3_1lyiyvq","score":7,"author_fullname":"t2_70vzcleel","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In my opinion, V100 SXM2 (16G/32G) is currently the only worthwhile pre-Ampere GPU to purchase (better than 2080TI 22GB overall). Its advantages and disadvantages are both very prominent:\\n\\nAdvantages: High FP16 tensor performance and memory bandwidth (comparable to 3090), and low price. Thanks to its high memory bandwidth, the V100 16G can run Qwen3-14B-Q4 at 50+ tokens per second, which is 70% faster than the 4060TI and slightly faster than 5060TI.\\n\\nDisadvantages: Lack of support for int8 and BF16 leads to bad model compatibility (e.g., does not support AWQ implementations in vLLM, or HF implementations of Gemma3 which require BF16). CUDA 13 will drop support for Volta architecture.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uj0cw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my opinion, V100 SXM2 (16G/32G) is currently the only worthwhile pre-Ampere GPU to purchase (better than 2080TI 22GB overall). Its advantages and disadvantages are both very prominent:&lt;/p&gt;\\n\\n&lt;p&gt;Advantages: High FP16 tensor performance and memory bandwidth (comparable to 3090), and low price. Thanks to its high memory bandwidth, the V100 16G can run Qwen3-14B-Q4 at 50+ tokens per second, which is 70% faster than the 4060TI and slightly faster than 5060TI.&lt;/p&gt;\\n\\n&lt;p&gt;Disadvantages: Lack of support for int8 and BF16 leads to bad model compatibility (e.g., does not support AWQ implementations in vLLM, or HF implementations of Gemma3 which require BF16). CUDA 13 will drop support for Volta architecture.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2uj0cw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752381868,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2utmy9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starikari","can_mod_post":false,"created_utc":1752387232,"send_replies":true,"parent_id":"t1_n2ubtr0","score":1,"author_fullname":"t2_1cqq3fards","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Xianyu yea","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2utmy9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Xianyu yea&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2utmy9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387232,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ubtr0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Glittering-Call8746","can_mod_post":false,"created_utc":1752378671,"send_replies":true,"parent_id":"t3_1lyiyvq","score":2,"author_fullname":"t2_tqwl6sawb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What are these ? Tianyu items ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ubtr0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are these ? Tianyu items ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2ubtr0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752378671,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2v1fzx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"llama-impersonator","can_mod_post":false,"created_utc":1752391633,"send_replies":true,"parent_id":"t3_1lyiyvq","score":1,"author_fullname":"t2_14usv0hw3h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"there are a lot of downsides. i have a friend with a 4xV100 32GB server. like a lot of things, it really depends on what you plan to do with it. if you want to train models, v100 is a poor choice as it doesn't support flash attention or bf16. if all you care about is llama.cpp inference and image gen, it's not the worst choice.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v1fzx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;there are a lot of downsides. i have a friend with a 4xV100 32GB server. like a lot of things, it really depends on what you plan to do with it. if you want to train models, v100 is a poor choice as it doesn&amp;#39;t support flash attention or bf16. if all you care about is llama.cpp inference and image gen, it&amp;#39;s not the worst choice.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2v1fzx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752391633,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ve6my","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uti24","can_mod_post":false,"created_utc":1752399089,"send_replies":true,"parent_id":"t1_n2v2rp3","score":1,"author_fullname":"t2_13hbro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I always wonder if it's an artificial price difference, or if increasing memory really costs that much more.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ve6my","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I always wonder if it&amp;#39;s an artificial price difference, or if increasing memory really costs that much more.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2ve6my/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752399089,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2v2rp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Astronomer3007","can_mod_post":false,"created_utc":1752392395,"send_replies":true,"parent_id":"t3_1lyiyvq","score":1,"author_fullname":"t2_krzzvgf9q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Huge difference in price 16gb vs 32gb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v2rp3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Huge difference in price 16gb vs 32gb&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2v2rp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752392395,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wp8zc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vll8q","score":1,"author_fullname":"t2_131eezppgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s actually the opposite- datacenter usage is mostly very low utilisation as a % of time, with infrequent bursty workloads.\\n\\n\\nSo it’s almost certain your cards had no more than 8 months and 1.5 months heavy 24/7 usage.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2wp8zc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s actually the opposite- datacenter usage is mostly very low utilisation as a % of time, with infrequent bursty workloads.&lt;/p&gt;\\n\\n&lt;p&gt;So it’s almost certain your cards had no more than 8 months and 1.5 months heavy 24/7 usage.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2wp8zc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752418933,"author_flair_text":null,"treatment_tags":[],"created_utc":1752418933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vqtjz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Specialist8602","can_mod_post":false,"created_utc":1752406089,"send_replies":true,"parent_id":"t1_n2vpgtx","score":1,"author_fullname":"t2_ecdkrq9p","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well written if I can first say. PCB is typically different in comparison. Totally with the thermal cycling but do insist heat does most certainly have an impact. It's not the silicon but the pads between them and the PCB also. 90c, even if in specifications, will certainly have an impact compared to if the card was run at 40c.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2vqtjz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well written if I can first say. PCB is typically different in comparison. Totally with the thermal cycling but do insist heat does most certainly have an impact. It&amp;#39;s not the silicon but the pads between them and the PCB also. 90c, even if in specifications, will certainly have an impact compared to if the card was run at 40c.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vqtjz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752406089,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vpgtx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1752405401,"send_replies":true,"parent_id":"t1_n2vntzr","score":1,"author_fullname":"t2_baavelp5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's incorrect view. Consumer and datacenter GPU use exactly the same hardware. Tesla M40 uses exactly the same chip as GTX Titan X or GTX 980 Ti. Instinct Mi50 uses exactly the same chip as Radeon VII. The resilience of those products must me a perfect match, because the silicons are the same, the power delivery is the same, the memory is almost the same (M40 uses the same memory, but twice as much chips). Heat also does not kill a gpu, as long as it's withing manufacturers spec. A GPU can work for years under 90C die temperature and won't have a single problem. What does kill a GPU is thermal cycling: swings in temperature cause cyclical expansion and contraction, which leads to material fatigue and development of microcracks; thus a 1000 of cycles between 20C and 60C is way worse than a year under a constant 90C, and this is the reason why consumer GPUs fail earlier that industial ones. If both variants were put under exactly the same load, they would last for the same time.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2vpgtx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s incorrect view. Consumer and datacenter GPU use exactly the same hardware. Tesla M40 uses exactly the same chip as GTX Titan X or GTX 980 Ti. Instinct Mi50 uses exactly the same chip as Radeon VII. The resilience of those products must me a perfect match, because the silicons are the same, the power delivery is the same, the memory is almost the same (M40 uses the same memory, but twice as much chips). Heat also does not kill a gpu, as long as it&amp;#39;s withing manufacturers spec. A GPU can work for years under 90C die temperature and won&amp;#39;t have a single problem. What does kill a GPU is thermal cycling: swings in temperature cause cyclical expansion and contraction, which leads to material fatigue and development of microcracks; thus a 1000 of cycles between 20C and 60C is way worse than a year under a constant 90C, and this is the reason why consumer GPUs fail earlier that industial ones. If both variants were put under exactly the same load, they would last for the same time.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vpgtx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752405401,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vntzr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Specialist8602","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vll8q","score":0,"author_fullname":"t2_ecdkrq9p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":".. If I added my 2 cents.  Typically, consumer grade cards have an average expected life of 3 to 5 years.  About 10 years, however, is a realistic estimate for longevity. The non consumer cards add an extra 5 years typically. \\n\\nWhat kills a card over time is heat.  Heat is the enemy #1. If a card is cooled well, aka looked after well, it will serve its duty. \\n\\nNow, comparing a consumer grade card to an enterprise card is like comparing a Whirlpool to a Speedqueen.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2vntzr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;.. If I added my 2 cents.  Typically, consumer grade cards have an average expected life of 3 to 5 years.  About 10 years, however, is a realistic estimate for longevity. The non consumer cards add an extra 5 years typically. &lt;/p&gt;\\n\\n&lt;p&gt;What kills a card over time is heat.  Heat is the enemy #1. If a card is cooled well, aka looked after well, it will serve its duty. &lt;/p&gt;\\n\\n&lt;p&gt;Now, comparing a consumer grade card to an enterprise card is like comparing a Whirlpool to a Speedqueen.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vntzr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404558,"author_flair_text":null,"treatment_tags":[],"created_utc":1752404558,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vll8q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Refrigerator-1672","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vav91","score":2,"author_fullname":"t2_baavelp5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Both of those cards are already used. M40 served for 8 months 24/7 without any issue **after** being used for 10 years in datacenters. Well, maybe it served for just a few years in a data center and then in somebody's private server or mining rig, but anyway, that's a lot of wear. Mi50s are serving for me **after** being deployed in datacenters for 5 years. Datacenter load is like the heaviest load you can find, and still the cards are perfectly stable and perform up to original specs, which debunks your clain that cards can only work for 5 years max.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2vll8q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Both of those cards are already used. M40 served for 8 months 24/7 without any issue &lt;strong&gt;after&lt;/strong&gt; being used for 10 years in datacenters. Well, maybe it served for just a few years in a data center and then in somebody&amp;#39;s private server or mining rig, but anyway, that&amp;#39;s a lot of wear. Mi50s are serving for me &lt;strong&gt;after&lt;/strong&gt; being deployed in datacenters for 5 years. Datacenter load is like the heaviest load you can find, and still the cards are perfectly stable and perform up to original specs, which debunks your clain that cards can only work for 5 years max.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vll8q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752403376,"author_flair_text":null,"treatment_tags":[],"created_utc":1752403376,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2vnqrw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2vav91","score":1,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have SAS drives with that many years of power on time. They outlast consumer drives I bought new.\\n\\nAll my old D/C stuff like boards and cards did well too. DC has climate control and the heavy use susses out failures early. You only get to sell survivors used.\\n\\nHave run into plenty of ooooold equipment many places. It usually gets decommissioned due to being obsolete. Not to say future generations will start pricing that projected 3-5 lifespan in and cheap out, but so far it's a relatively safe bet.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2vnqrw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have SAS drives with that many years of power on time. They outlast consumer drives I bought new.&lt;/p&gt;\\n\\n&lt;p&gt;All my old D/C stuff like boards and cards did well too. DC has climate control and the heavy use susses out failures early. You only get to sell survivors used.&lt;/p&gt;\\n\\n&lt;p&gt;Have run into plenty of ooooold equipment many places. It usually gets decommissioned due to being obsolete. Not to say future generations will start pricing that projected 3-5 lifespan in and cheap out, but so far it&amp;#39;s a relatively safe bet.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vnqrw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752404512,"author_flair_text":null,"treatment_tags":[],"created_utc":1752404512,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2vav91","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2v475n","score":-2,"author_fullname":"t2_131eezppgs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don’t quite understand because my claim was that they get 3-5 years of heavy usage but your claim is that one card is fine after just 8 months and the other card is fine after just 1.5 months. This easily fits with my claim of 3-5 years.","edited":false,"author_flair_css_class":null,"name":"t1_n2vav91","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t quite understand because my claim was that they get 3-5 years of heavy usage but your claim is that one card is fine after just 8 months and the other card is fine after just 1.5 months. This easily fits with my claim of 3-5 years.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lyiyvq","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2vav91/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752397110,"author_flair_text":null,"collapsed":false,"created_utc":1752397110,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2v475n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Refrigerator-1672","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2uudma","score":5,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;GPUs last on average 3-5 years under heavy usage\\n\\nThis is simply not true. I was running a 10 years old used datacenter GPU (Tesla M40) in my personal server 24/7 with zero downtime for \\\\~8 months, and then upgraded for used 5 years old 2x Instinct Mi50, which are running for 1.5 months in the same uninterrupted 24/7 environment. Datacenter products are for sure heavily used at this age, yet all of the mentioned GPUs are totally fine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v475n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;GPUs last on average 3-5 years under heavy usage&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;This is simply not true. I was running a 10 years old used datacenter GPU (Tesla M40) in my personal server 24/7 with zero downtime for ~8 months, and then upgraded for used 5 years old 2x Instinct Mi50, which are running for 1.5 months in the same uninterrupted 24/7 environment. Datacenter products are for sure heavily used at this age, yet all of the mentioned GPUs are totally fine.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2v475n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752393204,"author_flair_text":null,"treatment_tags":[],"created_utc":1752393204,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2uvf6p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starikari","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2uudma","score":2,"author_fullname":"t2_1cqq3fards","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They have 2 year store warranty where I buy these and these are still verified to have ECC memory intact, so that kinda helps with the situation. But also, my old gtx 980 still works after sitting in my homelab for 11 years, and gpus dont degrade generally- even mining cards which I used my 980 for for \\\\~3 years during the first crypto boom.  \\nAlso 50 series gpu drivers are a mess and instabilities all over, plus the lack of support on stable linux distros currently-","edited":1752388419,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2uvf6p","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They have 2 year store warranty where I buy these and these are still verified to have ECC memory intact, so that kinda helps with the situation. But also, my old gtx 980 still works after sitting in my homelab for 11 years, and gpus dont degrade generally- even mining cards which I used my 980 for for ~3 years during the first crypto boom.&lt;br/&gt;\\nAlso 50 series gpu drivers are a mess and instabilities all over, plus the lack of support on stable linux distros currently-&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2uvf6p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752388199,"author_flair_text":null,"treatment_tags":[],"created_utc":1752388199,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2uudma","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"SlowFail2433","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2utln9","score":-7,"author_fullname":"t2_131eezppgs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"GPUs last on average 3-5 years under heavy usage and this card came out 8 years ago\\n\\n\\nThere are also lots of small aspects of drivers, CUDA and PTX that improve each generation.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2uudma","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GPUs last on average 3-5 years under heavy usage and this card came out 8 years ago&lt;/p&gt;\\n\\n&lt;p&gt;There are also lots of small aspects of drivers, CUDA and PTX that improve each generation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2uudma/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387629,"author_flair_text":null,"treatment_tags":[],"created_utc":1752387629,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"n2utln9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starikari","can_mod_post":false,"created_utc":1752387212,"send_replies":true,"parent_id":"t1_n2u9gu1","score":1,"author_fullname":"t2_1cqq3fards","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How come? These are very comparable to 60ti levels of cards and are not old enough to have been dropped support for some newer stuff","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2utln9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How come? These are very comparable to 60ti levels of cards and are not old enough to have been dropped support for some newer stuff&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lyiyvq","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2utln9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752387212,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2u9gu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SlowFail2433","can_mod_post":false,"created_utc":1752377664,"send_replies":true,"parent_id":"t3_1lyiyvq","score":0,"author_fullname":"t2_131eezppgs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Old GPUs are a trap","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2u9gu1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Old GPUs are a trap&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lyiyvq/32g_sxm2_v100s_for_360_good_deal_for_llms/n2u9gu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752377664,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lyiyvq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
